{"qas": [{"question": "Where did the term \"qahwah\" come from?", "answer": ""}, {"question": "When did the term coffee come into english?", "answer": "1598", "ae_score": -0.3465652987149197, "qg_score": null}, {"question": "When did the term coffee come into english?", "answer": "1598", "ae_score": -0.3465652987149197, "qg_score": null}], "content": "The first reference to coffee in the English language is in the form ''chaona'', dated to 1598 and understood to be a misprint of ''chaoua'', equivalent, in the orthography of the time, to ''chaova''. This term and \"coffee\" both derive from the Ottoman Turkish ''kahve'', by way of the Italian ''caff\u00e8''.\nIn turn, the Arabic ''qahwah'' may be an origin, traditionally held to refer to a type of wine whose etymology is given by Arab lexicographers as deriving from the verb ''qahiya'' (\u0642\u0647\u064a), \"to lack hunger\", in reference to the drink's reputation as an appetite suppressant. It has also been proposed that the source may be the Proto-Central Semitic root q-h-h meaning \"dark\".\nAlternatively, the word Khat, a plant widely used as stimulant in Yemen and Ethiopia before being supplanted by coffee has been suggested as a possible origin, or the Arabic word ''quwwah'' (meaning \"strength\").  It may also come from the Kingdom of Kaffa in southeast Ethiopia where Coffea arabica grows wild, but this is considered less likely; in the local Kaffa language, the coffee plant is instead called \"bunno\".\nThe expression \"coffee break\" was first attested in 1952. The term \"coffee pot\" dates from 1705.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Etymology", "sub_heading": "Etymology", "_id": "0--0---1---1", "title": "Coffee in the English Language"}
{"qas": [{"question": "How did the discovery of coffee come about?", "answer": ""}, {"question": "When did the story of kaldi first appear?", "answer": "1671", "ae_score": -0.4743884856074893, "qg_score": null}, {"question": "When did the story of kaldi first appear?", "answer": "1671", "ae_score": -0.4743884856074893, "qg_score": null}], "content": "According to legend, ancestors of today's Oromo people in a region of Kaffa in Ethiopia were believed to have been the first to recognize the energizing effect of the coffee plant, though no direct evidence has been found indicating where in Africa coffee grew or who among the native populations might have used it as a stimulant or even known about it, earlier than the 17th century. The story of Kaldi, the 9th-century Ethiopian goatherd who discovered coffee when he noticed how excited his goats became after eating the beans from a coffee plant, did not appear in writing until 1671 and is probably apocryphal.\nOther accounts attribute the discovery of coffee to Sheikh Omar. According to the ancient chronicle (preserved in the Abd-Al-Kadir manuscript), Omar, who was known for his ability to cure the sick through prayer, was once exiled from Mocha in Yemen to a desert cave near Ousab (modern day Wusab, about 90 km east of Zabid). Starving, Omar chewed berries from nearby shrubbery, but found them to be bitter. He tried roasting the seeds to improve the flavor, but they became hard. He then tried boiling them to soften the seed, which resulted in a fragrant brown liquid. Upon drinking the liquid Omar was revitalized and sustained for days. As stories of this \"miracle drug\" reached Mocha, Omar was asked to return and was made a saint. From Ethiopia, the coffee plant was introduced into the Arab World through Egypt and Yemen.", "page_name": "Coffee", "page_id": "Coffee", "heading": "History", "sub_heading": "History", "_id": "0--1--0---1", "title": "The Origins of Coffee in the Arab World"}
{"qas": [{"question": "How did Brazil become the largest coffee producer in the world?", "answer": ""}, {"question": "Where did the dutch first grow coffee?", "answer": "Java and Ceylon", "ae_score": -0.20586261670899245, "qg_score": null}, {"question": "Where did the dutch first grow coffee?", "answer": "Java and Ceylon", "ae_score": -0.20586261670899245, "qg_score": null}], "content": "The earliest credible evidence of coffee-drinking or knowledge of the coffee tree appears in the middle of the 15th century in the accounts of Ahmed al-Ghaffar in Yemen. It was here in Arabia that coffee seeds were first roasted and brewed, in a similar way to how it is now prepared. Coffee was used by Sufi circles to stay awake for their religious rituals. Accounts differ on the origin of coffee (seeds) prior to its appearance in Yemen. One account credits Muhammad ben Said for bringing the beverage to Aden from the African coast. Other early accounts say Ali ben Omar of the Shadhili Sufi order was the first to introduce coffee to Arabia. According to al Shardi, Ali ben Omar may have encountered coffee during his stay with the Adal king Sadadin's companions in 1401. Famous 16th century Islamic scholar Ibn Hajar al-Haytami notes in his writings of a beverage called qahwa developed from a tree in the Zeila region.<ref name=encyclopedia-of-islam-kawah/>\nBy the 16th century, it had reached the rest of the Middle East, Persia, Turkey, and northern Africa.  The first coffee smuggled out of the Middle East was by Sufi Baba Budan from Yemen to India in 1670. Before then, all exported coffee was boiled or otherwise sterilised. Portraits of Baba Budan depict him as having smuggled seven coffee seeds by strapping them to his chest. The first plants grown from these smuggled seeds were planted in Mysore. Coffee then spread to Italy, and to the rest of Europe, to Indonesia, and to the Americas.\nIn 1583, Leonhard Rauwolf, a German physician, gave this description of coffee after returning from a ten-year trip to the Near East:\nFrom the Middle East, coffee spread to Italy. The thriving trade between Venice and North Africa, Egypt, and the Middle East brought many goods, including coffee, to the Venetian port. From Venice, it was introduced to the rest of Europe. Coffee became more widely accepted after it was deemed a Christian beverage by Pope Clement VIII in 1600, despite appeals to ban the \"Muslim drink.\" The first European coffee house opened in Rome in 1645.\nThe Dutch East India Company was the first to import coffee on a large scale. The Dutch later grew the crop in Java and Ceylon. The first exports of Indonesian coffee from Java to the Netherlands occurred in 1711.\nThrough the efforts of the British East India Company, coffee became popular in England as well. Oxford's Queen's Lane Coffee House, established in 1654, is still in existence today. Coffee was introduced in France in 1657, and in Austria and Poland after the 1683 Battle of Vienna, when coffee was captured from supplies of the defeated Turks.\nWhen coffee reached North America during the Colonial period, it was initially not as successful as it had been in Europe as alcoholic beverages remained more popular. During the Revolutionary War, the demand for coffee increased so much that dealers had to hoard their scarce supplies and raise prices dramatically; this was also due to the reduced availability of tea from British merchants, and a general resolution among many Americans to avoid drinking tea following the 1773 Boston Tea Party.<ref>(1) <br>(2)  At Google Books. Note: Fredricka Charlotte Riedesel was the wife of General Friedrich Adolf Riedesel, commander of all German and Indian troops in General John Burgoyne's Saratoga campaign and American prisoner of war during the American Revolution.<br>(3)  At Google Books.<br>(4) <br>(5) \nAfter the War of 1812, during which Britain temporarily cut off access to tea imports, the Americans' taste for coffee grew. Coffee consumption declined in England, giving way to tea during the 18th century. The latter beverage was simpler to make, and had become cheaper with the British conquest of India and the tea industry there. During the Age of Sail, seamen aboard ships of the British Royal Navy made substitute coffee by dissolving burnt bread in hot water.\nThe Frenchman Gabriel de Clieu took a coffee plant to the French territory of Martinique in the Caribbean, from which much of the world's cultivated arabica coffee is descended. Coffee thrived in the climate and was conveyed across the Americas. Coffee was cultivated in Saint-Domingue (now Haiti) from 1734, and by 1788 it supplied half the world's coffee. The conditions that the slaves worked in on coffee plantations were a factor in the soon to follow Haitian Revolution. The coffee industry never fully recovered there. It made a brief come-back in 1949 when Haiti was the world's 3rd largest coffee exporter, but fell quickly into rapid decline.\nMeanwhile, coffee had been introduced to Brazil in 1727, although its cultivation did not gather momentum until independence in 1822. After this time massive tracts of rainforest were cleared for coffee plantations, first in the vicinity of Rio de Janeiro and later S\u00e3o Paulo. Brazil went from having essentially no coffee exports in 1800, to being a significant regional producer in 1830, to being the largest producer in the world by 1852. In 1910-20, Brazil exported around 70% of the world's coffee, Colombia, Guatemala, and Venezuela, exported half of the remaining 30%, and Old World production accounted for less than 5% of world exports.\nCultivation was taken up by many countries in Central America in the latter half of the 19th century, and almost all involved the large-scale displacement and exploitation of the indigenous people. Harsh conditions led to many uprisings, coups and bloody suppression of peasants. The notable exception was Costa Rica, where lack of ready labor prevented the formation of large farms. Smaller farms and more egalitarian conditions ameliorated unrest over the 19th and 20th centuries.\nRapid growth in coffee production in South America during the second half of the 19th century was matched by growth in consumption in developed countries, though nowhere has this growth been as pronounced as in the United States, where high rate of population growth was compounded by doubling of per capita consumption between 1860 and 1920. Though the United States was not the heaviest coffee-drinking nation at the time (Nordic countries, Belgium, and Netherlands all had comparable or higher levels of per capita consumption), due to its sheer size, it was already the largest consumer of coffee in the world by 1860, and, by 1920, around half of all coffee produced worldwide was consumed in the USA.\nCoffee has become a vital cash crop for many developing countries. Over one hundred million people in developing countries have become dependent on coffee as their primary source of income. It has become the primary export and backbone for African countries like Uganda, Burundi, Rwanda, and Ethiopia, as well as many Central American countries.", "page_name": "Coffee", "page_id": "Coffee", "heading": "History", "sub_heading": "Historical transmission", "_id": "0--1--1---1", "title": "Coffee and the Coffee Industry in the World"}
{"qas": [{"question": "What is the significance of the new discovery of coffee in amber?", "answer": ""}, {"question": "What is the name of the plant that gives us coffee?", "answer": "Strychnos electri", "ae_score": -0.30613860369420065, "qg_score": null}, {"question": "What is the name of the plant that gives us coffee?", "answer": "Strychnos electri", "ae_score": -0.30613860369420065, "qg_score": null}], "content": "Several species of shrub of the genus ''Coffea'' produce the berries from which coffee is extracted. The two main species commercially cultivated are ''Coffea canephora'' (predominantly a form known as 'robusta') and ''C. arabica''. ''C. arabica'', the most highly regarded species, is native to the southwestern highlands of Ethiopia and the Boma Plateau in southeastern Sudan and possibly Mount Marsabit in northern Kenya. ''C. canephora'' is native to western and central Subsaharan Africa, from Guinea to Uganda and southern Sudan. Less popular species are ''C. liberica'', ''C. stenophylla'', ''C. mauritiana'', and ''C. racemosa''.\nAll coffee plants are classified in the large family Rubiaceae. They are evergreen shrubs or trees that may grow 5 m (15 ft) tall when unpruned. The leaves are dark green and glossy, usually 10\u201315 cm (4\u20136 in) long and 6 cm (2.4 in) wide, simple, entire, and opposite. Petioles of opposite leaves fuse at base to form interpetiolar stipules, characteristic of Rubiaceae. The flowers are axillary, and clusters of fragrant white flowers bloom simultaneously. Gynoecium consists of inferior ovary, also characteristic of Rubiaceae. The flowers are followed by oval berries of about 1.5 cm (0.6 in). When immature they are green, and they ripen to yellow, then crimson, before turning black on drying. Each berry usually contains two seeds, but 5\u201310% of the berries have only one; these are called peaberries. Arabica berries ripen in six to eight months, while robusta take nine to eleven months.\n''Coffea arabica'' is predominantly self-pollinating, and as a result the seedlings are generally uniform and vary little from their parents. In contrast, ''Coffea canephora'', and ''C. liberica'' are self-incompatible and require outcrossing. This means that useful forms and hybrids must be propagated vegetatively. Cuttings, grafting, and budding are the usual methods of vegetative propagation. On the other hand, there is great scope for experimentation in search of potential new strains.<ref name=CW158/>\nIn 2016, Oregon State University entomologist George Poinar, Jr. announced the discovery of a new plant species that's a 45-million-year-old relative of coffee found in amber.  Named Strychnos electri, after the Greek word for amber (electron), the flowers represent the first-ever fossils of an asterid, which is a family of flowering plants that not only later gave us coffee, but also sunflowers, peppers, potatoes, mint \u2014 and deadly poisons.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Biology", "sub_heading": "Biology", "_id": "0--2---1---1", "title": "''Coffea canephora'' and ''C. liber"}
{"qas": [{"question": "Why is it better to grow coffee in the shade than in the sun?", "answer": ""}, {"question": "What is the main problem with coffee beans?", "answer": "water", "ae_score": -0.4507702865708533, "qg_score": null}, {"question": "What is the main problem with coffee beans?", "answer": "water", "ae_score": -0.4507702865708533, "qg_score": null}], "content": "Originally, coffee farming was done in the shade of trees that provided a habitat for many animals and insects. Remnant forest trees were used for this purpose, but many species have been planted as well. These include leguminous trees of the genera ''Acacia'', ''Albizia'', ''Cassia'', ''Erythrina'', ''Gliricidia'', ''Inga'', and ''Leucaena'', as well as the nitrogen-fixing non-legume sheoaks of the genus ''Casuarina'', and the silky oak ''Grevillea robusta''.\nThis method is commonly referred to as the traditional shaded method, or \"shade-grown\". Starting in the 1970s, many farmers switched their production method to sun cultivation, in which coffee is grown in rows under full sun with little or no forest canopy. This causes berries to ripen more rapidly and bushes to produce higher yields, but requires the clearing of trees and increased use of fertilizer and pesticides, which damage the environment and cause health problems.\nUnshaded coffee plants grown with fertilizer yield the most coffee, although unfertilized shaded crops generally yield more than unfertilized unshaded crops: the response to fertilizer is much greater in full sun. While traditional coffee production causes berries to ripen more slowly and produce lower yields, the quality of the coffee is allegedly superior. In addition, the traditional shaded method provides living space for many wildlife species. Proponents of shade cultivation say environmental problems such as deforestation, pesticide pollution, habitat destruction, and soil and water degradation are the side effects of the practices employed in sun cultivation.<ref name=Janzen/>\nThe American Birding Association, Smithsonian Migratory Bird Center, National Arbor Day Foundation, and the Rainforest Alliance have led a campaign for 'shade-grown' and organic coffees, which can be sustainably harvested. Shaded coffee cultivation systems show greater biodiversity than full-sun systems, and those more distant from continuous forest compare rather poorly to undisturbed native forest in terms of habitat value for some bird species.\nAnother issue concerning coffee is its use of water. It takes about 140 l of water to grow the coffee beans needed to produce one cup of coffee, and coffee is often grown in countries where there is a water shortage, such as Ethiopia.\nUsed coffee grounds may be used for composting or as a mulch. They are especially appreciated by worms and acid-loving plants such as blueberries. Some commercial coffee shops run initiatives to make better use of these grounds, including Starbucks' \"Grounds for your Garden\" project, and community sponsored initiatives such as \"Ground to Ground\".\nStarbucks sustainability chief Jim Hanna has warned that climate change may significantly impact coffee yields within a few decades. A study by Kew Royal Botanic Gardens concluded that global warming threatens the genetic diversity of Arabica plants found in Ethiopia and surrounding countries.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Cultivation", "sub_heading": "Cultivation", "_id": "0--3--0---1", "title": "Why Shaded Coffee Is Better Than Sun-Cultivated"}
{"qas": [{"question": "How does the process of making green coffee work?", "answer": ""}, {"question": "What is lost during the roasting process?", "answer": "Sucrose", "ae_score": -0.17454135956703642, "qg_score": null}, {"question": "What is lost during the roasting process?", "answer": "Sucrose", "ae_score": -0.17454135956703642, "qg_score": null}], "content": "The next step in the process is the roasting of the green coffee. Coffee is usually sold in a roasted state, and with rare exceptions all coffee is roasted before it is consumed. It can be sold roasted by the supplier, or it can be home roasted. The roasting process influences the taste of the beverage by changing the coffee bean both physically and chemically. The bean decreases in weight as moisture is lost and increases in volume, causing it to become less dense. The density of the bean also influences the strength of the coffee and requirements for packaging.\nThe actual roasting begins when the temperature inside the bean reaches approximately 200 \u00b0C, though different varieties of seeds differ in moisture and density and therefore roast at different rates. During roasting, caramelization occurs as intense heat breaks down starches, changing them to simple sugars that begin to brown, which alters the color of the bean.\nSucrose is rapidly lost during the roasting process, and may disappear entirely in darker roasts. During roasting, aromatic oils and acids weaken, changing the flavor; at 205 \u00b0C, other oils start to develop. One of these oils, caffeol, is created at about 200 \u00b0C, which is largely responsible for coffee's aroma and flavor.\nRoasting is the last step of processing the beans in their intact state. During this last treatment, while still in the bean state, more caffeine breaks down above 235 \u00b0C. Dark roasting is the utmost step in bean processing removing the most caffeine. Although, dark roasting is not to be confused with the Decaffeination process.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Processing", "_id": "0--5--0---1", "title": "Coffee Roasting Process \u2014 Overview"}
{"qas": [{"question": "How do they determine the degree of roast coffee?", "answer": ""}, {"question": "What is the process used to determine the relative degree of roast?", "answer": "spectroscopy", "ae_score": -0.4573752792335833, "qg_score": null}, {"question": "What is the process used to determine the relative degree of roast?", "answer": "spectroscopy", "ae_score": -0.4573752792335833, "qg_score": null}], "content": "Depending on the color of the roasted beans as perceived by the human eye, they will be labeled as light, medium light, medium, medium dark, dark, or very dark. A more accurate method of discerning the degree of roast involves measuring the reflected light from roasted seeds illuminated with a light source in the near-infrared spectrum. This elaborate light meter uses a process known as spectroscopy to return a number that consistently indicates the roasted coffee's relative degree of roast or flavor development.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Grading roasted beans", "_id": "0--5--1---1", "title": "Roasted Beans \u2014 Roasted Coffee"}
{"qas": [{"question": "Why does coffee taste different depending on the roasting time?", "answer": ""}, {"question": "What is produced from the skin left on the seed after roasting?", "answer": "chaff", "ae_score": -0.3654458709779958, "qg_score": null}, {"question": "What is produced from the skin left on the seed after roasting?", "answer": "chaff", "ae_score": -0.3654458709779958, "qg_score": null}], "content": "The degree of roast has an effect upon coffee flavor and body. Darker roasts are generally bolder because they have less fiber content and a more sugary flavor. Lighter roasts have a more complex and therefore perceived stronger flavor from aromatic oils and acids otherwise destroyed by longer roasting times. Roasting does not alter the amount of caffeine in the bean, but does give less caffeine when the beans are measured by volume because the beans expand during roasting.\nA small amount of chaff is produced during roasting from the skin left on the seed after processing. Chaff is usually removed from the seeds by air movement, though a small amount is added to dark roast coffees to soak up oils on the seeds.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Roast characteristics", "_id": "0--5--2---1", "title": "Coffee Roasting \u2014 Coffee Roasting"}
{"qas": [{"question": "How does decaffeination work?", "answer": ""}, {"question": "What is the process of removing caffeine from coffee called?", "answer": "Decaffeination", "ae_score": -0.38872081148217874, "qg_score": null}, {"question": "What is the process of removing caffeine from coffee called?", "answer": "Decaffeination", "ae_score": -0.38872081148217874, "qg_score": null}], "content": "Decaffeination may also be part of the processing that coffee seeds undergo. Seeds are decaffeinated when they are still green. Many methods can remove caffeine from coffee, but all involve either soaking the green seeds in hot water (often called the \"Swiss water process\") or steaming them, then using a solvent to dissolve caffeine-containing oils. Decaffeination is often done by processing companies, and the extracted caffeine is usually sold to the pharmaceutical industry.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Decaffeination", "_id": "0--5--3---1", "title": "Decaffeination of Coffee Seeds"}
{"qas": [{"question": "Why does coffee need to be refrigerated?", "answer": ""}, {"question": "When was the sealed vacuum used to pack coffee?", "answer": "1931", "ae_score": -0.3989677457337543, "qg_score": null}, {"question": "When was the sealed vacuum used to pack coffee?", "answer": "1931", "ae_score": -0.3989677457337543, "qg_score": null}], "content": "Coffee is best stored in an airtight container made of ceramic, glass, or non-reactive metal. Higher quality prepackaged coffee usually has a one-way valve which prevents air from entering while allowing the coffee to release gases. Coffee freshness and flavor is preserved when it is stored away from moisture, heat, and light. The ability of coffee to absorb strong smells from food means that it should be kept away from such smells. Storage of coffee in the refrigerator is not recommended due to the presence of moisture which can cause deterioration. Exterior walls of buildings which face the sun may heat the interior of a home, and this heat may damage coffee stored near such a wall. Heat from nearby ovens also harms stored coffee.\nIn 1931, a method of packing coffee in a sealed vacuum in cans was introduced. The roasted coffee was packed and then 99% of the air was removed, allowing the coffee to be stored indefinitely until the can was opened. Today this method is in mass use for coffee in a large part of the world.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Storage", "_id": "0--5--4---1", "title": "How to Store Coffee in an Airtight Container"}
{"qas": [{"question": "Why does cold brew coffee taste better than hot brew coffee?", "answer": ""}, {"question": "What type of coffee is made with darker roasted coffee?", "answer": "espresso", "ae_score": -0.516824503745425, "qg_score": null}, {"question": "What type of coffee is made with darker roasted coffee?", "answer": "espresso", "ae_score": -0.516824503745425, "qg_score": null}], "content": "Coffee beans must be ground and brewed to create a beverage. The criteria for choosing a method include flavor and economy. Almost all methods of preparing coffee require that the beans be ground and then mixed with hot water long enough to allow the flavor to emerge but not so long as to draw out bitter compounds. The liquid can be consumed after the spent grounds are removed. Brewing considerations include the fineness of grind, the way in which the water is used to extract the flavor, the ratio of coffee grounds to water (the brew ratio), additional flavorings such as sugar, milk, and spices, and the technique to be used to separate spent grounds. Ideal holding temperatures range from 85-88 C to as high as 93 C and the ideal serving temperature is 68 to. The recommended brew ratio for non-espresso coffee is around 55 to 60 grams of grounds per litre of water, or two level tablespoons for a 5- or 6-ounce cup.\nThe roasted coffee beans may be ground at a roastery, in a grocery store, or in the home. Most coffee is roasted and ground at a roastery and sold in packaged form, though roasted coffee beans can be ground at home immediately before consumption. It is also possible, though uncommon, to roast raw beans at home.\nThe choice of brewing method depends to some extent on the degree to which the coffee beans have been roasted. Lighter roasted coffee tends to be used for filter coffee as the combination of method and roast style results in higher acidity, complexity, and clearer nuances. Darker roasted coffee is used for espresso because the machine naturally extracts more dissolved solids, causing lighter coffee to become too acidic.\nCoffee beans may be ground in several ways. A burr grinder uses revolving elements to shear the seed; a blade grinder cuts the seeds with blades moving at high speed; and a mortar and pestle crushes the seeds. For most brewing methods a burr grinder is deemed superior because the grind is more even and the grind size can be adjusted.\nThe type of grind is often named after the brewing method for which it is generally used. Turkish grind is the finest grind, while coffee percolator or French press are the coarsest grinds. The most common grinds are between these two extremes: a medium grind is used in most home coffee-brewing machines.\nCoffee may be brewed by several methods. It may be boiled, steeped, or pressurized. Brewing coffee by boiling was the earliest method, and Turkish coffee is an example of this method. It is prepared by grinding or pounding the seeds to a fine powder, then adding it to water and bringing it to the boil for no more than an instant in a pot called a ''cezve'' or, in Greek, a ''br\u00edki''. This produces a strong coffee with a layer of foam on the surface and sediment (which is not meant for drinking) settling at the bottom of the cup.\nCoffee percolators and automatic coffeemakers brew coffee using gravity. In an automatic coffeemaker, hot water drips onto coffee grounds that are held in a paper, plastic, or perforated metal coffee filter, allowing the water to seep through the ground coffee while extracting its oils and essences. The liquid drips through the coffee and the filter into a carafe or pot, and the spent grounds are retained in the filter.\nIn a percolator, boiling water is forced into a chamber above a filter by steam pressure created by boiling. The water then seeps through the grounds, and the process is repeated until terminated by removing from the heat, by an internal timer,or by a thermostat that turns off the heater when the entire pot reaches a certain temperature.\nCoffee may be brewed by steeping in a device such as a French press (also known as a cafeti\u00e8re, coffee press or coffee plunger). Ground coffee and hot water are combined in a cylindrical vessel and left to brew for a few minutes. A circular filter which fits tightly in the cylinder fixed to a plunger is then pushed down from the top to force the grounds to the bottom. The filter retains the grounds at the bottom as the coffee is poured from the container. Because the coffee grounds are in direct contact with the water, all the coffee oils remain in the liquid, making it a stronger beverage. This method of brewing leaves more sediment than in coffee made by an automatic coffee machine. Supporters of the French press method point out that the sediment issue can be minimized by using the right type of grinder: they claim that a rotary blade grinder cuts the coffee bean into a wide range of sizes, including a fine coffee dust that remains as sludge at the bottom of the cup, while a burr grinder uniformly grinds the beans into consistently-sized grinds, allowing the coffee to settle uniformly and be trapped by the press. Within the first minute of brewing 95% of the caffeine is released from the coffee bean.\nThe espresso method forces hot pressurized and vaporized water through ground coffee. As a result of brewing under high pressure (ideally between 9\u201310 atm), the espresso beverage is more concentrated (as much as 10 to 15 times the quantity of coffee to water as gravity-brewing methods can produce) and has a more complex physical and chemical constitution. A well-prepared espresso has a reddish-brown foam called ''crema'' that floats on the surface. Other pressurized water methods include the moka pot and vacuum coffee maker.\nCold brew coffee is made by steeping coarsely ground beans in cold water for several hours, then filtering them. This results in a brew lower in acidity than most hot-brewing methods.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Brewing", "_id": "0--5--5---1", "title": "How to Brew Coffee"}
{"qas": [{"question": "Why does coffee have so much caffeine in it?", "answer": ""}, {"question": "How much caffeine is in 100 gram of coffee grounds?", "answer": "212 mg", "ae_score": -0.9583148957553057, "qg_score": null}, {"question": "How much caffeine is in 100 gram of coffee grounds?", "answer": "212 mg", "ae_score": -0.9583148957553057, "qg_score": null}], "content": "Brewed coffee from typical grounds prepared with tap water contains 40 mg caffeine per 100 gram and no essential nutrients in significant content. In espresso, however, likely due to its higher amount of suspended solids, there are significant contents of magnesium, the B vitamins, niacin and riboflavin, and 212 mg of caffeine per 100 grams of grounds.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Nutrition", "_id": "0--5--6---1", "title": "Coffee | Processing | Nutrition"}
{"qas": [{"question": "What is the difference between coffee and tea?", "answer": ""}, {"question": "In irish coffee, what is added to coffee to make it drinkable?", "answer": "whiskey", "ae_score": -0.42518186813763736, "qg_score": null}, {"question": "In irish coffee, what is added to coffee to make it drinkable?", "answer": "whiskey", "ae_score": -0.42518186813763736, "qg_score": null}], "content": "Once brewed, coffee may be served in a variety of ways. Drip-brewed, percolated, or French-pressed/cafeti\u00e8re coffee may be served as ''white coffee'' with a dairy product such as milk or cream, or dairy substitute, or as ''black coffee'' with no such addition. It may be sweetened with sugar or artificial sweetener. When served cold, it is called ''iced coffee''.\nEspresso-based coffee has a variety of possible presentations. In its most basic form, an espresso is served alone as a ''shot'' or ''short black'', or with hot water added, when it is known as Caff\u00e8 Americano. A long black is made by pouring a double espresso into an equal portion of water, retaining the crema, unlike Caff\u00e8 Americano.Milk is added in various forms to an espresso: steamed milk makes a caff\u00e8 latte, equal parts steamed milk and milk froth make a cappuccino, and a dollop of hot foamed milk on top creates a caff\u00e8 macchiato. A flat white is prepared by adding steamed hot milk (microfoam) to espresso so that the flavour is brought out and the texture is unusually velvety. It has less milk than a latte but both are varieties of coffee to which the milk can be added in such a way as to create a decorative surface pattern. Such effects are known as latte art.\nCoffee can also be incorporated with alcohol to produce a variety of beverages: it is combined with whiskey in Irish coffee, and it forms the base of alcoholic coffee liqueurs such as Kahl\u00faa and Tia Maria. Darker beers such as stout and porter give a chocolate or coffee-like taste due to roasted grains even though actual coffee beans are not added to it.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Serving", "_id": "0--5--7---1", "title": "Coffee \u2014 The Art of Espresso"}
{"qas": [{"question": "Why is canned coffee so popular in Asian countries?", "answer": ""}, {"question": "What is the most popular brand of instant coffee?", "answer": "Nescaf\u00e9", "ae_score": -0.3444016936361491, "qg_score": null}, {"question": "What is the most popular brand of instant coffee?", "answer": "Nescaf\u00e9", "ae_score": -0.3444016936361491, "qg_score": null}], "content": "A number of products are sold for the convenience of consumers who do not want to prepare their own coffee or who do not have access to coffeemaking equipment. Instant coffee is dried into soluble powder or freeze-dried into granules that can be quickly dissolved in hot water. Originally invented in 1907, it rapidly gained in popularity in many countries in the post-war period, with Nescaf\u00e9 being the most popular product. Many consumers determined that the convenience in preparing a cup of instant coffee more than made up for a perceived inferior taste, although, since the late 1970s, instant coffee has been produced differently in such a way that is similar to the taste of freshly brewed coffee. Paralleling (and complementing) the rapid rise of instant coffee was the coffee vending machine invented in 1947 and widely distributed since the 1950s.\nCanned coffee has been popular in Asian countries for many years, particularly in China, Japan, South Korea, and Taiwan. Vending machines typically sell varieties of flavored canned coffee, much like brewed or percolated coffee, available both hot and cold. Japanese convenience stores and groceries also have a wide availability of bottled coffee drinks, which are typically lightly sweetened and pre-blended with milk. Bottled coffee drinks are also consumed in the United States.\nLiquid coffee concentrates are sometimes used in large institutional situations where coffee needs to be produced for thousands of people at the same time. It is described as having a flavor about as good as low-grade robusta coffee, and costs about 10\u00a2 a cup to produce. The machines can process up to 500 cups an hour, or 1,000 if the water is preheated.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Processing", "sub_heading": "Instant coffee", "_id": "0--5--8---1", "title": "Instant Coffee Vending Machines and Liquid Coffee Concentrate"}
{"qas": [{"question": "Why is coffee the world's second most valuable commodity?", "answer": ""}, {"question": "When did international coffee day start in japan?", "answer": "1983", "ae_score": -0.15114614713082236, "qg_score": null}, {"question": "When did international coffee day start in japan?", "answer": "1983", "ae_score": -0.15114614713082236, "qg_score": null}], "content": "Coffee ingestion on average is about a third of that of tap water in North America and Europe. Worldwide, 6.7 million metric tons of coffee were produced annually in 1998\u20132000, and the forecast is a rise to seven million metric tons annually by 2010.\nBrazil remains the largest coffee exporting nation, however Vietnam tripled its exports between 1995 and 1999 and became a major producer of robusta seeds. Indonesia is the third-largest coffee exporter overall and the largest producer of washed arabica coffee. Organic Honduran coffee is a rapidly growing emerging commodity owing to the Honduran climate and rich soil.\nIn 2013, ''The Seattle Times'' reported that global coffee prices dropped more than 50 percent year-over-year. In Thailand, black ivory coffee beans are fed to elephants whose digestive enzymes reduce the bitter taste of beans collected from dung.<ref name=hp/> These beans sell for up to $1,100 a kilogram ($500 per lb), achieving the world's most expensive coffee some three times costlier than beans harvested from the dung of Asian palm civets.<ref name=top10/><ref name=econ/>\nCoffee is bought and sold as green coffee beans by roasters, investors, and price speculators as a tradable commodity in commodity markets and exchange-traded funds. Coffee futures contracts for Grade 3 washed arabicas are traded on the New York Mercantile Exchange under ticker symbol '''KC''', with contract deliveries occurring every year in March, May, July, September, and December. Coffee is an example of a product that has been susceptible to significant commodity futures price variations. Higher and lower grade arabica coffees are sold through other channels. Futures contracts for robusta coffee are traded on the London International Financial Futures and Options Exchange and, since 2007, on the New York Intercontinental Exchange.\nDating to the 1970s, coffee has been incorrectly described by many, including historian Mark Pendergrast, as the world's \"second most legally traded commodity\". Instead, \"coffee was the second most valuable commodity exported by developing countries,\" from 1970 to circa 2000. This fact was derived from the United Nations Conference on Trade and Development Commodity Yearbooks which show \"Third World\" commodity exports by value in the period 1970\u20131998 as being in order of crude oil in first place, coffee in second, followed by sugar, cotton, and others. Coffee continues to be an important commodity export for developing countries, but more recent figures are not readily available due to the shifting and politicized nature of the category \"developing country\".\nInternational Coffee Day, which is claimed to have originated in Japan in 1983 with an event organised by the All Japan Coffee Association, takes place on September 29 in several countries.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Sale and distribution", "sub_heading": "Sale and distribution", "_id": "0--6---1---1", "title": "The World's Most Valuable Commodity: Coffee"}
{"qas": [{"question": "Why does coffee have psychoactive properties?", "answer": ""}, {"question": "What is the main psychoactive chemical in coffee?", "answer": "caffeine", "ae_score": -0.08360398330106443, "qg_score": null}, {"question": "What is the main psychoactive chemical in coffee?", "answer": "caffeine", "ae_score": -0.08360398330106443, "qg_score": null}], "content": "The primary psychoactive chemical in coffee is caffeine, an adenosine antagonist that is known for its stimulant effects. Coffee also contains the monoamine oxidase inhibitors \u03b2-carboline and harmane, which may contribute to its psychoactivity.\nIn a healthy liver, caffeine is mostly broken down by the hepatic microsomal enzymatic system. The excreted metabolites are mostly paraxanthines\u2014theobromine and theophylline\u2014and a small amount of unchanged caffeine. Therefore, the metabolism of caffeine depends on the state of this enzymatic system of the liver.\nPolyphenols in coffee have been shown to affect free radicals in vitro, but there is no evidence that this effect occurs in humans. Polyphenol levels vary depending on how beans are roasted as well as for how long. As interpreted by the Linus Pauling Institute and the European Food Safety Authority, dietary polyphenols, such as those ingested by consuming coffee, have little or no direct antioxidant value following ingestion.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Health and pharmacology", "sub_heading": "Health and pharmacology", "_id": "0--7--0---1", "title": "The Psychoactive Effects of Coffee"}
{"qas": [{"question": "Why is coffee associated with lower risk of type 2 diabetes?", "answer": ""}, {"question": "What are the effects of coffee on?", "answer": "cancer risk", "ae_score": -0.2270577958765514, "qg_score": null}, {"question": "What are the effects of coffee on?", "answer": "cancer risk", "ae_score": -0.2270577958765514, "qg_score": null}], "content": "Findings have been contradictory as to whether coffee has any specific health benefits, and results are similarly conflicting regarding the potentially harmful effects of coffee consumption. Furthermore, results and generalizations are complicated by differences in age, gender, health status, and serving size.\nExtensive scientific research has been conducted to examine the relationship between coffee consumption and an array of medical conditions. The consensus in the medical community is that moderate regular coffee drinking in healthy individuals is either essentially benign or mildly beneficial.  Researchers involved in an ongoing 22-year study by the Harvard School of Public Health stated that \"Coffee may have potential health benefits, but more research needs to be done.\"\nIn 2012, the National Institutes of Health\u2013AARP Diet and Health Study analysed the relationship between coffee drinking and mortality. They found that higher coffee consumption was associated with lower risk of death, and that those who drank any coffee lived longer than those who did not. However the authors noted, \"whether this was a causal or associational finding cannot be determined from our data.\" A 2014 meta-analysis found that coffee consumption (4 cups/day) was inversely associated with all-cause mortality (a 16% lower risk), as well as cardiovascular disease mortality specifically (a 21% lower risk from drinking 3 cups/day), but not with cancer mortality. Additional meta-analysis studies corroborated these findings, showing that higher coffee consumption (2\u20134 cups per day) was associated with a reduced risk of death by all disease causes.\nCoffee is no longer thought to be a risk factor for coronary heart disease. A 2012 meta-analysis concluded that people who drank moderate amounts of coffee had a lower rate of heart failure, with the biggest effect found for those who drank more than four cups a day. Moreover, in one preliminary study, habitual coffee consumption was associated with improved vascular function. Interestingly, a recent meta-analysis showed that coffee consumption was associated with a reduced risk of death in patients who have had a myocardial infarction.\nOne review published in 2004 indicated a negative correlation between suicide rates and coffee consumption, but this effect has not been confirmed in larger studies.\nLong-term studies of both risk and potential benefit of coffee consumption by elderly people, including assessment on symptoms of Alzheimer's disease and cognitive impairment, are not conclusive.<ref name=nehlig/>\nSome research suggests that a minority of moderate regular caffeine consumers experience some amount of clinical depression, anxiety, low vigor, or fatigue when discontinuing their caffeine use. However, the methodology of these studies has been criticized. Withdrawal effects are more common and better documented in heavy caffeine users.\nCoffee caffeine may aggravate pre-existing conditions such as migraines, arrhythmias, and cause sleep disturbances. Caffeine withdrawal from chronic use causes consistent effects typical of physical dependence, including headaches, mood changes and the possibility of reduced cerebral blood flow.\nIn a systematic review and meta-analysis of 28 prospective observational studies, representing 1,109,272 participants, every additional cup of caffeinated and decaffeinated coffee consumed in a day was associated with a 9% (95% CI 6%, 11%) and 6% (95% CI 2%, 9%) lower risk of type 2 diabetes, respectively.\nThe effects of coffee consumption on cancer risk remain unclear, with reviews and meta-analyses showing either no relationship or a small lower risk of cancer onset.\nInstant coffee has a greater amount of acrylamide than brewed coffee. It was once thought that coffee aggravates gastroesophageal reflux disease but recent research suggests no link.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Health and pharmacology", "sub_heading": "Health effects", "_id": "0--7--1---1", "title": "Coffee Consumption and Health Benefits"}
{"qas": [{"question": "What is the difference between coffee beans and coffee beans?", "answer": ""}, {"question": "What does coffee have in common with other beverages?", "answer": "caffeine content", "ae_score": -0.6830796722511032, "qg_score": null}, {"question": "What does coffee have in common with other beverages?", "answer": "caffeine content", "ae_score": -0.6830796722511032, "qg_score": null}], "content": "Depending on the type of coffee and method of preparation, the caffeine content of a single serving can vary greatly.The caffeine content of a cup of coffee varies depending mainly on the brewing method, and also on the variety of seed. According to the USDA National Nutrient Database, an 8-ounce (237 ml) cup of \"coffee brewed from grounds\" contains 95 mg caffeine, whereas an espresso (25 ml) contains 53 mg.\nAccording to an article in the ''Journal of the American Dietetic Association'', coffee has the following caffeine content, depending on how it is prepared:\nWhile the percent of caffeine content in coffee seeds themselves diminishes with increased roast level, the opposite is true for coffee brewed from different grinds and brewing methods using the same proportion of coffee to water volume. The coffee sack (similar to the French press and other steeping methods) extracts more caffeine from dark roasted seeds; the percolator and espresso methods extract more caffeine from light roasted seeds:\n''Coffea arabica'' normally contains about half the caffeine of ''Coffea robusta''. A ''Coffea arabica'' bean containing very little caffeine was discovered in Ethiopia in 2004.\nSee Low caffeine coffee.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Health and pharmacology", "sub_heading": "Caffeine content", "_id": "0--7--2---1", "title": "Low Caffeine Coffee"}
{"qas": [{"question": "What is the difference between a coffee shop employee and a barista?", "answer": ""}, {"question": "When did peet's coffee and tea open?", "answer": "1966", "ae_score": -0.2388896027590493, "qg_score": null}, {"question": "When did peet's coffee and tea open?", "answer": "1966", "ae_score": -0.2388896027590493, "qg_score": null}], "content": "Widely known as coffeehouses or caf\u00e9s, establishments serving prepared coffee or other hot beverages have existed for over five hundred years. Various legends involving the introduction of coffee to Istanbul at a \"Kiva Han\" in the late 15th century circulate in culinary tradition, but with no documentation.\nCoffeehouses in Mecca became a concern as places for political gatherings to the imams who banned them, and the drink, for Muslims between 1512 and 1524. In 1530 the first coffeehouse was opened in Damascus. The first coffeehouse in Constantinople was opened in 1475 by traders arriving from Damascus and Aleppo. Soon after, coffeehouses became part of the Ottoman Culture, spreading rapidly to all regions of the Ottoman Empire.\nIn the 17th century, coffee appeared for the first time in Europe outside the Ottoman Empire, and coffeehouses were established and quickly became popular. The first coffeehouses in Western Europe appeared in Venice, as a result of the traffic between La Serenissima and the Ottomans; the very first one is recorded in 1645. The first coffeehouse in England was set up in Oxford in 1650 by a Jewish man named Jacob in the building now known as \"The Grand Cafe\". A plaque on the wall still commemorates this and the Cafe is now a trendy cocktail bar. By 1675, there were more than 3,000 coffeehouses in England.\nA legend says that after the second Turkish siege of Vienna in 1683, the Viennese discovered many bags of coffee in the abandoned Ottoman encampment. Using this captured stock, a Polish soldier named Kulczycki opened the first coffeehouse in Vienna. This story never happened. Nowadays it is proven that the first coffeehouse in Vienna was opened by the Armenian Johannes Theodat in 1685.\nIn 1672 an Armenian named Pascal established a coffee stall in Paris that was ultimately unsuccessful and the city had to wait until 1689 for its first coffeehouse when Procopio Cut\u00f2 opened the Caf\u00e9 Procope. This coffeehouse still exists today and was a major meeting place of the French Enlightenment; Voltaire, Rousseau, and Denis Diderot frequented it, and it is arguably the birthplace of the ''Encyclop\u00e9die'', the first modern encyclopedia.  America had its first coffeehouse in Boston, in 1676. Coffee, tea and beer were often served together in establishments which functioned both as coffeehouses and taverns; one such was the Green Dragon in Boston, where John Adams, James Otis, and Paul Revere planned rebellion.<ref name=Pendergrast13/>\nThe modern espresso machine was invented in Milan in 1945 by Achille Gaggia, and from there spread across coffeehouses and restaurants across Italy and the rest of Europe and North America in the early 1950s. An Italian named Pino Riservato opened the first espresso bar, the Moka Bar, in Soho in 1952, and there were 400 such bars in London alone by 1956. Cappucino was particularly popular among English drinkers. Similarly in the United States, the espresso craze spread. North Beach in San Francisco saw the opening of the Caffe Trieste in 1957, which saw Beat Generation poets such as Allen Ginsberg and Bob Kaufman alongside bemused Italian immigrants.<ref name=Pendergrast219/> Similar such cafes existed in Greenwich Village and elsewhere.<ref name=Pendergrast219/>\nThe first Peet's Coffee & Tea store opened in 1966 in Berkeley, California by Dutch native Alfred Peet. He chose to focus on roasting batches with fresher, higher quality seeds than was the norm at the time. He was a trainer and supplier to the founders of Starbuck's.\nThe international coffeehouse chain Starbucks began as a modest business roasting and selling coffee beans in 1971, by three college students Jerry Baldwin, Gordon Bowker, and Zev Siegl. The first store opened on March 30, 1971 at the Pike Place Market in Seattle, followed by a second and third over the next two years. Entrepreneur Howard Schultz joined the company in 1982 as Director of Retail Operations and Marketing, and pushed to sell premade espresso coffee. The others were reluctant, but Schultz opened Il Giornale in Seattle in April 1986. He bought the other owners out in March 1987 and pushed on with plans to expand\u2014from 1987 to the end of 1991, the chain (rebranded from Il Giornale to Starbucks) expanded to over 100 outlets. The company has 16,600 stores in over 40 countries worldwide.\nSouth Korea experienced almost 900 percent growth in the number of coffee shops in the country between 2006 and 2011. The capital city Seoul now has the highest concentration of coffee shops in the world, with more than 10,000 cafes and coffeehouses.\nA contemporary term for a person who makes coffee beverages, often a coffeehouse employee, is a barista. The Specialty Coffee Association of Europe and the Specialty Coffee Association of America have been influential in setting standards and providing training.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Coffeehouses", "sub_heading": "Coffeehouses", "_id": "0--8---1---1", "title": "The History of Coffeehouses in America"}
{"qas": [{"question": "What is the difference between a coffee break and an afternoon tea?", "answer": ""}, {"question": "Where did the term coffee break come from?", "answer": "Stoughton, Wisconsin", "ae_score": -0.3747803211106129, "qg_score": null}, {"question": "Where did the term coffee break come from?", "answer": "Stoughton, Wisconsin", "ae_score": -0.3747803211106129, "qg_score": null}], "content": "A coffee break is a routine social gathering for a snack, the consumption of a hot beverage such as coffee or tea and short downtime practiced by employees in business and industry, corresponding with the Commonwealth terms \"elevenses\", \"Smoko\" (in Australia), \"morning tea\", \"tea break\", or even just \"tea\". An afternoon coffee break, or afternoon tea, sometimes occurs as well.\nThe coffee break originated in the late 19th century in Stoughton, Wisconsin, with the wives of Norwegian immigrants. The city celebrates this every year with the Stoughton Coffee Break Festival. In 1951, ''Time'' noted that \"[s]ince the war, the coffee break has been written into union contracts\". The term subsequently became popular through a Pan-American Coffee Bureau ad campaign of 1952 which urged consumers, \"Give yourself a Coffee-Break \u2013 and Get What Coffee Gives to You.\" John B. Watson, a behavioral psychologist who worked with Maxwell House later in his career, helped to popularize coffee breaks within the American culture. Coffee breaks usually last from 10 to 20 minutes and frequently occur at the end of the first third of the work shift. In some companies and some civil service, the coffee break may be observed formally at a set hour. In some places, a \"cart\" with hot and cold beverages and cakes, breads and pastries arrives at the same time morning and afternoon, an employer may contract with an outside caterer for daily service, or coffee breaks may take place away from the actual work-area in a designated cafeteria or tea room. More generally, the phrase \"coffee break\" has also come to denote any break from work.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Social and culture", "_id": "0--9--0---1", "title": "The Coffee Break"}
{"qas": [{"question": "Why do so many people in the Adventist Church avoid coffee?", "answer": ""}, {"question": "Which american coffee company is famous for its berry-based coffee?", "answer": "Maxwell House", "ae_score": -0.33906763414048996, "qg_score": null}, {"question": "Which american coffee company is famous for its berry-based coffee?", "answer": "Maxwell House", "ae_score": -0.33906763414048996, "qg_score": null}], "content": "Coffee was initially used for spiritual reasons. At least 1,100 years ago, traders brought coffee across the Red Sea into Arabia (modern-day Yemen), where Muslim dervishes began cultivating the shrub in their gardens. At first, the Arabians made wine from the pulp of the fermented coffee berries. This beverage was known as ''qishr'' (''kisher'' in modern usage) and was used during religious ceremonies.\nCoffee drinking was prohibited by jurists and scholars (''ulema'') meeting in Mecca in 1511 as ''haraam'', but the subject of whether it was intoxicating was hotly debated over the next 30 years until the ban was finally overturned in the mid-16th century. Use in religious rites among the Sufi branch of Islam led to coffee's being put on trial in Mecca: it was accused of being a heretical substance, and its production and consumption were briefly repressed. It was later prohibited in Ottoman Turkey under an edict by the Sultan Murad IV.\nCoffee, regarded as a Muslim drink, was prohibited by Ethiopian Orthodox Christians until as late as 1889; it is now considered a national drink of Ethiopia for people of all faiths. Its early association in Europe with rebellious political activities led to Charles II outlawing coffeehouses from January 1676 (although the uproar created forced the monarch to back down two days before the ban was due to come into force). Frederick the Great banned it in Prussia in 1777 for nationalistic and economic reasons; concerned about the price of import, he sought to force the public back to consuming beer. Lacking coffee-producing colonies, Prussia had to import all its coffee at a great cost.\nA contemporary example of religious prohibition of coffee can be found in The Church of Jesus Christ of Latter-day Saints. The organization holds that it is both physically and spiritually unhealthy to consume coffee. This comes from the Mormon doctrine of health, given in 1833 by founder Joseph Smith in a revelation called the Word of Wisdom. It does not identify coffee by name, but includes the statement that \"hot drinks are not for the belly,\" which has been interpreted to forbid both coffee and tea.\nQuite a number of members of the Seventh-day Adventist Church also avoid caffeinated drinks. In its teachings, the Church encourages members to avoid tea, coffee, and other stimulants. Abstinence from coffee, tobacco, and alcohol by many Adventists has afforded a near-unique opportunity for studies to be conducted within that population group on the health effects of coffee drinking, free from confounding factors. One study was able to show a weak but statistically significant association between coffee consumption and mortality from ischemic heart disease, other cardiovascular disease, all cardiovascular diseases combined, and all causes of death.\nFor a time, there had been controversy in the Jewish community over whether the coffee seed was a legume and therefore prohibited for Passover. Upon petition from coffeemaker Maxwell House, the coffee seed was classified in 1923 as a berry rather than a seed by orthodox Jewish rabbi Hersch Kohn, and therefore kosher for Passover.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Prohibition", "_id": "0--9--1---1", "title": "Coffee, Tea, and Alcohol"}
{"qas": [{"question": "Why is coffee so expensive in Europe?", "answer": ""}, {"question": "When was the european fair trade association founded?", "answer": "1987", "ae_score": -0.41322951817925485, "qg_score": null}, {"question": "When was the european fair trade association founded?", "answer": "1987", "ae_score": -0.41322951817925485, "qg_score": null}], "content": "The concept of fair trade labeling, which guarantees coffee growers a negotiated preharvest price, began in the late 1980s with the Max Havelaar Foundation's labeling program in the Netherlands. In 2004, 24,222 metric tons (of 7,050,000 produced worldwide) were fair trade; in 2005, 33,991 metric tons out of 6,685,000 were fair trade, an increase from 0.34% to 0.51%.A number of fair trade impact studies have shown that fair trade coffee produces a mixed impact on the communities that grow it. Many studies are skeptical about fair trade, reporting that it often worsens the bargaining power of those who are not part of it. Coffee was incorporated into the fair-trade movement in 1988, when the Max Havelaar mark was introduced in the Netherlands. The very first fair-trade coffee was an effort to import a Guatemalan coffee into Europe as \"Indio Solidarity Coffee\".\nSince the founding of organisations such as the European Fair Trade Association (1987), the production and consumption of fair trade coffee has grown as some local and national coffee chains started to offer fair trade alternatives. For example, in April 2000, after a year-long campaign by the human rights organization Global Exchange, Starbucks decided to carry fair-trade coffee in its stores. Since September 2009 all Starbucks Espresso beverages in UK and Ireland are made with Fairtrade and Shared Planet certified coffee.\nA 2005 study done in Belgium concluded that consumers' buying behavior is not consistent with their positive attitude toward ethical products. On average 46% of European consumers claimed to be willing to pay substantially more for ethical products, including fair-trade products such as coffee. The study found that the majority of respondents were unwilling to pay the actual price premium of 27% for fair trade coffee.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Fair trade", "_id": "0--9--2---1", "title": "Fair-Trade Coffee \u2014 The Future of Fair Trade Coffee"}
{"qas": [{"question": "Where did the idea of coffee come from?", "answer": ""}, {"question": "What is the name of the cantata composed by johann sebastian?", "answer": "Coffee Cantata", "ae_score": -0.08414345845142658, "qg_score": null}, {"question": "What is the name of the cantata composed by johann sebastian?", "answer": "Coffee Cantata", "ae_score": -0.08414345845142658, "qg_score": null}], "content": "The Oromo people would customarily plant a coffee tree on the graves of powerful sorcerers. They believed that the first coffee bush sprang up from the tears that the god of heaven shed over the corpse of a dead sorcerer.\nJohann Sebastian Bach was inspired to compose the ''Coffee Cantata'', about dependence on the beverage.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Folklore and culture", "_id": "0--9--3---1", "title": "''Coffee Cantata'' by Johann Sebastian Bach"}
{"qas": [{"question": "Why is Rio de Janeiro the capital of Brazil?", "answer": ""}, {"question": "How long does it take to plant coffee in brazil?", "answer": "four years", "ae_score": -0.4030136620905116, "qg_score": null}, {"question": "How long does it take to plant coffee in brazil?", "answer": "four years", "ae_score": -0.4030136620905116, "qg_score": null}], "content": "Market volatility, and thus increased returns, during 1830 encouraged Brazilian entrepreneurs to shift their attention from gold to coffee, a crop hitherto reserved for local consumption. Concurrent with this shift was the commissioning of vital infrastructures, including approximately 7,000 km of railroads between 1860 and 1885. The creation of these railways enabled the importation of workers, in order to meet the enormous need for labor. This development primarily affected the State of Rio de Janeiro, as well as the Southern States of Brazil, most notably S\u00e3o Paulo, due to its favourable climate, soils, and terrain.\nCoffee production attracted immigrants in search of better economic opportunities in the early 1900s. Mainly, these were Portuguese, Italian, Spanish, German, and Japanese nationals. For instance, S\u00e3o Paulo received approximately 733,000 immigrants in the decade preceding 1900, whilst only receiving approximately 201,000 immigrants in the six years to 1890. The production yield of coffee increases. In 1880, S\u00e3o Paulo produced 1.2 million bags (25% of total production), in 1888 2.6 million (40%), in 1902 8 million bags (60%). Coffee is then 63% of the country's exports. The gains made by this trade allow sustained economic growth in the country.\nThe four years between planting a coffee and the first harvest extends seasonal variations in the price of coffee. The Brazilian Government is thus forced, to some extent, to keep strong price subsidies during production periods.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Economic impacts", "_id": "0--9--4---1", "title": "Brazil's Coffee Production"}
{"qas": [{"question": "What is World Coffee Events?", "answer": ""}, {"question": "Where is the world's coffee king held?", "answer": "Melbourne, Australia", "ae_score": -0.398220499735135, "qg_score": null}, {"question": "Where is the world's coffee king held?", "answer": "Melbourne, Australia", "ae_score": -0.398220499735135, "qg_score": null}], "content": "Coffee competitions take place across the globe with people at the regional competing to achieve national titles and then compete on the international stage. World Coffee Events holds the largest of such events moving the location of the final competition each year. The competition includes the following events: Barista Championship, Brewers Cup, Latte Art and Cup Tasters.A World Brewer's Cup Championship takes place in Melbourne, Australia, every year that houses contestants from around the world to crown the World's Coffee King.", "page_name": "Coffee", "page_id": "Coffee", "heading": "Social and culture", "sub_heading": "Competition", "_id": "0--9--5---1", "title": "World Coffee Competitions"}
{"qas": [{"question": "Why are there so many cases of Irritable Bowel Syndrome?", "answer": ""}, {"question": "What type of disease is inflammatory bowel disease?", "answer": "autoimmune diseases", "ae_score": -0.1850651683737421, "qg_score": null}, {"question": "What type of disease is inflammatory bowel disease?", "answer": "autoimmune diseases", "ae_score": -0.1850651683737421, "qg_score": null}], "content": "The chief types of inflammatory bowel disease are Crohn's disease and ulcerative colitis (UC). Inflammatory bowel diseases fall into the class of autoimmune diseases, in which the body's own immune system attacks elements of the digestive system.\nAccounting for fewer cases are other forms of IBD, which are not always classified as typical IBD:\nNo disease specific markers are currently known in the blood, enabling the reliable separation of Crohn's disease and ulcerative colitis patients. The way doctors can tell the difference between Crohn's disease and UC is the ''location'' and ''nature'' of the inflammatory changes. Crohn's can affect any part of the gastrointestinal tract, from mouth to anus (''skip lesions''), although a majority of the cases start in the terminal ileum. Ulcerative colitis, in contrast, is restricted to the colon and the rectum.Microscopically, ulcerative colitis is restricted to the mucosa (epithelial lining of the gut), while Crohn's disease affects the full thickness of the bowel wall (\"transmural lesions\"). Lastly, Crohn's disease and ulcerative colitis present with extra-intestinal manifestations (such as liver problems, arthritis, skin manifestations and eye problems) in different proportions.\nIn 10%-15% of cases, a definitive diagnosis neither of Crohn's disease nor of ulcerative colitis can be made because of idiosyncrasies in the presentation. In this case, a diagnosis of indeterminate colitis may be made. Although a recognised definition, not all centres refer to this.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Classification", "sub_heading": "Classification", "_id": "1--0---1---1", "title": "Crohn's Disease vs. Ulcerative Colitis"}
{"qas": [{"question": "How does Crohn's Disease work?", "answer": ""}, {"question": "What is the most common complication of inflammatory bowel disease?", "answer": "Anemia", "ae_score": -0.22485480940336816, "qg_score": null}, {"question": "What is the most common complication of inflammatory bowel disease?", "answer": "Anemia", "ae_score": -0.22485480940336816, "qg_score": null}], "content": "In spite of Crohn's and UC being very different diseases, both may present with any of the following symptoms: abdominal pain, vomiting, diarrhea, rectal bleeding, severe internal cramps/muscle spasms in the region of the pelvis and weight loss. Anemia is the most prevalent extraintestinal complication of inflammatory bowel disease. Associated complaints or diseases include arthritis, pyoderma gangrenosum, primary sclerosing cholangitis, and non-thyroidal illness syndrome (NTIS). Associations with deep vein thrombosis (DVT) and bronchiolitis obliterans organizing pneumonia (BOOP) have also been reported.  Diagnosis is generally by assessment of inflammatory markers in stool followed by colonoscopy with biopsy of pathological lesions.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "1--1---1---1", "title": "Crohn's and UC Symptoms"}
{"qas": [{"question": "Why do some people get IBD and others don't?", "answer": ""}, {"question": "What type of Firmicutes are associated with inflammatory bowel disease?", "answer": "Lachnospiraceae", "ae_score": null, "qg_score": null}, {"question": "What type of Firmicutes are associated with inflammatory bowel disease?", "answer": "Lachnospiraceae", "ae_score": null, "qg_score": null}], "content": "Alterations in enteral bacteria may contribute to inflammatory gut diseases. IBD-affected individuals have been found to have 30-50 percent reduced biodiversity of commensal bacteria, such as decreases in Firmicutes (namely Lachnospiraceae) and Bacteroidetes. Further evidence of the role of gut flora in the cause of inflammatory bowel disease is that IBD-affected individuals are more likely to have been prescribed antibiotics in the 2-5 year period before their diagnosis than unaffected individuals. The enteral bacteria can be altered by environmental factors, such as concentrated milk fats (a common ingredient of processed foods and confectionery) or oral medications such as antibiotics and oral iron preparations.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Causes", "sub_heading": "Causes", "_id": "1--2--0---1", "title": "IBD-Affected Individuals Have 30-50 percent Reduced Biodiversity of Comme"}
{"qas": [{"question": "IBD?", "answer": ""}, {"question": "Which part of the body is damaged by inflammatory bowel disease ( ibd )?", "answer": "intestinal epithelium", "ae_score": -2.0434884653024215, "qg_score": null}, {"question": "Which part of the body is damaged by inflammatory bowel disease ( ibd )?", "answer": "intestinal epithelium", "ae_score": -2.0434884653024215, "qg_score": null}], "content": "Loss of integrity of the intestinal epithelium plays a key pathogenic role in IBD. Innate immune dysfunction through aberrant TLR signaling contributes to acute and chronic inflammatory processes in IBD colitis and associated cancer.Changes in the composition of the intestinal microbiota are an important environmental factor in the development of IBD. Detrimental changes in the intestinal microbiota induce an inappropriate (uncontrolled) immune response that results in damage to the intestinal epithelium. Breaches in this critical barrier (the intestinal epithelium) allow further infiltration of microbiota that, in turn, elicit further immune responses. IBD is a multifactorial disease that is nonetheless driven in part by an exaggerated immune response to gut microbiota that causes defects in epithelial barrier function.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Causes", "sub_heading": "Breach of intestinal barrier", "_id": "1--2--1---1", "title": "IBD: A multifactorial disease"}
{"qas": [{"question": "Why is it bad to eat plant based foods?", "answer": ""}, {"question": "Which amino acid is associated with inflammatory bowel disease?", "answer": "methionine", "ae_score": -0.8544780395406905, "qg_score": null}, {"question": "Which amino acid is associated with inflammatory bowel disease?", "answer": "methionine", "ae_score": -0.8544780395406905, "qg_score": null}], "content": "High protein intake, specifically animal protein via meat and fish consumption has been significantly associated with inflammatory bowel disease as well as ulcerative colitis. There was no such association related to plant proteins in the prospective study consisting of over 65,000 patients over a 10-year period. Animal proteins have greater amounts of sulphur containing amino acids such as methionine, which the colonic microflora accrues into hydrogen sulfide, resulting in the pathogenesis of IBD and ulcerative colitis. Such bacteria-derived cell poisons in the form of hydrogen sulfide are specifically elaborated by animal or meat and fish intake, and not by plant foods.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Causes", "sub_heading": "Diet", "_id": "1--2--2---1", "title": "IBD and ulcerative colitis"}
{"qas": [{"question": "What is the 163 loci and how does it work?", "answer": ""}, {"question": "How many susceptibility loci are there to inflammatory bowel disease?", "answer": "163", "ae_score": -0.8658457307665222, "qg_score": null}, {"question": "How many susceptibility loci are there to inflammatory bowel disease?", "answer": "163", "ae_score": -0.8658457307665222, "qg_score": null}], "content": "The genetic contribution is poorly understood and seems to arise from the small contribution of dozens of genes. In 2012, 163 IBD susceptibility loci were confirmed, which means that 163 alleles that can increase the susceptibility to the disease have been found. These 163 loci explain from an 8.2% to a 13.6% of variance in Crohn's disease and 4.1% to 7.5% in ulcerative colitis.\nThe 163 loci were related to 300 known genes. The functional enrichment analysis of this group of genes using gene ontology showed that there are many genes related with cytokine production, lymphocyte activation and the response to bacterial infection.  In an effort to identify likely causal genes, a probabilistic causal gene network was constructed. Here, a sub-network including NOD2, Il10 and CARD9 seems to indicate a close relationship between IBD and genes related with host interaction with bacteria. Of particular relevance is the presence of the gene HCK which seems to play an important role anti-inflammation. In the figure beside, there is a NOD2-focused cluster in the causal gene sub-network.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Causes", "sub_heading": "Genetics", "_id": "1--2--3---1", "title": "IBD susceptibility loci and their genetic contribution to IBD susceptibility loci"}
{"qas": [{"question": "Why do some diseases cause diarrhea while others do not?", "answer": ""}, {"question": "Acute self-limiting colitis is an example of?", "answer": "ulcerative colitis", "ae_score": -0.2059103297866805, "qg_score": null}, {"question": "Acute self-limiting colitis is an example of?", "answer": "ulcerative colitis", "ae_score": -0.2059103297866805, "qg_score": null}], "content": "The diagnosis is usually confirmed by biopsies on colonoscopy. Fecal calprotectin is useful as an initial investigation, which may suggest the possibility of IBD, as this test is sensitive but not specific for IBD.\nOther diseases may cause an increased excretion of fecal calprotectin, such as infectious diarrhea, untreated celiac disease, necrotizing enterocolitis, intestinal cystic fibrosis and neoplastic pediatric tumor cells.\nConditions with similar symptoms as Crohn's disease includes intestinal tuberculosis, Beh\u00e7et\u2019s disease, ulcerative colitis, nonsteroidal anti-inflammatory drug enteropathy, irritable bowel syndrome and celiac disease.\nConditions with similar symptoms as ulcerative colitis includes acute self-limiting colitis, amebic colitis, schistosomiasis, Crohn's disease, colon cancer, irritable bowel syndrome, intestinal tuberculosis and nonsteroidal anti-inflammatory drug enteropathy.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "1--3---1---1", "title": "Crohn\u2019s disease, colon cancer, ulcerative colitis, ulcerative colitis,"}
{"qas": [{"question": "What is the difference between Crohn's Disease and ulcerative colitis?", "answer": ""}, {"question": "What type of disease is inflammatory bowel disease?", "answer": "chronic inflammatory diseases", "ae_score": -0.46491989342845497, "qg_score": null}, {"question": "What type of disease is inflammatory bowel disease?", "answer": "chronic inflammatory diseases", "ae_score": -0.46491989342845497, "qg_score": null}], "content": "CD and UC are chronic inflammatory diseases, and are not medically curable. However, ulcerative colitis can in most cases be cured by proctocolectomy, although this may not eliminate extra-intestinal symptoms. An ileostomy will collect feces in a bag.  Alternatively, a pouch can be created from the small intestine; this serves as the rectum and prevents the need for a permanent ileostomy. A small percentage of patients with ileo-anal pouches do have to manage occasional or chronic pouchitis.\nSurgery cannot cure Crohn's disease but may be needed to treat complications such as abscesses, strictures or fistulae. Severe cases may require surgery, such as bowel resection, strictureplasty or a temporary or permanent colostomy or ileostomy.  In Crohn's disease, surgery involves removing the worst inflamed segments of the intestine and connecting the healthy regions, but unfortunately, it does not cure Crohn's or eliminate the disease. At some point after the first surgery, Crohn's disease can recur in the healthy parts of the intestine, usually at the resection site. (For example, if a patient with Crohn's disease has an ileocecal anastomosis, in which the caecum and terminal ileum are removed and the ileum is joined to the ascending colon, their Crohn's will nearly always flare-up near the anastomosis or in the rest of the ascending colon).", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Treatment", "_id": "1--4--0---1", "title": "Crohn's Disease: Surgery Cannot Cure Crohn's Disease"}
{"qas": [{"question": "How do doctors decide which drugs to use for IBD?", "answer": ""}, {"question": "Which drug is more effective in ulcerative colitis?", "answer": "mesalazine", "ae_score": -0.33064330873747033, "qg_score": null}, {"question": "Which drug is more effective in ulcerative colitis?", "answer": "mesalazine", "ae_score": -0.33064330873747033, "qg_score": null}], "content": "Medical treatment of IBD is individualised to each patient.  The choice of which drugs to use and by which route to administer them (oral, rectal, injection, infusion) depends on factors including the type, distribution, and severity of the patient's disease, as well as other historical and biochemical prognostic factors, and patient preferences.  For example, mesalazine is more useful in ulcerative colitis than in Crohn's disease.<ref name=agabegi2nd/> Generally, depending on the level of severity, IBD may require immunosuppression to control the symptoms, with drugs such as prednisone, TNF inhibitors, azathioprine (Imuran), methotrexate, or 6-mercaptopurine.\nSteroids, such as the glucocorticoid prednisone, are frequently used to control disease flares and were once acceptable as a maintenance drug. Biological therapy for inflammatory bowel disease, especially the TNF inhibitors, are used in people with more severe or resistant Crohn's disease and sometimes in ulcerative colitis.\nTreatment is usually started by administering drugs with high anti-inflammatory effects, such as prednisone. Once the inflammation is successfully controlled, another drug to keep the disease in remission, such as mesalazine in UC, is the main treatment. If further treatment is required, a combination of an immunosuppressive drug (such as azathioprine) with mesalazine (which may also have an anti-inflammatory effect) may be needed, depending on the patient. Controlled release Budesonide is used for mild ileal Crohn's disease.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Medical therapies", "_id": "1--4--1---1", "title": "IBD Treatment \u2014 Agabegi2nd"}
{"qas": [{"question": "What is the difference between parenteral iron and enteral nutrition?", "answer": ""}, {"question": "Which type of iron bypasses the gastrointestinal system and enables quicker treatment?", "answer": "parenteral iron", "ae_score": -0.3160762406013448, "qg_score": null}, {"question": "Which type of iron bypasses the gastrointestinal system and enables quicker treatment?", "answer": "parenteral iron", "ae_score": -0.3160762406013448, "qg_score": null}], "content": "Nutritional deficiencies play a prominent role in IBD. Malabsorption, diarrhea, and GI blood loss are common features of IBD. Deficiencies of B vitamins, fat-soluble vitamins, essential fatty acids, and key minerals such as magnesium, zinc, and selenium are extremely common and benefit from replacement therapy. Dietary interventions, including certain exclusion diets, low residue/low fibre diets, and low FODMAP diets have some benefits.\nAnaemia is commonly present in both ulcerative colitis and Crohn's disease. Due to raised levels of inflammatory cytokines which lead to the increased expression of hepcidin, parenteral iron is the preferred treatment option as it bypasses the gastrointestinal system, has lower incidence of adverse events and enables quicker treatment. Hepcidin itself is also an anti-inflammatory agent. In the murine model very low levels of iron restrict hepcidin synthesis, worsening the inflammation that is present. Enteral nutrition has been found to be efficient to improve hemoglobin level in patients with inflammatory bowel disease, especially combined with erythropoietin.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Nutritional and dietetic therapies", "_id": "1--4--2---1", "title": "IBD Symptoms and Treatments"}
{"qas": [{"question": "Why is it so important to get rid of inflammatory bowel disease?", "answer": ""}, {"question": "What type of therapy is being used to treat inflammatory bowel disease?", "answer": "antibiotic therapy", "ae_score": -0.24913625497798247, "qg_score": null}, {"question": "What type of therapy is being used to treat inflammatory bowel disease?", "answer": "antibiotic therapy", "ae_score": -0.24913625497798247, "qg_score": null}], "content": "There is evidence of an infectious contribution to inflammatory bowel disease in some patients and this subgroup of patients may benefit from antibiotic therapy.\nFecal microbiota transplant is a relatively new treatment option for IBD which has attracted attention since 2010.  Some preliminary studies have suggested benefits similar to those in Clostridium difficile infection but a review of use in IBD shows that FMT is safe, but of variably efficacy. A 2014 reviewed stated that more randomized controlled trials were needed.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Microbiome", "_id": "1--4--3---1", "title": "Fecal microbiota transplant"}
{"qas": [{"question": "What is the difference between acupuncture and other alternative medicine?", "answer": ""}, {"question": "Plantago ovata and curcumin are used in which type of maintenance therapy?", "answer": "UC", "ae_score": null, "qg_score": null}, {"question": "Plantago ovata and curcumin are used in which type of maintenance therapy?", "answer": "UC", "ae_score": null, "qg_score": null}], "content": "Complementary and alternative medicine approaches have been used in inflammatory bowel disorders.  Evidence from controlled studies of these therapies has been reviewed; risk of bias was quite heterogeneous. The best supportive evidence was found for herbal therapy, with Plantago ovata and curcumin in UC maintenance therapy, wormwood in CD, mind/body therapy and self-intervention in UC, and acupuncture in UC and CD.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Alternative medicine", "_id": "1--4--4---1", "title": "Complementary and alternative medicine approaches in inflammatory bowel disorders"}
{"qas": [{"question": "Is Stem Cell Therapy a viable treatment for IBD?", "answer": ""}, {"question": "What type of therapy is being studied for the treatment of inflammatory bowel disease?", "answer": "Stem cell therapy", "ae_score": -0.6160155478203195, "qg_score": null}, {"question": "What type of therapy is being studied for the treatment of inflammatory bowel disease?", "answer": "Stem cell therapy", "ae_score": -0.6160155478203195, "qg_score": null}], "content": "Stem cell therapy is undergoing research as a possible treatment for IBD. A review of studies suggests a promising role, although there are substantial challenges, including cost and characterization of effects, which limit the current use in clinical practice.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Treatment", "sub_heading": "Novel approaches", "_id": "1--4--5---1", "title": "Stem cell therapy is undergoing research as a possible treatment for IBD"}
{"qas": [{"question": "Why do IBD patients have a higher risk of colorectal cancer than the general population?", "answer": ""}, {"question": "What is the most common treatment for inflammatory bowel disease?", "answer": "colonoscopy", "ae_score": -0.28125097773784635, "qg_score": null}, {"question": "What is the most common treatment for inflammatory bowel disease?", "answer": "colonoscopy", "ae_score": -0.28125097773784635, "qg_score": null}], "content": "While IBD can limit quality of life because of pain, vomiting, diarrhea, and other socially undesired symptoms, it is rarely fatal on its own.  Fatalities due to complications such as toxic megacolon, bowel perforation and surgical complications are also rare.\nWhile patients of IBD do have an increased risk of  colorectal cancer, this is usually caught much earlier than the general population in routine surveillance of the colon by colonoscopy, and therefore patients are much more likely to survive.\nNew evidence suggests that patients with IBD may have an elevated risk of endothelial dysfunction and coronary artery disease.\nA recent literature review by Gandhi et al. described that IBD patients over the age of 65 and females are at increased risk of coronary artery disease despite the lack of traditional risk factors.\nThe goal of treatment is toward achieving remission, after which the patient is usually switched to a lighter drug with fewer potential side effects. Every so often, an acute resurgence of the original symptoms may appear; this is known as a \"flare-up\". Depending on the circumstances, it may go away on its own or require medication. The time between flare-ups may be anywhere from weeks to years, and varies wildly between patients - a few have never experienced a flare-up.\nLife with IBD can be challenging, however, it should not impede your ability to live a normal life. Patients with IBD can go to college, hold a normal job, get married, have children etc. As is the nature of any chronic, unpredictable disease, there will be ups and downs. The progress made in IBD research and treatment is astounding and will only improve in the years to come.\nAlthough living with IBD can be difficult, there are numerous resources available to help families navigate the ins and out of IBD. The Crohn's and Colitis Foundation of America (CCFA) is an excellent resource. CCFA is a vital resource to getting questions answered and finding support about life with IBD.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Prognosis", "sub_heading": "Prognosis", "_id": "1--5---1---1", "title": "Life with IBD: A Guide to Living With IBD"}
{"qas": [{"question": "Why is IBD so common in Europe?", "answer": ""}, {"question": "How many deaths did inflammatory bowel disease cause in 1990?", "answer": "55,000", "ae_score": -0.14786418382475638, "qg_score": null}, {"question": "How many deaths did inflammatory bowel disease cause in 1990?", "answer": "55,000", "ae_score": -0.14786418382475638, "qg_score": null}], "content": "IBD resulted in a global total of 51,000 deaths in 2013 and 55,000 deaths in 1990. The increased incidence of IBD since World War 2 has been linked to the increase in meat consumption worldwide, supporting the claim that animal protein intake is associated with IBD. Inflammatory bowel diseases are increasing in Europe.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "1--6---1---1", "title": "Inflammatory Bowel Disease (IBD)"}
{"qas": [{"question": "Why do people with IBD have higher odds of getting vitamin D deficiency?", "answer": ""}, {"question": "What disease is caused by inflammatory bowel disease?", "answer": "ulcerative colitis", "ae_score": -0.21454502838325176, "qg_score": null}, {"question": "What disease is caused by inflammatory bowel disease?", "answer": "ulcerative colitis", "ae_score": -0.21454502838325176, "qg_score": null}], "content": "The following treatment strategies are not used routinely, but appear promising in some forms of inflammatory bowel disease.\nInitial reports suggest that \"helminthic therapy\" may not only prevent but even control IBD: a drink with roughly 2,500 ova of the ''Trichuris suis'' helminth taken twice monthly decreased symptoms markedly in many patients. It is even speculated that an effective \"immunization\" procedure could be developed\u2014by ingesting the cocktail at an early age.\nPrebiotics and probiotics are focusing increasing interest as treatments for IBD. Currently, there is evidence to support the use of certain probiotics in addition to standard treatments in people with ulcerative colitis but there is no sufficient data to recommend probiotics in people suffering Crohn's disease. Further research is required to identify specific probiotic strains or their combinations and prebiotic substances for therapies of intestinal inflammation. Currently, the probiotic strain, frequency, dose and duration of the probiotic therapy are not established. In severely ill people with IBD there is a risk of the passage of viable bacteria from the gastrointestinal tract to the internal organs (bacterial translocation) and subsequent bacteremia, which can cause serious adverse health consequences. Live bacteria might not be essential because of beneficial effects of probiotics seems to be mediated by their DNA and by secreted soluble factors, and their therapeutic effects may be obtained by systemic administration rather than oral administration.\nIn 2005 New Scientist published a joint study by Bristol University and the University of Bath on the apparent healing power of cannabis on IBD. Reports that cannabis eased IBD symptoms indicated the possible existence of cannabinoid receptors in the intestinal lining, which respond to molecules in the plant-derived chemicals. CB1 cannabinoid receptors \u2013 which are known to be present in the brain \u2013 exist in the endothelial cells which line the gut, it is thought that they are involved in repairing the lining of the gut when damaged.\nThe team deliberately damaged the cells to cause inflammation of the gut lining and then added synthetically produced cannabinoids; the result was that gut started to heal: the broken cells were repaired and brought back closer together to mend the tears. It is believed that in a healthy gut, natural endogenous cannabinoids are released from endothelial cells when they are injured, which then bind to the CB1 receptors. The process appears to set off a wound-healing reaction, and when people use cannabis, the cannabinoids bind to these receptors in the same way.\nPrevious studies have shown that CB1 receptors located on the nerve cells in the gut respond to cannabinoids by slowing gut motility, therefore reducing the painful muscle contractions associated with diarrhea. The team also discovered another cannabinoid receptor, CB2, in the guts of IBD sufferers, which was not present in healthy guts. These receptors, which also respond to chemicals in cannabis, appear to be associated with apoptosis \u2013 programmed cell death \u2013 and may have a role in suppressing the overactive immune system and reducing inflammation by mopping up excess cells.\nAlicaforsen is a first generation antisense oligodeoxynucleotide designed to bind specifically to the human ICAM-1 messenger RNA  through Watson-Crick base pair interactions in order to subdue expression of ICAM-1. ICAM-1 propagates an inflammatory response promoting the extravasation and activation of leukocytes (white blood cells) into inflamed tissue. Increased expression of ICAM-1 has been observed within the inflamed intestinal mucosa of ulcerative colitis, pouchitis and Crohn's sufferers where ICAM-1 over production correlated with disease activity. This suggests that ICAM-1 is a potential therapeutic target in the treatment of these diseases.\nIn 2014, an alliance among the Broad Institute, Amgen and Massachusetts General Hospital formed with the intention to \"collect and analyze patient DNA samples to identify and further validate genetic targets.\"\nIn a recent meta-analysis on 938 IBD patients and 953 controls, IBD was significantly associated with having higher odds of vitamin D deficiency.\nGram-positive bacteria present in the lumen are could be associated with extending the time of relapse for ulcerative colitis.", "page_name": "Inflammatory bowel disease", "page_id": "Inflammatory%20bowel%20disease", "heading": "Research", "sub_heading": "Research", "_id": "1--7---1---1", "title": "IBD Treatments \u2014 A New Approach"}
{"qas": [{"question": "What is the difference between allergy and irritant dermatitis?", "answer": ""}, {"question": "Inflammation of the skin caused by contact with a foreign substance is called?", "answer": "Contact dermatitis", "ae_score": -0.28677784237628207, "qg_score": null}, {"question": "Inflammation of the skin caused by contact with a foreign substance is called?", "answer": "Contact dermatitis", "ae_score": -0.28677784237628207, "qg_score": null}], "content": "Contact dermatitis is a localized rash or irritation of the skin caused by contact with a foreign substance. Only the superficial regions of the skin are affected in contact dermatitis. Inflammation of the affected tissue is present in the epidermis (the outermost layer of skin) and the outer dermis (the layer beneath the epidermis).\nContact dermatitis results in large, burning, and itchy rashes. These can take anywhere from several days to weeks to heal.  This differentiates it from contact urticaria (hives), in which a rash appears within minutes of exposure and then fades away within minutes to hours. Even after days, contact dermatitis fades only if the skin no longer comes in contact with the allergen or irritant.  Chronic contact dermatitis can develop when the removal of the offending agent no longer provides expected relief.\nAllergic dermatitis is usually confined to the area where the trigger actually touched the skin, whereas irritant dermatitis may be more widespread on the skin. Symptoms of both forms include the following:\nWhile either form of contact dermatitis can affect any part of the body, irritant contact dermatitis often affects the hands, which have been exposed by resting in or dipping into a container (sink, pail, tub, swimming pools with high chlorine) containing the irritant.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "2--0---1---1", "title": "Symptoms of Contact Dermatitis"}
{"qas": [{"question": "Why does hot air make your skin itch?", "answer": ""}, {"question": "What causes contact dermatitis in the body?", "answer": "chemical irritants", "ae_score": -0.863938105556205, "qg_score": null}, {"question": "What causes contact dermatitis in the body?", "answer": "chemical irritants", "ae_score": -0.863938105556205, "qg_score": null}], "content": "Irritant contact dermatitis (ICD) can be divided into forms caused by chemical irritants, and those caused by physical irritants. Common chemical irritants implicated include: solvents (alcohol, xylene, turpentine, esters, acetone, ketones, and others); metalworking fluids (neat oils, water-based metalworking fluids with surfactants); latex; kerosene; ethylene oxide; surfactants in topical medications and cosmetics (sodium lauryl sulfate); and alkalis (drain cleaners, strong soap with lye residues).\nPhysical irritant contact dermatitis may most commonly be caused by low humidity from air conditioning. Also, many plants directly irritate the skin.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Causes", "sub_heading": "Causes", "_id": "2--1--0---1", "title": "Irritant Contact Dermatitis"}
{"qas": [{"question": "How does contact dermatitis work?", "answer": ""}, {"question": "Where does balsam come from in the world?", "answer": "Peru", "ae_score": -0.9926875534702241, "qg_score": null}, {"question": "Where does balsam come from in the world?", "answer": "Peru", "ae_score": -0.9926875534702241, "qg_score": null}], "content": "Allergic contact dermatitis (ACD) is accepted to be the most prevalent form of immunotoxicity found in humans, and is a common occupational and environmental health problem. By its allergic nature, this form of contact dermatitis is a hypersensitive reaction that is atypical within the population. The mechanisms by which this reaction occurs are complex, with many levels of fine control. Their immunology centres on the interaction of immunoregulatory cytokines and discrete subpopulations of T lymphocytes.\nAllergens include nickel, gold, Balsam of Peru (''Myroxylon pereirae''), chromium, and the oily coating from plants of the ''Toxicodendron'' genus, such as poison ivy, poison oak, and poison sumac.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Causes", "sub_heading": "Allergic contact dermatitis", "_id": "2--1--1---1", "title": "Allergic contact dermatitis"}
{"qas": [{"question": "Why do I get a burning sensation in my skin when I get contact dermatitis?", "answer": ""}, {"question": "What is the medical term for contact dermatitis?", "answer": "photoaggravated", "ae_score": -0.36870898505208116, "qg_score": null}, {"question": "What is the medical term for contact dermatitis?", "answer": "photoaggravated", "ae_score": -0.36870898505208116, "qg_score": null}], "content": "Sometimes termed \"photoaggravated\", and divided into two categories, phototoxic and photoallergic, PCD is the eczematous condition which is triggered by an interaction between an otherwise unharmful or less harmful substance on the skin and ultraviolet light (320\u2013400 nm UVA) (ESCD 2006), therefore manifesting itself only in regions where the sufferer has been exposed to such rays.\nWithout the presence of these rays, the photosensitiser is not harmful. For this reason, this form of contact dermatitis is usually associated only with areas of skin which are left uncovered by clothing, and it can be soundly defeated by avoiding exposure to sunlight.  The mechanism of action varies from toxin to toxin, but is usually due to the production of a photoproduct. Toxins which are associated with PCD include the psoralens. Psoralens are in fact used therapeutically for the treatment of psoriasis, eczema, and vitiligo.\nPhotocontact dermatitis is another condition in which the distinction between forms of contact dermatitis is not clear-cut. Immunological mechanisms can also play a part, causing a response similar to ACD.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Causes", "sub_heading": "Photocontact dermatitis", "_id": "2--1--2---1", "title": "Photocontact dermatitis \u2014 ACD"}
{"qas": [{"question": "Why does it take so long for an allergy medication to work?", "answer": ""}, {"question": "What causes contact dermatitis in the body?", "answer": "chemicals", "ae_score": -0.6877212455657096, "qg_score": null}, {"question": "What causes contact dermatitis in the body?", "answer": "chemicals", "ae_score": -0.6877212455657096, "qg_score": null}], "content": "Since contact dermatitis relies on an irritant or an allergen to initiate the reaction, it is important for the patient to identify the responsible agent and avoid it. This can be accomplished by having patch tests, one of various methods commonly known as allergy testing.  The top three allergens found in patch tests from 2005\u201306 were:  nickel sulfate (19.0%), Myroxylon pereirae (Balsam of Peru, 11.9%), and  fragrance mix I (11.5%).\nThe patient must know where the irritant or allergen is found to be able to avoid it. It is important to also note that chemicals sometimes have several different names, and do not always appear on labels.\nThe distinction between the various types of contact dermatitis is based on a number of factors. The morphology of the tissues, the histology, and immunologic findings are all used in diagnosis of the form of the condition. However, as suggested previously, there is some confusion in the distinction of the different forms of contact dermatitis. Using histology on its own is insufficient, as these findings have been acknowledged not to distinguish, and even positive patch testing does not rule out the existence of an irritant form of dermatitis as well as an immunological one.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "2--2---1---1", "title": "The Different Forms of Contact Dermatitis"}
{"qas": [{"question": "Why do people wear protective gear when working in an industrial setting?", "answer": ""}, {"question": "What type of antibiotics are used to treat contact dermatitis?", "answer": "Topical antibiotics", "ae_score": -0.2890466390137337, "qg_score": null}, {"question": "What type of antibiotics are used to treat contact dermatitis?", "answer": "Topical antibiotics", "ae_score": -0.2890466390137337, "qg_score": null}], "content": "In an industrial setting the employer has a duty of care to its worker to provide the correct level of safety equipment to mitigate exposure to harmful irritants. This can take the form of protective clothing, gloves, or barrier cream, depending on the working environment.\nTopical antibiotics should not be used to prevent infection in wounds after surgery.<ref name=\"AADfive\">", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Prevention", "sub_heading": "Prevention", "_id": "2--3---1---1", "title": "Contact dermatitis | Prevention"}
{"qas": [{"question": "Why do some people have a rash and others don't?", "answer": ""}, {"question": "Who takes the medicine for contact dermatitis?", "answer": "dermatologist", "ae_score": -0.16270716513925249, "qg_score": null}, {"question": "Who takes the medicine for contact dermatitis?", "answer": "dermatologist", "ae_score": -0.16270716513925249, "qg_score": null}], "content": "If the rash does not improve or continues to spread after 2\u20133 of days of self-care, or if the itching and/or pain is severe, the patient should contact a dermatologist or other physician. Medical treatment usually consists of lotions, creams, or oral medications.\nIn severe cases, a stronger medicine like halobetasol may be prescribed by a dermatologist.", "page_name": "Contact dermatitis", "page_id": "Contact%20dermatitis", "heading": "Treatment", "sub_heading": "Treatment", "_id": "2--4---1---1", "title": "Dermatopathology: Skin Rashes"}
{"qas": [{"question": "Where did the term \"firing\" come from?", "answer": ""}, {"question": "When did the term termination come into use?", "answer": "1910s", "ae_score": -0.6870323200200164, "qg_score": null}, {"question": "When did the term termination come into use?", "answer": "1910s", "ae_score": -0.6870323200200164, "qg_score": null}], "content": "\"Firing\" is a common colloquial term in the English language (particularly used in the U.S. and Australia) for termination.  The term \"firing\" may have been initiated  in the 1910s at the National Cash Register Company. Other terms for dismissal are being \"sacked\", \"canned\", \"ran-off\", \"axed\", \"given walking papers\", \"given the pink slip\" or \"boned\".  Other terms, more often used in Commonwealth countries, include \"to get the boot\" and \"to get the sack\".", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Usage", "sub_heading": "Usage", "_id": "3--0---1---1", "title": "\"Firing\" is a common colloquial term in the English language (particularly"}
{"qas": [{"question": "Why do some people get fired even if they have good attendance at a job?", "answer": ""}, {"question": "What is an example of an off-the-job behavior that can result in termination?", "answer": "drunk driving", "ae_score": -0.5463027184993718, "qg_score": null}, {"question": "What is an example of an off-the-job behavior that can result in termination?", "answer": "drunk driving", "ae_score": -0.5463027184993718, "qg_score": null}], "content": "Most US states have adopted the at-will employment contract that allows the employer to dismiss employees without having to provide a justified reason for firing, although the variety of court cases that have come out of \"at-will\" dismissals have made such at-will contracts ambiguous. Often, an at-will termination is handled as a \"layoff\". Sometimes, an employee will be dismissed if an employer can find better employees than the incumbent, even if the fired employee has not technically broken any rules. This is common with probationary employees who were recently hired, but who cannot adjust to the environment of the workplace, or those who have been around for a long time, but can be replaced with a less experienced employee who can be paid a lower salary. On the contrary, a dismissal in France is subjected to a just cause and a formal procedure.\nSome examples include conflict of interest, where the employee has done nothing wrong, but the presence of the employee on the employer's payroll may be harmful to the employer. For example: \nMore common reasons for firing include attendance problems, poor work performance, problematic conduct, insubordination (talking back to a manager or supervisor), drinking or doing illegal drugs at work (or consuming the same substances before work and showing up to work while intoxicated or \"high\" (an especially serious problem in jobs where the worker drives a vehicle, boat or aircraft or operates heavy machinery) or off job-site conduct. Attendance problems include frequent absenteeism or tardiness, or even worse, the \"no call, no show\" in which an employee does not come to work and fails to notify the employer. Other attendance problems involve improper taking of breaks, such as taking extended or unauthorized breaks, failure to return from breaks in a timely manner, or walking off the premises or job site without approval from the supervisor.\nWork performance problems can lead to termination even with good attendance at a job. An employee may be fired if their work performance does not meet the employer's standards. Some of these issues may be lack of necessary skills required to perform duties, incompetence, failure to learn the required skills or processes, neglect of maintenance or safety procedures, refusal to perform duties, laziness, or negligence. Conduct problems can lead to firing if they continue over a long period. Behavioral issues may include unprofessional manners (especially in customer service jobs), constant or gross insubordination, inability to properly relate (i.e., get along) with co-workers, customers or both, arguing with supervisor, co-workers or customers, use of foul language while at work, and sleeping while on duty. With these conduct problems, the firing is frequently (but not always) part of a \"progressive step\" process, meaning the employee will have been warned and given an opportunity to improve before more severe measures are taken.\nGross misconduct offenses can lead to immediate firing without any further warning. Gross misconduct includes damaging work equipment through negligence; discovery of false information on the job application (such as r\u00e9sum\u00e9 fraud), fighting or brawling at work; harassment of other employees, such as sexual or racial harassment; use of employer's equipment (e.g. vehicles and computers) to engage in non-work-related activity or other violations of employer policies, illegal activity, or to view pornography; testing positive for illegal drug usage; failure to submit to a mandatory drug test (especially for transportation or heavy equipment-related jobs such as machine operators); engaging in illegal activities on the job (such as embezzlement or illegal subordinate harassment); or cheating the employer out of wages by \"padding\" a time sheet.\nIn some cases, an employee's off-the-job behavior could result in job loss. A common example is drunk driving, especially if the employee's principal responsibilities require driving. Often, an employee getting charged with a crime will affect the employer's ability to trust the employee. Whether off-the-job criminal charges will result in termination relates to several factors, including the nature of the offense, the nature of the job, and the values of the employer. In some types of jobs, minor convictions that are not related to the job activities may not lead to termination; a ditch digger who works with a shovel who is convicted of drunk driving may not lose their job, while a food delivery driver who is convicted of drunk driving will lose their job. However, in some jobs, the perception of trust is very important, so even a non-job-related conviction, however minor, will result in termination, as in the case of banks, security firms, and schools. Another factor is the values of the employer; while some employers may believe that an employee should have a \"second chance\", other employers may have no tolerance for convicted individuals in their company, even if the employee has very little responsibility, as in the case of a manual labourer.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Reasons", "sub_heading": "Reasons", "_id": "3--1---1---1", "title": "Fired Employees in France \u2014 What Is The Reason?"}
{"qas": [{"question": "What is the point of a guard or officer escorting a fired employee to the parking lot?", "answer": ""}, {"question": "Who escorts a fired employee to the parking lot?", "answer": "a guard or officer", "ae_score": -1.2732286995878284, "qg_score": null}, {"question": "Who escorts a fired employee to the parking lot?", "answer": "a guard or officer", "ae_score": -1.2732286995878284, "qg_score": null}], "content": "Some fired employees may face additional consequences besides their dismissal. This may occur when the reason for the termination is a violation of criminal law, or if serious damages are caused to the employer as a result of the employee's actions. Such ex-employees may face criminal prosecution, a civil lawsuit, or a reporting to a database of those who have engaged in serious misconduct in such a position, so that the chances of ever obtaining a similar position with another employer are less likely. Some examples are a caregiver who engages in abuse, a bank teller who has stolen money from the cash drawer, or a member of law enforcement who has committed police brutality.\nFor the most serious violations, especially when the employer's security may be at risk from the employee in question, a guard or officer may escort a fired employee from the workplace to the parking lot upon their dismissal. Such actions are often taken by government offices or large corporations that contain sensitive materials, and where the risk exists that the terminated employee may remove some of these materials or otherwise steal trade secrets in order to retaliate against the employer or use it to the advantage of a competing enterprise.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Additional consequences", "sub_heading": "Additional consequences", "_id": "3--2---1---1", "title": "Fired Employees May Face Additional Penalties"}
{"qas": [{"question": "How do employers prevent employees from being fired?", "answer": ""}, {"question": "What is the most common method of dismissing an employee?", "answer": "forced resignation", "ae_score": -0.4249307106634022, "qg_score": null}, {"question": "What is the most common method of dismissing an employee?", "answer": "forced resignation", "ae_score": -0.4249307106634022, "qg_score": null}], "content": "Employers have several methods of countering some of these potential threats. A common method is forced resignation, and it allows the employee to resign as if by choice, thereby freeing the employer of the burden of a firing.  Other methods used by employers include:\nA forced resignation is when an employee is required to depart from their position due to some issue caused by their continued employment. A forced resignation may be due to the employer's wishes to dismiss the employee, but the employer may be offering a ''softened firing''. Or, in a high profile position, the employee may want to leave before the press learns more negative information about one's controversial nature. To avoid this, and to allow the dismissed employee to \"save face\" in a more \"graceful\" exit, the employer will often ask the employee to resign \"voluntarily\" from their position. If the employee chooses not to resign, the processes necessary to fire them may be pursued, and the employee will usually be fired. The resignation thus makes it unclear whether the resignation was forced or voluntary, and this opaqueness may benefit both parties.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Problem employees", "sub_heading": "Problem employees", "_id": "3--3--0---1", "title": "Employers Use Various Methods of Resigning"}
{"qas": [{"question": "How can a company fire an employee for \"just cause\"?", "answer": ""}, {"question": "The process of terminating a worker is called?", "answer": "administrative process", "ae_score": -0.43404516941921434, "qg_score": null}, {"question": "The process of terminating a worker is called?", "answer": "administrative process", "ae_score": -0.43404516941921434, "qg_score": null}], "content": "In some cases, the firing of an employee is a discriminatory act. Although an employer may often claim the dismissal was for \"just cause\", these discriminatory acts are often because of the employee's physical or mental disability, or perhaps their age, race, religion, gender, HIV status or sexual orientation. Other unjust firings may result from a workplace manager or supervisor wanting to retaliate against an employee. Often, this is because the worker reported wrongdoing (often, but not always sexual harassment or other misconduct) on the part of the supervisor. Such terminations are often illegal. Many successful lawsuits have resulted from discriminatory or retaliatory termination.\nDiscriminatory or retaliatory termination by a supervisor can take the form of administrative process. In this form the rules of the institution are used as the basis for termination. For example, if a place of employment has a rule that prohibits personal phone calls, receiving or making personal calls can be the grounds for termination even though it may be a common practice within the organization.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Discriminatory and retaliatory termination", "sub_heading": "Discriminatory and retaliatory termination", "_id": "3--4---1---1", "title": "Discriminatory and Retaliatory Termination"}
{"qas": [{"question": "How does \"forced resignation\" work?", "answer": ""}, {"question": "What is it called when an employee is fired?", "answer": "constructive dismissal", "ae_score": -0.476624080597198, "qg_score": null}, {"question": "What is it called when an employee is fired?", "answer": "constructive dismissal", "ae_score": -0.476624080597198, "qg_score": null}], "content": "Employers who wish for an employee to exit of their own accord, but do not wish to pursue firing or forced resignation, may degrade the employee's working conditions, hoping that he or she will leave \"voluntarily\". The employee may be moved to a different geographical location, assigned to an undesirable shift, given too few hours if part-time, demoted (or relegated to a menial task), or assigned to work in uncomfortable conditions. Other forms of manipulation may be used, such as being unfairly hostile to the employee, and punishing them for things that are deliberately overlooked with other employees. Such tactics may amount to constructive dismissal, which is illegal in some jurisdictions.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Changes of conditions", "sub_heading": "Changes of conditions", "_id": "3--5---1---1", "title": "Employers who wish for an employee to leave \"voluntarily\" may use \"constructive dismiss"}
{"qas": [{"question": "What is the difference between \"terminated without prejudice\" and \"without prejudice\"?", "answer": ""}, {"question": "When do you get terminated without prejudice?", "answer": "layoff", "ae_score": -1.481984875640863, "qg_score": null}, {"question": "When do you get terminated without prejudice?", "answer": "layoff", "ae_score": -1.481984875640863, "qg_score": null}], "content": "Depending on the circumstances, one whose employment has been terminated may or may not be eligible for being rehired by the same employer. If the decision to terminate was the employee's, the willingness of the employer to rehire is often contingent upon the relationship the employee had with the employer, the amount of notice given by the employee prior to departure, and the needs of the employer. In some cases, when an employee departed on good terms, they may be given special priority by the employer when seeking rehire.\nAn employee may be ''terminated without prejudice'', meaning the fired employee may be rehired readily for the same or a similar job in the future. This is usually true in the case of layoff. Conversely, a person can be ''terminated with prejudice'', meaning an employer will not rehire the former employee to a similar job in the future. This can be for many reasons: incompetence, misconduct (such as dishonesty or \"zero tolerance\" violations), insubordination or \"attitude\" (personality clashes with peers or bosses). Termination forms (\"pink slips\"in the U.S.) routinely include a set of check boxes where a supervisor can indicate \"with prejudice\" or \"without prejudice\". During the Vietnam War, the CIA used this terminology with regard to its locally hired operatives. In the case of severe misconduct, it is alleged that the CIA would assassinate them or \"terminate with extreme prejudice\".", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "Rehire following termination", "sub_heading": "Rehire following termination", "_id": "3--6---1---1", "title": "Termination and Rehire"}
{"qas": [{"question": "What is the difference between a high profile firing and a low profile firing?", "answer": ""}, {"question": "What is the legal term for termination of an employee?", "answer": "High-profile firing", "ae_score": -0.5997748289155062, "qg_score": null}, {"question": "What is the legal term for termination of an employee?", "answer": "High-profile firing", "ae_score": -0.5997748289155062, "qg_score": null}], "content": "High-profile firing refers to the termination of an employee who is in the public spotlight. In such cases, though terminology may be similar, the rules may differ from the typical firing. For example, in professional sports, a coach's dismissal is generally referred to as a firing. However, though the employment will cease, the team may be required to pay the coach the remainder of his contract. A player on a team who faces the same action is generally not considered to be \"fired\", but rather \"released\" or \"waived\".\nIn many countries and smaller jurisdictions, the chief executive reserves the right to dismiss certain officials who have been appointed to their positions, with the termination effective immediately and with no obligation for any further pay. In some cases, however, a severance package may be paid. There are times when the President of the United States will ask his entire Cabinet to submit their resignations. He can accept some of them and file the rest away. This is often done by a new President who has inherited his predecessor's Cabinet, as a way to reorganize with reduced hard feelings.", "page_name": "Dismissal (employment)", "page_id": "Dismissal%20(employment)", "heading": "High-profile firings", "sub_heading": "High-profile firings", "_id": "3--7---1---1", "title": "What is a High-profile Fire?"}
{"qas": [{"question": "How does Roselius\u2019s method of decaffeination work?", "answer": ""}, {"question": "When was the indirect organic solvent method first used?", "answer": "1941", "ae_score": -0.299055215355398, "qg_score": null}, {"question": "When was the indirect organic solvent method first used?", "answer": "1941", "ae_score": -0.299055215355398, "qg_score": null}], "content": "Friedlieb Ferdinand Runge performed the first isolation of pure caffeine from coffee beans in 1820. He did this after the Poet Goethe requested he perform an analysis on coffee beans after seeing his work on belladonna extract. Though Runge was able to isolate the compound, he didn\u2019t learn much as to the chemistry of caffeine itself, nor did he seek to use the process commercially to produce decaffeinated coffee.\nThe first commercially successful decaffeination process was invented by German merchant Ludwig Roselius and co-workers in 1903 and patented in 1906. In 1903, Ludwig accidentally stumbled upon this method when his freight of coffee beans was soaked in sea water and lost much of its caffeine without losing much taste. This original decaffeination process involved steaming coffee beans with various acids or bases, then using benzene as a solvent to remove the caffeine. Coffee decaffeinated this way was sold as Kaffee HAG after the company name ''Kaffee Handels-Aktien-Gesellschaft'' (Coffee Trading Company) in most of Europe, as ''Caf\u00e9 Sanka'' in France and later as Sanka brand coffee in the U.S.. Caf\u00e9 HAG and Sanka are now worldwide brands of Kraft Foods. Because of health concerns regarding benzene (which is recognised today as a proven carcinogen), benzene is no longer used as a solvent commercially.\nSince its inception, methods of decaffeination similar to those first developed by Roselius have continued to dominate. While Roselius used Benzene, many different solvents have since been tried after learning of the potential harmful effects of benzene. The most prevalent solvents used to date are dichloromethane and ethylacetate, which are still used largely today.\nAnother variation of Roselius\u2019s method is the indirect organic solvent method. This is very similar to the process described above, only instead of treating the beans directly, water resulting from the soaking of beans is treated with solvents and the process goes on until equilibrium is reached without caffeine in the beans. This method was first mentioned in 1941, and people have made great efforts to make the process more \u201cnatural\u2019 and a true water-based process by finding ways to process the caffeine out of the water in ways that circumvents the use of organic solvents.\nAnother process, known as the Swiss Water Method, uses solely water and osmosis to decaffeinate beans. The use of water as the solvent to decaffeinate coffee was originally pioneered in Switzerland in 1933 and developed as a commercially viable method of decaffeination by Coffex S.A. in 1980. In 1988, the Swiss Water Method was introduced by The Swiss Water Decaffeinated Coffee Company of Burnaby, British Columbia, Canada. Noted food engineer Torunn Atteraas Garin also developed a process to remove caffeine from coffee.\nMost recently, food scientists have turned to supercritical carbon dioxide as a means of decaffeination. Developed by Kurt Zosel, a scientist of the Max Planck Institute, it uses CO, heated and pressurized above its critical point, to extract caffeine and could be useful going forward because it circumvents the use of other solvents and their possible effects entirely.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "History", "sub_heading": "History", "_id": "4--0--0---1", "title": "How to Decaffeinate Coffee Using Carbon Dioxide"}
{"qas": [{"question": "Why is coffee decaffeinated?", "answer": ""}, {"question": "What is the best solution for decaffeination?", "answer": "water", "ae_score": -1.3888376502319275, "qg_score": null}, {"question": "What is the best solution for decaffeination?", "answer": "water", "ae_score": -1.3888376502319275, "qg_score": null}], "content": "In all decaffeination processes, coffee is always decaffeinated in its green, unroasted state. The greatest challenge to the decaffeination process is to try to separate only the caffeine from the coffee beans while leaving the other chemicals such as sucrose, cellulose, proteins, citric acid, tartaric acid, and formic acid at their original concentrations. This is not an easy task considering coffee contains somewhere around 1,000 chemicals that contribute to the taste and aroma. Since caffeine is a polar, water-soluble substance, water is used in all forms of decaffeination. However, water alone is not the best solution for decaffeination because it is not a selective solvent and therefore removes other soluble substances, including sugars and proteins, as well as caffeine. Therefore, most decaffeination processes use a decaffeinating agent such as methylene chloride, activated charcoal, , or ethyl acetate. These agents help speed up the process and minimize the \u201cwashed-out\u201d effects that water alone might have on the taste of decaffeinated coffee.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeination processes for coffee", "sub_heading": "Decaffeination processes for coffee", "_id": "4--1--0---1", "title": "Coffee Decaffeination Process"}
{"qas": [{"question": "How does the Swiss Water process work?", "answer": ""}, {"question": "How many concepts are used to decaffeinate coffee beans?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many concepts are used to decaffeinate coffee beans?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "This method is different in that it does not directly or indirectly add chemicals to extract the caffeine. Rather, it relies entirely on two concepts \u2013 solubility and osmosis \u2013 to decaffeinate coffee beans. The process begins by immersing a batch of green coffee beans in very hot water in order to dissolve and extract the caffeine. The water is then drawn off and passed through an activated charcoal filter. The porosity of this filter is sized to only capture larger caffeine molecules, while allowing smaller oil and flavor molecules to pass through it. However, this extraction process will also extract desirable oils and other solids from the beans, resulting in beans with no caffeine and no flavor in one tank, and caffeine-free but with flavor water in another tank. The Swiss Water process method attempts to overcome this difficulty by first discarding the flavorless caffeine-free beans, and then reusing the flavor-rich water to remove the caffeine from a fresh batch of coffee beans. Water saturated in this way is referred to as green coffee extract or GCE. It is created using a separate batch of green coffee beans, which are immersed in water and then discarded. In a pre-loading tank, water, cane sugar and formic acid are mixed and heated and used to preload carbon filter columns. The GCE is then filtered over the columns to extract caffeine from it. A fresh batch of green coffee beans is then immersed in the GCE to remove caffeine but retain other components. The other components can be retained because the water is already saturated with flavor ingredients, therefore, the flavors in this fresh batch cannot dissolve - only caffeine moves from the coffee beans to the water. This results in decaffeination without a massive loss of flavor. The process of filtering the GCE to remove caffeine and immersing the beans is repeated until the beans are 99.9% caffeine free by mass, meeting the required standard. This process takes 8 to 10 hours.\n Alternate link to Patent Citation", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeination processes for coffee", "sub_heading": "Swiss Water process", "_id": "4--1--1---1", "title": "Swiss Water Process \u2014 Coffee Bean Decaffeination. The Swiss Water process method..."}
{"qas": [{"question": "What is the difference between direct and indirect decaffeination?", "answer": ""}, {"question": "How long does it take to remove caffeine from coffee beans?", "answer": "10 hours", "ae_score": -0.28658940247644415, "qg_score": null}, {"question": "How long does it take to remove caffeine from coffee beans?", "answer": "10 hours", "ae_score": -0.28658940247644415, "qg_score": null}], "content": "Given numerous health scares connected to early efforts in decaffeination using solvents such as benzene, trichloroethylene, and chloroform, the solvents of choice have become dichloromethane and ethyl acetate. Dichloromethane is able to extract the caffeine selectively and has a low boiling point. Although it is mildly toxic and carcinogenic, its use as a decaffeination agent is allowed by the US Food and Drug Administration if the residual solvent is less than 10 parts per million (ppm). Actual coffee industry practice results in residues closer to one part per million. Starting in the 1980s, ethyl acetate was introduced as a replacement to dichloromethane.  Although ethyl acetate is mildly toxic, coffee that is decaffeinated with this solvent is sometimes marketed as \"naturally decaffeinated\" because this solvent may be obtained from a biological process such as the fermentation of sugar cane.\nIn the direct method, the coffee beans are first steamed for 30 minutes to open their pores and then repeatedly rinsed with either dichloromethane or ethyl acetate for about 10 hours to remove the caffeine. The caffeine-laden solvent is then drained away and the beans steamed to remove residual solvent.\nIn the indirect method, beans are first soaked in hot water for several hours, in essence making a strong pot of coffee. Then the beans are removed and either dichloromethane or ethyl acetate is used to extract the caffeine from the water. As in other methods, the caffeine can then be separated from the organic solvent by simple evaporation. The same water is recycled through this two-step process with new batches of beans. An equilibrium is reached after several cycles, wherein the water and the beans have a similar composition except for the caffeine. After this point, the caffeine is the only material removed from the beans, so no coffee strength or other flavorings are lost. Because water is used in the initial phase of this process, indirect method decaffeination is sometimes referred to as \"water-processed\".", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeination processes for coffee", "sub_heading": "Organic solvent processes", "_id": "4--1--2---1", "title": "Decaffeination Using Dichloromethane and Ethyl Acetate"}
{"qas": [{"question": "How do we know how much CO is in our atmosphere?", "answer": ""}, {"question": "What is the process used to extract carbon dioxide called?", "answer": "supercritical fluid extraction", "ae_score": -0.23159967065289583, "qg_score": null}, {"question": "What is the process used to extract carbon dioxide called?", "answer": "supercritical fluid extraction", "ae_score": -0.23159967065289583, "qg_score": null}], "content": "This process has been referred to as CO Method, Liquid Carbon Dioxide Method, and Supercritical Carbon Dioxide method but it is technically known as supercritical fluid extraction.\nThe supercritical CO acts selectively on the caffeine, releasing the alkaloid and nothing else. Water-soaked coffee beans are placed in an extraction vessel. The extractor is then sealed and supercritical CO is forced into the coffee at pressures of 1,000 pounds per square inch to extract the caffeine. The CO acts as the solvent to dissolve and draw the caffeine from the coffee beans, leaving the larger-molecule flavor components behind. The caffeine-laden CO is then transferred to another container called the absorption chamber where the pressure is released and the CO returns to its gaseous state and evaporates, leaving the caffeine behind. The caffeine is removed from the CO using charcoal filters, and the caffeine free CO is pumped back into a pressurized container for reuse on another batch of beans. This process has the advantage that it avoids the use of potentially harmful substances. Because of its cost, this process is primarily used to decaffeinate large quantities of commercial-grade, less-exotic coffee found in grocery stores.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeination processes for coffee", "sub_heading": "CO process", "_id": "4--1--3---1", "title": "Supercritical Carbon Dioxide Method"}
{"qas": [{"question": "How are green coffee beans made?", "answer": ""}, {"question": "How long does it take to decaffeinate a batch of beans?", "answer": "several hours", "ae_score": null, "qg_score": null}, {"question": "How long does it take to decaffeinate a batch of beans?", "answer": "several hours", "ae_score": null, "qg_score": null}], "content": "Green coffee beans are soaked in a hot water/coffee solution to draw the caffeine to the surface of the beans. Next, the beans are transferred to another container and immersed in coffee oils that were obtained from spent coffee grounds and let to soak\nAfter several hours of high temperatures, the triglycerides in the oils remove the caffeine, but not the flavor elements, from the beans. The beans are separated from the oils and dried. The caffeine is removed from the oils, which are reused to decaffeinate another batch of beans. This is a direct-contact method of decaffeination.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeination processes for coffee", "sub_heading": "Triglyceride process", "_id": "4--1--4---1", "title": "Decaffeination of Coffee Beans"}
{"qas": [{"question": "How do coffee companies know how much caffeine is in their coffee?", "answer": ""}, {"question": "How many samples of decaffeinated coffee from coffee shops showed that some caffeine remained?", "answer": "ten", "ae_score": -0.5623107487056287, "qg_score": null}, {"question": "How many samples of decaffeinated coffee from coffee shops showed that some caffeine remained?", "answer": "ten", "ae_score": -0.5623107487056287, "qg_score": null}], "content": "To ensure product quality, manufacturers are required to test the newly decaffeinated coffee beans to make sure that caffeine concentration is relatively low (no less than 97% caffeine content reduction according to United States standards). To do so, many coffee companies choose to employ High-performance liquid chromatography to quantitatively measure how much caffeine remains in the coffee beans. However, since HPLC can be quite costly, some coffee companies are beginning to use other methods such as Near-infrared (NIR) spectroscopy. Although HPLC is highly accurate, NIR spectroscopy is much faster, cheaper and overall easier to use. Lastly, another method typically used to quantify remaining caffeine includes Ultraviolet\u2013visible spectroscopy, which can be greatly advantageous for decaffeination processes that include supercritical CO as CO does not absorb in the UV-Vis range.\nA controlled study of ten samples of prepared decaffeinated coffee from coffee shops showed that some caffeine remained. Fourteen to twenty cups of such decaffeinated coffee would contain as much caffeine as one cup of regular coffee. The 16-ounce (473-ml) cups of coffee samples contained caffeine in the range of 8.6 mg to 13.9 mg. In another study of popular brands of decaf coffees, the caffeine content varied from 3 mg to 32 mg. An 8-ounce (237-ml) cup of regular coffee contains 95\u2013200 mg of caffeine, and a 12-ounce (355-milliliter) serving of Coca-Cola contains 36 mg.\nBoth of these studies tested the caffeine content of store-brewed coffee, suggesting that the caffeine may be residual from the normal coffee served rather than poorly decaffeinated coffee.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeinated coffee", "sub_heading": "Decaffeinated coffee", "_id": "4--2---1---1", "title": "How Much Caffeine Is Still in Coffee Beans?"}
{"qas": [{"question": "Why is decaffeinated coffee called decaffito?", "answer": ""}, {"question": "Decaffeinated coffee is trademarked in which country?", "answer": "Brazil", "ae_score": -0.39556402158376297, "qg_score": null}, {"question": "Decaffeinated coffee is trademarked in which country?", "answer": "Brazil", "ae_score": -0.39556402158376297, "qg_score": null}], "content": "As of 2009, progress toward growing coffee beans that do not contain caffeine was still continuing. The term \"Decaffito\" has been coined to describe this type of decaffeinated coffee, and trademarked in Brazil.\nThe prospect for Decaffito-type coffees was shown by the discovery of the naturally caffeine-free ''Coffea charrieriana'', reported in 2004. It has a deficient caffeine synthase gene, leading it to accumulate theobromine instead of converting it to caffeine. Either this trait could be bred into other coffee plants by crossing them with ''C. charrieriana'', or an equivalent effect could be achieved by knocking out the gene for caffeine synthase in normal coffee plants.", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffito", "sub_heading": "Decaffito", "_id": "4--3---1---1", "title": "Decaffeination | Decaffito"}
{"qas": [{"question": "Why does tea taste so much better than coffee?", "answer": ""}, {"question": "How much caffeine is in a cup of tea?", "answer": "40\u201350 mg", "ae_score": -0.4027322073950104, "qg_score": null}, {"question": "How much caffeine is in a cup of tea?", "answer": "40\u201350 mg", "ae_score": -0.4027322073950104, "qg_score": null}], "content": "Tea may also be decaffeinated, usually by using processes analogous to the direct method or the CO process, as described above. The process of oxidizing tea leaves to create black tea (\"red\" in Chinese tea culture) or oolong tea leaves from green leaves, does not affect the amount of caffeine in the tea, though tea-plant species (i.e., ''Camellia sinensis sinensis'' vs. ''Camellia sinensis assamica'') may differ in natural caffeine content. Younger leaves and buds contain more caffeine per weight than older leaves and stems. Although the CO process is favorable because it is convenient, nonexplosive, and nontoxic, a comparison between regular and decaffeinated green teas using supercritical carbon dioxide showed that most volatile, nonpolar compounds (such as linalool and phenylacetaldehyde), green and floral flavor compounds (such as hexanal and (''E'')-2-hexenal), and some unknown compounds disappeared or decreased after decaffeination.\nIn addition to CO process extraction, tea may be also decaffeinated using a hot water treatment. Optimal conditions are met by controlling water temperature, extraction time, and ratio of leaf to water, where higher temperatures at or over 100 \u00b0C, moderate extraction time of 3 minutes, and a 1:20 water to leaf weight per volume ratio removed 83% caffeine content and preserved 95% of total catechins. Catechins, a type of flavanol, contribute to the flavor of the tea and also, interestingly, have been shown to increase suppression of mutagens that may lead to cancer.\nBoth coffee and tea have tannins, which is responsible for the astringent taste, but tea has nearly three times smaller tannin content than coffee. Thus, decaffeination of tea requires more care to maintain tannin content than decaffeination of coffee in order to preserve this flavor. Preserving tannins is desirable not only because of their flavor, but also because they have been shown to have anticarcinogenic, antimutagenic, antioxidative, and antimicrobrial properties. Specifically, tannins accelerate blood clotting, reduce blood pressure, decrease the serum lipid level, produce liver necrosis, and modulate immunoresponses.\nCertain processes during normal production might help to decrease the caffeine content directly, or simply lower the rate at which it is released throughout each infusion. Several instances in China where this is evident is in many cooked pu-erh teas, as well as more heavily fired Wuyi Mountain oolongs; commonly referred to as 'zhonghuo' (mid-fired) or 'zuhuo' (high-fired).\nA generally accepted statistic is that a cup of normal black (often called red in China; as distinct from green) tea contains 40\u201350 mg of caffeine, roughly half the content of a cup of coffee.\nAlthough a common technique of discarding a short (30- to 60-second) steep is believed to much reduce caffeine content of a subsequent brew at the cost of some loss of flavor, research suggests that a five-minute steep yields up to 70% of the caffeine, and a second steep has one-third the caffeine of the first (about 23% of the total caffeine in the leaves).", "page_name": "Decaffeination", "page_id": "Decaffeination", "heading": "Decaffeinated tea", "sub_heading": "Decaffeinated tea", "_id": "4--4---1---1", "title": "How to Decaffeinate Tea in China"}
{"qas": [{"question": "Why didn't Germany just bomb Hiroshima and Nagasaki?", "answer": ""}, {"question": "What did german scientists focus on in heavy water sabotage?", "answer": "plutonium production", "ae_score": -0.5275731589124818, "qg_score": null}, {"question": "What did german scientists focus on in heavy water sabotage?", "answer": "plutonium production", "ae_score": -0.5275731589124818, "qg_score": null}], "content": "In nuclear weapon development, the main problem is securing sufficient \"weapons grade\" material. In particular, it is difficult to acquire either fissile isotopes of uranium-235 (U) or of Pu. Weapons grade uranium requires mining, extracting and enriching natural ore. Alternatively, plutonium can be \"bred\" in reactors fueled by unenriched uranium, which requires chemical separation of the Pu produced.\nUnlike the Allies, who pursued both the enrichment of uranium and the production of plutonium, German scientists only focused on plutonium production, as this method was less expensive.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Technical background", "sub_heading": "Technical background", "_id": "5--0--0---1", "title": "German Scientists Focused on Plutonium Production"}
{"qas": [{"question": "Why can't we use uranium as a primary fissile material for an atomic bomb?", "answer": ""}, {"question": "What is the most common isotope of uranium?", "answer": "uranium-238 (U", "ae_score": null, "qg_score": null}, {"question": "What is the most common isotope of uranium?", "answer": "uranium-238 (U", "ae_score": null, "qg_score": null}], "content": "Although the most common isotope of uranium, uranium-238 (U), can be used as secondary fissionable material in hydrogen bombs, it cannot be used as the primary fissile material for an atomic bomb.U can be used to produce Pu, through the fission of U which produces neutrons, some of which will be absorbed by U creating U. After a few days the U will decay, turning into weapons-usable Pu.\nThe Germans did not examine ultra-pure graphite because they did not know that the graphite they had tried was too impure to sustain a chain reaction, and abandoned it as a possible moderator. They instead settled on the heavy-water-based reactor design. A heavy water moderated nuclear reactor could be used to do nuclear fission research, and, ultimately, to breed plutonium from which a bomb could be constructed.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Technical background", "sub_heading": "Plutonium production", "_id": "5--0--1---1", "title": "The German Atomic Bomb"}
{"qas": [{"question": "Why is deuterium so prevalent in heavy water?", "answer": ""}, {"question": "Who was the german adviser to the production of heavy water in norway?", "answer": "Hans Suess", "ae_score": -0.30284856627097884, "qg_score": null}, {"question": "Who was the german adviser to the production of heavy water in norway?", "answer": "Hans Suess", "ae_score": -0.30284856627097884, "qg_score": null}], "content": "In normal water, there is only one deuterium atom for every 6400 hydrogen atoms, but deuterium is more prevalent in the residue of water used as an electrolyte. An analysis of the residues from the Vemork hydroelectric plant, a large-scale hydrogen production plant using electrolysis of water for ammonia production, showed a hydrogen/deuterium ratio of 48, most of the deuterium being bound in HDO molecules. Leif Tronstad, then a lecturer at the Norwegian Institute of Technology and Jomar Brun, head of the hydrogen plant put forward a proposal in 1933, the year heavy water was first isolated, for a project, which was accepted by Norsk Hydro and production started in 1935.\nThe technology is straightforward. Heavy water (DO) is separated from normal water by electrolysis because the difference in mass between the two hydrogen isotopes translates into a slight difference in the speed at which the reaction proceeds. To produce pure heavy water by electrolysis requires a large cascade of electrolysis chambers, and consumes large amounts of power. Since there was excess power available, heavy water could be purified from the existing electrolyte. As a result, Norsk Hydro became the heavy water supplier for the world's scientific community, as a by-product of fertilizer production, for which the ammonia was used.\nHans Suess was a German adviser to the production of heavy water. Suess had assessed the Vemork plant as being incapable of producing militarily useful quantities of heavy water in less than five years at its then capacity.<ref Name=Dahl1999/>", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Technical background", "sub_heading": "Heavy water production", "_id": "5--0--2---1", "title": "Heavy Water \u2014 A History of Heavy Water"}
{"qas": [{"question": "How did Norsk Hydro manage to produce so much heavy water after WW2?", "answer": ""}, {"question": "Who was the norsk hydro general director during world war ii?", "answer": "Axel Aubert", "ae_score": -0.529873873929062, "qg_score": null}, {"question": "Who was the norsk hydro general director during world war ii?", "answer": "Axel Aubert", "ae_score": -0.529873873929062, "qg_score": null}], "content": "French research considered production of Pu using both heavy water and graphite moderated reactors. Preliminary French research indicated that the graphite which was then available commercially was not pure enough to serve the purpose, and that heavy water would be required. The German research community had reached a similar conclusion and in January 1940 had procured additional heavy water from Vemork. The German firm IG Farben, which was a partial owner of Norsk Hydro, had ordered 100 kg/month; Norsk Hydro's maximum production rate was then limited to 10 kg/month.<ref Name=Dahl1999/>\nIn 1940, the \"Deuxi\u00e8me Bureau\" (French military intelligence) directed three French agents, Captain Muller and Lieutenants Moss\u00e9 and Knall-Demars, to remove the world's extant supply, 185 kg of heavy water from the Vemork plant in then-neutral Norway. The Norsk Hydro General Director, Axel Aubert, agreed to lend the heavy water to France for the duration of the war, observing that if Germany won the war, he was likely to be shot. Transportation was difficult as German Military Intelligence (the ''Abwehr'') maintained a presence in Norway and had been alerted of ongoing French activities in Norway (although they had not been specifically warned about heavy water). Had they become aware of the shipment, they might have attempted to intercept it. The French transported it secretly to Oslo, to Perth, Scotland and then to France.<ref Name=Dahl1999/>\nWhen France was invaded the French nuclear scientist Fr\u00e9d\u00e9ric Joliot-Curie took charge of the material, hiding it first in a Banque de France vault and then in a prison. Joliot-Curie then moved it to Bordeaux, where it, plus research papers and most of the scientists (Joliot-Curie remained in France) boarded the British tramp steamer , which was one of the many merchant ships involved in saving over 200,000 troops and civilians in the three weeks after Dunkirk. The ship already had industrial diamonds, machinery and a number of British evacuees aboard. SS ''Broompark'' delivered its passengers and cargo, together with all of the free supply of heavy water, to Falmouth on 21 June. The award of an OBE to Captain Paulsen was recorded in the London Gazette of 4 February 1941. Crucial to the success of the mission was the role played by Charles Howard, 20th Earl of Suffolk.\nAlthough the ready inventory of heavy water was removed, the plant remained capable of producing heavy water. In investigations of collaboration launched by Norwegian authorities after the war, Norsk Hydro management's collaboration with the Germans was considered. General Director Aubert's cooperation with the French aided the Norsk Hydro case.<ref Name=Dahl1999/>", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Operations to limit German access to heavy water", "sub_heading": "Operations to limit German access to heavy water", "_id": "5--1--0---1", "title": "Norwegian heavy water sabotage | Operations to limit German access to heavy water"}
{"qas": [{"question": "How did the British find out about the pink elephants?", "answer": ""}, {"question": "What was the german interest in during the berlin raid?", "answer": "heavy water production", "ae_score": -0.3964727528197829, "qg_score": null}, {"question": "What was the german interest in during the berlin raid?", "answer": "heavy water production", "ae_score": -0.3964727528197829, "qg_score": null}], "content": "Destruction of the Vemork plant was mounted by the Combined Operations command in November 1942. The plan consisted of two operations: the first would drop a number of Norwegian locals into the area as an advance force, and once they were in place a party of British engineers would be landed by military glider to attack the plant itself.\nOn 19 October 1942, a four-man team of Special Operations Executive (SOE)-trained Norwegian commandos parachuted into Norway. From their drop point in the wilderness they had to ski a long distance to the plant, so considerable time was given to complete this part of the mission, known as Operation ''Grouse''. This plan, unlike prior failures, included the team's studying and memorising blueprints.<ref name=Gall/>\nOnce the Norwegian Grouse team managed to make contact with the British, the British were suspicious, as they had not heard from the SOE team for a long time: they had been dropped at the wrong place and had gone off course from there several times. The secret question took the form of: \"What did you see in the early morning of (a day)?\" The Grouse team replied: \"Three pink elephants.\" The British were ecstatic at the success of the Norwegian team's insertion, and the next phase of operations commenced.<ref name=Gall/><ref name=Berglyd/>\nOn 19 November 1942, Operation ''Freshman'' followed with the planned glider-borne landing on frozen lake M\u00f8svatn near the plant. Two Airspeed Horsa gliders, towed by Handley Page Halifax bombers, each glider carrying two pilots and 15 Royal Engineers of the 9th Field Company, 1st British Airborne Division, took off from RAF Skitten near Wick in Caithness. The towing of gliders had always been hazardous, but in this case it was made worse by the long flying distance to Norway and poor weather conditions which severely restricted visibility. One of the Halifax tugs crashed into a mountain, killing all seven aboard; its glider was able to cast off, but crashed nearby, resulting in several casualties. The other Halifax arrived at the area of the landing zone, but although the conditions had substantially improved it was impossible to locate the landing zone itself, owing to the failure of the link between the Eureka (ground) and Rebecca (aircraft) beacons. After much endeavour and with fuel running low, the Halifax pilot decided to abort the operation and return to base. Shortly afterwards, however, the tug and glider combination encountered heavy cloud and in the resulting turbulence the tow rope broke. The glider made a crash landing, not far from where the other glider had come down, similarly inflicting several deaths and injuries. The Norwegians were unable to reach the crash sites in time, and the survivors eventually came into the hands of the ''Gestapo'', who tortured them during interrogation (not sparing the badly injured) and later had them executed under Adolf Hitler's Commando Order.<ref name=Gall/><ref name=Berglyd/>\nThe most important consequence of the unsuccessful raid was that the Germans were now alerted to a determined Allied interest in their heavy water production.<ref name=Gall/>\nThe Norwegian Grouse team thereafter had a long arduous wait in their mountain hideaway, subsisting on moss and lichen during the winter until, just before Christmas, a reindeer was encountered.<ref name=Gall/>", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Operations to limit German access to heavy water", "sub_heading": "Operations ''Grouse'' and ''Freshman''", "_id": "5--1--1---1", "title": "Operation ''Freshman'': The Norwegian Grouse"}
{"qas": [{"question": "How did soldiers in WW2 deal with supplies required by commandos?", "answer": ""}, {"question": "How many german soldiers skied 400 kilometres to sweden?", "answer": "five", "ae_score": -0.7274225855617895, "qg_score": null}, {"question": "How many german soldiers skied 400 kilometres to sweden?", "answer": "five", "ae_score": -0.7274225855617895, "qg_score": null}], "content": "British authorities were aware the Grouse team was still operational, and decided to mount another operation in concert with them. By this time the original Grouse team was being referred to as '''Swallow'''. On the night of 16 February 1943, in Operation ''Gunnerside'' (named after the village where SOE head Sir Charles Hambro and his family used to shoot grouse), an additional six Norwegian commandos were dropped by parachute by a Halifax bomber of 138 Squadron from RAF Tempsford. They were successful in landing, and encountered the Swallow team after a few days of searching on cross country skis. The combined team made final preparations for their assault, which was to take place on the night of 27/28 February 1943.\nSupplies required by the commandos were dropped with them in special CLE containers. (One of these was buried in the snow by a Norwegian patriot to hide it from the Germans; he later recovered it and in August 1976 handed it over to an officer of the (British) Army Air Corps, who were exercising in the area. The container was brought back to England and was displayed in the Airborne Museum at Aldershot. The Museum closed in 2008 and is now part of the Imperial War Museum Duxford).\nFollowing the failed Freshman attempt, the Germans put mines, floodlights, and additional guards around the plant. While the mines and lights remained in place, security of the actual plant had slackened somewhat over the winter months. However, the single 75 m bridge spanning the deep ravine, 200 m above the River M\u00e5ne, was fully guarded.<ref name=Gall/>\nThe force elected to descend into the ravine, ford the icy river and climb the steep hill on the far side. The winter river level was very low, and on the far side, where the ground levelled, they followed a single railway track straight into the plant area without encountering any guards. Even before Grouse landed in Norway, SOE had a Norwegian agent within the plant who supplied detailed plans and schedule information. The demolition party used this information to enter the main basement by a cable tunnel and through a window. Inside the plant the only person they came across was the Norwegian caretaker (Johansen), who was very willing to cooperate with them.<ref name=Gall/>\nThe saboteurs then placed explosive charges on the heavy water electrolysis chambers, and attached a fuse allowing sufficient time for their escape. A Thompson submachine gun was purposely left behind to indicate that this was the work of British forces and not of the local resistance, in order to try to avoid reprisals. A bizarre episode ensued when fuses were about to be lit: the caretaker was worried about his spectacles which were lying somewhere in the room (during the war new glasses were nearly impossible to acquire). A frantic search for the caretaker's spectacles ensued, they were found \u2014 and the fuses lit. The explosive charges detonated, destroying the electrolysis chambers.<ref name=Gall/>\nThe raid was considered successful. The entire inventory of heavy water produced during the German occupation, over 500 kg, was destroyed along with equipment critical to operation of the electrolysis chambers. Although 3,000 German soldiers were dispatched to search the area for the commandos, all of them escaped; five of them skied 400 kilometres to Sweden, two proceeded to Oslo where they assisted Milorg, and four remained in the region for further work with the resistance.<ref name=Riste/>", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Operations to limit German access to heavy water", "sub_heading": "Operation ''Gunnerside''", "_id": "5--1--2---1", "title": "'''Gunnerside''' \u2014 The Grouse Project"}
{"qas": [{"question": "Why did the Vemork plant collapse after the German commando raid?", "answer": ""}, {"question": "How many b-17 heavy bombers attacked the vemork hydroelectric power plant in?", "answer": "143", "ae_score": -0.7756098296100586, "qg_score": null}, {"question": "How many b-17 heavy bombers attacked the vemork hydroelectric power plant in?", "answer": "143", "ae_score": -0.7756098296100586, "qg_score": null}], "content": "Although this attack did no irreparable damage to the plant, it did stop production for several months. The Vemork plant was restored by April and SOE concluded that a repeat commando raid would be extremely difficult, as German security had been considerably improved.\nAlmost as soon as production restarted, the USAAF started a series of raids on Vemork. In November, the plant was attacked by a massed daylight bombing raid of 143 B-17 heavy bombers dropping 711 bombs, of which at least 600 missed the plant. The damage, however, was quite extensive.<br>Then, on November 16 and 18, 35 B-24 heavy bombers from the 392nd Bomber Group of out of Wendling, Station 118, attacked the hydro-electric power station at Rjukan with excellent coverage of the target. These missions were the longest for this bomber group, lasting 9 1/2 and 10 1/2 hours respectively. <br>The need for ground assaults was reduced from a year earlier as there was now an available alternative of night bombing, which had previously been unrealistic owing to German air cover. The Germans were convinced that air raids would result in further serious \"hits\", and they decided to abandon the plant and move remaining stocks and critical components to Germany in 1944.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Operations to limit German access to heavy water", "sub_heading": "Resumed operation and Allied air raids", "_id": "5--1--3---1", "title": "Norwegian heavy water sabotage | Operations to limit German access to heavy water | Resumed operation and Allied air raids"}
{"qas": [{"question": "Why didn't the Germans just send troops to the bottom of the Mariana trench?", "answer": ""}, {"question": "Who was the norwegian commando who planted the bomb in the ferry?", "answer": "Knut Haukelid", "ae_score": -0.27405488883499435, "qg_score": null}, {"question": "Who was the norwegian commando who planted the bomb in the ferry?", "answer": "Knut Haukelid", "ae_score": -0.27405488883499435, "qg_score": null}], "content": "Knut Haukelid, who was the only trained commando in the immediate area, was informed of the German plan to remove the heavy water and advised he would have to muster support and destroy the shipment. He recruited two people. They decided to sabotage a ferry that would be carrying the heavy water across Lake Tinn. One of the people he recruited recognised a ferry crew member and talked to him, taking this advantage to slip into the bottom of the ship and plant the bomb, after which he slipped away. Eight and a half kilograms of plastic explosive with two alarm-clock fuses were fixed to the keel of the ferry, SF ''Hydro'', which was to carry the railway cars with the heavy water drums across Lake Tinn. On 20 February 1944, shortly after setting off around midnight, the ferry and its cargo sank in deep water, finally capping the original mission's objective and halting Germany's atomic bomb development programme. A number of Norwegian civilians were killed as the ferry sank. Witnesses reported seeing steel drums floating after the sinking, leading to speculation that they did not really contain heavy water, but an examination of records after the war showed that some barrels were only half full, and therefore would have floated. A few of these may have been salvaged and transported to Germany.<ref name=Rhodes/>\nIn 2005, an expedition retrieved a barrel (numbered \"26\") from the bottom of the lake. Its contents of heavy water matched the concentration noted in the German records, and confirmed that the shipment was not a decoy. However, it also supported the notion that the concentration of heavy water in a number of the barrels was too small to be of value to a weapons program. This might explain the absence of heavy security measures around the shipment, including why the ferry itself was not searched for delayed charges. In the film ''Heroes of Telemark'', the locomotive and train is shown, somewhat implausibly covered with German soldiers. In the Ray Mears BBC coverage, it is stated that in fact the General in command had ordered this specific disposition of troops.\nUnknown to the saboteurs, a \"Plan B\" had been established by the SOE, who arranged a second team to attack the shipment at Her\u00f8ya should the first attempt fail. The disassembled factory was later found in southern Germany during the closing stages of the war by members of the ''Alsos'' Mission nuclear seizure force.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Operations to limit German access to heavy water", "sub_heading": "Sinking the SF Hydro", "_id": "5--1--4---1", "title": "''Heroes of Telemark'' \u2014 A History of the German"}
{"qas": [{"question": "Why didn't the Germans use the water from Norsk Hydro to make nuclear weapons?", "answer": ""}, {"question": "What was the name of the british raid on norway during world war ii?", "answer": "Freshman", "ae_score": -0.6220978401089734, "qg_score": null}, {"question": "What was the name of the british raid on norway during world war ii?", "answer": "Freshman", "ae_score": -0.6220978401089734, "qg_score": null}], "content": "Recent investigation of production records at Norsk Hydro and analysis of an intact barrel that was salvaged in 2004 revealed that although the barrels in this shipment contained water of pH 14\u2014indicative of the alkaline electrolytic refinement process, they did not contain high concentrations of DO. Despite the apparent size of shipment, the total quantity of pure heavy water was limited, with most barrels only containing between 1/2\u20131% pure heavy water, confirming the success of the Operation ''Gunnerside'' raid in destroying the higher purity heavy water. The Germans would have needed a total of about 5 t of heavy water to get a nuclear reactor running; while the manifest indicated that there was only 500 kg of heavy water being transported to Germany. Hence the ''Hydro'' was carrying too little heavy water to supply one reactor, let alone the 10 or more tons of heavy water needed to make enough plutonium for a nuclear weapon.<ref name=NOVA/>\nWith the benefit of hindsight, the consensus on the German wartime nuclear program is that it was a long way from producing a bomb, even if the Norwegian heavy water had been produced and shipped at the maximum rate. Nevertheless, the unsuccessful British raid (Freshman) and the feats of the Norwegian saboteurs (Swallow, Grouse, Gunnerside) made the top secret war against the heavy water production internationally known and the saboteurs national heroes.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Historical perspective", "sub_heading": "Historical perspective", "_id": "5--2---1---1", "title": "Norwegian heavy water sabotage | Historical perspective"}
{"qas": [{"question": "Why did the Gunnerside team die?", "answer": ""}, {"question": "How old was joachim r\u00f8nneberg when he died?", "answer": "96", "ae_score": -0.1732335188792726, "qg_score": null}, {"question": "How old was joachim r\u00f8nneberg when he died?", "answer": "96", "ae_score": -0.1732335188792726, "qg_score": null}], "content": "As of November 2015, Joachim R\u00f8nneberg, age 96, was the last surviving member of the Gunnerside team. ''The New York Times'' reported that R\u00f8nneberg was \"still mentally sharp at his advanced age and still possessed of the unflappable calm that so impressed British military commanders more than 70 years ago\".", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "SOE Norwegian agents involved", "sub_heading": "SOE Norwegian agents involved", "_id": "5--3---1---1", "title": "Joachim Rnneberg, the last surviving member of the Gunner"}
{"qas": [{"question": "What would happen if an atom bomb was detonated in the middle of the ocean?", "answer": ""}, {"question": "Who published the book 'assault in norway: sabotaging the nazi?", "answer": "Lyons Press", "ae_score": -0.2130659528328846, "qg_score": null}, {"question": "Who published the book 'assault in norway: sabotaging the nazi?", "answer": "Lyons Press", "ae_score": -0.2130659528328846, "qg_score": null}], "content": "A 1962 book by John D. Drummond, titled ''But For These Men'' (ISBN 0705700453), tells a true account of two dramatic raids\u2014one on the Norsk Hydro heavy water factory at Vemork, and another on the railway ferry \"Hydro\" to destroy Germany's heavy water production efforts.\nThe book ''The Real Heroes of Telemark: The True Story of the Secret Mission to Stop Hitler's Atomic Bomb'' by Ray Mears, published by Hodder & Stoughton 2003 (ISBN 0-340-83016-6) describes the events from the perspective of the unique survival skills of the Norwegian commandos. It accompanied a BBC television documentary series, ''The Real Heroes of Telemark'', which sticks more to the facts than the film it is named after. It also describes the survival aspects of the attack \u2014 how to survive for months in a mountain cabin.\nThe book ''Skis Against the Atom'' (ISBN 0-942323-07-6) is a first-hand account by Knut Haukelid, one of the ''Gunnerside'' raiders who stayed behind.\nJens-Anton Poulsson (''Swallow''/''Grouse'') has told the story in the book ''The Heavy Water Raid: The Race for the Atom Bomb 1942\u20131944'', Orion forlag As (2009), ISBN 978-82-458-0869-8.\nThe ill-fated Operation ''Freshman'' is covered extensively in two books: Richard Wiggan's ''Operation Freshman: The Rjukan Heavy Water Raid 1942'', William Kimber & Co Ltd (1986), ISBN 978-0-7183-0571-0, and the more recent, Jostein Berglyd's ''Operation Freshman: The Actions and the Aftermath'', Leandoer & Ekholm (2007), ISBN 978-91-975895-9-8.\nRichard Rhodes's Pulitzer Prize-winning book ''The Making of the Atomic Bomb'' includes details on the events in chapters 14-15.\nLeo Marks' 1998 book ''Between Silk and Cyanide: A Codemaker's Story 1941-1945'' covers the story in some detail.  Marks was SOE's cryptographer.  He knew the Norwegian team, trained them in cryptography so they could communicate with SOE back in England, and avidly followed their progress after they were dropped in Norway.  Published by HarperCollins. ISBN 0-684-86780-X\nThe raid is also the subject of the book, ''Assault in Norway: Sabotaging the Nazi Nuclear Program'' by Thomas Gallagher, published by Lyons Press (2002), ISBN 978-1-58574-750-4. This book is based on the author's interviews with many of the commandos.\nAn account of Operation Gunnerside is told in ''The Winter Fortress: The Epic Mission to Sabotage Hitlers Atomic Bomb'', by Neal Bascomb, published by Houghton Mifflin (2016), ISBN 978-0-544-36805-7.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Published histories", "sub_heading": "Published histories", "_id": "5--4---1---1", "title": "Operation ''Freshman'': The True Story of Operation"}
{"qas": [{"question": "Why do so many people from the holocaust seem to be from Norway?", "answer": ""}, {"question": "Who wrote the book 'a man called intrepid'?", "answer": "William Henry Stevenson", "ae_score": -0.21586930671775303, "qg_score": null}, {"question": "Who wrote the book 'a man called intrepid'?", "answer": "William Henry Stevenson", "ae_score": -0.21586930671775303, "qg_score": null}], "content": "A 1948 Norwegian movie based on Operations ''Freshman'' and ''Grouse'', called ''Kampen om tungtvannet'', features performances by at least four of the original participants in the raid.\nA 1965 British movie based on the Operation ''Gunnerside'' raid, titled ''The Heroes of Telemark''. It features a performance by one of the original participants in the raid \u2013 as the Nazi pursuer of the escapees.\nA 1966 book by Czech author Franti\u0161ek B\u011bhounek, titled ''Rokle u Rjukanu'' (''Gorge at Rjukan''), is a fiction inspired by the events.\nA 1979 Canadian movie and TV-series titled ''A Man Called Intrepid'', based on the book of the same name by William Henry Stevenson. It features David Niven, Michael York and Barbara Hershey.\nOn November 8, 2005, the Corporation for Public Broadcasting \u2013 WGBH Educational Foundation in Boston, MA aired a program which documented the work of a team of underwater archaeologists exploring the sunken ferry, SF ''Hydro'' in Lake Tinn.<ref name=WGBH/>\nThe games ''Blazing Angels Squadrons of WWII'', ''Battlefield 1942: Secret Weapons of WWII'', ''Medal of Honor'' and ''Enemy Front'' each include missions involving the destruction of the heavy water plant.\nOn their 2010 album ''Coat of Arms'', Swedish power metal band Sabaton has a song named \"Saboteurs\", detailing the operation.\nIn 2013, for the 70th anniversary of Operation Gunnerside, BBC News interviewed Joachim R\u00f8nneberg, the leader and last surviving member of the Gunnerside team.\nA six-episode TV mini-series titled ''The Heavy Water War'' (''The Saboteurs'' in the UK) tells the story with a particular emphasis on the role of Leif Tronstad. This Norwegian-Danish-British co-production is in 6 episodes, the first of which was initially broadcast on 4 January 2015.", "page_name": "Norwegian heavy water sabotage", "page_id": "Norwegian%20heavy%20water%20sabotage", "heading": "Fiction, film, and video coverage", "sub_heading": "Fiction, film, and video coverage", "_id": "5--5---1---1", "title": "The History of Operation ''Gunnerside'' \u2014 Episodes 1"}
{"qas": [{"question": "How does cell signaling work?", "answer": ""}, {"question": "What is it called when cells communicate with each other?", "answer": "Cell signaling", "ae_score": -0.9570732645784203, "qg_score": null}, {"question": "What is it called when cells communicate with each other?", "answer": "Cell signaling", "ae_score": -0.9570732645784203, "qg_score": null}], "content": "Cell signaling has been most extensively studied in the context of human diseases and signaling between cells of a single organism. However, cell signaling may also occur between the cells of two different organisms. In many mammals, early embryo cells exchange signals with cells of the uterus. In the human gastrointestinal tract, bacteria exchange signals with each other and with human epithelial and immune system cells. For the yeast ''Saccharomyces cerevisiae'' during mating, some cells send a peptide signal (mating factor pheromones) into their environment. The mating factor peptide may bind to a cell surface receptor on other yeast cells and induce them to prepare for mating.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Signaling between cells of one organism and multiple organisms", "sub_heading": "Signaling between cells of one organism and multiple organisms", "_id": "6--0---1---1", "title": "Cell Signaling in the Human Body"}
{"qas": [{"question": "What is the difference between cellular and biochemical signals?", "answer": ""}, {"question": "What type of signals are produced by endocrine cells?", "answer": "hormones", "ae_score": -0.5014205390453871, "qg_score": null}, {"question": "What type of signals are produced by endocrine cells?", "answer": "hormones", "ae_score": -0.5014205390453871, "qg_score": null}], "content": "Cell signaling can be classified to be mechanical and biochemical based on the type of the signal.Mechanical signals are the forces exerted on the cell and the forces produced by the cell. These forces can both be sensed and responded by the cells.Biochemical signals are the biochemical molecules such as proteins, lipids, ions and gases. These signals can be categorized based on the distance between signaling and responder cells. Signaling within, between, and among cells is subdivided into the following classifications:\nCells communicate with each other via direct contact (juxtacrine signaling), over short distances (paracrine signaling), or over large distances and/or scales (endocrine signaling).\nSome cell\u2013cell communication requires direct cell\u2013cell contact. Some cells can form gap junctions that connect their cytoplasm to the cytoplasm of adjacent cells. In cardiac muscle, gap junctions between adjacent cells allows for action potential propagation from the cardiac pacemaker region of the heart to spread and coordinately cause contraction of the heart.\nThe notch signaling mechanism is an example of juxtacrine signaling (also known as contact-dependent signaling) in which two adjacent cells must make physical contact in order to communicate. This requirement for direct contact allows for very precise control of cell differentiation during embryonic development. In the worm ''Caenorhabditis elegans'', two cells of the developing gonad each have an equal chance of terminally differentiating or becoming a uterine precursor cell that continues to divide. The choice of which cell continues to divide is controlled by competition of cell surface signals. One cell will happen to produce more of a cell surface protein that activates the Notch receptor on the adjacent cell. This activates a feedback loop or system that reduces Notch expression in the cell that will differentiate and that increases Notch on the surface of the cell that continues as a stem cell.\nMany cell signals are carried by molecules that are released by one cell and move to make contact with another cell. ''Endocrine'' signals are called hormones. Hormones are produced by endocrine cells and they travel through the blood to reach all parts of the body. Specificity of signaling can be controlled if only some cells can respond to a particular hormone. ''Paracrine'' signals such as retinoic acid target only cells in the vicinity of the emitting cell. Neurotransmitters represent another example of a paracrine signal. Some signaling molecules can function as both a hormone and a neurotransmitter. For example, epinephrine and norepinephrine can function as hormones when released from the adrenal gland and are transported to the heart by way of the blood stream. Norepinephrine can also be produced by neurons to function as a neurotransmitter within the brain. Estrogen can be released by the ovary and function as a hormone or act locally via paracrine or autocrine signaling. Active species of oxygen and nitric oxide can also act as cellular messengers. This process is dubbed redox signaling.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Classification", "sub_heading": "Classification", "_id": "6--1---1---1", "title": "Cell Signaling in the Human Body"}
{"qas": [{"question": "What is the difference between a molecule and a mode of signaling?", "answer": ""}, {"question": "Which gas is produced in small amounts by some cells of the human body?", "answer": "Hydrogen sulfide", "ae_score": -0.7981928897517805, "qg_score": null}, {"question": "Which gas is produced in small amounts by some cells of the human body?", "answer": "Hydrogen sulfide", "ae_score": -0.7981928897517805, "qg_score": null}], "content": "In a multicellular organism, signaling between cells occurs either through release into the extracellular space, divided in paracrine signaling (over short distances) and endocrine signaling (over long distances), or by direct contact, known as juxtacrine signaling. Autocrine signaling is a special case of paracrine signaling where the secreting cell has the ability to respond to the secreted signaling molecule. Synaptic signaling is a special case of paracrine signaling (for chemical synapses) or juxtacrine signaling (for electrical synapses) between neurons and target cells. Signaling molecules interact with a target cell as a ligand to cell surface receptors, and/or by entering into the cell through its membrane or endocytosis for intracrine signaling. This generally results in the activation of second messengers, leading to various physiological effects.\nA particular molecule is generally used in diverse modes of signaling, and therefore a classification by mode of signaling is not possible. At least three important classes of signaling molecules are widely recognized, although non-exhaustive and with imprecise boundaries, as such membership is non-exclusive and depends on the context:\nSignaling molecules can belong to several chemical classes: lipids, phospholipids, amino acids, monoamines, proteins, glycoproteins, or gases. Signaling molecules binding surface receptors are generally large and hydrophilic (e.g. TRH, Vasopressin, Acetylcholine), while those entering the cell are generally small and hydrophobic (e.g. glucocorticoids, thyroid hormones, cholecalciferol, retinoic acid), but important exceptions to both are numerous, and a same molecule can act both via surface receptor or in an intracrine manner to different effects.<ref name=bruce/> In intracrine signaling, once inside the cell, a signaling molecule can bind to intracellular receptors, other elements, or stimulate enzyme activity (e.g. gasses). The intracrine action of peptide hormones remains a subject of debate.\nHydrogen sulfide is produced in small amounts by some cells of the human body and has a number of biological signaling functions. Only two other such gases are currently known to act as signaling molecules in the human body: nitric oxide and carbon monoxide.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Cell signaling in multicellular organisms", "sub_heading": "Cell signaling in multicellular organisms", "_id": "6--2---1---1", "title": "Signaling Molecules and their Functions"}
{"qas": [{"question": "How do our bodies know what to do when we are sick?", "answer": ""}, {"question": "What type of hormone is produced in the ovaries?", "answer": "estrogen", "ae_score": -0.5518585393906089, "qg_score": null}, {"question": "What type of hormone is produced in the ovaries?", "answer": "estrogen", "ae_score": -0.5518585393906089, "qg_score": null}], "content": "Cells receive information from their neighbors through a class of proteins known as receptors. Notch is a cell surface protein that functions as a receptor. Animals have a small set of genes that code for signaling proteins that interact specifically with Notch receptors and stimulate a response in cells that express Notch on their surface. Molecules that activate (or, in some cases, inhibit) receptors can be classified as hormones, neurotransmitters, cytokines, and growth factors, in general called receptor ligands. Ligand receptor interactions such as that of the Notch receptor interaction, are known to be main interactions responsible for cell signaling mechanisms and communication.\nAs shown in Figure 2 (above; left), notch acts as a receptor for ligands that are expressed on adjacent cells. While some receptors are cell surface proteins, others are found inside cells. For example, estrogen is a hydrophobic molecule that can pass through the lipid bilayer of the membranes. As part of the endocrine system, intracellular estrogen receptors from a variety of cell types can be activated by estrogen produced in the ovaries.\nA number of transmembrane receptors for small molecules and peptide hormones as well as intracellular receptors for steroid hormones exist, giving cells the ability to respond to a great number of hormonal and pharmacological stimuli. In diseases, often, proteins that interact with receptors are aberrantly activated, resulting in constitutively activated downstream signals.\nFor several types of intercellular signaling molecules that are unable to permeate the hydrophobic cell membrane due to their hydrophilic nature, the target receptor is expressed on the membrane. When such signaling molecule activates its receptor, the signal is carried into the cell usually by means of a second messenger such as cAMP.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Receptors for cell motility and differentiation", "sub_heading": "Receptors for cell motility and differentiation", "_id": "6--3---1---1", "title": "Notch Receptor Interactions in Cells"}
{"qas": [{"question": "How does the body know what genes to send to a specific animal?", "answer": ""}, {"question": "Which neurotransmitter acts as a receptor in the cell?", "answer": "GABA", "ae_score": null, "qg_score": null}, {"question": "Which neurotransmitter acts as a receptor in the cell?", "answer": "GABA", "ae_score": null, "qg_score": null}], "content": "In some cases, receptor activation caused by ligand binding to a receptor is directly coupled to the cell's response to the ligand. For example, the neurotransmitter GABA can activate a cell surface receptor that is part of an ion channel. GABA binding to a GABA receptor on a neuron opens a chloride-selective ion channel that is part of the receptor. GABA receptor activation allows negatively charged chloride ions to move into the neuron, which inhibits the ability of the neuron to produce action potentials. However, for many cell surface receptors, ligand-receptor interactions are not directly linked to the cell's response. The activated receptor must first interact with other proteins inside the cell before the ultimate physiological effect of the ligand on the cell's behavior is produced. Often, the behavior of a chain of several interacting cell proteins is altered following receptor activation. The entire set of cell changes induced by receptor activation is called a signal transduction mechanism or pathway.\nIn the case of Notch-mediated signaling, the signal transduction mechanism can be relatively simple. As shown in Figure 2, activation of Notch can cause the Notch protein to be altered by a protease. Part of the Notch protein is released from the cell surface membrane and takes part in gene regulation. Cell signaling research involves studying the spatial and temporal dynamics of both receptors and the components of signaling pathways that are activated by receptors in various cell types.\nA more complex signal transduction pathway is shown in Figure 3. This pathway involves changes of protein\u2013protein interactions inside the cell, induced by an external signal. Many growth factors bind to receptors at the cell surface and stimulate cells to progress through the cell cycle and divide. Several of these receptors are kinases that start to phosphorylate themselves and other proteins when binding to a ligand. This phosphorylation can generate a binding site for a different protein and thus induce protein\u2013protein interaction. In Figure 3, the ligand (called epidermal growth factor (EGF)) binds to the receptor (called EGFR). This activates the receptor to phosphorylate itself. The phosphorylated receptor binds to an adaptor protein (GRB2), which couples the signal to further downstream signaling processes. For example, one of the signal transduction pathways that are activated is called the mitogen-activated protein kinase (MAPK) pathway. The signal transduction component labeled as \"MAPK\" in the pathway was originally called \"ERK,\" so the pathway is called the MAPK/ERK pathway. The MAPK protein is an enzyme, a protein kinase that can attach phosphate to target proteins such as the transcription factor MYC and, thus, alter gene transcription and, ultimately, cell cycle progression. Many cellular proteins are activated downstream of the growth factor receptors (such as EGFR) that initiate this signal transduction pathway.\nSome signaling transduction pathways respond differently, depending on the amount of signaling received by the cell. For instance, the hedgehog protein activates different genes, depending on the amount of hedgehog protein present.\nComplex multi-component signal transduction pathways provide opportunities for feedback, signal amplification, and interactions inside one cell between multiple signals and signaling pathways.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Signaling pathways", "sub_heading": "Signaling pathways", "_id": "6--4---1---1", "title": "Signaling in the Cell"}
{"qas": [{"question": "How do bacteria communicate with each other?", "answer": ""}, {"question": "What type of signaling molecules are involved in quorum sensing?", "answer": "autoinducers", "ae_score": -0.5225779687409037, "qg_score": null}, {"question": "What type of signaling molecules are involved in quorum sensing?", "answer": "autoinducers", "ae_score": -0.5225779687409037, "qg_score": null}], "content": "Molecular signaling can occur between different organisms, whether unicellular or multicellular, the emitting organism produces the signaling molecule, secrete it into the environment, where it diffuses, and it is sensed or internalized by the receiving organism. In some cases of interspecies signaling, the emitting organism can actually be a host of the receiving organism, or vice versa.\nIntraspecies signaling occurs especially in bacteria, yeast, social insects, but also many vertebrates. The signaling molecules used by multicellular organisms are often called pheromones, they can have such purposes as alerting against danger, indicating food supply, or assisting in reproduction. In unicellular organisms such as bacteria, signaling can be used to 'activate' peers from a dormant state, enhance virulence, defend against bacteriophages, etc. In quorum sensing, which is also found in social insects, the multiplicity of individual signals has the potentiality to create a positive feedback loop, generating coordinated response, in this context the signaling molecules are called autoinducers. This signaling mechanism may have been involved in evolution from unicellular to multicellular organisms.<ref name=miller/> Bacteria also use contact-dependent signaling, notably to limit their growth.\nMolecular signaling can also occur between individuals of different species, this has been particularly studied in bacteria. Different bacterial species can coordinate to colonize a host and participate in common quorum sensing. Therapeutic strategies to disrupt this phenomenon are being investigated. Interactions mediated through signaling molecules are also thought to occur between the gut flora and their host, as part of their commensal or symbiotic relationship.<ref name=Sperandio/> Gram negative microbes deploy bacterial outer membrane vesicles for intra- and inter-species signaling in natural environments and at the host-pathogen interface.\nAdditionally, interspecies signaling occurs between multicellular organisms. In ''Vespa mandarinia'', individuals release a scent that directs the colony to a food source.", "page_name": "Cell signaling", "page_id": "Cell%20signaling", "heading": "Intraspecies and interspecies signaling", "sub_heading": "Intraspecies and interspecies signaling", "_id": "6--5---1---1", "title": "Interspecies Signaling in Bacteria"}
{"qas": [{"question": "How do we know that the Sphinx is made of water?", "answer": ""}, {"question": "Who said the sphinx is 5,000 years old?", "answer": "David Coxill", "ae_score": -0.16696505684439805, "qg_score": null}, {"question": "Who said the sphinx is 5,000 years old?", "answer": "David Coxill", "ae_score": -0.16696505684439805, "qg_score": null}], "content": "R. A. Schwaller de Lubicz, a French mystic and alternative Egyptologist, first claimed evidence of water erosion on the walls of the Sphinx enclosure in the 1950s. John Anthony West, an author and alternative Egyptologist, investigated Schwaller de Lubicz's ideas further and, in 1989, sought the opinion of Robert M. Schoch, a geologist and associate professor of natural science at the College of General Studies at Boston University.\nFrom his investigation of the enclosure's geology, Schoch concluded the main type of weathering evident on the Sphinx enclosure walls was caused by prolonged and extensive rainfall. According to Schoch, the area has experienced a mean annual rainfall of approximately one inch (2.5 cm) since the Old Kingdom (''c''. 2686 \u2013 2134 BC), such that, since Egypt's last period of significant rainfall ended between the late fourth and early 3rd millennium BC, the Sphinx's construction must date to the 6th or 5th millennium BC.\nSchoch further notes the same heavy precipitation-induced weathering as seen on the walls of the Sphinx enclosure is also found on the core blocks of the Sphinx and Valley Temples, both known to have been originally constructed from blocks taken from the Sphinx enclosure when the body was carved. Though the presence of extensive 4th Dynasty repair work to the Sphinx and associated temples is acknowledged by such Egyptologists as Lehner and Hawass, Schoch contends: \"Therefore if the granite facing is covering deeply weathered limestone, the original limestone structures must predate by a considerable degree the granite facing. Obviously, if the limestone cores (originating from the Sphinx ditch) of the temples predate the granite ashlars (granite facings), and the granite ashlars are attributable to Khafre of the Fourth Dynasty, then the Great Sphinx was built prior to the reign of Khafre.\"\nColin Reader, a British geologist, agrees that the suggested evidence of weathering indicates prolonged water erosion. Reader found, ''inter alia'', that the flow of rainwater causing the weathering had been stemmed by the construction of 'Khufu's quarries', which lie directly \"upstream\" of the Sphinx enclosure, and therefore concludes that the Sphinx must predate the reign of Khufu (2589 \u2013 2566 BC), and certainly Khafra, by several hundred years. Reader disagrees with Schoch's palaeometeorological estimates, and instead concludes that the Sphinx dates to the Early Dynastic Period (c. 3150 \u2013 2686 BC). To explain the disproportionate size of the head compared to the body, Reader, as does Schoch, also suggests the head of the Sphinx was originally that of a lion and recarved sometime later in the likeness of a pharaoh.\nSimilarly, David Coxill, a geologist working independently of both Schoch and Reader, has concluded from the evidence of weathering in the enclosure that \"[t]he Sphinx is at least 5,000 years old and pre-dates dynastic times [before 3100 BC].\"", "page_name": "Sphinx water erosion hypothesis", "page_id": "Sphinx%20water%20erosion%20hypothesis", "heading": "Hypothesis", "sub_heading": "Hypothesis", "_id": "7--0---1---1", "title": "The Sphinx Enclosure"}
{"qas": [{"question": "Why is the Sphinx believed to have been built by Khafra?", "answer": ""}, {"question": "Who is the scientist that says the sphinx is weathering?", "answer": "Peter Lacovara", "ae_score": -0.3269237476921783, "qg_score": null}, {"question": "Who is the scientist that says the sphinx is weathering?", "answer": "Peter Lacovara", "ae_score": -0.3269237476921783, "qg_score": null}], "content": "Zahi Hawass, former Egyptian minister of state for antiquities affairs and secretary-general of the Supreme Council of Antiquities, was asked in an interview on the PBS series NOVA if it was possible that a more ancient civilization might have sculpted the Sphinx. Hawass replied: \"Of course it is not possible for one reason  \u2026.  No single artifact, no single inscription, or pottery, or anything has been found until now, in any place to predate the Egyptian civilization more than 5,000 years ago.\" This reasoning and conclusion was supported in a similar NOVA interview by Mark Lehner, another senior Egyptologist. Other archaeologists who have made similar criticisms include Kenneth Feder.\nA different argument used by Egyptologists to ascribe the Sphinx to Khafra is the \"context\" theory, which notes that the Sphinx is located in the context of the funerary complex surrounding the Second Pyramid, which is traditionally connected with Khafra. Apart from the Causeway, the Pyramid and the Sphinx, the complex also includes the Sphinx Temple and the Valley Temple, both of which display the same architectural style, with 100-tonne stone blocks quarried out of the Sphinx enclosure. A diorite statue of Khafre, which was discovered buried upside down along with other debris in the Valley Temple, is claimed as support for the Khafra theory. Reader agrees that the Sphinx Temple and Valley Temple are closely associated with the Sphinx, as is the Causeway and even part of the Khafra Mortuary Temple, but suggests this evidence merely indicates these structures also predate Khafra and does not link the Sphinx in any way to Khafra. Rainer Stadelmann, former director of the German Archaeological Institute in Cairo suggests Khufu, Khafre's father, was the builder of the Sphinx  and contends Khafra's Causeway was built to conform to a pre-existing structure which he concludes, given its location, could only have been the Sphinx. Lehner's official website also offers a similar argument based on an Archaeological sequence of structures built in the area. Lehner points to the way several structures in the area incorporate elements from older structures, and based on the order in which they were constructed concludes that the archaeological sequencing does not allow for a date older than the reign of Khafra.\nHawass points to the poor quality of much of the Giza limestone as the basis for the significant erosion levels. He has concluded, from the present-day rapid rate of erosion on the Member II surface of the Sphinx, that \"[t]he eleven hundred years between Khafre and the first major restoration in the Eighteenth Dynasty, or even half this time, would have been more than enough to erode the Member II into the deep recesses behind Phase I restoration masonry\". Schoch states that other structures and surfaces on the Giza Plateau are made from the same band of limestone as the Sphinx enclosure, but they do not show the same erosion as the walls of the Sphinx enclosure.\nPeter Lacovara, an Egyptologist and curator at the M. C. Carlos Museum in Emory University, assigns \"some of the erosional features\" on the enclosure walls to quarrying activities rather than weathering, and states that other wear and tear on the Sphinx itself is due to groundwater percolation and wind erosion.", "page_name": "Sphinx water erosion hypothesis", "page_id": "Sphinx%20water%20erosion%20hypothesis", "heading": "Response of Egyptologists and archaeologists", "sub_heading": "Response of Egyptologists and archaeologists", "_id": "7--1---1---1", "title": "The Sphinx and Khafra"}
{"qas": [{"question": "Why is Haloclasty rejected as an explanation for the vertical erosion features in the Giza pyramid complex?", "answer": ""}, {"question": "What caused the collapse of the sphinx?", "answer": "wind erosion", "ae_score": -0.3094035270886388, "qg_score": null}, {"question": "What caused the collapse of the sphinx?", "answer": "wind erosion", "ae_score": -0.3094035270886388, "qg_score": null}], "content": "Some geologists have proposed alternative explanations for the evidence of weathering in the Sphinx enclosure.\nOne of the alternative erosion mechanisms proposed is called haloclasty. Moisture on limestone will dissolve salts, which are then carried by percolating moisture into the spaces inside the porous limestone. When the moisture dries the salt crystallises, and the expanding crystals cause a fine layer of surface limestone to flake off. It is accepted by Schoch ''et al.'' that this mechanism is evident in many places on the Giza Plateau. One proponent of the haloclasty process is Dr James A. Harrell of the University of Toledo, who advocates that the deep erosion crevices were caused by the haloclasty process being driven by moisture in the sand that covered the carved rock for much of the time since it was exposed by quarrying. Lal Gauri ''et al.'' also favour the haloclasty process to explain the erosion features, but have theorised that the weathering was driven by moisture deriving from atmospheric precipitation such as dew.\nAnalysis of the Sphinx's bedrock by the Getty Conservation Institute (1990-1992) concluded that \"Continual salt crystallization, which has a destructive effect on the stone, would explain at least some of the deterioration of the Sphinx.\"\nHaloclasty is rejected as an explanation for the vertical erosion features by Schoch ''et al.'' because it doesn\u2019t explain all the visible evidence, namely that the water erosion features are not evenly distributed, being concentrated in those areas that would have been particularly exposed to running water, whereas the haloclasty process should have operated evenly on all exposed limestone surfaces. Similarly, Schoch points out that the alternative explanations do not account for the absence of similar weathering patterns on other rock surfaces in the Giza pyramid complex which were cut from the same limestone beds.\nReader, who agrees that the Sphinx predates Khafra but prefers a construction date within the Early Dynastic Period, points to the tombs dug into the enclosure walls during Dynasty XXVI (''c''. 600 BC), and notes that the entrances of the tombs have weathered so lightly that original chisel marks are still clearly visible. He points out that if the weathering on the enclosure walls (up to a metre deep in places) had been created by any of the proposed alternative causes of erosion, the tomb entrances would have been weathered much more severely.<ref name=Reader/>\nIt is also agreed that wind erosion has played a significant role in eroding the Sphinx. Schoch states that wind erosion forms distinctive horizontal bands, whereas the water erosion features are clearly vertical.", "page_name": "Sphinx water erosion hypothesis", "page_id": "Sphinx%20water%20erosion%20hypothesis", "heading": "Response of other geologists", "sub_heading": "Response of other geologists", "_id": "7--2---1---1", "title": "Eroding the Sphinx"}
{"qas": [{"question": "How do tombs in Egypt not get ruined by rain?", "answer": ""}, {"question": "Who discovered the sphinx in the nile valley?", "answer": "Judith Bunbury", "ae_score": -0.8874236864447409, "qg_score": null}, {"question": "Who discovered the sphinx in the nile valley?", "answer": "Judith Bunbury", "ae_score": -0.8874236864447409, "qg_score": null}], "content": "Recent studies by German climatologists Rudolph Kuper and Stefan Kr\u00f6pelin, of the University of Cologne suggest the change from a wet to a much drier climate may have come to an end around 3500 - 1500 BC, which is as much as 500 years later than currently thought. Egyptologist Mark Lehner believes this climate change may have been responsible for the severe weathering found on the Sphinx and other sites of the 4th Dynasty. After studying sediment samples in the Nile Valley, Judith Bunbury, a geologist at the University of Cambridge, concluded that climate change in the Giza region may have begun early in the Old Kingdom, with desert sands arriving in force late in the era.\nSchoch points out that mudbrick mastabas on the Saqqara plateau about 20 km away, indisputably dated to Dynasties I and II, have survived relatively undamaged, which he believes indicates that no heavy rainfall has occurred in the region since the Early Dynastic Period, and nor was any heavy rain anticipated by those Early Dynastic Period communities who built those structures.\nReader replied to this, stating that they \"were built on an area of high ground and do not lie within any natural catchment. These tombs will not, therefore, have been exposed to any significant run-off.\" He concludes that \"the fact that they are not significantly degraded, as Schoch has pointed out, demonstrates that rainfall itself has not been a significant agent of degradation in Egypt.\"  Rainfall water run-off, however, has been a more significant factor. Schoch cites evidence of flood water damage in another location to illustrate this.", "page_name": "Sphinx water erosion hypothesis", "page_id": "Sphinx%20water%20erosion%20hypothesis", "heading": "Response of climatologists", "sub_heading": "Response of climatologists", "_id": "7--3---1---1", "title": "Climate Change in Egypt \u2014 A Brief History"}
{"qas": [{"question": "Why is it called a third world country?", "answer": ""}, {"question": "Who argued that over urbanization was a threat to social order?", "answer": "John Dyckman", "ae_score": -0.503191777062674, "qg_score": null}, {"question": "Who argued that over urbanization was a threat to social order?", "answer": "John Dyckman", "ae_score": -0.503191777062674, "qg_score": null}], "content": "The concept of overurbanization first emerged in the mid-20th century to describe cities whose rate of industrialization was growing more slowly than their rate of urbanization.<ref name=Amin/>  According to sociologist Josef Gugler, the concept was \"widely accepted in the 1950s and into the 1960s\" and was split into two approaches, a diachronic and a synchronic approach.  The synchronic approach, the main one taken in the 1950s, was proposed by sociologists Kingsley Davis and Hilda Golden who defined whether a country was overurbanized based on  how its relationship between industrialization and urbanization compared to that of other countries during the same time period.<ref name=Davis/><ref name=Gugler/> Specifically, countries considered part of the Third World were compared to countries deemed part of the First World.<ref name=Gugler/> Davis and Golden used data on \"the percentage of economically active males not engaged in agriculture and the percentage of the population in cities of 100,000 or above in a large number of the countries in the world,\" in order to define the normal relationship between industrialization and urbanization.<ref name=Davis/><ref name=Sovani/> They then determine that countries whose rate of urbanization is significantly higher than normal in relation to their rate of industrialization are \"overurbanized.\"<ref name=Davis/><ref name=Sovani/> The authors calculate an \"expected\" level of urbanization based on the rates of urbanization of other countries of the world at similar levels of industrialization (measured by percentage of males not engaged in agriculture).<ref name=Davis/> A few countries in particular that Davis and Golden measured as having higher levels of urbanization than expected were Egypt, Greece, and South Korea.<ref name=Davis/><ref name=UNESCO/> Davis and Golden did not see overurbanization as a necessarily negative phenomenon, but rather a statistical reality that could have its challenges but would ultimately be self-correcting as an appropriate balance was found between levels of urbanization and industrialization.<ref name=Davis/> Scholars on overurbanization agree that N.V. Sovani was one of the first to discount Davis and Golden's argument, as he found that the connection between urbanization and industrialization was more significant in underdeveloped countries than developed ones, suggesting that Davis and Golden's measure of a \"normal\" relationship between urbanization and industrialization was not valid.<ref name=Kamerschen/><ref name=Sovani/>\nThe definition offered by the United Nations and UNESCO in 1956 took a different approach to measuring overurbanization: the diachronic approach.  A 1956 UNESCO report measured overurbanization historically, emphasizing that \"at comparable levels of urbanization developed countries of today had a correspondingly greater proportion of their labour force engaged in non-agricultural occupations\" than underdeveloped countries.<ref name=Kamerschen/><ref name=UNESCO/> Authors on overurbanization give the examples of France, the United States, Germany, and Canada as developed and often mention the continents of Asia and Africa as well as the region of Latin America as underdeveloped.<ref name=Davis/><ref name=Kamerschen/><ref name=UNESCO/> This historical approach was applied to Asia in the report, which argued that because a smaller percentage of the labor force was engaged in non-agricultural activities than certain Western developed countries had at similar levels of urbanization, Asia was overurbanized.<ref name=Gugler/><ref name=UNESCO/><ref name=Sovani/> However, this method has been criticized by scholars who argue that it supports an ethnocentric idea that all countries follow the same path of development. Furthermore, economist N.V. Sovani argued that the evidence offered is not consistent with the development trajectories of developed countries, pointing out specific examples of developed countries such as Switzerland where high levels of industrialization did not correspond with high levels of urbanization.<ref name=Kamerschen/><ref name=Sovani/> Sociologists John D. Kasarda and Edward Crenshaw pointed out that it was not so much the rate of urbanization of developing countries that was greater, but the absolute numbers of people migrating.\nScholars reference N.V. Sovani as a researcher who questioned whether to accept the 1950s definition of overurbanization. His debunking of the formerly accepted definitions of overurbanization encouraged further scholarly analysis and attempts to redefine the term.<ref name=Kamerschen/> Sovani suggested that claims of overurbanization in underdeveloped countries stemmed from the perception that rapid urbanization had negative consequences.<ref name=Sovani/> However, he claimed that there still lacked evidence for the idea that rapid urbanization actually made areas worse off.<ref name=Sovani/> Economist David R. Kamerschen found that there was little statistical evidence to support that \"rapid urbanization in underdeveloped countries hampers economic growth,\" suggesting that the phenomenon of overurbanization is questionable.<ref name=Kamerschen/>\nFollowing Sovani's work, several scholars offered alternative definitions, many of which included not just the relationship between population growth and their means of employment but also the ability of the urban area to provide public services, reflecting that economic development lagged behind population growth in a multitude of ways.<ref name=Gugler/><ref name=graves/> Several scholars also increasingly embraced a negative connotation for the term.<ref name=Gugler/><ref name=Laumas/><ref name=graves/><ref name=Dyckman/> Urban planner John Dyckman suggested that inability to accommodate the expectations of migrants to the city made overurbanization a threat to social order.<ref name=Dyckman/> Economists Philip Graves and Robert Sexton  argue that the definition of overurbanization must \"involve the presence of negative net external effects for the city size in question,\" suggesting that as long as \"positive external social benefits\" from rapid urbanization dominate negative externalities, overurbanization is not at play.<ref name=graves/> Gugler defined overurbanization by two factors: that migration to cities led to a \"less than optimal allocation of labor between the rural and urban sectors\" and that migration to cities \"increases the costs of providing for a country's growing population.\"<ref name=Gugler/> Sociologist Glenn Firebaugh disagreed, arguing that if overurbanization is caused by overpopulation, that overpopulation of rural areas could be worse than overpopulation of urban areas.<ref name=Firebaugh/>\nFrom its origins, the term has been used to differentiate between countries that are considered developed and underdeveloped. Davis and Golden considered a country to be underdeveloped if over half its economically active males were employed in agriculture.<ref name=Davis/> The UNESCO report frequently used the terms \"developed\" and \"Western\" in conjunction.<ref name=UNESCO/> Gugler and others use the terms \"third world\" and \"first world\" in their discussion.<ref name=Firebaugh/><ref name=Gugler/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Definition", "sub_heading": "Definition", "_id": "8--0---1---1", "title": "Overurbanization and the Evolution of the Social Sciences"}
{"qas": [{"question": "Why are rural areas more prone to overpopulation than urban areas?", "answer": ""}, {"question": "What are some negative factors that cause people to move?", "answer": "overcrowding", "ae_score": -0.39592173287894233, "qg_score": null}, {"question": "What are some negative factors that cause people to move?", "answer": "overcrowding", "ae_score": -0.39592173287894233, "qg_score": null}], "content": "The biggest cause of overurbanization emphasized by scholars is rural-urban migration and the \"push\" factors associated with it, including \"increased population, diminished size of holdings, and absentee landlord exactions.\"<ref name=Davis/><ref name=Kamerschen/><ref name=Gugler/><ref name=Sovani/> Specifically, lower death rates as a result of demographic transition lead to less available land and fewer opportunities for rural residents.<ref name=Firebaugh/> The larger process of urbanization is characterized both by these factors that \"push\" migrants away from their homes as well as factors that \"pull\" them towards new areas. Davis and the UNESCO report both discuss that overurbanization is affected by the \"push\" factors away from rural areas being stronger than the \"pull\" factors. Pull factors towards urban areas include expansion of economic opportunity and the infrastructure of cities as administrative centers<ref name=Davis/><ref name=UNESCO/> Shandra recognizes the relationship between push and pull factors, arguing that rural conditions, specifically environmental scarcity, cause decreasing income, decreased stability, and increased health risks, leading many to respond by migrating to urban areas.<ref name=Shandra/> For example, drought in Brazil and deforestation in the Philippines has made many rural residents' former manner of livelihood impossible, forcing them to move to the nearest city.<ref name=Shandra/> Because migrants are primarily motivated by factors pushing them out of rural areas rather than factors such as demand for labor pulling them to the city, these rural-urban migrants often find themselves unemployed or quitting \"low productive agricultural employment to [enter] yet another section marked by low productivity employment, namely handicraft production, retail trading, domestic services in urban areas.\"<ref name=Sovani/> A study done by sociologist Glenn Firebaugh showed that agricultural density, a strong indicator of land constraint, and the presence plantation agriculture both have significant effects on overurbanization.<ref name=Firebaugh/> These findings were later reversed by sociologist Bruce London, who emphasized that urban migration was not the only potential response to agricultural density.<ref name=London/>\nSovani argues that there is little evidence for the greater role of \"push\" factor of increased population in rural areas, as even countries where there is little pressure for land experience this phenomenon, but that instead the opportunity for higher income is responsible for the excessive migration and pressure on cities, as the salary for an unproductive job in an urban area was almost always higher than the salary for unproductive work in a rural area.<ref name=Kamerschen/><ref name=Sovani/>  Graves and Sexton also emphasize that individuals move despite negative factors such as overcrowding, suggesting that individuals still see urban migration as an overall benefit. They argue that if the benefits do indeed outweigh the costs for society as a whole, then the term \"overurbanization\" is not appropriate to describe the phenomenon.<ref name=graves/> Gugler argues that while the benefits outweigh the costs for an individual migrating to an urban area, greater costs such as resource scarcity and widespread unemployment and poverty are present when this occurs at a larger scale.<ref name=Gugler/>\nSovani also argues that the definition of overurbanization as developed by scholars in the 1950s and 1960s suggests some sort of limits to population density \"beyond which the resulting social situation is abnormal,\" which he argues need to be defined more clearly.<ref name=Sovani/> Such unsupportable growth would suggest that the cause of overurbanization is urbanization happening too rapidly for a city's level of economic development.<ref name=Kamerschen/> Dyckman would call this the \"pre-takeoff period.\"<ref name=Dyckman/> However, several scholars have questioned the validity of the connection between urbanization and industrialization.<ref name=Kamerschen/><ref name=graves/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Causes", "sub_heading": "Causes", "_id": "8--1--0---1", "title": "Overurbanization \u2014 A Brief History"}
{"qas": [{"question": "What is the economic modernization perspective?", "answer": ""}, {"question": "Who is the sociologist who proposed the theory of overurbanization?", "answer": "Jeffrey Kentor", "ae_score": -0.4634183185012507, "qg_score": null}, {"question": "Who is the sociologist who proposed the theory of overurbanization?", "answer": "Jeffrey Kentor", "ae_score": -0.4634183185012507, "qg_score": null}], "content": "The economic modernization perspective on the causes of overurbanization is based on modernization theory, which argues that a hierarchical progression exists from pre-modern to modern society. An explanation of overurbanization from this perspective was given by sociologist Jeffrey Kentor, who wrote that under modernization theory, urbanization results from development and industrialization creating jobs and infrastructure. This argument has been criticized by those who do not ascribe to the assumption that there is a linear path of development that all countries follow.<ref name=Sovani/><ref name=Kentor/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Causes", "sub_heading": "The economic modernization perspective", "_id": "8--1--1---1", "title": "The economic modernization perspective on the causes of overurbanization is based on modernization theory"}
{"qas": [{"question": "What is the political modernization perspective?", "answer": ""}, {"question": "Who argues that environmental degradation causes overurbanization?", "answer": "Shandra", "ae_score": null, "qg_score": null}, {"question": "Who argues that environmental degradation causes overurbanization?", "answer": "Shandra", "ae_score": null, "qg_score": null}], "content": "Shandra's take on the political modernization perspective asserts that environmental degradation causes overurbanization, because the destruction of natural resources in rural areas lowers production and increases poverty and health risks.<ref name=Shandra/> Supporters of the political modernization perspective suggest that a strong civil society supports lower levels of overurbanization. The presences of international non-governmental organizations (INGOs) in rural areas, political protests, and democratic government all have the ability of limiting rural-push factors by limiting factors that lead to resource scarcity.<ref name=Shandra/> INGOs can reduce overurbanization by stimulating alternative employment outside of agriculture, supporting grassroots movements, and improving rural conditions, such as by providing clean water.<ref name=Bradshaf/>  Considering the role of political protest, Shandra offers the example of the Chipko movement in India, where local women protested deforestation. Protection of this natural resource \"eliminated the causes (i.e., income risk and health effects) that facilitate rural to urban migration by protecting a natural resource base by which rural residents in India depended for their existence.\"<ref name=Shandra/> Given these considerations, Shandra argues that repressive regimes that do not respond to the desires of the public are more likely to cause higher rates of urbanization than democratic governments.<ref name=Shandra/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Causes", "sub_heading": "The political modernization perspective", "_id": "8--1--2---1", "title": "Shandra's Political Modernization Perspective"}
{"qas": [{"question": "The neo-malthusian perspective?", "answer": ""}, {"question": "What causes ecological problems, decreasing agricultural activity, and increased rural poverty?", "answer": "population growth", "ae_score": -0.10584572447939693, "qg_score": null}, {"question": "What causes ecological problems, decreasing agricultural activity, and increased rural poverty?", "answer": "population growth", "ae_score": -0.10584572447939693, "qg_score": null}], "content": "The neo-Malthusian perspective is closely related to rural-push and urban-pull factors, but it suggests that the cause behind these factors is population growth, which leads to ecological problems, decreasing agricultural activity, and increased rural poverty. These factors then push rural residents to the city.<ref name=Shandra/><ref name=Kasarda/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Causes", "sub_heading": "The neo-Malthusian perspective", "_id": "8--1--3---1", "title": "The neo-Malthusian perspective"}
{"qas": [{"question": "What is the dependency perspective on the causes of overurbanization?", "answer": ""}, {"question": "What theory argues that economic and political systems rendered less developed countries dependent on developed countries?", "answer": "dependency theory", "ae_score": -0.5833411122802564, "qg_score": null}, {"question": "What theory argues that economic and political systems rendered less developed countries dependent on developed countries?", "answer": "dependency theory", "ae_score": -0.5833411122802564, "qg_score": null}], "content": "The dependency perspective on the causes of overurbanization is based on dependency theory, which argued that economic and political systems rendered less developed countries dependent on developed countries, which used developing countries for resources, labor, and markets.Proponents of the dependency perspective argue that rural-push and urban-pull factors are not only a result of population growth and resource scarcity, but that these factors, among others, are caused by the exploitation of developed countries and the capitalist principles they operate under.<ref name=Kasarda/><ref name=London/> This is to say that \"a comprehensive understanding of Third World urbanization cannot focus solely on intra-national, rural-push, urban-pull explanations...but must explicitly incorporate the impact of international capitalist forces.\"<ref name=London/>  This holds that the negative rural-push factors are a result of the manipulation of developed countries.<ref name=Kasarda/> Michael Kentor found that dependence on foreign investment had a lagged effect on urbanization, meaning that urbanization rates increased a few years after foreign companies began profiting in developing countries.<ref name=Kentor/> Jeffrey Timberlake and Michael Kentor found in their analysis of 69 less developed countries that there was a significant relationship between dependence, as measured by level of foreign investment, and overurbanization.<ref name=Timberlake/>  Additionally, a study done by Bruce London found that factors related to dependency were not only connected to rapid urbanization, but also the negative aspects of urbanization such as urban inequality.<ref name=London/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Causes", "sub_heading": "The dependency perspective", "_id": "8--1--4---1", "title": "The Dependency Perspective on Overurbanization"}
{"qas": [{"question": "Why is overurbanization a negative phenomenon?", "answer": ""}, {"question": "What did davis and golden believe could spur industrial growth and modernization of agriculture?", "answer": "overurbanization", "ae_score": -0.8526111097658724, "qg_score": null}, {"question": "What did davis and golden believe could spur industrial growth and modernization of agriculture?", "answer": "overurbanization", "ae_score": -0.8526111097658724, "qg_score": null}], "content": "Davis and Golden did not see overurbanization as an inherently negative phenomenon, but as a statistical fact that would likely correct itself, as \"urbanization will fall off sharply or industrialization will gain a new impetus.\"<ref name=Davis/> Expanding on the latter, they suggest that overurbanization could spur industrial growth, modernization of agriculture, and social change.<ref name=Davis/> Even in the case of overurbanization, some of the positive effects of urbanization could be present in regards to economic growth, such as the development of more efficient economics due to scale, technological developments, diversity of both products and occupations, as well as \"the greater opportunity of occupational and social mobility and greater readiness to adapt.\"<ref name=UNESCO/><ref name=graves/> For example, they argue that industrialization supports greater efficiency of agriculture through technology, an advantage for the productivity of rural farmers as well as urban consumers.<ref name=Davis/> However, Firebaugh argues that great efficiency is often a result of an increasingly  capital-intensive system, which creates inequality between large and small landowners, such as in the Latin American latifundia system.<ref name=Firebaugh/>  Furthermore, Timberlake and Kentor found in their analysis of economic growth and overurbanization that countries that experienced increases in levels of overurbanization experienced less economic growth.<ref name=Timberlake/> Economic opportunities are lacking due to \"saturated urban labor markets\" that exclude much of both the rural and urban populations truncated opportunity structures in rural areas.<ref name=Gugler/><ref name=Kasarda/> Furthermore, high infrastructural costs stymie growth.<ref name=Kasarda/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Effects", "sub_heading": "Effects", "_id": "8--2--0---1", "title": "Overurbanization | Effects"}
{"qas": [{"question": "Why did the U.S. go from being a poor country to a prosperous country?", "answer": ""}, {"question": "Why does over urbanization put a strain on urban populations?", "answer": "lack of adequate public services", "ae_score": -0.6230002739029084, "qg_score": null}, {"question": "Why does over urbanization put a strain on urban populations?", "answer": "lack of adequate public services", "ae_score": -0.6230002739029084, "qg_score": null}], "content": "The UNESCO report emphasized the negative effects of overurbanization, detailing \"low levels of living\" as \"inadequate housing,  the almost complete absence of mass sanitary facilities, the presence of filth, squalor, repugnant odours, disease and high mortality\" and \"large urban groups who have little or no access to educational facilities.\"<ref name=UNESCO/> Several scholars have agreed that overurbanization puts a strain on the wellbeing of urban residents due to the lack of adequate public services.<ref name=Gugler/><ref name=UNESCO/><ref name=Dyckman/>\nDavis and Golden also argue that greater density of dissatisfied impoverished masses could improve conditions to the extent that it provokes the government to enact change to avoid revolution.<ref name=Davis/> Dyckman agreed that overurbanization lends itself to the potential for revolution, though he saw this as a potentially destabilizing factor as the conditions would lead to social dissatisfaction and seizure of control by revolutionary leaders.<ref name=Dyckman/> He saw informal squatter settlements as breeding ground for revolutionary activity.<ref name=Dyckman/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Effects", "sub_heading": "Social", "_id": "8--2--1---1", "title": "Overurbanization | Effects | Social"}
{"qas": [{"question": "Why are rural areas more prone to unemployment and underemployment?", "answer": ""}, {"question": "What are other problems in rural areas?", "answer": "unemployment and underemployment", "ae_score": -0.6227301257874678, "qg_score": null}, {"question": "What are other problems in rural areas?", "answer": "unemployment and underemployment", "ae_score": -0.6227301257874678, "qg_score": null}], "content": "Despite arguing the potential for economic growth, the UNESCO report also states that overurbanization prevents urban areas and countries from utilizing their \"potential human and physical resources\" due to unemployment, under-employment, and misemployment.<ref name=Gugler/><ref name=UNESCO/> The idea that rural-push factors are stronger than urban-pull factors in cases of overurbanization suggests that it is population pressure in rural areas rather than the pull of urban jobs that leads to rural-urban migration.<ref name=Kamerschen/><ref name=Sovani/> Migrants often end up unemployed, as overall urbanization rates rise faster than industrialization and the expansion of the urban job base.<ref name=Kamerschen/>\nIn addition to high levels of unemployment, overurbanization is characterized by underemployment and misemployment.  Underemployment is defined as the \"underutilization of labor,\" or when available laborers are not working at their full capacity due to seasonal variation in production or excess employment of laborers for the amount of work that needs to be done.<ref name=Gugler/> Misemployment is defined as unproductive labor, meaning that efforts are considered to \"contribute little to social welfare,\" such as the full-time labor of begging.<ref name=Gugler/>\nWhile these phenomena are all caused by excessive rates of migration to cities, it is notable that unemployment and underemployment are also problems in rural areas as well. Often unemployment in rural areas is what pushes residents to the city, where better economic opportunities are expected.<ref name=Gugler/><ref name=Shandra/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Effects", "sub_heading": "Employment", "_id": "8--2--2---1", "title": "UNESCO Report on Rural-Urban Migration"}
{"qas": [{"question": "How did Gugler and Shandra help combat over-urbanization?", "answer": ""}, {"question": "Along with york bradshaw, who studied the relationship between overurbanization and?", "answer": "Mark Schafer", "ae_score": -0.7200474150055637, "qg_score": null}, {"question": "Along with york bradshaw, who studied the relationship between overurbanization and?", "answer": "Mark Schafer", "ae_score": -0.7200474150055637, "qg_score": null}], "content": "A UNESCO report that discussed overurbanization in Asia suggested initial proposals that addressed rural-push factors such as lack of economic opportunity and low productivity by improving agricultural technology and supporting rural industries. Furthermore, rural misery could be reduced by bringing industrialization into rural areas to increase employment and wages and to support the development of infrastructure that creates a \"more desirable community environment.\"<ref name=UNESCO/> The UNESCO report also considers the role of governments in committing to providing adequate housing as well as regional planning that takes into consideration social concerns.<ref name=UNESCO/> However, these considerations, among others that propose dealing with unemployment, have been criticized as \"skirting the issue by addressing 'symptoms' of overurbanization\" rather than the root cause.<ref name=graves/>\nLater authors also emphasized improving rural conditions to combat overurbanization. Gugler suggested channeling more resources to rural areas and fighting the tendency to neglect rural areas with what economist Michael Lipton deemed \"urban bias,\" the tendency to allocate funds and public works to cities, where the elite and middle classes reside.<ref name=Gugler/> For example, monetary policies that create artificially low prices for agricultural products harm farmers while creating a surplus for the government. Thus a reallocation of resources to agricultural workers would help shift this system that favors urban elites over the rural poor. Sociologists York Bradshaw and Mark Schafer studied the relationship between INGOs and overurbanization and found that state expenditures towards development were less effective than the role of INGOs. While INGOs were shown statistically to decrease overurbanization, the presence of INGOS did not decrease the effects of foreign capital investment, which is considered one of the root causes of overurbanization by dependency theorists.<ref name=Bradshaf/> They and Shandra agree that INGOs can play an important role in decreasing overurbanization by supporting rural communities by promoting both economic and infrastructural development as well as the role of civic society.<ref name=Bradshaf/><ref name=Shandra/>", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Proposed solutions", "sub_heading": "Proposed solutions", "_id": "8--3---1---1", "title": "Overurbanization and the role of INGOs in reducing overurbanization in Asia"}
{"qas": [{"question": "Why do some countries have higher illiteracy rates than others?", "answer": ""}, {"question": "What percentage of korea's population was urban in 1949?", "answer": "17.2 percent", "ae_score": -0.9592028749584719, "qg_score": null}, {"question": "What percentage of korea's population was urban in 1949?", "answer": "17.2 percent", "ae_score": -0.9592028749584719, "qg_score": null}], "content": "Davis and Golden offered the example of Egypt as a country that significantly deviated from the normal relationship between urbanization and economic development. They argue that population growth in rural areas created congestion, poverty, and unemployment. They point out that only 10 percent of economically active males in rural areas are employed in non-agricultural work, compared to 50 percent in France, suggesting that there are no economic opportunities in rural areas in Egypt outside of farming.<ref name=Davis/> Egypt had similar levels of urbanization in the late 1940s to Sweden, Switzerland, and France, but significantly lower levels of industrialization. Based on the normal relationship Davis and Golden found between urbanization and industrialization, Egypt had higher levels of urbanization than expected. Dyckman gives an example of a consequence of urbanization in Cairo when he explains that urban dwellers actually have lower literacy rates than those in surrounding villages due to a lack of development.\nBoth the UNESCO report and Davis and Golden identify South Korea as an example of an overurbanized country. Davis and Golden discussed how following the removal of the Japanese after World War II, urbanization continued, but economic growth stagnated.<ref name=Davis/> Population growth and urbanization were driven by migration from overpopulated rural areas, even though the majority of jobs available were still in the agricultural sector.<ref name=UNESCO/> The 17.2 percent of Korea's population that were urban dwellers in 1949 were attributed largely to the presence of rural migrants.", "page_name": "Overurbanization", "page_id": "Overurbanization", "heading": "Case studies", "sub_heading": "Case studies", "_id": "8--4---1---1", "title": "Davis and Golden: The Normal Relationship Between Urbanization and Economic Development"}
{"qas": [{"question": "Why is antibiotic use so high in the United States?", "answer": ""}, {"question": "When did antibiotics become illegal in the us?", "answer": "1910", "ae_score": -0.3062731178442168, "qg_score": null}, {"question": "When did antibiotics become illegal in the us?", "answer": "1910", "ae_score": -0.3062731178442168, "qg_score": null}], "content": "In 1910 in the United States, a meat shortage resulted in protests and boycotts.<ref name=\"Ogle2013\">\nThis reference should be replaced with citations to a book later published by the same author\nSince the 1900s,  livestock production on United States farms has had to rear larger quantities of animals over a short period of time to meet new consumer demands. Factory farming or the use of high intensity feedlots originated in the late 19th century when advances in technology and science allowed for mass production of livestock.  Global agriculture production doubled four times within 1820 and 1975, feeding one billion in 1800 and up to 6.5 billion in 2002.  Along with the new large animal densities came the threat of disease, therefore requiring a greater disease control of these animals.In 1950, a group of United States scientists found that adding antibiotics to animal feed increases the growth rate of livestock.<ref>Ogle cites To meet this new consumer demand for animal meat, the improved health management has since introduced about seventeen classes of antimicrobial drugs is approved for use in food animals in the United States today.\nBy 2001 this practice had grown so much that a report by the Union of Concerned Scientists found that nearly 90% of the total use of antimicrobials in the United States was for non-therapeutic purposes in agricultural production.\nAntibiotics have an appropriate place in the humane care of illness in livestock, when they reduce the suffering of a sick animal or control the spread of the illness to nearby animals. Thus, ideas that they should ''never'' be used in livestock husbandry are misguided. Instead, the goal is to prevent the allowance of preventive use from being distorted into routine use, constituting overuse.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "History of the practice", "sub_heading": "History of the practice", "_id": "9--0---1---1", "title": "Antimicrobials in Animal Hustling"}
{"qas": [{"question": "How do antibiotics work?", "answer": ""}, {"question": "What part of the body can be affected by antibiotics?", "answer": "gut flora", "ae_score": -0.8699143793444511, "qg_score": null}, {"question": "What part of the body can be affected by antibiotics?", "answer": "gut flora", "ae_score": -0.8699143793444511, "qg_score": null}], "content": "Certain antibiotics, when given in low, sub-therapeutic doses, are known to improve feed conversion efficiency (more output, such as muscle or milk, for a given amount of feed) and/or may promote greater growth, most likely by affecting gut flora.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Drugs and growth stimulation", "sub_heading": "Drugs and growth stimulation", "_id": "9--1---1---1", "title": "Antibiotics, when given in low, sub-therapeutic doses, may promote greater"}
{"qas": [{"question": "Antibiotic resistance?", "answer": ""}, {"question": "What is the use of antibiotics to increase the growth of pigs called?", "answer": "subtherapeutic antibiotic use", "ae_score": -0.7396249310847275, "qg_score": null}, {"question": "What is the use of antibiotics to increase the growth of pigs called?", "answer": "subtherapeutic antibiotic use", "ae_score": -0.7396249310847275, "qg_score": null}], "content": "The use of antibiotics to increase the growth of pigs is most studied of all livestock. This use for growth rather than disease prevention is referred to as subtherapeutic antibiotic use. Studies have shown that administering low doses of antibiotics in livestock feed improves growth rate, reduces mortality and morbidity, and improves reproductive performance. It is estimated that over one-half of the antibiotics produced and sold in the United States is used as a feed additive. Although it is still not completely understood why and how antibiotics increase the growth rate of pigs, possibilities include metabolic effects, disease control effects, and nutritional effects. While subtherapeutic use has many benefits for raising swine, there is growing concern that this practice leads to increased antibiotic resistance in bacteria. Antibiotic resistance occurs when bacteria are resistant to one or more microbial agents that are usually used to treat infection. There are three stages in the possible emergence and continuation of antibiotic resistance: genetic change, antibiotic selection, and spread of antibiotic resistance.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Use in different livestock", "sub_heading": "Use in different livestock", "_id": "9--2---1---1", "title": "How Subtherapeutic Use of Antibiotics Increases the Growth of Pigs"}
{"qas": [{"question": "Why is it illegal in the USA to administer poisons or drugs to animals?", "answer": ""}, {"question": "When did antibiotics stop being used in livestock?", "answer": "December 2013", "ae_score": -0.4733434420830743, "qg_score": null}, {"question": "When did antibiotics stop being used in livestock?", "answer": "December 2013", "ae_score": -0.4733434420830743, "qg_score": null}], "content": "The use of drugs in food animals is regulated in nearly all countries. Historically, this has been to prevent alteration or contamination of meat, milk, eggs and other products with toxins that are harmful to humans. Treating a sick animal with drugs may lead to some of those drugs remaining in the animal when it is slaughtered or milked. Scientific experiments provide data that shows how long a drug is present in the body of an animal and what the animal's body does to the drug. Of particular concern are drugs that may be passed into milk or eggs. By the use of 'drug withdrawal periods' before slaughter or the use of milk or eggs from treated animals, veterinarians and animal owners ensure that the meat, milk and eggs is free of contamination.\nThese restrictions include not only poisons or drugs (such as penicillin) which may result in allergic reactions but also contaminants which may cause cancer. It is illegal in the USA to administer drugs or feed substances to animals if they have been shown to cause cancer.\nOne of the main restrictions is the amount that is administered to animals in the industry. These drugs should be administered to healthy livestock at a low concentration of 200 g per ton of feed. The amount distributed is also altered throughout the lifespan of livestock in order to meet specific growth needs.\nLegality of the use of specific drugs in animal medicine varies according to location.\nJust as in human medicine, some drugs are available over the counter and others are restricted to use only on the prescription of a veterinary physician. In the USA, the Food and Drug Administration (FDA) requires specific labels on all drugs, giving directions on the use of the drug.  For animals, this includes the species, dose, reason for giving the drug (indication) and the required withdrawal period, if any. Federal law requires laypersons to use drugs only in the manner listed. Veterinarians who have examined an animal or a herd of animals may issue a replacement label, giving new directions, based on their medical knowledge.  It is illegal in the USA for any layperson to administer any drug to a food animal in a way not specific to the drug label.  Over-the-counter drugs which may be used by laypersons include anti-parasite drugs (including fly sprays) and antimicrobials. These drugs can be applied as sprays, creams, injections, oral pills or fluids, or as a feed additive, depending on the drug and the label.\nIn December 2013, the FDA updated its regulations to try to begin reducing use of antibiotics for growth enhancement. Significant lobbying comes from all directions, from those against tighter regulation to those who complain it doesn't go far enough.\nCurrently few policies, regulations and laws exist that promote limitation of antibiotic use on factory farms.  In addition, few policies are being created that call for this decrease in antibiotic use.  However, numerous state senators and members of congress showed support for the Preventing Antibiotic Resistance Act of 2015 (PARA) and the Preservation of Antibiotics for Medical Treatment Act of 2013 (PAMTA).  These acts proposed amendments be made to the Federal Food, Drug and Cosmetic Act which would limit and preserve the use of antibiotics for medically necessary situations.  Both of these bills died in Congress in 2015.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Regulatory context", "sub_heading": "Regulatory context", "_id": "9--3---1---1", "title": "The Legality of the Use of Drugs in Animal Medicine"}
{"qas": [{"question": "Why do farmers need to take antibiotics?", "answer": ""}, {"question": "What is the most appropriate method of administering antibiotics in livestock?", "answer": "a slow-release injection", "ae_score": -1.2905667931788114, "qg_score": null}, {"question": "What is the most appropriate method of administering antibiotics in livestock?", "answer": "a slow-release injection", "ae_score": -1.2905667931788114, "qg_score": null}], "content": "Drugs can be administered to animals in a variety of means, just as with humans.  Among these are topical (on the skin), by injection (including intravenous, subcutaneous, subcutaneous implants, intramuscular and intraperitoneal), and orally. Oral drugs can be in pill or liquid form, or can be given by mixing with feed or drinking water.  The appropriate route for treatment depends on the specific case and can vary by: illness, severity of illness, selected drug, age or condition of the animal, species of the animal, type of housing and other factors. For animals that are not regularly fed a concentrated feed or which can be handled repeatedly, a slow-release injection might be the most appropriate. Some drugs are not available or appropriate in this form and should be delivered orally.  For animals that are fed regularly (rather than grazing freely) or that can not be easily handled, the most appropriate means of administering the drug may be to include the drug in feed or water. This eliminates the stress of daily (or more frequent) handling of animals, which can make the animals more ill. Poultry are most commonly medicated in this fashion, as they are easily stressed to the point of dying. Administering the drug by feed also prevents injection wounds in animals.\nThe timely administration of drugs is key to preventing animal suffering and economic loss to the farmer.  Animals which are ill can infect other animals, and may become so ill that they can not be sold.  A variety of techniques are used to monitor animals for illness so that they can be treated appropriately.  Stress reduction, adequate nutrition, shelter, and quarantine of incoming stock are all important factors to promote growth and reduce illness and the need for active treatment. The age and status of an animal is also important in determining correct treatment \u2013 a young animal or pregnant animal is at greater risk and are treated more aggressively than an older animal. Specifically in calves, the period in which they begin to separate from their mothers generates stress and makes them more susceptible to catching an infection like pneumonia. Antibiotics are commonly administered in the calves' feed during this time to fight the possibility of stress-induced infections. Feed antibiotics are also used to prevent  illnesses in calves caused by liver abscesses that develop during their last stages of growth.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Administering drugs", "sub_heading": "Administering drugs", "_id": "9--4---1---1", "title": "Drugs for Animals \u2014 A Guide to Veterinary Treatment"}
{"qas": [{"question": "How do we know the amount of antibiotics in the world?", "answer": ""}, {"question": "How much of the world's antibiotics are used in india?", "answer": "a third", "ae_score": -0.11028039926234731, "qg_score": null}, {"question": "How much of the world's antibiotics are used in india?", "answer": "a third", "ae_score": -0.11028039926234731, "qg_score": null}], "content": "The European Union (EU) in 1999 implemented an antibiotic resistance monitoring program and phase out plan for all antibiotic use by 2006. Although the European Union banned the use of antibiotics as growth agents from 2006, its use has not changed much until recently. In Germany, 1,734 tons of antimicrobial agents were used for animals in 2011 compared with 800 tons for humans. On the other hand, Sweden banned their use in 1986 and Denmark started cutting down drastically in 1994, so that its use is now 60% less. In the Netherlands, the use of antibiotics to treat diseases increased after the ban on its use for growth purposes in 2006. In 2011, the EU voted to ban the prophylactic use of antibiotics, alarmed at signs that the overuse of antibiotics is blunting their use for humans.\nIn 2011, a total of 13.6 million kilograms of antimicrobials were sold for use in food-producing animals in the United States, which represents 80% of all antibiotics sold or distributed in the United States. Of the antibiotics given to animals fom 2009 through 2013, just above 60% distributed for food animal use are \"medically-important\" drugs, that are also used in humans. The rest are drug classes like ionophores which are not used in human medicine. Due to concerns about the overuse of antibiotics in food-producing animals, the U.S. Food & Drug Administration has implemented new industry guidelines that will restrict the use of medically-important drugs to uses \"that are considered necessary for assuring animal health\" and will require veterinary oversight. The food animal and veterinary pharmaceutical industries will need to phase out medically important antimicrobial use by January 1, 2017.\nChina produces and consumes the most antibiotics of all countries.\nAntibiotic use has been measured by checking the water near factory farms in China. Measurements have also been taken from animal dung.\nHalf of the antibiotics manufactured in China are used in the production of livestock.\nIt was calculated that 38.5 million kg (or 84.9 million lbs) of antibiotics were used in China's swine and poultry production in 2012.\nIn 2012 India manufactured about a third of the total amount of antibiotics in the world.\nBrazil is the world's largest exporter of beef and the government regulates antibiotic use in the cattle production industry.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Use by country", "sub_heading": "Use by country", "_id": "9--5---1---1", "title": "The World's Largest Exporter of Antibiotics"}
{"qas": [{"question": "Why is it so hard to get rid of antibiotic resistance?", "answer": ""}, {"question": "What is the use of antibiotics in livestock?", "answer": "growth stimulation", "ae_score": -0.348474973004119, "qg_score": null}, {"question": "What is the use of antibiotics in livestock?", "answer": "growth stimulation", "ae_score": -0.348474973004119, "qg_score": null}], "content": "The practice of using antibiotics for growth stimulation is problematic for these reasons:\nDonald Kennedy, former director of the United States Food and Drug Administration, has said \"There's no question that routinely administering non-therapeutic doses of antibiotics to food animals contributes to antibiotic resistance.\" David Aaron Kessler, another former director of the FDA, said that \"We have more than enough scientific evidence to justify curbing the rampant use of antibiotics for livestock, yet the food and drug industries are not only fighting proposed legislation to reduce these practices, they also oppose collecting the data.\"\nIn 2013 the United States Centers for Disease Control and Prevention (CDC) published a white paper discussing antibiotic resistance threats in the US and calling for \"improved use of antibiotics\" among other measures to contain the threat to human health. The CDC asked leaders in agriculture, healthcare, and other disciplines to work together to combat the issue of increasing antibiotic resistance.\nSome scientists have said that \"all therapeutic antimicrobial agents should be available only by prescription for human and veterinary use.\"\nThe Pew Charitable Trusts have stated that \"hundreds of scientific studies conducted over four decades demonstrate that feeding low doses of antibiotics to livestock breeds antibiotic-resistant superbugs that can infect people. The FDA, the U.S. Department of Agriculture and the Centers for Disease Control and Prevention all testified before Congress that there is a definitive link between the routine, non-therapeutic use of antibiotics in food animal production and the challenge of antibiotic resistance in humans.\"", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Concerns about antibiotic resistance", "_id": "9--6--0---1", "title": "Antibiotic Resistance in Food Animal Production"}
{"qas": [{"question": "Is there any scientific evidence that antibiotic use is linked to antibiotic resistance?", "answer": ""}, {"question": "Who regulates the use of antibiotics in the us?", "answer": "The National Pork Board", "ae_score": -0.2504290573286312, "qg_score": null}, {"question": "Who regulates the use of antibiotics in the us?", "answer": "The National Pork Board", "ae_score": -0.2504290573286312, "qg_score": null}], "content": "In 2011 the National Pork Producers Council, an American trade association, has said \"Not only is there no scientific study linking antibiotic use in food animals to antibiotic resistance in humans, as the U.S. pork industry has continually pointed out, but there isn't even adequate data to conduct a study.\"<ref>\nThe National Pork Board, a Government-owned corporation of the United States, has said that \"the vast majority of producers use (antibiotics) appropriately.\"", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Positions of advocates for status quo", "_id": "9--6--2---1", "title": "Antibiotic use in livestock | Concerns about antibiotic resistance | Positions of advocates for status quo"}
{"qas": [{"question": "Why is it bad for the environment to ban antibiotics?", "answer": ""}, {"question": "What is the most commonly used medicine in livestock?", "answer": "antibiotics", "ae_score": -0.7219546073157821, "qg_score": null}, {"question": "What is the most commonly used medicine in livestock?", "answer": "antibiotics", "ae_score": -0.7219546073157821, "qg_score": null}], "content": "When government regulation restricts use of antibiotics the negative economic impact is not often considered.\nRegulation of antibiotics in livestock production would affect the business models of corporations including Tyson Foods, Cargill, and Hormel.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Effects of restricting antibiotic use", "_id": "9--6--3---1", "title": "Regulation of antibiotics in livestock production would have a negative economic impact on Tyson Foods"}
{"qas": [{"question": "Why is it so hard to figure out how to treat antibiotic resistance?", "answer": ""}, {"question": "Who published a report in 2011 stating that government and commercial agencies had not been collecting enough?", "answer": "The US Government Accountability Office", "ae_score": -0.5427439901301121, "qg_score": null}, {"question": "Who published a report in 2011 stating that government and commercial agencies had not been collecting enough?", "answer": "The US Government Accountability Office", "ae_score": -0.5427439901301121, "qg_score": null}], "content": "It is difficult to set up a comprehensive surveillance system for measuring rates of change in antibiotic resistance.  The US Government Accountability Office published a report in 2011 stating that government and commercial agencies had not been collecting sufficient data to make a decision about best practices.\nCurrently there is no regulatory agency in the United States that systematically collects detailed data on antibiotic use in humans and animals. It is not clear which antibiotics are prescribed for which purpose and at what time. Furthermore, the world has no surveillance infrastructure to monitor emerging antibiotic resistance threats. Because of these issues, it is difficult to quantify antibiotic resistance, to regulate antibiotic prescribing practices, and to detect and respond to rising threats.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Difficulties with determining relevant facts", "_id": "9--6--4---1", "title": "Antibiotic Resistance: A Global Challenge"}
{"qas": [{"question": "Why are there so many drug-resistant foodborne illnesses in the US?", "answer": ""}, {"question": "What is the most well-documented impact of antibiotic use on humans?", "answer": "foodborne gastrointestinal illness", "ae_score": -0.2754409565924626, "qg_score": null}, {"question": "What is the most well-documented impact of antibiotic use on humans?", "answer": "foodborne gastrointestinal illness", "ae_score": -0.2754409565924626, "qg_score": null}], "content": "There have been many studies that document antibiotic resistant bacteria in livestock, though the impact of the different bacteria in humans is still undergoing research. At this time, the most well-documented impact on humans is foodborne gastrointestinal illness. In most cases, these illnesses are mild and do not require antibiotics; though if the infectious bacteria is drug-resistant, research has shown that these bacteria have increased virulence (ability to cause disease), leading to prolonged illness. Furthermore, in approximately 10% of cases, the disease becomes severe, requiring more advanced treatments. These treatments can take the form of intravenous antibiotics, supportive care for blood infections, and hospital stays, leading to higher costs and greater morbidity with a trend toward higher mortality. Severe disease with this outcome is more common with drug-resistant bacteria. Though all people are susceptible, populations shown to be at higher risk for severe disease include children, the elderly, and those with chronic disease.\nOver the past 20 years, the most common drug-resistant foodborne bacteria in industrialized countries have been non-typhoidal salmonella and campylobacter. Research has consistently shown the main contributing factors are bacteria sourced in livestock. One example of this was a 1998 outbreak of multidrug-resistant salmonella in Denmark linked back to two Danish swine herds.  Coupled with the discovery of this link, there have been improved monitoring systems that have helped to quantify the impact. In the United States, it is estimated that there are approximately 400,000 cases and over 35,000 hospitalizations per year attributable to increasing resistant strains of salmonella and campylobacter. In terms of financial impact in the US, the treatment of non-typhoidal salmonella infections alone is now estimated to cost $365 million per year. In light of this, in its inaugural 2013 report on antibiotic resistance threats in the United States, the CDC identified resistant non-typhoidal salmonella and campylobacter as \"serious threats\" and called for improved surveillance and intervention in food production moving forward.\nThere are other bacteria as well, where research is evolving and revealing that bacterial resistance acquired through use in livestock may be contributing to disease in humans. Examples of these include Enterococcus, E. coli 0157 and Staphylococcus Aureus. In the case of foodborne illness from E.coli, though it is still not typically treated with antibiotics because of associated risk of renal failure, increasing rates of antibiotic resistant infections have been correlated with increasing virulence of the bacteria.  In the case of enterococcus and staphylococcus aureus, resistant forms of both of these bacteria have resulted in greatly increasing morbidity and mortality in the US.  At this point, there have been studies, though a limited number, that definitively link antibiotic use in food production to these resistance patterns in humans and further research will help to further characterize this relationship.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Specific resistance that has been identified and human impact", "_id": "9--6--5---1", "title": "The Impact of Foodborne Bacteria on Human Health"}
{"qas": [{"question": "Why is it bad to eat manure that is antibiotic-fed?", "answer": ""}, {"question": "What is the purpose of antibiotic-fed swine?", "answer": "fertilizer", "ae_score": -0.6212902331965704, "qg_score": null}, {"question": "What is the purpose of antibiotic-fed swine?", "answer": "fertilizer", "ae_score": -0.6212902331965704, "qg_score": null}], "content": "Humans can be exposed to antibiotic-resistant bacteria by ingesting them through the food supply. Dairy products, ground beef and poultry are the most common foods harboring these pathogens. There is evidence that a large proportion of resistant ''E. coli'' isolates causing blood stream infections in people are from livestock produced as food.\nWhen manure from antibiotic-fed swine is used as fertilizer elsewhere, the manure may be contaminated with bacteria which can infect humans.\nStudies have also shown that direct contact with livestock can lead to the spread of antibiotic-resistant bacteria from animals to humans.,", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Mechanisms for transfer to humans", "_id": "9--6--6---1", "title": "Antibiotic-Resistant Bacteria in Livestock"}
{"qas": [{"question": "Why is there a ban on the use of antibiotics in meat?", "answer": ""}, {"question": "When did antibiotics become illegal in livestock?", "answer": "2008", "ae_score": -0.2693836607947528, "qg_score": null}, {"question": "When did antibiotics become illegal in livestock?", "answer": "2008", "ae_score": -0.2693836607947528, "qg_score": null}], "content": "Legislation and activism worldwide have aimed at restricting antibiotic use in livestock.\nOn 1 January 2006 the European Union banned the non-medicinal use of antibiotics in livestock production.\nSome grocery stores have policies about voluntarily not selling meat produced by using antibiotics to stimulate growth. In 2012 in the United States advocacy organization Consumers Union organized a petition asking the store Trader Joe's to discontinue the sale of meat produced with antibiotics.<ref>, which is described in the following works\nThe U.S. Animal Drug User Fee Act was passed by Congress in 2008 and requires that drug manufacturers report all sales of antibiotics into the food animal production industry.\nSome proposed legislation in the US has failed to be adopted.  The Animal Drug and Animal Generic Drug User Fee Reauthorization Act of 2013 proposes other regulation.\nIn the United States the danger of emergence of antibiotic-resistant bacterial strains due to wide use of antibiotics to promote weight gain in livestock was determined by the United States Food and Drug Administration in 1977, but nothing effective was done to prevent the practice. In March, 2012 the United States District Court for the Southern District of New York, ruling in an action brought by the Natural Resources Defense Council and others, ordered the FDA to revoke approvals for the use of antibiotics in livestock which violated FDA regulations. On 11 April 2012 the FDA announced a program to phase out unsupervised use of drugs as feed additives and, on a voluntary basis, convert approved uses for antibiotics to therapeutic use only, requiring veterinarian supervision of their use and a prescription.\nIn response to consumer concerns about the use of antibiotics in poultry, in 2007, Perdue removed all human antibiotics from its feed and launched the Harvestland brand, under which it sold products that met the requirements for an \"antibiotic-free\" label. By 2014, Perdue had also phased out ionophores (antibiotics used in animals to lower production costs by promoting growth, and preventing disease) from its hatchery and began using the \"antibiotic free\" labels on its Harvestland, Simply Smart and Perfect Portions products.  By 2015, 52% of the company's chickens were raised without the use of any type of antibiotics.\nIn 1970 the FDA started recommending that antibiotic use in livestock be limited but set no actual regulations governing this recommendation.  Further, in 2004 the Government Accountability Office (GAO) heavily critiqued the FDA for not collecting enough information and data on antibiotic use in factory farms.  From this the GAO concluded that the FDA does not have enough information to create effective policy changes regarding antibiotic use.  In response to this the FDA insisted that more research was being conducted and voluntary efforts within the industry would solve the problem of antibiotic resistance.\nIn 2012, U.S. News & World Report described the Chinese government's regulation of antibiotics in livestock production as \"weak\".\nIn 2011 the Indian government proposed a \"National policy for containment of antimicrobial resistance\". Other policies set schedules for requiring that food producing animals not be given antibiotics for a certain amount of time before their food goes to market. A study released by Centre for Science and Environment (CSE) on 30 July 2014 found antibiotic residues in chicken. This study claims that Indians are developing resistance to antibiotics \u2014 and hence falling prey to a host of otherwise curable ailments. Some of this resistance might be due to large-scale unregulated use of antibiotics in the poultry industry. CSE finds that India has not set any limits for antibiotic residues in chicken and says that India will have to implement a comprehensive set of regulations including banning of antibiotic use as growth promoters in the poultry industry. Not doing this will put lives of people at risk.\nAntibiotic resistant bacteria have been found in Brazilian cattle.\nIn 1998 some researchers reported use in livestock production was a factor in the high prevalence of antibiotic resistant bacteria in Korea. In 2007 ''The Korea Times'' noted that Korea has relatively high usage of antibiotics in livestock production. In 2011 the Korean government banned the use of antibiotics as growth promoters in livestock.\nIn 1999 the New Zealand government issued a statement that they would not then ban the use of antibiotics in livestock production. In 2007 ABC Online reported on antibiotic use in chicken production in New Zealand.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Concerns about antibiotic resistance", "sub_heading": "Action and advocacy by country", "_id": "9--6--7---1", "title": "Antibiotic Resistance in the Food Animal Industry"}
{"qas": [{"question": "How do we know that bacteria can infect every living thing in the world?", "answer": ""}, {"question": "What type of bacteria is used in livestock production?", "answer": "Probiotics", "ae_score": -0.1805283912698567, "qg_score": null}, {"question": "What type of bacteria is used in livestock production?", "answer": "Probiotics", "ae_score": -0.1805283912698567, "qg_score": null}], "content": "Increasing concern due to the emergence of antibiotic resistant bacteria has led researchers to look for alternatives to using antibiotics in livestock.\nProbiotics, cultures of a single bacteria strain or mixture of different strains, are being studied in livestock as a production enhancer.\nPrebiotics are non-digestible carbohydrates. The carbohydrates are mainly made up of oligosaccharides which are short chains of monosaccharides. The two most commonly studied prebiotics are fructooligosaccharides (FOS) and mannanoligosaccharides (MOS). FOS has been studied for use in chicken feed. MOS works as a competitive binding site, as bacteria bind to it rather than the intestine and are carried out.\nBacteriophages are able to infect most bacteria and are easily found in most environments colonized by bacteria, and have been studied as well.<ref name=Allen/>\nIn another study it was found that using probiotics, competitive exclusion, enzymes, immunomodulators and organic acids prevents the spread of bacteria and can all be used in place of antibiotics.  Another research team was able to use bacteriocins, antimicrobial peptides and bacteriophages in the control of bacterial infections.  While further research is needed in this field, alternative methods have been identified in effectively controlling bacterial infections in animals.  All of the alternative methods listed pose no known threat to human health and all can lead the elimination of antibiotics in factory farms.  With further research it is highly likely that a cost effective and health effective alternative could and will be found.", "page_name": "Antibiotic use in livestock", "page_id": "Antibiotic%20use%20in%20livestock", "heading": "Research into alternatives", "sub_heading": "Research into alternatives", "_id": "9--7---1---1", "title": "Alternative Methods to Use Antibiotics in Animals"}
{"qas": [{"question": "Why is the gut so much more susceptible to bacteria than other parts of the body?", "answer": ""}, {"question": "What is the aggregate of all the genomes of gut microbiota?", "answer": "The gut metagenome", "ae_score": -0.5715976112164715, "qg_score": null}, {"question": "What is the aggregate of all the genomes of gut microbiota?", "answer": "The gut metagenome", "ae_score": -0.5715976112164715, "qg_score": null}], "content": "The gut flora is the complex community of microorganisms that live in the digestive tracts of humans and other animals, as well as insects.  The gut metagenome is the aggregate of all the genomes of gut microbiota. The gut is one niche that human microbiota inhabit.\nIn humans, the gut microbiota has the largest numbers of bacteria and the greatest number of species compared to other areas of the body.  In humans the gut flora is established at one to two years after birth, and by that time the intestinal epithelium and the intestinal mucosal barrier that it secretes have co-developed in a way that is tolerant to, and even supportive of, the gut flora and that also provides a barrier to pathogenic organisms.\nThe relationship between gut flora and humans is not merely commensal (a non-harmful coexistence), but rather a mutualistic relationship. Human gut microorganisms benefit the host by collecting the energy from the fermentation of undigested carbohydrates and the subsequent absorption of short-chain fatty acids (SCFAs), acetate, butyrate, and propionate.  Intestinal bacteria also play a role in synthesizing vitamin B and vitamin K as well as metabolizing bile acids, sterols, and xenobiotics.   The systemic importance of the SCFAs and other compounds they produce are like hormones and the gut flora itself appears to function like an endocrine organ, and dysregulation of the gut flora has been correlated with a host of inflammatory and autoimmune conditions.\nThe composition of human gut flora changes over time, when the diet changes, and as overall health changes.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Gut flora", "sub_heading": "Gut flora", "_id": "10--0---1---1", "title": "Gut Microbiota and Human Health"}
{"qas": [{"question": "What is a second brain?", "answer": ""}, {"question": "How many neurotransmitters are found in the gut?", "answer": "more than 30", "ae_score": null, "qg_score": null}, {"question": "How many neurotransmitters are found in the gut?", "answer": "more than 30", "ae_score": null, "qg_score": null}], "content": "The enteric nervous system is one of the main divisions of the nervous system and consists of a mesh-like system of neurons that governs the function of the gastrointestinal system; it has been described as a \"second brain\" for several reasons. The enteric nervous system can operate autonomously. It normally communicates with the central nervous system (CNS) through the parasympathetic (e.g., via the vagus nerve) and sympathetic (e.g., via the prevertebral ganglia) nervous systems.  However, vertebrate studies show that when the vagus nerve is severed, the enteric nervous system continues to function.\nIn vertebrates, the enteric nervous system  includes efferent neurons, afferent neurons, and interneurons, all of which make the enteric nervous system capable of carrying reflexes in the absence of CNS input.  The sensory neurons report on mechanical and chemical conditions.  Through intestinal muscles, the motor neurons control peristalsis and churning of intestinal contents.  Other neurons control the secretion of enzymes.  The enteric nervous system also makes use of more than 30 neurotransmitters, most of which are identical to the ones found in CNS, such as acetylcholine, dopamine, and serotonin. More than 90% of the body's serotonin lies in the gut, as well as about 50% of the body's dopamine and the dual function of these neurotransmitters is an active part of gut-brain research.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Enteric nervous system", "sub_heading": "Enteric nervous system", "_id": "10--1---1---1", "title": "The Enteric Nervous System"}
{"qas": [{"question": "Why does your gut flora change when you're in a stressful situation?", "answer": ""}, {"question": "When was the theory of the gut-brain axis discovered?", "answer": "2004", "ae_score": -0.4026392873111693, "qg_score": null}, {"question": "When was the theory of the gut-brain axis discovered?", "answer": "2004", "ae_score": -0.4026392873111693, "qg_score": null}], "content": "The gut\u2013brain axis, a bidirectional neurohumoral communication system, is important for maintaining homeostasis and is regulated through the central and enteric nervous systems and the neural, endocrine, immune, and metabolic pathways, and especially including the hypothalamic\u2013pituitary\u2013adrenal axis (HPA axis).  That term has been expanded to include the role of the gut flora as part of the \"microbiome-gut-brain axis\", a linkage of functions including the gut flora.\nInterest in the field was sparked by a 2004 study showing that germ-free mice (genetically homogeneous laboratory mice, birthed and raised in an antiseptic environment) showed an exaggerated HPA axis response to stress compared to non-GF laboratory mice.\nThe gut flora can produce a range of neuroactive molecules, such as acetylcholine, catecholamines, \u03b3-aminobutyric acid, histamine, melatonin, and serotonin, which is essential for regulating peristalsis and sensation in the gut.  Changes in the composition of the gut flora due to diet, drugs, or disease correlate with changes in levels of circulating cytokines, some of which can affect brain function.  The gut flora also release molecules that can directly activate the vagus nerve which transmits information about the state of the intestines to the brain.\nLikewise, chronic or acutely stressful situations activate the hypothalamic\u2013pituitary\u2013adrenal axis, causing changes in the gut flora and intestinal epithelium, and possibly having systemic effects.  Additionally, the cholinergic anti-inflammatory pathway, signaling through the vagus nerve, affects the gut epithelium and flora. Hunger and satiety are integrated in the brain, and the presence or absence of food in the gut and types of food present, also affect the composition and activity of gut flora.\nThat said, most of the work that has been done on the role of gut flora in the gut-brain axis has been conducted in animals, including the highly artificial germ-free mice.   As of 2016 studies with humans measuring changes to gut flora in response to stress, or measuring effects of various probiotics, have generally been small and cannot be generalized; whether changes to gut flora are a result of disease, a cause of disease, or both in any number of possible feedback loops in the gut-brain axis, remains unclear.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Gut-brain integration", "sub_heading": "Gut-brain integration", "_id": "10--2---1---1", "title": "Gut flora in the gut-brain axis"}
{"qas": [{"question": "Why do people with anxiety and mood disorders tend to have GI problems?", "answer": ""}, {"question": "What are the symptoms of the gut-brain axis?", "answer": "GI problems", "ae_score": -0.5156750511998486, "qg_score": null}, {"question": "What are the symptoms of the gut-brain axis?", "answer": "GI problems", "ae_score": -0.5156750511998486, "qg_score": null}], "content": "As of January 2016 work on the relationship between gut flora and anxiety disorders and mood disorders including depression was at an early stage, with insufficient evidence to draw conclusions about a causal role for gut flora changes in these conditions, nor for the efficacy of any probiotic treatment.\nPeople with anxiety and mood disorders tend to have GI problems; small studies have been conducted to compare the gut flora of people with major depressive disorder and healthy people, but those studies have had contradictory results.\nMuch interest was generated in the potential role of gut flora in anxiety disorders, and more generally in the role of gut flora in the gut-brain axis, by studies published in 2004 showing that germ-free mice have an exaggerated HPA axis response to stress caused by being restrained, which was reversed by colonizing their gut with a ''Bifidobacterium'' species.  Studies looking at maternal separation for rats shows neonatal stress leads to long-term changes in the gut microbiota such as its diversity and composition, which also led to stress and anxiety-like behavior.  Additionally, while much work had been done as of 2016 to characterize various neurotransmitters known to be involved in anxiety and mood disorders that gut flora can produce (for example, ''Escherichia'', ''Bacillus'', and ''Saccharomyces'' species can produce noradrenalin; ''Candida'', ''Streptococcus'', and ''Escherichia'' species can produce serotonin, etc) the inter-relationships and pathways by which the gut flora might affect anxiety in humans were unclear.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Specific conditions", "sub_heading": "Specific conditions", "_id": "10--3--0---1", "title": "Gut Flora and Anxiety Disorders"}
{"qas": [{"question": "Why do people with schizophrenia have GI problems?", "answer": ""}, {"question": "What drug causes changes in the gut flora of mice?", "answer": "phencyclidine", "ae_score": -0.2930416863933356, "qg_score": null}, {"question": "What drug causes changes in the gut flora of mice?", "answer": "phencyclidine", "ae_score": -0.2930416863933356, "qg_score": null}], "content": "People with schizophrenia tend to also have GI problems, but as of 2015, no studies had been carried out to compare the gut flora of people with schizophrenia with healthy people.  Research causing schizophrenia-like symptoms in mice by giving them phencyclidine (PCP) has found changes to the gut flora of the treated mice compared with untreated mice.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Specific conditions", "sub_heading": "Schizophrenia", "_id": "10--3--1---1", "title": "Schizophrenia-like symptoms in mice by giving them phencyclidine (PC"}
{"qas": [{"question": "Is there a link between autism and gut flora?", "answer": ""}, {"question": "What percentage of people with autism have gi problems?", "answer": "Around 70%", "ae_score": -0.4780305421111517, "qg_score": null}, {"question": "What percentage of people with autism have gi problems?", "answer": "Around 70%", "ae_score": -0.4780305421111517, "qg_score": null}], "content": "Around 70% of people with autism also have GI problems, and autism is often diagnosed at the time that the gut flora becomes established, indicating that there may be a connection between autism and gut flora.  Some studies have found differences in the gut flora of children with autism compared with normal children \u2013 most notably elevations in the amount of ''Clostridium'' in the stools of children with autism compared with the stools of the children without \u2013 but these results have not been consistently replicated.  Many of the environmental factors thought to be relevant to the development of autism would also affect the gut flora, leaving open the question whether specific developments in the gut flora drive the development of autism or whether those developments happen concurrently.   As of 2016, studies with probiotics had only been conducted with animals; studies of other dietary changes to treat autism have been inconclusive.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Specific conditions", "sub_heading": "Autism", "_id": "10--3--2---1", "title": "Gut flora and autism"}
{"qas": [{"question": "Why do people with Parkinson's disease have different gut flora?", "answer": ""}, {"question": "When did the gut flora of parkinson's disease change?", "answer": "2015", "ae_score": -0.8066863011791738, "qg_score": null}, {"question": "When did the gut flora of parkinson's disease change?", "answer": "2015", "ae_score": -0.8066863011791738, "qg_score": null}], "content": "As of 2015 one study had been conducted comparing the gut flora of people with Parkinson's disease to healthy controls; in that study people with Parkinsons had lower levels of ''Prevotellaceae'' and people with Parkinsons who had higher levels of''Enterobacteriaceae'' had more clinically severe symptoms; the authors of the study drew no conclusions about whether gut flora changes were driving the disease or vice versa.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Specific conditions", "sub_heading": "Parkinson's disease", "_id": "10--3--3---1", "title": "Gut flora of people with Parkinson's disease and healthy controls"}
{"qas": [{"question": "What are probiotics and why are they used?", "answer": ""}, {"question": "When was the first study done on the gut-brain axis?", "answer": "2016", "ae_score": -0.684960104254697, "qg_score": null}, {"question": "When was the first study done on the gut-brain axis?", "answer": "2016", "ae_score": -0.684960104254697, "qg_score": null}], "content": "Psychobiotics are defined by Dinan et al. as probiotics that may benefit people with psychiatric, or neurological illnesses. The concept generated enormous research interest.\nA systematic review from 2016 examined the preclinical and small human trials that have been conducted with certain commercially available strains of probiotic bacteria and found that among those tested, ''Bifidobacterium'' and ''Lactobacillus'' genera (''B. longum'', ''B. breve'', ''B. infantis'', ''L. helveticus'', ''L. rhamnosus'', ''L. plantarum'', and ''L. casei''), had the most potential to be useful for certain central nervous system disorders.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Psychobiotics", "sub_heading": "Psychobiotics", "_id": "10--4---1---1", "title": "Psychobiotics: A New Approach to Psychiatry"}
{"qas": [{"question": "How did candy makers keep up with the technology of the past?", "answer": ""}, {"question": "Who were the best paid women in candy making?", "answer": "chocolate dippers", "ae_score": -0.4985057288812837, "qg_score": null}, {"question": "Who were the best paid women in candy making?", "answer": "chocolate dippers", "ae_score": -0.4985057288812837, "qg_score": null}], "content": "The technology for candy making has generally kept pace with the technology of the times.  For example, when steam power became common in factories, steam power was also used in candy factories.\nCandy making and consumption increased greatly during the Industrial Revolution in the 19th century.  Candy had previously been made by hand, either occasionally at home or by specialists in small, local businesses.  Increased mechanization caused prices to drop and production to increase.\nIn the late 19th century and especially the early 20th century, industrial candy making was almost exclusively a masculine affair, and home-based candy making was a feminine affair.  Candy was considered sweet and dainty, so making it at home, giving it away to friends, and perhaps selling small amounts in the local area, conformed with the Western gender roles for women of the time. Most women making and selling candy did so only seasonally or for a little extra money; they rarely earned enough to support themselves or their families.  Despite several large brands being named after women or otherwise capitalizing on wholesome, feminine, and maternal images, very few were owned or operated by women.\nGender segregation also affected candy workers in the 19th century and the first half of the 20th century.  Men and boys were employed for cooking or operating machinery.  Women were mostly employed for wrapping and putting candies in packages or for hand-dipping candies in chocolate.  The best-paid women were chocolate dippers, yet the wages of these skilled and experienced female workers were almost always lower than that of the worst-paid male machine operators.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "History", "sub_heading": "History", "_id": "11--0---1---1", "title": "Candy Making in the 19th Century"}
{"qas": [{"question": "Why is it so dangerous to make candy?", "answer": ""}, {"question": "What is the main ingredient in candy making?", "answer": "boiled sugar", "ae_score": -2.1619529082423425, "qg_score": null}, {"question": "What is the main ingredient in candy making?", "answer": "boiled sugar", "ae_score": -2.1619529082423425, "qg_score": null}], "content": "Making candy can be hazardous due to the use of boiled sugar and melted chocolate. Boiling sugar often exceeds 150 C\u2014hotter than most cooked foods\u2014and the sugar tends to stick to the skin, causing burns and blisters upon skin contact.  Worker safety programs focus on reducing contact between workers and hot food or hot equipment, and reducing splashing, because even small splashes can cause burns.  Some ingredients can also irritate the eyes and lungs, if, for example, powdered ingredients are accidentally inhaled, so worker protection involves reducing exposure to potentially irritating ingredients.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "Safety", "sub_heading": "Safety", "_id": "11--1---1---1", "title": "Worker Safety Programs: How to Reduce Exposure to Hot Food and Hot Equipment"}
{"qas": [{"question": "What is the difference between a hard crack and a soft crack?", "answer": ""}, {"question": "What kind of candy is made when sucrose molecules break down?", "answer": "caramel", "ae_score": -0.10002954880664444, "qg_score": null}, {"question": "What kind of candy is made when sucrose molecules break down?", "answer": "caramel", "ae_score": -0.10002954880664444, "qg_score": null}], "content": "Hard candy, also referred to as boiled sweet, is a candy prepared from one or more syrups boiled to a temperature of 160 \u00b0C (320 \u00b0F). After a syrup boiled to this temperature cools, it is called hard candy, since it becomes stiff and brittle as it approaches room temperature. Hard candy recipes variously call for syrups of sucrose, glucose, or fructose. To add color, food coloring is sometimes used.\n The final texture of candy depends on the sugar concentration. As the syrup is heated, it boils and water evaporates as the sugar concentration increases. As a result, the boiling point rises because it is a colligative property and related to the concentration of the sugar solution. A given temperature corresponds to a particular sugar concentration because of this physical correlation, so temperature is used as a marker for the necessary concentration. In general, higher temperatures and greater sugar concentrations result in hard, brittle candies, and lower temperatures result in softer candies. The stages of sugar cooking are as follows:\nThe names come from the methods used to test the syrup before thermometers became affordable. The \"thread\" stage is tested by cooling a little syrup, and pulling it between the thumb and forefinger. When the correct stage is reached, a thread will form. This stage is used for making syrups. For subsequent stages, a small spoonful of syrup is dropped into cold water, and the characteristics of the resulting lump are evaluated to determine the concentration of the syrup. A smooth lump indicates \"ball\" stages, with the corresponding hardness described. At the \"soft crack\" stage, the syrup forms threads that are just pliable. At the \"hard crack\" stage, the threads are brittle.\nThis method is still used today in some kitchens. A candy thermometer is more convenient, but has the drawback of not automatically adjusting for local conditions such as altitude, as the cold water test does.\nOnce the syrup reaches 171 \u00b0C or higher, the sucrose molecules break down into many simpler sugars, creating an amber-colored substance known as caramel. This should not be confused with caramel candy, although it is the candy's main flavoring.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "Hard candy", "sub_heading": "Hard candy", "_id": "11--2---1---1", "title": "Hard Candy Recipes"}
{"qas": [{"question": "How does cotton candy work?", "answer": ""}, {"question": "What is another name for spun sugar?", "answer": "Candy Floss", "ae_score": -0.30891794475754913, "qg_score": null}, {"question": "What is another name for spun sugar?", "answer": "Candy Floss", "ae_score": -0.30891794475754913, "qg_score": null}], "content": "Cotton candy, also known as Candy Floss, is a form of spun sugar. Typical machines used to make cotton candy include a spinning head enclosing a small bowl into which granulated sugar is poured. Colored sugar or separate sugar and food coloring are used to provide color. Heaters near the rim of the head melt the sugar, which is squeezed out through tiny holes by centrifugal force, and the molten sugar solidifies in the air and is caught in a larger bowl which totally surrounds the spinning head. After the product builds up on the inside walls of the larger bowl, a stick, cone, or hands are inserted, upon which the sugar strands are gathered.\nMarshmallows are prepared using egg whites, corn syrup and sugar. The use of marshmallow to make a sweet dates back to ancient Egypt, where the recipe called for an extract from the root of the marshmallow plant (''Althaea officinalis'') and mixing it with nuts and honey. Another pre-modern recipe uses the pith of the marshmallow plant, rather than the root. In modern times, marshmallows are often commercially prepared using extrusion.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "Soft candy", "sub_heading": "Soft candy", "_id": "11--3---1---1", "title": "How to Make Marshmallows in 2021"}
{"qas": [{"question": "What is chocolatiering?", "answer": ""}, {"question": "What is it called when you make chocolate?", "answer": "Chocolatiering", "ae_score": -0.42152838731664305, "qg_score": null}, {"question": "What is it called when you make chocolate?", "answer": "Chocolatiering", "ae_score": -0.42152838731664305, "qg_score": null}], "content": "Chocolatiering involves the preparing of confections from chocolate. A chocolatier that has mastered the artistry of chocolate may be referred to as  a Master Chocolatier. Chocolatiering involves the techniques of tempering, molding and sculpting. Tempering is a heat treatment method performed on chocolate involving heating and cooling the chocolate to result in desired characteristics like shininess of the chocolate or 'snap', the way it breaks. Molding is a design technique used in making chocolate pieces that are of a certain shape by taking liquid chocolate and pouring it into a mold and letting it harden. Sculpting is a type of three-dimensional artwork that may involve using molds and pieces of chocolate, and decorating the piece with designs in chocolate.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "Chocolatiering", "sub_heading": "Chocolatiering", "_id": "11--4---1---1", "title": "Chocolatiering \u2014 The Art of Chocolate"}
{"qas": [{"question": "Why do some candies have a temperature of 160\u00b0C?", "answer": ""}, {"question": "What is the most common tool used in candy making?", "answer": "candy thermometer", "ae_score": -0.48117103328843447, "qg_score": null}, {"question": "What is the most common tool used in candy making?", "answer": "candy thermometer", "ae_score": -0.48117103328843447, "qg_score": null}], "content": "A variety of tools and machines are used in making candy, ranging from simple kitchen tools like bowls and spoons to elaborate factory machinery.\nBecause exact temperature control is critical for some candies, a common tool is the candy thermometer.  Inexpensive candy thermometers measure food temperatures up to about 160 \u00b0C, and those designed for commercial candy production may run even higher.\nA starch mogul is used in candy factories to shape soft candies or candy centers from syrups or gels.  These centers may then be sent through a chocolate enrober to coat them in chocolate.", "page_name": "Candy making", "page_id": "Candy%20making", "heading": "Tools and machinery", "sub_heading": "Tools and machinery", "_id": "11--5---1---1", "title": "Candy Factory Machinery & Tools"}
{"qas": [{"question": "How do batteries work?", "answer": ""}, {"question": "When did the first lithium ion battery come out?", "answer": "2015", "ae_score": -0.5906144043843844, "qg_score": null}, {"question": "What part of a lithium-ion battery is aluminium used for?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "In 2015, researchers at Massachusetts Institute of Technology developed a quick charge battery that has four times the energy density of typical lithium-ion batteries. The battery uses tiny capsules of titanium dioxide filled with aluminium. The aluminium yolk has space to expand and contract inside the shell. This overcomes previous problems of using aluminium as a battery anode.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Anode", "_id": "12--0--0---1", "title": "Quick Charge Battery \u2014 A Quick Charge Battery with Four Times the Energy Density of "}
{"qas": [{"question": "How does a smartphone charger work?", "answer": ""}, {"question": "What are the components of lithium ion batteries?", "answer": "nanotubes", "ae_score": -0.7101346787066203, "qg_score": null}, {"question": "Where is titanium dioxide used in a lithium ion battery?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Nanyang Technological University used titanium dioxide in an anode and achieved 10,000 charging cycles. The battery can be charged to 70% in two minutes. They used a gel material made from titanium dioxide, an abundant, cheap and safe material found in soil. They developed a simple method to turn naturally spherical titanium dioxide particles into nanotubes. This nanostructure sped up the charging reaction.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Titanium dioxide", "_id": "12--0--1---1", "title": "How to Charge a Titanium Battery in Two Minutes"}
{"qas": [{"question": "How do lithium ion batteries work?", "answer": ""}, {"question": "What is the energy density of pure lithium-ion batteries?", "answer": "400%", "ae_score": -0.5782095301801747, "qg_score": null}, {"question": "What is the main benefit of lithium ion batteries?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Lithium anodes have been used for the first lithium-ion batteries in the previous century, based on the  cell chemistry, but were eventually abandoned due to dendrite formation, causing internal short-circuits and fire hazard. In 2014, researchers at Stanford University discovered that a pure-lithium anode increased energy density 400%. Researchers claimed that the anode did not expand during charging. This is done by building nanospheres, which are protective layers of interconnected carbon domes on top of the anode.\nAlso in 2014, a second technique was announced by Cornell University researchers that added halogenated lithium salts to the liquid electrolyte. This prevented the formation of battery-destroying metal dendrites as the battery went through charge/discharge cycles.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Lithium", "_id": "12--0--2---1", "title": "Lithium Anodes Are Increasing Energy Density 400%"}
{"qas": [{"question": "What is Raman spectroscopy and why is it significant?", "answer": ""}, {"question": "How much more energy density does a lithium ion battery have?", "answer": "60%", "ae_score": -0.4550677417054802, "qg_score": null}, {"question": "What type of lithium ion battery is made from porous g graphene?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Oak Ridge National Laboratory developed an anode from modified carbon black from discarded tires. The new technology is environmentally friendly. It also has a higher energy density.\nIn 2014, researchers at University of California, Riverside developed a battery that charges up to 16 times faster with 60% additional energy density. They use a three-dimensional, cone-shaped cluster of carbon nanotubes.\nThat same year, researchers at Northwestern University found that metallic single-walled carbon nanotubes (SWCNTs) accommodate lithium much more efficiently than their semiconducting counterparts. If made denser, semiconducting SWCNT films take up lithium at levels comparable to metallic SWCNTs.\nIn 2015, researchers examined the feasibility of using carbon nanotubes decorated with mesoporous cobalt oxide (CNT@COO) as electrodes in a lithium-ion battery. They expected the porous structure of the cobalt oxide to enhance diffusion of the electrolyte into the electrode. Researchers synthesized the CNT@COO and confirmed the composition using Raman spectroscopy. They then performed electrochemical measurements using Swagelok-type cells, taking voltammetry measurements over numerous cycles. They found that the CNT@COO achieved theoretical capacity up to the second cycle, but decayed with successive cycles. While the material needs to be optimized, it demonstrates high electrochemical activity and a possible electrode material option for the future. These findings are significant because the same measurements can be performed on other metal oxides, offering a wider range of materials to use in lithium-ion batteries. \nHeating polystyrene packing peanuts to between 500 and 900 \u00b0C (932 to 1,652 \u00b0F) in an inert atmosphere, in either the presence or absence of a transition metal salt catalyst produced either nanoparticles or microsheets that made excellent anodes. The sheets were about one tenth the thickness of graphite anodes, reducing charging times and exhibiting less electrical resistance. Specific capacity reached 420 mAh/g, vs the theoretical 372 mAh/g maximum for graphite. The anodes survived 300 charging cycles without a significant capacity loss. The microsheets' porous structure exposed more contact area between the anode and the liquid electrolyte.\nIn 2015 researchers announced a one-step process for using natural silk to create 4.7% nitrogen-doped carbon-based nanosheets that reversibly 1865 mA h/g over 10,000 cycles with only a 9 percent capacity loss. The surface area  was ''S'': 2494 m/g, hierarchical pore volume was 2.28 cm/g. Capacitance reached 242 F/g and energy density was 102 W h/kg (48 W h/L).\nIn 2015 hydrogen-treated graphene nanofoam electrodes in LIBs showed higher capacity and faster transport. Chemical synthesis methods used in standard anode manufacture leave significant amounts of atomic hydrogen. Experiments and multiscale calculations revealed that low-temperature hydrogen treatment of defect-rich graphene can improve rate capacity. The hydrogen interacts with the graphene defects to open gaps to facilitate lithium penetration, improving transport. Additional reversible capacity is provided by enhanced lithium binding near edges, where hydrogen is most likely to bind. Rate capacities increased by 17-43% at 200 mA/g.\nIn 2015, researchers in China used porous graphene as the material for a lithium ion battery anode in order to increase the specific capacity and binding energy between lithium atoms at the anode. The properties of the battery can be tuned by applying strain. The binding energy increases as biaxial strain is applied.\nIn 2016 researchers pyrolized bee and cattail pollen to produce materials for an anode. Pyrolysis in an argon container produced pure carbon. The resulting carbon particles were heated at a lower temperature of around 300 \u00b0C (572 \u00b0F) in the presence of oxygen, which created pores in the carbon, increasing its energy capacity. In prototype devices at temperatures of 25 and 50 \u00b0C (77 and 122 \u00b0F) achieved gravimetric capacity of 590 mAh/g at 50 \u00b0C and 382 mAh/g at 25 \u00b0C.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Carbon", "_id": "12--0--3---1", "title": "Lithium-ion batteries: The future of lithium-ion battery technology"}
{"qas": [{"question": "Why can't we use nanowires to increase the life cycle of a cell?", "answer": ""}, {"question": "What is the expansion rate of silicon in lithium-ion batteries?", "answer": "400%", "ae_score": -0.2711495714598763, "qg_score": null}, {"question": "What is the benefit of using silicon and carbon in lithium ion batteries?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Silicon is an earth abundant element, and is fairly inexpensive to refine to high purity. When alloyed with lithium it has a theoretical capacity of ~3,600 milliampere hours per gram (mAh/g), which is nearly 10 times the energy density of graphite electrodes (372 mAh/g). One of silicon's inherent traits, unlike carbon, is the expansion of the lattice structure by as much as 400% upon full lithiation (charging). For bulk electrodes, this causes great structural stress gradients within the expanding material, inevitably leading to fractures and mechanical failure, which significantly limits the lifetime of the silicon anodes. In 2011, a group of researchers assembled data tables that summarized the morphology, composition, and method of preparation of those nanoscale and nanostructured silicon anodes, along with their electrochemical performance. Below are various structural morphologies attempted to overcome issue with silicon's intrinsic properties. \nIn 2016 researchers announced a method for caging 3 nm-diameter silicon particles in a shell of graphene. The particles were first coated with nickel. Graphene layers then coated the metal. Acid dissolved the nickel, leaving enough of a void within the cage for the silicon to expand. The particles broke into smaller pieces, but remained functional within the cages. The cages also prevented the silicon from reacting with the electrolyte.\nIn 2014 researchers encapsulated silicon nanoparticles inside carbon shells, and then encapsulated clusters of the shells with more carbon. The shells provide enough room inside to allow the nanoparticles to swell and shrink without damaging the shells, improving durability.\nIn 2015 researchers announced a flash heat treatment for fabricating silicon anodes that minimizes volume expansion while boosting the performance and cycle capability of lithium-ion batteries. The material delivered 1,000\u2009mAh/\u2009g for 2,275 cycles at 2\u2009A/g with increased energy capacity, by minimizing volume expansion.\nIn 2012 researchers announced a prototype using silicon nanowires to improve cycle life. Silicon nanowires can expand/contract without breaking. However, they are costly to make.\nIn 2014, Energ2 created a battery that blends silicon with carbon, claiming to increase energy density and offer five times greater cycle durability.\nIn 2015 a prototype electrode was demonstrated that consists of sponge-like silicon nanofibers increases Columbic efficiency and avoids the physical damage from silicon's expansion/contractions. The nanofibers were created by applying a high voltage between a rotating drum and a nozzle emitting a solution of tetraethyl orthosilicate (TEOS). The material was then exposed to magnesium vapors. The nanofibers contain 10 nm diameter nanopores on their surface. Along with additional gaps in the fiber network, these allow for silicon to expand without damaging the cell. Three other factors reduce expansion: a 1 nm shell of silicon dioxide; a second carbon coating that creates a buffer layer; and the 8-25 nm fiber size, which is below the size at which silicon tends to fracture.\nConventional lithium-ion cells use binders to hold together the active material and keep it in contact with the current collectors. These inactive materials make the battery bigger and heavier. Experimental binderless batteries do not scale because their active materials can be produced only in small quantities. The prototype has no need for current collectors, polymer binders or conductive powder additives. Silicon comprises over 80 percent of the electrode by weight. The electrode delivered 802 mAh/g after more than 600 cycles, with a Coulombic efficiency of 99.9 percent.\nIn 2014, researchers developed a silicon anode with an energy density above 1,100 mAh/g and a durability of 600 cycles, making their anode nearly three times more powerful and longer lasting than a typical commercial anode. They used porous silicon particles using ball-milling and stain-etching.\nIn 2013, researchers developed a battery with  three times the energy density of a conventional li-ion, and can be recharged in less time. It utilizes anodes made from porous silicon nanoparticles.\nIn 2014, researchers at University of California, Riverside announced an anode made from high-quartz sand collected from Cedar Creek Reservoir in Texas. They milled the sand to the nanometer scale and purified it, producing a similar color and texture to powdered sugar. Grinding salt and magnesium into the purified quartz and heating removed oxygen from the quartz, resulting in pure silicon with a porous, sponge-like consistency. After an extensive low current density activation process, at a discharge rate at C/2 tested over 1000 cycles, the half cell demonstrated a reversible capacity of 1024 mAh/g and a Coulombic efficiency of 99.1% using a lithium metal counter electrode.\nIn 2014, researchers at Pacific Northwest National Laboratory discovered that spongy silicon doubles the energy density of lithium-ion batteries. A mesoporous silicon sponge that is capable of being filled with silicon rather than the silicon expanding. Silicon typically expands to 400% during charging, with the new technology only expanding 30%\nIn 2013, researchers at Stanford University developed a battery that maintains high energy density through 5,000 cycles. They used silicon and conducting polymer hydrogel, a spongy substance similar to the material used in soft contact lenses and other household products. This process doesn't cause fires. It is also inexpensive.\nIn 2012, researchers at Stanford and SLAC developed a battery with superior durability. It maintains 85% of the energy density after 6,000 cycles. They are using a double-walled silicon nanotube coated with a thin layer of silicon oxide. This strong outer layer keeps the outside wall of the nanotube from expanding.\nIn 2011, researchers at State University of New York developed a silicon/magnesium oxide/graphite composite.\nIn 2011, researchers from Northwestern University developed a battery that increased cycle durability and energy density by up to a factor of ten. They sandwiched clusters of silicon between graphene sheets. They used a redox process to create in-plane defects (10 to 20 nanometers) in the graphene sheets so the lithium ions would have a \"shortcut\" into the anode and be stored there by reaction with silicon.\nIn 2011, researchers at United States Department of Energy national laboratories developed a battery anode that can absorb eight times the amount of lithium. The polymer binds closely to silicon particles while they expand and shrink.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Silicon", "_id": "12--0--4---1", "title": "Silicon Nanostructures \u2014 The Future of Battery Technology"}
{"qas": [{"question": "How do tin batteries work?", "answer": ""}, {"question": "When did the tin battery come out?", "answer": "2013", "ae_score": -0.5659208910156267, "qg_score": null}, {"question": "What property of a lithium ion battery is made possible by the tin electrodes?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2013, researchers at Washington State University developed a tin electrode technology that they predicted would triple the energy density of lithium ion batteries. The technology involves using standard electroplating processes to create tin nanoneedles that do not short circuit when the tin expands by one third during charging.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Tin", "_id": "12--0--5---1", "title": "Tin Electrode Technology Could Triple the Energy Density of Lithium Ion Batteries"}
{"qas": [{"question": "How does a nanowire battery work?", "answer": ""}, {"question": "What is the name of the lithium-ion battery invented by stanford university?", "answer": "nanowire battery", "ae_score": -0.3738875918232919, "qg_score": null}, {"question": "What type of material is used in lithium ion batteries?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "In 2007, researchers at Stanford University invented the nanowire battery, which improved battery performance. It uses nanowires to increase the surface area of one or both electrodes. Both replace the traditional graphite anode. One uses silicon, while the other uses germanium.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Nanowire", "_id": "12--0--6---1", "title": "Nanowire Battery \u2014 A New Way to Improve Battery Performance"}
{"qas": [{"question": "How do batteries last so long?", "answer": ""}, {"question": "How much energy density does a lithium ion battery retain after 10,000 charge-dis?", "answer": "76%", "ae_score": -0.21607302780067486, "qg_score": null}, {"question": "What property of a lithium-ion battery is it able to retain?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Rice University announced a method to create a flexible, long-lasting battery. They used nanoporous nickel(II) fluoride electrodes layered around a solid electrolyte without using lithium. The device retained 76% of its energy density after 10,000 charge-discharge cycles and 1,000 bending cycles.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Nickel-fluoride", "_id": "12--0--7---1", "title": "Long-Term Battery \u2014 A Nanoporous Nickel(II) Fluoride"}
{"qas": [{"question": "How do solid state 3D batteries work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2006", "ae_score": -0.4253289565133518, "qg_score": null}, {"question": "What is the name of the inky slurry in which lithium-ion batteries are?", "answer": "cathode", "ae_score": null, "qg_score": null}], "content": "In 2006, researchers developed a battery using nanotechnology that improves energy density by several times. Active materials are applied in a very thin film to copper nanorods anchored to sheets of copper foil The nanorods supply 50 cm of active material per cm of substrate.\nIn 2015 researchers announced a solid-state 3-D battery annode made of copper antimonide. It is electroplated onto a copper foam. The anode is then layered with a solid polymer electrolyte that provides a physical barrier across which ions (but not electrons) can travel. The cathode is an inky slurry. The volumetric energy density was up to twice as much energy conventional batteries. The solid electrolyte prevents dendrite formation.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Copper", "_id": "12--0--8---1", "title": "Nanotechnology Improves Energy Density"}
{"qas": [{"question": "What is the difference between a rechargeable battery and a regular battery?", "answer": ""}, {"question": "When was the first lithium ion battery invented?", "answer": "2009", "ae_score": -0.6793254208971091, "qg_score": null}, {"question": "What is the main benefit of a lithium ion battery?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2009, researchers at MIT developed a battery using genetically engineered viruses to make a more environmentally friendly battery. In 2015, another MIT group announced a flexible, puncture-resilient battery with fewer, thicker electrodes that used a semisolid aqueous suspension lithium-iorn-phosphate (LFP)/lithium-titanium-phosphate (LTP) to achieve higher energy density than a conventional aqueous vanadium-redox flow battery. Using suspended particles instead of solid slabs greatly reduces the tortuosity (path length of charged particles as they move through the material).", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Iron-phosphate", "_id": "12--0--9---1", "title": "The Future of Battery Energy"}
{"qas": [{"question": "What is the difference between a solid state battery and a liquid state battery?", "answer": ""}, {"question": "Who made the first lithium ion battery in 2015?", "answer": "SolidEnergy", "ae_score": -0.2710575996283692, "qg_score": null}, {"question": "What does lithium metal have in common with other lithium ion batteries?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Historically, lithium metal was used only for non-rechargeable cells, because it tends to react with the electrolyte, trapping the lithium ions and preventing more and more of them from participating in future charge/discharge cycles. The reaction also creates dendrites, metal spikes that can cause short circuits and heating that can ignite the flammable electrolyte. Lithium metal remains a subject of interest because of its potential to increased energy density by 2x or more.\nIn 2015, an MIT spinoff company, SolidEnergy, demonstrated a battery that uses a thin sheet of lithium-metal foil. The company claimed to have solved multiple issues, including safety and lifetime.\nSolidEnergy uses a combination of solid and liquid electrolytes. The solid electrolyte is applied to the lithium-metal foil\u2014the ions don\u2019t have far to travel through this thin material, so it does not matter that they move relatively slowly. Once through the solid electrolyte, they reach a non-flammable liquid electrolyte, which ferries them to the opposite electrode. The electrolyte has additives that prevent the lithium metal from reacting with it and that prevent dendrites.\nSolidEnergy\u2019s technology does not require new manufacturing equipment and can be recharged 300 times while retaining 80 percent of its storage capacity. It works at room temperature, whereas some other lithium-metal batteries operate at much higher temperatures.\nIn 2014 Seeo demonstrated a prototype of a solid-state battery, replacing the traditional liquid electrolyte with two polymer layers. One is soft and conducts ions; the other is hard and prevents dendrite formation. Battery charge cycling had yet to be assessed.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Lithium metal foil", "_id": "12--0--10---1", "title": "SolidEnergy\u2019s Lithium-Metal Foil Battery Can Increase Energy"}
{"qas": [{"question": "How does lithium-ion batteries work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2015", "ae_score": -0.6012016992237014, "qg_score": null}, {"question": "What type of device is used in lithium ion batteries?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "In 2015  an anode made from aluminum/titanium \"yolk-and-shell\" nanoparticles was introduced. The nanoparticles have a solid titanium outer shell and an inner aluminum \"yolk\" that can expand and contract within the shell, storing and releasing ions without damaging the structure of the electrode. Like lithium or silicon, aluminum can store much more energy per unit weight than graphite.\nProduction involved placing 50 nm-diameter aluminum particles in a solution of sulfuric acid and titanium oxysulfate. This coated the nanoparticles in a hard titanium shell three to four nanometers thick. A few hours in the acid shrank the aluminum particles to about 30 nanometers without affecting the outer shell. This gave the aluminum nanoparticles room to expand considerably as they absorbed lithium, without damaging the cell's electric contacts. The anode can reportedly store 1.2 Ah/g at a normal charging rate, declining to 0.66 Ah/g at a higher rate.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Anode", "sub_heading": "Aluminum/titanium", "_id": "12--0--11---1", "title": "Aluminum Nanoparticles Can Store More Energy Than Graphite Nanoparticles"}
{"qas": [{"question": "How do car batteries work?", "answer": ""}, {"question": "What type of lithium ion battery is Subaru using?", "answer": "vanadium", "ae_score": -0.23398686375651742, "qg_score": null}, {"question": "What is the main difference between a lithium ion battery and a car battery?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2007, Subaru introduced a battery with double the energy density while only taking 15 minutes for an 80% charge. They used vanadium, which is able to load two to three times more lithium ions onto the cathode.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Cathode", "_id": "12--1--0---1", "title": "Subaru\u2019s new battery uses vanadium, which is able to charge 80% more"}
{"qas": [{"question": "How can cobalt be used to make lithium-ion batteries?", "answer": ""}, {"question": "When was cobalt added to lithium oxide crystal structure?", "answer": "2014", "ae_score": -0.43702587166343965, "qg_score": null}, {"question": "What does cobalt add to lithium oxide crystal structure?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at the School of Engineering at the University of Tokyo and Nippon Shokubai discovered that adding cobalt to the lithium oxide crystal structure gave it seven times the energy density.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Cobalt", "_id": "12--1--1---1", "title": "Adding Cobalt to Lithium Oxide Gives It Seven Times the Energy Den"}
{"qas": [{"question": "How do carbon-based batteries work?", "answer": ""}, {"question": "Who developed the all carbon lithium battery?", "answer": "Rensselaer Polytechnic Institute", "ae_score": -0.6026260863570719, "qg_score": null}, {"question": "What type of lithium is used in a lithium battery?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Rensselaer Polytechnic Institute developed an all carbon battery that improves energy density and cycle durability. After over 1,000 charges, the battery showed highly stable performance. The new battery uses an anode and cathode made from graphene with metallic lithium and without cobalt.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Graphene/lithium metal", "_id": "12--1--2---1", "title": "New Carbon Battery Improves Energy Density and Cycle Durability"}
{"qas": [{"question": "How do lithium ion batteries work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2014", "ae_score": -0.48329029475108654, "qg_score": null}, {"question": "What is the main component of a lithium ion battery?", "answer": "cathode", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Massachusetts Institute of Technology found that creating lithium-ion batteries with disorder in the materials they are composed of achieved 660 watt-hours per kilogram at 2.5 volts.\nIn 2015 researchers blended powdered vanadium pentoxide with borate compounds at 900 C and quickly cooled the melt to form glass. The resulting paper-thin sheets were then crushed into a powder to increase their surface area. The powder was coated with reduced graphite oxide (RGO) to increase conductivity while protecting the electrode. The coated powder was used for the battery cathodes. Trials indicated that capacity was quite stable at high discharge rates and remained consistently over 100 charge/discharge cycles. Energy density reached around 1,000 watt-hours per kilogram and a discharge capacity that exceeded 300 mAh/g.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Disordered materials", "_id": "12--1--3---1", "title": "The Power of Lithium-ion Batteries"}
{"qas": [{"question": "What is graphene and why is it important?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2014", "ae_score": -0.8349606172977819, "qg_score": null}, {"question": "What property of a lithium-ion battery is superior to commercial cathodes?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at USC Viterbi School of Engineering used a graphite oxide coated sulfur cathode to create a battery with 800 mAh/g for 1,000 cycles of charge/discharge, over 5 times the energy density of commercial cathodes. Sulfur is abundant, low cost and has low toxicity. Sulfur has been a promising cathode candidate owing to its high theoretical energy density, over 10 times that of metal oxide or phosphate cathodes. However, sulfur's low cycle durability has prevented its commercialization. Graphene oxide coating over sulfur is claimed to solve the cycle durability problem. Graphene oxide high surface area, chemical stability, mechanical strength and flexibility.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Graphene oxide coated sulfur", "_id": "12--1--4---1", "title": "Graphite Oxide Coated Sulfur Battery"}
{"qas": [{"question": "How do batteries work in extreme temperatures?", "answer": ""}, {"question": "When did the first lithium ion battery come out?", "answer": "2012", "ae_score": -0.5906866641833413, "qg_score": null}, {"question": "Where is the lithium ion battery located in the body?", "answer": "electrode", "ae_score": null, "qg_score": null}], "content": "In 2012, researchers at A123 developed a battery that operates in extreme temperatures without the need for thermal management material. It went through 2,000 full charge-discharge cycles at 45 C while maintaining over 90% energy density. It does this using a nanophosphate positive electrode.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Nanophosphate", "_id": "12--1--5---1", "title": "A123\u2019s NanoPhosphate Positive Electrode Boosts Energy in Extrem"}
{"qas": [{"question": "What are transition metal oxides and how do they work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2000", "ae_score": -0.582185164858763, "qg_score": null}, {"question": "Cobalt, nickel, copper and iron are all types of which metal?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2000, researchers from the Universit\u00e9 de Picardie Jules Verne examined the use of nano-sized transition-metal oxides as cathode materials. The metals used were cobalt, nickel, copper and iron and they proved to have capacities of 700 mA h/g and maintain full capacity for 100 cycles. These promising results show that transition-metal oxides may be useful in ensuring the integrity of the lithium-ion battery over many discharge-recharge cycles. ", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Transition-metal Oxides", "_id": "12--1--6---1", "title": "Transition-Metal Oxides as Cathode Materials for Lithium-ion"}
{"qas": [{"question": "How do underwater batteries work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2012", "ae_score": -0.5736234716461842, "qg_score": null}, {"question": "What is the main difference between lithium-ion batteries and seawater?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2012, researchers at Polyplus Corporation created a battery with an energy density more than triple that of traditional lithium-ion batteries using seawater. It's energy density is 1,300 W\u00b7h/kg, which is a lot more than the traditional 400 W\u00b7h/kg. It has a solid lithium positive electrode and a solid electrolyte. It could be used in underwater applications.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Seawater", "_id": "12--1--7---1", "title": "Polyplus has created a lithium-ion battery with an energy density more than triple that"}
{"qas": [{"question": "How does purpurin work?", "answer": ""}, {"question": "What type of oxide is used in lithium ion batteries?", "answer": "lithium cobalt oxide", "ae_score": -0.3221605688161956, "qg_score": null}, {"question": "Purpurin oxide is a type of oxide of which metal?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2012, researchers at Rice University, The City College of New York and U.S. Army Research Laboratory found that using purpurin (1,2,4-Trihydroxyanthraquinone) in the cathode is more environmentally friendly than using the traditional lithium cobalt oxide.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Purpurin", "_id": "12--1--8---1", "title": "Purpurin is more environmentally friendly than lithium cobalt oxide"}
{"qas": [{"question": "How does wireless charging work?", "answer": ""}, {"question": "What is the current power density of the lithium-ion battery?", "answer": "7.4 W/cm/mm", "ae_score": -0.6026927062282172, "qg_score": null}, {"question": "What property of a lithium-ion battery is improved?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2011, researchers at University of Illinois at Urbana-Champaign discovered that wrapping a thin film into a three-dimensional nanostructure can decrease charge time by a factor of 10 to 100. The technology is also capable of delivering a higher voltage output. In 2013, the team improved the microbattery design, delivering 30 times the energy density 1,000x faster charging. The technology also delivers better power density than supercapacitors. The device achieved a power density of 7.4 W/cm/mm.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Three-dimensional nanostructure", "_id": "12--1--9---1", "title": "Microbattery Technology Delivers 1,000x Faster Charging Than Supercapacitors"}
{"qas": [{"question": "Why do car batteries have such low energy density?", "answer": ""}, {"question": "When was the first lithium ion battery invented?", "answer": "2009", "ae_score": -0.6570922439313654, "qg_score": null}, {"question": "What is the difference between a lithium nickel manganese cobalt oxide cathode and?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2009, researchers at Nissan announced a lithium nickel manganese cobalt oxide cathode (NMC). The new battery offered twice the energy density.\nIn 2009, scientists at Massachusetts Institute of Technology created nanoball batteries that increased charge rates 100 times. They are capable of a 10-second re-charge of a cell phone battery and a 5-minute re-charge of an electric car battery. The cathode is composed of nanosized balls of lithium iron phosphate. The rapid charging is because the nanoballs transmit electrons to the surface of the cathode at a much higher rate. The batteries have also shown higher energy density, power density and cycle durability.\nA \u201clithium orthosilicate-related\u201d cathode compound,  , was able to support a charging capacity of 335 mAh/g. LiMnSiO@C porous nanoboxes were synthesized via a wet-chemistry solid-state reaction method. The material displayed a hollow nanostructure with a crystalline porous shell composed of phase-pure LiMnSiO nanocrystals. Powder X-ray diffraction patterns and transmission electron microscopy images revealed that the high phase purity and porous nanobox architecture were achieved via monodispersed MnCO@SiO core\u2013shell nanocubes with controlled shell thickness.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Lithium", "_id": "12--1--10---1", "title": "Research in lithium-ion batteries | Cathode | Lithium"}
{"qas": [{"question": "How does a nanowire work?", "answer": ""}, {"question": "What is the cathode of a lithium ion battery?", "answer": "air", "ae_score": -0.4281812425393188, "qg_score": null}, {"question": "What property of a lithium-ion battery is measured by its surface area?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2013, researchers at MIT used a genetically modified virus called M13 to create crosslinked manganese oxide nanowire electrodes covered in spikes that more than double the surface area of the electrode along with its energy density. 3-5 weight-percent palladium increases conductivity. This room temperature process is water-based. Specific capacity of 7,340\u2009mAh/\u2009gc+catalyst) of  specific energy at 0.4\u2009A/\u2009gc.\nIn 2009, researchers at the University of Dayton Research Institute announced a solid-state battery with higher energy density that uses air as its cathode. When fully developed, the energy density could exceed 1,000 Wh/kg.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Air", "_id": "12--1--11---1", "title": "Energy-Dense Solid-State Batteries"}
{"qas": [{"question": "Why do lithium ion batteries last longer than other types of batteries?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2014", "ae_score": -0.4786833216269891, "qg_score": null}, {"question": "What property of a lithium-ion battery is determined by the rearrangement of oxygen?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Brookhaven National Laboratory conducted three studies that concluded the usage of nanoscale coatings and other methods could be used to improve the cycle durability of batteries.\nIn 2014, researchers at Nissan announced a new analytic technique to allow them to observe how cathodes operate.\nIn 2014, researchers at Helmholtz-Zentrum Berlin found that a lithium-rich cathode material () could be charged and discharged rapidly or at higher currents. In the formula, \"M\" stands for a transition metal. The material had twice the regular amount of lithium and smaller amounts of rare, toxic elements like nickel and cobalt. The technique allowed them to determine that the battery's rapid energy density drop was due to the rearrangement of oxygen atoms.\nIn 2014, researchers at Technical University of Munich used a neutron beam to observe when metallic lithium forms during charging without cutting the battery open. Metallic lithium formations lead to a reduced cycle durability and short circuits.\nIn 2014, researchers at Michigan Technological University discovered atomic shuffling when using transmission electron microscopy. They took a closer look at how the ions move into and out of the anode causing stress.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Cathode", "sub_heading": "Analysis technique", "_id": "12--1--12---1", "title": "The Best of 2014 \u2014 The Best of 2014 \u2014 The Best of 2014"}
{"qas": [{"question": "How do lithium ion batteries work?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2015", "ae_score": -0.4771568808201855, "qg_score": null}, {"question": "Where are lithium nitrate and lithium polysulfide found in a battery?", "answer": "electrode", "ae_score": null, "qg_score": null}], "content": "In 2015 researchers announced that a mixture of lithium nitrate and lithium polysulfide formed a solid and stable interface between the electrode and the electrolyte and that it prevented dendrite formation. The prototype device ran with 99 percent efficiency over 300 charging cycles.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Electrolyte", "_id": "12--2--0---1", "title": "Lithium nitrate and Lithium Polysulfide"}
{"qas": [{"question": "How do batteries know when to stop charging?", "answer": ""}, {"question": "Who created the first lithium ion battery?", "answer": "Stanford University", "ae_score": -0.7944656811082074, "qg_score": null}, {"question": "Where is the copper nanolayer located in a lithium-ion battery?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Stanford University discovered that adding a copper nanolayer to the electrolyte can detect fires by responding to a drop in the voltage caused by a dendrite, most likely formed during charging.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Copper", "_id": "12--2--1---1", "title": "Detecting fires by adding a copper nanolayer to an electrolyte"}
{"qas": [{"question": "What is Kevlar and how does it work?", "answer": ""}, {"question": "What is the name of the spin-off company that is trying to develop and commercial?", "answer": "Elegus Technologies", "ae_score": -0.22155642946679802, "qg_score": null}, {"question": "What type of ions are in a kevlar membrane?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2015 a battery using a separator membrane made of nanofibers extracted from Kevlar was demonstrated. It prevents dendrite growth because its pores are only 15-20 nm across, smaller than dendrites' 20- to 50-nm nanoscale tips, but large enough to allow individual lithium ions to pass. The membrane can be much thinner than existing separators. Kevlar is an insulator and offers good heat resistance. The university has founded a spin-off company, Elegus Technologies, to further develop and commercialize the technology. Production is expected to begin toward the end of 2016.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Kevlar", "_id": "12--2--2---1", "title": "Kevlar Separator Membrane \u2014 The Future of Lithium Batteries"}
{"qas": [{"question": "How do electrolyte batteries last so long?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2014", "ae_score": -0.5697910204342532, "qg_score": null}, {"question": "What property does pfe have in lithium-ion batteries?", "answer": "cycle durability", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at University of North Carolina found a way to replace the electrolyte\u2019s flammable organic solvent with nonflammable perfluoropolyether (PFPE). PFPE is usually used as an industrial lubricant, e.g., to prevent marine life from sticking to the ship bottoms. The material exhibited unprecedented high transference numbers and low electrochemical polarization, indicative of a higher cycle durability.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Perfluoropolyether", "_id": "12--2--3---1", "title": "PFPE is a nonflammable organic solvent for marine lubricants"}
{"qas": [{"question": "How does chewing gum work?", "answer": ""}, {"question": "When was chewing gum developed for use in batteries?", "answer": "2014", "ae_score": -0.4854221149619581, "qg_score": null}, {"question": "Chewing gum could replace what in lithium-ion batteries?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at Washington State University developed a chewing gum like substance that may replace liquid electrolytes. This new material contains liquid, but is sticky, which eliminates the fire hazard. This material is flexible, suggesting use in bendable electronics in the future.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Sticky", "_id": "12--2--4---1", "title": "The Future of Electronics"}
{"qas": [{"question": "Why are solid state batteries better than conventional batteries?", "answer": ""}, {"question": "When was the first lithium ion battery made?", "answer": "2015", "ae_score": -0.34868770885550104, "qg_score": null}, {"question": "What are the components of a lithium ion battery?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "While no solid-state batteries have reached the market, multiple groups are researching this alternative. The notion is that solid-state designs are safer because they prevent dendrites from causing short circuits. They may have other benefits ranging from lower temperature operation to increased energy density.\nIn 2015 researchers announced an electrolyte using superionic lithium-ion conductors, which are compounds of lithium, germanium, phosphorus and sulfur.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Solid-state", "_id": "12--2--5---1", "title": "Solid-State Batteries Could Be a Better Alternative to Lithium-Ion"}
{"qas": [{"question": "How did the Lithium Ion battery work?", "answer": ""}, {"question": "When was the first lithium ion battery developed?", "answer": "2015", "ae_score": -0.6287403275156022, "qg_score": null}, {"question": "What type of metal is used in lithium ion batteries?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "In 2015 researchers announced a new electrolyte completely eliminates dendrites and promises to increase battery efficiency and vastly improve current carrying capacity.\nThe material was 99% efficient and was compatible with a lithium metal anode. The electrolyte used lithium bis(fluorosulfonyl)imide salt, an organosilicon compound added to the solvent dimethoxyethanein. Instead of dendrites, the electrode developed a thin sheet of lithium nodules that did not extend into the electrolyte and risk short-circuiting the battery. The device survived more than 1,000 charge/discharge cycles producing 98.4 percent of its initial charge, with a current of around 4 milliamps per square centimeter.<ref name=Colin/>\nIn 2015, researchers worked with a lithium carbon fluoride battery. They incorporated a solid lithium thiophosphate electrolyte wherein the electrolyte and the cathode worked in cooperation, resulting in capacity 26 percent. Under discharge, the electrolyte generates a lithium fluoride salt that further catalyzes the electrochemical activity, converting an inactive component to an active one. More significantly, the technique was expected to substantially increase battery life.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Lithium", "_id": "12--2--6---1", "title": "New Electrolyte Improves Battery Efficiency"}
{"qas": [{"question": "How do superhalogens work?", "answer": ""}, {"question": "What is the toxic chemical in lithium-ion batteries?", "answer": "halogens", "ae_score": -0.40870756679235853, "qg_score": null}, {"question": "Where does the lithium ion battery come from?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "Conventional electrolytes generally contain halogens, which are toxic. In 2015 researchers claimed that these materials could be replaced with non-toxic superhalogens with no compromise in performance. In superhalogens the vertical electron detachment energies of the moieties that make up the negative ions are larger than those of any halogen atom. The researchers also found that the procedure outlined for Li-ion batteries is equally valid for other metal-ion batteries, such as sodium-ion or magnesium-ion batteries.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Electrolyte", "sub_heading": "Superhalogen", "_id": "12--2--7---1", "title": "Superhalogens can be replaced with non-toxic electrolytes with no compromise in performance"}
{"qas": [{"question": "How does wireless charging work?", "answer": ""}, {"question": "What is the name of the technology that storedot is working on that will enable?", "answer": "multifunction electrode", "ae_score": -0.20557574982703908, "qg_score": null}, {"question": "What property of a lithium-ion battery can be improved by increased charge speed?", "answer": "cycle durability", "ae_score": null, "qg_score": null}], "content": "In 2014, researchers at MIT, Sandia National Laboratories, Samsung Advanced Institute of Technology America and Lawrence Berkeley National Laboratory discovered that uniform charging could be used with increased charge speed to speed up battery charging. This discovery could also increase cycle durability to ten years. Traditionally slower charging prevented overheating, which shortens cycle durability. The researchers used a particle accelerator to learn that in conventional devices each increment of charge is absorbed by a single or a small number of particles until they are charged, then moves on. By distributing charge/discharge circuitry throughout the electrode, heating and degradation could be reduced while allowing much greater power density.\nIn 2014, researchers at Qnovo developed software for a smartphone and a computer chip capable of speeding up re-charge time by a factor of 3-6, while also increasing cycle durability. The technology is able to understand how the battery needs to be charged most effectively, while avoiding the formation of dendrites.\nIn 2014, StoreDot announced it had started working on a technology called multifunction electrode (MFE), that will enable future electric vehicles to fully charge in only 5 minutes. The MFE is a combination of a conductive polymer and metal oxide.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Design and management", "sub_heading": "Design and management", "_id": "12--3--0---1", "title": "Accelerating Battery Charging"}
{"qas": [{"question": "How do we know how much battery life is in an electronic device?", "answer": ""}, {"question": "What is the name of the device that makes li-ion batteries flexible, bendable?", "answer": "Miura fold", "ae_score": -0.32577706086443337, "qg_score": null}, {"question": "What part of the battery is used in lithium ion batteries?", "answer": "electrode", "ae_score": null, "qg_score": null}], "content": "In 2014, independent researchers from Canada announced a battery management system that increased cycles four-fold, that with specific energy of 110 \u2013 175 Wh/kg using a battery pack architecture and controlling algorithm that allows it to fully utilize the active materials in battery cells. The process maintains lithium-ion diffusion at optimal levels and eliminates concentration polarization, thus allowing the ions to be more uniformly attached/detached to the cathode. The SEI layer remains stable, preventing energy density losses.\nIn 2016 researchers announced a reversible shutdown system for preventing thermal runaway. The system employed a thermoresponsive polymer switching material. This material consists of electrochemically stable, graphene-coated, spiky nickel nanoparticles in a polymer matrix with a high thermal expansion coefficient. Film electrical conductivity at ambient temperature was up to 50\u2009S\u2009cm\u22121. Conductivity decreases within one second by 10-10 at the transition temperature and spontaneously recovers at room temperature. The system offers 103\u2013104x greater sensitivity than previous devices.\nIn 2014, multiple research teams and vendors demonstrated flexible battery technologies for potential use in textiles and other applications.\nOne technique made li-ion batteries flexible, bendable, twistable and crunchable using the Miura fold. This discovery uses conventional materials and could be commercialized for foldable smartphones and other applications.\nAnother approached used carbon nanotube fiber yarns. The 1 mm diameter fibers were claimed to be lightweight enough to create weavable and wearable textile batteries. The yarn was capable of storing nearly 71 mAh/g. Lithium manganate (LMO) particles were deposited on a carbon nanotube (CNT) sheet to create a CNT-LMO composite yarn for the cathode. The anode composite yarns sandwiched a CNT sheet between two silicon-coated CNT sheets. When separately rolled up and then wound together separated by a gel electrolyte the two fibers form a battery. They can also be wound onto a polymer fiber, for adding to an existing textile. When silicon fibers charge and discharge, the silicon expands in volume up to 300 percent, damaging the fiber. The CNT layer between the silion-coated sheet buffered the silicon's volume change and held it in place.\nA third approach produced rechargeable batteries that can be printed cheaply on commonly used industrial screen printers. The batteries used a zinc charge carrier with a solid polymer electrolyte that prevents dendrite formation and provides greater stability. The device survived 1,000 bending cycles without damage.\nA fourth group created a device that is one hundredth of an inch thick and doubles as a supercapacitor. The technique involved etching a 900 nanometer-thick layer of Nickel(II) fluoride with regularly spaced five nanometer holes to increase capacity. The device used an electrolyte made of potassium hydroxide in polyvinyl alcohol. The device can also be used as a supercapacitor. Rapid charging allows supercapacitor-like rapid discharge, while charging with a lower current rate provides slower discharge. It retained 76 percent of its original capacity after 10,000 charge-discharge cycles and 1,000 bending cycles. Energy density was measured at 384 Wh/kg, and power density at 112 kW/kg.\nCurrent research has been primarily focused on finding new materials and characterizing by means of specific capacity (mAh/'''g'''), which provides a good metric to compare and contrast all electrode materials.  Recently, some of the more promising materials are showing some large volume expansions which need to be considered upon engineering devices.  Lesser known to this realm of data is the volumetric capacity (mAh/'''cm''') of various materials to their design.", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Design and management", "sub_heading": "Management", "_id": "12--3--1---1", "title": "The Future of Battery Technology: Volumetric Capacity"}
{"qas": [{"question": "How do we know carbon nanotubes and nanowires exist?", "answer": ""}, {"question": "What type of sensors are being integrated into lithium-ion batteries?", "answer": "Nanosensors", "ae_score": -0.2425273756519942, "qg_score": null}, {"question": "What part of the battery is used in lithium ion batteries?", "answer": "electrode", "ae_score": null, "qg_score": null}], "content": "Researchers have taken various approaches to improving performance and other characteristics by using nanostructured materials. One strategy is to increase electrode surface area. Another is to reduce the distance between electrodes to reduce transport distances. A third is to allow the use of materials that exhibit unacceptable flaws when use in bulk forms, such as silicon.\nFinally, adjusting the geometries of the electrodes, e.g., by interdigitating anode and cathode units variously as rows of anodes and cathodes, alternating anodes and cathodes, hexagonally packed 1:2 anodes:cathodes and alternating anodic and cathodic triangular poles. One electrode can be nested within another.\nCarbon nanotubes and nanowires have been examined for various purposes, as have aerogels and other novel bulk materials.\nFinally, various nanocoatings have been examined, to increase electrode stability and performance.\nNanosensors is now being integrated in to each cell of the battery. This will help to monitor the state of charge in real time which will be helpful not only for security reason but also be useful to maximise the use of the battery. ", "page_name": "Research in lithium-ion batteries", "page_id": "Research%20in%20lithium-ion%20batteries", "heading": "Nanotechnology", "sub_heading": "Nanotechnology", "_id": "12--4---1---1", "title": "Nanostructured Materials in Battery Technology"}
{"qas": [{"question": "How did EJF get involved in the fishing crisis in Cambodia?", "answer": ""}, {"question": "When was the environmental justice foundation founded?", "answer": "2000", "ae_score": -0.33279690138302764, "qg_score": null}, {"question": "When was the environmental justice foundation founded?", "answer": "2000", "ae_score": -0.33279690138302764, "qg_score": null}], "content": "The Environmental Justice Foundation was founded in London, UK in 2000 and became a Registered Charity in August 2001 by Steve Trent and Juliette Williams. EJF's creation was a response to the human suffering and environmental degradation that its founders witnessed in their work as environmental campaigners.\nThis experience had led both founders to conclude that the basic human rights of people in the world's poorest countries often depend on those people's access to a healthy environment for food, shelter and a means to make a living.\nEJF undertook its first campaign in 2001: defending a community's fishing rights in Cambodia. As a result of training and documentation programmes, a national network \u2013 the Fisheries Action Coalition Team \u2013 was founded. The Fisheries Action Coalition Team is a coalition of NGO consisting 12 NGOs, both local and international, which was localised from NGO Forum. A campaign report called Feast or Famine was produced and presented to policymakers at a meeting hosted by the British Ambassador to Cambodia, proving to be a catalyst for the issue in the country as well as securing international support.\nEJF expanded its work to encompass the pesticide endosulfan (2002), trafficking of  wildlife (2003), shrimp trawling and shrimp farming (2003), illegal, unreported and unregulated IUU fishing (2004), cotton production (2004) and climate refugees (2009).", "page_name": "Environmental Justice Foundation", "page_id": "Environmental%20Justice%20Foundation", "heading": "History", "sub_heading": "History", "_id": "13--0---1---1", "title": "Environmental Justice Foundation"}
{"qas": [{"question": "What does the UN Human Rights Council do?", "answer": ""}, {"question": "Which nobel prize winner founded the environmental justice foundation?", "answer": "Harold Pinter", "ae_score": -0.6718880927035338, "qg_score": null}, {"question": "Which nobel prize winner founded the environmental justice foundation?", "answer": "Harold Pinter", "ae_score": -0.6718880927035338, "qg_score": null}], "content": "According to the Impact Report 2008/09, the Environmental Justice Foundation pursues its goals through: investigation, campaigns, aiding grassroots action by communities in producer countries and catalysing consumer, business and governmental action internationally.\nIt sends its own reporters to investigate, document and compile reports of environmental and human rights abuses in the Global South. It also works on the ground to help train local groups in effective investigative and reporting  techniques to publicise abuses in their area and then advocate on those issues nationally and globally.\nEJF's work often takes it into partnership with other NGOs, national governments  and international bodies, businesses and corporations. It works with celebrity ambassadors to publicise its campaigns including its Patrons \u2013 artist Rachel Whiteread, actress Emilia Fox, writer Iain Banks, explorer Benedict Allen and model, actress and activist Lily Cole. Nobel Prize-winner Harold Pinter, CH, CBE was an EJF Patron from 2003 to 2008.", "page_name": "Environmental Justice Foundation", "page_id": "Environmental%20Justice%20Foundation", "heading": "Areas of work and EJF's approach", "sub_heading": "Areas of work and EJF's approach", "_id": "13--1---1---1", "title": "Environmental Justice Foundation | Areas of work and EJF's approach"}
{"qas": [{"question": "How does the European Justice Fund (EJF) work?", "answer": ""}, {"question": "How many signatures did the environmental justice foundation petition to the un in january 2011?", "answer": "10,000", "ae_score": -0.5521791925416144, "qg_score": null}, {"question": "How many signatures did the environmental justice foundation petition to the un in january 2011?", "answer": "10,000", "ae_score": -0.5521791925416144, "qg_score": null}], "content": "EJF campaigns directly at policy-makers including the European Commission, Parliament and United Nations organisations. In January 2011 EJF presented a petition of 10,000 signatures to the UN in 2011 calling for a Global Record on Fishing Vessels.", "page_name": "Environmental Justice Foundation", "page_id": "Environmental%20Justice%20Foundation", "heading": "Campaigns", "sub_heading": "Campaigns", "_id": "13--2---1---1", "title": "EJF campaigns directly at policy-makers including the European Commission, Parliament and UN organisations"}
{"qas": [{"question": "Why is the World Health Organization (WHO) so concerned about the use of pesticides and insecticides on cotton?", "answer": ""}, {"question": "Who is the founder of environmental justice foundation?", "answer": "Ravi Shankar", "ae_score": -0.09891738438817768, "qg_score": null}, {"question": "Who is the founder of environmental justice foundation?", "answer": "Ravi Shankar", "ae_score": -0.09891738438817768, "qg_score": null}], "content": "One of EJF's first programs was its campaign for national and ultimately a global ban on the manufacture and use of chemical pesticide endosulfan. Categorized by the United States Environmental Protection Agency as a \u2018highly hazardous' substance, endosulfan has been compared to DDT in its potential for environmental harm.\nEJF points out that pesticides such as endosulfan, that are banned or restricted in the EU, the US and other developed nations, are widely used in developing countries, where their harmful potential can be exacerbated by low levels safety awareness, inadequate labeling, illiteracy and poor access to safety equipment.\nEndosulfan is readily absorbed by humans via the stomach, lungs and skin where it can cause hormone disruption as well as being a neurotoxin, haematoxin and nephrotoxin.\nDuring its investigations, EJF has documented in a series of reports of acute medical symptoms linked to endosulfan among farmers and local populations. These symptoms include headache, nausea, breathing problems, renal problems, loss of consciousness, and seizures; numerous fatalities have been documented, particularly in West Africa .\nIn its reports EJF has expressed concern that, like DDT, endosulfan is persistent in the environment, where it is harmful to mammals, fish, bees, birds and other wildlife. Endosulfan use has led to the pollution and abandonment of agricultural land and it has been shown to bioaccumulate and travel long distances through air and water. In 2009 the Stockholm Convention's Scientific Committee acknowledged endosulfan as being a persistent organic pollutant.\nEJF began documenting the use of endosulfan in Cambodia in 2002 and published a report called Death in Small Doses in 2003.\nDeath in Small Doses, a report on the problems of and alternatives to pesticide use in Cambodia, was presented to Ministries in Cambodia, international donor agencies, media, business and NGOs as part of an advocacy strategy to raise public and political awareness.\nWorking with CEDAC (Centre d'Etude et de D\u00e9veloppement Agricole Cambodgien), a Cambodian NGO, EJF documented widespread use of endosulfan by Cambodian farmers and recorded numerous safety concerns, including a lack of protective equipment and exposure of children, homes, livestock and family food crops.\nLabelling inadequacies where endosulfan was being imported to Cambodia from Vietnam and Thailand were also highlighted in EJF's 2004 briefing paper \"End of the Road for Endosulfan\".\nAs part of EJF's work in Cambodia in 2002, the charity worked with Cambodian farmers to promote sustainable agriculture and educate them about risks of hazardous pesticides. A short briefing entitled End of the Road for Endosulfan  was used to convince the Cambodian Environment Minister to ban endosulfan in the country.\nThis briefing was later cited in the European Union's 2008 proposal to include endosulfan in the Annexes of the Stockholm Convention.\nIn 2007, EJF produced a report, Deadly Chemicals in Cotton following investigations that gathered evidence of hazardous pesticide use on cotton crops in Mali and India in 2006, which included documenting the medical impacts of the chemical.\nThe report, Deadly Chemicals in Cotton, was produced with the Pesticide Action Network UK to raise awareness of the human and environmental costs of pesticide use in West Africa, Uzbekistan and India.\nThe report also highlights the heavy reliance of cotton production on pesticides and insecticides: an average estimated eight times more per hectare on cotton crop than per hectare of food crop.  EJF reports that US$2 billion-worth (2007) are used on cotton crops each year, US$819 million-worth of which are classed as hazardous by the World Health Organisation according to the report. EJF characterises cotton as the world's dirtiest crop.\nIn 2009 EJF launched a new report with the same name as the 2004 briefing paper, 'End of the Road for Endosulfan'. This documents health and environmental impacts associated with endosulfan exposure and advocates alternatives available for all its uses, organic crops and the avoidance of chemical fertilisers and pesticides.\nIn 2009/10 EJF recruited high profile Indian celebrities, including film directors Deepa Mehta and M Night Shyamalan, and musician Ravi Shankar, to lend their support to the campaign.\nIn 2010, EJF was involved in securing a commitment from Bayer Cropscience to end its manufacture of endosulfan by the end of that year.\nIn 2011, EJF announced on their website that they were \"delighted to announce that, after extensive review and debate, we have finally reached the end of the road for chemical pesticide endosulfan\" following news that on Friday April 29, 2011, national delegates at the fifth conference of parties (COP5) agreed to list endosulfan under Annex A of the Stockholm Convention on Persistent Organic Pollutants (POPs).", "page_name": "Environmental Justice Foundation", "page_id": "Environmental%20Justice%20Foundation", "heading": "End of the Road for Endosulfan", "sub_heading": "End of the Road for Endosulfan", "_id": "13--3---1---1", "title": "End of the Road for Endosulfan \u2014 EJF"}
{"qas": [{"question": "How are black bears and sun bears kept alive in Vietnam?", "answer": ""}, {"question": "Who did the environmental justice foundation recruit to front a public service announcement?", "answer": "My Linh", "ae_score": -0.13549613040094244, "qg_score": null}, {"question": "Who did the environmental justice foundation recruit to front a public service announcement?", "answer": "My Linh", "ae_score": -0.13549613040094244, "qg_score": null}], "content": "EJF's stated objective for its wildlife campaign is to train and support investigators and advocates for wildlife in key conservation locations around the globe. It is particularly concerned that illegal trafficking of plants and animals for pets, trophies, food and traditional medicines, estimated to be worth $20 billion a year, has a detrimental effect on biodiversity and ecosystems and is pushing some species to the brink of extinction.\nThe campaign has so far concentrated on working in Vietnam where EJF report that a great diversity of wild species is under threat from the swift recent conversion to agriculture and building development. EJF believe that, Vietnam, although a signatory to CITES, lacks the manpower and legal framework to enforce domestic wildlife legislation. [ ]\nEJF first collaborated with the NGO Education for Nature Vietnam (ENV) in 2003 which was established in 2000 as Vietnam's first non-governmental organization focused on conservation of nature and wildlife, to combat illegal bear farming. EJF reports that estimated 4000 Asiatic black bears and sun bears are kept illegally in Vietnam's bear farms.  Adult bears are caged and their bile regularly extracted for the ursodeoxycholic acid it contains which is then used in traditional medicines and tonics.\nIn 2003, EJF provided ENV with video, media and advocacy training, a digital stills camera and a computer for film editing and design. It also gave advice and support on website development.\nIn 2004 EJF helped ENV to conduct undercover investigations into bear farms in and around Hanoi and undertake a consumer survey in preparation for a campaign to influence people's attitudes to bear farming. This included recruiting Vietnamese singer My Linh to front a public service announcement (PSA) shown on Vietnamese television. [ ]\nIn 2006-07, EJF continued training ENV in the use of film to produce another PSA, supplying a cameraman and editor to give assistance. The charity used funding from the World Society for the Protection of Animals to equip ENV with new computer and filming equipment and professional editing software.  Further video and media training for ENV was completed in 2008-09.\nAs a separate part of its wildlife campaign, EJF has committed to support the leading wildlife charity WildAid in their work to support protected areas, investigate illegal wildlife trade and reduce consumer demand. EJF and WildAid UK share a London office and Steve Trent, EJF's Executive Director is the President of WildAid.", "page_name": "Environmental Justice Foundation", "page_id": "Environmental%20Justice%20Foundation", "heading": "Wildlife", "sub_heading": "Wildlife", "_id": "13--4---1---1", "title": "EJF Wildlife Campaign"}
{"qas": [{"question": "Why do people migrate?", "answer": ""}, {"question": "Who are children left behind by when they migrate?", "answer": "their parents", "ae_score": -2.193290055520254, "qg_score": null}, {"question": "Who are children left behind by when they migrate?", "answer": "their parents", "ae_score": -2.193290055520254, "qg_score": null}], "content": "The motivations for children to migrate are as diverse as the individuals who migrate. They include economic reasons, educational aspirations, reasons related to gender or culture, personal motivations as well as emergencies, natural disasters and climate change, persecution and humanitarian crises. Some children leave in search of better opportunities while others escape violence, exploitation, abuse or conflict. Multiple reasons often coincide. When parents migrate or separate, children may move to another place or country with one or both parents, or they might be left behind by their parents and are then indirectly affected by migration.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Reasons for migration", "sub_heading": "Reasons for migration", "_id": "14--0---1---1", "title": "Why Children Migrate?"}
{"qas": [{"question": "What is the right to be heard?", "answer": ""}, {"question": "Who influences the information gathering process in asylum procedures?", "answer": "Interpreters", "ae_score": -0.7753304857348479, "qg_score": null}, {"question": "Who influences the information gathering process in asylum procedures?", "answer": "Interpreters", "ae_score": -0.7753304857348479, "qg_score": null}], "content": "The right to be heard is a child rights principle as defined by the UN Convention on the Rights of the Child. According to Article 12 of the Convention, children have the right to express their views in all matters affecting them, and their views have to be given due weight in accordance with the age and maturity of the child. This right applies equally to children\u2019s participation in social and political matters as well as in judicial and administrative proceedings. As a general principle, the child\u2019s right to be heard reflects the concept of children's \u2018agency\u2019, viewing children not only as vulnerable persons in need of special protection, but also as informed decision makers, rights holders and active members of society.\nMany children are reluctant to share information with the authorities in the country of destination due to fears that disclosing information might not be in their interest and that telling their story might lead to being returned to their country of origin. Children might have been instructed by third persons to reveal only certain parts of their story, there might be threats and fears of reprisals involved, and the child might not trust the police and local authorities will be able to protect them. A reception system that demonstrates respect and upholds the dignity of the child can achieve to foster a sense of trust in the child towards the officials and professionals whom she or he meets with. Interpreters might influence the information gathering process in asylum procedures and criminal investigations as they affect how the child\u2019s story is being understood and perceived. Inaccurate translation might compromise the child\u2019s statement, leading to decisions on the basis of incorrect information. This relates not only to the content translated but also to the style and semantic choices made by the child and how the interpreters convey the message.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Rights of children in migration and mobility", "_id": "14--1--0---1", "title": "The right to be heard: a child\u2019s right to be heard"}
{"qas": [{"question": "How do countries determine the life expectancy of a child?", "answer": ""}, {"question": "What is a central component of the best interests determination process?", "answer": "Risk and resilience assessments", "ae_score": -0.8831611370524833, "qg_score": null}, {"question": "What is a central component of the best interests determination process?", "answer": "Risk and resilience assessments", "ae_score": -0.8831611370524833, "qg_score": null}], "content": "Best interests is defined in Article 3 of the UN Convention on the Rights of the Child, which says that \u201cin all actions concerning children, whether undertaken by public or private social welfare institutions, courts of law, administrative authorities or legislative bodies, the best interests of the child shall be a primary consideration\u201d. Assessing the best interests of a child means to evaluate and balance \u201call the elements necessary to make a decision in a specific situation for a specific individual child or group of children\u201d. The right of the child to have her or his best interests taken as a primary consideration means that the child\u2019s interests have high priority and are not just one of several considerations. The assessment is specific to the child as an individual, making it important to establish a trust-based relationship with the child and to communicate effectively in a language that the girl or boy understands. The assessments ideally involves a multi-disciplinary team of qualified professionals.\nRisk and resilience assessments are a central component of the best interests\u2019 determination process because they consider the context of the countries of destination and origin and also how the risks and resiliency of the child will change on the basis of any decision taken.\nIn transnational cases, a comprehensive best interests\u2019 assessment and determination process considers the following:", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Best interests\u2019 assessment and determination", "_id": "14--1--1---1", "title": "Best interests\u2019 assessment and determination process in transnational cases"}
{"qas": [{"question": "How is the Convention on the Rights of the Child not discrimination?", "answer": ""}, {"question": "The convention on the rights of the child affords broad protection from what?", "answer": "discrimination", "ae_score": -0.5948797054641907, "qg_score": null}, {"question": "The convention on the rights of the child affords broad protection from what?", "answer": "discrimination", "ae_score": -0.5948797054641907, "qg_score": null}], "content": "The Convention on the Rights of the Child affords a broad protection from discrimination. It  stipulates that States Parties shall respect and ensure the rights set forth in the Convention to each child within their jurisdiction without discrimination of any kind, irrespective of the child\u2019s or his or her parent\u2019s or legal guardian\u2019s race, colour, sex, language, religion, political or other opinion, national, ethnic or social origin, property, disability, birth or other status.\nThe rights afforded under the Convention apply to non-national children, regardless of their immigration status or the migration status of their parents. This includes children who are visiting, refugees, children of migrant workers and undocumented children. The right to non-discrimination entitles each child to immediate assistance and support while the situation of the child and her or his best interests are being assessed. Non-discrimination does not imply that a child is granted an automatic permit of stay, but that a decision is taken on the basis of the best interests\u2019 determination, whether a child shall be returned or whether the country of destination assumes jurisdiction over the child.\nWhile assessing the child\u2019s case and situation, state authorities have a responsibility to clarify which state has the jurisdiction over a child and, if required and appropriate, transfer or establish jurisdiction in the country of destination. When jurisdiction over a non-national child remains unclear, the child risks staying in a state of uncertainty and might benefit only from temporary services and protection measures, until the child\u2019s status is fully regularised or the child returns to the country holding jurisdiction. Common factors that affect jurisdiction include: ", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Right to non-discrimination: Status, access and jurisdiction", "_id": "14--1--2---1", "title": "Non-Discrimination in the Child"}
{"qas": [{"question": "Why is it that when a child is born, they don't have the same physical needs as adults?", "answer": ""}, {"question": "What document provides for the right to life, survival and development?", "answer": "Convention on the Rights of the Child", "ae_score": -0.9235890213694883, "qg_score": null}, {"question": "What document provides for the right to life, survival and development?", "answer": "Convention on the Rights of the Child", "ae_score": -0.9235890213694883, "qg_score": null}], "content": "The rights of the child to life, survival and development is afforded under Article 6 of the Convention on the Rights of the Child. These rights are related to survival, security and health as a precondition for physical development as well as the mental, spiritual, moral, intellectual, cognitive, emotional and socio-cultural development of the child.\nThe quality of care has a direct effect on a child's development. Promoting the child\u2019s developmental rights and needs means enabling her to grow up in her family of origin or in a family-based or family-like alternative care placement, wherever this is in the best interests of the child. The care arrangements and access to quality services for health and education are important when assessing the child\u2019s developmental needs.\nThe following factors are relevant when assessing the development needs of a child (with reference to the relevant articles under the UN Convention on the Rights of the Child):", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Development", "_id": "14--1--3---1", "title": "Developmental Rights of the Child"}
{"qas": [{"question": "Why is it illegal for a child to be a witness to a crime?", "answer": ""}, {"question": "What standards apply to national children when they are in conflict with law?", "answer": "juvenile justice", "ae_score": -0.8077495792900975, "qg_score": null}, {"question": "What standards apply to national children when they are in conflict with law?", "answer": "juvenile justice", "ae_score": -0.8077495792900975, "qg_score": null}], "content": "Children on the move sometimes are affected by or are in conflict with the law, including with cross-border family disputes and matters of parental responsibility and contact, as asylum seekers or victims of crime and, in some cases, as children who are in conflict with the law for immigration matters or for illegal and criminal matters. Some children in conflict with the law are actually victims of crime. International and European law provide for clear standards regulating the treatment, rights and entitlement of children in contact with the judiciary, as victims, defendants or perpetrators of crime.\nThe UN Convention on the Rights of the Child prohibits the exploitation of children in any form and in any context (Articles 19, 32-36). Any child who is exposed to violence, exploitation or abuse can be considered a victim of crime and enjoys the correlated rights and entitlements, including access to assistance, protection and support, services for recovery and rehabilitation, access to justice, with due procedural safeguards in any related legal or administrative proceedings. Children at risk of exploitation should be identified as being at risk and referred to assistance and support in order to prevent their exploitation or any other harm.\nAn important safeguard for child victims of crime is the \u2018non-punishment clause\u2019. It means that child victims of criminal offences, including human trafficking, are to be protected from sanctions or prosecution for acts that they committed in relation to their situation as victims. The non-punishment clause protects children who are exploited in illegal or criminal activities and child victims of exploitation and/or trafficking who were forced to enter a country without valid travel documents.\nThe UN Guidelines on Justice in Matters involving Child Victims and Witnesses of Crime emphasise that \u201cchildren who are victims and witnesses may suffer additional hardship if mistakenly viewed as offenders when they are in fact victims and witnesses.\u201d  The Guidelines say child victims should be protected from prosecution irrespective of any form of \u2018consent\u2019 or their active involvement in an offence and irrespective of the child\u2019s age in relation to national laws defining the age of criminal liability. A child victim should be considered and treated as such \u201c... regardless of their role in the offence or in the prosecution of the alleged offender or groups of offenders\u201d.\nThe Office of the High Commissioner for Human Rights (OHCHR) Recommended Principles and Guidelines on Human Rights and Human Trafficking and the UNICEF Guidelines on the Protection of Child Victims of Trafficking reiterate the right to non-criminalisation specifically in relation to the situation of victims of trafficking who are to be protected from criminal liability for \u201cany criminal offence that was a direct result from being trafficked\u201d.  This provision is further strengthened by the non-punishment clause of the 2011 EU Anti-trafficking Directive and the Council of Europe Convention on Action against Trafficking in Human Beings, and is therefore made binding upon States Parties: \u201cEach Party shall, in accordance with the basic principles of its legal system, provide for the possibility of not imposing penalties on victims for their involvement in unlawful activities, to the extent that they have been compelled to do so.\u201d (Article 26).\nWhen a non-national child is in conflict with the law and there are no indication that the child has been exploited in illegal activities or has otherwise been victimised, the same standards of juvenile justice apply as for national children.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Access to justice", "_id": "14--1--4---1", "title": "Child Victims and Witnesses of Crime"}
{"qas": [{"question": "How does the United States protect the rights of children who are outside of their country of residence?", "answer": ""}, {"question": "When was the vienna convention on consular relations of the united nations established?", "answer": "1963", "ae_score": null, "qg_score": null}, {"question": "When was the vienna convention on consular relations of the united nations established?", "answer": "1963", "ae_score": null, "qg_score": null}], "content": "Children who are outside of their country of residence have a right to assistance by embassies and consular offices representing their country. Consular staff can play an important role in supporting and assisting children abroad, establishing supportive contacts and referral, and mobilising help. Consular staff may contact central authorities or national contact points for technical advice in cases involving children. Under the 1963 Vienna Convention on Consular Relations of the United Nations, consular functions include helping and assisting nationals of the sending state. This could involve measures to safeguard the interests of children who are nationals of the sending State within the limits imposed by the laws and regulations of the receiving State, particularly when a guardian needs to be appointed. The authorities of the country of destination must inform the competent consular office without delay when the appointment of a guardian for a child is considered. The laws and regulations of the receiving State concerning the appointment of a guardian apply and are not affected by the information sharing with the relevant consular offices.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Right to consular assistance", "_id": "14--1--5---1", "title": "Consular Services for Children in the United States"}
{"qas": [{"question": "What are the rights of migrant children in Europe?", "answer": ""}, {"question": "Along with iceland, norway and switzerland, what country has freedom of movement?", "answer": "Liechtenstein", "ae_score": null, "qg_score": null}, {"question": "Along with iceland, norway and switzerland, what country has freedom of movement?", "answer": "Liechtenstein", "ae_score": null, "qg_score": null}], "content": "All individuals, including parents, families with children and unaccompanied children, enjoy freedom of movement within the European area. In the European area of freedom of movement, citizens of EU Member States and the EFTA States Iceland, Liechtenstein, Norway and Switzerland are entitled to enter and reside in other EU Member States for a period of up to three months without registration and are granted a permit to stay when they can demonstrate an income. The rights of children as unaccompanied migrants in the European area of freedom of movement are not explicitly defined and the related institutional responsibilities remain unclear. The way that national governments interpret and regulate the rules of freedom of movement for unaccompanied children under 18 years of age differs among the countries.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Migration and mobility within the European Union", "_id": "14--1--6---1", "title": "Unaccompanied children in the European area of freedom of movement"}
{"qas": [{"question": "Why does the European Union allow children to seek asylum in the EU?", "answer": ""}, {"question": "What convention regulates the right of persons to seek international protection?", "answer": "The UN Refugee Convention", "ae_score": -0.8167761297376726, "qg_score": null}, {"question": "What convention regulates the right of persons to seek international protection?", "answer": "The UN Refugee Convention", "ae_score": -0.8167761297376726, "qg_score": null}], "content": "The UN Refugee Convention and its Protocol regulate the right of persons to seek international protection. Children enjoy special safeguards and have a right to have their asylum application examined individually. Child-specific grounds of persecution need to be considered irrespective of whether the child applies alone or together with a parent or caregiver. The European Union Member States have re-elaborated these standards for the EU context and have adopted a series of Directives regulating the qualification and reception conditions of asylum seekers in the EU as well as asylum procedures and matters of return.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Rights of children in migration and mobility", "sub_heading": "Asylum", "_id": "14--1--7---1", "title": "Asylum seekers in the European Union"}
{"qas": [{"question": "What is the difference between vulnerability and child protection?", "answer": ""}, {"question": "What are children on the move referred to as?", "answer": "vulnerable", "ae_score": -1.2846893338364507, "qg_score": null}, {"question": "What are children on the move referred to as?", "answer": "vulnerable", "ae_score": -1.2846893338364507, "qg_score": null}], "content": "Children on the move are routinely referred to as \u2018vulnerable\u2019 although the meaning of the term has not been defined or clarified for the child protection context. Vulnerability is often understood as a deficit and equated with weakness and a need of protection. From a child rights-based approach, vulnerability refers to the limited chances of a child to fully exercise her or his rights as afforded under the UN Convention on the Rights of the Child. Existing definitions of vulnerability that are in use in the context of poverty reduction, health and nutrition can be useful in the child protection context.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Vulnerability", "sub_heading": "Vulnerability", "_id": "14--2---1---1", "title": "Vulnerability in the Child Protection context"}
{"qas": [{"question": "Why do so many people migrate to other countries?", "answer": ""}, {"question": "How can children and young adults support their families?", "answer": "remittances", "ae_score": -1.478691841900049, "qg_score": null}, {"question": "How can children and young adults support their families?", "answer": "remittances", "ae_score": -1.478691841900049, "qg_score": null}], "content": "Some children migrate well-protected and cared for and some succeed to achieve the goals that motivated their journeys. When migration is safe and successful, children have opportunities to increase their well-being, to access higher-quality services and to benefit from better education. Safe migration opportunities can support children significantly in their transition into adulthood and an independent life. They will have improved life chances, including in their transition into adulthood and the labour market, with better working conditions, higher salaries and an increased potential to contribute proactively to their communities and societies, in countries of origin and destination. Children and young adults might support their families through remittances and support the development of their communities of origin.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Safe migration", "sub_heading": "Safe migration", "_id": "14--3---1---1", "title": "Safe migration opportunities can support children in their transition into adulthood and an independent life"}
{"qas": [{"question": "Why are there so many children on the move?", "answer": ""}, {"question": "Along with prostitution, what is another form of child exploitation?", "answer": "pornography", "ae_score": -2.1511835909619066, "qg_score": null}, {"question": "Along with prostitution, what is another form of child exploitation?", "answer": "pornography", "ae_score": -2.1511835909619066, "qg_score": null}], "content": "Children on the move are at risk of different forms of exploitation. They include sexual exploitation in prostitution and pornography, including by travelling sex offenders, through web-cams, child abuse images and illegal content on the internet. Exploitation takes place in child labour and domestic work, as au-pairs, in factories, construction, asphalt laying, restaurants and cleaning industries, agriculture and berry picking and in begging. There are also transnational cases of early and forced marriage of children. The exploitation of children could be organised by families, small groups or large-scale criminal networks. Children are exploited also in illegal and criminal activities, including in drug production and drug trafficking, pick-pocketing or burglary.  Child victims of trafficking are also increasingly used by traffickers for purposes such as begging, benefit fraud, identity fraud, credit fraud and insurance fraud.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Risks for children in migration", "sub_heading": "Risks for children in migration", "_id": "14--4--0---1", "title": "Exploitation of Children"}
{"qas": [{"question": "Why are human trafficking victims protected under the Human Rights Act?", "answer": ""}, {"question": "When was the council of europe convention on action against trafficking in human beings adopted?", "answer": "2005", "ae_score": -0.31412716201523777, "qg_score": null}, {"question": "When was the council of europe convention on action against trafficking in human beings adopted?", "answer": "2005", "ae_score": -0.31412716201523777, "qg_score": null}], "content": "Child trafficking is defined in the UN Trafficking Protocol of 2000 as the recruitment, transportation, transfer, harbouring or receipt of a child for the purpose of exploitation. While this definition applies only to transnational cases and/or cases involving organized criminal groups, child trafficking is now typically recognized well outside these parameters. The International Labour Organization expands definition to include movement and exploitation as key aspects of child trafficking.\nVictims of transnational trafficking might cross borders with or without legal travel documents and with or without the assistance of smugglers. Persons are often recruited into trafficking only after they have crossed an international border. In many cases, trafficking takes place within countries and there are no border crossings involved. The UN Trafficking Protocol of 2000 considers the means of trafficking and the consent of the child to any of the trafficking acts as irrelevant in the identification of a trafficking victim. Forms of exploitation that could constitute trafficking include, \u201cat a minimum, the exploitation of the prostitution of others or other forms of sexual exploitation, forced labour or services, slavery or practices similar to slavery, servitude or the removal of organs\u201d.\nChild trafficking can be prosecuted when it is possible to prove the intent to exploit the child, even when exploitation has not yet taken place. Varying interpretations sometimes make it difficult to distinguish child trafficking from other types of exploitation.\nThe Council of Europe Convention on Action Against Trafficking in Human Beings (2005) adopted the international definition, identical in wording, underlining however that victims shall be protected also in cases where trafficking takes place within countries and without the involvement of large-scale organised crime groups.\nThe EU Anti-Trafficking Directive (2011) broadened the notion of exploitation in the trafficking concept. It explicitly includes the purpose of exploitation in criminal activities as part of the definition of human trafficking. Article 2.3 clarifies that the \u201c\u2018exploitation of criminal activities\u2019 should be understood as the exploitation of a person to commit, inter alia, pick-pocketing, shop-lifting, drug trafficking and other similar activities which are subject to penalties and imply financial gain\u201d. The Directive states that \u201cthe exploitation of begging, including the use of a trafficked dependent person for begging, falls within the scope of the definition of trafficking in human beings only when all the elements of forced labour or services occur\u201d.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Risks for children in migration", "sub_heading": "Trafficking", "_id": "14--4--1---1", "title": "Child Trafficking in the EU"}
{"qas": [{"question": "How does human smuggling work?", "answer": ""}, {"question": "What is the united nations protocol against the smuggling of migrants by?", "answer": "Land, Sea and Air", "ae_score": -1.9127536684482052, "qg_score": null}, {"question": "What is the united nations protocol against the smuggling of migrants by?", "answer": "Land, Sea and Air", "ae_score": -1.9127536684482052, "qg_score": null}], "content": "The United Nations Protocol Against the Smuggling of Migrants by Land, Sea and Air defines human smuggling as the \u201cprocurement, in order to obtain, directly or indirectly, a financial or other material benefit of the illegal entry of a person into a State Party of which the person is not a national or a permanent resident\u201d.  A smuggler facilitates the border crossing of others without the required travel documents and for financial or other gain. Once a smuggler has facilitated the border crossing or ensured the migrant\u2019s arrival at the agreed destination, the contact between the smuggler and the smuggled migrants usually ceases. The smuggling of persons across international borders can be part of the act of trafficking when it is done for the purpose of exploiting the persons in the country of destination. Although smuggling is considered a crime against the state, persons who are using the services of smugglers might be victimised by acts of violence while being smuggled or they might die due to unsafe transportation conditions.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Risks for children in migration", "sub_heading": "Smuggling", "_id": "14--4--2---1", "title": "Smuggling of Migrants by Land, Sea and Air."}
{"qas": [{"question": "The difference between trafficking and the sale of children.?", "answer": ""}, {"question": "What means any act or transaction whereby a child is transferred by any person or group of?", "answer": "The sale of children", "ae_score": -0.8366426596847523, "qg_score": null}, {"question": "What means any act or transaction whereby a child is transferred by any person or group of?", "answer": "The sale of children", "ae_score": -0.8366426596847523, "qg_score": null}], "content": "The sale of children means any act or transaction whereby a child is transferred by any person or group of persons to another for remuneration or any other consideration. While trafficking could involve the purchase and sale of persons, the sale of children may lead to exploitation but does not necessarily have to. Children are sometimes sold in illegal adoptions, for instance. Children are also sold for sexual exploitation or labour. In these cases, there may be an overlap between trafficking and sale as two criminal acts within a single case.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Risks for children in migration", "sub_heading": "Sale of children", "_id": "14--4--3---1", "title": "The sale of children"}
{"qas": [{"question": "Why is migration a bad thing?", "answer": ""}, {"question": "From a human rights-based and development oriented perspective, who share the responsibility for managing?", "answer": "countries of origin and destination", "ae_score": -0.7918423411703541, "qg_score": null}, {"question": "From a human rights-based and development oriented perspective, who share the responsibility for managing?", "answer": "countries of origin and destination", "ae_score": -0.7918423411703541, "qg_score": null}], "content": "The link between migration and development have been widely recognised. Migration is directly relevant to the 2030 Agenda for Sustainable Development. According to current demographic trends, the populations in richer countries will continue to age disproportionately while the younger generations are overrepresented in lower income countries, causing strain on the labour market, social security, education and nutrition.\nMigration can mitigate these population imbalances on both ends. It has a potential to increase the work force and strengthen the younger generations in numbers where needed. This would mean increased contributions to the social welfare systems in higher income countries of destination and a reduced strain on the social welfare systems in countries of origin with high poverty and unemployment rates. Migration and mobility policies should ideally facilitate a mutual exchange of knowledge, capacity and human resources while preventing one directional movements and brain drain. Seen from this point of view, migration holds potential benefits for poverty reduction and for fostering more equitable and sustainable global development.  The linkages between migration and development have implications for policy and practice in these areas and relevant measures need to be coordinated in countries of destination and origin.\nFrom a human rights-based and development oriented perspective, countries of origin and destination share the responsibility for managing migration. Maximising the good developments and minimising the risks from migration could include developing the human capital of migrants and investing in migration management cooperation between countries of origin and destination in social, economic and political terms.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "Migration and sustainable development", "sub_heading": "Migration and sustainable development", "_id": "14--5---1---1", "title": "The link between migration and development"}
{"qas": [{"question": "Why are there so many Aboriginal children in Australia?", "answer": ""}, {"question": "What was it called when aboriginal australian children were removed from their families and placed?", "answer": "Stolen Generations", "ae_score": -0.26116900930933346, "qg_score": null}, {"question": "What was it called when aboriginal australian children were removed from their families and placed?", "answer": "Stolen Generations", "ae_score": -0.26116900930933346, "qg_score": null}], "content": "During the  late 19th and early 20th centuries, many Aboriginal Australian children were removed from their families and placed in institutions and foster homes, in what became known as the Stolen Generations.\n130,000 children were migrated to Australia under assisted child migration schemes from Great Britain alone, with a small number from Malta. Child migrants were adopted or brought up in children's homes, institutions, orphanages or foster care. A large portion of these children were used in slave labour by the churches in Australia. Many of these children experienced neglect and abuse while in institutional care.\nIn November 2009 Australian Prime Minister, Kevin Rudd formally apologized to \"Forgotten Australians\" and child migrants on behalf of the nation. \"Forgotten Australians\" is a term the Australian Senate has used to describe children who were brought up in orphanages, children's homes, institutions or foster care in Australia. Child migrants are a specific group of \"Forgotten Australians\".", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "History of child migration by country", "_id": "14--6--0---1", "title": "\"Forgotten Australians\" and Child Migrants in Australia"}
{"qas": [{"question": "What is child migration and how does it work?", "answer": ""}, {"question": "What nationality were the market gardeners who migrated to austria-hungary?", "answer": "Bulgarian", "ae_score": null, "qg_score": null}, {"question": "What nationality were the market gardeners who migrated to austria-hungary?", "answer": "Bulgarian", "ae_score": null, "qg_score": null}], "content": "Child migration was a phenomenon associated with the migration of Bulgarian market-gardeners to Austria-Hungary in the second half of 19th and early 20th Century, due to the use of child labor (mostly boys) in market-gardening. Child labor brought master gardeners the biggest profit since children did not get paid but worked as apprentices for their keep only. Younger children helped in the gardens and learned gardening skills, while those who were already physically strong performed specialized gardening activities. Different patterns of child migration can be distinguished based on the autobiographies and personal life stories of market-gardeners: children who migrated with their market-gardening parents as a family or those of market-gardeners who were born abroad; children who migrated with one of the parents (usually the market-gardening father) or with relatives of the market-gardening father so as to \u201clearn the craft\u201d; children who migrated with their market-gardening parents as a family, then the parents returned to their homeland with the younger children, while the older child was left abroad to work \u201con a garden\u201d and make his own living, thus supporting his family financially.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "Bulgaria", "_id": "14--6--1---1", "title": "Child Migration in Bulgarian Market-Gardening"}
{"qas": [{"question": "The Canadian Indian Residential School System?", "answer": ""}, {"question": "When was the last residential school in canada closed?", "answer": "1996", "ae_score": -0.3006447615322351, "qg_score": null}, {"question": "When was the last residential school in canada closed?", "answer": "1996", "ae_score": -0.3006447615322351, "qg_score": null}], "content": "The Canadian Indian residential school system, founded in the 19th century, was intended to force the assimilation of the Aboriginal peoples in Canada into European-Canadian society. The last residential school was closed in 1996. On June 11, 2008, Prime Minister Stephen Harper apologized, on behalf of the sitting Cabinet, in front of an audience of Aboriginal delegates, and in an address that was broadcast nationally on the CBC, for the past governments' policies of assimilation.In 2009, Pope Benedict XVI expressed his sorrow at \"the anguish caused by the deplorable conduct of some members of the Church\" and offered his \"sympathy and prayerful solidarity\".", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "Canada", "_id": "14--6--2---1", "title": "Canadian Indian Residential School System"}
{"qas": [{"question": "Why are there so many Maltese children in Australia?", "answer": ""}, {"question": "How many maltese children were sent to australia between 1950 and 1965?", "answer": "310", "ae_score": -0.6825710137371236, "qg_score": null}, {"question": "How many maltese children were sent to australia between 1950 and 1965?", "answer": "310", "ae_score": -0.6825710137371236, "qg_score": null}], "content": "310 children were emigrated from Malta to Australia between 1950 and 1965 under the \u2018Child Migration to Australia Scheme\u2019 following an agreement between the Australian Catholic Immigration committee and the Emigration and Labour Minister on 9 December 1949. Most of the Maltese children sent to Australia under this scheme came either from government orphanages or Church children\u2019s homes and all were said to have left with their parents\u2019 consent. The Australian government had offered to welcome Maltese boys, aged between eight and 11, and girls aged between five and 10 years into Catholic institutions and promised to offer them employment supervised by the responsible Catholic authorities. One of these children became a priest and many others embarked on a career though many grew up hurt knowing that their parents had consented to their departure from home. The Maltese emigrants were included in the Australian Prime Minister's 2009 public apology to those who suffered abuse at the hands of their carers in institutions, orphanages and foster care.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "Malta", "_id": "14--6--3---1", "title": "Maltese children sent to Australia under the \u2018Child Migration to Australia Scheme\u2019 in"}
{"qas": [{"question": "Why are there so many school children in the US?", "answer": ""}, {"question": "How many children were evacuated from areas at risk of aerial bombing?", "answer": "3.5 million", "ae_score": -0.22293106690407286, "qg_score": null}, {"question": "How many children were evacuated from areas at risk of aerial bombing?", "answer": "3.5 million", "ae_score": -0.22293106690407286, "qg_score": null}], "content": "The practice of sending poor or orphaned children to the English settler colonies, to help alleviate the shortage of labour, began in England in 1618, with the rounding-up and transportation of 100 vagrant children to the Virginia Colony. Prior to the second half of the twentieth century, the Home Children programme was seen as a way to move impoverished children to a \"better life\" in Australia, Canada and elsewhere, also providing good \"white stock\" to former colonies.  The children and parents were not consulted, and often siblings were separated. In total 130,000 children were sent from the United Kingdom to Canada, New Zealand, South Africa, Rhodesia (now Zimbabwe), and Australia.  Often children were lied to about their parents being dead and many faced abuse in their new homes. In February 2010 British Prime Minister, Gordon Brown issued an official apology for the 'shameful' child resettlement programme and announced a \u00a36 million fund designed to compensate the families affected by the \"misguided\" programme. The Child Migrants Trust has since set up the Family Restoration Fund in order to use this money to help reunite former child migrants with their families as part of the British government's package of support to former child migrants and their families.\nDuring the Second World War, some 3.5 million children were evacuated from areas at risk of aerial bombing to rural locations. (see Evacuations of civilians in Britain during World War II.)\nA study completed in 2012 by the University of Oxford's Centre on Migration, Policy and Society (COMPAS) led by Dr Nando Sigona has shed light on the situation of children with no right to live in the United Kingdom. The study, 'No way out, no way in: Irregular migrant children and families in the UK', estimates a population of 120,000 children without status, of whom 65,000 were born in the UK to parents with no right to live in the country.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "United Kingdom", "_id": "14--6--4---1", "title": "Children with no right to live in the United Kingdom"}
{"qas": [{"question": "Why are there so many orphanages in the US?", "answer": ""}, {"question": "What was the most famous migration of children in the 19th century?", "answer": "orphan train movement", "ae_score": -0.6609300371629119, "qg_score": null}, {"question": "What was the most famous migration of children in the 19th century?", "answer": "orphan train movement", "ae_score": -0.6609300371629119, "qg_score": null}], "content": "During the 19th century there were a number of attempts to move children from crowded east coast cities to midwestern and western rural families & orphanages. Most famous was the orphan train movement. Additionally Native American children were separated from their families & sent to boarding schools to force them into assimilating western culture.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "United States", "_id": "14--6--5---1", "title": "The Orphan Train Movement"}
{"qas": [{"question": "Why are there so many war children in Finland?", "answer": ""}, {"question": "How many finnish children were transported by train and boat during world war ii?", "answer": "about 70 000", "ae_score": -0.6745640004541444, "qg_score": null}, {"question": "How many finnish children were transported by train and boat during world war ii?", "answer": "about 70 000", "ae_score": -0.6745640004541444, "qg_score": null}], "content": "During the Second World War, when Finland was at war with Russia, about 70 000 Finnish children were transported by train and boat mainly to Sweden, but also to Norway and Denmark. These children are commonly referred to as war children. By the end of the war, thousands of children were adopted by their \"new\" parents.", "page_name": "Child migration", "page_id": "Child%20migration", "heading": "History of child migration by country", "sub_heading": "Finland", "_id": "14--6--6---1", "title": "Child migration | History of child migration by country | Finland"}
{"qas": [{"question": "How do we know how much water is in a river?", "answer": ""}, {"question": "What type of water is difficult to sample because its quality varies during the day and during?", "answer": "Freshwaters", "ae_score": -0.6394314075354016, "qg_score": null}, {"question": "What type of water is difficult to sample because its quality varies during the day and during?", "answer": "Freshwaters", "ae_score": -0.6394314075354016, "qg_score": null}], "content": "Freshwaters are surprisingly difficult to sample because they are rarely homogeneous and their quality varies during the day and during the year. In addition the most representative sampling locations are often at a distance from the shore or bank increasing the logistic complexity.\nFilling a clean bottle with river water is a very simple task, but a single sample is only representative of that point along the river the sample was taken from and at that point in time. Understanding the chemistry of a whole river, or even a significant tributary, requires prior investigative work to understand how homogeneous or mixed the flow is and to determine if the quality changes during the course of a day and during the course of a year. Almost all natural rivers will have very significant patterns of change through the day and through the seasons. Many rivers also have a very large flow that is unseen. This flows through underlying gravel and sand layers and is called the hyporheic zone How much mixing there is between the hyporheic zone and the water in the open channel will depend on a variety of factors, some of which relate to flows leaving aquifers which may have been storing water for many years.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Characterisation", "sub_heading": "Characterisation", "_id": "15--0--0---1", "title": "The Chemistry of a Freshwater River"}
{"qas": [{"question": "How do we know how much water is in the ground?", "answer": ""}, {"question": "When did the need to study ground water dynamics increase?", "answer": "recent decades", "ae_score": null, "qg_score": null}, {"question": "When did the need to study ground water dynamics increase?", "answer": "recent decades", "ae_score": null, "qg_score": null}], "content": "Ground waters by their very nature  are often very difficult to access to take a sample. As a consequence the majority of ground-water data comes from samples taken from springs, wells, water supply bore-holes and in natural caves. In recent decades as the need to understand ground water dynamics has increased, an increasing number or monitoring bore-holes have been drilled into aquifers", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Characterisation", "sub_heading": "Ground-waters", "_id": "15--0--1---1", "title": "Ground Water Monitoring"}
{"qas": [{"question": "How do lakes and ponds work?", "answer": ""}, {"question": "What is the scientific name for fresh water quality parameters?", "answer": "Limnology", "ae_score": -0.10525846774773838, "qg_score": null}, {"question": "What is the scientific name for fresh water quality parameters?", "answer": "Limnology", "ae_score": -0.10525846774773838, "qg_score": null}], "content": "''see also Limnology''\nLakes  and ponds can be very large  and support a complex  eco-system in which environmental parameters vary widely in all three physical dimensions and with time. Large lakes in the temperate zone often stratify in the warmer months into a warmer upper layers rich in oxygen and a colder lower layer with low oxygen levels. In the autumn, falling temperatures and  occasional high winds result in the mixing of the two layers into a more homogeneous whole. When stratification occurs it not only affects oxygen levels but also many related parameters such as iron, phosphate and manganese which are all changed in their chemical form by change in the redox potential of the environment.\nLakes also receive waters, often from many different sources with varying qualities. Solids from stream inputs will typically settle near the mouth of the stream and depending on a variety of factors the incoming water may float over the surface of the lake, sink beneath the surface or rapidly mix with the lake water. All of these phenomena can  skew the results of any environmental monitoring unless the process are well understood.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Characterisation", "sub_heading": "Lakes", "_id": "15--0--2---1", "title": "''see also Limnology''."}
{"qas": [{"question": "How do rivers meet?", "answer": ""}, {"question": "How many rivers meet at a confluence?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many rivers meet at a confluence?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "Where two rivers meet at a confluence there exists a mixing zone. A mixing zone may be very large and extend for many miles as in the case of the Mississippi and Missouri rivers in the United States and the River Clwyd and River Elwy in North Wales. In a mixing zone water chemistry may be very variable and can be difficult to predict. The chemical interactions are not just simple mixing but may be complicated by biological processes from submerged macrophytes and by water joining the channel from the hyporheic zone or from springs draining an aquifer.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Mixing zones", "sub_heading": "Mixing zones", "_id": "15--1---1---1", "title": "Water chemistry in a mixing zone."}
{"qas": [{"question": "Why does water from a river or lake have a higher concentration of calcium than water from other bodies of water?", "answer": ""}, {"question": "Where does fresh water come from on a river?", "answer": "aquifers", "ae_score": -0.40258997936624374, "qg_score": null}, {"question": "Where does fresh water come from on a river?", "answer": "aquifers", "ae_score": -0.40258997936624374, "qg_score": null}], "content": "The geology that underlies a river or lake has a major impact on its chemistry. A river flowing across very ancient precambrian schists is likely to have dissolved very little from the rocks and maybe similar to de-ionised water at least in the headwaters. Conversely a river flowing through chalk hills, and especially if its source is in the chalk, will have a high concentration of carbonates and bicarbonates of Calcium and possibly Magnesium.\nAs a river progresses along its course it may pass through a variety of geological types and it may have inputs from aquifers that do not appear on the surface anywhere in the locality.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Geological inputs", "sub_heading": "Geological inputs", "_id": "15--2---1---1", "title": "The Geology of a River or Lake"}
{"qas": [{"question": "How does water chemistry work?", "answer": ""}, {"question": "What is the most important chemical component of water chemistry?", "answer": "Oxygen", "ae_score": -0.45395043889778597, "qg_score": null}, {"question": "What is the most important chemical component of water chemistry?", "answer": "Oxygen", "ae_score": -0.45395043889778597, "qg_score": null}], "content": "Oxygen is probably the most important chemical constituent of surface water chemistry, as all aerobic organisms require it for survival.  It enters the water mostly via diffusion at the water-air interface.  Oxygen\u2019s solubility in water decreases as water temperature increases. Fast, turbulent streams expose more of the water\u2019s surface area to the air and tend to have low temperatures and thus more oxygen than slow, backwaters.  Oxygen is a by-product of photosynthesis, so systems with a high abundance of aquatic algae and plants may also have high concentrations of oxygen during the day.  These levels can decrease significantly during the night when primary producers switch to respiration.  Oxygen can be limiting if circulation between the surface and deeper layers is poor, if the activity of animals is very high, or if there is a large amount of organic decay occurring such as following Autumn leaf-fall.\nMost other atmospheric inputs come from man-made or anthropogenic sources the most significant of which are the oxides of sulphur produced by burning sulphur rich fuels such as coal and oil which give rise to acid rain. The chemistry of sulphur oxides is complex both in the atmosphere and in river systems. However the effect on the overall chemistry is simple in that it reduces the pH of the water making it more acidic. The pH change is most marked in rivers with very low concentrations of dissolved salts as these cannot buffer the effects of the acid input. Rivers downstream of major industrial conurbations are also at greatest risk. In parts of Scandinavia and West Wales and Scotland many rivers became so acidic from oxides of sulphur that most fish life was destroyed and pHs as low as pH4 were recorded  during critical weather conditions.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Atmospheric inputs", "sub_heading": "Atmospheric inputs", "_id": "15--3---1---1", "title": "The Effects of Sulphur Oxides on the Environment"}
{"qas": [{"question": "Why are rivers so polluted?", "answer": ""}, {"question": "When was the last time rivers were polluted?", "answer": "the first half of the 20th centuries", "ae_score": null, "qg_score": null}, {"question": "When was the last time rivers were polluted?", "answer": "the first half of the 20th centuries", "ae_score": null, "qg_score": null}], "content": "The majority of rivers on the planet and many lakes have received or are receiving inputs from human-kind's activities. In the industrialised world, many rivers have been very seriously polluted, at least during the 19th and the first half of the 20th centuries. Although in general there has been much improvement in the developed world, there is still a great deal of river pollution apparent on the planet.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Anthropogenic inputs", "sub_heading": "Anthropogenic inputs", "_id": "15--4---1---1", "title": "River Pollution in the Industrialised World"}
{"qas": [{"question": "How do chemical constituents affect the behavior of an organism?", "answer": ""}, {"question": "In which type of environment is the presence or absence of an organism usually determined?", "answer": "environmental", "ae_score": -2.526458880496451, "qg_score": null, "filter_answer": "Freshwater environmental quality parameters"}, {"question": "In which type of environment is the presence or absence of an organism usually determined?", "answer": "environmental", "ae_score": -2.526458880496451, "qg_score": null, "filter_answer": "Freshwater environmental quality parameters"}], "content": "In most environmental situations the presence or absence of an organism is determined by a complex web of interactions only some of which will be related to measurable chemical or biological parameters. Flow rate, turbulence, inter and intra specific competition, feeding behaviour, disease, parasatism, commensalism and symbiosis are just a few of the pressures and opportunities facing any organism or population. Most chemical constituents favour some organisms and are less favourable to others. However, there are some cases where a chemical constituent exerts a toxic effect. i.e. where the concentration can kill or severely inhibit the normal functioning of the organism. Where a toxic effect has been demonstrated this may be noted in the sections below dealing with the individual parameters.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Toxicity", "sub_heading": "Toxicity", "_id": "15--5---1---1", "title": "Biological Parameters and Chemical Parameters."}
{"qas": [{"question": "Why do rivers have a yellow hue to them?", "answer": ""}, {"question": "Where does the yellow in rivers come from?", "answer": "dissolved humic acids", "ae_score": -0.4868321851949504, "qg_score": null}, {"question": "Where does the yellow in rivers come from?", "answer": "dissolved humic acids", "ae_score": -0.4868321851949504, "qg_score": null}], "content": "Often it is the colour of freshwater or how clear or hazy the water is that is the most obvious visual characteristic. Unfortunately neither colour nor turbidity are strong indicators of the overall chemical composition of water. However both colour and turbidity reduce the amount of light penetrating the water and can have significant impact on algae and macrophytes. Some algae in particular are highly dependent on water with low colour and turbidity\nMany rivers draining high moor-lands overlain by peat have a very deep yellow brown colour caused by dissolved humic acids.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Chemical constituents", "_id": "15--6--0---1", "title": "Colour and Turbidity in Freshwater"}
{"qas": [{"question": "How do we know the effects of synthetic chemicals on aquatic life?", "answer": ""}, {"question": "Where does most of the earths freshwater come from?", "answer": "treated sewage", "ae_score": -0.10539904681268618, "qg_score": null}, {"question": "Where does most of the earths freshwater come from?", "answer": "treated sewage", "ae_score": -0.10539904681268618, "qg_score": null}], "content": "One of the principal sources of elevated concentrations of organic chemical constituents is from treated sewage.\nDissolved organic material is most commonly measured using either the Biochemical oxygen demand (BOD) test or the Chemical oxygen demand (COD) test. Organic constituents are significant in river chemistry for the effect that they have on dissolved oxygen concentration and for the impact that individual organic species may have directly on aquatic biota.\nAny organic and degradable material consumes oxygen as it decomposes. Where organic concentrations are significantly elevated the effects on oxygen concentrations can be significant and as conditions get extreme the river bed may become anoxic.\nSome organic constituents such as synthetic hormones, pesticides, phthalates have direct metabolic effects on aquatic biota and even on humans drinking water taken from the river. Understanding such constituents and how they can be identified and quantified is becoming of increasing importance in the understanding of freshwater chemistry.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Organic constituents", "_id": "15--6--1---1", "title": "Organic Components in Freshwater Chemistry"}
{"qas": [{"question": "Why is lead so toxic to the human body?", "answer": ""}, {"question": "What is a major source of metals in freshwater?", "answer": "Coal mining", "ae_score": -0.6056878634383869, "qg_score": null}, {"question": "What is a major source of metals in freshwater?", "answer": "Coal mining", "ae_score": -0.6056878634383869, "qg_score": null}], "content": "A wide range of metals may be found in rivers from natural sources where metal ores are present in the rocks over which the river flows or in the aquifers feeding water into the river. However many rivers have an increased load of metals because of industrial activities which include mining and quarrying and the processing and use of metals.\nIron, usually as Fe is a common constituent of river waters at very low levels. Higher iron concentrations in acidic springs or an anoxic hyporheic zone may cause visible orange/brown staining or semi-gelatinous precipitates of dense orange iron bacterial floc carpeting the river bed. Such conditions are very deleterious to most organisms and can cause serious damage in a river system.\nCoal mining is also a very significant source of  Iron both in mine-waters and from stocking yards of coal and from coal processing. Long abandoned mines can be a highly intractable source of high concentrations of Iron.Low levels of iron are common in spring waters emanating from deep-seated aquifers and maybe regarding as health giving springs. Such springs are commonly called Chalybeate springs and have given rise to a number of Spa towns in Europe and the United States.\nZinc is normally associated with metal mining, especially Lead and Silver mining but is also a component pollutant associated with a variety of other metal mining activities and with Coal mining. Zinc is toxic at relatively low concentrations to many aquatic organisms. ''Microregma'' starts to show a toxic reaction at concentrations as low as 0.33 mg/l \nLead and silver in river waters are commonly found together and associated with  lead mining. Impacts from very old mines can be very long-lived. In the River Ystwyth in Wales for example, the effects of silver and lead mining in the 17th and 18th centuries in the headwaters still causes unacceptably high levels of Zinc and Lead in the river water right down to its confluence with the sea. Silver is very toxic even at very low concentrations but leaves no visible evidence of its contamination.\nLead is also highly toxic to freshwater organisms and to humans if the water is used as drinking water. As with Silver, Lead pollution is not visible to the naked eye. The River Rheidol in west Wales had a major series of lead mines in its headwaters until the end of the 19th century and its mine discharges and waste tips remain to this day. In 1919 - 1921  only 14 species of invertebrates were found in the lower Rheidol when Lead concentrations were between 0.2ppm and 0.5ppm. By 1932 the lead concentration had reduced to 0.02ppm to 0.1ppm because of the abandonment of mining and, at those concentrations, the bottom fauna had stabilized to 103 species including three leeches.\nCoal mining is also a very significant source of metals, especially Iron, Zinc and Nickel particularly where the coal is rich if pyrites which oxidises on contact with the air producing a very acidic leachate which is able to dissolve metals from the coal.\nSignificant levels of copper are unusual in rivers and where it does it occur the source is most likely to be mining activities, coal stocking, or pig farming. Rarely elevated levels may be of geological origin. Copper is acutely toxic to many freshwater organisms, especially algae, at very low concentrations and significant concentration in river water may have serious adverse effects on the local ecology.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Metals", "_id": "15--6--2---1", "title": "Metals in Rivers"}
{"qas": [{"question": "Why does ammonia have such a toxic effect on fish?", "answer": ""}, {"question": "Where does most of the nitrogen in rivers come from?", "answer": "sewage", "ae_score": -0.5096303768617821, "qg_score": null}, {"question": "Where does most of the nitrogen in rivers come from?", "answer": "sewage", "ae_score": -0.5096303768617821, "qg_score": null}], "content": "Nitrogenous compounds have a variety of sources including washout of oxides of nitrogen from the atmosphere, some geological inputs and some from macrophyte and algal nitrogen fixation. However, for many rivers in the proximity of humans, the largest input is from sewage whether treated or untreated. The nitrogen derives from breakdown products of proteins found in urine and faeces. These products, being very soluble, often pass through sewage treatment process and are discharged into rivers as a component of sewage treatment effluent. Nitrogen may be in the form of nitrate, nitrite, ammonia or ammonium salts or what is termed albuminoid nitrogen or nitrogen still within an organic proteinoid molecule.\nThe differing forms of nitrogen are relatively stable in most river systems with nitrite slowly transforming into nitrate in well oxygenated rivers and ammonia transforming into nitrite/ nitrate. However, the process are slow in cool rivers and reduction in concentration may more often be attributed to simple dilution. All forms of nitrogen are taken up by macrophytes and algae and elevated levels of nitrogen are often associated with overgrowths of plants or eutrophication. These can have the effect of blocking channels and inhibiting navigation. However, ecologically, the more significant effect is on dissolved oxygen concentrations which may become super-saturated during daylight due to plant photosynthesis but then drop to very low levels during darkness as plant respiration uses up the dissolved oxygen. Coupled with the release of oxygen in photosynthesis is the creation of bi-carbonate ions which cause a steep rise in pH and this is matched in darkness as carbon dioxide is released through respiration which substantially lowers the pH. Thus high levels of nitrogenous compounds tends to lead to eutrophication with extreme variations in parameters which in turn can substantially degrade the ecological worth of the watercourse.\nAmmonium ions also have a toxic effect, especially on fish. The toxicity of ammonia is dependent on both pH and temperature  and an added complexity is the buffering effect of the blood/water interface across the gill membrane which masks any additional toxicity over about pH 8.0. The management of river chemistry to avoid ecological damage is particularly difficult in the case of ammonia as a wide range of potential scenarios of concentration, pH and temperature have to be considered and the diurnal pH fluctuation caused by photosynthesis considered. On warm summer days with high-bi-carbonate concentrations unexpectedly toxic conditions can be created.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Nitrogen", "_id": "15--6--3---1", "title": "Nitrogen in Rivers"}
{"qas": [{"question": "Where do phosphates come from?", "answer": ""}, {"question": "When do phosphates become toxic in water?", "answer": "the late summer", "ae_score": null, "qg_score": null}, {"question": "When do phosphates become toxic in water?", "answer": "the late summer", "ae_score": null, "qg_score": null}], "content": "Phosphorus compounds are usually found as relatively insoluble phosphates in river water and, except in some exceptional circumstances, their origin is agriculture or human sewage. Phosphorus can encourage excessive growths of plants and algae and contribute to eutrophication. If a river discharges into a lake or reservoir phosphate can be mobilised year after year by natural processes. In the summer time, lakes stratify so that warm oxygen rich water floats on top of cold oxygen poor water. In the warm upper layers - the epilimnion- plants consume the available phosphate. As the plants die in the late summer they fall into the cool water layers underneath - the hypolimnion - and decompose. During winter turn-over, when a lake becomes fully mixed through the action of winds on a cooling body of water - the phosphates are spread throughout the lake again to feed a new generation of plants. This process is one of the principal causes of persistent algal blooms at some lakes.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Phosphorus", "_id": "15--6--4---1", "title": "Phosphorus Compounds in Lakes & Reservoirs"}
{"qas": [{"question": "How does arsenic enter the hydrological cycle?", "answer": ""}, {"question": "What causes arsenic to enter the hydrological cycle?", "answer": "poorly stored tailings", "ae_score": -1.7343321107362664, "qg_score": null}, {"question": "What causes arsenic to enter the hydrological cycle?", "answer": "poorly stored tailings", "ae_score": -1.7343321107362664, "qg_score": null}], "content": "Geological deposits of arsenic may be released into rivers where deep ground-waters are exploited as in parts of Pakistan. Many metalloid ores such as lead, gold and copper contain traces of arsenic and poorly stored tailings may result in arsenic entering the hydrological cycle.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Arsenic", "_id": "15--6--5---1", "title": "Geological Deposits of Arsenic may be released into rivers where deep ground-water"}
{"qas": [{"question": "Why are there no freshwater fish in montane rivers?", "answer": ""}, {"question": "What type of solids are produced in montane rivers?", "answer": "Inert solids", "ae_score": -0.6841114087542488, "qg_score": null}, {"question": "What type of solids are produced in montane rivers?", "answer": "Inert solids", "ae_score": -0.6841114087542488, "qg_score": null}], "content": "Inert solids are produced in all montane rivers as the energy of the water helps grind away rocks into gravel, sand and finer material. Much of this settles very quickly and provides an important substrate for many aquatic organisms. Many salmonid fish require beds of gravel and sand in which to lay their eggs.Many other types of solids from agriculture, mining, quarrying, urban run-off and sewage may block-out sunlight from the river and may block interstices in gravel beds making them useless for spawning and supporting insect life.", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Solids", "_id": "15--6--6---1", "title": "Gravel and Sand in the Montane River"}
{"qas": [{"question": "Why are there so many E.coli bacteria in the ocean?", "answer": ""}, {"question": "Where are e coli bacteria found in the earth?", "answer": "Sand", "ae_score": -0.601281287740785, "qg_score": null}, {"question": "Where are e coli bacteria found in the earth?", "answer": "Sand", "ae_score": -0.601281287740785, "qg_score": null}], "content": "Both agriculture and sewage treatment produce  inputs into rivers with very high concentrations of bateria and viruses including a wide range of pathogenic organisms. Even in areas with little human activity significant levels of bacteria and viruses can be detected originating from fish and aquatic mammals and from animals grazing near rivers such as deer.Upland waters draining areas frequented by sheep, goats or deer may also harbour a variety of opportunistic human parasites such as liver fluke. Consequently, there are very few rivers from which the water is safe to drink without some form of sterilisation or disinfection. In rivers used for contact recreation such as swimming, safe levels of bacteria and viruses can be established based on risk assessment.\nUnder certain conditions bacteria can colonise freshwaters occasionally making large rafts of filamentous mats known as ''sewage fungus'' \u2013 usually ''Sphaerotilus natans''. The presence of such organisms is almost always an indicator of extreme organic pollution and would be expected to be matched with low dissolved oxygen concentrations and high BOD vales.\nE. coli bacteria have been commonly found in recreational waters and their presence is used to indicate the presence of recent fecal contamination, but E. coli presence may not be indicative of human waste.  E. coli are harbored in all warm-blooded animals: birds and mammals alike.  E. coli bacteria have also been found in fish and turtles.  Sand also harbors E. coli bacteria and some strains of E. coli have become naturalized. Some geographic areas may support unique populations of E. coli and conversely, some E. coli strains are cosmopolitan .", "page_name": "Freshwater environmental quality parameters", "page_id": "Freshwater%20environmental%20quality%20parameters", "heading": "Chemical constituents", "sub_heading": "Bacterial, viral and parasite inputs", "_id": "15--6--7---1", "title": "E. coli \u2014 Viruses and Bacteria in Rivers"}
{"qas": [{"question": "Why are antibiotics prescribed by an infectious disease specialist rather than by a non-infectious disease specialist?", "answer": ""}, {"question": "How many states used antibiotics in 2011?", "answer": "32", "ae_score": -0.7235023749441616, "qg_score": null}, {"question": "How many states used antibiotics in 2011?", "answer": "32", "ae_score": -0.7235023749441616, "qg_score": null}], "content": "Antibiotics can cause severe reactions and add significantly to the cost of care.  In the United States, antibiotics and anti-infectives are the leading cause of adverse effect from drugs.  In a study of 32 States in 2011, antibiotics and anti-infectives accounted for nearly 24 percent of ADEs that were present on admission, and 28 percent of those that occurred during a hospital stay.\nPrescribing by an infectious disease specialist compared with prescribing by a non-infectious disease specialist decreases antibiotic consumption and reduces costs.", "page_name": "Antibiotic misuse", "page_id": "Antibiotic%20misuse", "heading": "Social and economic impact", "sub_heading": "Social and economic impact", "_id": "16--1---1---1", "title": "Antibiotics and Anti-Infectives are the leading cause of adverse effect from drugs"}
{"qas": [{"question": "Why is there a rise in antibiotic resistance?", "answer": ""}, {"question": "What is the name of the first-line antibiotic?", "answer": "fluoroquinolones", "ae_score": -0.24182192693401322, "qg_score": null}, {"question": "What is the name of the first-line antibiotic?", "answer": "fluoroquinolones", "ae_score": -0.24182192693401322, "qg_score": null}], "content": "Though antibiotics are required to treat severe bacterial infections, misuse has contributed to a rise in bacterial resistance. The overuse of fluoroquinolone and other antibiotics fuels antibiotic resistance in bacteria, which can inhibit the treatment antibiotic-resistant infections. Their excessive use in children with otitis media has given rise to a breed of bacteria resistant to antibiotics entirely.\nWidespread use of fluoroquinolones as a first-line antibiotic has led to decreased antibiotic sensitivity, with negative implications for serious bacterial infections such as those associated with cystic fibrosis, where quinolones are among the few viable antibiotics.", "page_name": "Antibiotic misuse", "page_id": "Antibiotic%20misuse", "heading": "Antibiotic resistance", "sub_heading": "Antibiotic resistance", "_id": "16--2---1---1", "title": "Fluoroquinolones as First-Line Antibiotic Fuels Antibiotic Resistance"}
{"qas": [{"question": "Why are antibiotics ineffective against viral infections like the common cold?", "answer": ""}, {"question": "Where is the most abundant use of antibiotics?", "answer": "livestock", "ae_score": -0.5040832115721177, "qg_score": null}, {"question": "Where is the most abundant use of antibiotics?", "answer": "livestock", "ae_score": -0.5040832115721177, "qg_score": null}], "content": "Antibiotics have no effect on viral infections such as the common cold. They are also ineffective against sore throats, which are usually viral and self-resolving. Most cases of bronchitis (90\u201395%) are viral as well, passing after a few weeks\u2014the use of antibiotics against bronchitis is superfluous and can put the patient at risk of suffering adverse reactions.\nOfficial guidelines by the American Heart Association for dental antibiotic prophylaxis call for the administration of antibiotics to prevent infective endocarditis. Though the current (2007) guidelines dictate more restricted antibiotic use, many dentists and dental patients follow the 1997 guidelines instead, leading to overuse of antibiotics.\nThere has been massive use of antibiotics in animal husbandry. The most abundant use of antimicrobials worldwide are in livestock; they are typically distributed in animal feed or water for purposes such as disease prevention and growth.Debates have arisen surrounding the extent of the impact of these antibiotics, particularly antimicrobial growth promoters, on human antibiotic resistance. Although some sources believe that there remains a lack of knowledge on which antibiotic use generates the most risk to humans, policies and regulations have been placed to limit any harmful effects.", "page_name": "Antibiotic misuse", "page_id": "Antibiotic%20misuse", "heading": "Inappropriate use", "sub_heading": "Inappropriate use", "_id": "16--3---1---1", "title": "The Impact of Antibiotic Use on Human Antibiotic Resistance"}
{"qas": [{"question": "What happens to zeolites?", "answer": ""}, {"question": "What type of minerals transform to other minerals under weathering or hydrothermal alteration?", "answer": "Zeolites", "ae_score": -0.1815523273275094, "qg_score": null}, {"question": "What type of minerals transform to other minerals under weathering or hydrothermal alteration?", "answer": "Zeolites", "ae_score": -0.1815523273275094, "qg_score": null}], "content": "Zeolites have a porous structure that can accommodate a wide variety of cations, such as Na, K, Ca, Mg and others. These positive ions are rather loosely held and can readily be exchanged for others in a contact solution. Some of the more common mineral zeolites are analcime, chabazite, clinoptilolite, heulandite, natrolite, phillipsite, and stilbite. An example of the mineral formula of a zeolite is: NaAlSiO\u00b72HO, the formula for natrolite.\nNatural zeolites form where volcanic rocks and ash layers react with alkaline groundwater. Zeolites also crystallize in post-depositional environments over periods ranging from thousands to millions of years in shallow marine basins. Naturally occurring zeolites are rarely pure and are contaminated to varying degrees by other minerals, metals, quartz, or other zeolites. For this reason, naturally occurring zeolites are excluded from many important commercial applications where uniformity and purity are essential.\nZeolites are the aluminosilicate members of the family of microporous solids known as \"molecular sieves.\" The term molecular sieve refers to a particular property of these materials, i.e., the ability to selectively sort molecules based primarily on a size exclusion process. This is due to a very regular pore structure of molecular dimensions. The maximum size of the molecular or ionic species that can enter the pores of a zeolite is controlled by the dimensions of the channels. These are conventionally defined by the ring size of the aperture, where, for example, the term \"8-ring\" refers to a closed loop that is built from eight tetrahedrally coordinated silicon (or aluminium) atoms and 8 oxygen atoms. These rings are not always perfectly symmetrical due to a variety of effects, including strain induced by the bonding between units that are needed to produce the overall structure, or coordination of some of the oxygen atoms of the rings to cations within the structure. Therefore, the pores in many zeolites are not cylindrical.\nZeolites transform to other minerals under weathering, hydrothermal alteration or metamorphic conditions. Some examples:", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Properties and occurrence", "sub_heading": "Properties and occurrence", "_id": "17--0---1---1", "title": "Natural Zeolites and Minerals"}
{"qas": [{"question": "Why are zeolites so valuable?", "answer": ""}, {"question": "What is used to heat zeolite in aqueous solutions?", "answer": "sodium hydroxide", "ae_score": -0.4979262666711799, "qg_score": null}, {"question": "What is used to heat zeolite in aqueous solutions?", "answer": "sodium hydroxide", "ae_score": -0.4979262666711799, "qg_score": null}], "content": "Industrially important zeolites are produced synthetically.  Typical procedures entail heating aqueous solutions of alumina and silica with sodium hydroxide.  Equivalent reagents include sodium aluminate and sodium silicate.  Further variations include changes in the cations to include quaternary ammonium cations.\nSynthetic zeolites hold some key advantages over their natural analogues. The synthetic materials are manufactured in a uniform, phase-pure state. It is also possible to produce zeolite structures that do not appear in nature. Zeolite A is a well-known example. Since the principal raw materials used to manufacture zeolites are silica and alumina, which are among the most abundant mineral components on earth, the potential to supply zeolites is virtually unlimited.\nConventional open-pit mining techniques are used to mine natural zeolites. The overburden is removed to allow access to the ore. The ore may be blasted or stripped for processing by using tractors equipped with ripper blades and front-end loaders. In processing, the ore is crushed, dried, and milled. The milled ore may be air-classified as to particle size and shipped in bags or bulk. The crushed product may be screened to remove fine material when a granular product is required, and some pelletized products are produced from fine material.\nAs of 2016 the world's annual production of natural zeolite approximates 3 million tonnes. Major producers in 2010 included China (2 million tonnes), South Korea (210,000 t), Japan (150,000 t), Jordan (140,000 t), Turkey (100,000 t) Slovakia (85,000 t) and the United States (59,000 t). The ready availability ofzeolite-rich rock at low cost and the shortage of competing minerals and rocks are probably the most important factors for its large-scale use. According to the United States Geological Survey, it is likely that a significant percentage of the material sold as zeolites in some countries is ground or sawn volcanic tuff that contains only a small amount of zeolites. Some examples of such usage include dimension stone (as an altered volcanic tuff), lightweight aggregate, pozzolanic cement, and soil conditioners.\nThere are several types of synthetic zeolites that form by a process of slow crystallization of a silica-alumina gel in the presence of alkalis and organic templates. One of the important processes used to carry out zeolite synthesis is sol-gel processing. The product properties depend on reaction mixture composition, pH of the system, operating temperature, pre-reaction 'seeding' time, reaction time as well as the templates used. In sol-gel process, other elements (metals, metal oxides) can be easily incorporated. The silicalite sol formed by the hydrothermal method is very stable. The ease of scaling up this process makes it a favorite route for zeolite synthesis.", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Production", "sub_heading": "Production", "_id": "17--1---1---1", "title": "Synthetic Zeolite Synthesis"}
{"qas": [{"question": "What are zeolites and how do they work?", "answer": ""}, {"question": "Who developed the substance zeolite for long-term storage of energy?", "answer": "Fraunhofer e.V.", "ae_score": -0.5414119127001423, "qg_score": null}, {"question": "Who developed the substance zeolite for long-term storage of energy?", "answer": "Fraunhofer e.V.", "ae_score": -0.5414119127001423, "qg_score": null}], "content": "Synthetic zeolites are widely used as catalysts in the petrochemical industry, for instance in fluid catalytic cracking and hydrocracking. Zeolites confine molecules in small spaces, which causes changes in their structure and reactivity. The hydrogen form of zeolites (prepared by ion-exchange) are powerful solid-state acids, and can facilitate a host of acid-catalyzed reactions, such as isomerisation, alkylation, and cracking. The specific activation modality of most zeolitic catalysts used in petrochemical applications involves quantum-chemical Lewis acid site reactions.\nCatalytic cracking uses reactor and a regenerator.  Feed is injected onto hot, fluidized catalyst where large gasoil molecules are broken into smaller gasoline molecules and olefins.  The vapor-phase products are separated from the catalyst and distilled into various products.  The catalyst is circulated to a regenerator where air is used to burn coke off the surface of the catalyst that was formed as a byproduct in the cracking process.  The hot regenerated catalyst is then circulated back to the reactor to complete its cycle.\nZeolites have uses in advanced reprocessing methods, where their micro-porous ability to capture some ions while allowing others to pass freely, allowing many fission products to be efficiently removed from nuclear waste and permanently trapped. Equally important are the mineral properties of zeolites. Their alumino-silicate construction is extremely durable and resistant to radiation even in porous form. Additionally, once they are loaded with trapped fission products, the zeolite-waste combination can be hot pressed into an extremely durable ceramic form, closing the pores and trapping the waste in a solid stone block. This is a waste form factor that greatly reduces its hazard compared to conventional reprocessing systems. Zeolites are also used in the management of leaks of radioactive materials. For example, in the aftermath of the Fukushima Daiichi nuclear disaster, sandbags of zeolite were dropped into the seawater near the power plant to adsorb radioactive caesium which was present in high levels.\nThe German group Fraunhofer e.V. announced that they had developed a zeolite substance for use in the biogas industry for long-term storage of energy at a density 4x more than water. Ultimately, the goal is to be able to store heat both in industrial installations and in small combined heat and power plants such as those used in larger residential buildings.", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Uses", "sub_heading": "Uses", "_id": "17--2--0---1", "title": "Zeolitic Catalysts in the Petrochemical Industry"}
{"qas": [{"question": "What are synthetic zeolites and how do they work?", "answer": ""}, {"question": "Where does zeolite come from in the world?", "answer": "laundry detergent market", "ae_score": -0.35059569105782007, "qg_score": null}, {"question": "Where does zeolite come from in the world?", "answer": "laundry detergent market", "ae_score": -0.35059569105782007, "qg_score": null}], "content": "Zeolites can be used as solar thermal collectors and for adsorption refrigeration. In these applications, their high heat of adsorption and ability to hydrate and dehydrate while maintaining structural stability is exploited. This hygroscopic property coupled with an inherent exothermic (energy releasing) reaction when transitioning from a dehydrated to a hydrated form make natural zeolites useful in harvesting waste heat and solar heat energy. Zeolites are also used as a molecular sieve in cryosorption style vacuum pumps.\nThe largest single use for zeolite is the global laundry detergent market. This amounted to 1.44 million metric tons per year of anhydrous zeolite A in 1992.\nNon-clumping cat litter is often made of zeolite or diatomite.\nSynthetic zeolites are used as an additive in the production process of warm mix asphalt concrete. The development of this application started in Germany in the 1990s. They help by decreasing the temperature level during manufacture and laying of asphalt concrete, resulting in lower consumption of fossil fuels, thus releasing less carbon dioxide, aerosols, and vapours. The use of synthetic zeolites in hot mixed asphalt leads to easier compaction and, to a certain degree, allows cold weather paving and longer hauls.\nWhen added to Portland cement as a pozzolan they can reduce chloride permeability and improve workability. They reduce weight and help moderate water content while allowing for slower drying which improves break strength. When added to lime mortars and lime-metakaolin mortars, synthetic zeolite pellets can act simultaneously as pozzolanic material and water reservoir.", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Uses", "sub_heading": "Commercial and domestic", "_id": "17--2--1---1", "title": "Synthetic Zeolites \u2014 The World\u2019s Largest Synthetic Zeolites"}
{"qas": [{"question": "Why do thomsonite nodules have rings in them?", "answer": ""}, {"question": "What rare gemstone is found in lakes superior and michigan?", "answer": "Thomsonites", "ae_score": -0.2311004741677747, "qg_score": null}, {"question": "What rare gemstone is found in lakes superior and michigan?", "answer": "Thomsonites", "ae_score": -0.2311004741677747, "qg_score": null}], "content": "Thomsonites, one of the rarer zeolite minerals, have been collected as gemstones from a series of lava flows along Lake Superior in Minnesota and to a lesser degree in Michigan, U.S. Thomsonite nodules from these areas have eroded from basalt lava flows and are collected on beaches and by scuba divers in Lake Superior.\nThese thomsonite nodules have concentric rings in combinations of colors: black, white, orange, pink, purple, red, and many shades of green. Some nodules have copper inclusions and rarely will be found with copper \"eyes.\" When polished by a lapidary the thomsonites sometimes display a \"cat's eye\" effect (chatoyancy).", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Uses", "sub_heading": "Gemstones", "_id": "17--2--2---1", "title": "Thomsonites, a rarer zeolite mineral"}
{"qas": [{"question": "What is clinoptilite and what does it do?", "answer": ""}, {"question": "What is the name of the naturally occurring zeolite used in soil treatment?", "answer": "clinoptilolite", "ae_score": -0.2817115468743817, "qg_score": null}, {"question": "What is the name of the naturally occurring zeolite used in soil treatment?", "answer": "clinoptilolite", "ae_score": -0.2817115468743817, "qg_score": null}], "content": "Research into and development of the many biochemical and biomedical applications of zeolites, particularly the naturally occurring species heulandite, clinoptilolite and chabazite has been ongoing.\nZeolite-based oxygen concentrator systems are widely used to produce medical-grade oxygen. The zeolite is used as a molecular sieve to create purified oxygen from air using its ability to trap impurities, in a process involving the adsorption of nitrogen, leaving highly purified oxygen and up to 5% argon.\nQuikClot brand hemostatic agent, which is used to stop severe bleeding, contains a calcium-loaded form of zeolite found in kaolin clay.\nIn agriculture, clinoptilolite (a naturally occurring zeolite) is used as a soil treatment. It provides a source of slowly released potassium. If previously loaded with ammonium, the zeolite can serve a similar function in the slow release of nitrogen. Zeolites can also act as water moderators, in which they will absorb up to 55% of their weight in water and slowly release it under the plant's demand. This property can prevent root rot and moderate drought cycles.Clinoptilolite has also been added to chicken food, the absorption of water and ammonia by the zeolite made the birds droppings drier, less odoriferous and hence easier to handle.\nPet stores market zeolites for use as filter additives in aquaria.<ref name=usgs/> In aquaria, zeolites can be used to adsorb ammonia and other nitrogenous compounds. However, due to the high affinity of some zeolites for calcium, they may be less effective in hard water and may deplete calcium. Zeolite filtration is used in some marine aquaria to keep nutrient concentrations low for the benefit of corals adapted to nutrient-depleted waters.\nWhere and how the zeolite was formed is an important consideration for aquaria. Most Northern hemisphere natural zeolites were formed when molten lava came in contact with sea water, thereby 'loading' the zeolite with Na (sodium) sacrificial ions. The mechanism is well known to chemists as ion exchange. These sodium ions will speciate with other ions in solution, thus the takeup of nitrogen in ammonia, with the release of the sodium. A deposit near Bear River in southern Idaho, (US) is a fresh water variety (Na<.05%). Southern hemisphere zeolites are typically formed in freshwater and have a high calcium content.\nZeolite filters ammonia effectively, but must be used with some care, especially with delicate tropical corals that are sensitive to water chemistry and temperature.", "page_name": "Zeolite", "page_id": "Zeolite", "heading": "Uses", "sub_heading": "Biological", "_id": "17--2--3---1", "title": "Zeolite \u2014 a natural zeolite"}
{"qas": [{"question": "What is the difference between a peatland and a mire?", "answer": ""}, {"question": "What does peat turn into when it is wet?", "answer": "lignite coal", "ae_score": -0.4160025010064823, "qg_score": null}, {"question": "What does peat turn into when it is wet?", "answer": "lignite coal", "ae_score": -0.4160025010064823, "qg_score": null}], "content": "In a widely cited article, Joosten and Clarke (2002) defined peatlands, or mire (which they claim are the same) as,\nPeatlands are areas of land with a naturally accumulated layer of peat. Peatlands are found in at least 175 countries and cover around 4 million km\u00b2 or 3% of the world\u2019s land area. In Europe, peatlands extend to about 515,000 km2.\nPeat deposits are found in many places around the world, including northern Europe and North America, principally in Canada and the Northern United States. Some of the world's largest peatlands include the West Siberian Lowland, the Hudson Bay Lowland, and the Mackenzie River Valley. The amount of peat is smaller in the Southern Hemisphere, partly because there is less land, yet South America (Southern Patagonia/Tierra del Fuego) has one of the world's largest wetlands, the vast Magellanic Moorland, with extensive peat-dominated landscapes. Peat can be found in New Zealand, Kerguelen, and the Falkland Islands, Indonesia (Kalimantan (Sungai Putri, Danau Siawan, Sungai Tolak), Rasau Jaya (West Kalimantan), and Sumatra). Indonesia has more tropical peat land and mangrove forests than any other nation on earth, but Indonesia is losing wetlands by 100,000 hectare per year.\nAbout 60% of the world's wetlands are peat. About 7% of total peatlands have been exploited for agriculture and forestry. Under proper conditions, peat will turn into lignite coal over geologic periods of time.", "page_name": "Peat", "page_id": "Peat", "heading": "Peatlands distribution", "sub_heading": "Peatlands distribution", "_id": "18--0---1---1", "title": "Peatlands: The World\u2019s Largest Wetland"}
{"qas": [{"question": "How much carbon do peatlands contain?", "answer": ""}, {"question": "How much carbon is in a peat?", "answer": "550 Gt", "ae_score": -0.2199765047934785, "qg_score": null}, {"question": "How much carbon is in a peat?", "answer": "550 Gt", "ae_score": -0.2199765047934785, "qg_score": null}], "content": "Peat forms when plant material, usually in wet areas, is inhibited from decaying fully by acidic and anaerobic conditions. It is composed mainly of wetland vegetation: principally bog plants including mosses, sedges, and shrubs. As it accumulates, the peat can hold water, thereby slowly creating wetter conditions, and allowing the area of wetland to expand. Peatland features can include ponds, ridges, and raised bogs.\nMost modern peat bogs formed in high latitudes after the retreat of the glaciers at the end of the last ice age some 12,000 years ago. Peat usually accumulates slowly, at the rate of about a millimeter per year.\nPeat in the world's peatlands is currently believed to have been forming for 360 million years and contains 550 Gt of carbon.", "page_name": "Peat", "page_id": "Peat", "heading": "Formation", "sub_heading": "Formation", "_id": "18--1---1---1", "title": "Peat in the World's Peatland"}
{"qas": [{"question": "What is the difference between peat and soil?", "answer": ""}, {"question": "What type of grass is phragmites made of?", "answer": "reed grass", "ae_score": -0.8553572978205667, "qg_score": null}, {"question": "What type of grass is phragmites made of?", "answer": "reed grass", "ae_score": -0.8553572978205667, "qg_score": null}], "content": "Peat material is either fibric, hemic, or sapric. Fibric peats are the least decomposed, and comprise intact fiber. Hemic peats are somewhat decomposed, and sapric are the most decomposed.''Phragmites'' peat is one composed of reed grass, ''Phragmites australis'', and other grasses. It is denser than many other types of peat.Engineers may describe a soil as peat which has a relatively high percentage of organic material. This soil is problematic because it exhibits poor consolidation properties.", "page_name": "Peat", "page_id": "Peat", "heading": "Types of peat material", "sub_heading": "Types of peat material", "_id": "18--2---1---1", "title": "''Phragmites'' Peat is a type of peat"}
{"qas": [{"question": "Why do some Scotch whiskies have peat in them?", "answer": ""}, {"question": "How long does it take to dry malted barley?", "answer": "30 hours", "ae_score": -0.5150247540460948, "qg_score": null}, {"question": "How long does it take to dry malted barley?", "answer": "30 hours", "ae_score": -0.5150247540460948, "qg_score": null}], "content": "Some Scotch whisky distilleries, such as those on Islay, use peat fires to dry malted barley. The drying process takes about 30 hours. This gives the whiskies a distinctive smoky flavour, often called \"peatiness\".The peatiness, or degree of peat flavor, of a whisky is calculated in ppm of phenol. The normal Highland whiskies have a peat level of up to 30 ppm, and the whiskies on Islay usually have up to 50 ppm. In rare types, like the Octomore, the whisky can have more than 100 ppm of phenol.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Characteristics and uses", "_id": "18--3--0---1", "title": "Scotch Whisky: Peaty Peaty Peaty Scotch Whisk"}
{"qas": [{"question": "What is peat moss and how does it work?", "answer": ""}, {"question": "Who makes peat in the republic of ireland?", "answer": "Bord na M\u00f3na", "ae_score": -0.3354344812571438, "qg_score": null}, {"question": "Who makes peat in the republic of ireland?", "answer": "Bord na M\u00f3na", "ae_score": -0.3354344812571438, "qg_score": null}], "content": "In Ireland, large-scale domestic and industrial peat usage is widespread. In the Republic of Ireland, a state-owned company called Bord na M\u00f3na is responsible for managing peat production. It produces milled peat which is used in power stations. It sells processed peat fuel in the form of peat briquettes which are used for domestic heating. These are oblong bars of densely compressed, dried, and shredded peat.  Peat moss is a manufactured product for use in garden cultivation. Turf (dried out peat sods) is very commonly used in rural areas.\nIn Northern Ireland there is small-scale domestic turf cutting in rural areas, but areas of bog lands have been diminished because of changes in agriculture. Afforestation has seen the establishment of tentative steps towards conservation, such as at Peatlands Park, County Armagh, which is an Area of Special Scientific Interest.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "In Ireland", "_id": "18--3--1---1", "title": "Peatlands Park, County Armagh"}
{"qas": [{"question": "How did they extract peat from the Somerset Levels?", "answer": ""}, {"question": "When was the british patent naphtha company established?", "answer": "1844", "ae_score": -0.5807306917889579, "qg_score": null}, {"question": "When was the british patent naphtha company established?", "answer": "1844", "ae_score": -0.5807306917889579, "qg_score": null}], "content": "The extraction of peat from the Somerset Levels is known to have taken place during Roman times, and has been carried out since the Levels were first drained. On Dartmoor there were several commercial distillation plants formed and run by the British Patent Naphtha Company in 1844. These produced naphtha on a commercial scale from the high-quality local peat.\nFenn's, Whixall and Bettisfield Mosses are elements of a post-Ice Age peat bog that straddles the England-Wales border. Only lightly hand-dug, it is now a national nature reserve which is being restored to natural condition and contains many rare plant and animal species due to the acidic environment created by the peat.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "In England", "_id": "18--3--2---1", "title": "Dartmoor Peat Bogs"}
{"qas": [{"question": "Why is peat still a fossil fuel in Finland?", "answer": ""}, {"question": "How much of finland's energy comes from peat?", "answer": "6.2%", "ae_score": -0.649517617558557, "qg_score": null}, {"question": "How much of finland's energy comes from peat?", "answer": "6.2%", "ae_score": -0.649517617558557, "qg_score": null}], "content": "The climate, geography and environment of Finland favour bog and peat bog formation. Peat is available in considerable quantities: some estimates put the amount of peat in Finland alone to be twice the size of the North Sea oil reserves. This abundant resource (often mixed with wood at an average of 2.6%) is burned to produce heat and electricity. Peat provides around 6.2% of Finland's annual energy production, second only to Ireland. The contribution of peat to greenhouse gas emissions of Finland can exceed a yearly amount of 10 million tonnes carbon dioxide, equal to the total emissions of all passenger car traffic in Finland.\nFinland classifies peat as a slowly renewing biomass fuel, and that position has also been taken by the European Union. The Intergovernmental Panel on Climate Change has taken the position that peat is not a fossil fuel. Peat producers in Finland often claim that peat is a special form of biofuel because of the relatively fast retake rate of released CO if the bog is not forested for the following 100 years. Also, agricultural and forestry-drained peat bogs actively release more CO annually than is released in peat energy production in Finland. The average regrowth rate of a single peat bog, however, is indeed slow, from 1,000 up to 5,000 years. Furthermore, it is a common practice to forest used peat bogs instead of giving them a chance to renew, leading to lower levels of CO storage than the original peat bog.\nAt 106 g CO/MJ, the carbon dioxide emissions of peat are higher than those of coal (at 94.6 g CO/MJ) and natural gas (at 56.1). According to one study, increasing the average amount of wood in the fuel mixture from the current 2.6% to 12.5% would take the emissions down to 93 g CO/MJ, though little effort is being made to achieve this.\nPeat extraction is also seen by some conservationists as the main threat to mire biodiversity in Finland. The International Mire Conservation Group (IMCG) in 2006 urged the local and national governments of Finland to protect and conserve the remaining pristine peatland ecosystems. This includes the cessation of drainage and peat extraction in intact mire sites and the abandoning of current and planned groundwater extraction that may affect these sites. A proposal for a Finnish peatland management strategy was presented to the government in 2011, after a lengthy consultation phase.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "In Finland", "_id": "18--3--3---1", "title": "The Impact of Peat on Finland's Biodiversity"}
{"qas": [{"question": "How did peat become the main source of energy for the Soviet Union?", "answer": ""}, {"question": "What percentage of the soviet union's energy came from peat in 1980?", "answer": "1%", "ae_score": -0.2192609392720489, "qg_score": null}, {"question": "What percentage of the soviet union's energy came from peat in 1980?", "answer": "1%", "ae_score": -0.2192609392720489, "qg_score": null}], "content": "Use of peat for energy production was prominent during the Soviet Union, with the peak occurring in 1965 and declining from that point. In 1929, over 40% of the Soviet Union's electric energy came from peat, which dropped to 1% by 1980.\nIn the 1960s, larger sections of swamps and bogs in Western Russia were drained for agricultural use and to generate peat fields for mining.  Plans are underway to increase peat output and increase peat's contribution to Russian energy generation. However, there is concern about the environmental impact as peat fields are flammable, drainage degrades eco-systems, and burning of peat releases carbon dioxide.<ref name=treehugger/> Due to 2010 forest and peat fires the Russian government is under heavy pressure to finance re-flooding of the previously drained bogs around Moscow. The initial costs for the programme are estimated to be about 20 to 25 billion rubles, which is close to 500 million euros.\nCurrently, Russia is responsible for 17% of the world's peat production, and 20% of the peat that it produces, 1.5 million tons, is used for energy purposes. Shatura Power Station in Moscow Oblast and Kirov Power Station in Kirov Oblast are the two largest peat power stations in the world.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "In Russia", "_id": "18--3--4---1", "title": "Peat Power Plants in Russia"}
{"qas": [{"question": "What is the purpose of peat?", "answer": ""}, {"question": "Where do they grow peat in the world?", "answer": "Sweden", "ae_score": -0.8548090515379229, "qg_score": null}, {"question": "Where do they grow peat in the world?", "answer": "Sweden", "ae_score": -0.8548090515379229, "qg_score": null}], "content": "In Sweden, farmers use dried peat to absorb excrement from cattle that are wintered indoors. The most important property of peat is retaining moisture in container soil when it is dry and yet preventing the excess of water from killing roots when it is wet. Peat can store nutrients although it is not fertile itself \u2013 it is a polyelectrolytic with a high ion exchange capacity due to its oxidized lignin. Peat is discouraged as a soil amendment by the Royal Botanic Gardens, Kew, England, and has been since 2003. While bark-based peat-free potting soil mixes are on the rise, particularly in the U.K., peat remains an important raw material in horticulture in Canada, as well as parts of the United States. However, it is recommended to treat peat thermally, e.g., through soil steaming, in order to kill inherent pests and reactivate nutrients.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Use in agriculture", "_id": "18--3--5---1", "title": "Peat is an important raw material for horticulture in Canada"}
{"qas": [{"question": "What is peat and why does it stain water?", "answer": ""}, {"question": "What is the name of the soft stuff that softens water?", "answer": "Peat", "ae_score": -1.149647088589779, "qg_score": null}, {"question": "What is the name of the soft stuff that softens water?", "answer": "Peat", "ae_score": -1.149647088589779, "qg_score": null}], "content": "Peat is sometimes used in freshwater aquaria, most commonly in soft water or blackwater river systems, such as those mimicking the Amazon River basin. In addition to being soft in texture and therefore suitable for demersal (bottom-dwelling) species such as ''Corydoras'' catfish, peat is reported to have a number of other beneficial functions in freshwater aquaria. It softens water by acting as an ion exchanger; it also contains substances that are beneficial for plants, and for the reproductive health of fishes. It can even prevent algae growth and kill microorganisms. Peat often stains the water yellow or brown due to the leaching of tannins.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Freshwater aquaria", "_id": "18--3--6---1", "title": "Peat in Freshwater Aquarien"}
{"qas": [{"question": "What is the purpose of peat?", "answer": ""}, {"question": "What is the purpose of peat in water?", "answer": "water filtration", "ae_score": -0.5260960966786267, "qg_score": null}, {"question": "What is the purpose of peat in water?", "answer": "water filtration", "ae_score": -0.5260960966786267, "qg_score": null}], "content": "Peat is used in water filtration, such as for the treatment of septic tank effluent, as well as for urban runoff. Due to its purifying properties, peat also serves as a filter for septic tanks and may be used as a water purifier.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Water filtration", "_id": "18--3--7---1", "title": "Peat is used as a filter for septic tank effluent"}
{"qas": [{"question": "Why is peat used in so many different ways?", "answer": ""}, {"question": "What is used in balneotherapy to treat disease?", "answer": "Peat", "ae_score": -0.8799975708469657, "qg_score": null}, {"question": "What is used in balneotherapy to treat disease?", "answer": "Peat", "ae_score": -0.8799975708469657, "qg_score": null}], "content": "Peat is widely used in balneotherapy (the use of bathing to treat disease). Many traditional spa treatments include peat as part of peloids. Such health treatments have a very long tradition in Europe, especially in Poland, the Czech Republic, Germany and Austria. Some of these old spas go back to the 18th century, and they are still active today. The most common types of peat application in balneotherapy are peat muds, poultices, and suspension baths.", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Balneotherapy", "_id": "18--3--8---1", "title": "Peat is widely used in balneotherapy"}
{"qas": [{"question": "How do we know the age of the Earth?", "answer": ""}, {"question": "When was the first study of peat published?", "answer": "1980", "ae_score": -0.2554334563392332, "qg_score": null}, {"question": "When was the first study of peat published?", "answer": "1980", "ae_score": -0.2554334563392332, "qg_score": null}], "content": "Authors Rydin and Jeglum in ''Biology of Habitats'' described the concept of peat archives, a phrase coined by influential peatland scientist Harry Godwin in 1981.\nIn ''Quaternary Palaeoecology'', first published in 1980, Birks and Birks described how paleoecological studies \"of peat can be used to reveal what plant communities were present (locally and regionally), what time period each community occupied, how environmental conditions changed, and how environment affected the ecosystem in that time and place.\"\nScientists continue to compare modern mercury (Hg) accumulation rates in bogs with historical natural archives records in peat bogs and lake sediments to estimate the potential human impacts on the biogeochemical cycle of mercury, for example. Over the years different dating models and technologies for measuring date sediments and peat profiles accumulated over the last 100\u2013150 years, have been used, including the widely used vertical distribution of 210Pb, the ICP-SMS and more recently the Initial Penetration (IP).", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Peat archives", "_id": "18--3--9---1", "title": "Peat Archives and the Biogeochemical Cycle of Mercury"}
{"qas": [{"question": "How do peat holes form?", "answer": ""}, {"question": "What is the name of the erosion of a peat?", "answer": "hags", "ae_score": -0.7352655071209554, "qg_score": null}, {"question": "What is the name of the erosion of a peat?", "answer": "hags", "ae_score": -0.7352655071209554, "qg_score": null}], "content": "Peat \"hags\" are a form of erosion that occurs at the sides of gullies that cut into the peat or, sometimes, in isolation. Hags may result when flowing water cuts downwards into the peat or when fire or overgrazing exposes the peat surface. Once the peat is exposed in these ways, it is prone to further erosion by wind, water and livestock. The result is overhanging vegetation and peat. Hags are too steep and unstable for vegetation to establish and so they continue to erode unless restoration action is taken.<ref name=YPP/>", "page_name": "Peat", "page_id": "Peat", "heading": "Characteristics and uses", "sub_heading": "Peat hags", "_id": "18--3--10---1", "title": "Peat Hags \u2014 a form of erosion that occurs at the side of "}
{"qas": [{"question": "What is happening to the world's peatlands?", "answer": ""}, {"question": "What does the organic carbon in peatland turn into?", "answer": "carbon dioxide", "ae_score": -0.7307036496817079, "qg_score": null}, {"question": "What does the organic carbon in peatland turn into?", "answer": "carbon dioxide", "ae_score": -0.7307036496817079, "qg_score": null}], "content": "Large areas of organic wetland (peat) soils are currently drained for agriculture, forestry, and peat extraction. This process is taking place all over the world. This not only destroys the habitat of many species, but also heavily fuels climate change. As a result of peat drainage, the organic carbon\u2014which was built up over thousands of years and is normally under water\u2014is suddenly exposed to the air. It decomposes and turns into carbon dioxide (), which is released into the atmosphere. The global  emissions from drained peatlands have increased from 1,058 Mton in 1990 to 1,298 Mton in 2008 (>20%). This increase has particularly taken place in developing countries, of which Indonesia, China, Malaysia, and Papua New Guinea, are the fastest growing top emitters. This estimate excludes emissions from peat fires (conservative estimates amount to at least 4,000 Mton/-eq./yr for south-east Asia). With 174 Mton/-eq./yr the EU is after Indonesia (500 Mton) and before Russia (161 Mton) the World's 2nd largest emitter of drainage related peatland  (excl. extracted peat and fires). Total  emissions from the worldwide 500,000 km of degraded peatland may exceed 2.0 Gtons (including emissions from peat fires) which is almost 6% of all global carbon emissions.", "page_name": "Peat", "page_id": "Peat", "heading": "Environmental and ecological issues", "sub_heading": "Environmental and ecological issues", "_id": "18--4--0---1", "title": "Global Carbon Emissions from Degraded Peatlands"}
{"qas": [{"question": "Why is Indonesia so much more carbonated than the rest of the world?", "answer": ""}, {"question": "When is it predicted that peat bogs in southeast asia will be destroyed?", "answer": "2040", "ae_score": -0.2045148337825876, "qg_score": null}, {"question": "When is it predicted that peat bogs in southeast asia will be destroyed?", "answer": "2040", "ae_score": -0.2045148337825876, "qg_score": null}], "content": "Peat has a high carbon content and can burn under low moisture conditions. Once ignited by the presence of a heat source (e.g., a wildfire penetrating the subsurface), it smolders. These smoldering fires can burn undetected for very long periods of time (months, years, and even centuries) propagating in a creeping fashion through the underground peat layer.\nDespite the damage that the burning of raw peat can cause, bogs are naturally subject to wildfires and depend on the wildfires to keep woody competition from lowering the water table and shading out many bog plants. Several families of plants including the carnivorous Sarracenia, Dionaea, Utricularia and even non-carnivorous plants such as the Sandhills Lily, Toothache Grass and many species of orchid are now threatened and in some cases endangered from the combined forces of human drainage, negligence and absence of fire.\nRecent burning of peat bogs in Indonesia, with their large and deep growths containing more than 50 billion tons of carbon, has contributed to increases in world carbon dioxide levels Peat deposits in Southeast Asia could be destroyed by 2040.\nIt is estimated that in 1997, peat and forest fires in Indonesia released between 0.81 and 2.57 Gt of carbon; equivalent to 13\u201340 percent of the amount released by global fossil fuel burning, and greater than the carbon uptake of the world's biosphere. These fires may be responsible for the acceleration in the increase in carbon dioxide levels since 1998.  More than 100 peat fires in Kalimantan and East Sumatra have continued to burn since 1997. Each year, the peat fires in Kalimantan and East Sumatra ignite new forest fires above the ground.\nIn North America, peat fires can occur during severe droughts throughout their occurrence, from boreal forests in Canada to swamps and fens in the subtropical southern Florida Everglades. Once a fire has burnt through the area, hollows in the peat are burnt out, and hummocks are desiccated but can contribute to ''Sphagnum'' recolonization.\nIn the summer of 2010, an unusually high heat wave of up to 40 C ignited large deposits of peat in Central Russia, burning thousands of houses and covering the capital of Moscow with a toxic smoke blanket. The situation remained critical until the end of August 2010.", "page_name": "Peat", "page_id": "Peat", "heading": "Environmental and ecological issues", "sub_heading": " Peat fires", "_id": "18--4--1---1", "title": "Peat and Forest Fires in Southeast Asia: A Threat to the World"}
{"qas": [{"question": "What is the Wetlands Restoration Project and how does it work?", "answer": ""}, {"question": "When did the wetlands ecosystem and tropical peat swamp forest rehabilitation project start?", "answer": "June 2002", "ae_score": -0.4442772779871434, "qg_score": null}, {"question": "When did the wetlands ecosystem and tropical peat swamp forest rehabilitation project start?", "answer": "June 2002", "ae_score": -0.4442772779871434, "qg_score": null}], "content": "In June 2002, the United Nations Development Programme launched the Wetlands Ecosystem and Tropical Peat Swamp Forest Rehabilitation Project. This project was targeted to last for 5 years until 2007 and brings together the efforts of various non-government organisations.\nIn November 2002, the '''International Peat Society''' and the International Mire Conservation Group (IMCG) published guidelines on the \"Wise Use of Mires and Peatlands \u2014 Backgrounds and Principles including a framework for decision-making\". The aim of this publication is to develop mechanisms that can balance the conflicting demands on the global peatland heritage, to ensure its wise use to meet the needs of humankind.\nIn June 2008, the International Peat Society published the book ''Peatlands and Climate Change'', summarizing the currently available knowledge on the topic. In 2010, IPS presented a \"Strategy for Responsible Peatland Management\" which can be applied worldwide for decision-making.", "page_name": "Peat", "page_id": "Peat", "heading": "Wise use and protection", "sub_heading": "Wise use and protection", "_id": "18--5---1---1", "title": "The International Peat Society and the International Mire Conservation Group (IMCG) published a"}
{"qas": [{"question": "How did the idea of raising the minimum wage come about?", "answer": ""}, {"question": "When did the first sweatshop open in america?", "answer": "1910", "ae_score": -0.19704561829005404, "qg_score": null}, {"question": "When did the first sweatshop open in america?", "answer": "1910", "ae_score": -0.19704561829005404, "qg_score": null}], "content": "A sweatshop is a factory or workshop, especially in the clothing industry, where manual workers are employed at very low wages for long hours and under poor conditions.\nMany workplaces through history have been crowded, low-paying and without job security; but the concept of a sweatshop originated between 1830 and 1850 as a specific type of workshop in which a certain type of middleman, the ''sweater'', directed others in ''garment making'' (the process of producing clothing) under arduous conditions. The terms ''sweater'' for the middleman and ''sweat system'' for the process of subcontracting piecework were used in early critiques like Charles Kingsley's ''Cheap Clothes and Nasty'', written in 1850, which described conditions in London, England. The workplaces created for the '''sweating system''', a system of subcontracting in the tailoring trade were called ''sweatshops'' and might contain only a few workers or as many as 100 and more.\nBetween 1850 and 1900, sweatshops attracted the rural poor to rapidly growing cities, and attracted immigrants to places such as London and New York City's garment district, located near the tenements of New York's Lower East Side. These sweatshops incurred criticism: labour leaders cited them as crowded, poorly ventilated, and prone to fires and rat infestations: in many cases, there were many workers crowded into small tenement rooms.\nIn the 1890s, a group calling itself the National Anti-Sweating League was formed in Melbourne and campaigned successfully for a minimum wage via trade boards. A group with the same name campaigned from 1906 in the UK, resulting in the Trade Boards Act 1909.\nIn 1910, the International Ladies' Garment Workers' Union was founded to try to improve the condition of these workers.\nCriticism of garment sweatshops became a major force behind workplace safety regulation and labor laws. As some journalists strove to change working conditions, the term ''sweatshop'' came to refer to a broader set of workplaces whose conditions were considered inferior. In the United States, investigative journalists, known as Muckrakers, wrote expos\u00e9s of business practices, and progressive politicians campaigned for new laws. Notable expos\u00e9s of sweatshop conditions include Jacob Riis' photo documentary ''How the Other Half Lives'' and Upton Sinclair's book, ''The Jungle'' about the meat packing industry.\nIn 1911, negative public perceptions of sweatshops were galvanized by the Triangle Shirtwaist Factory Fire in New York City. The pivotal role of this time and place is chronicled at the Lower East Side Tenement Museum, part of the Lower East Side Tenement National Historic Site. While trade unions, minimum wage laws, fire safety codes, and labour laws have made sweatshops (in the original sense) rarer in the developed world, they did not eliminate them, and the term is increasingly associated with factories in the developing world.\nIn a report issued in 1994, the United States Government Accountability Office found that there were still thousands of sweatshops in the United States, using a definition of a ''sweatshop'' as any \"employer that violates more than one federal or state labor law governing minimum wage and overtime, child labor, industrial homework, occupational safety and health, workers' compensation, or industry registration\". This recent definition eliminates any historical distinction about the role of a middleman or the items produced, and focuses on the legal standards of developed country workplaces. An area of controversy between supporters of outsourcing production to the Third World and the anti-sweatshop movement is whether such standards can or should be applied to the workplaces of the developing world.\nSweatshops are also sometimes implicated in human trafficking when workers have been tricked into starting work without informed consent, or when workers are kept at work through debt bondage or mental duress, all of which are more likely if the workforce is drawn from children or the uneducated rural poor. Because they often exist in places without effective workplace safety or environmental laws, sweatshops sometimes injure their workers or the environment at greater rates than would be acceptable in developed countries. Sometimes penal labor facilities (employing prisoners) are grouped under the sweatshop label. Sweatshops conditions resemble prison labor in many cases, especially from a common found Western perspective. Recently in 2014 \"Apple was caught failing to protect its workers\" in one of its Pegatron factories. Overwhelmed workers were caught falling asleep during their 12-hour shift and an undercover reporter had to work 18 days in a row.   Sweatshops in question carry characteristics such as compulsory pregnancy tests for female laborers and terrorization from supervisors into submission. Workers then go into a state of forced labor, if even one day of work is not accounted for, most are immediately fired. These working conditions have been the source of suicidal unrest within factories in the past. Chinese sweatshops known to have increased numbers of suicidal employees have suicide nets covering the whole site, in place to stop over-worked and stressed employees leaping to their deaths.\nSweatshops have proved a difficult issue to resolve because their roots lie in the conceptual foundations of the world economy. Developing countries like India, China, Vietnam, Bangladesh, and Honduras encourage the outsourcing of work from the developed world to provide work for their people and profits for their employers. Outsourced work can, at times, bring some form of wealth to impoverished countries. Regardless of Western labor concerns, people living in poor conditions prefer low wages to none at all. The shift of production to developing countries is part of globalization, but may also be described as neoliberal globalization to emphasize the role that free market economics plays in outsourcing.", "page_name": "Sweatshop", "page_id": "Sweatshop", "heading": "History", "sub_heading": "History", "_id": "19--0---1---1", "title": "What is a Sweatshop?"}
{"qas": [{"question": "How did the working class in the U.S. become so concerned about working conditions?", "answer": ""}, {"question": "Who is the mayor of north olmsted ohio?", "answer": "Ed Boyle", "ae_score": -0.33506076751894504, "qg_score": null}, {"question": "Who is the mayor of north olmsted ohio?", "answer": "Ed Boyle", "ae_score": -0.33506076751894504, "qg_score": null}], "content": "Some of the earliest sweatshop critics were found in the 19th century abolitionist movement that had originally coalesced in opposition to chattel slavery, and many abolitionists saw similarities between slavery and sweatshop work. As slavery was successively outlawed in industrial countries between 1794 (in France) and 1865 (in the United States), some abolitionists sought to broaden the anti-slavery consensus to include other forms of harsh labor, including sweatshops. As it happened, the first significant law to address sweatshops (the Factory Act of 1833) was passed in the United Kingdom at the same time that the slave trade (1807) and ownership of slaves (1833) were made illegal.\nUltimately, the abolitionist movement split apart. Some advocates focused on working conditions and found common cause with trade unions and Marxists and socialist political groups, or progressive movement and the muckrakers. Others focused on the continued slave trade and involuntary servitude in the colonial world. For those groups that remained focused on slavery, sweatshops became one of the primary objects of controversy. Workplaces across multiple sectors of the economy were categorized as sweatshops. However, there were fundamental philosophical disagreements about what constituted slavery. Unable to agree on the status of sweatshops, the abolitionists working with the League of Nations and the United Nations ultimately backed away from efforts to define slavery, and focused instead on a common precursor of slavery \u2013 human trafficking.\nThose focused on working conditions included Friedrich Engels, whose book ''The Condition of the Working Class in England in 1844'' would inspire the Marxist movement named for his collaborator, Karl Marx. In the United Kingdom the Factory Act was revised six further times between 1844 and 1878 to help improve the condition of workers by limiting work hours and the use of child labor. The formation of the International Labour Organization in 1919 under the League of Nations and then the United Nations sought to address the plight of workers the world over. Concern over working conditions as described by muckraker journalists during the Progressive Era in the United States saw the passage of new workers rights laws and ultimately resulted in the Fair Labor Standards Act of 1938, passed during the New Deal.\nOn February 4, 1997 Mayor Ed Boyle of North Olmsted, in the U.S. state of Ohio, introduced the first piece of legislation prohibiting the government of purchasing, renting, or taking on consignment any and all goods made under sweatshop conditions and including in the definition those goods made by political prisoners and incarcerated criminals.  Similar legislation was subsequently passed in other American cities such as Detroit, New York, and San Francisco.  Later Mayor Boyle introduced the legislation to the Mayors and Managers Association where it was immediately endorsed, and he was invited by President Bill Clinton to address a panel studying the subject in Washington, DC.\nClothing and footwear factories overseas have progressively improved working conditions because the high demand of anti-sweatshop movement, labour right advocates. Sweatshops over seas have been receiving enormous amounts of pressure. Around the working conditions from college students, and other opponents of sweatshops which has led to some of the powerful companies like Nike and the Gap who have agreed to cut back on child labour, restrict the use of dangerous and poisonous chemicals, and drop the average rate of employees working 80 hour weeks, according to groups that monitor such factories. Labour advocates say, this could be a major turning point after 4 decades of workers in Asia and Latin American factories being under paid, under appreciated and working in an unsafe environment.", "page_name": "Sweatshop", "page_id": "Sweatshop", "heading": "Anti-sweatshop movement", "sub_heading": "Anti-sweatshop movement", "_id": "19--1---1---1", "title": "The Rise of Sweatshops in America"}
{"qas": [{"question": "How do sweatshops offer better jobs than what is available in local communities?", "answer": ""}, {"question": "Who is the founder of the sweaterhop?", "answer": "Johan Norberg", "ae_score": -0.08398724905563819, "qg_score": null}, {"question": "Who is the founder of the sweaterhop?", "answer": "Johan Norberg", "ae_score": -0.08398724905563819, "qg_score": null}], "content": "In 1997, economist Jeffrey Sachs said, \"My concern is not that there are too many sweatshops, but that there are too few.\" Sachs and other proponents of free trade and the global movement of capital cite the economic theory of comparative advantage, which states that international trade will, in the long run, make all parties better off. The theory holds that developing countries improve their condition by doing something that they do \"better\" than industrialized nations (in this case, they charge less but do the same work). Developed countries will also be better off because their workers can shift to jobs that they do better. These are jobs that some economists say usually entail a level of education and training that is exceptionally difficult to obtain in the developing world. Thus, economists like Sachs say, developing countries get factories and jobs that they would not otherwise. Some would say with this situation occurs when developing countries try to increase wages because sweatshops tend to just get moved on to a new state that is more welcoming. This leads to a situation where states often don't try to increase wages for sweatshop workers for fear of losing investment and boosted GDP. However, this only means average wages around the world will increase at a steady rate. A nation only gets left behind if it demands wages higher than the current market price for that labor.\nWhen asked about the working condition in sweatshops, proponents say that although wages and working conditions may appear inferior by the standards of developed nations, they are actually improvements over what the people in developing countries had before. It is said that if jobs in such factories did not improve their workers' standard of living, those workers would not have taken the jobs when they appeared. It is also often pointed out that, unlike in the industrialized world, the sweatshops are not replacing high-paying jobs. Rather, sweatshops offer an improvement over subsistence farming and other back-breaking tasks, or even prostitution, trash picking, or starvation by unemployment.\nSweatshops, not only offer better jobs then what are available in the local communities but the wages that the workers receive lead to a better standard of living for the workers and their families. Raveena Aulkah a journalist for Mail Online News went undercover as a sweatshop worker and documented her experience. One of her main takeaways was that even though working conditions were not optimal the families could now afford \"goats, schooling, and clothing for their families\".\nThe absence of the work opportunities provided by sweatshops can quickly lead to malnourishment or starvation. After the Child Labor Deterrence Act was introduced in the US, an estimated 50,000 children were dismissed from their garment industry jobs in Asia, leaving many to resort to jobs such as \"stone-crushing, street hustling, and prostitution.\" UNICEF's 1997 ''State of the World's Children'' study found these alternative jobs \"more hazardous and exploitative than garment production.\" As Nobel prize-winning economist Paul Krugman states in a 1997 article for Slate, \"as manufacturing grows in poor countries, it creates a ripple effect that benefits ordinary people: 'The pressure on the land becomes less intense, so rural wages rise; the pool of unemployed urban dwellers always anxious for work shrinks, so factories start to compete with each other for workers, and urban wages also begin to rise.' In time average wages creep up to a level comparable to minimum-wage jobs in the United States.\"\nWriter Johan Norberg, a proponent of market economics, points out an irony:\nHeavy-handed responses to reports of child labor and worker rights abuses such as widespread boycotts can be counterproductive if the net effect is simply to eliminate contracts with suppliers rather than to reform their employment practices.  A 2005 article in the ''Christian Science Monitor'' states, \"For example, in Honduras, the site of the infamous Kathy Lee Gifford sweatshop scandal, the average apparel worker earns $13.10 per day, yet 44 percent of the country's population lives on less than $2 per day... In Cambodia, Haiti, Nicaragua, and Honduras, the average wage paid by a firm accused of being a sweatshop is more than double the average income in that country's economy.\" On three documented occasions during the 1990s, anti-sweatshop activists in rich countries have apparently caused increases in child prostitution in poor countries. In Bangladesh, the closure of several sweatshops run by a German company put Bangladeshi children out of work, and some ended up working as prostitutes, turning to crime, or starving to death. In Pakistan, several sweatshops closed, including ones run by Nike, Reebok, and other corporations\u2014which caused some of those Pakistani children to turn to prostitution. In Nepal, a carpet manufacturing company closed several sweatshops, resulting in thousands of Nepalese girls turning to prostitution.\nA 1996 study of corporate codes of conduct in the apparel industry by the U.S. Department of Labor has concluded that corporate codes of conduct that monitor labor norms in the apparel industry, rather than boycott or eliminate contracts upon the discovery of violations of internationally recognized labor norms, are a more effective way to eliminate child labor and the exploitation of children, provided they provide for effective monitoring that includes the participation of workers and their knowledge of the standards to which their employers are subject.\nArguably, the United States underwent a similar process during its own industrialization where child labor and the suppression of worker organizations were prevalent.  According to an article in Gale Opposing Viewpoints in Context, sweatshops became prevalent in the United States during the Industrial Revolution. Although the working conditions and wages in these factories were very poor, as new jobs in factories began to appear, people left the hard life of farming to work in these factories, and the agricultural nature of the economy shifted into a manufacturing one because of this industrialization. However, during this new industrialized economy, the labor movement drove the rise in the average level of income as factory workers began to demand better wages and working conditions. Through much struggle, sufficient wealth was created and a large middle class began to emerge. Workers and advocates were able to achieve basic rights for workers, which included the right to form unions, and negotiate terms such as wages, overtime pay, health insurance, and retirement pensions; and eventually they were also able to attain legal protections such as minimum wage standards, and discrimination and sexual abuse protections. Furthermore, Congress set forth to ensure a minimum set of safety standards were followed in workplaces by passing the Occupational Safety and Health Act (OSHA) in 1970. These developments were able to improve working environments for Americans but it was through sweatshops that the economy grew and people were able to accumulate wealth and move out of poverty.\nIn contrast, similar efforts in developing nations have not produced the same results, because of corruption and lack of democracy in communist nations such as China and Vietnam, worker intimidation and murder in Latin America\u2014and corruption throughout the developing world. These barriers prevent creation of similar legal protections for workers in these countries, as numerous studies by the International Labor Organization show.  Nonetheless, a boycott approach to protesting these conditions is likely to hurt workers willing to accept employment even under poor working conditions, as a loss of employment would result in a comparatively worse level of poverty. According to a November 2001 BBC article, in the previous two months, 100,000 sweatshop workers in Bangladesh had been put off work. The workers petitioned their government to lobby the U.S. government to repeal its trade barriers on their behalf to retain their jobs.\nDefenders of sweatshops cite Hong Kong, Singapore, South Korea, and Taiwan as recent examples of countries that benefited from having sweatshops.\nIt should be noted, however, that in these countries, legislative and regulatory frameworks to protect and promote labor rights and the rights of workers against unsafe and exploitative working conditions exist, and studies have shown no systematic relationship between labor rights, such as collective bargaining and the freedom of association, and national economic growth.", "page_name": "Sweatshop", "page_id": "Sweatshop", "heading": "Modern anti-globalization movement", "sub_heading": "Modern anti-globalization movement", "_id": "19--2--0---1", "title": "The Rise of Sweatshops in the World"}
{"qas": [{"question": "What is sweatshop free?", "answer": ""}, {"question": "What company claims to be sweatshop free?", "answer": "American Apparel", "ae_score": -0.4325512374061806, "qg_score": null}, {"question": "What company claims to be sweatshop free?", "answer": "American Apparel", "ae_score": -0.4325512374061806, "qg_score": null}], "content": "Sweatshop-free is a term the fashion brand American Apparel created to mean coercion-free, fair-compensation for garment workers who make their products. American Apparel claims its employees earn on average double the federal minimum wage. They receive a number of employee benefits, from health insurance to subsidized transportation and meals, and have access to an onsite medical clinic. It has been heavily featured in the company's advertisements for nearly a decade and become a common term in the garment industry.", "page_name": "Sweatshop", "page_id": "Sweatshop", "heading": "Sweatshop-free", "sub_heading": "Sweatshop-free", "_id": "19--3---1---1", "title": "Sweatshop-free is a term the fashion brand American Apparel invented to mean"}
{"qas": [{"question": "Why are meringues shaped the way they are?", "answer": ""}, {"question": "Who was the first person to introduce meringue pastry?", "answer": "Antonin Car\u00eame", "ae_score": -0.1587901359043688, "qg_score": null}, {"question": "Who was the first person to introduce meringue pastry?", "answer": "Antonin Car\u00eame", "ae_score": -0.1587901359043688, "qg_score": null}], "content": "It has been claimed that meringue was invented in the Swiss village of Meiringen and improved by an Italian chef named Gasparini in the 18th century. However this claim is contested; the ''Oxford English Dictionary'' states that the French word is of unknown origin.  It is sure nevertheless that the name ''meringue'' for this confection first appeared in print in Fran\u00e7ois Massialot's cookbook of 1692. The word ''meringue'' first appeared in English in 1706 in an English translation of Massialot's book. Two considerably earlier seventeenth-century English manuscript books of recipes give instructions for confections that are recognizable as meringue, though called \"white biskit bread\" in the book of recipes started in 1604 by Lady Eleanor Poole Fettiplace (c. 1570 \u2013 c. 1647) of ''Gloucestershire'' and called \"pets\" in the manuscript of collected recipes written by Lady Rachel Fane (1612/13\u20131680), of Knole, Kent. Slowly baked meringues are still referred to as \"pets\" in the Loire region of France due to their light and fluffy texture.\nMeringues were traditionally shaped between two large spoons, as they are generally at home today. Meringue piped through a pastry bag was introduced by Antonin Car\u00eame.", "page_name": "Meringue", "page_id": "Meringue", "heading": "History", "sub_heading": "History", "_id": "20--0---1---1", "title": "''Meringue'' is a French concoction"}
{"qas": [{"question": "What is the difference between meringue and other desserts?", "answer": ""}, {"question": "What is the french name for the island of meringue?", "answer": "Floating Island", "ae_score": null, "qg_score": null}, {"question": "What is the french name for the island of meringue?", "answer": "Floating Island", "ae_score": null, "qg_score": null}], "content": "There are several types of meringue: the sweetened, beaten egg whites that form the \"islands\" of Floating Island (also known in French as ''\u00eele flottante''); the partly cooked toppings of lemon meringue pie and other meringue-topped desserts; and the classic dry featherweight meringue. Different preparation techniques produce these results.", "page_name": "Meringue", "page_id": "Meringue", "heading": "Types of Meringue", "sub_heading": "Types of Meringue", "_id": "20--1---1---1", "title": "Meringue \u2014 Desserts and Desserts"}
{"qas": [{"question": "Why do egg whites get hard when you lift them?", "answer": ""}, {"question": "How many stages of meringue egg whites are there?", "answer": "three", "ae_score": -0.6210329039957908, "qg_score": null}, {"question": "How many stages of meringue egg whites are there?", "answer": "three", "ae_score": -0.6210329039957908, "qg_score": null}], "content": "Protein distribution in egg whites is as follows: (54%) ovalbumin, (13%) conalbumin/ ovotransferrin, (11%) ovomucoid, (4%) ovoglobulins, (3.5%) lysozyme, and (2%) ovomucin. Ovoglobulins drive foaming, ovomucin is the main stabilization agent, and the remainder of the proteins interact to contribute to overall foaming and stability. When egg whites are beaten, some of the hydrogen bonds in the proteins break, causing the proteins to unfold (\"denature\") and to aggregate non-specifically. When these egg white proteins denature (due to agitation from beating), their hydrophobic regions are exposed and the formation of intermolecular protein-protein interactions is promoted. These protein-protein interactions, usually disulfide bridges, create networks responsible for the structure of the foam and this change in structure leads to the stiff consistency required for meringues. The use of a copper bowl, or the addition of cream of tartar is required to additionally denature the proteins to create the firm peaks, otherwise the whites will not be firm. Plastic bowls, wet or greasy bowls will likely result in the meringue mix being prevented from becoming peaky. Wiping the bowl with a wedge of lemon to remove any traces of grease can often help the process.\nWhen beating egg whites, they are classified in three stages according to the peaks they form when the beater is lifted: soft, firm, and stiff peaks\nEgg whites and sugar are both hygroscopic (water-attracting) chemicals. Consequently, meringue becomes soggy when refrigerated or stored in a high-humidity environment. This quality also explains the problem called \"weeping\" or \"sweating\", in which beads of moisture form on all surfaces of the meringue. Sweating is a particular problem for French meringues in which the granulated sugar is inadequately dissolved in the egg whites, and for high-moisture pie fillings.", "page_name": "Meringue", "page_id": "Meringue", "heading": "Chemistry", "sub_heading": "Chemistry", "_id": "20--2---1---1", "title": "Egg Whites and Meringue \u2014 A Guide"}
{"qas": [{"question": "How do Meringues stay in the oven for so long?", "answer": ""}, {"question": "What type of cake is a meringue tart?", "answer": "sponge cake", "ae_score": -0.12609280081544114, "qg_score": null}, {"question": "What type of cake is a meringue tart?", "answer": "sponge cake", "ae_score": -0.12609280081544114, "qg_score": null}], "content": "Meringues eaten like biscuits are baked at a very low heat for a long time. One name for them is \"Forgotten Cookies\" as they can be left in a gas oven for long periods of time after the cooking is done. They are not supposed to be \"tanned\" at all, but they need to be very crisp and dry. They will keep for at least a week if stored in an airtight container.\nMeringue can be used as the basis for various desserts including baked Alaska, dacquoise, Esterh\u00e1zy torte, Eton mess, floating island, key lime pie, Kyiv cake, lemon meringue pie, macarons, merveilleux, pavlova, Queen of Puddings, sans rival, silvana, Spanische Windtorte, and Zuger Kirschtorte. In some recipes, the meringue may be cooked at a higher temperature for a shorter amount of time, resulting in a soft meringue with slightly browned peaks on top.\nAnother dish is \"Meringue de Angel\", which consists of shortbread biscuits layered with meringue and lemon curd, topped off with drizzled lemon glaze. Variations include raspberries, peaches, mangos, blueberries, blackberries, pineapple, papayas, honeydew, oranges, cantaloupe, or cherries and strawberries.\nMeringue may be used for embellishment. It can be formed into whimsical shapes, like mushrooms, or piped into a crisp basket that is baked and filled later with cake, fruit, or flowers.\nA meringue tart is a sponge cake covered with meringue.", "page_name": "Meringue", "page_id": "Meringue", "heading": "Uses", "sub_heading": "Uses", "_id": "20--3---1---1", "title": "Meringue and Desserts"}
{"qas": [{"question": "Why is meringue a fat-free food?", "answer": ""}, {"question": "What kind of food is meringue when it's baked?", "answer": "fat-free food", "ae_score": -0.5658290273625627, "qg_score": null}, {"question": "What kind of food is meringue when it's baked?", "answer": "fat-free food", "ae_score": -0.5658290273625627, "qg_score": null}], "content": "Meringue is a fat-free food, because the presence of even small amounts of fat before the meringue is baked causes the beaten egg whites to collapse. The principal nutritional components are protein from the egg whites and simple carbohydrates from the refined sugar.", "page_name": "Meringue", "page_id": "Meringue", "heading": "Nutritional content", "sub_heading": "Nutritional content", "_id": "20--4---1---1", "title": "Meringue is a fat-free food"}
{"qas": [{"question": "Why is bush meat such a big deal in Asia?", "answer": ""}, {"question": "What is a threat to malaysia's natural diversity?", "answer": "illegal hunting and trade", "ae_score": -0.19157790514278522, "qg_score": null}, {"question": "What is a threat to malaysia's natural diversity?", "answer": "illegal hunting and trade", "ae_score": -0.19157790514278522, "qg_score": null}], "content": "Anthropologists believe that the Stone Age people and hunter-gatherers relied on wildlife, both plants and animals, for their food. In fact, some species may have been hunted to extinction by early human hunters. Today, hunting, fishing, and gathering wildlife is still a significant food source in some parts of the world. In other areas, hunting and non-commercial fishing are mainly seen as a sport or recreation, with the edible meat as mostly a side benefit of it. Meat sourced from wildlife that is not traditionally regarded as game is known as bush meat. The increasing demand for wildlife as a source of traditional food in East Asia is decimating populations of sharks, primates, pangolins and other animals, which they believe have aphrodisiac properties.\nIn November 2008, almost 900 plucked and \"oven-ready\" owls and other protected wildlife species were confiscated by the Department of Wildlife and National Parks in Malaysia, according to TRAFFIC.  The animals were believed to be bound for China, to be sold in wild meat restaurants.  Most are listed in CITES (the Convention on International Trade in Endangered Species of Wild Fauna and Flora) which prohibits or restricts such trade.\nMalaysia is home to a vast array of amazing wildlife. However, illegal hunting and trade poses a threat to Malaysia's natural diversity.\nA November 2008 report from biologist and author Sally Kneidel, PhD, documented numerous wildlife species for sale in informal markets along the Amazon River, including wild-caught marmosets sold for as little as $1.60 (5 Peruvian soles). Many Amazon species, including peccaries, agoutis, turtles, turtle eggs, anacondas, armadillos, etc., are sold primarily as food.  Others in these informal markets, such as monkeys and parrots, are destined for the pet trade, often smuggled into the United States. Still other Amazon species are popular ingredients in traditional medicines sold in local markets. The medicinal value of animal parts is based largely on superstition.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Food, pets, and traditional medicines", "sub_heading": "Food, pets, and traditional medicines", "_id": "21--0---1---1", "title": "The Threat to Malaysia's Natural Diversity"}
{"qas": [{"question": "Why are certain animals considered sacred?", "answer": ""}, {"question": "On what holiday do muslims sacrifice animals?", "answer": "Eid-ul-Adha", "ae_score": -0.2834881959357162, "qg_score": null}, {"question": "On what holiday do muslims sacrifice animals?", "answer": "Eid-ul-Adha", "ae_score": -0.2834881959357162, "qg_score": null}], "content": "Many animal species have spiritual significance in different cultures around the world, and they and their products may be used as sacred objects in religious rituals. For example, eagles, hawks and their  feathers have great cultural and spiritual value to Native Americans as religious objects. In Hinduism the cow is regarded sacred.\nMuslims conduct sacrifices on Eid-ul-Adha to commemorate the sacrificial spirit of Ibrahim [Abraham] in love of God. Camels, sheep, goats, and cows may be offered as sacrifice during the three days of Eid.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Religion", "sub_heading": "Religion", "_id": "21--1---1---1", "title": "Eid-ul-Adha \u2014 The Three Days of Eid."}
{"qas": [{"question": "Why is India so rich in wildlife?", "answer": ""}, {"question": "How many national parks are there in india?", "answer": "89", "ae_score": -0.39618236585324185, "qg_score": null}, {"question": "How many national parks are there in india?", "answer": "89", "ae_score": -0.39618236585324185, "qg_score": null}], "content": "Many nations have established their tourism sector around their natural wildlife. South Africa has, for example, many opportunities for tourists to see the country's wildlife in its national parks, such as the Kruger Park. In South India the Periar Wildlife Sanctuary, Bandipur National Park and Mudamalai Wildlife Sanctuary are situated around and in forests. India is home to many national parks and wildlife sanctuaries showing the diversity of its wildlife, much of its unique fauna, and excels in the range. There are 89 national parks, 13 bio reserves and more than 400 wildlife sanctuaries across India which are the best places to go to see tigers, lions, elephants, rhinoceros, birds, and other wildlife which reflect the importance that the country places on nature and wildlife conservation.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Tourism", "sub_heading": "Tourism", "_id": "21--2---1---1", "title": "The Best Places to Go to See Wildlife in India"}
{"qas": [{"question": "Why is the extinction of endangered species such a big deal?", "answer": ""}, {"question": "Populations that are confined to islands are at risk of dramatic population declines following what?", "answer": "unsustainable hunting", "ae_score": -0.3547395425488469, "qg_score": null}, {"question": "Populations that are confined to islands are at risk of dramatic population declines following what?", "answer": "unsustainable hunting", "ae_score": -0.3547395425488469, "qg_score": null}], "content": "Wildlife is an invaluable treasure but it is being exploited due to illegal trade of many of its species.Overkill happens whenever hunting occurs at rates greater than the reproductive capacity of the population is being exploited.  The effects of this are often noticed much more dramatically in slow growing populations such as many larger species of fish.  Initially when a portion of a wild population is hunted, an increased availability of resources (food, etc.) is experienced increasing growth and reproduction as density dependent inhibition is lowered.  Hunting, fishing and so on, has lowered the competition between members of a population.  However, if this hunting continues at rate greater than the rate at which new members of the population can reach breeding age and produce more young, the population will begin to decrease in numbers.\nPopulations that are confined to islands, whether literal islands or just areas of habitat that are effectively an \"island\" for the species concerned, have also been observed to be at greater risk of dramatic population declines following unsustainable hunting.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Destruction", "sub_heading": "Destruction", "_id": "21--3--0---1", "title": "Wildlife | Destruction"}
{"qas": [{"question": "Why are there so many wild animals in the wild?", "answer": ""}, {"question": "Grazing of bushland by farmed animals is called what?", "answer": "habitat destruction", "ae_score": -0.6586828601230483, "qg_score": null}, {"question": "Grazing of bushland by farmed animals is called what?", "answer": "habitat destruction", "ae_score": -0.6586828601230483, "qg_score": null}], "content": "The habitat of any given species is considered its preferred area or territory.  Many processes associated with human habitation of an area cause loss of this area and decrease the carrying capacity of the land for that species.  In many cases these changes in land use cause a patchy break-up of the wild landscape.  Agricultural land frequently displays this type of extremely fragmented, or relictual, habitat.  Farms sprawl across the landscape with patches of uncleared woodland or forest dotted in-between occasional paddocks.\nExamples of habitat destruction include grazing of bushland by farmed animals, changes to natural fire regimes, forest clearing for timber production and wetland draining for city expansion.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Destruction", "sub_heading": "Habitat destruction and fragmentation", "_id": "21--3--1---1", "title": "Habitat Destroyment in Agricultural Land"}
{"qas": [{"question": "Why are there so many invasive species in the world?", "answer": ""}, {"question": "Who felt it was unlikely that exotic species would ever be able to grow abundantly in a?", "answer": "Charles Darwin", "ae_score": -0.738070385541147, "qg_score": null}, {"question": "Who felt it was unlikely that exotic species would ever be able to grow abundantly in a?", "answer": "Charles Darwin", "ae_score": -0.738070385541147, "qg_score": null}], "content": "Mice, cats, rabbits, dandelions and poison ivy are all examples of species that have become invasive threats to wild species in various parts of the world .  Frequently species that are uncommon in their home range become out-of-control invasions in distant but similar climates.  The reasons for this have not always been clear and Charles Darwin felt it was unlikely that exotic species would ever be able to grow abundantly in a place in which they had not evolved. The reality is that the vast majority of species exposed to a new habitat do not reproduce successfully. Occasionally, however, some populations do take hold and after a period of acclimation can increase in numbers significantly, having destructive effects on many elements of the native environment of which they have become part.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Destruction", "sub_heading": "Impact of introduced species", "_id": "21--3--2---1", "title": "Invasive Threats to Wild Animals"}
{"qas": [{"question": "What would happen if all the birds in the world disappeared?", "answer": ""}, {"question": "Where are black drongos and cattle egrets found?", "answer": "India", "ae_score": -0.5194485959987262, "qg_score": null}, {"question": "Where are black drongos and cattle egrets found?", "answer": "India", "ae_score": -0.5194485959987262, "qg_score": null}], "content": "This final group is one of secondary effects.  All wild populations of living things have many complex intertwining links with other living things around them.  Large herbivorous animals such as the hippopotamus have populations of insectivorous birds that feed off the many parasitic insects that grow on the hippo. Should the hippo die out, so too will these groups of birds, leading to further destruction as other species dependent on the birds are affected.  Also referred to as a domino effect, this series of chain reactions is by far the most destructive process that can occur in any ecological community.\nAnother example is the black drongos and the cattle egrets found in India. These birds feed on insects on the back of cattle, which helps to keep them disease-free. Destroying the nesting habitats of these birds would cause a decrease in the cattle population because of the spread of insect-borne diseases.", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Destruction", "sub_heading": "Chains of extinction", "_id": "21--3--3---1", "title": "The domino effect is the most destructive process that can occur in any ecological community"}
{"qas": [{"question": "Why are there so many documentaries on wildlife?", "answer": ""}, {"question": "Who was the host of the tv series 'wild kingdom'?", "answer": "Marlin Perkins", "ae_score": -0.5409208743347772, "qg_score": null}, {"question": "Who was the host of the tv series 'wild kingdom'?", "answer": "Marlin Perkins", "ae_score": -0.5409208743347772, "qg_score": null}], "content": "Wildlife has long been a common subject for educational television shows. National Geographic specials appeared on CBS beginning in 1965, later moving to ABC and then PBS. In 1963, NBC debuted ''Wild Kingdom,'' a popular program featuring zoologist Marlin Perkins as host.  The  BBC natural history unit in the UK was a similar pioneer, the first wildlife series LOOK presented by Sir Peter Scott, was a studio-based show, with filmed inserts.  It was in this series that David Attenborough first made his appearance which led to the series Zoo Quest during which he and cameraman Charles Lagus went to many exotic places looking for and filming elusive wildlife\u2014notably the Komodo dragon in Indonesia and lemurs in Madagascar. Since 1984, the Discovery Channel and its spin off Animal Planet in the US have dominated the market for shows about wildlife on cable television, while on PBS the NATURE strand made by WNET-13 in New York and NOVA by WGBH in Boston are notable. See also Nature documentary. Wildlife television is now a multimillion-dollar industry with specialist documentary film-makers in many countries including UK, US, New Zealand NHNZ, Australia, Austria, Germany, Japan, and Canada.There are many magazines which cover wildlife including National Wildlife Magazine, Birds & Blooms, Birding (magazine), and Ranger Rick (for children).", "page_name": "Wildlife", "page_id": "Wildlife", "heading": "Media", "sub_heading": "Media", "_id": "21--4---1---1", "title": "Wildlife TV \u2014 a multimillion-dollar industry with a multimillion-dollar industry"}
{"qas": [{"question": "How are rare earth elements named?", "answer": ""}, {"question": "How many rare earth elements are there?", "answer": "seventeen", "ae_score": -0.7385954640430609, "qg_score": null}, {"question": "How many rare earth elements are there?", "answer": "seventeen", "ae_score": -0.7385954640430609, "qg_score": null}], "content": "A table listing the seventeen rare earth elements, their atomic number and symbol, the etymology of their names, and their main usages (see also Applications of lanthanides) is provided here. Some of the rare earth elements are named after the scientists who discovered or elucidated their elemental properties, and some after their geographical discovery.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "List", "sub_heading": "List", "_id": "22--0---1---1", "title": "Rare Earth Elements"}
{"qas": [{"question": "What is the difference between a \"c\" and a \"d\" in a word?", "answer": ""}, {"question": "What is the common name for rare earth element?", "answer": "abbreviations", "ae_score": -0.5018529313695639, "qg_score": null}, {"question": "What is the common name for rare earth element?", "answer": "abbreviations", "ae_score": -0.5018529313695639, "qg_score": null}], "content": "The following abbreviations are often used:\nThe densities of the LREEs (as pure elements) range from 2.989 (scandium) to 7.9 g/cc (gadolinium), whereas those of the HREEs are from 8.2 to 9.8, except for yttrium (4.47) and ytterbium (between 6.9 and 7). The distinction between the groups is more to do with atomic volume and geological behavior (see lower down).", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Abbreviations", "sub_heading": "Abbreviations", "_id": "22--1---1---1", "title": "LREEs and HREEs (as pure elements)"}
{"qas": [{"question": "How do we know that there is an unknown element in the universe?", "answer": ""}, {"question": "What is the maximum number of rare earth elements?", "answer": "25", "ae_score": -0.228585391270016, "qg_score": null}, {"question": "What is the maximum number of rare earth elements?", "answer": "25", "ae_score": -0.228585391270016, "qg_score": null}], "content": "There were no further discoveries for 30 years, and the element didymium was listed in the periodic table of elements with a molecular mass of 138. In 1879 Delafontaine used the new physical process of optical-flame spectroscopy, and he found several new spectral lines in didymia. Also in 1879, the new element ''samarium'' was isolated by Paul \u00c9mile Lecoq de Boisbaudran from the mineral samarskite.\nThe samaria earth was further separated by Lecoq de Boisbaudran in 1886 and a similar result was obtained by Jean Charles Galissard de Marignac by direct isolation from samarskite. They named the element ''gadolinium'' after Johan Gadolin, and its oxide was named \"gadolinia\".\nFurther spectroscopic analysis between 1886 and 1901 of samaria, yttria, and samarskite by William Crookes, Lecoq de Boisbaudran and Eug\u00e8ne-Anatole Demar\u00e7ay yielded several new spectroscopic lines that indicated the existence of an unknown element. The fractional crystallization of the oxides then yielded ''europium'' in 1901.\nIn 1839 the third source for rare earths became available. This is a mineral similar to gadolinite, ''uranotantalum'' (now called \"samarskite\"). This mineral from Miass in the southern Ural Mountains was documented by Gustave Rose. The Russian chemist R. Harmann proposed that a new element he called \"ilmenium\" should be present in this mineral, but later, Christian Wilhelm Blomstrand, Galissard de Marignac, and Heinrich Rose found only tantalum and niobium (columbium) in it.\nThe exact number of rare earth elements that existed was highly unclear, and a maximum number of 25 was estimated. The use of X-ray spectra (obtained by X-ray crystallography) by Henry Gwyn Jeffreys Moseley made it possible to assign atomic numbers to the elements. Moseley found that the exact number of lanthanides had to be 15 and that element 61 had yet to be discovered.\nUsing these facts about atomic numbers from X-ray crystallography, Moseley also showed that hafnium (element 72) would not be a rare earth element. Moseley was killed in World War I in 1915, years before hafnium was discovered. Hence, the claim of Georges Urbain that he had discovered element 72 was untrue. Hafnium is an element that lies in the periodic table immediately below zirconium, and hafnium and zirconium are very similar in their chemical and physical properties.\nDuring the 1940s, Frank Spedding and others in the United States (during the Manhattan Project) developed the chemical ion exchange procedures for separating and purifying the rare earth elements. This method was first applied to the actinides for separating plutonium-239 and neptunium, from uranium, thorium, actinium, and the other actinides in the materials produced in nuclear reactors. The plutonium-239 was very desirable because it is a fissile material.\nThe principal sources of rare earth elements are the minerals bastn\u00e4site, monazite, and loparite and the lateritic ion-adsorption clays. Despite their high relative abundance, rare earth minerals are more difficult to mine and extract than equivalent sources of transition metals (due in part to their similar chemical properties), making the rare earth elements relatively expensive. Their industrial use was very limited until efficient separation techniques were developed, such as ion exchange, fractional crystallization and liquid-liquid extraction during the late 1950s and early 1960s.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Discovery and early history", "sub_heading": "Discovery and early history", "_id": "22--2--0---1", "title": "Rare Earths \u2014 A History"}
{"qas": [{"question": "Why are some rare earth elements (e.g. europium, gadolinium, and terbium) separated into different groups?", "answer": ""}, {"question": "Which rare earth element, named after a greek goddess, has the latin name?", "answer": "europium", "ae_score": -1.8522845442489069, "qg_score": null, "filter_answer": "terbium"}, {"question": "Which rare earth element, named after a greek goddess, has the latin name?", "answer": "europium", "ae_score": -1.8522845442489069, "qg_score": null, "filter_answer": "terbium"}], "content": "Before the time that ion exchange methods and elution were available, the separation of the rare earths was primarily achieved by repeated precipitation or crystallisation. In those days, the first separation was into two main groups, the cerium group earths (scandium, lanthanum, cerium, praseodymium, neodymium, and samarium) and the yttrium group earths (yttrium, dysprosium, holmium, erbium, thulium, ytterbium, and lutetium). Europium, gadolinium, and terbium were either considered as a separate group of rare earth elements (the terbium group), or europium was included in the cerium group, and gadolinium and terbium were included in the yttrium group. The reason for this division arose from the difference in solubility of rare earth double sulfates with sodium and potassium. The sodium double sulfates of the cerium group are difficultly soluble, those of the terbium group slightly, and those of the yttrium group are very soluble.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Discovery and early history", "sub_heading": "Early classification", "_id": "22--2--1---1", "title": "Rare Earth Separation"}
{"qas": [{"question": "How are rare earth elements produced?", "answer": ""}, {"question": "Which rare earth element is produced by supernova nucleosynthesis?", "answer": "scandium", "ae_score": -0.7394283752838848, "qg_score": null}, {"question": "Which rare earth element is produced by supernova nucleosynthesis?", "answer": "scandium", "ae_score": -0.7394283752838848, "qg_score": null}], "content": "Rare earth elements, except scandium, are heavier than iron and thus are produced by supernova nucleosynthesis or the s-process in asymptotic giant branch stars. In nature, spontaneous fission of uranium-238 produces trace amounts of radioactive promethium, but most promethium is synthetically produced in nuclear reactors.\nDue to their chemical similarity, the concentrations of rare earths in rocks are only slowly changed by geochemical processes, making their proportions useful for geochronology and dating fossils.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Origin", "sub_heading": "Origin", "_id": "22--3---1---1", "title": "Rare Earths in Rocks"}
{"qas": [{"question": "What is the difference between monoclinic monazite and rare earth phosphates?", "answer": ""}, {"question": "What is the half life of promethium?", "answer": "17.7 years", "ae_score": -0.29484033930512055, "qg_score": null}, {"question": "What is the half life of promethium?", "answer": "17.7 years", "ae_score": -0.29484033930512055, "qg_score": null}], "content": "Rare earth cerium is actually the 25th most abundant element in Earth's crust, having 68 parts per million (about as common as copper). Only the highly unstable and radioactive promethium \"rare earth\" is quite scarce.\nThe rare earth elements are often found together. The longest-lived isotope of promethium has a half life of 17.7 years, so the element exists in nature in only negligible amounts (approximately 572 g in the entire Earth's crust). Promethium is one of the two elements that do not have stable (non-radioactive) isotopes and are followed by (i.e. with higher atomic number) stable elements (the other being technetium).\nDue to lanthanide contraction, yttrium, which is trivalent, is of similar ionic size as dysprosium and its lanthanide neighbors. Due to the relatively gradual decrease in ionic size with increasing atomic number, the rare earth elements have always been difficult to separate. Even with eons of geological time, geochemical separation of the lanthanides has only rarely progressed much farther than a broad separation between light versus heavy lanthanides, otherwise known as the cerium and yttrium earths. This geochemical divide is reflected in the first two rare earths that were discovered, yttria in 1794 and ceria in 1803. As originally found, each comprised the entire mixture of the associated earths. Rare earth minerals, as found, usually are dominated by one group or the other, depending on which size range best fits the structural lattice.\nThus, among the anhydrous rare earth phosphates, it is the tetragonal mineral xenotime that incorporates yttrium and the yttrium earths, whereas the monoclinic monazite phase incorporates cerium and the cerium earths preferentially. The smaller size of the yttrium group allows it a greater solid solubility in the rock-forming minerals that comprise Earth's mantle, and thus yttrium and the yttrium earths show less enrichment in Earth's crust relative to chondritic abundance, than does cerium and the cerium earths. This has economic consequences: large ore bodies of the cerium earths are known around the world, and are being exploited. Corresponding orebodies for yttrium tend to be rarer, smaller, and less concentrated. Most of the current supply of yttrium originates in the \"ion absorption clay\" ores of Southern China. Some versions provide concentrates containing about 65% yttrium oxide, with the heavy lanthanides being present in ratios reflecting the Oddo-Harkins rule: even-numbered heavy lanthanides at abundances of about 5% each, and odd-numbered lanthanides at abundances of about 1% each. Similar compositions are found in xenotime or gadolinite.\nWell-known minerals containing yttrium include gadolinite, xenotime, samarskite, euxenite, fergusonite, yttrotantalite, yttrotungstite, yttrofluorite (a variety of fluorite), thalenite, yttrialite. Small amounts occur in zircon, which derives its typical yellow fluorescence from some of the accompanying heavy lanthanides. The zirconium mineral eudialyte, such as is found in southern Greenland, contains small but potentially useful amounts of yttrium. Of the above yttrium minerals, most played a part in providing research quantities of lanthanides during the discovery days. Xenotime is occasionally recovered as a byproduct of heavy sand processing, but is not as abundant as the similarly recovered monazite (which typically contains a few percent of yttrium). Uranium ores from Ontario have occasionally yielded yttrium as a byproduct.\nWell-known minerals containing cerium and the light lanthanides include bastn\u00e4site, monazite, allanite, loparite, ancylite, parisite, lanthanite, chevkinite, cerite, stillwellite, britholite, fluocerite, and cerianite. Monazite (marine sands from Brazil, India, or Australia; rock from South Africa), bastn\u00e4site (from Mountain Pass, California, or several localities in China), and loparite (Kola Peninsula, Russia) have been the principal ores of cerium and the light lanthanides.\nIn 2011, Yasuhiro Kato, a geologist at the University of Tokyo who led a study of Pacific Ocean seabed mud, published results indicating the mud could hold rich concentrations of rare earth minerals. The deposits, studied at 78 sites, came from \"[h]ot plumes from hydrothermal vents pull[ing] these materials out of seawater and deposit[ing] them on the seafloor, bit by bit, over tens of millions of years. One square patch of metal-rich mud 2.3 kilometers wide might contain enough rare earths to meet most of the global demand for a year, Japanese geologists report July 3 in ''Nature Geoscience''.\" \"I believe that rare earth resources undersea are much more promising than on-land resources,\" said Kato. \"[C]oncentrations of rare earths were comparable to those found in clays mined in China. Some deposits contained twice as much heavy rare earths such as dysprosium, a component of magnets in hybrid car motors.\"", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Geological distribution", "sub_heading": "Geological distribution", "_id": "22--4---1---1", "title": "Yttrium and the Light Lanthanides"}
{"qas": [{"question": "Why is the price of rare earth so low right now?", "answer": ""}, {"question": "When did the wto rule china broke free trade agreements?", "answer": "August 29, 2014", "ae_score": -0.256619581006669, "qg_score": null}, {"question": "When did the wto rule china broke free trade agreements?", "answer": "August 29, 2014", "ae_score": -0.256619581006669, "qg_score": null}], "content": "These concerns have intensified due to the actions of China, the predominant supplier.  Specifically, China has announced regulations on exports and a crackdown on smuggling. On September 1, 2009, China announced plans to reduce its export quota to 35,000 tons per year in 2010\u20132015 to conserve scarce resources and protect the environment. On October 19, 2010, ''China Daily'', citing an unnamed Ministry of Commerce official, reported that China will \"further reduce quotas for rare earth exports by 30 percent at most next year to protect the precious metals from over-exploitation\". The government in Beijing further increased its control by forcing smaller, independent miners to merge into state-owned corporations or face closure. At the end of 2010, China announced that the first round of export quotas in 2011 for rare earths would be 14,446 tons, which was a 35% decrease from the previous first round of quotas in 2010. China announced further export quotas on 14 July 2011 for the second half of the year with total allocation at 30,184 tons with total production capped at 93,800 tonnes. In September 2011, China announced the halt in production of three of its eight major rare earth mines, responsible for almost 40% of China's total rare earth production.<ref name=ReutersSept611/> In March 2012, the US, EU, and Japan confronted China at WTO about these export and production restrictions. China responded with claims that the restrictions had environmental protection in mind. In August 2012, China announced a further 20% reduction in production. These restrictions have damaged industries in other countries and forced producers of rare earth products to relocate their operations to China. The Chinese restrictions on supply failed in 2012 as prices dropped in response to the opening of other sources. The price of dysprosium oxide was $994/kg in 2011, but dropped to $265/kg by 2014.\nOn August 29, 2014, the WTO ruled that China had broken free trade agreements, and the WTO said in the summary of key findings that\nChina declared it would implement the ruling on September 26, 2014, but would need some time to do so. By January 5, 2015, China had lifted all quotas from the export of rare earths, however export licences will still be required.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Global rare earth production", "_id": "22--5--0---1", "title": "Rare Earths \u2014 China's actions on exports, smuggling,"}
{"qas": [{"question": "Why is there so much speculation about mining in Africa?", "answer": ""}, {"question": "Who does north korea sell rare earth metals to?", "answer": "China", "ae_score": -0.3284462998344731, "qg_score": null}, {"question": "Who does north korea sell rare earth metals to?", "answer": "China", "ae_score": -0.3284462998344731, "qg_score": null}], "content": "As a result of the increased demand and tightening restrictions on exports of the metals from China, some countries are stockpiling rare earth resources. Searches for alternative sources in Australia, Brazil, Canada, South Africa, Tanzania, Greenland, and the United States are ongoing. Mines in these countries were closed when China undercut world prices in the 1990s, and it will take a few years to restart production as there are many barriers to entry.<ref name=Livergood2010/> One example is the Mountain Pass mine in California, which announced its resumption of operations on a start-up basis on August 27, 2012.<ref name=Wikinvest/> Other significant sites under development outside of China include the Nolans Project in Central Australia, the remote Hoidas Lake project in northern Canada, and the Mount Weld project in Australia.<ref name=Wikinvest/> The Hoidas Lake project has the potential to supply about 10% of the $1 billion of REE consumption that occurs in North America every year. Vietnam signed an agreement in October 2010 to supply Japan with rare earths from its northwestern Lai Ch\u00e2u Province.\nAlso under consideration for mining are sites such as Thor Lake in the Northwest Territories, various locations in Vietnam,<ref name=Wikinvest/><ref name=Reuters/>and a site in southeast Nebraska in the US, where Quantum Rare Earth Development, a Canadian company, is currently conducting test drilling and economic feasibility studies toward opening a niobium mine. Additionally, a large deposit of rare earth minerals was recently discovered in Kvanefjeld in southern Greenland. Pre-feasibility drilling at this site has confirmed significant quantities of black lujavrite, which contains about 1% rare-earth oxides (REO). The European Union has urged Greenland to restrict Chinese development of rare-earth projects there, but as of early 2013, the government of Greenland has said that it has no plans to impose such restrictions.  Many Danish politicians have expressed concerns that other nations, including China, could gain influence in thinly populated Greenland, given the number of foreign workers and investment that could come from Chinese companies in the near future because of the law passed December 2012.\nAdding to potential mine sites, ASX listed Peak Resources announced in February 2012, that their Tanzanian-based Ngualla project contained not only the 6th largest deposit by tonnage outside of China, but also the highest grade of rare earth elements of the 6.\nNorth Korea has been reported to have sold rare earth metals to China. During May and June 2014, North Korea sold over US$1.88 million worth of rare earth metals to China. Other sources suggest that North Korea has the world's second largest reserve of rare earth metals, with potentially over 20 million tons in total.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Outside of China", "_id": "22--5--1---1", "title": "Rare Earth Resources in the United States and Australia"}
{"qas": [{"question": "What are the chances of finding a deposit in the bottom of the ocean?", "answer": ""}, {"question": "Where can rare earth elements be found in the world?", "answer": "Nuclear reprocessing", "ae_score": -0.25260004142720016, "qg_score": null}, {"question": "Where can rare earth elements be found in the world?", "answer": "Nuclear reprocessing", "ae_score": -0.25260004142720016, "qg_score": null}], "content": "Significant quantities of rare earth oxides are found in tailings accumulated from 50 years of uranium ore, shale and loparite mining at Sillam\u00e4e, Estonia. Due to the rising prices of rare earths, extraction of these oxides has become economically viable. The country currently exports around 3,000 tonnes per year, representing around 2% of world production. Similar resources are suspected in the western United States, where gold rush-era mines are believed to have discarded large amounts of rare earths, because they had no value at the time.\nNuclear reprocessing is another potential source of rare earth or any other elements. Nuclear fission of uranium or plutonium produces a full range of elements, including all their isotopes. However, due to the radioactivity of many of these isotopes, it is unlikely that extracting them from the mixture can be done safely and economically.\nIn May 2012, researchers from two universities in Japan announced that they had discovered rare earths in Ehime Prefecture, Japan.\nIn January 2013 a Japanese deep-sea  research vessel obtained seven deep-sea mud core samples from the Pacific Ocean seafloor at 5,600 to 5,800 meters depth, approximately 250 km south of the island of Minami-Tori-Shima. The research team found a mud layer 2 to 4 meters beneath the seabed with concentrations of up to 0.66% rare earth oxides. A potential deposit might compare in grade with the ion-absorption-type deposits in southern China that provide the bulk of Chinese REO mine production, which grade in the range of 0.05% to 0.5% REO.\nAnother recently developed source of rare earths is electronic waste and other wastes that have significant rare earth components. New advances in recycling technology have made extraction of rare earths from these materials more feasible, and recycling plants are currently operating in Japan, where there is an estimated 300,000 tons of rare earths stored in unused electronics. In France, the Rhodia group is setting up two factories, in La Rochelle and Saint-Fons, that will produce 200 tons of rare earths a year from used fluorescent lamps, magnets and batteries.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Other sources", "_id": "22--5--2---1", "title": "Rare Earths: A New Source of Rare Earths"}
{"qas": [{"question": "How do companies like Lynas get away with selling their products for so long?", "answer": ""}, {"question": "When was the rare earth element lynas discovered?", "answer": "2 September 2014", "ae_score": -0.5171195276400452, "qg_score": null}, {"question": "When was the rare earth element lynas discovered?", "answer": "2 September 2014", "ae_score": -0.5171195276400452, "qg_score": null}], "content": "In early 2011, Australian mining company, Lynas, was reported to be \"hurrying to finish\" a US$230 million rare earth refinery on the eastern coast of Peninsular Malaysia's industrial port of Kuantan. The plant would refine ore\u2014 lanthanides concentrate from the Mount Weld mine in Australia. The ore would be trucked to Fremantle and transported by container ship to Kuantan. However, the Malaysian authorities confirmed that as of October 2011, Lynas was not given any permit to import any rare earth ore into Malaysia. On February 2, 2012, the Malaysian AELB (Atomic Energy Licensing Board) recommended that Lynas be issued a Temporary Operating License (TOL) subject to completion of a number of conditions. On April 3, 2012, Lynas announced to the Malaysian media that these conditions had been met, and was now waiting on the issuance of the licence.Within two years, Lynas was said to expect the refinery to be able to meet nearly a third of the world's demand for rare earth materials, not counting China.\" The Kuantan development brought renewed attention to the Malaysian town of Bukit Merah in Perak, where a rare-earth mine operated by a Mitsubishi Chemical subsidiary, Asian Rare Earth, closed in 1992 and left continuing environmental and health concerns. In mid-2011, after protests, Malaysian government restrictions on the Lynas plant were announced. At that time, citing subscription-only Dow Jones Newswire reports, a ''Barrons'' report said the Lynas investment was $730 million, and the projected share of the global market it would fill put at \"about a sixth.\" An independent review was initiated by Malaysian Government and United Nations and conducted by the International Atomic Energy Agency (IAEA) between 29 May and 3 June 2011 to address concerns of radioactive hazards. The IAEA team was not able to identify any non-compliance with international radiation safety standards.\nOn 2 September 2014, Lynas was issued a 2-year Full Operating Stage License (FOSL) by the Malaysian Atomic Energy Licensing Board (AELB).", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Malaysian refining plans", "_id": "22--5--3---1", "title": "Lynas and the Malaysian Atomic Energy Licensing Board"}
{"qas": [{"question": "How is Lynas able to produce so much radiation in such a short amount of time?", "answer": ""}, {"question": "How much money has been spent to clean up the Bukit merah mine?", "answer": "US$100 million", "ae_score": -0.3251093701260841, "qg_score": null}, {"question": "How much money has been spent to clean up the Bukit merah mine?", "answer": "US$100 million", "ae_score": -0.3251093701260841, "qg_score": null}], "content": "Mining, refining, and recycling of rare earths have serious environmental consequences if not properly managed. A particular hazard is mildly radioactive slurry tailings resulting from the common occurrence of thorium and uranium in rare earth element ores. Additionally, toxic acids are required during the refining process. Improper handling of these substances can result in extensive environmental damage. In May 2010, China announced a major, five-month crackdown on illegal mining in order to protect the environment and its resources. This campaign is expected to be concentrated in the South, where mines \u2013 commonly small, rural, and illegal operations \u2013 are particularly prone to releasing toxic wastes into the general water supply.<ref name=Wikinvest/> However, even the major operation in Baotou, in Inner Mongolia, where much of the world's rare earth supply is refined, has caused major environmental damage.\nResidents blamed a rare earth refinery at Bukit Merah for birth defects and eight leukemia cases within five years in a community of 11,000 \u2014 after many years with no leukemia cases. Seven of the leukemia victims died. Osamu Shimizu, a director of Asian Rare Earth, said, \"the company might have sold a few bags of calcium phosphate fertilizer on a trial basis as it sought to market byproducts; calcium phosphate is not radioactive or dangerous,\" in reply to a former resident of Bukit Merah who said, \"The cows that ate the grass [grown with the fertilizer] all died.\"<ref name=Bl01/> Malaysia's Supreme Court ruled on 23 December 1993 that there was no evidence that the local chemical joint venture Asian Rare Earth was contaminating the local environment.\nThe Bukit Merah mine in Malaysia has been the focus of a US$100 million cleanup that is proceeding in 2011. After having accomplished the hilltop entombment of 11,000 truckloads of radioactively contaminated material, the project is expected to entail in summer, 2011, the removal of \"more than 80,000 steel barrels of radioactive waste to the hilltop repository.\"<ref name=NYT01/>\nIn May 2011, after the Fukushima Daiichi nuclear disaster, widespread protests took place in Kuantan over the Lynas refinery and radioactive waste from it. The ore to be processed has very low levels of thorium, and Lynas founder and chief executive Nicholas Curtis said \"There is absolutely no risk to public health.\" T. Jayabalan, a doctor who says he has been monitoring and treating patients affected by the Mitsubishi plant, \"is wary of Lynas's assurances. The argument that low levels of thorium in the ore make it safer doesn't make sense, he says, because radiation exposure is cumulative.\" Construction of the facility has been halted until an independent United Nations IAEA panel investigation is completed, which is expected by the end of June 2011. New restrictions were announced by the Malaysian government in late June.<ref name=B01/>\nIAEA panel investigation is completed and no construction has been halted. Lynas is on budget and on schedule to start producing 2011. The IAEA report has concluded in a report issued on Thursday June 2011 said it did not find any instance of \"any non-compliance with international radiation safety standards\" in the project.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Environmental considerations", "_id": "22--5--4---1", "title": "Rare earth element | Global rare earth production | Environmental considerations"}
{"qas": [{"question": "Why is China so strict on its rare-earth mineral production?", "answer": ""}, {"question": "Which rare earth element was identified as the most critical in terms of import reliance?", "answer": "dysprosium", "ae_score": -0.08608616183426107, "qg_score": null}, {"question": "Which rare earth element was identified as the most critical in terms of import reliance?", "answer": "dysprosium", "ae_score": -0.08608616183426107, "qg_score": null}], "content": "China has officially cited resource depletion and environmental concerns as the reasons for a nationwide crackdown on its rare earth mineral production sector. However, non-environmental motives have also been imputed to China's rare earth policy. According to ''The Economist'', \"Slashing their exports of rare-earth metals...is all about moving Chinese manufacturers up the supply chain, so they can sell valuable finished goods to the world rather than lowly raw materials.\" One possible example is the division of General Motors that deals with miniaturized magnet research, which shut down its US office and moved its entire staff to China in 2006 (it should be noted that China's export quota only applies to the metal but not products made from these metals such as magnets).\nIt was reported, but officially denied, that China instituted an export ban on shipments of rare earth oxides (but not alloys) to Japan on 22 September 2010, in response to the detainment of a Chinese fishing boat captain by the Japanese Coast Guard. On September 2, 2010, a few days before the fishing boat incident, ''The Economist'' reported that \"China...in July announced the latest in a series of annual export reductions, this time by 40% to precisely 30,258 tonnes.\"\nThe United States Department of Energy in its 2010 Critical Materials Strategy report identified dysprosium as the element that was most critical in terms of import reliance.\nA 2011 report issued by the US Geological Survey and US Department of the Interior, \"China's Rare-Earth Industry,\" outlines  industry trends within China and examines national policies that may guide the future of the country's production. The report notes that China's lead in the production of rare-earth minerals has accelerated over the past two decades. In 1990, China accounted for only 27% of such minerals. In 2009, world production was 132,000 metric tons; China produced 129,000 of those tons. According to the report, recent patterns suggest that China will slow the export of such materials to the world: \"Owing to the increase in domestic demand, the Government has gradually reduced the export quota during the past several years.\" In 2006, China allowed 47 domestic rare-earth producers and traders and 12 Sino-foreign rare-earth producers to export. Controls have since tightened annually; by 2011, only 22 domestic rare-earth producers and traders and 9 Sino-foreign rare-earth producers were authorized. The government's future policies will likely keep in place strict controls: \"According to China's draft rare-earth development plan, annual rare-earth production may be limited to between 130,000 and 140,000 [metric tons] during the period from 2009 to 2015. The export quota for rare-earth products may be about 35,000 [metric tons] and the Government may allow 20 domestic rare-earth producers and traders to export rare earths.\"\nThe United States Geological Survey is actively surveying southern Afghanistan for rare earth deposits under the protection of United States military forces. Since 2009 the USGS has conducted remote sensing surveys as well as fieldwork to verify Soviet claims that volcanic rocks containing rare earth metals exist in Helmand province near the village of Khanneshin. The USGS study team has located a sizable area of rocks in the center of an extinct volcano containing light rare earth elements including cerium and neodymium. It has mapped 1.3 million metric tons of desirable rock, or about 10 years of supply at current demand levels. The Pentagon has estimated its value at about $7.4 billion.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Geo-political considerations", "_id": "22--5--5---1", "title": "China's Rare-Earth Industry"}
{"qas": [{"question": "Why are rare earth elements so expensive?", "answer": ""}, {"question": "Why are magnets made with rare earth elements?", "answer": "uncertainty of pricing and availability", "ae_score": -0.7861298347336045, "qg_score": null}, {"question": "Why are magnets made with rare earth elements?", "answer": "uncertainty of pricing and availability", "ae_score": -0.7861298347336045, "qg_score": null}], "content": "Rare earth elements are not exchange-traded in the same way that precious (for instance, gold and silver) or non-ferrous metals (such as nickel, tin, copper, and aluminium) are. Instead they are sold on the private market, which makes their prices difficult to monitor and track. The 17 elements are not usually sold in their pure form, but instead are distributed in mixtures of varying purity, e.g. \"Neodymium metal \u2265 99%\". As such, pricing can vary based on the quantity and quality required by the end user's application.\nThe uncertainty of pricing and availability have caused particularly Japanese companies to develop permanent magnets and associated electric motors with fewer or no rare earth elements.", "page_name": "Rare earth element", "page_id": "Rare%20earth%20element", "heading": "Global rare earth production", "sub_heading": "Rare earth pricing", "_id": "22--5--6---1", "title": "Rare earth elements are not exchange-traded in the same way that precious (for example,"}
{"qas": [{"question": "Why are there so many houses on the California coast?", "answer": ""}, {"question": "Which 17th century fortress in malta is threatened by coastal erosion?", "answer": "Fort Ricasoli", "ae_score": -0.29849775424161423, "qg_score": null}, {"question": "Which 17th century fortress in malta is threatened by coastal erosion?", "answer": "Fort Ricasoli", "ae_score": -0.29849775424161423, "qg_score": null}], "content": "A place where erosion of a cliffed coast has occurred is at Wamberal in the Central Coast region of New South Wales where houses built on top of the cliffs began to collapse into the sea. This is due to waves causing erosion of the primarily sedimentary material on which the buildings foundations sit.\nDunwich, the capital of the English medieval wool trade, disappeared over the period of a few centuries due to redistribution of sediment by waves. Human interference can also increase coastal erosion: Hallsands in Devon, England, was a coastal village that washed away over the course of a year, an event directly caused by dredging of shingle in the bay in front of it.\nThe California coast, which has soft cliffs of sedimentary rock and is heavily populated, regularly has incidents of housing damage as cliffs erodes . Devil's Slide, Santa Barbara, the coast just north of Ensenada, and Malibu are regularly affected.\nThe Holderness coastline on the east coast of England, just north of the Humber Estuary, is one of the fastest eroding coastline in Europe due to its soft clay cliffs and powerful waves. Groynes and other artificial measures to keep it under control has only accelerated the process further down the coast, because longshore drift starves the beaches of sand, leaving them more exposed. The White Cliffs of Dover have also been affected.\nFort Ricasoli, a historic 17th century fortress in Malta is being threatened by coastal erosion, as it was built on a fault in the headland which is prone to erosion. A small part of one of the bastion walls has already collapsed since the land under it has eroded, and there are cracks in other walls as well.", "page_name": "Coastal erosion", "page_id": "Coastal%20erosion", "heading": "Examples", "sub_heading": "Examples", "_id": "23--0---1---1", "title": "The Eroding of the Coastline"}
{"qas": [{"question": "How does sea water dissolve rocks?", "answer": ""}, {"question": "What is it called when waves cause loose pieces of rock debris to collide with each other?", "answer": "Attrition", "ae_score": -0.2694879787973291, "qg_score": null}, {"question": "What is it called when waves cause loose pieces of rock debris to collide with each other?", "answer": "Attrition", "ae_score": -0.2694879787973291, "qg_score": null}], "content": "Hydraulic action occurs when waves striking a cliff face compress air in cracks on the cliff face. This exerts pressure on the surrounding rock, and can progressively splinter and remove pieces. Over time, the cracks can grow, sometimes forming a cave. The splinters fall to the sea bed where they are subjected to further wave action.\nAttrition occurs when waves causes loose pieces of rock debris (scree) to collide with each other, grinding and chipping each other, progressively becoming smaller, smoother and rounder. Scree also collides with the base of the cliff face, chipping small pieces of rock from the cliff or have a corrasion (abrasion) effect, similar to sandpapering.\nAcids contained in sea water will dissolve some types of rock such as chalk or limestone.\nCorrasion or otherwise known as abrasion occurs when waves break on cliff faces and slowly erode it. As the sea pounds cliff faces it also uses the scree from other wave actions to batter and break off pieces of rock from higher up the cliff face which can be used for this same wave action and attrition.\nCorrosion or solution/chemical weathering occurs when the sea's pH (anything below pH 7.0) corrodes rocks on a cliff face. Limestone cliff faces, which have a moderately high pH, are particularly affected in this way. Wave action also increases the rate of reaction by removing the reacted material.", "page_name": "Coastal erosion", "page_id": "Coastal%20erosion", "heading": "Wave action", "sub_heading": "Wave action", "_id": "23--1---1---1", "title": "Wave Action and Attrition"}
{"qas": [{"question": "How do cliff fall debris get removed from the foreshore?", "answer": ""}, {"question": "What determines the hardness of sea-facing rocks?", "answer": "rock strength", "ae_score": -0.36242878403703344, "qg_score": null}, {"question": "What determines the hardness of sea-facing rocks?", "answer": "rock strength", "ae_score": -0.36242878403703344, "qg_score": null}], "content": "The ability of waves to cause erosion of the cliff face depends on many factors.\nThe hardness (or inversely, the erodibility) of sea-facing rocks is controlled by the rock strength and the presence of fissures, fractures, and beds of non-cohesive materials such as silt and fine sand.\nThe rate at which cliff fall debris is removed from the foreshore depends on the power of the waves crossing the beach. This energy must reach a critical level to remove material from the debris lobe. Debris lobes can be very persistent and can take many years to completely disappear.\nBeaches dissipate wave energy on the foreshore and provide a measure of protection to the adjoining land.\nThe stability of the foreshore, or its resistance to lowering. Once stable, the foreshore should widen and become more effective at dissipating the wave energy, so that fewer and less powerful waves reach beyond it. The provision of updrift material coming onto the foreshore beneath the cliff helps to ensure a stable beach.\nThe adjacent bathymetry, or configuration of the seafloor, controls the wave energy arriving at the coast, and can have an important influence on the rate of cliff erosion.  Shoals and bars offer protection from wave erosion by causing storm waves to break and dissipate their energy before reaching the shore. Given the dynamic nature of the seafloor, changes in the location of shoals and bars may cause the locus of beach or cliff erosion to change position along the shore.\nCoastal erosion has been greatly affected by the rising sea levels globally. There has been great measures of increased coastal erosion on the Eastern seaboard of the United States. Locations such as Florida have noticed increased coastal erosion. In reaction to these increases Florida and its individual counties have increased budgets to replenish the eroded sands that attract visitors to Florida and help support its multibillion-dollar tourism industries.", "page_name": "Coastal erosion", "page_id": "Coastal%20erosion", "heading": "Factors that influence erosion rates", "sub_heading": "Factors that influence erosion rates", "_id": "23--2---1---1", "title": "Coastal Erosion in Florida"}
{"qas": [{"question": "How does coastal erosion control work?", "answer": ""}, {"question": "How many forms of coastal erosion control are there?", "answer": "three", "ae_score": -0.2407811080671054, "qg_score": null}, {"question": "How many forms of coastal erosion control are there?", "answer": "three", "ae_score": -0.2407811080671054, "qg_score": null}], "content": "There are three common forms of coastal erosion control methods. These three include: soft-erosion controls, hard-erosion controls, and relocation.\nHard-erosion control methods provide a more permanent solution than soft-erosion control methods. Seawalls and groynes serve as semi-permanent infrastructure. These structures are not immune from normal wear-and-tear and will have to be refurbished or rebuilt. It is estimated the average life span of a seawall is 50\u2013100 years and the average for a groyne is 30\u201340 years. Because of their relative permanence, it is assumed that these structures can be a final solution to erosion. Seawalls can also deprive public access to the beach and drastically alter the natural state of the beach. Groynes also drastically alter the natural state of the beach. Some claim that groynes could reduce the interval between beach nourishment projects though they are not seen as a solution to beach nourishment.\nNatural forms of hard-erosion control include planting or maintaining native vegetation, such as mangrove forests and coral reefs.\nSoft erosion strategies refer to temporary options of slowing the effects of erosion. These options, including Sandbag and beach nourishment, are not intended to be long term solutions or permanent solutions. Another method, beach scraping or beach bulldozing allows for the creation of an artificial dune in front of a building or as means of preserving a building foundation. However, there is a U.S. federal moratorium on beach bulldozing during turtle nesting season, 1 May \u2013 15 November. One of the most common methods of soft erosion control is beach nourishment projects. These projects involve dredging sand and moving it to the beaches as a means of reestablishing the sand lost due to erosion.\nUnder this response, humans move from the coast and surrender the coast to the natural processes of both absolute and relative sea level rise and erosion.  This solution is eco-centric meaning that the focus is on forcing humans to adapt to the natural processes rather than the opposite. By removing structures along the oceanfront, the beach is surrendered to the natural forces of the ocean. In this case, property owners and coastal communities are essentially \u201cretreating\u201d from the sea. Typically, there has been low public support for \u201cretreating.\u201d However, this would be most effective in reducing the impacts of erosion on human society.", "page_name": "Coastal erosion", "page_id": "Coastal%20erosion", "heading": "Coastal Erosion Control Strategies", "sub_heading": "Coastal Erosion Control Strategies", "_id": "23--3---1---1", "title": "Beach Erosion Control: Soft Erosion Control, Hard Erosion Control, Re"}
{"qas": [{"question": "How do we know how much land is covered by ocean?", "answer": ""}, {"question": "What weather causes coastal erosion hundreds of times faster than normal weather?", "answer": "Storms", "ae_score": -0.436339492017084, "qg_score": null}, {"question": "What weather causes coastal erosion hundreds of times faster than normal weather?", "answer": "Storms", "ae_score": -0.436339492017084, "qg_score": null}], "content": "Storms can cause erosion hundreds of times faster than normal weather.  Before-and-after comparisons can be made using data gathered by manual surveying, laser altimeter, or even a GPS unit mounted on an ATV. Remote sensing data such as Landsat scenes can be used for large scale and multi year assessments of coastal erosion.", "page_name": "Coastal erosion", "page_id": "Coastal%20erosion", "heading": "Tracking", "sub_heading": "Tracking", "_id": "23--4---1---1", "title": "Coastal Erosion Assessments Using Landsat and Landsat"}
{"qas": [{"question": "Why is the word 'o' pronounced with a short 'o'?", "answer": ""}, {"question": "Where does the word yogurt come from in england?", "answer": "Wales", "ae_score": null, "qg_score": null}, {"question": "Where does the word yogurt come from in england?", "answer": "Wales", "ae_score": null, "qg_score": null}], "content": "The word is derived from yo\u011furt, and is usually related to the verb ''yo\u011furmak'', \"to knead\", or \"to be curdled or coagulated; to thicken\". It may be related to ''yo\u011fun'', meaning thick or dense. The sound \u011f was traditionally rendered as \"gh\" in transliterations of Turkish prior to 1928. In older Turkish, the letter denoted a voiced velar fricative , but this sound is elided between back vowels in modern Turkish, in which the word is pronounced , or .\n<span class=\"spellingvariants\" id=\"spellings\">In English, there are several variations of the spelling of the word, including ''yogurt'', ''yoghurt'' and to a lesser extent ''yoghourt'', ''yogourt'', ''yaghourt'', ''yahourth'', ''yoghurd'', ''joghourt'', and ''jogourt''. In the United Kingdom and Australia, ''yogurt'' and ''yoghurt'' are both current, ''yogurt'' being used by the Australian and British dairy councils, and ''yoghourt'' is an uncommon alternative. In the United States, Canada, and New Zealand, ''yogurt'' is the usual spelling and ''yoghurt'' a minor variant.\nHistorically, there have been cases of yogurt being spelled with a \"J\" instead of a \"Y\" (e.g. ''jogurt'' and ''joghurt'') due to alternative transliteration methods. However, there has been a decline in these variations in English speaking countries; in certain European countries, on the other hand, it is still commonly spelled with a \"J\". Most people tend to spell in the manner shown on the packaging of the major brands in their country.\nWhatever the spelling, the word is usually pronounced with a short ''o''  in England and Wales, and with a long ''o''  in Scotland, North America, Australia, New Zealand, Ireland and South Africa.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Etymology and spelling", "sub_heading": "Etymology and spelling", "_id": "24--0---1---1", "title": "Yogurt | Etymology and spelling"}
{"qas": [{"question": "How do we know that bacteria in milk is from plants?", "answer": ""}, {"question": "When was yogurt made with fruit jam invented?", "answer": "1933", "ae_score": -0.18779324474480838, "qg_score": null}, {"question": "When was yogurt made with fruit jam invented?", "answer": "1933", "ae_score": -0.18779324474480838, "qg_score": null}], "content": "Analysis of the ''L. delbrueckii'' subsp. ''bulgaricus'' genome indicates that the bacterium may have originated on the surface of a plant. Milk may have become spontaneously and unintentionally exposed to it through contact with plants, or bacteria may have been transferred from the udder of domestic milk-producing animals.\nThe origins of yogurt are unknown, but it is thought to have been invented in Mesopotamia around 5000 BC.\nIn ancient Indian records, the combination of yogurt and honey is called \"the food of the gods\". Persian traditions hold that \"Abraham owed his fecundity and longevity to the regular ingestion of yogurt\".\nThe cuisine of ancient Greece included a dairy product known as oxygala (\u03bf\u03be\u03cd\u03b3\u03b1\u03bb\u03b1) which is believed to have been a form of yogurt. Galen (AD 129 \u2013 c.\u2009200/c.\u2009216) mentioned that oxygala was consumed with honey, similar to the way thickened Greek yogurt is eaten today.\nThe oldest writings mentioning yogurt are attributed to Pliny the Elder, who remarked that certain \"barbarous nations\" knew how \"to thicken the milk into a substance with an agreeable acidity\". The use of yogurt by medieval Turks is recorded in the books ''Diwan Lughat al-Turk'' by Mahmud Kashgari and ''Kutadgu Bilig'' by Yusuf Has Hajib written in the 11th century. Both texts mention the word \"yogurt\" in different sections and describe its use by nomadic Turks. The earliest yogurts were probably spontaneously fermented by wild bacteria in goat skin bags.\nSome accounts suggest that Indian emperor Akbar's cooks would flavor yogurt with mustard seeds and cinnamon. Another early account of a European encounter with yogurt occurs in French clinical history: Francis I suffered from a severe diarrhea which no French doctor could cure. His ally Suleiman the Magnificent sent a doctor, who allegedly cured the patient with yogurt. Being grateful, the French king spread around the information about the food which had cured him.\nUntil the 1900s, yogurt was a staple in diets of people in the Russian Empire (and especially Central Asia and the Caucasus), Western Asia, South Eastern Europe/Balkans, Central Europe, and India. Stamen Grigorov (1878\u20131945), a Bulgarian student of medicine in Geneva, first examined the microflora of the Bulgarian yogurt. In 1905, he described it as consisting of a spherical and a rod-like lactic acid-producing bacteria. In 1907, the rod-like bacterium was called ''Bacillus bulgaricus'' (now ''Lactobacillus delbrueckii subsp. bulgaricus''). The Russian Nobel laureate and biologist Ilya Ilyich Mechnikov (also known as \u00c9lie Metchnikoff), from the Institut Pasteur in Paris, was influenced by Grigorov's work and hypothesized that regular consumption of yogurt was responsible for the unusually long lifespans of Bulgarian peasants. Believing ''Lactobacillus'' to be essential for good health, Mechnikov worked to popularize yogurt as a foodstuff throughout Europe.\nIsaac Carasso industrialized the production of yogurt. In 1919, Carasso, who was from Ottoman Salonika, started a small yogurt business in Barcelona, Spain, and named the business Danone (\"little Daniel\") after his son. The brand later expanded to the United States under an Americanized version of the name: Dannon.\nYogurt with added fruit jam was patented in 1933 by the Radlick\u00e1 Ml\u00e9k\u00e1rna dairy in Prague.\nYogurt was introduced to the United States in the first decade of the twentieth century, influenced by \u00c9lie Metchnikoff's ''The Prolongation of Life; Optimistic Studies'' (1908); it was available in tablet form for those with digestive intolerance and for home culturing. It was popularized by John Harvey Kellogg at the Battle Creek Sanitarium, where it was used both orally and in enemas, and later by Armenian immigrants Sarkis and Rose Colombosian, who started \"Colombo and Sons Creamery\" in Andover, Massachusetts in 1929. Colombo Yogurt was originally delivered around New England in a horse-drawn wagon inscribed with the Armenian word \"madzoon\" which was later changed to \"yogurt\", the Turkish name of the product, as Turkish was the lingua franca between immigrants of the various Near Eastern ethnicities who were the main consumers at that time. Yogurt's popularity in the United States was enhanced in the 1950s and 1960s, when it was presented as a health food. By the late 20th century, yogurt had become a common American food item and Colombo Yogurt was sold in 1993 to General Mills, which discontinued the brand in 2010.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "History", "sub_heading": "History", "_id": "24--1---1---1", "title": "The Origins of Yogurt in the United States"}
{"qas": [{"question": "Why does yogurt taste so much better than other dairy products?", "answer": ""}, {"question": "What represents missing or incomplete data in nutritional information?", "answer": "Tilde", "ae_score": -0.5572093953396923, "qg_score": null}, {"question": "What represents missing or incomplete data in nutritional information?", "answer": "Tilde", "ae_score": -0.5572093953396923, "qg_score": null}], "content": "In a 100-gram amount providing 406 kJ of dietary energy, yogurt (plain Greek yogurt from whole milk) is 81% water, 9% protein, 5% fat and 4% carbohydrates, including 4% sugars (table). As a proportion of the Daily Value (DV), a serving of yogurt is a rich source of vitamin B (31% DV) and riboflavin (23% DV), with moderate content of protein, phosphorus and selenium (14 to 19% DV; table).\n\t\t \tTilde (~) represents missing or incomplete data.\t\t \u2212\tThe above shows that there is little difference between whole milk and yogurt made from whole milk with respect to the listed nutritional constituents. The differences may be explained as a result of testing the product after draining liquid whey from the yogurt thereby changing the percentage of that constituent in the final product.\nAlthough yogurt is often associated with probiotics having positive effects on immune, cardiovascular or metabolic health, there is insufficient high-quality clinical evidence to conclude that consuming yogurt lowers risk of diseases or improves health.\nLactose-intolerant individuals may tolerate yogurt better than other dairy products due to the conversion of lactose to the sugars glucose and galactose, and the fermentation of lactose to lactic acid carried out by the bacteria present in the yogurt.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Nutrition and health", "sub_heading": "Nutrition and health", "_id": "24--2---1---1", "title": "Yogurt \u2014 a rich source of protein, riboflavin and se"}
{"qas": [{"question": "Why is there so much controversy over sweetened yogurt?", "answer": ""}, {"question": "What is there concern about the health effects of?", "answer": "sweetened yogurt", "ae_score": -0.3144662851597379, "qg_score": null}, {"question": "What is there concern about the health effects of?", "answer": "sweetened yogurt", "ae_score": -0.3144662851597379, "qg_score": null}], "content": "To offset its natural sourness, yogurt is also sold sweetened, flavored or in containers with fruit or fruit jam on the bottom. The two styles of yogurt commonly found in the grocery store are set type yogurt and Swiss style yogurt. Set type yogurt is when the yogurt is packaged with the fruit on the bottom of the cup and the yogurt on top. Swiss style yogurt is when the fruit is blended into the yogurt prior to packaging.\nLassi and Moru are common beverages in India. Lassi is stirred liquified curd that is either salted or sweetened with sugar commonly, less commonly honey and often combined with fruit pulp to create flavored lassi. Mango lassi is a western favorite, as is coconut lassi. Consistency can vary widely, with urban and commercial lassis being of uniform texture through being processed, whereas rural and rustic lassi has curds in it, and sometimes has malai (cream) added or removed. Moru is a popular South Indian summer drink, meant to keep drinkers hydrated through the hot and humid summers of the South. It is prepared by considerably thinning down yogurt with water, adding salt (for electrolyte balance) and spices, usually green chili peppers, asafoetida, curry leaves and mustard.\nLarge amounts of sugar \u2013 or other sweeteners for low-energy yogurts \u2013 are often used in commercial yogurt. Some yogurts contain added starch, pectin (found naturally in fruit), and/or gelatin to create thickness and creaminess artificially at lower cost. Gelatin is a meat or fish product, therefore vegetarians should avoid products containing it. This type of yogurt is also marketed under the name Swiss-style, although it is unrelated to the way yogurt is eaten in Switzerland. Some yogurts, often called \"cream line\", are made with whole milk which has not been homogenized so the cream rises to the top.\nIn the UK, Ireland, France and United States, sweetened, flavored yogurt is the most popular type, typically sold in single-serving plastic cups. Common flavors include vanilla, honey, and toffee, and fruit such as strawberry, cherry, blueberry, blackberry, raspberry, mango and peach. In the early twenty-first century yogurt flavors inspired by desserts, such as chocolate or cheesecake, have been available.\nThere is concern about the health effects of sweetened yogurt. The United Kingdom and the United States recommend different maximum amounts of daily sugar intake but in both nations many sweetened yogurts have too much.\nConsumers wanting sweetened yogurt are advised to choose yogurt sweetened with sugar substitute and check the contents list to avoid corn syrup, high fructose corn syrup, honey, or sugar.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Varieties and presentation", "sub_heading": "Varieties and presentation", "_id": "24--3--0---1", "title": "What is Sweetened Yogurt?"}
{"qas": [{"question": "Why do some yogurts have to be boiled first, while others don't?", "answer": ""}, {"question": "What is the name of east indian dessert?", "answer": "mishti dahi", "ae_score": -0.13513013881506222, "qg_score": null}, {"question": "What is the name of east indian dessert?", "answer": "mishti dahi", "ae_score": -0.13513013881506222, "qg_score": null}], "content": "Strained yogurt is yogurt which has been strained through a filter, traditionally made of muslin and more recently of paper or cloth. This removes the whey, giving a much thicker consistency and a distinctive slightly tangy taste. Strained yogurt is becoming more popular with those who make yogurt at home, especially if using skimmed milk which results in a thinner consistency.\nYogurt that has been strained to filter or remove the whey is known as Labneh in Middle Eastern countries. It has a consistency between that of yogurt and cheese. It is popular for sandwiches in Middle Eastern countries. Olive oil, cucumber slices, olives, and various green herbs may be added. It can be thickened further and rolled into balls, preserved in olive oil, and fermented for a few more weeks. It is sometimes used with onions, meat, and nuts as a stuffing for a variety of pies or kibbeh balls.\nSome types of strained yogurts are boiled in open vats first, so that the liquid content is reduced. The popular East Indian dessert, a variation of traditional dahi called mishti dahi, offers a thicker, more custard-like consistency, and is usually sweeter than western yogurts.\nStrained yogurt is also enjoyed in Greece and is the main component of ''tzatziki'' (from Turkish \"cac\u0131k\"), a well-known accompaniment to gyros and souvlaki pita sandwiches: it is a yogurt sauce or dip made with the addition of grated cucumber, olive oil, salt and, optionally, mashed garlic.\nSrikhand, a popular dessert in India, is made from strained yogurt, saffron, cardamom, nutmeg and sugar and sometimes fruits such as mango or pineapple.\nIn North America and Britain, strained yogurt is commonly called \u201cGreek yogurt\u201d. Strained yogurt is sometimes marketed in North America as \"Greek yogurt\" and in Britain as \"Greek-style yoghurt\". In Britain the name \"Greek\" may only be applied to yogurt made in Greece.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Varieties and presentation", "sub_heading": "Strained yogurt", "_id": "24--3--1---1", "title": "Strained Yogurt \u2014 What is it?"}
{"qas": [{"question": "What is the difference between a smoothie and a fruit smoothie?", "answer": ""}, {"question": "What are sweetened yogurt called in the us?", "answer": "drinkable yogurt", "ae_score": -0.21770116940518505, "qg_score": null}, {"question": "What are sweetened yogurt called in the us?", "answer": "drinkable yogurt", "ae_score": -0.21770116940518505, "qg_score": null}], "content": "Doogh (\"dawghe\" in Neo-Aramaic), ayran or dhall\u00eb is a yogurt-based, salty drink popular in Iran, Albania, Bulgaria, Turkey, Azerbaijan, Afghanistan, Pakistan, Bangladesh, Macedonia, Uzbekistan, Kazakhstan and Kyrgyzstan. It is made by mixing yogurt with water and (sometimes) salt. The same drink is known ''tan'' in Armenia; ''laban ayran'' in Syria and Lebanon; ''shenina'' in Iraq and Jordan; ''laban arbil'' in Iraq; ''majjiga'' (Telugu), ''majjige'' (Kannada), and ''moru'' (Tamil and Malayalam) in South India; namkeen ''lassi'' in Punjab and all over Pakistan.\nBorhani (or Burhani) is a spicy yogurt drink popular in Bangladesh and parts of Bengal. It is usually served with kacchi biryani at weddings and special feasts. Key ingredients are yogurt blended with mint leaves (mentha), mustard seeds and black rock salt (Kala Namak). Ground roasted cumin, ground white pepper, green chili pepper paste and sugar are often added.\nLassi is a yogurt-based beverage originally from the Indian subcontinent that is usually slightly salty or sweet. Lassi is a staple in Punjab. In some parts of the subcontinent, the sweet version may be commercially flavored with rosewater, mango or other fruit juice to create a very different drink. Salty lassi is usually flavored with ground, roasted cumin and red chilies; this salty variation may also use buttermilk, and in India is interchangeably called ''ghol'' (Bengal), ''mattha'' (North India), \"majjige\" (Karnataka), ''majjiga'' (Telangana & Andhra Pradesh), ''moru'' (Tamil Nadu and Kerala), ''Dahi paani'' ''Chalha'' (Odisha), ''tak'' (Maharashtra), or ''chaas'' (Gujarat). Lassi is very widely drunk in India, Pakistan, and Bangladesh. Mango Lassi is a popular drink at Indian restaurants in US.\nIn Bosnia and Herzegovina, Croatia, Macedonia, Montenegro, Serbia, and Slovenia, an unsweetened and unsalted yogurt drink usually called simply ''jogurt'' is a popular accompaniment to ''burek'' and other baked goods.\nSweetened yogurt drinks are the usual form in Europe (including the UK) and the US, containing fruit and added sweeteners. These are typically called \"drinkable yogurt\".\nAlso available are \"yogurt smoothies\", which contain a higher proportion of fruit and are more like smoothies. In Ecuador, yogurt smoothies flavored with native fruit are served with pan de yuca as a common type of fast food.\nAlso in Turkey, yogurt soup or ''Yayla \u00c7orbas\u0131'' is a popular way of consuming yogurt. The soup is a mix of yogurt, rice, flour and dried mint.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Varieties and presentation", "sub_heading": "Beverages", "_id": "24--3--2---1", "title": "Yogurt Drinks in India, Pakistan, Afghanistan, Pakistan, Pakistan, Afghanistan, Pakistan"}
{"qas": [{"question": "Why are there so many different kinds of yogurt?", "answer": ""}, {"question": "What is the most popular plant milk yogurts?", "answer": "soy yogurt", "ae_score": -0.3928705534053926, "qg_score": null}, {"question": "What is the most popular plant milk yogurts?", "answer": "soy yogurt", "ae_score": -0.3928705534053926, "qg_score": null}], "content": "A variety of plant-milk yogurts appeared in the 2000s, using soy milk, rice milk, and nut milks such as almond milk and coconut milk. So far the most widely sold variety of plant milk yogurts is soy yogurt. These yogurts are suitable for vegans, people with intolerance to dairy milk, and those who prefer plant milks.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Plant-milk yogurt", "sub_heading": "Plant-milk yogurt", "_id": "24--4---1---1", "title": "Plant Milk Yogurts"}
{"qas": [{"question": "Why is yogurt so much firmer than regular milk?", "answer": ""}, {"question": "What happens to the proteins in yogurt when it is heated to a temperature that denatures?", "answer": "scalding", "ae_score": -0.4855615748037434, "qg_score": null}, {"question": "What happens to the proteins in yogurt when it is heated to a temperature that denatures?", "answer": "scalding", "ae_score": -0.4855615748037434, "qg_score": null}], "content": "Yogurt is made by heating milk to a temperature that denaturates its proteins (scalding), essential for making yogurt, cooling it to a temperature that will not kill the live microorganisms that turn the milk into yogurt, inoculating certain bacteria (starter culture), usually ''Streptococcus thermophilus'' and ''Lactobacillus bulgaricus'', into the milk, and finally keeping it warm for several hours. The milk may be held at 85 C for a few minutes, or boiled (giving a somewhat different result). It must be cooled to 50 C or somewhat less, typically 40 -. Starter culture must then be mixed in well, and the mixture must be kept undisturbed and warm for several hours, ranging from 5 to 12, with longer fermentation producing a more acid yogurt. The starter culture may be a small amount of live yogurt; dried starter culture is available commercially.\nMilk with a higher concentration of solids than normal milk may be used; the higher solids content produces a firmer yogurt. Solids can be increased by adding dried milk.\nThe yogurt-making process provides two significant barriers to pathogen growth, heat and acidity (low pH). Both are necessary to ensure a safe product. Acidity alone has been questioned by recent outbreaks of food poisoning by ''E. coli O157:H7'' that is acid-tolerant. ''E. coli O157:H7'' is easily destroyed by pasteurization (heating); the initial heating of the milk kills pathogens as well as denaturing proteins. The microorganisms that turn milk into yogurt can tolerate higher temperatures than most pathogens, so that a suitable temperature not only encourages the formation of yogurt, but inhibits pathogenic microorganisms.\nOnce the yogurt has formed it can, if desired, be strained to reduce the whey content and thicken it.", "page_name": "Yogurt", "page_id": "Yogurt", "heading": "Making yogurt at home", "sub_heading": "Making yogurt at home", "_id": "24--5---1---1", "title": "Yogurt \u2014 How to Make It"}
{"qas": [{"question": "What is atmospheric chemistry and why is it important?", "answer": ""}, {"question": "The study of the earth's atmosphere is called?", "answer": "Atmospheric chemistry", "ae_score": -0.31932944833401805, "qg_score": null}, {"question": "The study of the earth's atmosphere is called?", "answer": "Atmospheric chemistry", "ae_score": -0.31932944833401805, "qg_score": null}], "content": "Atmospheric chemistry is a branch of atmospheric science in which the chemistry of the Earth's atmosphere and that of other planets is studied. It is a multidisciplinary field of research and draws on environmental chemistry, physics, meteorology, computer modeling, oceanography, geology and volcanology and other disciplines. Research is increasingly connected with other areas of study such as climatology.\nThe composition and chemistry of the atmosphere is of importance for several reasons, but primarily because of the interactions between the atmosphere and living organisms. The composition of the Earth's atmosphere has been changed by human activity and some of these changes are harmful to human health, crops and ecosystems. Examples of problems which have been addressed by atmospheric chemistry include acid rain, photochemical smog and global warming. Atmospheric chemistry seeks to understand the causes of these problems, and by obtaining a theoretical understanding of them, allow possible solutions to be tested and the effects of changes in government policy evaluated.", "page_name": "Atmospheric sciences", "page_id": "Atmospheric%20sciences", "heading": "Atmospheric chemistry", "sub_heading": "Atmospheric chemistry", "_id": "25--0---1---1", "title": "Atmospheric Chemistry: A branch of atmospheric science"}
{"qas": [{"question": "What is atmospheric dynamical analysis?", "answer": ""}, {"question": "What is the study of the motion systems of meteorological importance?", "answer": "Atmospheric dynamics", "ae_score": -0.485257352445855, "qg_score": null}, {"question": "What is the study of the motion systems of meteorological importance?", "answer": "Atmospheric dynamics", "ae_score": -0.485257352445855, "qg_score": null}], "content": "Atmospheric dynamics involves the study of observations and theory dealing with all motion systems of meteorological importance. Common topics studied include diverse phenomena such as thunderstorms, tornadoes, gravity waves, tropical cyclones, extratropical cyclones, jet streams, and global-scale circulations. The goal of dynamical studies is to explain the observed circulations on the basis of fundamental principles from physics. The objectives of such studies incorporate improving weather forecasting, developing methods for predicting seasonal and interannual climate fluctuations, and understanding the implications of human-induced perturbations (e.g., increased carbon dioxide concentrations or depletion of the ozone layer) on the global climate.", "page_name": "Atmospheric sciences", "page_id": "Atmospheric%20sciences", "heading": "Atmospheric dynamics", "sub_heading": "Atmospheric dynamics", "_id": "25--1---1---1", "title": "Atmospheric sciences | Atmospheric dynamics"}
{"qas": [{"question": "How do meteorologists determine the temperature of the atmosphere?", "answer": ""}, {"question": "What do the earth's magnetic field and solar wind interact with?", "answer": "the atmosphere", "ae_score": -0.4888533827698947, "qg_score": null}, {"question": "What do the earth's magnetic field and solar wind interact with?", "answer": "the atmosphere", "ae_score": -0.4888533827698947, "qg_score": null}], "content": "Atmospheric physics is the application of physics to the study of the atmosphere. Atmospheric physicists attempt to model Earth's atmosphere and the atmospheres of the other planets using fluid flow equations, chemical models, radiation balancing, and energy transfer processes in the atmosphere and underlying oceans. In order to model weather systems, atmospheric physicists employ elements of scattering theory, wave propagation models, cloud physics, statistical mechanics and spatial statistics, each of which incorporate high levels of mathematics and physics. Atmospheric physics has close links to meteorology and climatology and also covers the design and construction of instruments for studying the atmosphere and the interpretation of the data they provide, including remote sensing instruments.\nIn the United Kingdom, atmospheric studies are underpinned by the Meteorological Office. Divisions of the U.S. National Oceanic and Atmospheric Administration (NOAA) oversee research projects and weather modeling involving atmospheric physics. The U.S. National Astronomy and Ionosphere Center also carries out studies of the high atmosphere.\nThe Earth's magnetic field and the solar wind interact with the atmosphere, creating the ionosphere, Van Allen radiation belts, telluric currents, and radiant energy.", "page_name": "Atmospheric sciences", "page_id": "Atmospheric%20sciences", "heading": "Atmospheric physics", "sub_heading": "Atmospheric physics", "_id": "25--2---1---1", "title": "Atmospheric sciences | Atmospheric physics"}
{"qas": [{"question": "What is climatology?", "answer": ""}, {"question": "What is a person who studies the nature of climates?", "answer": "Climatologists", "ae_score": -0.7601948473521175, "qg_score": null}, {"question": "What is a person who studies the nature of climates?", "answer": "Climatologists", "ae_score": -0.7601948473521175, "qg_score": null}], "content": "In contrast to meteorology, which studies short term weather systems lasting up to a few weeks, climatology studies the frequency and trends of those systems. It studies the periodicity of weather events over years to millennia, as well as changes in long-term average weather patterns, in relation to atmospheric conditions. Climatologists, those who practice climatology, study both the nature of climates \u2013 local, regional or global \u2013 and the natural or human-induced factors that cause climates to change. Climatology considers the past and can help predict future climate change.\nPhenomena of climatological interest include the atmospheric boundary layer, circulation patterns, heat transfer (radiative, convective and latent), interactions between the atmosphere and the oceans and land surface (particularly vegetation, land use and topography), and the chemical and physical composition of the atmosphere. Related disciplines include astrophysics, atmospheric physics, chemistry, ecology, physical geography, geology, geophysics, glaciology, hydrology, oceanography, and volcanology.", "page_name": "Atmospheric sciences", "page_id": "Atmospheric%20sciences", "heading": "Climatology", "sub_heading": "Climatology", "_id": "25--3---1---1", "title": "Climatology \u2014 The Science of Climate Change"}
{"qas": [{"question": "Why is the Earth's atmosphere so different from other planets?", "answer": ""}, {"question": "What extrasolar planet is claimed to possess a weather system similar to the great red spot?", "answer": "HD 189733 b", "ae_score": -0.5530858490722748, "qg_score": null}, {"question": "What extrasolar planet is claimed to possess a weather system similar to the great red spot?", "answer": "HD 189733 b", "ae_score": -0.5530858490722748, "qg_score": null}], "content": "All of the Solar System's planets have atmospheres.  This is because their gravity is strong enough to keep gaseous particles close to the surface.  Larger gas giants are massive enough to keep large amounts of the light gases hydrogen and helium close by, while the smaller planets lose these gases into space. The composition of the Earth's atmosphere is different from the other planets because the various life processes that have transpired on the planet have introduced free molecular oxygen. Much of Mercury's atmosphere has been blasted away by the solar wind. The only moon that has retained a dense atmosphere is Titan. There is a thin atmosphere on Triton, and a trace of an atmosphere on the Moon.\nPlanetary atmospheres are affected by the varying degrees of energy received from either the Sun or their interiors, leading to the formation of dynamic weather systems such as hurricanes, (on Earth), planet-wide dust storms (on Mars), an Earth-sized anticyclone on Jupiter (called the Great Red Spot), and holes in the atmosphere (on Neptune). At least one extrasolar planet, HD 189733 b, has been claimed to possess such a weather system, similar to the Great Red Spot but twice as large.\nHot Jupiters have been shown to be losing their atmospheres into space due to stellar radiation, much like the tails of comets. These planets may have vast differences in temperature between their day and night sides which produce supersonic winds, although the day and night sides of HD 189733b appear to have very similar temperatures, indicating that planet's atmosphere effectively redistributes the star's energy around the planet.", "page_name": "Atmospheric sciences", "page_id": "Atmospheric%20sciences", "heading": "Atmospheres on other celestial bodies", "sub_heading": "Atmospheres on other celestial bodies", "_id": "25--4---1---1", "title": "Atmospheric sciences | Atmospheres on other celestial bodies"}
{"qas": [{"question": "How did classical economics deal with the economic crisis of the 19th century?", "answer": ""}, {"question": "Who developed the theory of alternating cycles?", "answer": "Charles Dunoyer", "ae_score": -0.3267658431431643, "qg_score": null}, {"question": "Over overproduction and underconsumption are the two main causes of what?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "The first systematic exposition of periodic economic crises, in opposition to the existing theory of economic equilibrium, was the 1819 ''Nouveaux Principes d'\u00e9conomie politique'' by Jean Charles L\u00e9onard de Sismondi. Prior to that point classical economics had either denied the existence of business cycles, blamed them on external factors, notably war, or only studied the long term. Sismondi found vindication in the Panic of 1825, which was the first unarguably international economic crisis, occurring in peacetime.\nSismondi and his contemporary Robert Owen, who expressed similar but less systematic thoughts in 1817 ''Report to the Committee of the Association for the Relief of the Manufacturing Poor,'' both identified the cause of economic cycles as overproduction and underconsumption, caused in particular by wealth inequality. They advocated government intervention and socialism, respectively, as the solution. This work did not generate interest among classical economists, though underconsumption theory developed as a heterodox branch in economics until being systematized in Keynesian economics in the 1930s.\nSismondi's theory of periodic crises was developed into a theory of alternating ''cycles'' by Charles Dunoyer, and similar theories, showing signs of influence by Sismondi, were developed by Johann Karl Rodbertus. Periodic crises in capitalism formed the basis of the theory of Karl Marx, who further claimed that these crises were increasing in severity and, on the basis of which, he predicted a communist revolution. He devoted hundreds of pages of ''Das Kapital'' (1867) to crises. In ''Progress and Poverty'' (1879), Henry George focused on land's role in crises \u2013 particularly land speculation \u2013 and proposed a single tax on land as a solution.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "History", "sub_heading": "History", "_id": "26--0--0---1", "title": "Periodic Crises in Economics"}
{"qas": [{"question": "Why are there so many business cycles?", "answer": ""}, {"question": "The idea of periodic cycles has waned since the development of?", "answer": "modern macroeconomics", "ae_score": -0.3335523920549631, "qg_score": null}, {"question": "What are the four stages of the business cycle?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "In 1860 French economist Clement Juglar first identified economic cycles 7 to 11 years long, although he cautiously did not claim any rigid regularity. Later, economist Joseph Schumpeter (1883\u20131950) argued that a Juglar Cycle has four stages:\nSchumpeter's Juglar model associates recovery and prosperity with increases in productivity, consumer confidence, aggregate demand, and prices.\nIn the mid-20th century, Schumpeter and others proposed a typology of business cycles according to their periodicity, so that a number of particular cycles were named after their discoverers or proposers:\nInterest in the different typologies of cycles has waned since the development of modern macroeconomics, which gives little support to the idea of regular periodic cycles.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "History", "sub_heading": "Classification by periods", "_id": "26--0--1---1", "title": "The Juglar Cycle"}
{"qas": [{"question": "Why did the world economy recover so quickly after World War II?", "answer": ""}, {"question": "Which event caused a multi-year decline in the business cycle?", "answer": "Great Depression", "ae_score": -0.6021417647702173, "qg_score": null}, {"question": "What is the term for a period of time in which technological progress has had a large?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "There were great increases in  productivity, industrial production and real per capita product throughout period from 1870 to 1890 that included the Long Depression and two other recessions.  There were also significant increases in productivity in the years leading up to the Great Depression.  Both the Long and Great Depressions were characterized by overcapacity and market saturation.\nOver the period since the Industrial Revolution, technological progress has had a much larger effect on the economy than any fluctuations in credit or debt, the primary exception being the Great Depression, which caused a multi-year steep economic decline.  The effect of technological progress can be seen by the purchasing power of an average hour's work, which has grown from $3 in 1900 to $22 in 1990, measured in 2010 dollars.  There were similar increases in real wages during the 19th century.  See: Productivity improving technologies (historical)  A table of innovations and long cycles can be seen at: Kondratiev wave\nThere were frequent crises in Europe and America in the 19th and first half of the 20th century, specifically the period 1815\u20131939. This period started from the end of the Napoleonic wars in 1815, which was immediately followed by the Post-Napoleonic depression in the United Kingdom (1815\u201330), and culminated in the Great Depression of 1929\u201339, which led into World War II. See Financial crisis: 19th century for listing and details. The first of these crises not associated with a war was the Panic of 1825.\nBusiness cycles in OECD countries after World War II were generally more restrained than the earlier business cycles. This was particularly true during the Golden Age of Capitalism (1945/50\u20131970s), and the period 1945\u20132008 did not experience a global downturn until the Late-2000s recession.   Economic stabilization policy using fiscal policy and monetary policy appeared to have dampened the worst excesses of business cycles, and automatic stabilization due to the aspects of the government's budget also helped mitigate the cycle even without conscious action by policy-makers.\nIn this period, the economic cycle \u2013 at least the problem of depressions \u2013 was twice declared dead. The first declaration was in the late 1960s, when the Phillips curve was seen as being able to steer the economy. However, this was followed by stagflation in the 1970s, which discredited the theory.  The second declaration was in the early 2000s, following the stability and growth in the 1980s and 1990s in what came to be known as The Great Moderation. Notably, in 2003, Robert Lucas, in his presidential address to the American Economic Association, declared that the \"central problem of depression-prevention [has] been solved, for all practical purposes.\"  Unfortunately, this was followed by the 2008\u20132012 global recession.\nVarious regions have experienced prolonged depressions, most dramatically the economic crisis in former Eastern Bloc countries following the end of the Soviet Union in 1991.  For several of these countries the period 1989\u20132010 has been an ongoing depression, with real income still lower than in 1989.  This has been attributed not to a cyclical pattern, but to a mismanaged transition from command economies to market economies.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "History", "sub_heading": "Occurrence", "_id": "26--0--2---1", "title": "The Economic Cycle: The Great Depression and the Industrial Revolution"}
{"qas": [{"question": "Why is it so hard to get a job at a gas station?", "answer": ""}, {"question": "Who came up with the business cycle theory?", "answer": "A. F. Burns", "ae_score": -0.03866198270562937, "qg_score": null}, {"question": "Who came up with the business cycle theory?", "answer": "A. F. Burns", "ae_score": -0.03866198270562937, "qg_score": null}], "content": "In 1946, economists Arthur F. Burns and Wesley C. Mitchell provided the now standard definition of business cycles in their book ''Measuring Business Cycles'':\nAccording to A. F. Burns:\nIn the United States, it is generally accepted that the National Bureau of Economic Research (NBER) is the final arbiter of the dates of the peaks and troughs of the business cycle. An expansion is the period from a trough to a peak, and a recession as the period from a peak to a trough. The NBER identifies a recession as \"a significant decline in economic activity spread across the economy, lasting more than a few months, normally visible in real GDP, real income, employment, industrial production\".\nThere is often a close timing relationship between the upper turning points ofthe business cycle, commodity prices and freight rates, which is shown to be particularly tightin the grand peak years of 1873, 1889, 1900 and 1912.\nRecent research employing spectral analysis has confirmed the presence of Kondratiev waves in the world GDP dynamics at an acceptable level of statistical significance. Korotayev & Tsirel also detected shorter business cycles, dating the Kuznets to about 17 years and calling it the third sub-harmonic of the Kondratiev, meaning that there are three Kuznets cycles per Kondratiev.\nIn recent years economic theory has moved towards the study of ''economic fluctuation'' rather than a 'business cycle' \u2013 though some economists use the phrase 'business cycle' as a convenient shorthand. For Milton Friedman calling the business cycle a \"cycle\" is a misnomer, because of its non-cyclical nature. Friedman believed that for the most part, excluding very large supply shocks, business declines are more of a monetary phenomenon.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Identifying", "sub_heading": "Identifying", "_id": "26--1---1---1", "title": "Business Cycles \u2014 A Misnomer"}
{"qas": [{"question": "What is the difference between endogenous and endogenous economic cycles?", "answer": ""}, {"question": "The economic cycle as caused exogenously dates back to?", "answer": "Say's law", "ae_score": -0.3687695528592528, "qg_score": null}, {"question": "What are the two main causes of the economic cycle?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "Within mainstream economics, the debate over external (exogenous) versus internal (endogenous) being the causes of the economic cycles, with the classical school (now neo-classical) arguing for exogenous causes and the underconsumptionist (now Keynesian) school arguing for endogenous causes. These may also broadly be classed as \"supply-side\" and \"demand-side\" explanations: supply-side explanations may be styled, following Say's law, as arguing that \"supply creates its own demand\", while demand-side explanations argue that effective demand may fall short of supply, yielding a recession or depression.\nThis debate has important policy consequences: proponents of exogenous causes of crises such as neoclassicals largely argue for minimal government policy or regulation (laissez faire), as absent these external shocks, the market functions, while proponents of endogenous causes of crises such as Keynesians largely argue for larger government policy and regulation, as absent regulation, the market will move from crisis to crisis. This division is not absolute \u2013 some classicals (including Say) argued for government policy to mitigate the damage of economic cycles, despite believing in external causes, while Austrian School economists argue against government involvement as only worsening crises, despite believing in internal causes.\nThe view of the economic cycle as caused exogenously dates to Say's law, and much debate on endogeneity or exogeneity of causes of the economic cycle is framed in terms of refuting or supporting Say's law; this is also referred to as the \"general glut\" debate.\nUntil the Keynesian revolution in mainstream economics in the wake of the Great Depression, classical and neoclassical explanations (exogenous causes) were the mainstream explanation of economic cycles; following the Keynesian revolution, neoclassical macroeconomics was largely rejected. There has been some resurgence of neoclassical approaches in the form of real business cycle (RBC) theory.  The debate between Keynesians and neo-classical advocates was reawakened following the recession of 2007.\nMainstream economists working in the neoclassical tradition, as opposed to the Keynesian tradition, have usually viewed the departures of the harmonic working of the market economy as due to exogenous influences, such as the State or its regulations, labor unions, business monopolies, or shocks due to technology or natural causes.\nContrarily, in the heterodox tradition of Jean Charles L\u00e9onard de Sismondi, Clement Juglar, and Marx the recurrent upturns and downturns of the market system are an endogenous characteristic of it.\nThe 19th-century school of underconsumptionism also posited endogenous causes for the business cycle, notably the paradox of thrift, and today this previously heterodox school has entered the mainstream in the form of Keynesian economics via the Keynesian revolution.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Proposed explanations", "_id": "26--2--0---1", "title": "Keynesian economics and the neo-classical debate"}
{"qas": [{"question": "What are Keynesian business cycles?", "answer": ""}, {"question": "Who is the author of the model of the business cycle?", "answer": "Richard Goodwin", "ae_score": -0.3578325937044273, "qg_score": null}, {"question": "What is the term for the cycle of output and output?", "answer": "wage cycle", "ae_score": null, "qg_score": null}], "content": "According to Keynesian economics, fluctuations in aggregate demand cause the economy to come to short run equilibrium at levels that are different from the full employment rate of output. These fluctuations express themselves as the observed business cycles. Keynesian models do not necessarily imply periodic business cycles. However, simple Keynesian models involving the interaction of the Keynesian multiplier and accelerator give rise to cyclical responses to initial shocks. Paul Samuelson's \"oscillator model\" is supposed to account for business cycles thanks to the multiplier and the accelerator. The amplitude of the variations in economic output depends on the level of the investment, for investment determines the level of aggregate output (multiplier), and is determined by aggregate demand (accelerator).\nIn the Keynesian tradition, Richard Goodwin accounts for cycles in output by the distribution of income between business profits and workers' wages. The fluctuations in wages are almost the same as in the level of employment (wage cycle lags one period behind the employment cycle), for when the economy is at high employment, workers are able to demand rises in wages, whereas in periods of high unemployment, wages tend to fall. According to Goodwin, when unemployment and business profits rise, the output rises.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Keynesian", "_id": "26--2--1---1", "title": "Keynesian Economics: Business Cycles"}
{"qas": [{"question": "Why are credit causes not mentioned in the mainstream?", "answer": ""}, {"question": "What are the main causes of the economic cycle?", "answer": "credit causes", "ae_score": -0.21497362118043936, "qg_score": null}, {"question": "The cycle of credit, interest rates and financial frailty is known as?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "One alternative theory is that the primary cause of economic cycles is due to the credit cycle: the net expansion of credit (increase in private credit, equivalently debt, as a percentage of GDP) yields economic expansions, while the net contraction causes recessions, and if it persists, depressions. In particular, the bursting of speculative bubbles is seen as the proximate cause of depressions, and this theory places finance and banks at the center of the business cycle.\nA primary theory in this vein is the debt deflation theory of Irving Fisher, which he proposed to explain the Great Depression. A more recent complementary theory is the Financial Instability Hypothesis of Hyman Minsky, and the credit theory of economic cycles is often associated with Post-Keynesian economics such as Steve Keen.\nPost-Keynesian economist Hyman Minsky has proposed an explanation of cycles founded on fluctuations in credit, interest rates and financial frailty, called the Financial Instability Hypothesis. In an expansion period, interest rates are low and companies easily borrow money from banks to invest. Banks are not reluctant to grant them loans, because expanding economic activity allows business increasing cash flows and therefore they will be able to easily pay back the loans. This process leads to firms becoming excessively indebted, so that they stop investing, and the economy goes into recession.\nWhile credit causes have not been a primary theory of the economic cycle within the mainstream, they have gained occasional mention, such as , cited approvingly by .\nCarlota Perez blames \"financial capital\" for excess speculation, which she claims is likely to occur in the \"frenzy\" stage of a new technology, such as the 1998\u20132000 computer, internet, dot.com mania and bust.  Perez also says excess speculation is likely to occur in the mature phase of a technological age.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Credit/debt cycle", "_id": "26--2--2---1", "title": "The Credit Theory of Economic Cycles"}
{"qas": [{"question": "What is the difference between RBC and Keynesian economics?", "answer": ""}, {"question": "Who is a leading advocate of the business cycle theory?", "answer": "Paul Krugman", "ae_score": -0.1566793477077718, "qg_score": null}, {"question": "Who is a leading advocate of the business cycle theory?", "answer": "Paul Krugman", "ae_score": -0.1566793477077718, "qg_score": null}], "content": "Within mainstream economics, Keynesian views have been challenged by real business cycle models in which fluctuations are due to technology shocks. This theory is most associated with Finn E. Kydland and Edward C. Prescott, and more generally the Chicago school of economics (freshwater economics). They consider that economic crisis and fluctuations cannot stem from a monetary shock, only from an external shock, such as an innovation.\nRBC theory has been categorically rejected by a number of mainstream economists in the Keynesian tradition, such as  and Paul Krugman.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Real business cycle theory", "_id": "26--2--3---1", "title": "Keynesian Business Cycle Models"}
{"qas": [{"question": "What is the \"partisan business cycle\"?", "answer": ""}, {"question": "Which party leads the business cycle in germany?", "answer": "Party A", "ae_score": -0.7862105855325433, "qg_score": null}, {"question": "What is the upward part of the business cycle called?", "answer": "swing cycle", "ae_score": null, "qg_score": null}], "content": "Another set of models tries to derive the business cycle from political decisions. The ''partisan business cycle'' suggests that cycles result from the successive elections of administrations with different policy regimes. Regime A adopts expansionary policies, resulting in growth and inflation, but is voted out of office when inflation becomes unacceptably high. The replacement, Regime B, adopts contractionary policies reducing inflation and growth, and the downwards swing of the cycle. It is voted out of office when unemployment is too high, being replaced by Party A.\nThe political business cycle is an alternative theory stating that when an administration of any hue is elected, it initially adopts a contractionary policy to reduce inflation and gain a reputation for economic competence. It then adopts an expansionary policy in the lead up to the next election, hoping to achieve simultaneously low inflation and unemployment on election day.\nThe political business cycle theory is strongly linked to the name of Micha\u0142 Kalecki who discussed \"the reluctance of the 'captains of industry' to accept government intervention in the matter of employment.\"  Persistent full employment would mean increasing workers' bargaining power to raise wages and to avoid doing unpaid labor, potentially hurting profitability. (He did not see this theory as applying under fascism, which would use direct force to destroy labor's power.) In recent years, proponents of the \"electoral business cycle\" theory have argued that incumbent politicians encourage prosperity before elections in order to ensure re-election \u2013 and make the citizens pay for it with recessions afterwards.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Politically based business cycle", "_id": "26--2--4---1", "title": "Political Business Cycle Theory"}
{"qas": [{"question": "How did the Great Depression happen?", "answer": ""}, {"question": "What is the main engine of the market economy?", "answer": "profit", "ae_score": -0.3403801177044669, "qg_score": null}, {"question": "What is the name of the economic cycle in which the working class gains more power and?", "answer": "wage cycle", "ae_score": null, "qg_score": null}], "content": "For Marx the economy based on production of commodities to be sold in the market is intrinsically prone to crisis. In the heterodox Marxian view profit is the major engine of the market economy, but business (capital) profitability has a tendency to fall that recurrently creates crises, in which mass unemployment occurs, businesses fail, remaining capital is centralized and concentrated and profitability is recovered. In the long run these crises tend to be more severe and the system will eventually fail.\nSome Marxist authors such as Rosa Luxemburg viewed the lack of purchasing power of workers as a cause of a tendency of supply to be larger than demand, creating crisis, in a model that has similarities with the Keynesian one. Indeed, a number of modern authors have tried to combine Marx's and Keynes's views. Henryk Grossman reviewed the debates and the counteracting tendencies and Paul Mattick subsequently emphasized the basic differences between the Marxian and the Keynesian perspective: while Keynes saw capitalism as a system worth maintaining and susceptible to efficient regulation, Marx viewed capitalism as a historically doomed system that cannot be put under societal control.\nThe American mathematician and economist, Richard M. Goodwin formalised a Marxist model of business cycles, known as the Goodwin Model in which recession was caused by increased bargaining power of workers (a result of high employment in boom periods) pushing up the wage share of national income, suppressing profits and leading to a breakdown in capital accumulation. Later theorists applying variants of the Goodwin model have identified both short and long period profit-led growth and distribution cycles in the United States, and elsewhere. David Gordon provided a Marxist model of long period institutional growth cycles, in an attempt to explain the Kondratiev wave. This cycle is due to the periodic breakdown of the 'social structure of accumulation' \u2013 a set of institutions which secure and stabilise capital accumulation.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Marxian economics", "_id": "26--2--5---1", "title": "Marxist and Keynesian Perspectives on Capitalism"}
{"qas": [{"question": "What is the Austrian explanation of the business cycle?", "answer": ""}, {"question": "When was the central bank established in austrian business cycle theory?", "answer": "1913", "ae_score": -0.5193224779011442, "qg_score": null}, {"question": "When was the central bank established in austrian business cycle theory?", "answer": "1913", "ae_score": -0.5193224779011442, "qg_score": null}], "content": "Economists of the Austrian School argue that business cycles are caused by excessive issuance of credit by banks in fractional reserve banking systems. According to Austrian economists, excessive issuance of bank credit may be exacerbated if central bank monetary policy sets interest rates too low, and the resulting expansion of the money supply causes a \"boom\" in which resources are misallocated or \"malinvested\" because of artificially low interest rates. Eventually, the boom cannot be sustained and is followed by a \"bust\" in which the malinvestments are liquidated  (sold for less than their original cost) and the money supply contracts.\nOne of the criticisms of the Austrian business cycle theory is based on the observation that the United States suffered recurrent economic crises in the 19th century, notably the Panic of 1873, which occurred prior to the establishment of a U.S. central bank in 1913.  Adherents of the Austrian School, such as the historian Thomas Woods, argue that these earlier financial crises were prompted by government and bankers' efforts to expand credit despite restraints imposed by the prevailing gold standard, and are thus consistent with Austrian Business Cycle Theory.\nThe Austrian explanation of the business cycle differs significantly from the mainstream understanding of business cycles and is generally rejected by mainstream economists. Mainstream economists generally do not support Austrian school explanations for business cycles, on both theoretical as well as real-world empirical grounds.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Austrian School", "_id": "26--2--6---1", "title": "The Austrian Business Cycle Theory"}
{"qas": [{"question": "What is the difference between a negative yield curve and a positive yield curve?", "answer": ""}, {"question": "Who defines the cycle of recessions in the us?", "answer": "NBER business cycle dating committee", "ae_score": -0.5998034087581041, "qg_score": null}, {"question": "What is it called when the yield curve is inverted?", "answer": "model recession", "ae_score": null, "qg_score": null}], "content": "The slope of the yield curve is one of the most powerful predictors of future economic growth, inflation, and recessions.  One measure of the yield curve slope (i.e. the difference between 10-year Treasury bond rate and the 3-month Treasury bond rate) is included in the Financial Stress Index published by the St. Louis Fed.  A different measure of the slope (i.e. the difference between 10-year Treasury bond rates and the federal funds rate) is incorporated into the Index of Leading Economic Indicators.\nAn inverted yield curve is often a harbinger of recession.  A positively sloped yield curve is often a harbinger of inflationary growth.  Work by Dr. Arturo Estrella & Dr. Tobias Adrian has established the predictive power of an inverted yield curve to signal a recession.  Their models show that when the difference between short-term interest rates (he uses 3-month T-bills) and long-term interest rates (10-year Treasury bonds) at the end of a federal reserve tightening cycle is negative or less than 93 basis points positive that a rise in unemployment usually occurs.  The New York Fed publishes a monthly recession probability prediction derived from the yield curve and based on Dr. Estrella's work.\nAll the recessions in the US since 1970 (up through 2015) have been preceded by an inverted yield curve (10-year vs 3-month).  Over the same time frame, every occurrence of an inverted yield curve has been followed by recession as declared by the NBER business cycle dating committee.\nDr. Estrella has postulated that the yield curve affects the business cycle via the balance sheet of banks.  When the yield curve is inverted banks are often caught paying more on short-term deposits than they are making on long-term loans leading to a loss of profitability and reluctance to lend resulting in a credit crunch.  When the yield curve is upward sloping, banks can profitably take-in short term deposits and make long-term loans so they are eager to supply credit to borrowers. This eventually leads to a credit bubble.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Yield curve", "_id": "26--2--7---1", "title": "The Predictive Power of the Yield Curve"}
{"qas": [{"question": "Why does the price of housing and commercial real estate go up so quickly?", "answer": ""}, {"question": "Who said land prices were the main cause of business cycles?", "answer": "Henry George", "ae_score": -0.34583106173869793, "qg_score": null}, {"question": "The tendency for real estate prices to rise on an exponential basis as the economy grows is?", "answer": "swing cycle", "ae_score": null, "qg_score": null}], "content": "Henry George claimed land price fluctuations were the primary cause of most business cycles.  The theory is generally ignored in most of today's discussions of the subject despite two of the greatest economic contractions of the last 100 years (1929\u20131933 and 2008\u20132009) involving speculative real estate bubbles.\nGeorge observed that one necessary factor in production \u2013 land \u2013 has an inherent tendency to rise in price on an exponential basis as the economy grows.  The reason for this is that the quantity of land (the stock of locations and natural resources) is fixed, while its quality is improved due to improvements such as transportation infrastructures and economic development of the surroundings.  Investors see this tendency as the economy grows and they buy land ahead of the boom areas, withholding it from use in order to take advantage of its increased value in the future.  Because housing and commercial real estate provide collateral for a large portion of lending, there is a tendency for real estate prices to rise faster than the rate of inflation in business cycle upswings.Speculation in land concentrates profits in landholders and diverts economic resources to speculation in land, squeezing profits away from production that has to occur on this land.\nIn effect, land speculation creates a built-in supply shock, that squeezes the economy just as economic output increases. This is a systemic retardation of the economy, placing a sharp brake on further economic expansion. This shock to the economy occurs as long as there is land speculation, creating an underlying tendency toward inflation and recession late in the growth phase of the business cycle. Land speculation, according to George, is always the cause of economic downturns. There are any number of contributing causes; things like oil price shocks, consumer confidence crises, international trade fluctuations, natural disasters \u2013 but none of these things creates the underlying weakness.\nLand speculation slows the economy in two ways. It increases production costs by making land in general more expensive (shifting the Aggregate supply (AS) curve upward) as well as decreasing productivity by denying access to the best locations, shifting the AS curve to the left and lowering \"potential output\".", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Proposed explanations", "sub_heading": "Georgism", "_id": "26--2--8---1", "title": "Henry George\u2019s Theory of Land Price Fluctuations"}
{"qas": [{"question": "Why is it bad for the economy to have a repeat business cycle crisis?", "answer": ""}, {"question": "What should governments focus on instead of stabilization?", "answer": "long-term growth", "ae_score": -0.38052084839770023, "qg_score": null}, {"question": "What should governments focus on instead of stabilization?", "answer": "long-term growth", "ae_score": -0.38052084839770023, "qg_score": null}], "content": "Many social indicators, such as mental health, crimes, and suicides, worsen during economic recessions (though general mortality tends to fall, and it is in expansions when it tends to increase). As periods of economic stagnation are painful for the many who lose their jobs, there is often political pressure for governments to mitigate recessions. Since the 1940s, following the Keynesian revolution, most governments of developed nations have seen the mitigation of the business cycle as part of the responsibility of government, under the rubric of stabilization policy.\nSince in the Keynesian view, recessions are caused by inadequate aggregate demand, when a recession occurs the government should increase the amount of aggregate demand and bring the economy back into equilibrium.  This the government can do in two ways, firstly by increasing the money supply (expansionary monetary policy) and secondly by increasing government spending or cutting taxes (expansionary fiscal policy).\nBy contrast, some economists, notably New classical economist Robert Lucas, argue that the welfare cost of business cycles are very small to negligible, and that governments should focus on long-term growth instead of stabilization.\nHowever, even according to Keynesian theory, managing economic policy to smooth out the cycle is a difficult task in a society with a complex economy. Some theorists, notably those who believe in Marxian economics, believe that this difficulty is insurmountable. Karl Marx claimed that recurrent business cycle crises were an inevitable result of the operations of the capitalistic system. In this view, all that the government can do is to change the ''timing'' of economic crises. The crisis could also show up in a different ''form'', for example as severe inflation or a steadily increasing government deficit. Worse, by delaying a crisis, government policy is seen as making it ''more dramatic'' and thus more painful.\nAdditionally, since the 1960s neoclassical economists have played down the ability of Keynesian policies to manage an economy.  Since the 1960s, economists like Nobel Laureates Milton Friedman and Edmund Phelps have made ground in their arguments that inflationary expectations negate the Phillips curve in the long run.  The stagflation of the 1970s provided striking support for their theories while proving a dilemma for Keynesian policies, which appeared to necessitate both expansionary policies to mitigate recession and contractionary policies to reduce inflation.Friedman has gone so far as to argue that all the central bank of a country should do is to avoid making large mistakes, as he believes they did by contracting the money supply very rapidly in the face of the Wall Street Crash of 1929, in which they made what would have been a recession into the Great Depression.", "page_name": "Business cycle", "page_id": "Business%20cycle", "heading": "Mitigating an economic downturn", "sub_heading": "Mitigating an economic downturn", "_id": "26--3---1---1", "title": "Keynesian Economic Theory and the Crisis of the Economy"}
{"qas": [{"question": "Why are there no anemonefish in the Atlantic?", "answer": ""}, {"question": "What type of fish live in shallow waters in the red sea?", "answer": "Anemonefish", "ae_score": -0.7787079026895146, "qg_score": null}, {"question": "What type of fish live in shallow waters in the red sea?", "answer": "Anemonefish", "ae_score": -0.7787079026895146, "qg_score": null}], "content": "Anemonefish are native to warmer waters of the Indian and Pacific oceans, including the Great Barrier Reef and the Red Sea. While most species have restricted distributions, others are widespread. Anemonefish live at the bottom of shallow seas in sheltered reefs or in shallow lagoons. There are no anemonefish in the Atlantic.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Distribution and habitats", "sub_heading": "Distribution and habitats", "_id": "27--0---1---1", "title": "Anemonefish in the Pacific Ocean"}
{"qas": [{"question": "How do anemonefish survive in the ocean?", "answer": ""}, {"question": "Where does the majority of anemonefish eat?", "answer": "algae", "ae_score": -0.7022887827233907, "qg_score": null}, {"question": "Where does the majority of anemonefish eat?", "answer": "algae", "ae_score": -0.7022887827233907, "qg_score": null}], "content": "Anemonefish are omnivorous and can feed on undigested food from their host anemones, and the fecal matter from the anemonefish provides nutrients to the sea anemone. Anemonefish primarily feed on small zooplankton from the water column, such as copepods and tunicate larvae, with a small portion of their diet coming from algae, with the exception of ''Amphiprion perideraion'', which primarily feeds on algae. They may also consume the tentacles of their host anemone.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Diet", "sub_heading": "Diet", "_id": "27--1---1---1", "title": "Anemonefish are omnivores and can feed on undigested food from"}
{"qas": [{"question": "What is the purpose of anemonefish and sea anemones?", "answer": ""}, {"question": "What type of fish live in venomous tentacles?", "answer": "Anemonefish", "ae_score": -0.05985565384801311, "qg_score": null}, {"question": "What type of fish live in venomous tentacles?", "answer": "Anemonefish", "ae_score": -0.05985565384801311, "qg_score": null}], "content": "Anemonefish and sea anemones have a symbiotic, mutualistic relationship, each providing a number of benefits to the other. The individual species are generally highly host specific, and especially the genera ''Heteractis'' and ''Stichodactyla'', and the species ''Entacmaea quadricolor'' are frequent anemonefish partners. The sea anemone protects the anemonefish from predators, as well as providing food through the scraps left from the anemone's meals and occasional dead anemone tentacles. In return, the anemonefish defends the anemone from its predators, and parasites. The anemone also picks up nutrients from the anemonefish's excrement, and functions as a safe nest site. The nitrogen excreted from anemonefish increases the amount of algae incorporated into the tissue of their hosts, which aids the anemone in tissue growth and regeneration. It has been theorized that the anemonefish use their bright coloring to lure small fish to the anemone, and that the activity of the anemonefish results in greater water circulation around the sea anemone. Studies on anemonefish have found that anemonefish alter the flow of water around sea anemone tentacles by certain behaviours and movements such as \"wedging\" and \"switching.\"  Aeration of the host anemone tentacles allows for benefits to the metabolism of both partners, mainly by increasing anemone body size and both anemonefish and anemone respiration.\nThere are several theories about how they can survive the sea anemone poison:\nAnemonefish are the best known example of fish that are able to live among the venomous sea anemone tentacles, but there are several others, including juvenile threespot dascyllus, certain cardinalfish (such as Banggai cardinalfish),  Bucchich's (or anemone) goby and juvenile painted greenling.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Symbiosis and mutualism", "sub_heading": "Symbiosis and mutualism", "_id": "27--2---1---1", "title": "Anemonefish and Sea Anemones \u2014 a mutualistic relationship"}
{"qas": [{"question": "Where do anemonefish lay their eggs?", "answer": ""}, {"question": "How many anemonefish are in a group?", "answer": "two", "ae_score": -0.7641522366231478, "qg_score": null}, {"question": "How many anemonefish are in a group?", "answer": "two", "ae_score": -0.7641522366231478, "qg_score": null}], "content": "In a group of anemonefish, there is a strict dominance hierarchy. The largest and most aggressive female is found at the top. Only two anemonefish, a male and a female, in a group reproduce through external fertilization. Anemonefish are sequential hermaphrodites, meaning that they develop into males first, and when they mature, they become females. If the female anemonefish is removed from the group, such as by death, one of the largest and most dominant males will become a female. The remaining males will move up a rank in the hierarchy.\nAnemonefish lay eggs on any flat surface close to their host anemones. In the wild, anemonefish spawn around the time of the full moon. Depending on the species, anemonefish can lay hundreds or thousands of eggs. The male parent guards the eggs until they hatch about six to ten days later, typically two hours after dusk.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Reproduction", "sub_heading": "Reproduction", "_id": "27--3---1---1", "title": "Anemonefish \u2014 Anemones"}
{"qas": [{"question": "Why are male anemonefish so much more successful than females?", "answer": ""}, {"question": "Which type of fish is the caretaker of eggs?", "answer": "male anemonefish", "ae_score": -0.7642271625289181, "qg_score": null}, {"question": "Which type of fish is the caretaker of eggs?", "answer": "male anemonefish", "ae_score": -0.7642271625289181, "qg_score": null}], "content": "Most anemonefish are protandrous hermaphrodites, meaning they alternate between the male and female sexes at some point in their lives.  Anemonefish colonies usually consist of the reproductive male and female and a few juveniles, who help tend the colony. Although multiple males co-habit an environment with a single female, polygamy does not occur and only the adult pair exhibit reproductive behavior.  However, if the largest female dies, the social hierarchy shifts with the breeding male exhibiting protandrous sex reversal to become the breeding female.  The largest juvenile will then become the new breeding male after a period of rapid growth. The existence of protandry in anemonefish may rest on the case that non-breeders modulate their phenotype in a way that causes breeders to tolerate them.  This strategy prevents conflict by reducing competition between the males for one female.  For example, by purposefully modifying their growth rate to remain small and submissive, the juveniles in a colony present no threat to the fitness of the adult male, thereby protecting themselves from being evicted by the dominant fish.\nThe reproductive cycle of anemonefish is often correlated with the lunar cycle.  Rates of spawning for anemonefish peak at approximately the first and third quarters of the moon.  The timing of this spawn means that the eggs will hatch around the full moon or new moon periods.  One explanation for this lunar clock is that spring tides produce the highest tides during full or new moons.  Nocturnal hatching during high tide may reduce predation by allowing for a greater capacity for escape.  Namely, the stronger currents and greater water volume during high tide protects the hatchlings by effectively sweeping them to safety.  Before spawning, anemonefish exhibit increased rates of anemone and substrate biting, which help prepare and clean the nest for the spawn.\nIn terms of parental care, male anemonefish are often the caretakers of eggs.  Before making the clutch, the parents often clear an oval sized clutch varying in diameter for the spawn.  Fecundity, or reproductive rate, of the females usually ranges from 600 to 1500 eggs depending on the size of the female.  In contrast to most animal species, the female only occasionally takes responsibility for the eggs, with males expending most of the time and effort.  Male anemonefish care for their eggs by fanning and guarding them for 6 to 10 days until they hatch.  Studies have shown that, in general, eggs develop more rapidly in a clutch when males fan properly and that fanning represents a crucial mechanism of successfully developing eggs.   This suggests that males have the ability to control the success of hatching an egg clutch by investing different amounts of time and energy towards the eggs.  For example, a male could choose to fan less in times of scarcity or fan more in times of abundance.  Furthermore, males display increased alertness when guarding more valuable broods, or eggs in which paternity was guaranteed.  Females, on the other hand, display generally less preference for parental behavior than males.  All these suggest that males have increased parental investment towards the eggs compared to females.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Parental investment", "sub_heading": "Parental investment", "_id": "27--4---1---1", "title": "The Evolution of Anemonefish: The Evolution of Protandry"}
{"qas": [{"question": "How do sea anemonefish survive in aquariums?", "answer": ""}, {"question": "What percentage of marine ornamentals are anemonefish?", "answer": "43%", "ae_score": -0.3071402111947253, "qg_score": null}, {"question": "What percentage of marine ornamentals are anemonefish?", "answer": "43%", "ae_score": -0.3071402111947253, "qg_score": null}], "content": "Anemonefish make up 43% of the global marine ornamental trade, and 25% of the global trade comes from fish bred in captivity, while the majority are captured from the wild,  accounting for decreased densities in exploited areas.  Public aquaria and captive breeding programs are essential to sustain their trade as marine ornamentals, and has recently become economically feasible. It is one of a handful of marine ornamentals whose complete life cycle has been closed in captivity. Members of some anemonefish species, such as the maroon clownfish, become aggressive in captivity; others, like the false percula clownfish, can be kept successfully with other individuals of the same species.\nWhen a sea anemone is not available in an aquarium, the anemonefish may settle in some varieties of soft corals, or large polyp stony corals. Once an anemone or coral has been adopted, the anemonefish will defend it. As there is less pressure to forage for food in an aquarium, it is common for anemonefish to remain within 2-4 inches of their host for their entire lifetime. Anemonefish, however, are not obligately tied to hosts, and can survive alone in captivity.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "In the aquarium", "sub_heading": "In the aquarium", "_id": "27--5---1---1", "title": "Anemonefish in Captivity"}
{"qas": [{"question": "Why are there so many different species of anemonefish?", "answer": ""}, {"question": "What is the key innovation that allowed anemonefish to radiate rapidly?", "answer": "obligate mutualism", "ae_score": -0.12925514161349458, "qg_score": null}, {"question": "What is the key innovation that allowed anemonefish to radiate rapidly?", "answer": "obligate mutualism", "ae_score": -0.12925514161349458, "qg_score": null}], "content": "Historically anemonefish have been identified by morphological features, color pattern in the field, while in a laboratory other features such as scalation of the head, tooth shape and body proportions. These features have been used to group species into 6 complexes, clownfish, tomato, skunk, clarkii, saddleback and maroon.  As can been seen from the gallery, each of the fish in these complexes have a similar appearance. Genetic analysis has shown that these complexes are not monophyletic groups, particularly the 11 species in the clarkii group, where only ''A. clarkii'' and ''A. tricintus'' are in the same clade, with six species,''A. allardi'' ''A. bicinctus'' ''A. chagosensis'' ''A. chrosgaster'' ''A. fuscocaudatus'' ''A. latifasciatus'' and ''A. omanensis'' being in an Indian clade, ''A. chrysopterus'' having monospecific lineage, and ''A. akindynos'' in the Australian clade with ''A. mccullochi''.  Other significant differences are that ''A. latezonatus'' also has monospecific lineage, and ''A. nigripes'' is in the Indian clade rather than with akallopisos, the skunk anemonefish.  ''A. latezonatus'' is more closely related to ''A. percula'' and ''Premnas biaculeatus'' that to the saddleback fish it was previously grouped with.\nIt is thought that obligate mutualism was the key innovation that allowed anemonefish to radiate rapidly, with rapid and convergent morhological changes that were correlated with the ecological niches offered by the host anemones. The complexity of mitochondrial DNA structure shown by genetic analysis of the Australian clade suggested evolutionary connectivity among samples of ''A. akindynos'' and ''A. mccullochi'' that the authors theorize was the result of historical hybridization and introgression in the evolutionary past.  There were two evolutionary groups with individuals of both species detected in both, thus the species lacked reciprocal monophyly.  There were no shared haplotypes between species.", "page_name": "Amphiprioninae", "page_id": "Amphiprioninae", "heading": "Taxonomy", "sub_heading": "Taxonomy", "_id": "27--6---1---1", "title": "The Evolution of Anemonefish"}
{"qas": [{"question": "Where did the word \"halva\" come from?", "answer": ""}, {"question": "When did the word halva come to english?", "answer": "between 1840 and 1850", "ae_score": null, "qg_score": null}, {"question": "When did the word halva come to english?", "answer": "between 1840 and 1850", "ae_score": null, "qg_score": null}], "content": "The word ''halva'' entered the English language between 1840 and 1850 from the Yiddish ''halva'', which came from the Turkish ''helva'', itself ultimately derived from the \u062d\u0644\u0648\u0649 ''\u1e25alw\u00e1'', a sweet confection. The Arabic root \u062d\u0644\u0648 ''\u1e25elw'' means \"sweet\".", "page_name": "Halva", "page_id": "Halva", "heading": "Etymology", "sub_heading": "Etymology", "_id": "28--0---1---1", "title": "Halva | Etymology"}
{"qas": [{"question": "Why is there so much coconut milk in Zanzibar?", "answer": ""}, {"question": "What is the name of the rice flour in zanzibar?", "answer": "halva", "ae_score": -0.09075129237625154, "qg_score": null}, {"question": "What is the name of the rice flour in zanzibar?", "answer": "halva", "ae_score": -0.09075129237625154, "qg_score": null}], "content": "This type of halva is made by frying flour (such as semolina) in oil, mixing it into a roux, and then cooking it with a sugary syrup. This variety is popular in India, Greece, Armenia, Iran, Azerbaijan,  Turkey, Somalia, Pakistan and Afghanistan. \nThis variety of halva is produced and served in India, Afghanistan, Nepal, Bangladesh, Pakistan, and surrounding countries (different versions of it are also found in Albania, Azerbaijan, Bulgaria, Cyprus, Greece, Montenegro, Macedonia and Turkey). It is usually made with wheat semolina, sugar or honey, and butter or vegetable oil. Raisins, dates, other dried fruits, or nuts such as almonds or walnuts, are often added to semolina halva. The halva is very sweet, with a gelatinous texture similar to polenta; the added butter gives it a rich mouthfeel. The standard proportions of semolina halva are one part fat (a vegetable oil or butter), two parts semolina, two parts sweetening agent (e.g. sugar or honey) and four parts water. The semolina is saut\u00e9ed in the fat while a syrup is being made of the sweetener and water. Then the two are mixed carefully while hot, and any extra ingredients are added. At this point, the halva is off-white to light beige, and rather soft. Depending on recipe and taste, it can be cooked a bit further, which makes it darker and firmer, or left to settle as is.\nIn India, halva is prepared in different forms. The recipes use flour, melted butter or ghee, sugar and optionally goondh (gum arabic, also known as Dinka or Goond or Katira Goond or Gond or Kamarka). It comes in various colors like orange, brown, green and cream with a translucent appearance studded with raisins, cashew nuts, pistachios, almonds, etc. Technically the term halva is used in native recipes throughout India, and though semolina halva is considered to be essentially a \"Northern\" confection, it is also quite popular in South India. A prominent South Indian version of halva (or ''alvaa'' in Tamil) is from Tirunelveli, a city in the state of Tamil Nadu. The first branded Tirunelveli Halwa under the brand name of Tirunelveli Melting Halwas was introduced by Melting Foods India (MFI), a sweet manufacturing firm from Tirunelveli, which has achieved the remarkable shelf life of 30 days naturally. Another semolina preparation widely enjoyed throughout South India called ''kesari'' or ''kesari-bath'' originates from the state of Karnataka.\nAlternative vegetable-based halva recipes popular in India and Pakistan use beetroots, potato, yam, and most commonly carrots (for ''gajar halwa''), mung beans (for ''moong dal halwa'') or bottle gourds (for ''doodi halwa'') instead of semolina. Prepared with condensed milk and ghee, without semolina to bind it together, the end result has a moist, yet flaky, texture when freshly prepared. Other examples include the famous Agra Petha easily available at Taj Mahal, Agra.\nCornstarch halva is popular in Greece, and has many variations. The ''Farsala'' recipe is the most well known. It is quite sweet, with caramel-like syrup.\nThis rice flour and coconut milk halva is common fare on the streets of Zanzibar.", "page_name": "Halva", "page_id": "Halva", "heading": "Types", "sub_heading": "Types", "_id": "28--1--0---1", "title": "Halva | Types"}
{"qas": [{"question": "Why are pistachio nuts so much more expensive than regular nuts?", "answer": ""}, {"question": "Halva is made from which type of seeds?", "answer": "sunflower seeds", "ae_score": -0.22972867932864438, "qg_score": null}, {"question": "Halva is made from which type of seeds?", "answer": "sunflower seeds", "ae_score": -0.22972867932864438, "qg_score": null}], "content": "This type of halva is made by grinding oily seeds, such as sesame or sunflower seeds, to a paste, and then mixing with hot sugar syrup cooked to hard-crack stage. This type is popular in eastern Arab nations, the Mediterranean, and in Balkan regions and countries. Some include Bosnia and Herzegovina, Croatia, Romania, Serbia, Macedonia, Montenegro, Bulgaria, Russia, Greece and Cyprus, Egypt, Iraq, Iran, the Levant, Macedonia, Albania, Central Asia, southern India, the Caucasus region and Turkey. It is also popular in Algeria and on the central Mediterranean islands of Malta.\nSesame halva is popular in the Balkans, Poland, Middle East, and other areas surrounding the Mediterranean Sea. The primary ingredients in this confection are sesame butter or paste (tahini), and sugar, glucose or honey. Soapwort (called ''\u2018erq al halaweh'' in Arabic; ''\u00e7\u00f6ven'' in Turkish), egg white, or marshmallow root are added in some recipes to stabilize the oils in the mixture or create a distinctive texture for the resulting confection. A version of sesame halva, called sesame crisp candy (\u829d\u9ebb\u9165\u7cd6) in China uses ground sesame and sugar, cooked to the hard ball stage because it is made crispier than other halvas.\nOther ingredients and flavourings, such as pistachio nuts, cocoa powder, orange juice, vanilla or chocolate, are often added to the basic tahini and sugar base.\nSunflower halva is popular in countries in Eastern Europe, including Belarus, Bulgaria, Romania, Moldova, Latvia, Lithuania, Estonia, Russia and Ukraine. It is made of sunflower seeds instead of sesame.", "page_name": "Halva", "page_id": "Halva", "heading": "Types", "sub_heading": "Nut butter\u2013based", "_id": "28--1--1---1", "title": "Sesame Halva ()     "}
{"qas": [{"question": "What is Halva?", "answer": ""}, {"question": "What type of flour is used for halva?", "answer": "Wheat flour", "ae_score": -0.5955615455112536, "qg_score": null}, {"question": "What type of flour is used for halva?", "answer": "Wheat flour", "ae_score": -0.5955615455112536, "qg_score": null}], "content": "Halva, ''hallv\u00eb'' in Albanian, is usually eaten as a dessert-based meal, that is, with no entrees or appetizers consumed prior. The majority of halva in Albania is flour halva, although home-cooked semolina halva and shop-produced sesame halva are also consumed. Wheat flour is usually used, although corn flour halva is also common.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Cultural use", "_id": "28--2--0---1", "title": "''Halva'' in Albanian"}
{"qas": [{"question": "Why is peanut butter so popular in Argentina?", "answer": ""}, {"question": "What is the origin of halva confectioners?", "answer": "Armenian", "ae_score": null, "qg_score": null}, {"question": "What is the origin of halva confectioners?", "answer": "Armenian", "ae_score": null, "qg_score": null}], "content": "Halva is available in Argentina, especially from confectioners of Syrian-Lebanese or Armenian origin. In the 1940s, a halva substitute named ''Mantecol'' made with peanut butter was introduced by R\u00edo Segundo's Georgalos, a Greek immigrant family firm. It became a popular product; in 2001, the brand was sold to global firm Cadbury Schweppes, which altered the recipe. Georgalos now manufactures the original product under the name ''Nucrem''. Both versions are available in candy stores and supermarkets. It is also popular by the Indians and Indo-Caribbeans who brought their form of halva.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Argentina", "_id": "28--2--1---1", "title": "Halva is a popular substitute for peanut butter in Argentina"}
{"qas": [{"question": "What is the difference between halva and regular sweet?", "answer": ""}, {"question": "What is halva made from in bahrain?", "answer": "sesame paste", "ae_score": -0.2006674157833998, "qg_score": null}, {"question": "What is halva made from in bahrain?", "answer": "sesame paste", "ae_score": -0.2006674157833998, "qg_score": null}], "content": "In Bahrain, the most popular form of halva is a jelly-styled sweet also known as ''halwa Bahraini'' in neighboring countries. And it is not like the halva that in most countries is based on sesame paste and in Kuwait called rahash.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Bahrain", "_id": "28--2--2---1", "title": "''Halva Bahraini'' is a Jelly-Styled Sweet"}
{"qas": [{"question": "Halwa?", "answer": ""}, {"question": "Halua is eaten in which state of india?", "answer": "West Bengal", "ae_score": null, "qg_score": null}, {"question": "Halua is eaten in which state of india?", "answer": "West Bengal", "ae_score": null, "qg_score": null}], "content": "Various kinds of ''halwa'' (\u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be) are prepared across Bangladesh and West Bengal. Some of the most common types of ''halua'' include semolina (\u09b8\u09c1\u099c\u09bf\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''shujir halua''), carrot (\u0997\u09be\u099c\u09b0\u09c7\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''gajorer halua''), chickpea (\u09ac\u09c1\u099f\u09c7\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''bu\u1e6der halua''), flour (\u09a8\u09c7\u09b6\u09c7\u09b8\u09cd\u09a4\u09be\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''neshestar halua'') almond (\u09ac\u09be\u09a6\u09be\u09ae\u09c7\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''badamer halua''), and papaya (\u09aa\u09c7\u0981\u09aa\u09c7\u09b0 \u09b9\u09be\u09b2\u09c1\u09af\u09bc\u09be ''p\u1ebdper halua''). ''Halua'' is usually eaten as a rich dessert, but it is not uncommon for Bangladeshis to eat it for breakfast with traditional breads, such as puris (\u09aa\u09c1\u09b0\u09bf ''puri'') or parathas (\u09aa\u09b0\u09cb\u099f\u09be ''p\u00f4ro\u1e6da'').", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Bangladesh", "_id": "28--2--3---1", "title": "''Halua'' () in Bangladesh"}
{"qas": [{"question": "What is the difference between plain and chocolate tahini halva?", "answer": ""}, {"question": "Where is halva made in the world?", "answer": "Brazil", "ae_score": -0.2693648000278896, "qg_score": null}, {"question": "Where is halva made in the world?", "answer": "Brazil", "ae_score": -0.2693648000278896, "qg_score": null}], "content": "In Brazil, which is home to the largest Syrian-Lebanese population outside the Middle East, plain and chocolate tahini halva can be found in cans in some supermarkets, while fancy varieties are sold in specialized food shops.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Brazil", "_id": "28--2--5---1", "title": "Tahini halva is a popular snack in Brazil"}
{"qas": [{"question": "Why is it that in some countries, halvos are flavoured with Good King Henry?", "answer": ""}, {"question": "What is the name of the dessert made from sunflower seed tahini?", "answer": "Tahini halva", "ae_score": -0.5915012048123791, "qg_score": null}, {"question": "What is the name of the dessert made from sunflower seed tahini?", "answer": "Tahini halva", "ae_score": -0.5915012048123791, "qg_score": null}], "content": "In Bulgaria, the term halva (\u0445\u0430\u043b\u0432\u0430) is used for several varieties of the dessert. Tahini halva (\u0442\u0430\u0445\u0430\u043d \u0445\u0430\u043b\u0432\u0430) is most popular and can be found in all food stores. Two different types of tahini halva are made \u2013 one using sunflower seed tahini and another using sesame seed tahini. Traditionally, the regions of Yablanitsa and Haskovo are famous for their halva. Semolina halva (\u0433\u0440\u0438\u0441 \u0445\u0430\u043b\u0432\u0430) is made at home and can be found only in some pastry stores. White halva (\u0431\u044f\u043b\u0430 \u0445\u0430\u043b\u0432\u0430), which is made of sugar, is popular on the last Sunday before Lent (Sirni Zagovezni; \u0421\u0438\u0440\u043d\u0438 \u0437\u0430\u0433\u043e\u0432\u0435\u0437\u043d\u0438), celebrated with customs, in one of which a string is tied to a piece of white halva and all the children, while standing in a circle must catch the turning piece of halva using only their mouths.\nAlmost all types of halva in Bulgaria are flavoured with essence of Good King Henry (\u0447\u0443\u0432\u0435\u043d).", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Bulgaria", "_id": "28--2--6---1", "title": "\u0430\u043b\u0432\u0430 \u0430\u043b\u0432\u0430 \u0430\u043b\u0432\u0430 \u0430\u043b\u0432\u0430 \u0430\u043b"}
{"qas": [{"question": "Why is Halva so popular in Croatia?", "answer": ""}, {"question": "What is the name of the sweet that is consumed in parts of croatia?", "answer": "Halva", "ae_score": -0.2542448401890752, "qg_score": null}, {"question": "What is the name of the sweet that is consumed in parts of croatia?", "answer": "Halva", "ae_score": -0.2542448401890752, "qg_score": null}], "content": "Halva is a sweet that is consumed in parts of Croatia. It is not uncommon to come across the specialty in the regions of Slavonia, Kordun, Lika and Baranja or regions that at one time came into contact with the Ottoman Empire. Halva is especially popular in Slavonia during ''kirvaj'' or local church fairs.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Croatia", "_id": "28--2--7---1", "title": "Halva is a sweet that is consumed in parts of Croatia"}
{"qas": [{"question": "Halawa Tehiniya?", "answer": ""}, {"question": "Halawa is a popular confection originating in which country?", "answer": "Egypt", "ae_score": null, "qg_score": null}, {"question": "Halawa is a popular confection originating in which country?", "answer": "Egypt", "ae_score": null, "qg_score": null}], "content": "''Halawa tehiniya'' (\u062d\u0644\u0627\u0648\u0629 \u0637\u062d\u064a\u0646\u064a\u0629, ) or usually simply ''halawa'' is a popular confection in Egypt that is relatively inexpensive (as of 2012, one kilogram (2.2 lb) can be bought for about EGP 20). It is sesame-based, and comes as plain, mixed with nuts (often pistachios), or mixed with chocolate. It can be enjoyed alone, or with ''baladi'' (lit. \"rural/rustic\") whole-wheat round loaf or bread roll, and sometimes with the Arabic equivalent of clotted cream (\u0642\u0634\u0637\u0629, ''eshta'' ). Halawa is available as big blocks freshly cut according to weight (usually 1/4 or 1/2 kg), or pre-packaged in plastic containers or as snack bars. More recently, extra-sweet \"halawa spread\" has been introduced. Less common is the fine, fibrous ''halawa shaar'' (hair halawa) (\u062d\u0644\u0627\u0648\u0629 \u0634\u0639\u0631, ).", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Egypt", "_id": "28--2--8---1", "title": "''Halawa tehiniya'' (, "}
{"qas": [{"question": "What is the difference between semolina halva and sesame halva?", "answer": ""}, {"question": "What is the ratio of oil to sugar in halva?", "answer": "1:2:3:4", "ae_score": -0.605072327112473, "qg_score": null}, {"question": "What is the ratio of oil to sugar in halva?", "answer": "1:2:3:4", "ae_score": -0.605072327112473, "qg_score": null}], "content": "In Greece and Cyprus, the term halvas (\u03c7\u03b1\u03bb\u03b2\u03ac\u03c2) is used for both varieties of the dessert. Sesame halva was produced in classical times. The standard recipe for semolina halva is referred to as \"1:2:3:4\", as it calls for one unit of oil, two of semolina, three of sugar and four of water.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Greece and Cyprus", "_id": "28--2--9---1", "title": "Sesame Halva ()"}
{"qas": [{"question": "Why are there so many different types of halva in India?", "answer": ""}, {"question": "What is another name for halva in india?", "answer": "halva", "ae_score": -0.19046444537739926, "qg_score": null}, {"question": "What is another name for halva in india?", "answer": "halva", "ae_score": -0.19046444537739926, "qg_score": null}], "content": "India has many types of halva, some unique to particular regions of the country.\nVarious types of halva from India are distinguished by the region and the ingredients from which they are prepared. In northern India, the most famous include ''sooji '' (or ''suji'') ''halva'' (semolina), ''aate ka halva'' (wheat), ''moong dal ka halva'' (mung bean halva), ''gajar halva'' (carrot), ''dudhi halva'', ''chana daal halwa'' (chickpeas), and ''Satyanarayan halwa'' (variation of ''suji halwa'', with the addition of detectable traces of banana), and ''kaju halva'' (cashew nut). ''Kashi halva'', made from winter melon or ash gourd, is a famous and traditional sweet of Karnataka, and mainly makes a regular appearance in traditional Brahmin weddings. Sooji halwa is sold in many eateries in Karnataka as Kesari bhath, usually alongside pineapple.\nIn the Indian state of Kerala, halva is known as ''haluva'' or ''aluva''. It is one of the most commonly found or easily recognised sweets in bakeries throughout Kerala. Kozhikode (anglicized as Calicut) in Kerala, is famous for its unique and exotic haluva, which is popularly known as ''Kozhikodan Haluva''. Significant Arab and Middle Eastern influence in this region, through ancient trade routes via the Arabian Sea and through Arab traders who settled here, contributed to the evolution of Kozhikodan Haluva. Europeans used to call ''Kozhikodan Haluva'' 'sweet meat' due to its texture. A street in Calicut where ''Kozhikodan Haluvas'' were sold was named Sweet Meat Street (S.M. Street for short) during colonial rule. The street still carries that name and is called ''Mithai Theruvu'' which is the Malayalam for 'sweet street'. Kozhikodan haluva is mostly made from ''maida'' (highly refined wheat), and comes in various flavours, such as banana, ghee, coconut, cashew, date, tender coconut, pineapple, jackfruit, etc. However, ''karutha haluva'' (black haluva) made from rice is also very popular. Pure ''wheat haluva'' is also available now in some shops.\nIn the Indian state of Tamil Nadu, halva is known as ''halwa'' or ''alva''. Tirunelveli, in Tamil Nadu, is famous for its unique and exotic haluva, which is popularly known as ''Tirunelveli halva''. Significant for its taste, Tirunelveli alva is mostly made from ''maida'' (highly refined wheat).\nThe maker of halva is called a ''halwai''.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "India", "_id": "28--2--10---1", "title": "''Kozhikodan Haluva'' or ''al"}
{"qas": [{"question": "What is the difference between \"Honey Halva\" and \"Mazandaran\"?", "answer": ""}, {"question": "Halva paste is made from which vegetable?", "answer": "sesame", "ae_score": -0.842644324358956, "qg_score": null}, {"question": "Halva paste is made from which vegetable?", "answer": "sesame", "ae_score": -0.842644324358956, "qg_score": null}], "content": "''Halva Ardeh'' is the Iranian term for tahini-based halva, and may or may not include whole pistachios. ''Ardeh'' is processed sesame in the form of paste, usually sweetened with syrup.\nIn Iran, ''halva''(\u062d\u0644\u0648\u0627) usually refers to a related confection made from wheat flour and butter and flavored with rose water. The final product has a dark brown color. The halva is spread thin on a plate till it dries into a paste. Halva usually is served at funerals and other formal ceremonies, often with almonds or coconut shavings on the top.\nOne variation from the Caspian region of Gilan is called ''asali halva'' (honey halva) and Mazandaran is called ''Khoshk halva''. It is different from other types of halva prepared in Iran since it is based on rice flour rather than semolina, and is sweetened with honey instead of sugar. In Iran, halva is also eaten with lavash at breakfast.Iranian urbanites, especially in Tehran and Karaj, use melted chocolate and coffee to flavor the halva, which are black or dark brown in color, respectively. Confectionaries sell two-layered halva cut into diamond shapes and garnished with almond and pistachio slivers. These are often served in memorial services held in mosques or at the deceased person's grave.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Iran", "_id": "28--2--11---1", "title": "''Halva Ardeh'' is the Iranian term for ta"}
{"qas": [{"question": "Tahini Halvah?", "answer": ""}, {"question": "What is the name of the halvah in israel?", "answer": "Tahini halvah", "ae_score": -0.4240842705111037, "qg_score": null}, {"question": "What is the name of the halvah in israel?", "answer": "Tahini halvah", "ae_score": -0.4240842705111037, "qg_score": null}], "content": "Tahini halvah (\u05d7\u05dc\u05d1\u05d4) is very popular in Israel and among people of Jewish background all over the world. Spelled \"halvah\" in English, it usually comes in slabs or small packages, and is available in a wide variety of flavours, chocolate and vanilla being very common. The halvah is almost always parve. Israeli halvah will usually not contain wheat flour or semolina, but will contain sesame tahini, glucose, sugar, vanilla and saponaria root extracts (soapwort), which are not usually found in other recipes.  It is often served as a breakfast component at Israeli hotels, though it is not usually part of an Israeli breakfast, and it is even used in specialty ice-cream.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Israel", "_id": "28--2--12---1", "title": "Tahini halvah () is very popular in Israel, and among people"}
{"qas": [{"question": "What is halawa?", "answer": ""}, {"question": "Where does halawa cheese come from in the world?", "answer": "Lebanon", "ae_score": -0.6602533588906886, "qg_score": null}, {"question": "Where does halawa cheese come from in the world?", "answer": "Lebanon", "ae_score": -0.6602533588906886, "qg_score": null}], "content": "In the region of the Levant, which includes Israel, Lebanon, Syria, Iraq, Jordan, and Palestine, halawa (\u062d\u0644\u0627\u0648\u0629) is typically the sesame or tahini-based form, which can be flavoured in various ways, and may include pistachios, almonds or chocolate. A large quantity of halawa is exported from Lebanon throughout the world.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Lebanon, Syria, Iraq, Jordan, and Palestine", "_id": "28--2--13---1", "title": "Halawa () is a halawa-based tahini-"}
{"qas": [{"question": "What is Alva?", "answer": ""}, {"question": "Which type of sunflower is used to make alva?", "answer": "tahini", "ae_score": -0.9912710381102922, "qg_score": null}, {"question": "Which type of sunflower is used to make alva?", "answer": "tahini", "ae_score": -0.9912710381102922, "qg_score": null}], "content": "In Republic of Macedonia, ALVA (\u0430\u043b\u0432\u0430, ''alva'') refers to a sweet which comes in a few varieties. Alva made from tahini (sesame or sunflower) (\u0422\u0430\u0430\u043d \u0430\u043b\u0432\u0430) is most used in Macedonia. Most popular is the alva from Negotino and Super Alva from Skopje. Alva from semolina (\u0430\u043b\u0432\u0430 \u043e\u0434 \u0433\u0440\u0438\u0437) is made only at home. Izmirska halva (\u0418\u0437\u043c\u0438\u0440\u0441\u043a\u0430 \u0430\u043b\u0432\u0430) brought back from Izmir Turkey, of which large areas are populated by Macedonians, is a chocolate type of alva made from flour, cocoa, sugar and peanuts. This alva is also made at home. Alva is also popular in the City of Prilep and surrounds, which have been famous for food production since pre-Ottoman times.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Republic of Macedonia", "_id": "28--2--16---1", "title": "Alva (\u0430\u043b\u0432\u0430, ''alva'') is a sweet that"}
{"qas": [{"question": "What is Turk's sweet?", "answer": ""}, {"question": "What are the ingredients of halva in malta?", "answer": "pistachios or almonds", "ae_score": -0.6765261365534817, "qg_score": null}, {"question": "What are the ingredients of halva in malta?", "answer": "pistachios or almonds", "ae_score": -0.6765261365534817, "qg_score": null}], "content": "In Malta, the term ''\u0127elwa tal-Tork'' (''Turk's sweet'') is used to refer to a tahini-based block confection sometimes containing pistachios or almonds. It forms part of the Maltese cuisine, and is a common sweet snack on the islands, especially served at the end of wedding celebrations and during feasts.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Malta", "_id": "28--2--17---1", "title": "''elwa tal-Tork'' is a"}
{"qas": [{"question": "Why are poppy seeds so popular in Myanmar?", "answer": ""}, {"question": "What colour are poppy seeds in burma?", "answer": "brown", "ae_score": -0.5552793367551982, "qg_score": null}, {"question": "What colour are poppy seeds in burma?", "answer": "brown", "ae_score": -0.5552793367551982, "qg_score": null}], "content": "In Myanmar, it is called ''halawa'' (), and is associated with the port town of Pathein in the Ayeyarwady Region. Burmese ''halawa'' usually contains poppy seeds and is brown in colour. It is popular as a gift item.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Myanmar", "_id": "28--2--18---1", "title": "''Halawa'' (Burmese Poppy Seed)"}
{"qas": [{"question": "What is Halwa?", "answer": ""}, {"question": "Halwa is a traditional dish of which country?", "answer": "Oman", "ae_score": null, "qg_score": null}, {"question": "Halwa is a traditional dish of which country?", "answer": "Oman", "ae_score": null, "qg_score": null}], "content": "In Oman, local halwa is made from eggs, red and white sugar, corn flour and fat. The most popular Omani variations are made either with saffron and dried fruits, or with pureed dates. Halwa is a common delicacy served with Arabic coffee at festivals and special occasions.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Oman", "_id": "28--2--19---1", "title": "Halwa in Oman"}
{"qas": [{"question": "What is Halva in Pakistan?", "answer": ""}, {"question": "Halva is the traditional dish of which country?", "answer": "Pakistan", "ae_score": null, "qg_score": null}, {"question": "Halva is the traditional dish of which country?", "answer": "Pakistan", "ae_score": null, "qg_score": null}], "content": "Halva in Pakistan is similar to that in India, distinguished by the region and base ingredients. Most common are the ones made from semolina, ghee and sugar, garnished with dried fruits and nuts. Other types of halva replace semolina with certain vegetables (carrots, pumpkin, and bottle gourds being the most popular), lentils (particularly, chickpeas) or nuts (almonds, walnuts). Different regions have come to be associated with distinctive variations of the traditional halva: e.g. Sohan Halva from Southern Punjab, and Karachi halva from Karachi, Sindh.In Urdu, the word ''halva'' \u062d\u0644\u0648\u06c1 denotes a certain family of sweets of Persian origin and South Asian flair, and a p\u00e2tissier specializing in such sweets is called a ''Halvai'' \u062d\u0644\u0648\u0627\u0649.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Pakistan", "_id": "28--2--20---1", "title": "Halva | Cultural use | Pakistan"}
{"qas": [{"question": "What is Halva?", "answer": ""}, {"question": "What is the name of the sesame street product?", "answer": "Halva", "ae_score": -0.3947201615079532, "qg_score": null}, {"question": "What is the name of the sesame street product?", "answer": "Halva", "ae_score": -0.3947201615079532, "qg_score": null}], "content": "Halva (cha\u0142wa) in Poland is sesame-based. It is not usually made at home, but it is sold under various brands in the form of large or small bars, as well as boxed hard mass.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Poland", "_id": "28--2--21---1", "title": "Halva (chawa) in Poland is sesame-based. It is"}
{"qas": [{"question": "Halva de r\u0103s\u0103rit\u0103rii?", "answer": ""}, {"question": "What is the name of the sunflower-based block confection sometimes containing pistach?", "answer": "halva", "ae_score": -0.7784429574669331, "qg_score": null}, {"question": "What is the name of the sunflower-based block confection sometimes containing pistach?", "answer": "halva", "ae_score": -0.7784429574669331, "qg_score": null}], "content": "In Romania and Moldova, the term halva is used to refer to a sunflower-based block confection sometimes containing pistachios, almonds or chocolate. In the Republic of Moldova, it is mostly referred to as ''halva de r\u0103s\u0103rit\u0103''; in Romania, it is known as ''halva de floarea soarelui''.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Romania and Moldova", "_id": "28--2--22---1", "title": "Halva de r\u0103s\u0103rit\u0103 soarelui"}
{"qas": [{"question": "What is the difference between halva and semolina based sweets?", "answer": ""}, {"question": "What is the name of the sesame based halva sweet?", "answer": "tan alva''", "ae_score": null, "qg_score": null}, {"question": "What is the name of the sesame based halva sweet?", "answer": "tan alva''", "ae_score": null, "qg_score": null}], "content": "Halva, generally is called ''alva'' (''\u0410\u043b\u0432\u0430'') in Serbian, while semolina based is called ''\u0107etena alva'' (''\u045b\u0435\u0442\u0435\u043d \u0430\u043b\u0432\u0430'') and sesame based is called ''tan alva'' (''\u0442\u0430\u043d \u0430\u043b\u0432\u0430'') or ''tehen alva'' (''\u0442\u0435\u0445\u0435\u043d \u0430\u043b\u0432\u0430''). It is common to the whole region. ''Alva'' is a typical sweet in local church fairs around Serbia. Also, sesame-based halva imported from Greece or the Republic of Macedonia is common in Serbian supermarkets. In Serbia of the 2000s, halva is losing its popularity to other types of sweets and candies and more and more is becoming something of a luxury.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Serbia", "_id": "28--2--24---1", "title": "''Alva'' (''\u043b\u0432\u0430'') is "}
{"qas": [{"question": "What is halva and why is it so popular in Somalia?", "answer": ""}, {"question": "What is the name of halva in somalia?", "answer": "xalwo", "ae_score": -0.8087889418436937, "qg_score": null}, {"question": "What is the name of halva in somalia?", "answer": "xalwo", "ae_score": -0.8087889418436937, "qg_score": null}], "content": "In Somalia, halva is known as ''xalwo'' (halwo). A staple of Somali cuisine, it is a popular confection served during special occasions, such as Eid celebrations or wedding receptions. ''Xalwo'' is made from sugar, cornstarch, cardamom powder, nutmeg powder and ghee. Peanuts are sometimes added to enhance texture and flavor.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Somalia", "_id": "28--2--26---1", "title": "''Xalwo'' (halwo) is a sweet confection"}
{"qas": [{"question": "What is aluwa?", "answer": ""}, {"question": "Halva is a sweet made from rice flour and potato in which month of the year?", "answer": "April", "ae_score": -0.7461444101519337, "qg_score": null}, {"question": "Halva is a sweet made from rice flour and potato in which month of the year?", "answer": "April", "ae_score": -0.7461444101519337, "qg_score": null}], "content": "''Aluwa'' is a sweet made from rice flour or potato either with sugar (''seeni aluwa'') or treacle (''pani aluwa'') and often with cashew nuts. It is served during the Sinhalese New Year festival each April.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Sri Lanka", "_id": "28--2--27---1", "title": "''Aluwa'' is a sweet made from rice flour or"}
{"qas": [{"question": "What is the difference between soft sesame halva and sesame sesame?", "answer": ""}, {"question": "What kind of halva is made from sugar syrup?", "answer": "Soft sesame halva", "ae_score": -0.9521312631098946, "qg_score": null}, {"question": "What kind of halva is made from sugar syrup?", "answer": "Soft sesame halva", "ae_score": -0.9521312631098946, "qg_score": null}], "content": "Soft sesame halva is made from sugar syrup, egg whites, and sesame seeds. Solid sesame halva is made from pulled sugar, repeatedly stretched to give a white colour; prepared sesame is added to the warm sugar and formed on big trays. In Tajikistan, as well as in Uzbekistan, the local name is ''lavz'' (\u041b\u0430\u0432\u0437).", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Tajikistan and Uzbekistan", "_id": "28--2--28---1", "title": "Sesame Halva (\u0430\u0432) in Tajikistan."}
{"qas": [{"question": "What is a \"helva\" in Turkey?", "answer": ""}, {"question": "What is yaz helva made out of?", "answer": "almond or walnut", "ae_score": -0.8105974576748477, "qg_score": null}, {"question": "What is yaz helva made out of?", "answer": "almond or walnut", "ae_score": -0.8105974576748477, "qg_score": null}], "content": "The term ''helva'' is used by Turkish people, to describe ''tahin'' (crushed sesame seeds), flour, or semolina halva, called ''tahin helvas\u0131'', ''un helvas\u0131'', and ''irmik helvas\u0131'', respectively. ''Yaz helvas\u0131'' is made of almond or walnut. Semolina halva (garnished with pine nuts) has a cultural significance in Turkish folk religion and is the most common type. Traditionally, halva prepared with flour (''un helvas\u0131'') is cooked and served upon the death of a person. In addition, some sweets and desserts are also called helva, such as ''pamuk helva'' or ''koz helva'', a sweet-like dessert which is widespread in Turkey. In Safranbolu, ''koz helva'' is also called \"leaf-halva\". Assyrians also consume Turkish halva as a traditional dessert.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Turkey", "_id": "28--2--29---1", "title": "Halva | Cultural use | Turkey"}
{"qas": [{"question": "What is Halva?", "answer": ""}, {"question": "Is halva more or less sweet than other halvas?", "answer": "less sweet", "ae_score": -1.54460997699126, "qg_score": null}, {"question": "Is halva more or less sweet than other halvas?", "answer": "less sweet", "ae_score": -1.54460997699126, "qg_score": null}], "content": "Halva (\u0445\u0430\u043b\u0432\u0430) is made from a paste of ground sunflower seeds and sunflower oil, laid out in a sheet and cut into brick form; it tends to be less sweet than other halvas.  The sunflower is one of the symbols of Ukraine and sunflowers carry a very special meaning in Ukrainian culture, making halvah a popular snack.  Standard flavors include vanilla, raisin and chocolate.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "Ukraine", "_id": "28--2--30---1", "title": "Halva (\u0430\u043b\u0432\u0430) is a snack made from sunflower seeds and sunflower oil"}
{"qas": [{"question": "Why is Halva so popular in the US?", "answer": ""}, {"question": "Where is the halva store located in the united states?", "answer": "Brooklyn", "ae_score": -0.4904691334763811, "qg_score": null}, {"question": "Where is the halva store located in the united states?", "answer": "Brooklyn", "ae_score": -0.4904691334763811, "qg_score": null}], "content": "Halva can be found in ethnic Indian, Jewish, Argentine, and Middle Eastern community stores. Besides being imported from the Middle East or India (or ''Mantecol'' imported into Argentine stores), one can find the version manufactured in the U.S. by Joyva in Brooklyn. Greek Americans have also made this sweet popular, in Greek delis, supermarkets and homes.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural use", "sub_heading": "United States", "_id": "28--2--31---1", "title": "Halva is a Greek sweet that is popular in Greek restaurants, supermarkets, and homes"}
{"qas": [{"question": "Why is the phrase \"idea se kao halva\" used in so many different languages?", "answer": ""}, {"question": "What term is used in pakistan to refer to hypocritical religious people?", "answer": "Halva Molvi", "ae_score": -0.2815162195749826, "qg_score": null}, {"question": "What term is used in pakistan to refer to hypocritical religious people?", "answer": "Halva Molvi", "ae_score": -0.2815162195749826, "qg_score": null}], "content": "In Afghanistan, Turkey and Iran, after the burial ceremony, on the seventh and fortieth day following the death of a Muslim, and also on the first anniversary, semolina helva or flour helva is cooked and offered to visitors and neighbours by relatives of the deceased. For this reason, flour (''un'') helva is also called in Turkish ''\u00f6l\u00fc helvas\u0131'', meaning \"helva of the dead\". The expression ''roasting the helva of someone'' suggests the person referred to died some time ago.\nThe Greek saying ''Ante re halva!'' (\"\u0386\u03bd\u03c4\u03b5 \u03c1\u03b5 \u03c7\u03b1\u03bb\u03b2\u03ac!\" \u2013 could be translated as \"get lost, halva\") is used when the speaker wants to offend someone, usually a man, by calling him a coward and/or chubby. Another saying, dating from the period of Ottoman domination, states \"\u03a1\u03c9\u03bc\u03b1\u03af\u03b9\u03ba\u03bf\u03c2 \u03ba\u03b1\u03b2\u03b3\u03ac\u03c2, \u03c4\u03bf\u03cd\u03c1\u03ba\u03b9\u03ba\u03bf\u03c2 \u03c7\u03b1\u03bb\u03b2\u03ac\u03c2\" (roughly translated as \"A fight among Greeks is halva to Turks\").\nIn Egypt, it is believed, as it has often been portrayed in literature and media, within the incarcerated community, halawa is a prized item commonly offered to inmates by visiting family members. This has led to the exploitation of this cultural phenomenon by a local halawa manufacturer in a recent advertising campaign.\nIn Bosnia and Herzegovina (and also, to a lesser extent, Croatia, Slovenia (Styrian part of the country) and Serbia), the phrase \"''ide / prodaje se kao halva''\" or Styrian dialect of Slovene \"''re ko' alva''\" (\"sells like halva\") is a colloquial expression denoting a product's sales are very high, similar to the English expression \"sells like hotcakes\" or the German expression \"''verkauft sich wie warme Semmeln''\" (\"sells like hot bread rolls\").\nIn regions of India where Hindi is a spoken language, \"Halwa hai kya?\" which literally translates to \"(Do you think) it is halwa?\" is a snide rhetorical question used to indicate to another person that he or she is about to do or ask for something that's far less trivial than he or she possibly comprehends. \"Halwa puri khana\" (to eat puri with halwa) is an idiom for a celebration (of possibly modest means). \"Lay halwa\" is a Bengali interjection expressing exasperation or unpleasant surprise.\nIn Pakistan, the term Halva Molvi is used to refer to religious people who are hypocritical and indulge in lavish life-styles.\nRecurring references to halvah have been made in ''Mad'' magazine over the years.\nAllan Sherman's song \"The Streets of Miami\", a Jewish-centered parody of \"The Streets of Laredo\" contains the line, \"I shot and Sam crumbled / Just like a piece halvah...\"\nA minor planet, 518 Halawe, is named after halva.", "page_name": "Halva", "page_id": "Halva", "heading": "Cultural references", "sub_heading": "Cultural references", "_id": "28--3---1---1", "title": "Halva | Cultural references"}
{"qas": [{"question": "How is it that we are able to detect diseases like Ebola so quickly?", "answer": ""}, {"question": "How long does it take for legionella bacteria to show up?", "answer": "up to 10 days", "ae_score": -0.4675895264327358, "qg_score": null}, {"question": "How long does it take for legionella bacteria to show up?", "answer": "up to 10 days", "ae_score": -0.4675895264327358, "qg_score": null}], "content": "''Legionella'' is traditionally detected by culture on buffered charcoal yeast extract (BCYE) agar. ''Legionella'' requires the presence of cysteine and iron to grow, so does not grow on common blood agar media used for laboratory-based total viable counts or on-site dipslides. Common laboratory procedures for the detection of ''Legionella'' in water concentrate the bacteria (by centrifugation and/or filtration through 0.2-\u03bcm filters) before inoculation onto a charcoal yeast extract agar containing antibiotics (e.g. glycine, vancomycin, polymixin, cyclohexamide, GVPC) to suppress other flora in the sample. Heat or acid treatment are also used to reduce interference from other microbes in the sample.\nAfter incubation for up to 10 days, suspect colonies are confirmed as ''Legionella'' if they grow on BCYE containing cysteine, but not on agar without cysteine added.  Immunological techniques are then commonly used to establish the species and/or serogroups of bacteria present in the sample.\nAlthough the plating method is quite specific for most species of ''Legionella'', one study has shown that a coculture method that accounts for the close relationship with amoebae may be more sensitive since it can detect the presence of the bacteria even when masked by its presence inside the amoeba. Consequently, the true clinical and environmental prevalence of the bacteria is likely to be underestimated due to false negatives inherent in the current lab methodology.\nMany hospitals use the ''Legionella'' urinary antigen test for initial detection when ''Legionella'' pneumonia is suspected. Some of the advantages offered by this test are that the results can be obtained in a matter of hours rather than the five days required for culture, and that a urine specimen is generally more easily obtained than a sputum specimen. Disadvantages are that the urine antigen test only detects antigen of ''Legionella pneumophila'' serogroup 1 (LP1); only a culture will detect infection by non-LP1 strains or other ''Legionella'' species and that isolates of ''Legionella'' are not obtained, which impairs public health investigations of outbreaks of LD.\nNew techniques for the rapid detection of ''Legionella'' in water samples are emerging, including the use of polymerase chain reaction and rapid immunological assays. These technologies can typically provide much faster results.\nGovernment public health surveillance has demonstrated increasing proportions of drinking water\u2013associated outbreaks specifically in healthcare settings.", "page_name": "Legionella", "page_id": "Legionella", "heading": "Detection", "sub_heading": "Detection", "_id": "29--0---1---1", "title": "Detection of ''Legionella'' in Water Samples"}
{"qas": [{"question": "Where did the coldest water come from?", "answer": ""}, {"question": "Where does legionella come from in the world?", "answer": "industrial coolant", "ae_score": -1.6806474950359882, "qg_score": null}, {"question": "Where does legionella come from in the world?", "answer": "industrial coolant", "ae_score": -1.6806474950359882, "qg_score": null}], "content": "Documented sources include cooling towers, swimming pools (especially in Scandinavian countries), domestic water systems and showers, ice-making machines, refrigerated cabinets, whirlpool spas, hot springs, fountains, dental equipment, Soil, automobile windshield washer fluid, and industrial coolant.", "page_name": "Legionella", "page_id": "Legionella", "heading": "Pathogenesis", "sub_heading": "Pathogenesis", "_id": "29--1--0---1", "title": "Cooling Towers, Swimming Pools, Whirlpool Spas, Hot Springs"}
{"qas": [{"question": "How far can you travel from the source of a disease?", "answer": ""}, {"question": "Where is legionella found in air conditioning?", "answer": "cooling towers", "ae_score": -0.6575097763982036, "qg_score": null}, {"question": "Where is legionella found in air conditioning?", "answer": "cooling towers", "ae_score": -0.6575097763982036, "qg_score": null}], "content": "The largest and most common source of Legionnaires' disease outbreaks are cooling towers (heat rejection equipment used in air conditioning and industrial cooling water systems) primarily because of the risk for widespread circulation. Many governmental agencies, cooling tower manufacturers, and industrial trade organisations have developed design and maintenance guidelines for controlling the growth and proliferation of ''Legionella'' within cooling towers.\nRecent research in the ''Journal of Infectious Diseases'' provides evidence that ''L. pneumophila'', the causative agent of Legionnaires' disease, can travel at least 6 km from its source by airborne spread. It was previously believed that transmission of the bacterium was restricted to much shorter distances. A team of French scientists reviewed the details of an epidemic of Legionnaires' disease that took place in Pas-de-Calais, northern France, in 2003\u20132004. Of 86 confirmed cases during the outbreak, 18 resulted in death. The source of infection was identified as a cooling tower in a petrochemical plant, and an analysis of those affected in the outbreak revealed that some infected people lived as far as 6\u20137 km from the plant.", "page_name": "Legionella", "page_id": "Legionella", "heading": "Pathogenesis", "sub_heading": "Airborne transmission from cooling towers", "_id": "29--1--1---1", "title": "Legionnaires' disease can travel at least 6 km from its source by airborne spread"}
{"qas": [{"question": "Why is there no vaccine for legionellosis?", "answer": ""}, {"question": "Where can you get a vaccine for legionella?", "answer": "US", "ae_score": null, "qg_score": null}, {"question": "Where can you get a vaccine for legionella?", "answer": "US", "ae_score": null, "qg_score": null}], "content": "No vaccine is available for legionellosis, and antibiotic prophylaxis is not effective. Any licensed vaccine for humans in the US is most probably still many years away. Vaccination studies using heat-killed or acetone-killed cells have been carried out, and guinea pigs were challenged intraperitoneally or by using the aerosol model of infection. Both vaccines were shown to give moderately high levels of protection. Protection was found to be dose-dependent and correlated with antibody levels as measured by enzyme-linked immunosorbent assay to an outer membrane antigen and by indirect immunofluorescence to heat-killed cells.", "page_name": "Legionella", "page_id": "Legionella", "heading": "Pathogenesis", "sub_heading": "Vaccine research", "_id": "29--1--2---1", "title": "Legionellosis Vaccination Study"}
{"qas": [{"question": "How does chlorination work?", "answer": ""}, {"question": "What is the most effective treatment for legionella bacteria?", "answer": "chlorine", "ae_score": -0.2205557354366372, "qg_score": null}, {"question": "What is the most effective treatment for legionella bacteria?", "answer": "chlorine", "ae_score": -0.2205557354366372, "qg_score": null}], "content": "A very effective chemical treatment is chlorine. For systems with marginal issues, chlorine  provides effective results at 0.5 ppm residual in the hot water system. For systems with significant ''Legionella'' problems, temporary shock chlorination\u2014where levels are raised to higher than 2 ppm for a period of 24 hours or more and then returned to 0.5 ppm may be effective. Hyperchlorination can also be used where the water system is taken out of service and the chlorine residual is raised to 50 ppm or higher at all distal points for 24 hours or more. The system is then flushed and returned to 0.5 ppm chlorine prior to being placed back into service. These high levels of chlorine penetrate biofilm, killing both the ''Legionella'' bacteria and the host organisms. Annual hyperchlorination can be an effective part of a comprehensive ''Legionella'' preventive action plan.", "page_name": "Legionella", "page_id": "Legionella", "heading": "''Legionella'' control", "sub_heading": "''Legionella'' control", "_id": "29--3--0---1", "title": "''Legionella'' Preventative Action Plan"}
{"qas": [{"question": "Why can't we use CuAg to disinfect our drinking water?", "answer": ""}, {"question": "What is the name of the process used to control legionella?", "answer": "CuAg ionization", "ae_score": -0.7324035776668592, "qg_score": null}, {"question": "What is the name of the process used to control legionella?", "answer": "CuAg ionization", "ae_score": -0.7324035776668592, "qg_score": null}], "content": "Industrial-size copper-silver ionization is recognized by the U.S. Environmental Protection Agency and WHO for ''Legionella'' control and prevention. Copper and silver ion concentrations must be maintained at optimal levels, taking into account both water flow and overall water usage, to control ''Legionella''. The disinfection function within all of a facility's water distribution network occurs within 30 to 45 days. Key engineering features such as 10 amps per ion chamber cell and automated variable voltage outputs having no less than 100 VDC are but a few of the required features for proper ''Legionella'' control and prevention, using a specific, nonreferenced CuAg system. Swimming pool ion generators are not designed for potable water treatment.\nQuestions remain whether the silver and copper ion concentrations required for effective control of symbiotic hosts could exceed those allowed under the U.S. Safe Drinking Water Act's Lead and Copper Rule. In any case, any facility or public water system using CuAg for disinfection should monitor its copper and silver ion concentrations to ensure they are within intended levels \u2013 both minimum and maximum. Further, no current standards for silver in the EU and other regions allow use of this technology.\nCuAg ionization is an effective process to control ''Legionella'' in potable water distribution systems found in health facilities, hotels, nursing homes, and most large buildings. CuAg is not intended for cooling towers because of pH levels over 8.6 that cause ionic copper to precipitate. In 2003, researchers who heavily support ionization developed a validation process that supports their research on ionization. Ionization became the first such hospital disinfection process to have fulfilled a proposed four-step modality evaluation; by then it had been adopted by over 100 hospitals. Additional studies indicate ionization is superior to thermal eradication.", "page_name": "Legionella", "page_id": "Legionella", "heading": "''Legionella'' control", "sub_heading": "Copper-silver (CuAg) ionization", "_id": "29--3--1---1", "title": "''Legionella'' Control and Prevention with CuAg Ionization"}
{"qas": [{"question": "What is the difference between chlorine dioxide and chlorine dioxide?", "answer": ""}, {"question": "What is the name of the chemical that causes legionella?", "answer": "Chlorine dioxide", "ae_score": -0.3972824559122524, "qg_score": null}, {"question": "What is the name of the chemical that causes legionella?", "answer": "Chlorine dioxide", "ae_score": -0.3972824559122524, "qg_score": null}], "content": "Chlorine dioxide has been EPA approved as a primary potable water disinfectant since 1945. Chlorine dioxide does not produce any carcinogenic byproducts like chlorine when used in the purification of drinking water that contains natural organic compounds such as humic and fulvic acids, chlorine tends to form halogenated disinfection by-products such as trihalomethanes (THMs). Drinking water containing such disinfection by-products has been shown to increase the risk of cancer. ClO2 works differently to chlorine; its action is one of pure oxidation rather than halogenation, so these halogenated by-products are not formed.Chlorine Dioxide is not a restricted heavy metal like copper. It has proven excellent control of ''Legionella'' in cold and hot water systems and its ability as a biocide is not affected by pH, or any water corrosion inhibitors such as silica or phosphate.  Monochloramine is an alternative. Like chlorine and chlorine dioxide, monochloramine is EPA approved as a primary potable water disinfectant. EPA registration requires an EPA biocide label which lists toxicity and other data required by the EPA for all registered biocides. If the product is being sold as a biocide, then the manufacturer is legally required to supply a biocide label, and the purcharser is legally required to apply the biocide per the biocide label. When first applied to a system, chlorine dioxide can be added at disinfection levels of 2 ppm for 6 hours to clean up a system.  This will not remove all biofilm, but will effectively remediate the system of ''Legionella''.", "page_name": "Legionella", "page_id": "Legionella", "heading": "''Legionella'' control", "sub_heading": "Chlorine dioxide", "_id": "29--3--2---1", "title": "Chlorine Dioxide and Monochloramine \u2014 A Biocide"}
{"qas": [{"question": "Why is there a limit to how many people can get Legionella?", "answer": ""}, {"question": "Which company was fined for failing to show proper monitoring records?", "answer": "Nalco + Bulmers", "ae_score": -0.6983164779632625, "qg_score": null}, {"question": "Which company was fined for failing to show proper monitoring records?", "answer": "Nalco + Bulmers", "ae_score": -0.6983164779632625, "qg_score": null}], "content": "Several European countries established the European Working Group for ''Legionella'' Infections (EWGLI) to share knowledge and experience about monitoring potential sources of ''Legionella''. The EWGLI has published guidelines about the actions to be taken to limit the number of colony-forming units (that is, live bacteria that are able to multiply) of ''Legionella'' per litre:\nMonitoring guidelines are stated in Approved Code of Practice (ACOP) L8 in the UK. These are not mandatory, but are widely regarded as so. An  employer or property owner must follow an ACOP, or achieve the same result. Failure to show monitoring records to at least this standard has resulted in several high-profile prosecutions, e.g. Nalco + Bulmers \u2013 neither could prove a sufficient scheme to be in place whilst investigating an outbreak, therefore both were fined about \u00a3300,000GBP. Important case law in this area is R v Trustees of the Science Museum 3 All ER 853, (1993) 1 WLR 1171\nEmployers and those responsible for premises within the UK are required under COSHH to undertake an assessment of the risks arising from Legionella. This risk assessment may be very simple for low risk premises, however for larger or higher risk properties may include a narrative of the site, asset register, simplified schematic drawings, recommendations on compliance, and a proposed monitoring scheme.\nThe L8 ACOP recommend that the risk assessment should be reviewed at least every 2 years and whenever a reason exists to suspect it is no longer valid, such as water systems have been amended or modified, or if the use of the water system has changed, or if there is reason to suspect that Legionella control measures are no longer working.", "page_name": "Legionella", "page_id": "Legionella", "heading": "''Legionella'' control", "sub_heading": "European standards", "_id": "29--3--4---1", "title": "''Legionella'' Monitoring Guidelines"}
{"qas": [{"question": "Is it possible to genetically modify diseases like Legionella?", "answer": ""}, {"question": "Who is the scientist who created legionella?", "answer": "Sergei Popov", "ae_score": -0.6225991302851529, "qg_score": null}, {"question": "Who is the scientist who created legionella?", "answer": "Sergei Popov", "ae_score": -0.6225991302851529, "qg_score": null}], "content": "It has been suggested that ''Legionella'' could be used as a weapon, and indeed genetic modification of ''Legionella pneumophila'' has been shown where the mortality rate in infected animals can be increased to nearly 100%. A former Soviet bioengineer, Sergei Popov, stated in 2000 that his team experimented with genetically enhanced bioweapons, including ''Legionella''. Popov worked as a lead researcher at the Vector Institute from 1976 to 1986, then at Obolensk until 1992, when he defected to the West. He later divulged much of the Soviet biological weapons program and settled in the United States.", "page_name": "Legionella", "page_id": "Legionella", "heading": "Weaponization", "sub_heading": "Weaponization", "_id": "29--4---1---1", "title": "''Legionella'' Could Be Used As a Weapon"}
{"qas": [{"question": "Postinfective IBS?", "answer": ""}, {"question": "What are the different types of ibs?", "answer": "constipation-predominant", "ae_score": -0.9705868611520171, "qg_score": null}, {"question": "What are the different types of ibs?", "answer": "constipation-predominant", "ae_score": -0.9705868611520171, "qg_score": null}], "content": "IBS can be classified as either diarrhea-predominant (IBS-D), constipation-predominant (IBS-C), or with alternating stool pattern (IBS-A) or pain-predominant. In some individuals, IBS may have an acute onset and develop after an infectious illness characterized by two or more of: fever, vomiting, diarrhea, or positive stool culture. This postinfective syndrome has consequently been termed \"postinfectious IBS\" (IBS-PI).", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Classification", "sub_heading": "Classification", "_id": "30--0---1---1", "title": "Postinfectious IBS (IBS-PI)."}
{"qas": [{"question": "IBS?", "answer": ""}, {"question": "Where did the term irritable bowel syndrome come from?", "answer": "White2002/", "ae_score": null, "qg_score": null}, {"question": "Where did the term irritable bowel syndrome come from?", "answer": "White2002/", "ae_score": null, "qg_score": null}], "content": "The primary symptoms of IBS are abdominal pain or discomfort in association with frequent diarrhea or constipation and a change in bowel habits. Symptoms usually are experienced as acute attacks that subside within one day, but recurrent attacks are likely. There may also be urgency for bowel movements, a feeling of incomplete evacuation (tenesmus), bloating, or abdominal distension. In some cases, the symptoms are relieved by bowel movements. People with IBS, more commonly than others, have gastroesophageal reflux, symptoms relating to the genitourinary system, chronic fatigue syndrome, fibromyalgia, headache, backache, and psychiatric symptoms such as depression and anxiety.<ref name=White2002/> About a third of men and women who have IBS also report sexual dysfunction typically in the form of a reduction in libido.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "30--1---1---1", "title": "IBS Symptoms and Treatment"}
{"qas": [{"question": "Why do some people develop IBS more often than others?", "answer": ""}, {"question": "What percentage of ibs cases are triggered by an acute gastroenteritis infection?", "answer": "10 percent", "ae_score": -0.5942390525671924, "qg_score": null}, {"question": "What part of the gut is affected by irritable bowel syndrome?", "answer": "epithelial barrier", "ae_score": null, "qg_score": null}], "content": "Approximately 10 percent of IBS cases are triggered by an acute gastroenteritis infection. Genetic defects relating to the innate immune system and epithelial barrier as well as high stress and anxiety levels appear from evidence to increase the risk of developing post-infectious IBS. Post-infectious IBS usually manifests itself as the diarrhea predominant subtype. Evidence has demonstrated that the release of high levels of proinflammatory cytokines during acute enteric infection causes increased gut permeability leading to translocation of the commensal bacteria across the epithelial barrier resulting in significant damage to local tissues which is likely to result in chronic gut abnormalities in sensitive individuals. However, increased gut permeability is strongly associated with IBS regardless of whether IBS was initiated by an infection or not.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Cause", "sub_heading": "Cause", "_id": "30--2--0---1", "title": "Post-Infectious IBS Symptoms"}
{"qas": [{"question": "Why does depression cause anxiety?", "answer": ""}, {"question": "When was irritable bowel syndrome discovered in the uk?", "answer": "1990s", "ae_score": -0.43152068145687156, "qg_score": null}, {"question": "When was irritable bowel syndrome discovered in the uk?", "answer": "1990s", "ae_score": -0.43152068145687156, "qg_score": null}], "content": "Publications suggesting the role of brain-gut \"axis\" appeared in the 1990s and childhood physical and psychological abuse is often associated with the development of IBS.\nGiven the high levels of anxiety seen in IBS patients and the overlap with conditions such as fibromyalgia and chronic fatigue syndrome, a potential model of IBS involves a disruption of the stress system. The stress response in the body involves the HPA axis and the sympathetic nervous system, both of which have been shown to operate abnormally in IBS patients. Psychiatric illness or anxiety precedes IBS symptoms in two-thirds of patients, and psychological traits predispose previously healthy people to developing IBS after gastroenteritis.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Cause", "sub_heading": "Stress", "_id": "30--2--1---1", "title": "IBS Symptoms and the Stress System"}
{"qas": [{"question": "What is the difference between SIBO and normal bowel movements?", "answer": ""}, {"question": "What is the cause of diarrhea in ibs patients?", "answer": "Small intestinal bacterial overgrowth", "ae_score": -0.8971740373336872, "qg_score": null}, {"question": "What is the cause of diarrhea in ibs patients?", "answer": "Small intestinal bacterial overgrowth", "ae_score": -0.8971740373336872, "qg_score": null}], "content": "Small intestinal bacterial overgrowth occurs with greater frequency in patients who have been diagnosed with IBS compared to healthy controls. SIBO is most common in diarrhea-predominate IBS but also occurs in constipation-predominant IBS more frequently than healthy controls. Symptoms of SIBO include bloating, abdominal pain, diarrhea or constipation among others. IBS may be the result of the immune system interacting abnormally with gut microbiota resulting in an abnormal cytokine signalling profile.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Cause", "sub_heading": "Bacteria", "_id": "30--2--2---1", "title": "SIBO Symptoms in IBS Patients"}
{"qas": [{"question": "What is the difference between mycobiota and my gut microbiota?", "answer": ""}, {"question": "What is the yeast that causes irritable bowel syndrome?", "answer": "Candida albicans", "ae_score": -0.6184080558728077, "qg_score": null}, {"question": "What is the yeast that causes irritable bowel syndrome?", "answer": "Candida albicans", "ae_score": -0.6184080558728077, "qg_score": null}], "content": "There is growing evidence that alterations of gut microbiota (dysbiosis) are associated with the intestinal manifestations of IBS, but also with the psychiatric morbidity that coexists in up to 80% of patients with IBS. The role of the gut mycobiota, and especially of the abnormal proliferation of the yeast ''Candida albicans'' in some patients with IBS, is under investigation.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Cause", "sub_heading": "Fungus", "_id": "30--2--3---1", "title": "The role of the gut microbiota in IBS"}
{"qas": [{"question": "Protozoal infections?", "answer": ""}, {"question": "What is the cause of irritable bowel syndrome?", "answer": "Protozoal infections", "ae_score": -0.6093461790916019, "qg_score": null}, {"question": "What is the cause of irritable bowel syndrome?", "answer": "Protozoal infections", "ae_score": -0.6093461790916019, "qg_score": null}], "content": "Protozoal infections can cause symptoms that mirror specific IBS subtypes, e.g., infection by certain substypes of ''blastocystis hominis'' (blastocystosis) has a significant (possibly causal) relationship with IBS-D; certain protozoal infections also occur more frequently in IBS patients. ''Dientamoeba fragilis'' has also been considered a possible organism to study, though it is also found in people without IBS.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Cause", "sub_heading": "Protozoa", "_id": "30--2--4---1", "title": "Protozoal infections in IBS-D"}
{"qas": [{"question": "Why do some people have IBS and others don't?", "answer": ""}, {"question": "What is the most common component of the digestive system?", "answer": "flagellin", "ae_score": -1.0191789653219558, "qg_score": null}, {"question": "What is the most common component of the digestive system?", "answer": "flagellin", "ae_score": -1.0191789653219558, "qg_score": null}], "content": "There is evidence that abnormalities occur in the gut flora of individuals who have IBS, such as reduced diversity, a decreased abundance of bacteria belonging to the phylum ''Bacteroidetes'', and an increased abundance of those belonging to the phylum ''Firmicutes''. The changes in gut flora are most profound in individuals who have diarrhoea predominant IBS. Antibodies against common components (namely flagellin) of the commensal gut flora are a common occurrence in IBS affected individuals. Chronic low-grade inflammation commonly occurs in IBS affected individuals with abnormalities found including increased enterochromaffin cells, intraepithelial lymphocytes, and mast cells resulting in chronic immune mediated inflammation of the gut mucosa.\nGenetic, environmental, and psychological factors seem to be important in the development of IBS. Studies have shown that IBS has a genetic component even though there is a predominant influence of environmental factors. IBS has been reported in greater quantities in multigenerational families with IBS than in the regular population.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Mechanism", "sub_heading": "Mechanism", "_id": "30--3---1---1", "title": "IBS Symptoms and Symptoms of IBS"}
{"qas": [{"question": "Why is it so hard to find a cure for cancer?", "answer": ""}, {"question": "When did the rome iii process come out?", "answer": "2006", "ae_score": -0.6995832708253761, "qg_score": null}, {"question": "What is the medical term for irritable bowel syndrome?", "answer": "celiac disease", "ae_score": null, "qg_score": null}], "content": "Colon cancer, inflammatory bowel disease, thyroid disorders, and giardiasis can all feature abnormal defecation and abdominal pain. Less common causes of this symptom profile are carcinoid syndrome, microscopic colitis, bacterial overgrowth, and eosinophilic gastroenteritis; IBS is, however, a common presentation, and testing for these conditions would yield low numbers of positive results, so it is considered difficult to justify the expense.\nSome people, managed for years for IBS, may have non-celiac gluten sensitivity (NCGS). Gastrointestinal symptoms of IBS are clinically indistinguishable from those of NCGS, but the presence of any of the following non-intestinal manifestations suggest a possible NCGS: headache or migraine, \"foggy mind\", chronic fatigue, fibromyalgia, joint and muscle pain, leg or arm numbness, tingling of the extremities, dermatitis (eczema or skin rash), atopic disorders, allergy to one or more inhalants, foods or metals (such as mites, graminaceae, parietaria, cat or dog hair, shellfish, or nickel), depression, anxiety, anemia, iron-deficiency anemia, folate deficiency, asthma, rhinitis, eating disorders, neuropsychiatric disorders (such as schizophrenia, autism, peripheral neuropathy, ataxia, attention deficit hyperactivity disorder) or autoimmune diseases. An improvement with a gluten-free diet of immune-mediated symptoms, including autoimmune diseases, once having reasonably ruled out coeliac disease and wheat allergy, is another way to realize a differential diagnosis.\nBecause many causes of diarrhea give IBS-like symptoms, the American Gastroenterological Association published a set of guidelines for tests to be performed to rule out other causes for these symptoms. These include gastrointestinal infections, lactose intolerance, and coeliac disease. Research has suggested these guidelines are not always followed. Once other causes have been excluded, the diagnosis of IBS is performed using a diagnostic algorithm. Well-known algorithms include the Manning criteria, the obsolete Rome I and II criteria, and the Kruis criteria, and studies have compared their reliability. The more recent Rome III process was published in 2006. Physicians may choose to use one of these guidelines or may simply choose to rely on their own anecdotal experience with past patients. The algorithm may include additional tests to guard against misdiagnosis of other diseases as IBS.  Such \"red flag\" symptoms may include weight loss, gastrointestinal bleeding, anemia, or nocturnal symptoms. However, red flag conditions may not always contribute to accuracy in diagnosis; for instance, as many as 31% of IBS patients have blood in their stool, many possibly from hemorrhoidal bleeding.\nThe diagnostic algorithm identifies a name that can be applied to the patient's condition based on the combination of the patient's symptoms of diarrhea, abdominal pain, and constipation. For example, the statement \"50% of returning travelers had developed functional diarrhea while 25% had developed IBS\" would mean half the travelers had diarrhea while a quarter had diarrhea with abdominal pain. While some researchers believe this categorization system will help physicians understand IBS, others have questioned the value of the system and suggested all IBS patients have the same underlying disease but with different symptoms.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "30--4--0---1", "title": "Diarrhea and IBS: A Differential Diagnosis"}
{"qas": [{"question": "Why is it that when you have diarrhea, you don't get rid of the acid?", "answer": ""}, {"question": "Who recommends that all patients with symptoms of ibs be tested for coeliac?", "answer": "The American College of Gastroenterology", "ae_score": -0.2836777873046221, "qg_score": null}, {"question": "What is the cause of diarrhea in ibs?", "answer": "bile acid malabsorption", "ae_score": null, "qg_score": null}], "content": "Some common examples of misdiagnosis include infectious diseases, coeliac disease, ''Helicobacter pylori'', parasites (non-protozoal).<ref name=Stark7/>\nCoeliac disease in particular is often misdiagnosed as IBS. The American College of Gastroenterology recommends all patients with symptoms of IBS be tested for coeliac disease.\nBile acid malabsorption is also sometimes missed in patients with diarrhea-predominant IBS. SeHCAT tests suggest around 30% of D-IBS patients have this condition, and most respond to bile acid sequestrants.\nChronic use of certain sedative-hypnotic drugs, especially the benzodiazepines, may cause irritable bowel-like symptoms that can lead to a misdiagnosis of irritable bowel syndrome.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Diagnosis", "sub_heading": "Misdiagnosis", "_id": "30--4--2---1", "title": "Misdiagnosis of irritable bowel syndrome"}
{"qas": [{"question": "Why is it bad to eat a lot of fiber when you have IBS?", "answer": ""}, {"question": "What is an example of an insoluble fiber that can be used to treat irritable?", "answer": "bran", "ae_score": -0.5202006940730882, "qg_score": null}, {"question": "What is an example of an insoluble fiber that can be used to treat irritable?", "answer": "bran", "ae_score": -0.5202006940730882, "qg_score": null}], "content": "Studies have shown that up to 70% of IBS patients benefited from eating a low FODMAP diet. Symptoms most likely to improve from such a diet include urgency, flatulence, bloating, abdominal pain, and altered stool output. One national guideline advises a low FODMAP diet for managing IBS when other dietary and lifestyle measures have been unsuccessful. This diet restricts various carbohydrates which are poorly absorbed in the small intestine, as well as fructose and lactose, which are similarly poorly absorbed in those with intolerances to them. Reduction of fructose and fructan has been shown to reduce IBS symptoms in a dose-dependent manner in patients with fructose malabsorption and IBS.\nSome IBS patients believe they have some form of dietary intolerance; however, tests attempting to predict food sensitivity in IBS have proven disappointing. A small study reported that an IgG antibody test was somewhat effective in determining food sensitivity in IBS patients, with patients on the elimination diet experiencing 10% greater symptom-reduction than those on a sham diet. However, more research is necessary before IgG testing can be recommended.\nA diet restricted in fermentable oligo- di- and monosaccharides and polyols (FODMAPs) now has an evidence base sufficiently strong to recommend its widespread application in conditions such as IBS and IBD. They also state the restriction of FODMAPs globally, rather than individually, controls the symptoms of functional gut disorders (e.g., IBS), and the majority of IBD patients respond just as well. It is more successful than restricting only fructose and fructans, which are also FODMAPs, as is recommended for those with fructose malabsorption. Longer-term compliance with the diet was high.\nSome evidence suggests soluble fiber supplementation (e.g., psyllium/ispagula husk) is effective.<ref name=Mao2014/> It acts as a bulking agent, and for many IBS-D patients, allows for a more consistent stool. For IBS-C patients, it seems to allow for a softer, moister, more easily passable stool.\nHowever, insoluble fiber (e.g., bran) has not been found to be effective for IBS. In some people, insoluble fiber supplementation may aggravate symptoms.\nFiber might be beneficial in those who have a predominance of constipation. In people who have IBS-C, soluble fiber can reduce overall symptoms, but will not reduce pain. The research supporting dietary fiber contains conflicting, small studies complicated by the heterogeneity of types of fiber and doses used.\nOne meta-analysis found only soluble fiber improved global symptoms of irritable bowel, but neither type of fiber reduced pain. An updated meta-analysis by the same authors also found soluble fiber reduced symptoms, while insoluble fiber worsened symptoms in some cases.  Positive studies have used 10\u201330 grams per day of psyllium.  One study specifically examined the effect of dose, and found 20 g of ispaghula husk were better than 10 g and equivalent to 30 g per day.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Management", "sub_heading": "Management", "_id": "30--5--0---1", "title": "IBS-D and IBS-C Symptom Reduction"}
{"qas": [{"question": "What are mast cells and why are they important in the treatment of IBS?", "answer": ""}, {"question": "What is the name of the anti-inflammatory drug used to treat irritable bowel syndrome?", "answer": "Alosetron", "ae_score": -0.20106638176229627, "qg_score": null}, {"question": "What type of antidepressants are used to treat irritable bowel syndrome?", "answer": "selective serotonin reuptake inhibitors", "ae_score": null, "qg_score": null}], "content": "Medications may consist of stool softeners and laxatives in IBS-C and antidiarrheals (e.g., opiate, opioid, or opioid analogs such as loperamide, codeine, diphenoxylate) in IBS-D for mild symptoms and stronger opiates such as morphine and oxycodone for severe cases.\nDrugs affecting serotonin (5-HT) in the intestines can help reduce symptoms. On the other hand, many IBS-D patients report that SSRI type medications exacerbate spasms and diarrhea.  This is thought to be due to the large number of serotonin receptors in the gut.  5HT3 antagonists such as ondansetron are effective in postinfectious IBS and diarrhoea-dominant IBS due to their blockade of serotonin on 5HT3 receptors in the gut; the reason for their benefit is believed to be that excessive serotonin in the gut is thought to play a role in the pathogenesis of some subtypes of IBS. Certain atypical antipsychotic medications, such as clozapine and olanzapine, may also provide relief due to serotonergic properties these agents possess, acting on the same receptors as other medications in this specific category. Benefits may include reduced diarrhoea, reduced abdominal cramps, and improved general well-being. Any nausea present may also respond to 5HT3 antagonists owing to their antiemetic properties. Serotonin stimulates the gut motility and so agonists can help constipation-predominant irritable bowel, while antagonists can help diarrhea-predominant irritable bowel. Selective serotonin reuptake inhibitors, SSRIs, frequently prescribed for panic and/or anxiety disorder and depression, affect serotonin in the gut, as well as the brain. The bowels are highly dependent on serotonin for neural communication. \"Selective serotonin reuptake inhibitor antidepressants seem to promote global well-being in some patients with irritable bowel syndrome and, possibly, some improvement in abdominal pain and bowel symptoms, but this effect appears to be independent of improved depression. Further research is required.\"\nMast cells and the compound that they secrete are central to the pathophysiology and implicated in the treatment of IBS; some of the secreted mast cell mediators (and associated receptors) which have been implicated in symptoms of IBS or specific subtypes include: histamine (HRH1, HRH2, HRH3), tryptase and chymase (PAR2), serotonin (5-HT3), PGD2 (DP1).  Histamine also causes epithelial secretion of chloride ions and water (associated with secretory diarrhea) by signaling through a receptor or ligand-gated ion channel that has not been identified as of 2015.  A 2015 review noted that both H1-antihistamines and mast cell stabilizers have shown efficacy in reducing pain associated with visceral hypersensitivity in IBS; other lower quality studies have also suggested the benefit of these agents for IBS. In a related review on idiopathic mast cell activation syndromes (including IBS), a combined treatment approach using antileukotrienes, H1/H2-antihistamines, and a mast cell stabilizer are suggested.\nFor patients who do not adequately respond to dietary fiber, osmotic laxatives such as polyethylene glycol, sorbitol, and lactulose can help avoid \"cathartic colon\" which has been associated with stimulant laxatives.  Among the osmotic laxatives, doses of 17\u201326 g/d of polyethylene glycol have been well studied. Lubiprostone (Amitiza) is a gastrointestinal agent used for the treatment of idiopathic chronic constipation and constipation-predominant IBS. It is well tolerated in adults, including elderly patients. As of July 20, 2006, lubiprostone had not been studied in pediatric patients. Lubiprostone is a bicyclic fatty acid (prostaglandin E1 derivative) that acts by specifically activating ClC-2 chloride channels on the apical aspect of gastrointestinal epithelial cells, producing a chloride-rich fluid secretion. These secretions soften the stool, increase motility, and promote spontaneous bowel movements. Unlike many laxative products, lubiprostone does not show signs of tolerance, dependency, or altered serum electrolyte concentration.\nThe use of antispasmodic drugs (e.g., anticholinergics such as hyoscyamine or dicyclomine) may help patients, especially those with cramps or diarrhea. A meta-analysis by the Cochrane Collaboration concludes if seven patients are treated with antispasmodics, one patient will benefit.<ref name=pmid21833945/> Antispasmodics can be divided in two groups: neurotropics and musculotropics.\nProton pump inhibitors (PPIs) used to suppress stomach acid production may cause bacterial overgrowth leading to IBS symptoms. Discontinuation of PPIs in selected individuals has been recommended as it may lead to an improvement or resolution of IBS symptoms.\nStrong evidence indicates low doses of tricyclic antidepressants can be effective for IBS. However, the evidence is less robust as to the effectiveness of other antidepressant classes such as SSRIs.\nAlosetron, a selective 5-HT3 antagonist for IBS-D and cilansetron (also a selective 5-HT3 antagonist) were trialed for IBS. Due to severe adverse effects, namely ischemic colitis and severe constipation, they are not available or recommended.\nMagnesium aluminum silicates and alverine citrate drugs can be effective for IBS.\nEvidence is conflicting about the benefit of antidepressants in IBS. Some meta-analyses have found a benefit, while others have not. A meta-analysis of randomized controlled trials of mainly TCAs found three patients have to be treated with TCAs for one patient to improve. A separate randomized controlled trial found TCAs are best for patients with IBS-D.\nRifaximin can be used as an effective treatment for abdominal bloating and flatulence, giving more credibility to the potential role of bacterial overgrowth in some patients with IBS.\nDomperidone, a dopamine receptor blocker and a parasympathomimetic, has been shown to reduce bloating and abdominal pain as a result of an accelerated colon transit time and reduced faecal load, that is, a relief from 'hidden constipation'; defecation was similarly improved.\nThe use of opioids is controversial due to the potential risk of tolerance, physical dependence, and addiction, but can be the only relief for some diarrhea-predominant cases when other treatment has been ineffective.\nStatistically significant reduction in IBS symptoms occurs following antibiotic therapy for small intestinal bacterial overgrowth. However, recent research has shown that the lactulose hydrogen breath test does not actually measure SIBO, and that SIBO is unlikely to be the cause of IBS.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Management", "sub_heading": "Medication", "_id": "30--5--1---1", "title": "Medications for IBS"}
{"qas": [{"question": "Hypnosis and cognitive behavioral therapy?", "answer": ""}, {"question": "What type of therapy is used to deal with irritable bowel syndrome?", "answer": "cognitive behavioural therapy", "ae_score": -0.7193142256951983, "qg_score": null}, {"question": "What type of therapy is used to deal with irritable bowel syndrome?", "answer": "cognitive behavioural therapy", "ae_score": -0.7193142256951983, "qg_score": null}], "content": "The mind-body or brain-gut interactions has been proposed for IBS, and is gaining increasing research attention. Hypnosis can improve mental well-being, and cognitive behavioural therapy can provide psychological coping strategies for dealing with distressing symptoms, as well as help suppress thoughts and behaviours that increase the symptoms of IBS, although the evidence base for effectiveness of psychotherapy and hypnosis is weak and such therapies are in general not recommended. However, in treatment resistant cases where pharmacological therapies over a period of at least 12 months have failed to give relief, NICE clinical guidelines recommend that consideration should be given to psychological treatment strategies such as cognitive behavioural therapy [CBT], hypnotherapy and/or psychological therapy.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Management", "sub_heading": "Psychological therapies", "_id": "30--5--2---1", "title": "Cognitive Behavioral Therapy for IBS"}
{"qas": [{"question": "Is there any evidence for the effectiveness of other herbal remedies for IBS?", "answer": ""}, {"question": "What is the main treatment for irritable bowel syndrome?", "answer": "Reducing stress", "ae_score": -0.28331371339277084, "qg_score": null}, {"question": "Which part of the brain is affected by inflammatory bowel syndrome?", "answer": "Gut-brain axis", "ae_score": null, "qg_score": null}], "content": "Reducing stress may reduce the frequency and severity of IBS symptoms. Techniques that may be helpful include:\nProbiotics can be beneficial in the treatment of IBS; taking 10 billion to 100 billion beneficial bacteria per day is recommended for beneficial results. However, further research is needed on individual strains of beneficial bacteria for more refined recommendations. Probiotics have positive effects such as enhancing the intestinal mucosal barrier, providing a physical barrier, bacteriocin production (resulting in reduced numbers of pathogenic and gas-producing bacteria), reducing intestinal permeability and bacterial translocation, and regulating the immune system both locally and systemically among other beneficial effects. Probiotics may also have positive effects on the gut-brain axis by their positive effects countering the effects of stress on gut immunity and gut function.\nA number of probiotics have been found to be effective, including ''Lactobacillus plantarum'', and ''Bifidobacteria infantis''; but one review found only ''Bifidobacteria infantis'' showed efficacy. ''B. infantis'' may have effects beyond the gut via it causing a reduction of proinflammatory cytokine activity and elevation of blood tryptophan levels, which may cause an improvement in symptoms of depression. Some yogurt is made using probiotics that may help ease symptoms of IBS. A probiotic yeast called Saccharomyces boulardii has some evidence of effectiveness in the treatment of irritable bowel syndrome.\nCertain probiotics have different effects on certain symptoms of IBS. For example, ''Bifidobacterium breve'', ''B. longum,'' and ''Lactobacillus acidophilus'' have been found to alleviate abdominal pain. ''B. breve, B. infantis, L. casei'', or ''L. plantarum'' species alleviated distension symptoms. ''B. breve, B. infantis, L. casei, L. plantarum, B. longum, L. acidophilus, L. bulgaricus'', and ''Streptococcus salivarius'' ssp. ''thermophilus'' have all been found to affect flatulence levels. Most clinical studies show probiotics do not improve straining, sense of incomplete evacuation, stool consistency, fecal urgency, or stool frequency, although a few clinical studies did find some benefit of probiotic therapy. The evidence is conflicting for whether probiotics improve overall quality of life scores.\nProbiotics may exert their beneficial effects on IBS symptoms via preserving the gut microbiota, normalisation of cytokine blood levels, improving the intestinal transit time, decreasing small intestine permeability, and by treating small intestinal bacterial overgrowth of fermenting bacteria.\nPeppermint oil appears useful. Safety during pregnancy has not been established, however, and caution is required not to chew or break the enteric coating; otherwise, gastroesophageal reflux may occur as a result of lower esophageal sphincter relaxation. Occasionally, nausea and perianal burning occur as side effects. Iberogast, a multi-herbal extract, was found to be superior in efficacy to placebo. Commiphora mukul and Plantago ovata\nOnly limited evidence exists for the effectiveness of other herbal remedies for IBS. As with all herbs, it is wise to be aware of possible drug interactions and adverse effects.\nYoga may be effective for some IBS patients, especially poses which exercise the lower abdomen.\nA meta-analysis found no benefits of acupuncture relative to placebo for IBS symptom severity or IBS-related quality of life.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Management", "sub_heading": "Stress relief", "_id": "30--5--3---1", "title": "IBS Symptoms & Treatments"}
{"qas": [{"question": "Why is there such a high prevalence of IBS?", "answer": ""}, {"question": "What is the medical term for irritable bowel syndrome?", "answer": "IBS", "ae_score": null, "qg_score": null}, {"question": "What is the medical term for irritable bowel syndrome?", "answer": "IBS", "ae_score": null, "qg_score": null}], "content": "The prevalence of IBS varies by country and by age range examined. The bar graph at right shows the percentage of the population reporting symptoms of IBS in studies from various geographic regions (see table below for references). The following table contains a list of studies performed in different countries that measured the prevalence of IBS and IBS-like symptoms:\nWomen are around two to three times more likely to be diagnosed with IBS and four to five times more likely to seek specialty care for it than men. These differences likely reflect a combination of both biological (sex) and social (gender) factors. People diagnosed with IBS are usually younger than 45 years old.<ref name=NIH2015Fact/> Studies of female patients with IBS show symptom severity often fluctuates with the menstrual cycle, suggesting hormonal differences may play a role. Endorsement of gender-related traits has been associated with quality of life and psychological adjustment in IBS.  Gender differences in healthcare-seeking may also play a role. Gender differences in trait anxiety may contribute to lower pain thresholds in women, putting them at greater risk for a number of chronic pain disorders. Finally, sexual trauma is a major risk factor for IBS, with as many as 33% of those affected reporting such abuse.  Because women are at higher risk of sexual abuse than men, sex-related risk of abuse may contribute to the higher rate of IBS in women.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "30--6---1---1", "title": "The Prevalence of IBS in Women and Men"}
{"qas": [{"question": "How did the concept of an irritable bowel come about?", "answer": ""}, {"question": "When was the term irritable bowel syndrome first used?", "answer": "1950", "ae_score": -0.26898251253671684, "qg_score": null}, {"question": "When was the term irritable bowel syndrome first used?", "answer": "1950", "ae_score": -0.26898251253671684, "qg_score": null}], "content": "One of the first references to the concept of an \"irritable bowel\" appeared in the ''Rocky Mountain Medical Journal'' in 1950.  The term was used to categorize patients who developed symptoms of diarrhea, abdominal pain, and constipation, but where no well-recognized infective cause could be found.  Early theories suggested the irritable bowel was caused by a psychosomatic or mental disorder.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "History", "sub_heading": "History", "_id": "30--7---1---1", "title": "Irritable Bowel Syndrome"}
{"qas": [{"question": "Why is irritable bowel syndrome so expensive?", "answer": ""}, {"question": "How much does it cost to treat irritable bowel syndrome?", "answer": "$1.7\u201310 billion", "ae_score": -0.4330466486353463, "qg_score": null}, {"question": "How much does it cost to treat irritable bowel syndrome?", "answer": "$1.7\u201310 billion", "ae_score": -0.4330466486353463, "qg_score": null}], "content": "The aggregate cost of irritable bowel syndrome in the United States has been estimated at $1.7\u201310 billion in direct medical costs, with an additional $20 billion in indirect costs, for a total of $21.7\u201330 billion.<ref name=Hul2004/> A study by a managed care company comparing medical costs of IBS patients to non-IBS controls identified a 49% annual increase in medical costs associated with a diagnosis of IBS. IBS patients incurred average annual direct costs of $5,049 and $406 in out-of-pocket expenses in 2007. A study of workers with IBS found that they reported a 34.6% loss in productivity, corresponding to 13.8 hours lost per 40 hour week. A study of employer-related health costs from a Fortune 100 company conducted with data from the 1990s found IBS patients incurred US $4527 in claims costs vs. $3276 for controls. A study on Medicaid costs conducted in 2003 by the University of Georgia's College of Pharmacy and Novartis found IBS was associated in an increase of $962 in Medicaid costs in California, and $2191 in North Carolina.  IBS patients had higher costs for physician visits, outpatients visits, and prescription drugs.  The study suggested the costs associated with IBS were comparable to those found in asthma patients.", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Economics", "sub_heading": "Economics", "_id": "30--8---1---1", "title": "IBS Costs Estimated at $1.7\u201330 Billion"}
{"qas": [{"question": "Why do so many people with irritable bowel syndrome (IBS) have a hard time getting over it?", "answer": ""}, {"question": "Which drug has been shown to significantly reduce immune mediated inflammation in the gut of ibs?", "answer": "Mesalazine", "ae_score": -0.6771771880636712, "qg_score": null}, {"question": "Which drug is used to treat inflammatory bowel syndrome ( ibs )?", "answer": "mesalazin", "ae_score": null, "qg_score": null}], "content": "Individuals with IBS have been found to have decreased diversity and numbers of bacteroidetes microbiota. Preliminary research into the effectiveness of fecal microbiota transplant in the treatment of IBS has been very favourable with a 'cure' rate of between 36 percent and 60 percent with remission of core IBS symptoms persisting at 9 and 19 months follow up. Treatment with probiotic strains of bacteria has shown to be effective, though not all strains of microorganisms confer the same benefit and adverse side effects have been documented in a minority of cases.\nThere is increasing evidence for the effectiveness of mesalazine (5-aminosalicylic acid) in the treatment of IBS. Mesalazine is a drug with anti-inflammatory properties that has been reported to significantly reduce immune mediated inflammation in the gut of IBS affected individuals with mesalazine therapy resulting in improved IBS symptoms as well as feelings of general wellness in IBS affected people. It has also been observed that mesalazine therapy helps to normalise the gut flora which is often abnormal in people who have IBS. The therapeutic benefits of mesalazine may be the result of improvements to the epithelial barrier function.\nAn IgG-mediated food intolerance diet led to a 24% greater deterioration in symptoms compared to those on the elimination diet and food elimination based on IgG antibodies may be effective in reducing IBS symptoms and is worthy of further biomedical research. The main problem with this study was that the differences in symptoms were only observed in exclusion diets is limited, treatment based on \"abnormally\" high IgG antibodies cannot be recommended.\nDifferences in visceral sensitivity and intestinal physiology have been noted in IBS. Mucosal barrier reinforcement in response to oral 5-HTP was absent in IBS compared to controls. IBS/IBD individuals are less often HLA DQ2/8 positive than in upper functional gastrointestinal disease and healthy populations.\nA questionnaire in 2006 designed to identify patients' perceptions about IBS, their preferences on the type of information they need, and educational media and expectations from health care providers revealed misperceptions about IBS developing into other conditions, including colitis, malnutrition, and cancer. The survey found IBS patients were most interested in learning about foods to avoid (60%), causes of IBS (55%), medications (58%), coping strategies (56%), and psychological factors related to IBS (55%). The respondents indicated they wanted their physicians to be available by phone or e-mail following a visit (80%), have the ability to listen (80%), and provide hope (73%) and support (63%).", "page_name": "Irritable bowel syndrome", "page_id": "Irritable%20bowel%20syndrome", "heading": "Research", "sub_heading": "Research", "_id": "30--9---1---1", "title": "Irritable bowel syndrome | Research"}
{"qas": [{"question": "What is the difference between conservation biology and evolutionary genetics?", "answer": ""}, {"question": "When was the first international conference on conservation biology held?", "answer": "1978", "ae_score": -0.7856661952205011, "qg_score": null}, {"question": "When was the first international conference on conservation biology held?", "answer": "1978", "ae_score": -0.7856661952205011, "qg_score": null}], "content": "The term conservation biology and its conception as a new field originated with the convening of \"The First International Conference on Research in Conservation Biology\" held at the University of California, San Diego in La Jolla, California in 1978 led by American biologists Bruce A. Wilcox and Michael E. Soul\u00e9 with a group of leading university and zoo researchers and conservationists including Kurt Benirschke, Sir Otto Frankel, Thomas E. Lovejoy, and Jared M. Diamond. The meeting was prompted by the concern over tropical deforestation, disappearing species, eroding genetic diversity within species. The conference and proceedings that resulted<ref name=ConsBiol80/> sought to initiate the bridging of a gap between theory in ecology and evolutionary genetics on the one hand and conservation policy and practice on the other. Conservation biology and the concept of biological diversity (biodiversity) emerged together, helping crystallize the modern era of conservation science and policy.  The inherent multidisciplinary basis for conservation biology has led to new subdisciplines including conservation social science, conservation behavior and conservation physiology. It stimulated further development of conservation genetics which Otto Frankel had originated first but is now often considered a subdiscipline as well.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Origination of Conservation Biology", "sub_heading": "Origination of Conservation Biology", "_id": "31--0---1---1", "title": "Conservation Biology and Biodiversity"}
{"qas": [{"question": "What do conservation biologists do?", "answer": ""}, {"question": "What is conservation biology closely related to?", "answer": "ecology", "ae_score": -0.6785125304724275, "qg_score": null}, {"question": "What is conservation biology closely related to?", "answer": "ecology", "ae_score": -0.6785125304724275, "qg_score": null}], "content": "The rapid decline of established biological systems around the world means that conservation biology is often referred to as a \"Discipline with a deadline\". Conservation biology is tied closely to ecology in researching the population ecology (dispersal, migration, demographics, effective population size, inbreeding depression, and minimum population viability) of rare or endangered species. Conservation biology is concerned with phenomena that affect the maintenance, loss, and restoration of biodiversity and the science of sustaining evolutionary processes that engender genetic, population, species, and ecosystem diversity. The concern stems from estimates suggesting that up to 50% of all species on the planet will disappear within the next 50 years, which has contributed to poverty, starvation, and will reset the course of evolution on this planet.\nConservation biologists research and educate on the trends and process of biodiversity loss, species extinctions, and the negative effect these are having on our capabilities to sustain the well-being of human society. Conservation biologists work in the field and office, in government, universities, non-profit organizations and industry. The topics of their research are diverse, because this is an interdisciplinary network with professional alliances in the biological as well as social sciences. Those dedicated to the cause and profession advocate for a global response to the current biodiversity crisis based on morals, ethics, and scientific reason. Organizations and citizens are responding to the biodiversity crisis through conservation action plans that direct research, monitoring, and education programs that engage concerns at local through global scales.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Description", "sub_heading": "Description", "_id": "31--1---1---1", "title": "Conservation Biologists \u2014 A Discipline with a Deadline"}
{"qas": [{"question": "Why do some cultures have rules and regulations about how to use natural resources?", "answer": ""}, {"question": "What type of fish did the alaskan tlingit clans and the haida?", "answer": "sockeye salmon", "ae_score": -0.5137514834089628, "qg_score": null}, {"question": "What type of fish did the alaskan tlingit clans and the haida?", "answer": "sockeye salmon", "ae_score": -0.5137514834089628, "qg_score": null}], "content": "Conscious efforts to conserve and protect ''global'' biodiversity are a recent phenomenon. Natural resource conservation, however, has a history that extends prior to the age of conservation. Resource ethics grew out of necessity through direct relations with nature. Regulation or communal restraint became necessary to prevent selfish motives from taking more than could be locally sustained, therefore compromising the long-term supply for the rest of the community. This social dilemma with respect to natural resource management is often called the \"Tragedy of the Commons\".\nFrom this principle, conservation biologists can trace communal resource based ethics throughout cultures as a solution to communal resource conflict. For example, the Alaskan Tlingit peoples and the Haida of the Pacific Northwest had resource boundaries, rules, and restrictions among clans with respect to the fishing of sockeye salmon. These rules were guided by clan elders who knew lifelong details of each river and stream they managed. There are numerous examples in history where cultures have followed rules, rituals, and organized practice with respect to communal natural resource management.\nConservation ethics are also found in early religious and philosophical writings. There are examples in the Tao, Shinto, Hindu, Islamic and Buddhist traditions. In Greek philosophy, Plato lamented about pasture land degradation: \"What is left now is, so to say, the skeleton of a body wasted by disease; the rich, soft soil has been carried off and only the bare framework of the district left.\" In the bible, through Moses, God commanded to let the land rest from cultivation every seventh year. Before the 18th century, however, much of European culture considered it a pagan view to admire nature. Wilderness was denigrated while agricultural development was praised. However, as early as AD 680 a wildlife sanctuary was founded on the Farne Islands by St Cuthbert in response to his religious beliefs.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "History", "sub_heading": "History", "_id": "31--2--0---1", "title": "Conservation Ethics: The Evolution of Conservation Ethics"}
{"qas": [{"question": "Why are there so many natural history museums in the US?", "answer": ""}, {"question": "How many natural history museums existed in germany by 1900?", "answer": "150", "ae_score": -0.36132385682183404, "qg_score": null}, {"question": "How many natural history museums existed in germany by 1900?", "answer": "150", "ae_score": -0.36132385682183404, "qg_score": null}], "content": "Natural history was a major preoccupation in the 18th century, with grand expeditions and the opening of popular public displays in Europe and North America. By 1900 there were 150 natural history museums in Germany, 250 in Great Britain, 250 in the United States, and 300 in France. Preservationist or conservationist sentiments are a development of the late 18th to early 20th centuries.\nBefore Charles Darwin set sail on the HMS Beagle, most people in the world, including Darwin, believed in special creation and that all species were unchanged. George-Louis Leclerc was one of the first naturalist that questioned this belief. He proposed in his 44 volume natural history book that species evolve due to environmental influences. Erasmus Darwin was also a naturalist who also suggested that species evolved. Erasmus Darwin noted that some species have vestigial structures which are anatomical structures that have no apparent function in the species currently but would have been useful for the species' ancestors. The thinking of these early 18th century naturalist helped to change the mindset and thinking of the early 19th century naturalist.\nBy the early 19th century biogeography was ignited through the efforts of Alexander von Humboldt, Charles Lyell and Charles Darwin. The 19th-century fascination with natural history engendered a fervor to be the first to collect rare specimens with the goal of doing so before they became extinct by other such collectors. Although the work of many 18th and 19th century naturalists were to inspire nature enthusiasts and conservation organizations, their writings, by modern standards, showed insensitivity towards conservation as they would kill hundreds of specimens for their collections.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "History", "sub_heading": "Early naturalists", "_id": "31--2--1---1", "title": "Naturalists and Conservationists"}
{"qas": [{"question": "How did the Madras Board of Revenue get involved in forest conservation?", "answer": ""}, {"question": "Who is considered to be the founder of conservation biology?", "answer": "Lord Monboddo", "ae_score": -0.19636930657300317, "qg_score": null}, {"question": "Who is considered to be the founder of conservation biology?", "answer": "Lord Monboddo", "ae_score": -0.19636930657300317, "qg_score": null}], "content": "The modern roots of conservation biology can be found in the late 18th-century Enlightenment period particularly in England and Scotland. A number of thinkers, among them notably Lord Monboddo, described the importance of \"preserving nature\"; much of this early emphasis had its origins in Christian theology.\nScientific conservation principles were first practically applied to the forests of British India. The conservation ethic that began to evolve included three core principles: that human activity damaged the environment, that there was a civic duty to maintain the environment for future generations, and that scientific, empirically based methods should be applied to ensure this duty was carried out. Sir James Ranald Martin was prominent in promoting this ideology, publishing many medico-topographical reports that demonstrated the scale of damage wrought through large-scale deforestation and desiccation, and lobbying extensively for the institutionalization of forest conservation activities in British India through the establishment of Forest Departments.\nThe Madras Board of Revenue started local conservation efforts in 1842, headed by Alexander Gibson, a professional botanist who systematically adopted a forest conservation program based on scientific principles. This was the first case of state conservation management of forests in the world. Governor-General Lord Dalhousie introduced the first permanent and large-scale forest conservation program in the world in 1855, a model that soon spread to other colonies, as well the United States, where Yellowstone National Park was opened in 1872 as the world\u2019s first national park.\nThe term ''conservation'' came into widespread use in the late 19th century and referred to the management, mainly for economic reasons, of such natural resources as timber, fish, game, topsoil, pastureland, and minerals. In addition it referred to the preservation of forests (forestry), wildlife (wildlife refuge), parkland, wilderness, and watersheds. This period also saw the passage of the first conservation legislation and the establishment of the first nature conservation societies. The Sea Birds Preservation Act of 1869 was passed in Britain as the first nature protection law in the world after extensive lobbying from the Association for the Protection of Seabirds and the respected ornithologist Alfred Newton. Newton was also instrumental in the passage of the first Game laws from 1872, which protected animals during their breeding season so as to prevent the stock from being brought close to extinction.\nOne of the first conservation societies was the Royal Society for the Protection of Birds, founded in 1889 in Manchester as a protest group campaigning against the use of great crested grebe and kittiwake skins and feathers in fur clothing. Originally known as \"the Plumage League\". the group gained popularity and eventually amalgamated with the Fur and Feather League in Croydon, and formed the RSPB. The National Trust formed in 1895 with the manifesto to \"...promote the permanent preservation, for the benefit of the nation, of lands, ...to preserve (so far practicable) their natural aspect.\"\nIn the United States, the Forest Reserve Act of 1891 gave the President power to set aside forest reserves from the land in the public domain. John Muir founded the Sierra Club in 1892, and the New York Zoological Society was set up in 1895. A series of national forests and preserves were established by Theodore Roosevelt from 1901 to 1909. The 1916 National Parks Act, included a 'use without impairment' clause, sought by John Muir, which eventually resulted in the removal of a proposal to build a dam in Dinosaur National Monument in 1959.\nIn the 20th century, Canadian civil servants, including Charles Gordon Hewitt  and James Harkin spearheaded the movement toward wildlife conservation.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "History", "sub_heading": "Conservation movement", "_id": "31--2--2---1", "title": "The Evolution of Conservation Biology in the 20th Century"}
{"qas": [{"question": "What is the significance of the recent ecological crisis in the United States?", "answer": ""}, {"question": "When was landscape scale conservation first used?", "answer": "2000", "ae_score": -0.4424750191917739, "qg_score": null}, {"question": "When was landscape scale conservation first used?", "answer": "2000", "ae_score": -0.4424750191917739, "qg_score": null}], "content": "In the mid-20th century, efforts arose to target individual species for conservation, notably efforts in big cat conservation in South America led by the New York Zoological Society. In the early 20th century the New York Zoological Society was instrumental in developing concepts of establishing preserves for particular species and conducting the necessary conservation studies to determine the suitability of locations that are most appropriate as conservation priorities; the work of Henry Fairfield Osborn Jr., Carl E. Akeley, Archie Carr and Archie Carr III is notable in this era. Akeley for example, having led expeditions to the Virunga Mountains and observed the mountain gorilla in the wild, became convinced that the species and the area were conservation priorities. He was instrumental in persuading Albert I of Belgium to act in defense of the mountain gorilla and establish Albert National Park (since renamed Virunga National Park) in what is now Democratic Republic of Congo.\nBy the 1970s, led primarily by work in the United States under the Endangered Species Act along with the Species at Risk Act (SARA) of Canada, Biodiversity Action Plans developed in Australia, Sweden, the United Kingdom, hundreds of species specific protection plans ensued. Notably the United Nations acted to conserve sites of outstanding cultural or natural importance to the common heritage of mankind. The programme was adopted by the General Conference of UNESCO in 1972. As of 2006, a total of 830 sites are listed: 644 cultural, 162 natural. The first country to pursue aggressive biological conservation through national legislation was the United States, which passed back to back legislation in the Endangered Species Act (1966) and National Environmental Policy Act (1970), which together injected major funding and protection measures to large-scale habitat protection and threatened species research. Other conservation developments, however, have taken hold throughout the world. India, for example, passed the Wildlife Protection Act of 1972.\nIn 1980 a significant development was the emergence of the urban conservation movement. A local organization was established in Birmingham, UK, a development followed in rapid succession in cities across the UK, then overseas. Although perceived as a grassroots movement, its early development was driven by academic research into urban wildlife. Initially perceived as radical, the movement's view of conservation being inextricably linked with other human activity has now become mainstream in conservation thought. Considerable research effort is now directed at urban conservation biology. The Society for Conservation Biology originated in 1985.\nBy 1992 most of the countries of the world had become committed to the principles of conservation of biological diversity with the Convention on Biological Diversity; subsequently many countries began programmes of Biodiversity Action Plans to identify and conserve threatened species within their borders, as well as protect associated habitats. The late 1990s saw increasing professionalism in the sector, with the maturing of organisations such as the Institute of Ecology and Environmental Management and the Society for the Environment.\nSince 2000 the concept of landscape scale conservation has risen to prominence, with less emphasis being given to single-species or even single-habitat focused actions. Instead an ecosystem approach is advocated by most mainstream conservationists, although concerns have been expressed by those working to protect some high-profile species.\nEcology has clarified the workings of the biosphere; i.e., the complex interrelationships among humans, other species, and the physical environment. The burgeoning human population and associated agriculture, industry, and the ensuing pollution, have demonstrated how easily ecological relationships can be disrupted.\nThe last word in ignorance is the man who says of an animal or plant: \"What good is it?\" If the land mechanism as a whole is good, then every part is good, whether we understand it or not. If the biota, in the course of aeons, has built something we like but do not understand, then who but a fool would discard seemingly useless parts? To keep every cog and wheel is the first precaution of intelligent tinkering.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "History", "sub_heading": "Global conservation efforts", "_id": "31--2--3---1", "title": "The Evolution of Conservation"}
{"qas": [{"question": "How do scientists estimate the number of species in the world?", "answer": ""}, {"question": "What is the most significant contribution to the scientific understanding of the process of species extinction?", "answer": "The Theory of Island Biogeography", "ae_score": -0.2501880468631825, "qg_score": null}, {"question": "What is the most significant contribution to the scientific understanding of the process of species extinction?", "answer": "The Theory of Island Biogeography", "ae_score": -0.2501880468631825, "qg_score": null}], "content": "Extinction rates are measured in a variety of ways. Conservation biologists measure and apply statistical measures of fossil records, rates of habitat loss, and a multitude of other variables such as loss of biodiversity as a function of the rate of habitat loss and site occupancy to obtain such estimates. ''The Theory of Island Biogeography'' is possibly the most significant contribution toward the scientific understanding of both the process and how to measure the rate of species extinction. The current background extinction rate is estimated to be one species every few years.\nThe measure of ongoing species loss is made more complex by the fact that most of the Earth's species have not been described or evaluated. Estimates vary greatly on how many species actually exist (estimated range: 3,600,000-111,700,000) to how many have received a species binomial (estimated range: 1.5-8 million). Less than 1% of all species that have been described have been studied beyond simply noting its existence. From these figures, the IUCN reports that 23% of vertebrates, 5% of invertebrates and 70% of plants that have been evaluated are designated as endangered or threatened. Better knowledge is being constructed by The Plant List for actual numbers of species.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Concepts and foundations", "_id": "31--3--0---1", "title": "''The Theory of Island Biogeography'': Extinction Rates"}
{"qas": [{"question": "What is systematic conservation planning?", "answer": ""}, {"question": "What is an effective way to seek and identify efficient and effective types of reserve design to?", "answer": "Systematic conservation planning", "ae_score": -0.44955870533959047, "qg_score": null}, {"question": "What is an effective way to seek and identify efficient and effective types of reserve design to?", "answer": "Systematic conservation planning", "ae_score": -0.44955870533959047, "qg_score": null}], "content": "Systematic conservation planning is an effective way to seek and identify efficient and effective types of reserve design to capture or sustain the highest priority biodiversity values and to work with communities in support of local ecosystems. Margules and Pressey identify six interlinked stages in the systematic planning approach:\nConservation biologists regularly prepare detailed conservation plans for grant proposals or to effectively coordinate their plan of action and to identify best management practices (e.g.). Systematic strategies generally employ the services of Geographic Information Systems to assist in the decision making process.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Systematic conservation planning", "_id": "31--3--1---1", "title": "Systematic Conservation Planning"}
{"qas": [{"question": "Conservation Physiology?", "answer": ""}, {"question": "Who is the author of the book conservation biology?", "answer": "Steven J. Cooke", "ae_score": -0.7395313898774128, "qg_score": null}, {"question": "Who is the author of the book conservation biology?", "answer": "Steven J. Cooke", "ae_score": -0.7395313898774128, "qg_score": null}], "content": "Conservation Physiology was defined by Steven J. Cooke and colleagues as: \u2018An integrative scientific discipline applying physiological concepts, tools, and knowledge to characterizing biological diversity and its ecological implications; understanding and predicting how organisms, populations, and ecosystems respond to environmental change and stressors; and solving conservation problems across the broad range of taxa (i.e. including microbes, plants, and animals). Physiology is considered in the broadest possible terms to include functional and mechanistic responses at all scales, and conservation includes the development and refinement of strategies to rebuild populations, restore ecosystems, inform conservation policy, generate decision-support tools, and manage natural resources.\u2019  Conservation physiology is particularly relevant to practitioners in that it has the potential to generate cause-and-effect relationships and reveal the factors that contribute to population declines.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Conservation physiology: a mechanistic approach to conservation", "_id": "31--3--2---1", "title": "Conservation Physiology \u2014 An Integrative Scientific Discipline"}
{"qas": [{"question": "What is the difference between a conservation biologist and a biologist?", "answer": ""}, {"question": "What is the goal of conservation biology?", "answer": "conserving biodiversity", "ae_score": -0.5625453336190072, "qg_score": null}, {"question": "What is the goal of conservation biology?", "answer": "conserving biodiversity", "ae_score": -0.5625453336190072, "qg_score": null}], "content": "The Society for Conservation Biology is a global community of conservation professionals dedicated to advancing the science and practice of conserving biodiversity. Conservation biology as a discipline reaches beyond biology, into subjects such as philosophy, law, economics, humanities, arts, anthropology, and education. Within biology, conservation genetics and evolution are immense fields unto themselves, but these disciplines are of prime importance to the practice and profession of conservation biology.\nIs conservation biology an objective science when biologists advocate for an inherent value in nature? Do conservationists introduce bias when they support policies using qualitative description, such as habitat ''degradation'', or ''healthy'' ecosystems? As all scientists hold values, so do conservation biologists. Conservation biologists advocate for reasoned and sensible management of natural resources and do so with a disclosed combination of science, reason, logic, and values in their conservation management plans. This sort of advocacy is similar to the medical profession advocating for healthy lifestyle options, both are beneficial to human well-being yet remain scientific in their approach.\nThere is a movement in conservation biology suggesting a new form of leadership is needed to mobilize conservation biology into a more effective discipline that is able to communicate the full scope of the problem to society at large. The movement proposes an adaptive leadership approach that parallels an adaptive management approach. The concept is based on a new philosophy or leadership theory steering away from historical notions of power, authority, and dominance. Adaptive conservation leadership is reflective and more equitable as it applies to any member of society who can mobilize others toward meaningful change using communication techniques that are inspiring, purposeful, and collegial. Adaptive conservation leadership and mentoring programs are being implemented by conservation biologists through organizations such as the Aldo Leopold Leadership Program", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Conservation biology as a profession", "_id": "31--3--3---1", "title": "Adaptive Conservation Leadership: A New Leadership Approach"}
{"qas": [{"question": "What is the difference between conservation and ex-situ conservation?", "answer": ""}, {"question": "Which type of conservation involves protecting an endangered species in its natural habitat?", "answer": "in-situ conservation", "ae_score": -0.5915957423102283, "qg_score": null}, {"question": "Which type of conservation involves protecting an endangered species in its natural habitat?", "answer": "in-situ conservation", "ae_score": -0.5915957423102283, "qg_score": null}], "content": "Conservation may be classified as either in-situ conservation, which is protecting an endangered species in its natural habitat, or ex-situ conservation, which occurs outside the natural habitat. In-situ conservation involves protecting or restoring the habitat. Ex-situ conservation, on the other hand, involves protection outside of an organism's natural habitat, such as on reservations or in gene banks, in circumstances where viable populations may not be present in the natural habitat.\nAlso, non-interference may be used, which is termed a preservationist method. Preservationists advocate for giving areas of nature and species a protected existence that halts interference from the humans. In this regard, conservationists differ from preservationists in the social dimension, as conservation biology engages society and seeks equitable solutions for both society and ecosystems. Some preservationists emphasize the potential of biodiversity in a world without humans.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Approaches", "_id": "31--3--4---1", "title": "Conservationists and Conservationists"}
{"qas": [{"question": "What is the difference between a conservation biologist and a conservationist?", "answer": ""}, {"question": "Who is regarded as a classical thinker and writer on conservation ethics?", "answer": "Aldo Leopold", "ae_score": -0.3354324939359706, "qg_score": null}, {"question": "Who is regarded as a classical thinker and writer on conservation ethics?", "answer": "Aldo Leopold", "ae_score": -0.3354324939359706, "qg_score": null}], "content": "Conservation biologists are interdisciplinary researchers that practice ethics in the biological and social sciences. Chan states that conservationists must advocate for biodiversity and can do so in a scientifically ethical manner by not promoting simultaneous advocacy against other competing values. A conservationist researches biodiversity and reasons through a Resource Conservation Ethic , which identify what measures will deliver \"the greatest good for the greatest number of people for the longest time.\"\nSome conservation biologists argue that nature has an intrinsic value that is independent of anthropocentric usefulness or utilitarianism. Intrinsic value advocates that a gene, or species, be valued because they have a utility for the ecosystems they sustain. Aldo Leopold was a classical thinker and writer on such conservation ethics whose philosophy, ethics and writings are still valued and revisited by modern conservation biologists. His writing is often required reading for those in the profession.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Ethics and values", "_id": "31--3--5---1", "title": "Conservation Ethics and Ethics"}
{"qas": [{"question": "What is the difference between a hotspot and a conservation approach?", "answer": ""}, {"question": "What percentage of all species in four vertebrate groups are confined to 25 hotspots?", "answer": "35%", "ae_score": -0.3723527632482225, "qg_score": null}, {"question": "What percentage of all species in four vertebrate groups are confined to 25 hotspots?", "answer": "35%", "ae_score": -0.3723527632482225, "qg_score": null}], "content": "The International Union for the Conservation of Nature (IUCN) has organized a global assortment of scientists and research stations across the planet to monitor the changing state of nature in an effort to tackle the extinction crisis. The IUCN provides annual updates on the status of species conservation through its Red List. The IUCN Red List serves as an international conservation tool to identify those species most in need of conservation attention and by providing a global index on the status of biodiversity. More than the dramatic rates of species loss, however, conservation scientists note that the sixth mass extinction is a biodiversity crisis requiring far more action than a priority focus on rare, endemic or endangered species. Concerns for biodiversity loss covers a broader conservation mandate that looks at ecological processes, such as migration, and a holistic examination of biodiversity at levels beyond the species, including genetic, population and ecosystem diversity. Extensive, systematic, and rapid rates of biodiversity loss threatens the sustained well-being of humanity by limiting supply of ecosystem services that are otherwise regenerated by the complex and evolving holistic network of genetic and ecosystem diversity. While the conservation status of species is employed extensively in conservation management, some scientists highlight that it is the common species that are the primary source of exploitation and habitat alteration by humanity. Moreover, common species are often undervalued despite their role as the primary source of ecosystem services.\nWhile most in the community of conservation science \"stress the importance\" of sustaining biodiversity, there is debate on how to prioritize genes, species, or ecosystems, which are all components of biodiversity (e.g. Bowen, 1999). While the predominant approach to date has been to focus efforts on endangered species by conserving ''biodiversity hotspots'', some scientists (e.g) and conservation organizations, such as the Nature Conservancy, argue that it is more cost-effective, logical, and socially relevant to invest in ''biodiversity coldspots''. The costs of discovering, naming, and mapping out the distribution of every species, they argue, is an ill-advised conservation venture. They reason it is better to understand the significance of the ecological roles of species.\nBiodiversity hotspots and coldspots are a way of recognizing that the spatial concentration of genes, species, and ecosystems is not uniformly distributed on the Earth's surface. For example, \"[...] 44% of all species of vascular plants and 35% of all species in four vertebrate groups are confined to 25 hotspots comprising only 1.4% of the land surface of the Earth.\"\nThose arguing in favor of setting priorities for coldspots point out that there are other measures to consider beyond biodiversity. They point out that emphasizing hotspots downplays the importance of the social and ecological connections to vast areas of the Earth's ecosystems where biomass, not biodiversity, reigns supreme. It is estimated that 36% of the Earth's surface, encompassing 38.9% of the worlds vertebrates, lacks the endemic species to qualify as biodiversity hotspot. Moreover, measures show that maximizing protections for biodiversity does not capture ecosystem services any better than targeting randomly chosen regions. Population level biodiversity (i.e. coldspots) are disappearing at a rate that is ten times that at the species level. The level of importance in addressing biomass versus endemism as a concern for conservation biology is highlighted in literature measuring the level of threat to global ecosystem carbon stocks that do not necessarily reside in areas of endemism. A hotspot priority approach would not invest so heavily in places such as steppes, the Serengeti, the Arctic, or taiga. These areas contribute a great abundance of population (not species) level biodiversity and ecosystem services, including cultural value and planetary nutrient cycling.\nThose in favor of the hotspot approach point out that species are irreplaceable components of the global ecosystem, they are concentrated in places that are most threatened, and should therefore receive maximal strategic protections. The IUCN Red List categories, which appear on Wikipedia species articles, is an example of the hotspot conservation approach in action; species that are not rare or endemic are listed the least concern and their Wikipedia articles tend to be ranked low on the importance scale. This is a hotspot approach because the priority is set to target species level concerns over population level or biomass. Species richness and genetic biodiversity contributes to and engenders ecosystem stability, ecosystem processes, evolutionary adaptability, and biomass. Both sides agree, however, that conserving biodiversity is necessary to reduce the extinction rate and identify an inherent value in nature; the debate hinges on how to prioritize limited conservation resources in the most cost-effective way.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Conservation priorities", "_id": "31--3--6---1", "title": "Biodiversity Hotspots and Coldspots"}
{"qas": [{"question": "Why is there so much biodiversity loss in places like Africa?", "answer": ""}, {"question": "What is the system of accounting used by conservation biologists called?", "answer": "natural capital", "ae_score": -0.6909650772784867, "qg_score": null}, {"question": "What is the system of accounting used by conservation biologists called?", "answer": "natural capital", "ae_score": -0.6909650772784867, "qg_score": null}], "content": "Conservation biologists have started to collaborate with leading global economists to determine how to measure the wealth and services of nature and to make these values apparent in global market transactions. This system of accounting is called ''natural capital'' and would, for example, register the value of an ecosystem before it is cleared to make way for development. The WWF publishes its ''Living Planet Report'' and provides a global index of biodiversity by monitoring approximately 5,000 populations in 1,686 species of vertebrate (mammals, birds, fish, reptiles, and amphibians) and report on the trends in much the same way that the stock market is tracked.\nThis method of measuring the global economic benefit of nature has been endorsed by the G8+5 leaders and the European Commission. Nature sustains many ecosystem services that benefit humanity. Many of the earths ecosystem services are public goods without a market and therefore no price or value. When the ''stock market'' registers a financial crisis, traders on Wall Street are not in the business of trading stocks for much of the planet's living natural capital stored in ecosystems. There is no natural stock market with investment portfolios into sea horses, amphibians, insects, and other creatures that provide a sustainable supply of ecosystem services that are valuable to society. The ecological footprint of society has exceeded the bio-regenerative capacity limits of the planet's ecosystems by about 30 percent, which is the same percentage of vertebrate populations that have registered decline from 1970 through 2005.\nThe inherent natural economy plays an essential role in sustaining humanity, including the regulation of global atmospheric chemistry, pollinating crops, pest control, cycling soil nutrients, purifying our water supply, supplying medicines and health benefits, and unquantifiable quality of life improvements. There is a relationship, a correlation, between markets and natural capital, and social income inequity and biodiversity loss. This means that there are greater rates of biodiversity loss in places where the inequity of wealth is greatest\nAlthough a direct market comparison of natural capital is likely insufficient in terms of human value, one measure of ecosystem services suggests the contribution amounts to trillions of dollars yearly. For example, one segment of North American forests has been assigned an annual value of 250 billion dollars; as another example, honey-bee pollination is estimated to provide between 10 and 18 billion dollars of value yearly. The value of ecosystem services on one New Zealand island has been imputed to be as great as the GDP of that region. This planetary wealth is being lost at an incredible rate as the demands of human society is exceeding the bio-regenerative capacity of the Earth. While biodiversity and ecosystems are resilient, the danger of losing them is that humans cannot recreate many ecosystem functions through technological innovation.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Economic values and natural capital", "_id": "31--3--7---1", "title": "How to Measure the Wealth and Services of Nature"}
{"qas": [{"question": "How do scientists know what species are in the wild?", "answer": ""}, {"question": "Which butterfly is an example of an umbrella species?", "answer": "monarch butterfly", "ae_score": -0.7349390235866493, "qg_score": null}, {"question": "Which butterfly is an example of an umbrella species?", "answer": "monarch butterfly", "ae_score": -0.7349390235866493, "qg_score": null}], "content": "Some species, called a ''keystone species'' form a central supporting hub unique to their the ecosystem. The loss of such a species results in a collapse in ecosystem function, as well as the loss of coexisting species. Keystone species are usually predators due to their ability to control the population of prey in their ecosystem. The importance of a keystone species was shown by the extinction of the Steller's sea cow (''Hydrodamalis gigas'') through its interaction with sea otters, sea urchins, and kelp. Kelp beds grow and form nurseries in shallow waters to shelter creatures that support the food chain. Sea urchins feed on kelp, while sea otters feed on sea urchins. With the rapid decline of sea otters due to overhunting, sea urchin populations grazed unrestricted on the kelp beds and the ecosystem collapsed. Left unchecked, the urchins destroyed the shallow water kelp communities that supported the Steller's sea cow's diet and hastened their demise. The sea otter was thought to be a keystone species because the coexistence of many ecological associates in the kelp beds relied upon otters for their survival. However this was later questioned by Turvey and Risley, who showed that hunting alone would have driven the Steller's sea cow extinct.\nAn ''indicator species'' has a narrow set of ecological requirements, therefore they become useful targets for observing the health of an ecosystem. Some animals, such as amphibians with their semi-permeable skin and linkages to wetlands, have an acute sensitivity to environmental harm and thus may serve as a ''miner's canary''. Indicator species are monitored in an effort to capture environmental degradation through pollution or some other link to proximate human activities. Monitoring an indicator species is a measure to determine if there is a significant environmental impact that can serve to advise or modify practice, such as through different forest silviculture treatments and management scenarios, or to measure the degree of harm that a pesticide may impart on the health of an ecosystem.\nGovernment regulators, consultants, or NGOs regularly monitor indicator species, however, there are limitations coupled with many practical considerations that must be followed for the approach to be effective. It is generally recommended that multiple indicators (genes, populations, species, communities, and landscape) be monitored for effective conservation measurement that prevents harm to the complex, and often unpredictable, response from ecosystem dynamics (Noss, 1997).\nAn example of an ''umbrella species'' is the monarch butterfly, because of its lengthy migrations and aesthetic value. The monarch migrates across North America, covering multiple ecosystems and so requires a large area to exist. Any protections afforded to the monarch butterfly will at the same time umbrella many other species and habitats. An umbrella species is often used as ''flagship species'', which are species, such as the giant panda, the blue whale, the tiger, the mountain gorilla and the monarch butterfly, that capture the public's attention and attract support for conservation measures.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Concepts and foundations", "sub_heading": "Strategic species concepts", "_id": "31--3--8---1", "title": "Monitoring Indicator Species for Conservation"}
{"qas": [{"question": "Why is the extinction rate so high?", "answer": ""}, {"question": "What percentage of all surviving species are threatened with extinction according to the global amphibian assessment?", "answer": "over 32%", "ae_score": -0.8082978626780908, "qg_score": null}, {"question": "What percentage of all surviving species are threatened with extinction according to the global amphibian assessment?", "answer": "over 32%", "ae_score": -0.8082978626780908, "qg_score": null}], "content": "Conservation biologists are dealing with and have published evidence from all corners of the planet indicating that humanity may be causing the sixth and fastest planetary extinction event. It has been suggested that we are living in an era of unprecedented numbers of species extinctions, also known as the Holocene extinction event. The global extinction rate may be approximately 1,000 times higher than the natural background extinction rate. It is estimated that two-thirds of all mammal genera and one-half of all mammal species weighing at least 44 kg have gone extinct in the last 50,000 years.<ref name=pmid17148336/> The Global Amphibian Assessment reports that amphibians are declining on a global scale faster than any other vertebrate group, with over 32% of all surviving species being threatened with extinction. The surviving populations are in continual decline in 43% of those that are threatened. Since the mid-1980s the actual rates of extinction have exceeded 211 times rates measured from the fossil record. However, \"The current amphibian extinction rate may range from 25,039 to 45,474 times the background extinction rate for amphibians.\" The global extinction trend occurs in every major vertebrate group that is being monitored. For example, 23% of all mammals and 12% of all birds are Red Listed by the International Union for Conservation of Nature (IUCN), meaning they too are threatened with extinction. Even though extinction is natural, the decline in species is happening at such an incredible rate that evolution can simply not match, therefore, leading to the greatest continual mass extinction on Earth. Humans have dominated the planet and our high consumption of resources, along with the pollution generated is affecting the environments in which other species live. There are a wide variety of species that humans are working to protect such as the Hawaiian Crow and the Whooping Crane of Texas. People can also take action on preserving species by advocating and voting for policies that improve climate. The Earth's oceans especially require attention, as climate change has altered pH levels making it inhabitable for organisms with shells, that are dissolving as a result.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Context and trends", "sub_heading": "Context and trends", "_id": "31--4--0---1", "title": "The Global Extinction Event: Humans are causing the 6th and Fastest"}
{"qas": [{"question": "Is there any hope of averting mass extinction in the ocean?", "answer": ""}, {"question": "By 2000, what percentage of the world's coral reef ecosystems had effectively collapsed?", "answer": "27%", "ae_score": -0.2952862406111071, "qg_score": null}, {"question": "By 2000, what percentage of the world's coral reef ecosystems had effectively collapsed?", "answer": "27%", "ae_score": -0.2952862406111071, "qg_score": null}], "content": "Global assessments of coral reefs of the world continue to report drastic and rapid rates of decline. By 2000, 27% of the world's coral reef ecosystems had effectively collapsed. The largest period of decline occurred in a dramatic \"bleaching\" event in 1998, where approximately 16% of all the coral reefs in the world disappeared in less than a year. ''Coral bleaching'' is caused by a mixture of environmental stresses, including increases in ocean temperatures and acidity, causing both the release of symbiotic algae and death of corals. Decline and extinction risk in coral reef biodiversity has risen dramatically in the past ten years. The loss of coral reefs, which are predicted to go extinct in the next century, threatens the balance of global biodiversity, will have huge economic impacts, and endangers food security for hundreds of millions of people.  Conservation biology plays an important role in international agreements covering the world's oceans (and other issues pertaining to biodiversity).\nThe oceans are threatened by acidification due to an increase in CO levels. This is a most serious threat to societies relying heavily upon oceanic natural resources. A concern is that the majority of all marine species will not be able to evolve or acclimate in response to the changes in the ocean chemistry.\nThe prospects of averting mass extinction seems unlikely when \"[...] 90% of all of the large (average approximately \u226550 kg), open ocean tuna, billfishes, and sharks in the ocean\" are reportedly gone. Given the scientific review of current trends, the ocean is predicted to have few surviving multi-cellular organisms with only microbes left to dominate marine ecosystems.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Context and trends", "sub_heading": "Status of oceans and reefs", "_id": "31--4--1---1", "title": "The Threat to the World's Coral Reef Biodiversity"}
{"qas": [{"question": "Why are so many people against the conservation of insects?", "answer": ""}, {"question": "Which insect has infested 470000 km2 of forested land since 1999?", "answer": "mountain pine beetle", "ae_score": -0.6174497428420248, "qg_score": null}, {"question": "Which insect has infested 470000 km2 of forested land since 1999?", "answer": "mountain pine beetle", "ae_score": -0.6174497428420248, "qg_score": null}], "content": "Serious concerns also being raised about taxonomic groups that do not receive the same degree of social attention or attract funds as the vertebrates. These include fungal (including lichen-forming species), invertebrate (particularly insect) and plant communities where the vast majority of biodiversity is represented. Conservation of fungi and conservation of insects, in particular, are both of pivotal importance for conservation biology. As mycorrhizal symbionts, and as decomposers and recyclers, fungi are essential for sustainability of forests. The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness. The greatest bulk of biomass on land is found in plants, which is sustained by insect relations. This great ecological value of insects is countered by a society that often reacts negatively toward these aesthetically 'unpleasant' creatures.\nOne area of concern in the insect world that has caught the public eye is the mysterious case of missing honey bees (''Apis mellifera''). Honey bees provide an indispensable ecological services through their acts of pollination supporting a huge variety of agriculture crops. The use of honey and wax have become vastly used throughout the world. The sudden disappearance of bees leaving empty hives or colony collapse disorder (CCD) is not uncommon. However, in  16-month period from 2006 through 2007, 29% of 577 beekeepers across the United States reported CCD losses in up to 76% of their colonies. This sudden demographic loss in bee numbers is placing a strain on the agricultural sector. The cause behind the massive declines is puzzling scientists. Pests, pesticides, and global warming are all being considered as possible causes.\nAnother highlight that links conservation biology to insects, forests, and climate change is the mountain pine beetle (''Dendroctonus ponderosae'') epidemic of British Columbia, Canada, which has infested 470000 km2 of forested land since 1999. An action plan has been prepared by the Government of British Columbia to address this problem.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Context and trends", "sub_heading": "Groups other than vertebrates", "_id": "31--4--2---1", "title": "Conservation Biology \u2014 Insects, Forests, and Climate Change"}
{"qas": [{"question": "Are parasite species threatened by extinction?", "answer": ""}, {"question": "What are a large proportion of parasite species threatened by?", "answer": "extinction", "ae_score": -0.47417519599680924, "qg_score": null}, {"question": "What are a large proportion of parasite species threatened by?", "answer": "extinction", "ae_score": -0.47417519599680924, "qg_score": null}], "content": "A large proportion of parasite species are threatened by extinction. A few of them are being eradicated as pests of humans or domestic animals, however, most of them are harmless. Threats include the decline or fragmentation of host populations, or the extinction of host species.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Context and trends", "sub_heading": "Conservation biology of parasites", "_id": "31--4--3---1", "title": "Parasites are threatened by extinction."}
{"qas": [{"question": "Why is it so important that humans continue to contribute to the ecosystem?", "answer": ""}, {"question": "What is the main threat to biodiversity?", "answer": "habitat destruction", "ae_score": -0.4540962184358283, "qg_score": null}, {"question": "What is the main threat to biodiversity?", "answer": "habitat destruction", "ae_score": -0.4540962184358283, "qg_score": null}], "content": "Today, many threats to Biodiversity exist. An acronym that can be used to express the top threats of present-day H.I.P.P.O stands for Habitat Loss, Invasive Species, Pollution, Human Population, and Overharvesting. The primary threats to biodiversity are habitat destruction (such as deforestation, agricultural expansion, urban development), and overexploitation (such as wildlife trade). Habitat fragmentation also poses challenges, because the global network of protected areas only covers 11.5% of the Earth's surface.  A significant consequence of fragmentation and lack of linked protected areas is the reduction of animal migration on a global scale. Considering that billions of tonnes of biomass are responsible for nutrient cycling across the earth, the reduction of migration is a serious matter for conservation biology.\nHowever, human activities need not necessarily cause irreparable harm to the biosphere. With conservation management and planning for biodiversity at all levels, from genes to ecosystems, there are examples where humans mutually coexist in a sustainable way with nature. Even with the current threats to biodiversity there are ways we can improve the current condition and start anew.\nMany of the threats to biodiversity, including disease and climate change, are reaching inside borders of protected areas, leaving them 'not-so protected' (e.g. Yellowstone National Park). Climate change, for example, is often cited as a serious threat in this regard, because there is a feedback loop between species extinction and the release of carbon dioxide into the atmosphere. Ecosystems store and cycle large amounts of carbon which regulates global conditions. In present day, there have been major climate shifts with temperature changes making survival of some species difficult. The effects of global warming add a catastrophic threat toward a mass extinction of global biological diversity. Conservationists have claimed that not all the species can be saved, and they have to decide which their efforts should be used to protect. This concept is known as the Conservation Triage. The extinction threat is estimated to range from 15 to 37 percent of all species by 2050, or 50 percent of all species over the next 50 years. The current extinction rate is 100-100,000 times more rapid today than the last several billion years.", "page_name": "Conservation biology", "page_id": "Conservation%20biology", "heading": "Context and trends", "sub_heading": "Threats to biodiversity", "_id": "31--4--4---1", "title": "The Threats to Biodiversity \u2014 How to Start anew"}
{"qas": [{"question": "What is the state of food insecurity in the world?", "answer": ""}, {"question": "Who commissioned the national academy of sciences study?", "answer": "USDA", "ae_score": null, "qg_score": null}, {"question": "Who commissioned the national academy of sciences study?", "answer": "USDA", "ae_score": null, "qg_score": null}], "content": "Food security indicators and measures are derived from country level household income and expenditure surveys to estimate per capita caloric availability. In general the objective of food security indicators and measures is to capture some or all of the main components of food security in terms of food availability, access and utilization or adequacy. While availability (production and supply) and utilization/adequacy (nutritional status/anthropometric measures) seemed much easier to estimate, thus more popular, access (ability to acquire sufficient quantity and quality) remain largely elusive. The factors influencing household food access are often context specific. Thus the financial and technical demands of collecting and analyzing data on all aspects of household's experience of food access and the development of valid and clear measures remain a huge challenge.Nevertheless, several measures have been developed that aim to capture the access component of food security, with some notable examples developed by the USAID-funded Food and Nutrition Technical Assistance (FANTA) project, collaborating with Cornell and Tufts University and Africare and World Vision. These include:\nFood insecurity is measured in the United States by questions in the Census Bureau's Current Population Survey. The questions asked are about anxiety that the household budget is inadequate to buy enough food, inadequacy in the quantity or quality of food eaten by adults and children in the household, and instances of reduced food intake or consequences of reduced food intake for adults and for children. A National Academy of Sciences study commissioned by the USDA criticized this measurement and the relationship of \"food security\" to hunger, adding \"it is not clear whether hunger is appropriately identified as the extreme end of the food security scale.\"\nThe FAO, World Food Programme (WFP), and International Fund for Agricultural Development (IFAD) collaborate to produce ''The State of Food Insecurity in the World''. The 2012 edition described improvements made by the FAO to the prevalence of undernourishment (PoU) indicator that is used to measure rates of food insecurity. New features include revised minimum dietary energy requirements for individual countries, updates to the world population data, and estimates of food losses in retail distribution for each country. Measurements that factor into the indicator include dietary energy supply, food production, food prices, food expenditures, and volatility of the food system. The stages of food insecurity range from food secure situations to full-scale famine.A new peer-reviewed journal of ''Food Security: The Science, Sociology and Economics of Food Production and Access to Food'' began publishing in 2009.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Measurement", "sub_heading": "Measurement", "_id": "32--0---1---1", "title": "Food Security: The Science, Sociology and Economics of Food Production and Access to Food"}
{"qas": [{"question": "Why are so many people in the world chronically undernourished?", "answer": ""}, {"question": "How many people were chronically undernourished in the years 2010-2012?", "answer": "almost 870 million", "ae_score": -0.6597773433245677, "qg_score": null}, {"question": "How many people were chronically undernourished in the years 2010-2012?", "answer": "almost 870 million", "ae_score": -0.6597773433245677, "qg_score": null}], "content": "With its prevalence of undernourishment (PoU) indicator, the FAO reported that almost 870 million people were chronically undernourished in the years 2010-2012. This represents 12.5% of the global population, or 1 in 8 people. Higher rates occur in developing countries, where 852 million people (about 15% of the population) are chronically undernourished. The report noted that Asia and Latin America have achieved reductions in rates of undernourishment that put these regions on track for achieving the Millennium Development Goal of halving the prevalence of undernourishment by 2015.  The UN noted that about 2 billion people do not consume a sufficient amount of vitamins and minerals. In India, the second-most populous country in the world, 30 million people have been added to the ranks of the hungry since the mid-1990s and 46% of children are underweight.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Rates", "sub_heading": "Rates", "_id": "32--1---1---1", "title": "The World\u2019s Most Undernourished People are Undernourished"}
{"qas": [{"question": "Why are grain prices so high right now?", "answer": ""}, {"question": "When did food riots occur in many countries?", "answer": "2011", "ae_score": -0.8435010769086948, "qg_score": null}, {"question": "When did food riots occur in many countries?", "answer": "2011", "ae_score": -0.8435010769086948, "qg_score": null}], "content": "In late 2007, export restrictions and panic buying, US dollar depreciation,  increased farming for use in biofuels, world oil prices at more than $100 a barrel, global population growth, climate change, loss of agricultural land to residential and industrial development, and growing consumer demand in China and India are claimed to have pushed up the price of grain. However, the role of some of these factors is under debate. Some argue the role of biofuel has been overplayed as grain prices have come down to the levels of 2006. Nonetheless, food riots took place in many countries across the world in 2011.", "page_name": "Food security", "page_id": "Food%20security", "heading": "History", "sub_heading": "History", "_id": "32--2---1---1", "title": "The Role of Biofuels in the Rise of Food Prices"}
{"qas": [{"question": "What is the difference between the US and UK voting systems?", "answer": ""}, {"question": "When was food security introduced in the united states?", "answer": "2012", "ae_score": -0.18441302355346614, "qg_score": null}, {"question": "When was food security introduced in the united states?", "answer": "2012", "ae_score": -0.18441302355346614, "qg_score": null}], "content": "The United States Department of Agriculture defines food insecurity as \"limited or uncertain availability of nutritionally adequate and safe foods or limited or uncertain ability to acquire acceptable foods in socially acceptable ways.\"  \nNational Food Security Surveys are the main survey tool used by the USDA to measure food security in the United States. Based on respondents' answers to survey questions, the household can be placed on a continuum of food security defined by the USDA. This continuum has four categories: high food security, marginal food security, low food security, and very low food security.  Economic Research Service report number 155 (ERS-155) estimates that 14.5 percent (17.6 million) of US households were food insecure at some point in 2012. The prevalence of food insecurity has been relatively in the United States since the economic recession 2008.\nIn 2012:\nThe government of the United States has taken up an initiative along with other local government agencies as well as global partners, the G8 countries, and donors to reduce global hunger and to improve food security conditions in the world. Exploiting the G8 Summit of 2009 held in L'Aquila, Italy, President Barack Obama encouraged global leaders to revert the three-decade old trend of reduced agricultural investments, and instead, choose to increase cash flow in their respective agricultural sectors in a drive to bolster global food security. This led to the birth of the \"Feed the Future\" program.\nInitially, the U.S had been successful in collecting over $18 billion in funds for the program from the G8 countries as well as other donors. The \"Feed the Future\" initiative is presently led by the U.S Agency for International Development and has the support of other government-funded bodies like the State Department, Peace Corps, Millennium Challenge Corporation, the Treasury Department, U.S. Trade Representative, Overseas Private Investment Corporation, the U.S. African Development Foundation, and the U.S Department of Agriculture.\nThe target group of this initiative is the small holder farmers, especially women. Feed the Future has plans to help partner countries to develop their agricultural sector with an aim to improve their agricultural output. A spurt in economic growth would ultimately lead to higher income and help to eradicate hunger, and poverty, as well as under nutrition from the society. This initiative is expected to work on the basis of country-led priorities that call for consistent support by the governments, donor organizations, the private sector, and the civil society to accomplish its long-term goals.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Food security in the US", "sub_heading": "Food security in the US", "_id": "32--3---1---1", "title": "Feed the Future: A Global Initiative to Improve Food Security in the United States"}
{"qas": [{"question": "Why is there no World Food Security summit in Rome?", "answer": ""}, {"question": "Who was the director general of the fao in june 2009?", "answer": "Dr Jacques Diouf", "ae_score": -0.21635993677827722, "qg_score": null}, {"question": "Who was the director general of the fao in june 2009?", "answer": "Dr Jacques Diouf", "ae_score": -0.21635993677827722, "qg_score": null}], "content": "The World Summit on Food Security held in Rome in 1996, aimed to renew a global commitment to the fight against hunger. The Food and Agriculture Organization of the United Nations (FAO) called the summit in response to widespread under-nutrition and growing concern about the capacity of agriculture to meet future food needs. The conference produced two key documents, the Rome Declaration on World Food Security and the World Food Summit Plan of Action.\nThe Rome Declaration calls for the members of the United Nations to work to halve the number of chronically undernourished people on the Earth by the year 2015. The Plan of Action sets a number of targets for government and non-governmental organizations for achieving food security, at the individual, household, national, regional and global levels.\nAnother World Summit on Food Security took place in Rome between November 16 and 18, 2009. The decision to convene the summit was taken by the Council of FAO in June 2009, at the proposal of FAO Director-General Dr Jacques Diouf. Heads of State and Government attended the summit, which took place at the FAO's headquarters.", "page_name": "Food security", "page_id": "Food%20security", "heading": "World Summit on Food Security", "sub_heading": "World Summit on Food Security", "_id": "32--4---1---1", "title": "World Food Summit Plan of Action"}
{"qas": [{"question": "How do countries achieve food security?", "answer": ""}, {"question": "What relates to the supply of food through production, distribution and exchange?", "answer": "Food availability", "ae_score": -0.6659580308323152, "qg_score": null}, {"question": "What relates to the supply of food through production, distribution and exchange?", "answer": "Food availability", "ae_score": -0.6659580308323152, "qg_score": null}], "content": "Food availability relates to the supply of food through production, distribution, and exchange. Food production is determined by a variety of factors including land ownership and use; soil management; crop selection, breeding, and management; livestock breeding and management; and harvesting. Crop production can be affected by changes in rainfall and temperatures. The use of land, water, and energy to grow food often competes with other uses, which can affect food production. Land used for agriculture can be used for urbanization or lost to desertification, salinization, and soil erosion due to unsustainable agricultural practices. Crop production is not required for a country to achieve food security. Nations don't have to have the natural resources required to produce crops in order to achieve food security, as seen in the examples of Japan and Singapore.\nBecause food consumers outnumber producers in every country, food must be distributed to different regions or nations. Food distribution involves the storage, processing, transport, packaging, and marketing of food. Food-chain infrastructure and storage technologies on farms can also affect the amount of food wasted in the distribution process. Poor transport infrastructure can increase the price of supplying water and fertilizer as well as the price of moving food to national and global markets. Around the world, few individuals or households are continuously self-reliant for food. This creates the need for a bartering, exchange, or cash economy to acquire food. The exchange of food requires efficient trading systems and market institutions, which can affect food security. Per capita world food supplies are more than adequate to provide food security to all, and thus food accessibility is a greater barrier to achieving food security.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Pillars of food security", "sub_heading": "Pillars of food security", "_id": "32--5--0---1", "title": "Food Accessibility and Food Security"}
{"qas": [{"question": "How does access to food work?", "answer": ""}, {"question": "What refers to the affordability and allocation of food and the preferences of individuals and households?", "answer": "Food access", "ae_score": -0.5154496612964534, "qg_score": null}, {"question": "What refers to the affordability and allocation of food and the preferences of individuals and households?", "answer": "Food access", "ae_score": -0.5154496612964534, "qg_score": null}], "content": "Food access refers to the affordability and allocation of food, as well as the preferences of individuals and households. The UN Committee on Economic, Social, and Cultural Rights noted that the causes of hunger and malnutrition are often not a scarcity of food but an inability to access available food, usually due to poverty. Poverty can limit access to food, and can also increase how vulnerable an individual or household is to food price spikes. Access depends on whether the household has enough income to purchase food at prevailing prices or has sufficient land and other resources to grow its own food. Households with enough resources can overcome unstable harvests and local food shortages and maintain their access to food.\nThere are two distinct types of access to food: direct access, in which a household produces food using human and material resources, and economic access, in which a household purchases food produced elsewhere. Location can affect access to food and which type of access a family will rely on. The assets of a household, including income, land, products of labor, inheritances, and gifts can determine a household's access to food. However, the ability to access to sufficient food may not lead to the purchase of food over other materials and services. Demographics and education levels of members of the household as well as the gender of the household head determine the preferences of the household, which influences the type of food that are purchased. A household's access to enough and nutritious food may not assure adequate food intake of all household members, as intrahousehold food allocation may not sufficiently meet the requirements of each member of the household. The USDA adds that access to food must be available in socially acceptable ways, without, for example, resorting to emergency food supplies, scavenging, stealing, or other coping strategies.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Pillars of food security", "sub_heading": "Access", "_id": "32--5--1---1", "title": "Access to Food \u2014 A Guide"}
{"qas": [{"question": "How does food security work?", "answer": ""}, {"question": "What is the next pillar of food security?", "answer": "food utilization", "ae_score": -0.34422258337550776, "qg_score": null}, {"question": "What is the next pillar of food security?", "answer": "food utilization", "ae_score": -0.34422258337550776, "qg_score": null}], "content": "The next pillar of food security is food utilization, which refers to the metabolism of food by individuals. Once food is obtained by a household, a variety of factors affect the quantity and quality of food that reaches members of the household. In order to achieve food security, the food ingested must be safe and must be enough to meet the physiological requirements of each individual. Food safety affects food utilization, and can be affected by the preparation, processing, and cooking of food in the community and household. Nutritional values of the household determine food choice, and whether food meets cultural preferences is important to utilization in terms of psychological and social well-being. Access to healthcare is another determinant of food utilization, since the health of individuals controls how the food is metabolized. For example, intestinal parasites can take nutrients from the body and decrease food utilization. Sanitation can also decrease the occurrence and spread of diseases that can affect food utilization. Education about nutrition and food preparation can affect food utilization and improve this pillar of food security. education bring accountability among people,create awareness,which foster them for food security", "page_name": "Food security", "page_id": "Food%20security", "heading": "Pillars of food security", "sub_heading": "Utilization", "_id": "32--5--2---1", "title": "Food Security \u2014 Food Safety, Food Utilization, and Access to Healthcare"}
{"qas": [{"question": "What is chronic food insecurity?", "answer": ""}, {"question": "The ability to obtain food over time is known as?", "answer": "Food stability", "ae_score": -0.3438757836454386, "qg_score": null}, {"question": "The ability to obtain food over time is known as?", "answer": "Food stability", "ae_score": -0.3438757836454386, "qg_score": null}], "content": "Food stability refers to the ability to obtain food over time. Food insecurity can be transitory, seasonal, or chronic. In transitory food insecurity, food may be unavailable during certain periods of time. At the food production level, natural disasters and drought result in crop failure and decreased food availability. Civil conflicts can also decrease access to food. Instability in markets resulting in food-price spikes can cause transitory food insecurity. Other factors that can temporarily cause food insecurity are loss of employment or productivity, which can be caused by illness. Seasonal food insecurity can result from the regular pattern of growing seasons in food production.\nChronic (or permanent) food insecurity is defined as the long-term, persistent lack of adequate food. In this case, households are constantly at risk of being unable to acquire food to meet the needs of all members. Chronic and transitory food insecurity are linked, since the reoccurrence of transitory food security can make households more vulnerable to chronic food insecurity.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Pillars of food security", "sub_heading": "Stability", "_id": "32--5--3---1", "title": "Food Insecurity \u2014 Food Stability, Seasonal Food Insecurity, and Chronic Food In"}
{"qas": [{"question": "Why is it so hard to stop hunger?", "answer": ""}, {"question": "What are famine and hunger rooted in?", "answer": "food insecurity", "ae_score": -0.1910955107169847, "qg_score": null}, {"question": "What are famine and hunger rooted in?", "answer": "food insecurity", "ae_score": -0.1910955107169847, "qg_score": null}], "content": "\"Famine and hunger are both rooted in food insecurity. Chronic food insecurity translates into a high degree of vulnerability to famine and hunger; ensuring food security presupposes elimination of that vulnerability.\"\nMany countries experience ongoing food shortages and distribution problems. These result in chronic and often widespread hunger amongst significant numbers of people. Human populations can respond to chronic hunger and malnutrition by decreasing body size, known in medical terms as stunting or stunted growth. This process starts ''in utero'' if the mother is malnourished and continues through approximately the third year of life. It leads to higher infant and child mortality, but at rates far lower than during famines. Once stunting has occurred, improved nutritional intake after the age of about two years is unable to reverse the damage. Stunting itself can be viewed as a coping mechanism,  bringing body size into alignment with the calories available during adulthood in the location where the child is born. Limiting body size as a way of adapting to low levels of energy (calories) adversely affects health in three ways:", "page_name": "Food security", "page_id": "Food%20security", "heading": "Effects of food insecurity", "sub_heading": "Effects of food insecurity", "_id": "32--6---1---1", "title": "How Stunting Reduces Body Size During Hunger and Famine"}
{"qas": [{"question": "What will happen to the world's food supply if the world runs out of water?", "answer": ""}, {"question": "How many african people live in a water-stressed environment?", "answer": "300 million", "ae_score": -0.4429340765154181, "qg_score": null}, {"question": "How many african people live in a water-stressed environment?", "answer": "300 million", "ae_score": -0.4429340765154181, "qg_score": null}], "content": "Water deficits, which are already spurring heavy grain imports in numerous smaller countries, may soon do the same in larger countries, such as China or India. The water tables are falling in scores of countries (including northern China, the US, and India) due to widespread overpumping using powerful diesel and electric pumps. Other countries affected include Pakistan, Afghanistan, and Iran. This will eventually lead to water scarcity and cutbacks in grain harvest. Even with the overpumping of its aquifers, China is developing a grain deficit. When this happens, it will almost certainly drive grain prices upward. Most of the 3 billion people projected to be born worldwide by mid-century will be born in countries already experiencing water shortages. After China and India, there is a second tier of smaller countries with large water deficits \u2013 Afghanistan, Algeria, Egypt, Iran, Mexico, and Pakistan. Four of these already import a large share of their grain. Only Pakistan remains self-sufficient. But with a population expanding by 4 million a year, it will likely soon turn to the world market for grain.\nRegionally, Sub-Saharan Africa has the largest number of water-stressed countries of any place on the globe, as of an estimated 800 million people who live in Africa, 300 million live in a water-stressed environment.  It is estimated that by 2030, 75 million to 250 million people in Africa will be living in areas of high water stress, which will likely displace anywhere between 24 million and 700 million people as conditions become increasingly unlivable.<ref name=IaC/> Because the majority of Africa remains dependent on an agricultural lifestyle and 80 to 90 percent of all families in rural Africa rely upon producing their own food, water scarcity translates to a loss of food security.\nMultimillion-dollar investments beginning in the 1990s by the World Bank have reclaimed desert and turned the Ica Valley in Peru, one of the driest places on earth, into the largest supplier of asparagus in the world. However, the constant irrigation has caused a rapid drop in the water table, in some places as much as eight meters per year, one of the fastest rates of aquifer depletion in the world. The wells of small farmers and local people are beginning to run dry and the water supply for the main city in the valley is under threat. As a cash crop, asparagus has provided jobs for local people, but most of the money goes to the buyers, mainly the British. A 2010 report concluded that the industry is not sustainable and accuses investors, including the World Bank, of failing to take proper responsibility for the effect of their decisions on the water resources of poorer countries. Diverting water from the headwaters of the Ica River to asparagus fields has also led to a water shortage in the mountain region of Huancavelica, where indigenous communities make a marginal living herding.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Challenges to achieving food security", "_id": "32--7--0---1", "title": "Water Scarcity in Sub-Saharan Africa"}
{"qas": [{"question": "Why is Africa so poor?", "answer": ""}, {"question": "What often leads to a vicious cycle of exhaustion of soil fertility and decline of agricultural yields?", "answer": "Intensive farming", "ae_score": -0.5830710856159362, "qg_score": null}, {"question": "What often leads to a vicious cycle of exhaustion of soil fertility and decline of agricultural yields?", "answer": "Intensive farming", "ae_score": -0.5830710856159362, "qg_score": null}], "content": "Intensive farming often leads to a vicious cycle of exhaustion of soil fertility and decline of agricultural yields. Approximately 40 percent of the world's agricultural land is seriously degraded. In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25 percent of its population by 2025, according to UNU's Ghana-based Institute for Natural Resources in Africa.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Land degradation", "_id": "32--7--1---1", "title": "Affecting the Future of Agriculture in Africa"}
{"qas": [{"question": "What will happen to the world's food supply if the global warming continues?", "answer": ""}, {"question": "Who is an example of a food security researcher?", "answer": "Evan Fraser", "ae_score": -0.40686194185236885, "qg_score": null}, {"question": "Who is an example of a food security researcher?", "answer": "Evan Fraser", "ae_score": -0.40686194185236885, "qg_score": null}], "content": "Extreme events, such as droughts and floods, are forecast to increase as climate change and global warming takes hold. Ranging from overnight floods to gradually worsening droughts, these will have a range of effects on the agricultural sector. By 2040, almost the entire Nile region, which once included large areas of irrigated agricultural land, is expected to become hot desert where cultivation is impossible due to water limitation. According to the Climate & Development Knowledge Network report ''Managing Climate Extremes and Disasters in the Agriculture Sectors: Lessons from the IPCC SREX Report'', the effects will include changing productivity and livelihood patterns, economic losses, and effects on infrastructure, markets and food security. Food security in future will be linked to our ability to adapt agricultural systems to extreme events. For example, the Garifuna women in Honduras are helping to ensure food security locally by reviving and improving production of traditional root crops, building up traditional methods of soil conservation, carrying out training in organic composting and pesticide use and creating the first Garifuna farmers' market. Sixteen towns have worked together to establish tool and seed banks. Efforts to plant wild fruit trees along the coast are helping to prevent soil erosion. The aim is to reduce the communities' vulnerability to the hazards of shifting weather patterns.\nApproximately 2.4 billion people live in the drainage basin of the Himalayan rivers. India, China, Pakistan, Afghanistan, Bangladesh, Nepal and Myanmar could experience floods followed by severe droughts in coming decades. In India alone, the Ganges provides water for drinking and farming for more than 500 million people. The west coast of North America, which gets much of its water from glaciers in mountain ranges such as the Rocky Mountains and Sierra Nevada, also would be affected. Glaciers aren't the only worry that the developing nations have; sea level is reported to rise as climate change progresses, reducing the amount of land available for agriculture.\nIn other parts of the world, a big effect will be low yields of grain according to the World Food Trade Model, specifically in the low latitude regions where much of the developing world is located. From this the price of grain will rise, along with the developing nations trying to grow the grain. Due to this, every 2\u20132.5% price hike will increase the number of hungry people by 1%. Low crop yields are just one of the problem facing farmers in the low latitudes and tropical regions. The timing and length of the growing seasons, when farmers plant their crops, are going to be changing dramatically, per the USDA, due to unknown changes in soil temperature and moisture conditions.\nAnother way of thinking about food security and climate change comes from Evan Fraser, a geographer working at the University of Guelph in Ontario Canada.  His approach is to explore the vulnerability of food systems to climate change and he defines vulnerability to climate change as situations that occur when relatively minor environmental problems cause major effects on food security.  Examples of this include the Irish Potato Famine, which was caused by a rainy year that created ideal conditions for the fungal blight to spread in potato fields, or the Ethiopian Famine in the early 1980s. Three factors stand out as common in such cases, and these three factors act as a diagnostic \"tool kit\" through which to identify cases where food security may be vulnerable to climate change.  These factors are: (1) specialized agro-ecosystems; (2) households with very few livelihood options other than farming; (3) situations where formal institutions do not provide adequate safety nets to protect people. \"The International Food Policy Research Institute (IFPRI) estimates that an additional US$ 7.1-7.3 billion per year are needed in agricultural investments to offset the negative effect of climate change on nutrition for children by 2050 (Table 6).\"", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Climate change", "_id": "32--7--2---1", "title": "Climate Change and Food Security"}
{"qas": [{"question": "How does a disease affecting livestock or crops affect food availability?", "answer": ""}, {"question": "Wild wheat plants are screened for resistance to what?", "answer": "rust", "ae_score": -0.5302987536443887, "qg_score": null}, {"question": "Wild wheat plants are screened for resistance to what?", "answer": "rust", "ae_score": -0.5302987536443887, "qg_score": null}], "content": "Diseases affecting livestock or crops can have devastating effects on food availability especially if there are no contingency plans in place.For example, Ug99, a lineage of wheat stem rust  which can cause up to 100% crop losses, is present in wheat fields in several countries in Africa and the Middle East and is predicted to spread rapidly through these regions and possibly further afield, potentially causing a wheat production disaster that would affect food security worldwide.\nThe genetic diversity of the crop wild relatives of wheat can be used to improve modern varieties to be more resistant to rust. In their centers of origin wild wheat plants are screened for resistance to rust, then their genetic information is studied and finally wild plants and modern varieties are crossed through means of modern plant breeding in order to transfer the resistance genes from the wild plants to the modern varieties.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Agricultural diseases", "_id": "32--7--3---1", "title": "Genetic Diversity of the Wild Relatives of Wheat to Improve Modern Varieties"}
{"qas": [{"question": "Why does the government care so much about the rights of people without property?", "answer": ""}, {"question": "Who said there is no such thing as an apolitical food problem?", "answer": "Amartya Sen", "ae_score": -0.1719503460724014, "qg_score": null}, {"question": "Who said there is no such thing as an apolitical food problem?", "answer": "Amartya Sen", "ae_score": -0.1719503460724014, "qg_score": null}], "content": "Nobel Prize winning economist Amartya Sen has observed that \"there is no such thing as an apolitical food problem.\" While drought and other naturally occurring events may trigger famine conditions, it is government action or inaction that determines its severity, and often even whether or not a famine will occur. The 20th century is full of examples of governments undermining the food security of their own nations \u2013 sometimes intentionally.\nWhen governments come to power by force or rigged elections, and not by way of fair and open elections, their base of support is often narrow and built upon cronyism and patronage. Under such conditions \"The distribution of food within a country is a political issue. Governments in most countries give priority to urban areas, since that is where the most influential and powerful families and enterprises are usually located. The government often neglects subsistence farmers and rural areas in general. The more remote and underdeveloped the area the less likely the government will be to effectively meet its needs. Many agrarian policies, especially the pricing of agricultural commodities, discriminate against rural areas. Governments often keep prices of basic grains at such artificially low levels that subsistence producers cannot accumulate enough capital to make investments to improve their production. Thus, they are effectively prevented from getting out of their precarious situation.\"\nFurther dictators and warlords have used food as a political weapon, rewarding their supporters while denying food supplies to areas that oppose their rule. Under such conditions food becomes a currency with which to buy support and famine becomes an effective weapon to be used against the opposition.\nGovernments with strong tendencies towards kleptocracy can undermine food security even when harvests are good. When government monopolizes trade, farmers may find that they are free to grow cash crops for export, but under penalty of law only able to sell their crops to government buyers at prices far below the world market price. The government then is free to sell their crop on the world market at full price, pocketing the difference. This creates an artificial \"poverty trap\" from which even the most hard working and motivated farmers may not escape.\nWhen the rule of law is absent, or private property is non-existent, farmers have little incentive to improve their productivity. If a farm becomes noticeably more productive than neighboring farms, it may become the target of individuals well connected to the government. Rather than risk being noticed and possibly losing their land, farmers may be content with the perceived safety of mediocrity.\nAs pointed out by William Bernstein in his book ''The Birth of Plenty'': \"Individuals without property are susceptible to starvation, and it is much easier to bend the fearful and hungry to the will of the state. If a [farmer's] property can be arbitrarily threatened by the state, that power will inevitably be employed to intimidate those with divergent political and religious opinions.\"", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Dictatorship and kleptocracy", "_id": "32--7--4---1", "title": "The Politics of Food Security"}
{"qas": [{"question": "What is Food Sovereignty?", "answer": ""}, {"question": "What does food sovereignty view the business practices of multinational corporations as?", "answer": "neocolonialism", "ae_score": -0.6340002932394041, "qg_score": null}, {"question": "What does food sovereignty view the business practices of multinational corporations as?", "answer": "neocolonialism", "ae_score": -0.6340002932394041, "qg_score": null}], "content": "The approach known as food sovereignty views the business practices of multinational corporations as a form of neocolonialism. It contends that multinational corporations have the financial resources available to buy up the agricultural resources of impoverished nations, particularly in the tropics. They also have the political clout to convert these resources to the exclusive production of cash crops for sale to industrialized nations outside of the tropics, and in the process to squeeze the poor off of the more productive lands. Under this view subsistence farmers are left to cultivate only lands that are so marginal in terms of productivity as to be of no interest to the multinational corporations. Likewise, food sovereignty holds it to be true that communities should be able to define their own means of production and that food is a basic human right. With several multinational corporations now pushing agricultural technologies on developing countries, technologies that include improved seeds, chemical fertilizers, and pesticides, crop production has become an increasingly analyzed and debated issue. Many communities calling for food sovereignty are protesting the imposition of Western technologies on to their indigenous systems and agency.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Challenges to achieving food security", "sub_heading": "Food sovereignty", "_id": "32--7--5---1", "title": "Food Sovereignty \u2014 A New Approach to Food Production"}
{"qas": [{"question": "Will the world's population ever reach 9 billion?", "answer": ""}, {"question": "How many people die of malnutrition and hunger related diseases everyday?", "answer": "25,000", "ae_score": -0.9101901135497659, "qg_score": null}, {"question": "How many people die of malnutrition and hunger related diseases everyday?", "answer": "25,000", "ae_score": -0.9101901135497659, "qg_score": null}], "content": "Current UN projections show a continued increase in population in the near future (but a steady decline in the population growth rate), with the global population expected to reach between 8.3 and 10.9 billion by 2050. UN Population Division estimates for the year 2150 range between 3.2 and 24.8 billion; mathematical modeling supports the lower estimate. Some analysts have questioned the sustainability of further world population growth, highlighting the growing pressures on the environment, global food supplies, and energy resources. Solutions for feeding the nine billion in the future are being studied and documented. One out of every seven people on our planet go to sleep hungry. People are suffering due to overpopulation, 25,000 people die of malnutrition and hunger related diseases everyday.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Risks to food security", "_id": "32--8--0---1", "title": "Global Population Forecasts for 2050 \u2014 Global Population Forecast"}
{"qas": [{"question": "How did the world's population increase by 250% in the last 100 years?", "answer": ""}, {"question": "Where did the energy for the green revolution come from?", "answer": "fossil fuels", "ae_score": -0.3702426914341246, "qg_score": null}, {"question": "Where did the energy for the green revolution come from?", "answer": "fossil fuels", "ae_score": -0.3702426914341246, "qg_score": null}], "content": "While agricultural output increased as a result of the Green Revolution, the energy input into the process (that is, the energy that must be expended to produce a crop) has also increased at a greater rate, so that the ratio of crops produced to energy input has decreased over time. Green Revolution techniques also heavily rely on chemical fertilizers, pesticides and herbicides, some of which must be developed from fossil fuels, making agriculture increasingly reliant on petroleum products.\nBetween 1950 and 1984, as the Green Revolution transformed agriculture around the globe, world grain production increased by 250%. The energy for the Green Revolution was provided by fossil fuels in the form of fertilizers (natural gas), pesticides (oil), and hydrocarbon fueled irrigation.\nDavid Pimentel, professor of ecology and agriculture at Cornell University, and Mario Giampietro, senior researcher at the National Research Institute on Food and Nutrition (INRAN), place in their study ''Food, Land, Population and the U.S. Economy'' the maximum U.S. population for a sustainable economy at 210 million. To achieve a sustainable economy and avert disaster, the United States must reduce its population by at least one-third, and world population will have to be reduced by two-thirds, says the study.\nThe authors of this study believe that the mentioned agricultural crisis will only begin to affect us after 2020, and will not become critical until 2050. The oncoming peaking of global oil production (and subsequent decline of production), along with the peak of North American natural gas production will very likely precipitate this agricultural crisis much sooner than expected. Geologist Dale Allen Pfeiffer claims that coming decades could see spiraling food prices without relief and massive starvation on a global level such as never experienced before.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Fossil fuel dependence", "_id": "32--8--1---1", "title": "The Green Revolution and the U.S. Agriculture Crisis"}
{"qas": [{"question": "How did the world become so homogeneous?", "answer": ""}, {"question": "Between 1961 and 2009, the differences between the foods eaten in different countries were reduced by?", "answer": "68%", "ae_score": -0.6434956719357284, "qg_score": null}, {"question": "Between 1961 and 2009, the differences between the foods eaten in different countries were reduced by?", "answer": "68%", "ae_score": -0.6434956719357284, "qg_score": null}], "content": "Since 1961, human diets across the world have become more diverse in the consumption of major commodity staple crops, with a corollary decline in consumption of local or regionally important crops, and thus have become more homogeneous globally. The differences between the foods eaten in different countries were reduced by 68% between 1961 and 2009. The modern \"global standard\"<ref name=Khoury/> diet contains an increasingly large percentage of a relatively small number of major staple commodity crops, which have increased substantially in the share of the total food energy (calories), protein, fat, and food weight that they provide to the world's human population, including wheat, rice, sugar, maize, soybean (by +284%<ref name=Kinver/>), palm oil (by +173%<ref name=Kinver/>), and sunflower (by +246%<ref name=Kinver/>). Whereas nations used to consume greater proportions of locally or regionally important crops, wheat has become a staple in over 97% of countries, with the other global staples showing similar dominance worldwide. Other crops have declined sharply over the same period, including rye, yam, sweet potato (by -45%<ref name=Kinver/>), cassava (by -38%<ref name=Kinver/>), coconut, sorghum (by -52%<ref name=Kinver/>) and millets (by -45%<ref name=Kinver/>).<ref name=Khoury/> Such globalization of food supplies is associated with mixed effects on food security, improving under-nutrition in some regions but contributing to the diet-related diseases caused by over-consumption of macronutrients.<ref name=Khoury/>", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Homogeneity in the global food supply", "_id": "32--8--2---1", "title": "Globalization of Food Supply"}
{"qas": [{"question": "Rice price fixing cartel?", "answer": ""}, {"question": "Which country announced the creation of the organisation of rice exporting countries?", "answer": "Thailand", "ae_score": -0.35874228308614386, "qg_score": null}, {"question": "Which country announced the creation of the organisation of rice exporting countries?", "answer": "Thailand", "ae_score": -0.35874228308614386, "qg_score": null}], "content": "On April 30, 2008, Thailand, one of the world's biggest rice exporters, announced the creation of the Organisation of Rice Exporting Countries with the potential to develop into a price-fixing cartel for rice. It is a project to organize 21 rice exporting countries to create a homonymous organisation to control the price of rice. The group is mainly made up of Thailand, Vietnam, Cambodia, Laos and Myanmar. The organization attempts to serve the purpose of making a \"contribution to ensuring food stability, not just in an individual country but also to address food shortages in the region and the world\". However, it is still questionable whether this organization will serve its role as an effective rice price fixing cartel, that is similar to OPEC's mechanism for managing petroleum. Economic analysts and traders said the proposal would go nowhere because of the inability of governments to cooperate with each other and control farmers' output. Moreover, countries that are involved expressed their concern, that this could only worsen the food security.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Price setting", "_id": "32--8--3---1", "title": "The Organization of Rice Exporting Countries"}
{"qas": [{"question": "If China needs less than 120 million hectares of arable land for its food security, why can't they just convert it to urban use?", "answer": ""}, {"question": "How many hectares of arable land has china recently reported a surplus?", "answer": "15 million hectares", "ae_score": -0.485270139523554, "qg_score": null}, {"question": "How many hectares of arable land has china recently reported a surplus?", "answer": "15 million hectares", "ae_score": -0.485270139523554, "qg_score": null}], "content": "China needs not less than 120 million hectares of arable land for its food security. China has recently reported a surplus of 15 million hectares. On the other side of the coin, some 4 million hectares of conversion to urban use and 3 million hectares of contaminated land have been reported as well. Furthermore, a survey found that 2.5% of China's arable land is too contaminated to grow food without harm.In Europe, the conversion of agricultural soil implied a net loss of potential. But the rapid loss in the area of arable soils appears to be economically meaningless because EU is perceived to be dependent on internal food supply anymore. During the period 2000-2006 the European Union lost 0.27% of its cropland and 0.26% of its crop productive potential. The loss of agricultural land during the same time was the highest in the Netherlands, which lost 1.57% of its crop production potential within six years. The figures are quite alarming for Cyprus (0.84%), Ireland (0.77%) and Spain (0.49%) as well.In Italy, in the Emilia-Romagna plain (ERP), the conversion of 15,000 ha of agricultural soil (period 2003-2008) implied a net loss of 109,000 Mg per year of wheat, which accounts for the calories needed by 14% of ERP population (425,000 people). Such a loss in wheat production is just 0.02% of gross domestic product (GDP) of the Emilia-Romagna region which is actually a minor effect in financial terms. Additionally, the income from the new land use is often much higher than the one guaranteed by agriculture, as in the case of urbanisation or extraction of raw materials.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Land use change", "_id": "32--8--4---1", "title": "Agricultural Land Loss in the EU"}
{"qas": [{"question": "What would happen if the sun disappeared?", "answer": ""}, {"question": "How long could sulfate particles in the stratosphere stay there?", "answer": "years", "ae_score": null, "qg_score": null}, {"question": "How long could sulfate particles in the stratosphere stay there?", "answer": "years", "ae_score": null, "qg_score": null}], "content": "As anthropogenic greenhouse gas emissions reduce the stability of the global climate, abrupt climate change could become more intense. The impact of an asteroid or comet larger than about 1 km diameter has the potential to block the sun globally, causing impact winter. Particles in the troposphere would quickly rain out, but particles in the stratosphere, especially sulfate, could remain there for years. Similarly, a supervolcanic eruption would reduce the potential of agricultural production from solar photosynthesis, causing volcanic winter. The Toba super volcanic eruption approximately 70,000 years ago may have nearly caused the extinction of humans (see Toba catastrophe theory). Again, primarily sulfate particles could block the sun for years. Solar blocking is not limited to natural causes as nuclear winter is also possible, which refers to the scenario involving widespread nuclear war and burning of cities that release soot into the stratosphere that would stay there for about 10 years. The high stratospheric temperatures produced by soot absorbing solar radiation would create near-global ozone hole conditions even for a regional nuclear conflict.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Risks to food security", "sub_heading": "Global catastrophic risks", "_id": "32--8--5---1", "title": "Climate Change: Impact Winter"}
{"qas": [{"question": "Why is it that in the United States, there are so many people who are food insecure?", "answer": ""}, {"question": "When did unicef report on climate change?", "answer": "April 29, 2008", "ae_score": -0.3878184964438807, "qg_score": null}, {"question": "When did unicef report on climate change?", "answer": "April 29, 2008", "ae_score": -0.3878184964438807, "qg_score": null}], "content": "On April 29, 2008, a UNICEF UK report found that the world's poorest and most vulnerable children are being hit the hardest by climate change. The report, \"Our Climate, Our Children, Our Responsibility: The Implications of Climate Change for the World's Children\", says that access to clean water and food supplies will become more difficult, particularly in Africa and Asia.\nBy way of comparison, in one of the largest food producing countries in the world, the United States, approximately one out of six people are \"food insecure\", including 17 million children, according to the U.S. Department of Agriculture. A 2012 study in the ''Journal of Applied Research on Children'' found that rates of food security varied significantly by race, class and education. In both kindergarten and third grade, 8% of the children were classified as food insecure, but only 5% of white children were food insecure, while 12% and 15% of black and Hispanic children were food insecure, respectively. In third grade, 13% of black and 11% of Hispanic children are food insecure compared to 5% of white children.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Children and food security", "sub_heading": "Children and food security", "_id": "32--9---1---1", "title": "The Implications of Climate Change for the World's Poorest and Most Vulner"}
{"qas": [{"question": "Why is there such a huge gender gap in the world?", "answer": ""}, {"question": "Who are the most affected by food insecurity?", "answer": "women and girls", "ae_score": -0.697855949831915, "qg_score": null}, {"question": "Who are the most affected by food insecurity?", "answer": "women and girls", "ae_score": -0.697855949831915, "qg_score": null}], "content": "Gender inequality both leads to and is a result of food insecurity. According to estimates women and girls make up 60% of the world's chronically hungry and little progress has been made in ensuring the equal right to food for women enshrined in the Convention on the Elimination of All Forms of Discrimination against Women. Women face discrimination both in education and employment opportunities and within the household, where their bargaining power is lower. On the other hand, gender equality is described as instrumental to ending malnutrition and hunger. Women tend to be responsible for food preparation and childcare within the family and are more likely to spend their income on food and their children's needs. Women also play an important role in food production, processing, distribution and marketing. They often work as unpaid family workers, are involved in subsistence farming and represent about 43% of the agricultural labor force in developing countries, varying from 20% in Latin America to 50% in Eastern and Southeastern Asia and Sub-Saharan Africa. However, women face discrimination in access to land, credit, technologies, finance and other services. Empirical studies suggest that if women had the same access to productive resources as men, women could boost their yields by 20\u201330%; raising the overall agricultural output in developing countries by 2.5 to 4%. While those are rough estimates, the significant benefit of closing the gender gap on agricultural productivity cannot be denied. The gendered aspects of food security are visible along the four pillars of food security: availability, access, utilization and stability, as defined by the Food and Agriculture Organization.\nThe number of people affected by hunger is extremely high, with enormous effects on women and girls. Making this trend disappear \"must be a top priority for governments and international institutions\".<ref name=Bridge/> Actions governments take must take into consideration that food insecurity is an issue regarding \"equality, rights and social justice\".<ref name=Bridge/>\"Food and nutrition insecurity is a political and economic phenomenon fuelled by inequitable global and national processes\".<ref name=Bridge/> Factors like capitalism, exploration of Indigenous lands all contribute to food insecurity for minorities and the people who are the most oppressed in various countries (women being one of these oppressed groups). To emphasis, \"food and nutrition insecurity is a gender justice issue\".<ref name=Bridge/> The facts that women and girls are the most oppressed by \"the inequitable global economic processes that govern food systems and by global trends such as climate change\", shows how institutions continue to place women in positions of disadvantage and impoverishment to make money and thrive on capitalizing the food system.<ref name=Bridge/> When the government withholds food by raising its prices to amounts only privileged people can afford, they both benefit and are able to control the \"lower-class\"/ marginalized people via the food market. An interesting fact is that \"despite rapid economic growth in India, thousands of women and girls still lack food and nutrition security as a direct result of their lower status compared with men and boys\".<ref name=Bridge/> \"Such inequalities are compounded by women and girls' often limited access to productive resources, education and decision-making, by the 'normalised' burden of unpaid work \u2013 including care work \u2013 and by the endemic problems of gender-based violence (GBV), HIV and AIDS\".<ref name=Bridge/>", "page_name": "Food security", "page_id": "Food%20security", "heading": "Gender and food security", "sub_heading": "Gender and food security", "_id": "32--10---1---1", "title": "Gender Inequality and Gender Justice in Food and Nutrition Insecurity"}
{"qas": [{"question": "Why does the Philippines have such a high Vitamin A deficiency?", "answer": ""}, {"question": "Where is golden rice produced in the world?", "answer": "Philippines", "ae_score": -0.49163281094405675, "qg_score": null}, {"question": "Where is golden rice produced in the world?", "answer": "Philippines", "ae_score": -0.49163281094405675, "qg_score": null}], "content": "Respected scientists question the safety of biotechnology as a panacea; agroecologists Miguel Altieri and Peter Rosset have enumerated ten reasons why biotechnology will not ensure food security, protect the environment, or reduce poverty. Reasons include:\nBased on evidence from previous attempts, there is a likely lack of transferability of one type of GM crop from one region to another. For example, modified crops that have proven successful in Asia from the Green Revolution have failed when tried in regions of Africa. More research must be done regarding the specific requirements of growing a specific crop in a specific region.\nThere is also a drastic lack of education given to governments, farmers, and the community about the science behind GM crops, as well as suitable growing practices. In most relief programs, farmers are given seeds with little explanation and little attention is paid to the resources available to them or even laws that prohibit them from distributing produce. Governments are often not advised on the economic and health implications that come with growing GM crops, and are then left to make judgments on their own. Because they have so little information regarding these crops, they usually shy away from allowing them or do not take the time and effort required to regulate their use. Members of the community that will then consume the produce from these crops are also left in the dark about what these modifications mean and are often scared off by their 'unnatural' origins. This has resulted in failure to properly grow crops as well as strong opposition to the unknown practices.\nA study published in June 2016 evaluated the status of the implementation of Golden Rice, which was first developed in the 1990s to produce higher levels of Vitamin A than its non-GMO counterparts. This strain of rice was designed so that malnourished women and children in third world countries who were more susceptible to deficiencies could easily improve their Vitamin A intake levels and prevent blindness, which is a common result. Golden Rice production was centralized to the Philippines, yet there have been many hurdles to jump in order to get production moving. The study showed that the project is far behind schedule and is not living up to its expectations. Although research on Golden Rice still continues, the country has moved forward with other non-GMO initiatives to address the Vitamin A deficiency problem which is so prevasive in that region.\nMany anti-GMO activists argue that the use of GM crops decreases biodiversity amongst plants. Livestock biodiversity is also threatened by the modernization of agriculture and the focus on more productive major breeds. Therefore, efforts have been made by governments and non-governmental organizations to conserve livestock biodiversity through strategies such as Cryoconservation of animal genetic resources.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Use of genetically modified (GM) crops", "sub_heading": "Use of genetically modified (GM) crops", "_id": "32--11--0---1", "title": "10 Reasons Why Biotechnology Will Not Save Food Security, Protect the Environment, and Reduce Po"}
{"qas": [{"question": "What is the difference between GM crops and regular crops?", "answer": ""}, {"question": "What is one of the biggest threats to rice?", "answer": "blast disease", "ae_score": -0.21923183712889405, "qg_score": null}, {"question": "What is one of the biggest threats to rice?", "answer": "blast disease", "ae_score": -0.21923183712889405, "qg_score": null}], "content": "Many GM crop success stories exist, primarily in developed nations like the USA, China, and various countries in Europe. Common GM crops include cotton, maize, and soybeans, all of which are grown throughout North and South America as well as regions of Asia. Modified cotton crops, for example, have been altered such that they are resistant to pests, can grown in more extreme heat, cold, or drought, and produce longer, stronger fibers to be used in textile production.\nOne of the biggest threats to rice, which is a staple food crop especially in India and other countries within Asia, is blast disease which is a fungal infection that causes lesions to form on all parts of the plant. A genetically engineered strain of rice has been developed so that it is resistant to blast, greatly improving the crop yield of farmers and allowing rice to be more accessible to everyone. Some other crops have been modified such that they produce higher yields per plant or that they require less land for growing. The latter can be helpful in extreme climates with little arable land and also decreases deforestation, as fewer trees need to be cut down in order to make room for crop fields. Others yet have been altered such that they do not require the use of insecticides or fungicides. This addresses various health concerns associated with such pesticides and can also work to improve biodiversity within the area in which these crops are grown.\nIn a review of Borlaug's 2000 publication entitled ''Ending world hunger: the promise of biotechnology and the threat of antiscience zealotry'', the authors argued that Borlaug's warnings were still true in 2010,Research conducted by the GMO Risk Assessment and Communication of Evidence (GRACE) program through the EU between 2007 and 2013 focused on many uses of GM crops and evaluated many facets of their effects on human, animal, and environmental health.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Use of genetically modified (GM) crops", "sub_heading": "Support of GM crops", "_id": "32--11--1---1", "title": "Genetically Modified Crops"}
{"qas": [{"question": "How has the World Food Organization been able to achieve its Millennium Development Goal?", "answer": ""}, {"question": "Who is the un special Rapporteur on the right to food?", "answer": "Olivier De Schutter", "ae_score": -0.33226551936789817, "qg_score": null}, {"question": "Who is the un special Rapporteur on the right to food?", "answer": "Olivier De Schutter", "ae_score": -0.33226551936789817, "qg_score": null}], "content": "The UN Millennium Development Goals are one of the initiatives aimed at achieving food security in the world. The first Millennium Development Goal states that the UN \"is to eradicate extreme hunger and poverty\" by 2015. Olivier De Schutter, the UN Special Rapporteur on the Right to Food, advocates for a multidimensional approach to food security challenges. This approach emphasizes the physical availability of food; the social,economic and physical access people have to food; and the nutrition, safety and cultural appropriateness or adequacy of food.\nThe Food and Agriculture Organization of the United Nations stated in ''The State of Food Insecurity in the World 2003'' that countries that have reduced hunger often had rapid economic growth, specifically in their agricultural sectors. These countries were also characterized as having slower population growth, lower HIV rates, and higher rankings in the Human Development Index. At that time, the FAO considered addressing agriculture and population growth vital to achieving food security. In ''The State of Food Insecurity in the World 2012'', the FAO restated its focus on economic growth and agricultural growth to achieve food security and added a focus on the poor and on \"nutrition-sensitive\" growth. For example, economic growth should be used by governments to provide public services to benefit poor and hungry populations. The FAO also cited smallholders, including women, as groups that should be involved in agricultural growth to generate employment for the poor. For economic and agricultural growth to be \"nutrition-sensitive\", resources should be utilized to improve access to diverse diets for the poor as well as access to a safe water supply and to healthcare.The FAO has proposed a \"twin track\" approach to fight food insecurity that combines sustainable development and short-term hunger relief. Development approaches include investing in rural markets and rural infrastructure. In general, the FAO proposes the use of public policies and programs that promote long-term economic growth that will benefit the poor. To obtain short-term food security, vouchers for seeds, fertilizer, or access to services could promote agricultural production. The use of conditional or unconditional food or cash transfers was another approach the FAO noted. Conditional transfers could include school feeding programs, while unconditional transfers could include general food distribution, emergency food aid or cash transfers. A third approach is the use of subsidies as safety nets to increase the purchasing power of households. The FAO stated that \"approaches should be human rights-based, target the poor, promote gender equality, enhance long-term resilience and allow sustainable graduation out of poverty.\"\nThe FAO noted that some countries have been successful in fighting food insecurity and decreasing the number of people suffering from undernourishment. Bangladesh is an example of a country that has met the Millennium Development Goal hunger target. The FAO credited growth in agricultural productivity and macroeconomic stability for the rapid economic growth in the 1990s that resulted in an increase in food security. Irrigation systems were established through infrastructure development programs. Two programs, HarvestPlus and the Golden Rice Project, provided biofortified crops in order to decrease micronutrient deficiencess.\nWorld Food Day was established on October 16, in honor of the date that the FAO was founded in 1945. On this day, the FAO hosts a variety of event at the headquarters in Rome and around the world, as well as seminars with UN officials.\nThe World Food Programme (WFP) is an agency of the United Nations that uses food aid to promote food security and eradicate hunger and poverty. In particular, the WFP provides food aid to refugees and to others experiencing food emergencies. It also seeks to improve nutrition and quality of life to the most vulnerable populations and promote self-reliance. An example of a WFP program is the \"Food For Assets\" program in which participants work on new infrastructure, or learn new skills, that will increase food security, in exchange for food. The WFP and the Government of Kenya have partnered in the Food For Assets program in hopes of increasing the resilience of communities to shocks.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Approaches", "_id": "32--12--0---1", "title": "World Food Day: The FAO's Approach to Food Security"}
{"qas": [{"question": "Why does the United States spend so much money on food aid?", "answer": ""}, {"question": "What agreement was signed in april 2012?", "answer": "Food Assistance Convention", "ae_score": -0.4228530544033041, "qg_score": null}, {"question": "What agreement was signed in april 2012?", "answer": "Food Assistance Convention", "ae_score": -0.4228530544033041, "qg_score": null}], "content": "In April 2012, the Food Assistance Convention was signed, the world's first legally binding international agreement on food aid. The May 2012 Copenhagen Consensus recommended that efforts to combat hunger and malnutrition should be the first priority for politicians and private sector philanthropists looking to maximize the effectiveness of aid spending. They put this ahead of other priorities, like the fight against malaria and AIDS.\nThe main global policy to reduce hunger and poverty are the recently approved Sustainable Development Goals. In particular Goal 2: Zero Hunger sets globally agreed targets to end hunger, achieve food security and improved nutrition and promote sustainable agriculture by 2030. A number of organizations have formed initiatives with the more ambitious goal to achieve this outcome in only 10 years, by 2025:", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Global partnerships to achieve food security and end hunger", "_id": "32--12--1---1", "title": "Goal 2: Zero Hunger"}
{"qas": [{"question": "How does the United States government help rural areas?", "answer": ""}, {"question": "What is another name for the food stamp program?", "answer": "Supplemental Nutrition Assistance Program", "ae_score": -0.4679016503658611, "qg_score": null}, {"question": "What is another name for the food stamp program?", "answer": "Supplemental Nutrition Assistance Program", "ae_score": -0.4679016503658611, "qg_score": null}], "content": "The United States Agency for International Development (USAID) proposes several key steps to increasing agricultural productivity which is in turn key to increasing rural income and reducing food insecurity. They include:\nSince the 1960s, the U.S. has been implementing a Food Stamp Program (now called the Supplemental Nutrition Assistance Program) to directly target consumers who lack the income to purchase food. According to Tim Josling, a Senior Fellow at the Freeman Spogli Institute for International Studies, Stanford University, food stamps or other methods of distribution of purchasing power directly to consumers might fit into the range of international programs under consideration to tackle food insecurity.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "By the United States Agency for International Development", "_id": "32--12--2---1", "title": "Increasing Rural Income and Reducing Food insecurity"}
{"qas": [{"question": "Why is it so important to increase the number of farmers in the world?", "answer": ""}, {"question": "What fraction of the world's poor live in rural areas?", "answer": "Three-quarters", "ae_score": -0.7997797927154515, "qg_score": null}, {"question": "What fraction of the world's poor live in rural areas?", "answer": "Three-quarters", "ae_score": -0.7997797927154515, "qg_score": null}], "content": "There are strong, direct relationships between agricultural productivity, hunger, poverty, and sustainability. Three-quarters of the world's poor live in rural areas and make their living from agriculture. Hunger and child malnutrition are greater in these areas than in urban areas. Moreover, the higher the proportion of the rural population that obtains its income solely from subsistence farming (without the benefit of pro-poor technologies and access to markets), the higher the incidence of malnutrition. Therefore, improvements in agricultural productivity aimed at small-scale farmers will benefit the rural poor first. Food and feed crop demand is likely to double in the next 50 years, as the global population approaches nine billion. Growing sufficient food will require people to make changes such as increasing productivity in areas dependent on rainfed agriculture; improving soil fertility management; expanding cropped areas; investing in irrigation; conducting agricultural trade between countries; and reducing gross food demand by influencing diets and reducing post-harvest losses.\nAccording to the Comprehensive Assessment of Water Management in Agriculture, a major study led by the International Water Management Institute (IWMI), managing rainwater and soil moisture more effectively, and using supplemental and small-scale irrigation, hold the key to helping the greatest number of poor people. It has called for a new era of water investments and policies for upgrading rainfed agriculture that would go beyond controlling field-level soil and water to bring new freshwater sources through better local management of rainfall and runoff. Increased agricultural productivity enables farmers to grow more food, which translates into better diets and, under market conditions that offer a level playing field, into higher farm incomes. With more money, farmers are more likely to diversify production and grow higher-value crops, benefiting not only themselves but the economy as a whole.\"\nResearchers suggest forming an alliance between the emergency food program and community-supported agriculture, as some countries' food stamps cannot be used at farmer's markets and places where food is less processed and grown locally.The gathering of wild food plants appears to be an efficient alternative method of subsistence in tropical countries, which may play a role in poverty alleviation.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Improving agricultural productivity to benefit the rural poor", "_id": "32--12--3---1", "title": "A new era of agricultural productivity will benefit the world's poor first"}
{"qas": [{"question": "Why can't we use fossil fuels as a source of energy?", "answer": ""}, {"question": "What is the solution to using fossil fuel energy sources?", "answer": "natural gas digesting bacteria", "ae_score": -0.20748858151339292, "qg_score": null}, {"question": "What is the solution to using fossil fuel energy sources?", "answer": "natural gas digesting bacteria", "ae_score": -0.20748858151339292, "qg_score": null}], "content": "David Denkenberger and Joshua Pearce have proposed in Feeding Everyone No Matter What a variety of alternate foods which convert fossil fuels or biomass into food without sunlight to address sunlight-blocking food security scenarios. The solution using fossil fuel energy source is natural gas digesting bacteria. One example of a biomass alternate food is that mushrooms can grow directly on wood without sunlight. Another example is that cellulosic biofuel production typically already creates sugar as an intermediate product.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Producing food without agriculture", "_id": "32--12--4---1", "title": "Feeding Everyone No Matter What: Alternative Foods"}
{"qas": [{"question": "How long would it take for the world to stop storing wheat?", "answer": ""}, {"question": "What would a lack of food storage cause?", "answer": "raising food prices", "ae_score": -0.7610549122985922, "qg_score": null}, {"question": "What would a lack of food storage cause?", "answer": "raising food prices", "ae_score": -0.7610549122985922, "qg_score": null}], "content": "The minimum annual global wheat storage is approximately 2 months. To counteract the severe food security issues caused by global catastrophic risks, years of food storage has been proposed. Though this could ameliorate smaller scale problems like regional conflict and drought, it would exacerbate current food insecurity by raising food prices.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Large-scale food stockpiling", "_id": "32--12--5---1", "title": "Global Food Security Issues \u2014 The Future of Global Food Security"}
{"qas": [{"question": "How do bees and other pollinating insects help the world?", "answer": ""}, {"question": "What is a major disadvantage of index-based insurance?", "answer": "Basis risk", "ae_score": -0.2865377205376086, "qg_score": null}, {"question": "What is a major disadvantage of index-based insurance?", "answer": "Basis risk", "ae_score": -0.2865377205376086, "qg_score": null}], "content": "Insurance is a financial instrument, which allows exposed individuals to pool resources to spread their risk. They do so by contributing premium to an insurance fund, which will indemnify those who suffer insured loss. This procedure reduces the risk for an individual by spreading his/her risk among the multiple fund contributors. Insurance can be designed to protect many types of individuals and assets against single or multiple perils and buffer insured parties against sudden and dramatic income or asset loss.\nCrop insurance is purchased by agricultural producers to protect themselves against either the loss of their crops due to natural disasters. Two type of insurances are available: (1) claim-based insurances, and (2) index-based insurances. In particular in poor countries facing food security problems, index-based insurances offer some interesting advantages: 1) indices can be derived from globally available satellite images that correlate well with what is insured; (2) these indices can be delivered at low cost; and (3) the insurance products open up new markets that are not served by claim-based insurances.\nAn advantage of index-based insurance is that it can potentially be delivered at lower cost. A significant barrier that hinders uptake of claim-based insurance is the high transaction cost for searching for prospective policyholders, negotiating and administering contracts, verifying losses and determining payouts. Index insurance eliminates the loss verification step, thereby mitigating a significant transaction cost. A second advantage of index-based insurance is that, because it pays an indemnity based on the reading of an index rather than individual losses, it eliminates much of the fraud, moral hazard and adverse selection, which are common in classical claim-based insurance. A further advantage of index insurance is that payments based on a standardized and indisputable index also allow for a fast indemnity payment. The indemnity payment could be automated, further reducing transaction costs.\nBasis risk is a major disadvantage of index-based insurance. It is the situation where an individual experiences a loss without receiving payment or vice versa. Basis risk is a direct result of the strength of the relation between the index that estimates the average loss by the insured group and the loss of insured assets by an individual. The weaker this relation the higher the basis risk. It is obvious that high basis risk undermines the willingness of potential clients to purchase insurance. It thus challenges insurance companies to design insurances such as to minimize basis risk.\n'''Food Security, Quality through Bees'''\nBees and other pollinating insects are currently improving the food production of 2 billion small farmers worldwide, helping to ensure food security for the world\u2019s population. Research shows that if pollination is managed well on small diverse farms, with all other factors being equal, crop yields can increase by a significant median of 24 percent.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Approaches", "sub_heading": "Agricultural insurances", "_id": "32--12--6---1", "title": "Index-Based Insurances \u2014 Benefits and Disadvantages."}
{"qas": [{"question": "How do pollinators affect fruit?", "answer": ""}, {"question": "When was food security defined as adequate nutritional status?", "answer": "1995", "ae_score": -0.4822831341191687, "qg_score": null}, {"question": "When was food security defined as adequate nutritional status?", "answer": "1995", "ae_score": -0.4822831341191687, "qg_score": null}], "content": "As of 2015 the concept of food security has mostly focused on food calories rather than the quality and nutrition of food. The concept of nutrition security evolved over time. In 1995, it has been defined as \"adequate nutritional status in terms of protein, energy, vitamins, and minerals for all household members at all times\".\nHow animal pollinators positively affect fruit condition and nutrient content is still being discovered.", "page_name": "Food security", "page_id": "Food%20security", "heading": "Criticism", "sub_heading": "Criticism", "_id": "32--13---1---1", "title": "Food Security \u2014 The concept of food security"}
{"qas": [{"question": "Why is drowning portrayed as a violent struggle?", "answer": ""}, {"question": "Who is a lifeguard and researcher of rescue techniques?", "answer": "Frank Pia", "ae_score": -0.2658376394307395, "qg_score": null}, {"question": "Who is a lifeguard and researcher of rescue techniques?", "answer": "Frank Pia", "ae_score": -0.2658376394307395, "qg_score": null}], "content": "Drowning is most often quick and unspectacular. Its media depictions as a loud, violent struggle have much more in common with distressed non-swimmers, who may well drown but have not yet begun to do so. In particular, an asphyxiating person is seldom able to call for help. The instinctive drowning response covers many signs or behaviors associated with drowning or near-drowning:\nFrank Pia, a lifeguard and researcher of rescue techniques and drowning, notes that drowning begins at the point a person is unable to keep their mouth above water; inhalation of water takes place at a later stage. Most people demonstrating the instinctive drowning response do not show prior evidence of distress.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "33--0---1---1", "title": "Instinctive Drowning Response"}
{"qas": [{"question": "How long has it been since a human has been submerged in water?", "answer": ""}, {"question": "What percentage of drownings take place in seawater?", "answer": "10%", "ae_score": -0.22205490137965603, "qg_score": null}, {"question": "What percentage of drownings take place in seawater?", "answer": "10%", "ae_score": -0.22205490137965603, "qg_score": null}], "content": "Approximately 90% of drownings take place in freshwater (rivers, lakes and swimming pools) and 10% in seawater. Drownings in other fluids are rare, and often relates to industrial accidents. In New Zealand's early colonial history, so many settlers died while trying to cross rivers that drowning was known as \"The New Zealand death\".\nPeople have drowned in as little as 30 mm of water lying face down. Children have drowned in baths, buckets and toilets; inebriates or those under the influence of drugs have died in puddles.\nDrowning can also happen in ways that are less well known:", "page_name": "Drowning", "page_id": "Drowning", "heading": "Cause", "sub_heading": "Cause", "_id": "33--1---1---1", "title": "Drownings in New Zealand"}
{"qas": [{"question": "Why is it that when a person is rescued, they are able to breathe normally for a few minutes?", "answer": ""}, {"question": "What is the most effective way to get someone out of drowning?", "answer": "Artificial respiration", "ae_score": -0.28149437104528635, "qg_score": null}, {"question": "What is the most effective way to get someone out of drowning?", "answer": "Artificial respiration", "ae_score": -0.28149437104528635, "qg_score": null}], "content": "A conscious person will hold his or her breath (see Apnea) and will try to access air, often resulting in panic, including rapid body movement.  This uses up more oxygen in the blood stream and reduces the time to unconsciousness.  The person can voluntarily hold his or her breath for some time, but the breathing reflex will increase until the person tries to breathe, even when submerged.\nThe breathing reflex in the human body is weakly related to the amount of oxygen in the blood but strongly related to the amount of carbon dioxide (see Hypercapnia). During apnea, the oxygen in the body is used by the cells, and excreted as carbon dioxide.  Thus, the level of oxygen in the blood decreases, and the level of carbon dioxide increases. Increasing carbon dioxide levels lead to a stronger and stronger breathing reflex, up to the ''breath-hold breakpoint'', at which the person can no longer voluntarily hold his or her breath. This typically occurs at an arterial  partial pressure of carbon dioxide of 55 mm Hg, but may differ significantly from individual to individual and can be increased through training.\nThe breath-hold break point can be suppressed or delayed either intentionally or unintentionally.  Hyperventilation before any dive, deep or shallow, flushes out carbon dioxide in the blood resulting in a dive commencing with an abnormally low carbon dioxide level; a potentially dangerous condition known as hypocapnia.  The level of carbon dioxide in the blood after hyperventilation may then be insufficient to trigger the breathing reflex later in the dive and a blackout may occur without warning and before the diver feels any urgent need to breathe.  This can occur at any depth and is common in distance breath-hold divers in swimming pools.  Hyperventilation is often used by both deep and distance free-divers to flush out carbon dioxide from the lungs to suppress the breathing reflex for longer. It is important not to mistake this for an attempt to increase the body's oxygen store.  The body at rest is fully oxygenated by normal breathing and cannot take on any more.  Breath holding in water should always be supervised by a second person, as by hyperventilating, one increases the risk of shallow water blackout because insufficient carbon dioxide levels in the blood fail to trigger the breathing reflex.\nA continued lack of oxygen in the brain, hypoxia, will quickly render a person unconscious usually around a blood partial pressure of oxygen of 25\u201330 mmHg. An unconscious person rescued with an airway still sealed from laryngospasm stands a good chance of a full recovery. Artificial respiration is also much more effective without water in the lungs. At this point the person stands a good chance of recovery if attended to within minutes.\nA lack of oxygen or chemical changes in the lungs may cause the heart to stop beating. This cardiac arrest stops the flow of blood and thus stops the transport of oxygen to the brain. Cardiac arrest used to be the traditional point of death but at this point there is still a chance of recovery. The brain cannot survive long without oxygen and the continued lack of oxygen in the blood combined with the cardiac arrest will lead to the deterioration of brain cells causing first brain damage and eventually brain death from which recovery is generally considered impossible. The brain will die after approximately six minutes without oxygen but special conditions may prolong this.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "33--2--0---1", "title": "How to Become a Free-diver"}
{"qas": [{"question": "How long does it take to die from drowning in salt water?", "answer": ""}, {"question": "What is the medical term for drowning?", "answer": "rigor mortis", "ae_score": -0.4848432202415409, "qg_score": null}, {"question": "What is the medical term for drowning?", "answer": "rigor mortis", "ae_score": -0.4848432202415409, "qg_score": null}], "content": "If water enters the airways of a conscious person, the person will try to cough up the water or swallow it, thus inhaling more water involuntarily.  Upon water entering the airways, both conscious and unconscious persons experience laryngospasm, in which the larynx or the vocal cords in the throat constrict, sealing the airway.  This prevents water from entering the lungs. Because of this laryngospasm, in the initial phase of drowning, water enters the stomach and very little water enters the lungs. Though laryngospasm prevents water from entering the lungs, it also interferes with breathing. In most persons, the laryngospasm relaxes some time after unconsciousness and water can enter the lungs causing a \"wet drowning\".  However, about 7\u201310% of people maintain this seal until cardiac arrest. This has been called \"dry drowning\", as no water enters the lungs.  In forensic pathology, water in the lungs indicates that the person was still alive at the point of submersion. Absence of water in the lungs may be either a dry drowning or indicates a death before submersion.\nWhen water is taken into the lungs, it negatively affects blood chemistry. The mechanism  differs for fresh and salt water.\nAutopsies on drowned persons show no indications of these effects and there appears to be little difference between drownings in salt water and fresh water. After death, rigor mortis will set in and remains for about two days, depending on many factors, including water temperature.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Pathophysiology", "sub_heading": "Water aspiration", "_id": "33--2--1---1", "title": "The Causes of Drowning in the United States"}
{"qas": [{"question": "Why is it that when you are submerged in water for a long period of time, you start to feel the urge to jump out of the water?", "answer": ""}, {"question": "What is the mechanism of drowning called?", "answer": "brain cooling", "ae_score": -0.40086947429681674, "qg_score": null}, {"question": "What is the mechanism of drowning called?", "answer": "brain cooling", "ae_score": -0.40086947429681674, "qg_score": null}], "content": "Submerging the face in water cooler than about 21 \u00b0C triggers the mammalian diving reflex, found in mammals, and especially in marine mammals such as whales and seals. This reflex protects the body by putting it into ''energy saving'' mode to maximize the time it can stay under water. The strength of this reflex is greater in colder water and has three principal effects:\nThe reflex action is automatic and allows both a conscious and an unconscious person to survive longer without oxygen under water than in a comparable situation on dry land. The exact mechanism for this effect has been debated and may be a result of brain cooling similar to the protective effects seen in patients treated with deep hypothermia.\nIn very cold or freezing water reflex reactions can be lethal instead, killing up to 70% of people within 15\u201330 minutes, as they give rise first to cold shock, a combination of uncontrolled gasping and massively increased blood pressure with possible cardiac arrest, followed by the rapid loss of control of bodily functions needed for swimming and gripping.\nHeat transfers very well through water, and body heat is therefore lost extremely quickly in water compared to air, even in merely 'cool' swimming waters around 70F (~20C). A water temperature of 10 C can lead to death in as little as one hour, and water temperatures hovering at freezing can lead to death in as little as 15 minutes. This is because cold water can have other lethal effects on the body, so hypothermia is not usually a reason for drowning or the clinical cause of death for those who drown in cold water.\nThe actual cause of death in cold or very cold water are usually lethal bodily reactions to increased heat loss and to freezing water, rather than any loss of core body temperature. Of those who die after plunging into freezing seas, around 20% die within 2 minutes from cold shock (uncontrolled rapid breathing and gasping causing water inhalation, massive increase in blood pressure and cardiac strain leading to cardiac arrest, and panic), another 50% die within 15 \u2013 30 minutes from cold incapacitation (loss of use and control of limbs and hands for swimming or gripping, as the body 'protectively' shuts down the peripheral muscles of the limbs to protect its core), and exhaustion and unconsciousness cause drowning, claiming the rest within a similar time. A notable example of this occurred during the sinking of the ''Titanic'', in which most people who entered the -2 C water died within 15\u201330 minutes.\nHypothermia (and also cardiac arrest) present a risk for ''survivors'' of immersion, as for survivors of exposure; in particular the risk increases if the survivor, feeling well again, tries to get up and move, not realizing their core body temperature is still very low and will take a long time to recover.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Pathophysiology", "sub_heading": "Cold water immersion", "_id": "33--2--2---1", "title": "The Mammalian Diving Reflex in Cold Water"}
{"qas": [{"question": "What is the difference between drowning and drowning?", "answer": ""}, {"question": "When did the world health organization define drowning?", "answer": "2005", "ae_score": -0.6807647419273983, "qg_score": null}, {"question": "When did the world health organization define drowning?", "answer": "2005", "ae_score": -0.6807647419273983, "qg_score": null}], "content": "The World Health Organization in 2005 defined drowning as \"the process of experiencing respiratory impairment from submersion/immersion in liquid\". This definition does not imply death, or even the necessity for medical treatment after removal of the cause, nor that any fluid enters the lungs. The WHO further recommended that outcomes should be classified as: death, morbidity, and no morbidity. There was also consensus that the terms wet, dry, active, passive, silent, and secondary drowning should no longer be used.\nExperts differentiate between distress and drowning. They also divide drowning into passive and active:", "page_name": "Drowning", "page_id": "Drowning", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "33--3---1---1", "title": "Drowning | Diagnosis"}
{"qas": [{"question": "How do swimming pools know when someone is drowning?", "answer": ""}, {"question": "Who plays an important role in drowning detection?", "answer": "bystanders", "ae_score": -0.43910930413096266, "qg_score": null}, {"question": "Who plays an important role in drowning detection?", "answer": "bystanders", "ae_score": -0.43910930413096266, "qg_score": null}], "content": "Many pools and designated bathing areas either have lifeguards, a pool safety camera system for local or remote monitoring, or computer-aided drowning detection.  However, bystanders play an important role in drowning detection and either intervention or the notification of authorities by phone or alarm.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Management", "sub_heading": "Management", "_id": "33--4--0---1", "title": "Pools and designated bathing areas may have lifeguards, a pool safety camera system"}
{"qas": [{"question": "How do lifeguards know when someone is drowning?", "answer": ""}, {"question": "Who came up with the term drowning?", "answer": "Frank Pia", "ae_score": -0.2745951731452532, "qg_score": null}, {"question": "Who came up with the term drowning?", "answer": "Frank Pia", "ae_score": -0.2745951731452532, "qg_score": null}], "content": "The acronym ''RID'' was originated by Frank Pia to summarize important reasons why lifeguards may be unaware of a drowning. The term stands for \"failure to recognize the struggle, the intrusion of non-lifeguard duties upon lifeguards' primary task-preventive lifeguarding, and the distraction from surveillance duties\".  In his paper on the RID factors, Pia makes a number of observations on the role, and the required behavior and training of lifeguards, as well as the importance of administrators directing lifeguards to this role and avoiding double tasking them (due to the very brief time of 20 \u2013 60 seconds required for drowning to occur). He ended by summarizing the role of lifeguards as guardians of life, and that they should be directed exclusively to this duty and none other, while on surveillance, due to the high value placed on human life.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Management", "sub_heading": "RID factors", "_id": "33--4--1---1", "title": "''RID'' is a term used by Frank Pia to describe the"}
{"qas": [{"question": "Why is it so common for children to die from drowning?", "answer": ""}, {"question": "What age is drowning the leading cause of death?", "answer": "12 and younger", "ae_score": -0.17212636241811635, "qg_score": null}, {"question": "What age is drowning the leading cause of death?", "answer": "12 and younger", "ae_score": -0.17212636241811635, "qg_score": null}], "content": "In 2013 drowning was estimated to have resulted in 368,000 deaths down from 545,000 deaths in 1990.<ref name=GDB2013/> It the third leading cause of death from unintentional trauma after traffic injuries and falls.\nIn many countries, drowning is one of the leading causes of death for children under 12 years old. In the United States in 2006, 1100 people under 20 years of age died from drowning. Typically the United Kingdom suffers 450 drownings per year or 1 per 150,000 of population whereas the United States suffers 6,500 drownings or around 1 per 50,000 of population. In Asia, according to a study by The Alliance for Safe Children, suffocation and drowning were the most easily preventable causes of death for children under five years of age; a 2008 report by the organization found that in Bangladesh, for instance, 46 children drown each day.\n In the United States, it is the second leading cause of death (after motor vehicle crashes) in children 12 and younger.\nPeople who drown are more likely to be male, young or adolescent.<ref name=CDC_Tip_Sheet/>  Surveys indicate that 10% of children under 5 have experienced a situation with a high risk of drowning. Worldwide, about 175,000 children die through drowning every year. The causes of drowning cases in the US from 1999 to 2006 are as follows:", "page_name": "Drowning", "page_id": "Drowning", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "33--5---1---1", "title": "Why Do Children Die Through Drowsing?"}
{"qas": [{"question": "How did they put people in the water during the height of high tide?", "answer": ""}, {"question": "When did the practice of drowning stop in england?", "answer": "1623", "ae_score": -0.6420786093379428, "qg_score": null}, {"question": "When did the practice of drowning stop in england?", "answer": "1623", "ae_score": -0.6420786093379428, "qg_score": null}], "content": "In Europe, drowning was used as capital punishment. In fact, during the Middle Ages, a sentence of death was read using the words \"''cum fossa et furca''\", or \"with drowning-pit and gallows\". Furthermore, drowning was used as a way to determine if a woman was a witch. The idea was that witches would float and innocent women would drown. For more details, see trial by drowning. It is understood that drowning was used as the least brutal form of execution, and was therefore reserved primarily for women, although favored men were executed in this way, as well.\nVersions of this method of execution included throwing people in the water with weights attached and chaining people to rocks below the high tide line, and waiting for the water to cover and drown them.\nDrowning survived as a method of execution in Europe until the 17th and 18th centuries. England had abolished the practice by 1623, Scotland by 1685, Switzerland in 1652, Austria in 1776, Iceland in 1777, and Russia by the beginning of the 1800s. France revived the practice during the French Revolution (1789\u20131799) and was carried out by Jean-Baptiste Carrier at Nantes.", "page_name": "Drowning", "page_id": "Drowning", "heading": "Capital punishment", "sub_heading": "Capital punishment", "_id": "33--6---1---1", "title": "Drowning in Europe"}
{"qas": [{"question": "Why is it so difficult to provide clean tap water to urban and suburban populations?", "answer": ""}, {"question": "What is the chemical in tap water that kills toxins?", "answer": "chlorine", "ae_score": -0.6800642286050604, "qg_score": null}, {"question": "What is the chemical in tap water that kills toxins?", "answer": "chlorine", "ae_score": -0.6800642286050604, "qg_score": null}], "content": "Publicly available treated water has historically been associated with major increases in life expectancy and improved public health.  Water-borne diseases are vastly reduced by proper sewage and fresh water availability. Providing tap water to large urban or suburban populations requires a complex and carefully designed system of collection, storage, treatment and distribution, and is commonly the responsibility of a government agency, often the same agency responsible for the removal and treatment of clean water.\nSpecific chemical compounds are often taken out of tap water during the treatment process to adjust the pH or remove contaminants, and chlorine may be added to kill biological toxins. Local geological conditions affecting groundwater are determining factors for the presence of various metal ions, often rendering the water \"soft\" or \"hard\".\nTap water remains susceptible to biological or chemical contamination. In the event of contamination deemed dangerous to public health, government officials typically issue an advisory regarding water consumption. In the case of biological contamination, residents are usually advised to boil their water before consumption or to use bottled water as an alternative. In the case of chemical contamination, residents may be advised to refrain from consuming tap water entirely until the matter is resolved.\nIn many areas a compound of fluoride is added to tap water in an effort to improve dental health among the public. In some communities \"fluoridation\" remains a controversial issue. (See water fluoridation controversy.)", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Background", "sub_heading": "Background", "_id": "34--0---1---1", "title": "Water Contamination in the United States"}
{"qas": [{"question": "How did humans evolve to drink water from the ground?", "answer": ""}, {"question": "Where does tap water come from in a home?", "answer": "stream or river", "ae_score": -1.0299381363100142, "qg_score": null}, {"question": "Where does tap water come from in a home?", "answer": "stream or river", "ae_score": -1.0299381363100142, "qg_score": null}], "content": "This supply may come from several possible sources.\nDomestic water systems have been evolving since people first located their homes near a running water supply, such as a stream or river.  The water flow also allowed sending waste water away from the residences.\nModern indoor plumbing delivers clean, safe, potable water to each service point in the distribution system.  It is important that the clean water not be contaminated by the waste water (disposal) side of the process system.  Historically, this contamination of drinking water has been the largest killer of humans.\nTap water can sometimes appear cloudy, often mistaken for mineral impurities in the water. It is usually caused by air bubbles coming out of solution due to change in temperature or pressure. Because cold water holds more air than warm water, small bubbles will appear in water. It has a high dissolved gas content that is heated or depressurized, which reduces how much dissolved gas the water can hold. The harmless cloudiness of the water disappears quickly as the gas is released from the water.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Potable water supply", "sub_heading": "Potable water supply", "_id": "34--1---1---1", "title": "How to Clean Your Drinking Water"}
{"qas": [{"question": "Where does hot water come from?", "answer": ""}, {"question": "Where does tap water come from in a house?", "answer": "water heater appliances", "ae_score": -1.7813117355863808, "qg_score": null}, {"question": "Where does tap water come from in a house?", "answer": "water heater appliances", "ae_score": -1.7813117355863808, "qg_score": null}], "content": "Domestic hot water is provided by means of water heater appliances, or through district heating.  The hot water from these units is then piped to the various fixtures and appliances that require hot water, such as lavatories, sinks, bathtubs, showers, washing machines, and dishwashers.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Hot water supply", "sub_heading": "Hot water supply", "_id": "34--2---1---1", "title": "Hot Water for Domestic Hot Water"}
{"qas": [{"question": "What are fixtures and how do they work?", "answer": ""}, {"question": "What are tap water devices called that use water?", "answer": "Fixtures", "ae_score": -0.41389725971659397, "qg_score": null}, {"question": "What are tap water devices called that use water?", "answer": "Fixtures", "ae_score": -0.41389725971659397, "qg_score": null}], "content": "Everything in a building that uses water falls under one of two categories; fixture or appliance.  As the consumption points above perform their function, most produce waste/sewage components that will require removal by the waste/sewage side of the system.  The minimum is an air gap. See cross connection control & backflow prevention for an overview of backflow prevention methods and devices currently in use, both through the use of mechanical and physical principles.\nFixtures are devices that use water without an additional source of power.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Fixtures and appliances", "sub_heading": "Fixtures and appliances", "_id": "34--3---1---1", "title": "Fixture & Appliance"}
{"qas": [{"question": "What is the purpose of water pipes?", "answer": ""}, {"question": "What is the french word for tap water?", "answer": "plombier", "ae_score": -0.5305273267563713, "qg_score": null}, {"question": "What is the french word for tap water?", "answer": "plombier", "ae_score": -0.5305273267563713, "qg_score": null}], "content": "The installation of water pipes can be done using the following materials:\nOther materials, if the pipes made from them have been let into circulation and the widespread use in the construction of the water supply systems.\nFor many centuries, water pipes were made of lead, because of its ease of processing and durability. The use of lead pipes was a cause of health problems due to ignorance of the dangers of lead on the human body, which causes miscarriages and high death rates of newborns. Lead pipes, which were installed mostly in the late 1800s in the US, are still common today, much of which are located in the Northeast and the Midwest. Their impact is relatively small due to the fouling of pipes and stone cessation of the evolution of lead in the water; however, lead pipes are still detrimental. Most of the lead pipes that exist today are being removed and replaced with the more common material, copper or some type of plastic.\nRemnants of pipes in some languages are the names of the experts involved in the execution, reparation, maintenance, and installation of water supply systems, which have been formed from the Latin word 'lead', English word 'plumber', French word, 'plombier'.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Materials", "sub_heading": "Materials", "_id": "34--5---1---1", "title": "Water Pipes \u2014 Remains and Remnants"}
{"qas": [{"question": "How do they determine the standard for potable and fire water?", "answer": ""}, {"question": "Who regulates tap water in the us?", "answer": "FDA", "ae_score": null, "qg_score": null}, {"question": "Who regulates tap water in the us?", "answer": "FDA", "ae_score": null, "qg_score": null}], "content": "Before a water supply system is constructed or modified, the designer and contractor need to consult the local plumbing code and obtain a building permit prior to construction. Even replacing an existing water heater may require a permit and inspection of the work. The US national standard for potable water piping guidelines is NSF/ANSI 61 certified materials. NSF/ANSI also sets standards for certifying polytanks, though the FDA approves the materials. National and local fire codes should be integrated in the design phase of the water system too to prevent \"failure to comply with regulations\" notices. Some areas of the United States require on-site water reserves of potable and fire water by law.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Regulation and compliance", "sub_heading": "Regulation and compliance", "_id": "34--6---1---1", "title": "Water Supply System Design and Construction"}
{"qas": [{"question": "Where does all the water go when you flush the toilet?", "answer": ""}, {"question": "Where does tap water go after it goes to?", "answer": "treatment plants", "ae_score": -0.9087238320156464, "qg_score": null}, {"question": "Where does tap water go after it goes to?", "answer": "treatment plants", "ae_score": -0.9087238320156464, "qg_score": null}], "content": "Wastewater from various appliances, fixtures, and taps is transferred to the waste and sewage removal system via the sewage drain system to treatment plants.  This system consists of larger diameter piping, water traps, and ventilation to prevent toxic gases from entering the living space.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Wastewater", "sub_heading": "Wastewater", "_id": "34--7---1---1", "title": "Waste and Sewage Removal Systems"}
{"qas": [{"question": "How does water conservation work?", "answer": ""}, {"question": "What percentage of water is blocked by plastic flow reducers?", "answer": "between 15 and 50%", "ae_score": -0.7032002619680383, "qg_score": null}, {"question": "What percentage of water is blocked by plastic flow reducers?", "answer": "between 15 and 50%", "ae_score": -0.7032002619680383, "qg_score": null}], "content": "Water flow though a tap can be reduced by inexpensive small plastic flow reducers.  These restrict flow between 15 and 50%, aiding water conservation and reducing the burden on both water supply and treatment facilities.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Water flow reduction", "sub_heading": "Water flow reduction", "_id": "34--8---1---1", "title": "Water flow through a tap can be reduced by inexpensive small plastic flow reducers"}
{"qas": [{"question": "Why is bottled water better for the environment than tap water?", "answer": ""}, {"question": "Who is the author of heart of dryness?", "answer": "James Workman", "ae_score": -0.28224581352576517, "qg_score": null}, {"question": "Who is the author of heart of dryness?", "answer": "James Workman", "ae_score": -0.28224581352576517, "qg_score": null}], "content": "In modern Western society, levels of contaminants found in tap water vary for every household and plumbing system but tend to be low. Two general conceptions with popular appeal are:\nBoth lack scientific support. In reality, both tap water and bottled water are usually safe, although in both cases exceptions can occur. The University of Cincinnati recently completed a Tap Water Quality Analysis, funded by PUR, for major US cities. Its findings show generally safe water quality in most regions. While most US cities have what is considered safe tap water, contaminants ranging from bacteria to heavy metals are present in some tap water, and occasionally serious violations of tap water standards have been well-publicized, such as the severe 1993 Cryptosporidium outbreak in Milwaukee, Wisconsin, which led to several deaths and around 400,000 illnesses (see: Milwaukee Cryptosporidium outbreak). Regarding bottled water quality perceptions and reality, in 1999, the Natural Resources Defense Council (NRDC) released controversial findings from a 4-year study on bottled water. The results of this study claimed that one-third of the waters tested contained levels of contamination\u2014including synthetic organic chemicals, bacteria, and arsenic\u2014in at least one sample that exceeded allowable limits under either state or bottled water industry standards or guidelines. However, the bottled water industry was quick to dispute the claim, saying bottled water is one of the most highly regulated food products under the FDA regulatory authority and that the FDA system worked extremely well when coupled with the International Bottled Water Association's Model Code and unannounced inspections.\nUsing tap water (whether straight from the tap or filtered first) is generally considered to be better for one's environmental impact than habitually drinking bottled water, because the bottling and distribution of bottled water consumes resources and produces emissions (electricity and oil to make the bottles, diesel fuel to truck the filled bottles through the supply chain, truck exhaust, powerplant emissions, bottle recycling, and so on). In comparison, the water treatment plant activities were going to happen anyway in either case, but the other costs and effects are avoided in the tap water case.\nMany municipalities in the United States are making an effort to use tap water over bottled water on government properties and events. However, others voted the idea down, including voters in the state of Washington, who repealed a bottled water tax via citizen initiative.\nJames Workman, author of the book ''Heart of Dryness: How the Last Bushmen Can Help Us Endure the Coming Age of Permanent Drought'' and co-founder of SmartMarkets says that he doesn't believe that \"tap water is bad and bottled water is good\". Rather he cites differences in quality regulations and standards. \"Bottled water is often tap water put through another filter and not held to the same quality regulations as public utility water is.\"\nChlorine is a disinfectant which is added to tap water in the United States.  Chlorine can leave organic material like trihalomethanes and haloacetic acids in the water. The level of chlorine found is small, 1L of chlorinated water gives 0.2 mg of chlorine, which has not been found to cause any health problems.", "page_name": "Tap water", "page_id": "Tap%20water", "heading": "Comparison to bottled water", "sub_heading": "Comparison to bottled water", "_id": "34--9---1---1", "title": "Tap Water and Bottled Water"}
{"qas": [{"question": "Why is it that we are running out of metals?", "answer": ""}, {"question": "When did giurco publish his report on resource depletion?", "answer": "2009", "ae_score": null, "qg_score": null}, {"question": "When did giurco publish his report on resource depletion?", "answer": "2009", "ae_score": null, "qg_score": null}], "content": "Giurco et al. (2009) indicate that the debate about how to analytically describe resource depletion is ongoing. Traditionally, a fixed stock paradigm has been applied, but Tilton and Lagos (2007) suggest using an opportunity cost paradigm is better because the usable resource quantity is represented by price and the opportunity cost of using the resource. Unlike energy minerals such as coal or oil \u2014 or minerals used in a dissipative or metabolic fashion like phosphorus \u2014 most non-energy minerals and metals are unlikely to run out. Metals are inherently recyclable and more readily recoverable from end uses where the metal is used in a pure form and not transformed or dissipated; in addition, metal ore is accessible at a range of different grades. So, although metals are not facing exhaustion, they are becoming more challenging to obtain in the quantities that society demands, and the energy, environmental and social cost of acquiring them could constrain future increases in production and usage.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Definition", "sub_heading": "Definition", "_id": "35--0--0---1", "title": "Resource Depletion \u2014 Using Opportunity Cost Paradigm"}
{"qas": [{"question": "How do we know that the world is running out of oil?", "answer": ""}, {"question": "Who predicted that oil production would peak by 1970?", "answer": "M. King Hubbert", "ae_score": -0.28101474642653257, "qg_score": null}, {"question": "Who predicted that oil production would peak by 1970?", "answer": "M. King Hubbert", "ae_score": -0.28101474642653257, "qg_score": null}], "content": "Given increasing global population and rapidly growing consumption (especially in China and India), frameworks for the analysis of resource depletion can assist in developing appropriate responses. The most popular contemporary focus for resource depletion is oil (or petroleum) resources. In 1956, oil geologist M. King Hubbert famously predicted that conventional oil production from the lower 48 (mainland) states of the United States would peak by 1970 and then enter a terminal decline. This model was accurate in predicting the peak (although the peak year was 1971). This phenomenon is now commonly called 'Peak Oil', with peak production curves known as Hubbert Curves.\nThe concept of peak minerals is an extrapolation and extension of Hubbert's model of peak oil. Although widely cited for his predictions of peak oil, Hubbert intended to explore an appropriate response to the finite supply of oil, and framed this work within the context of increasing global population and rapidly growing consumption of oil.\nIn establishing the peak oil model, Hubbert was primarily focused on arguing that a planned transition was required to ensure future energy services.\nWorld gold production has experienced multiple peaks due to new discoveries and new technologies.  Many mineral resources have exhibited logistic Hubbert-type production trends in the past, but have transitioned to exponential growth during the last 10\u201315 years, precluding reliable estimates of reserves from within the framework of the logistic model.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Definition", "sub_heading": "Peak minerals and peak oil", "_id": "35--0--1---1", "title": "Exploring Resource Depletion in the Age of Global Population and Consumption"}
{"qas": [{"question": "How do we know the value of a mineral if we haven't mined it yet?", "answer": ""}, {"question": "How much substantive work has been done to understand the value of peak oil?", "answer": "limited", "ae_score": -1.3734069729498943, "qg_score": null}, {"question": "How much substantive work has been done to understand the value of peak oil?", "answer": "limited", "ae_score": -1.3734069729498943, "qg_score": null}], "content": "Only limited substantive work is currently undertaken to examine how the concepts and assumptions of Peak oil can be extrapolated so as to be applied to minerals in general. When extrapolating peak oil to account for peak minerals and then utilising this analytical 'peak framework' as a general model of resource exploitation, several factors must be taken into consideration:  \nIn understanding how these factors are important for modelling peak minerals, it is important to consider assumptions concerning the modelling process, assumptions about production (particularly economic conditions), and the ability to make accurate estimates of resource quantity and quality and the potential of future exploration.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Definition", "sub_heading": "Peak minerals as extrapolating peak oil", "_id": "35--0--2---1", "title": "Peak Oil and Peak Minerals as a General Model of Exploration"}
{"qas": [{"question": "Why is Australia so dependent on minerals?", "answer": ""}, {"question": "What percentage of australia's exports are minerals?", "answer": "56%", "ae_score": -0.28988796561853114, "qg_score": null}, {"question": "What percentage of australia's exports are minerals?", "answer": "56%", "ae_score": -0.28988796561853114, "qg_score": null}], "content": "In 2008-09, minerals and fuel exports made up around 56% of Australia\u2019s total exports. Consequently, minerals play a major role in Australia\u2019s capacity to participate in international trade and contribute to the international strength of its currency. Whether this situation contributes to Australia\u2019s economic wealth or weakens its economic position is contested. While those supporting Australia\u2019s reliance on minerals cite the theory of comparative advantage, opponents suggest a reliance on resources leads to issues associated with 'Dutch disease' (a decline in other sectors of the economy associated with natural resource exploitation) and ultimately the hypothesised \u2018resource curse\u2019.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Cheap and easy in the past; costly and difficult in future", "sub_heading": "Cheap and easy in the past; costly and difficult in future", "_id": "35--1--0---1", "title": "Australia\u2019s Reliance on Minerals"}
{"qas": [{"question": "What will happen to the economics of a commodity?", "answer": ""}, {"question": "The paradox where natural resource abundance has a negative impact on the growth of the national economy?", "answer": "resource curse", "ae_score": -0.39294515157753346, "qg_score": null}, {"question": "The paradox where natural resource abundance has a negative impact on the growth of the national economy?", "answer": "resource curse", "ae_score": -0.39294515157753346, "qg_score": null}], "content": "Contrary to the theory of the comparative advantage, many mineral resource-rich countries are often outperformed by resource-poor countries. This paradox, where natural resource abundance actually has a negative impact on the growth of the national economy is termed the resource curse. After an initial economic boost, brought on by the booming minerals economy, negative impacts linked to the boom surpass the positive, causing economic activity to fall below the pre-resource windfall level.\nThe economics of a commodity are generally determined by supply and demand. Mineral supply and demand will change dramatically as all costs (economic, technological, social and environmental) associated with production, processing and transportation of minerals increases with falling ore grades. These costs will ultimately influence the ability of companies to supply commodities, and the ability of consumers to purchase them. It is likely that social and environmental issues will increasingly drive economic costs associated with supply and demand patterns.\nAs neither overall stocks nor future markets are known, most economists normally do not consider physical scarcity as a good indicator for the availability of a resource for society. Economic scarcity has subsequently been introduced as a more valid approach to assess the supply of minerals. There are three commonly accepted measures for economic scarcity: the user costs associated with a resource, the real price of the resource, and the resource\u2019s extraction costs. These measures have historically externalised impacts of a social or environmental nature \u2013 so might be considered inaccurate measures of economic scarcity given increased environmental or social scrutiny in the mining industry. Internalisation of these costs will contribute to economic scarcity by increasing the user costs, the real price of the resource, and its extraction costs.\nWhile the ability to supply a commodity determines its availability as has been demonstrated, demand for minerals can also influence their availability. How minerals are used, where they are distributed and how, trade barriers, downstream use industries, substitution and recycling can potentially influence the demand for minerals, and ultimately their availability. While economists are cognisant of the role of demand as an availability driver, historically they have not considered factors besides depletion as having a long-term impact on mineral availability.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Cheap and easy in the past; costly and difficult in future", "sub_heading": "Threats from dependence on the resource sector", "_id": "35--1--1---1", "title": "Economic Scarcity and the Impact of Depletion on Mineral Supply and Demand"}
{"qas": [{"question": "Why is it so hard for the oil industry to adjust to a higher energy intensity?", "answer": ""}, {"question": "What are the downsides of finding new minerals?", "answer": "less accessible", "ae_score": -1.3009264005335262, "qg_score": null}, {"question": "What are the downsides of finding new minerals?", "answer": "less accessible", "ae_score": -1.3009264005335262, "qg_score": null}], "content": "There are a variety of indicators that show production is becoming more difficult and more expensive. Key environmental indicators that reflect increasingly expensive production are primarily associated with the decline in average ore grades of many minerals. This has consequences in mineral exploration, for mine depth, the energy intensity of mining, and the increasing quantity of waste rock.\nAdjusting to a higher energy intensity is challenging for the industry in light of peak oil and rising energy costs in a carbon constrained future. New deposits in remote locations will also be constrained by rising energy costs, and the associated transportation.\nAlthough new mineral deposits are still being discovered, and reserves are increasing for some minerals, these are of lower quality and are less accessible. This reduces the competitiveness of new deposits in the global sector, and necessitates the development of new technology to remain competitive.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Future production", "sub_heading": "Future production", "_id": "35--2---1---1", "title": "Mineral Exploration & Exploration \u2014 Mineral Exploration"}
{"qas": [{"question": "Why are there so many political and social issues in the United States?", "answer": ""}, {"question": "Who are the main buyers of peak minerals?", "answer": "farmers", "ae_score": -0.7317978011337438, "qg_score": null}, {"question": "Who are the main buyers of peak minerals?", "answer": "farmers", "ae_score": -0.7317978011337438, "qg_score": null}], "content": "Different social issues must be addressed through time in relation to peak minerals at a national scale, and other issues manifest on the local scale.\nAs global mining companies seek to expand operations to access larger mining areas, competition with farmers for land and for scare water is becoming increasingly intense. Negative relationships with near neighbours influence companies' ability to establish and maintain a ''social license to operate'' within the community.\nAccess to identified resources is becoming harder as questions are asked about the benefit from the regional economic development mining is reputed to bring.", "page_name": "Peak minerals", "page_id": "Peak%20minerals", "heading": "Social context", "sub_heading": "Social context", "_id": "35--3---1---1", "title": "Exploration of Peak Minerals at a National and Local Scale"}
{"qas": [{"question": "Why is the justice system in the United States so different from that of the rest of the world?", "answer": ""}, {"question": "The development of this tradition of natural justice into one of natural law is usually attributed to?", "answer": "Stoics", "ae_score": -0.07661218979744734, "qg_score": null}, {"question": "The development of this tradition of natural justice into one of natural law is usually attributed to?", "answer": "Stoics", "ae_score": -0.07661218979744734, "qg_score": null}], "content": "Natural law theories base human rights on a \"natural\" moral, religious or even biological order that is independent of transitory human laws or traditions.\nSocrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right (''dikaion physikon'', ''\u03b4\u03b9\u03ba\u03b1\u03b9\u03bf\u03bd \u03c6\u03c5\u03c3\u03b9\u03ba\u03bf\u03bd'', Latin ''ius naturale''). Of these, Aristotle is often said to be the father of natural law, although evidence for this is due largely to the interpretations of his work by Thomas Aquinas.\nThe development of this tradition of natural justice into one of natural law is usually attributed to the Stoics.\nSome of the early Church Fathers sought to incorporate the until then pagan concept of natural law into Christianity. Natural law theories have featured greatly in the philosophies of Thomas Aquinas, Francisco Su\u00e1rez, Richard Hooker, Thomas Hobbes, Hugo Grotius, Samuel von Pufendorf, and John Locke.\nIn the 16th century, asked by the Spanish monarchs to investigate the legitimacy of claims to land dominion by the ''indios'' of Latin America, Francisco de Vitoria expounded a theory of natural rights, especially in his famous ''Relectio de Indis''.\nIn the 17th century Thomas Hobbes founded a contractualist theory of legal positivism beginning from the principle that man in the state of nature, which is to say without a \"commonwealth\" (a state) is in a state of constant war one with the other and thus in fear of his life and possessions (there being no property nor right without a sovereign to define it). Hobbes asserted natural law as how a rational human, seeking to survive and prosper, would act; the first principle of natural law being to seek peace, in which is self-preservation. Natural law (which Hobbes accepted was a misnomer, there being no law without a commonwealth) was discovered by considering humankind's natural interests, whereas previous philosophers had said that natural rights were discovered by considering the natural law. In Hobbes' opinion, the only way natural law could prevail was for human beings to agree to create a commonwealth by submitting to the command of a sovereign, whether an individual or an assembly of individuals. In this lay the foundations of the theory of a social contract between the governed and the governor.\nHugo Grotius based his philosophy of international law on natural law. He wrote that \"even the will of an omnipotent being cannot change or abrogate\" natural law, which \"would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs.\" (''De iure belli ac pacis'', Prolegomeni XI). This is the famous argument ''etiamsi daremus'' (''non esse Deum''), that made natural law no longer dependent on theology.\nJohn Locke incorporated natural law into many of his theories and philosophy, especially in ''Two Treatises of Government''. Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect \"life, liberty, and property,\" people could justifiably overthrow the existing state and create a new one.\nThe Belgian philosopher of law Frank Van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. There are also emerging and secular forms of natural law theory that define human rights as derivative of the notion of universal human dignity.\n\"Dignity\" is a key term for the discussion of human rights. The Universal Declaration of Human Rights does not justify its claims on any philosophical basis, but rather it simply appeals to human dignity.\nKarl Rahner discusses human dignity as it relates to freedom. Specifically, his ideas of freedom relate to human rights as an appeal to the freedom to communicate with the divine. As embodied individuals who can have this freedom and dignity threatened by external forces, the protection of this dignity takes on an appeal to protect human rights.\nThe term \"human rights\" has replaced the term \"natural rights\" in popularity, because the rights are less and less frequently seen as requiring natural law for their existence. But in fact, the campaigning for the legal recognition of new \"human rights\" (such as LGBT rights, or euthanasia) must necessarily be based on the assumption that some kind of \"Natural Law\" commands the recognition of those \"rights\". The debate on human rights remains thus a debate around the correct interpretation of Natural Law, and human rights themselves a positive, but reductionist, expression thereof", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Natural rights", "sub_heading": "Natural rights", "_id": "36--0---1---1", "title": "Natural Law and Human Rights in the Modern World"}
{"qas": [{"question": "What is the most fundamental fiduciary relationship in our society?", "answer": ""}, {"question": "Who wrote du contrat social (the social contract)?", "answer": "Jean-Jacques Rousseau", "ae_score": -0.273129969919253, "qg_score": null}, {"question": "Who wrote du contrat social (the social contract)?", "answer": "Jean-Jacques Rousseau", "ae_score": -0.273129969919253, "qg_score": null}], "content": "The English philosopher Thomas Hobbes suggested the existence of a hypothetical ''social contract'' where a group of free individuals agree for the sake of preservation to form institutions to govern them. They give up their natural complete liberty in exchange for protection from the Sovereign. This led to John Locke's theory that a failure of the government to secure rights is a failure which justifies the removal of the government, and was mirrored in later postulation by Jean-Jacques Rousseau in his \"Du Contrat Social\" (The Social Contract).\nInternational equity expert Paul Finn has echoed this view:\nthe most fundamental fiduciary relationship in our society is manifestly that which exists between the community (the people) and the state, its agencies and officials.\nThe relationship between government and the governed in countries which follow the English law tradition is a fiduciary one. In equity law, a politician's fiduciary obligations are not only the duties of good faith and loyalty, but also include duties of skill and competence in managing a country and its people. Originating from within the Courts of Equity, the fiduciary concept exists to prevent those holding positions of power from abusing their authority. The fiduciary relationship between government and the governed arises from the governments ability to control people with the exercise of its power. In effect, if a government has the power to abolish any rights, it is equally burdened with the fiduciary duty to protect such an interest because it would benefit from the exercise of its own discretion to extinguish rights which it alone had the power to dispose of.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Social contract", "sub_heading": "Social contract", "_id": "36--1---1---1", "title": "The Fiduciary Relationship Between Government and the Governed"}
{"qas": [{"question": "The Golden Rule?", "answer": ""}, {"question": "When was the declaration toward a global ethic published?", "answer": "1993", "ae_score": -0.42544677640268963, "qg_score": null}, {"question": "When was the declaration toward a global ethic published?", "answer": "1993", "ae_score": -0.42544677640268963, "qg_score": null}], "content": "The Golden Rule, or the ''ethic of reciprocity'' states that one must do unto others as one would be treated themselves; the principle being that reciprocal recognition and respect of rights ensures that one's own rights will be protected. This principle can be found in all the world's major religions in only slightly differing forms, and was enshrined in the \"Declaration Toward a Global Ethic\" by the Parliament of the World's Religions in 1993.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Reciprocity", "sub_heading": "Reciprocity", "_id": "36--2---1---1", "title": "The Golden Rule, or the ''ethic of reciprocity'', is"}
{"qas": [{"question": "Why did the Soviet Union have so many secret courts?", "answer": ""}, {"question": "Who was required to take their client's guilt for granted?", "answer": "Defense lawyers", "ae_score": -0.3904507061371676, "qg_score": null}, {"question": "Who was required to take their client's guilt for granted?", "answer": "Defense lawyers", "ae_score": -0.3904507061371676, "qg_score": null}], "content": "Soviet concept of human rights was different from conceptions prevalent in the West. According to Western legal theory, \"it is the individual who is the beneficiary of human rights which are to be asserted ''against'' the government\", whereas Soviet law declared that state is the source of human rights. Therefore, Soviet legal system regarded law as an arm of politics and courts as agencies of the government. Extensive extra-judiciary powers were given to the Soviet secret police agencies. The regime abolished Western rule of law, civil liberties, protection of law and guarantees of property. According to Vladimir Lenin, the purpose of socialist courts was \"not to eliminate terror ... but to substantiate it and legitimize in principle\".\nCrime was determined not as the infraction of law, but as any action which could threaten the Soviet state and society. For example, a desire to make a profit could be interpreted as a counter-revolutionary activity punishable by death. The liquidation and deportation of millions peasants in 1928\u201331 was carried out within the terms of Soviet Civil Code. Some Soviet legal scholars even asserted that \"criminal repression\" may be applied in the absence of guilt.\". Martin Latsis, chief of the Ukrainian Cheka explained: \"Do not look in the file of incriminating evidence to see whether or not the accused rose up against the Soviets with arms or words. Ask him instead to which class he belongs, what is his background, his education, his profession. These are the questions that will determine the fate of the accused. That is the meaning and essence of the Red Terror.\"\nThe purpose of public trials was \"not to demonstrate the existence or absence of a crime \u2013 that was predetermined by the appropriate party authorities \u2013 but to provide yet another forum for political agitation and propaganda for the instruction of the citizenry (see Moscow Trials for example). Defense lawyers, who had to be party members, were required to take their client's guilt for granted...\"", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Soviet concept of human rights", "sub_heading": "Soviet concept of human rights", "_id": "36--3---1---1", "title": "The Red Terror in the Soviet Republic"}
{"qas": [{"question": "What are the main arguments for and against global warming?", "answer": ""}, {"question": "What is the name of the philosophy of human rights?", "answer": "Ipso Facto Legal Rights Theory", "ae_score": -0.10617623570171997, "qg_score": null}, {"question": "What is the name of the philosophy of human rights?", "answer": "Ipso Facto Legal Rights Theory", "ae_score": -0.10617623570171997, "qg_score": null}], "content": "The philosopher John Finnis argues that human rights are justifiable on the grounds of their instrumental value in creating the necessary conditions for human well-being. Interest theories highlight the duty to respect the rights of other individuals on grounds of self-interest:\nHuman rights law, applied to a State's own citizens serves the interest of states, by, for example, minimizing the risk of violent resistance and protest and by keeping the level of dissatisfaction with the government manageable\nThe biological theory considers the comparative reproductive advantage of human social behavior based on empathy and altruism in the context of natural selection.\nHuman security is an emerging school of thought which challenges the traditional, state-based conception of security and argues that a people-focused approach to security is more appropriate in the modern interdependent world and would be more effective in advancing the security of individuals and societies across the globe.\n'''Ipso Facto Legal Rights Theory'''\nAccording to the recommendation of human rights scholar Barrister Dr Mohammed Yeasin Khan LLB Honours, LLM, PhD, PGDL, Barrister-at-Law (Lincoln\u2019s Inn), UK: \u2018Right\u2019 being synonymous of \u2018legal\u2019 and antonymous of both \u2018wrong\u2019 and \u2018illegal\u2019, every \u2018right\u2019 of any human person is ipso facto a \u2018legal right\u2019 which deserves protection of law and legal remedy irrespective of having been written into the law, constitution or otherwise in any country.\n'''Man for Man Theory of World Peace'''\nAccording to Barrister Dr Mohammed Yeasin Khan: The only way \u2018(a) to make the world terrorism and war free and also free from hunger, poverty, discrimination and exploitation; (b) to establish rule of law and economic, political and social justice; and (c) to confirm freedom of man, peace and development worldwide\u2019 is protection and promotion human rights as \u2018Ipso Facto Legal Rights\u2019 and the unity of the world community in one and single theory of \u2018man for man\u2019 correlative, interdependent and \u2018one to one-cum-one for other\u2019 approach, namely, the \u2018Man for Man Theory\u2019 approach of world peace.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Other theories of human rights", "sub_heading": "Other theories of human rights", "_id": "36--4---1---1", "title": "'''Man for Man Theory of World Peace'''"}
{"qas": [{"question": "What was so revolutionary about Thomas Jefferson's \"Declaration of Rights\" that made it so controversial?", "answer": ""}, {"question": "Whose views on natural rights are best articulated in reflections on the revolution in france?", "answer": "Edmund Burke", "ae_score": -0.36820707623355226, "qg_score": null}, {"question": "Whose views on natural rights are best articulated in reflections on the revolution in france?", "answer": "Edmund Burke", "ae_score": -0.36820707623355226, "qg_score": null}], "content": "Edmund Burke was an 18th-century philosopher, political theorist and statesman largely associated with the school of conservatism. His views on natural rights are best articulated in ''Reflections on the Revolution in France'', which directly attacked the ''Declaration of the Rights of Man and the Citizen'' (1789) and its authors.\nA great deal of Burke\u2019s uneasiness of the ''Declaration'' lies in the drafter\u2019s abandonment of the existing establishment. For Burke, constitutional legitimacy was derived not from the Rousseauian doctrine of general will, but from a form of inherited wisdom. He thought that it was arrogant and limiting for the drafters of the ''Declaration'' to cast aside traditional notions that had stood the test of time. Although it may seem to the drafters that they had abandoned the shackles of tradition, for Burke, they had limited their findings to the narrow minded conception of one person or group. This is the grounding from which Burke\u2019s attack of the ''Declaration'' is based.\nBurke did not deny the existence of natural rights; rather he thought that the a priori reasoning adopted by the drafters produced notions that were too abstract to have application within the framework of society. In stating that \u201cthe pretended right of these theorists are all extremes; and in a proportion as they are metaphysically true, they are morally and politically false\u201d, Burke identified that abstract rights are meaningless without a societal framework:\nWhat is the use of discussing a man\u2019s abstract right to food or medicine? The question is upon the method of procuring and administering them.\nIn contrast to Locke, Burke did not believe the purpose of government was to protect pre-existing natural rights; he believed \u201cthe primitive rights of man undergo such a variety of refractions and reflections, that it becomes absurd to talk of them as if they continued in the simplicity of their original direction.\u201d For Burke it was the government, as a result of long social evolution, that transformed the meaningless natural rights into the practical advantaged afforded to citizens.\nIt was not the rights themselves, as much as the level of abstraction and the placing of them above government which Burke found dangerous. He stated \u201cthose who pull down important ancient establishments, who wantonly destroy modes of administration, and public institutions\u2026 are the most mischievous, and therefore the wickedest of men\u201d. For Burke politics had no simple answers, and definitely no overarching, universal maxims such as those expressed in the ''Declaration''. Rather the rights afforded to individuals were to be assessed in the context of the social framework. However, he acknowledged that the simplicity of the ''Declaration'' was attractive and feared its ability to undermine social order. Burke believed that the absolute nature of these principles of abstraction were inherently revolutionary; they were uncompromising and any derogation from the principles a reason to rise up in arms. This was a problem because;\nAll government\u2026 is founded on compromise and barter. We balance inconveniences; we give and take; we remit some rights, that we may enjoy others; and we choose rather to be happy citizens, than subtle disputants.\nThe natural rights \u201cAgainst which there can be no prescription; against these no agreements is binding\u201d gave the revolutionaries the tools to destroy the very society that Burke believed afforded them with rights. In this way Burke thought the rights contained in the ''Declaration'' would lead to \u201cthe antagonist world of madness, discord, vice, confusion, and unavailing sorrow.\u201d", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Critiques of human rights", "sub_heading": "Critiques of human rights", "_id": "36--5--0---1", "title": "Burke\u2019s Attack on the ''Declaration''"}
{"qas": [{"question": "Why did Thomas Bentham think that there was no logical basis for the theory of natural rights?", "answer": ""}, {"question": "What type of approach did bentham think was harmful to society?", "answer": "individualistic", "ae_score": -0.39281984022322264, "qg_score": null}, {"question": "What type of approach did bentham think was harmful to society?", "answer": "individualistic", "ae_score": -0.39281984022322264, "qg_score": null}], "content": "The 18th-century Utilitarian philosopher Jeremy Bentham criticised the ''Declaration of the Rights of Man and the Citizen'' in his text ''Anarchical Fallacies''. He famously asserted that the concept of natural rights was \u201cnonsense upon stilts\u201d. Bentham criticised the ''Declaration'' both for the language that it adopted and the theories it posited, stating; \u201cLook to the letter, you find nonsense; look beyond the letter, you find nothing.\u201d\nOne of the critiques Bentham levelled against the ''Declaration'' was its assertions of rights in the form of absolute and universal norms. He identified that absolute rights possessed by everyone equally are meaningless and undesirable. They lack meaning because if everyone has, for example, unbounded liberty, there is nothing precluding them from using that liberty to impinge on the liberty of another. In this way \u201chuman government and human laws\u201d are required to give some bounds to rights in order for them to be realised. Even if advocates of absolute rights recognise this necessity, as the proponents of the ''Declaration'' did, Bentham argues that it is in vain . \u201cIt would be self-contradictory, because these rights are, in the same breath which their existence is declared, declared to be impresciptable; and impriscriptable\u2026 means nothing unless it excludes the interference of the laws.\u201d\nIn addition to this contradiction, Bentham warned of the dangers of couching rights in absolute terms. A government that is able to protect every person\u2019s right absolutely and equally is a utopian aspiration, but the ''Declaration'' couches it as the conditions for its legitimacy. \u201cAgainst every government which fails in any degree of fulfilling these expectations, then, it is the professed object of this manifesto to excite insurrection.\u201d Bentham does not deny that there are some laws that are morally wrong; his uneasiness is in easily justifying a revolutionary call to arms \u2013 with the violence, chaos and destruction associated with it \u2013 based on a repugnant law.\nOf the theoretical faults, Bentham thought that natural rights were a construction adopted to pursue the selfish aims of the drafters, of which no logical basis could be found. He acknowledged that it may be desirable to have rights, but \u201ca reason for wishing that a certain right were established, is not that right; want is not supply; hunger is not bread.\u201d To establish rights existed by virtue of laws enacted by a sovereign was logically sound, but to assert rights established by nature was not. \u201cA natural right is a son that never had a father.\u201d\nNot only did Bentham think that there was no logical basis for the theory of natural rights, but he believed that their individualistic approach was harmful to society.\nThe great enemies of public peace are the selfish and the dissocial passions \u2013 necessary as they are \u2013 the one to the very existence of each individual, the other to his security\u2026What has been the object, the perpetual and palpable object, of this declaration to pretended rights? To add such force as possible to these passions, but already too strong, - to burst the cords that hold them in, - to say to the selfish passions, there \u2013 everywhere \u2013 is your prey! - to the angry passions, there \u2013everywhere- is your enemy. Such is the morality of this celebrated manifesto.\nBentham thought that society was dependent upon people's ability to pursue the greater good, not just the short-term satisfaction of their own desires. The advancement of natural rights, which he saw as celebrating selfishness, was to provide the means to break down the social community that makes human life bearable.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Critiques of human rights", "sub_heading": "Jeremy Bentham on natural rights", "_id": "36--5--1---1", "title": "Jeremy Bentham\u2019s Critique of the ''Declaration''"}
{"qas": [{"question": "Why is it so hard to find a good place to live?", "answer": ""}, {"question": "What was marx's basic criticism of political society?", "answer": "co-operative", "ae_score": -0.4794193761319344, "qg_score": null}, {"question": "What was marx's basic criticism of political society?", "answer": "co-operative", "ae_score": -0.4794193761319344, "qg_score": null}], "content": "In On the Jewish Question, Karl Marx criticized ''Declaration of the Rights of Man and of the Citizen'' as bourgeois ideology:\nand that:\nThus for Marx, liberal rights and ideas of justice are premised on the idea that each of us needs protection from other human beings. Therefore, liberal rights are rights of separation, designed to protect us from such perceived threats. Freedom on such a view, is freedom from interference. What this view denies is the possibility \u2014 according to Marx, the fact \u2014 that real freedom is to be found positively in our relations with other people. It is to be found in human community, not in isolation. So insisting on a regime of rights encourages us to view each other in ways which undermine the possibility of the real freedom we may find in human emancipation.\nMarxist critical theorist Slavoj \u017di\u017eek argued that: \"liberal attitudes towards the other are characterized both by respect for otherness, openness to it, and an obsessive fear of harassment. In short, the other is welcomed insofar as its presence is not intrusive, insofar as it is not really the other. Tolerance thus coincides with its opposite. My duty to be tolerant towards the other effectively means that I should not get too close to him or her, not intrude into his space\u2014in short, that I should respect his intolerance towards my over-proximity. This is increasingly emerging as the central human right of advanced capitalist society: the right not to be 'harassed', that is, to be kept at a safe distance from others.\" and \"universal human rights are effectively the right of white, male property-owners to exchange freely on the market, exploit workers and women, and exert political domination.\"\nBritish sociologist Robert Fine claims that the key to Marx\u2019s argument was to rebut the radicalism Bauer espoused: a radicalism that not only denied the rights of Jews but at once trashed the rights of man and citizen as such. What Marx stood for in the Jewish Question as in his earlier writings more generally was a philosophy of right. Fine believes what Marx stood against was a spiritless radicalism that revealed its inhumanity not only through its hostility to Jews but also through its hostility to the idea of right.\" Moreover, Fine argued that Marx argued that the society that gives rise to the idea of rights is the same as that which gives rise to the commodity form. They are two sides of the same medal. It is a society based on production by independent producers whose contact with each other is mediated through the exchange of products on the market. These producers are formally free to produce what and how much they wish. They are formally equal in that no producer can force others to produce against their will or expropriate their products against their will. They are self\u2010interested in that they are all entitled to pursue their own private interests regardless of what others think or do. Their contact with other producers takes the form of free and equal exchanges in which individuals exchange their property in return for the property of another and this exchange of unneeded things in return for useful things appears to be done for the mutual benefit of each party.\nFine also claims that for Marx, exchange relations appear to be formed among free and equal property owners who enter a voluntary contract in pursuit of their own self\u2010interest. Fine cites what he believes to be Marx's point about how in exchange lies the clue to all modern conceptions of freedom and equal right:\nFurthermore, the parties to the exchange must place themselves in relation to one another as persons whose will resides in those objects and must behave in such a way that each does not appropriate the commodity of the other and alienate his own, except through an act to which both parties consent. Marx characterised this sphere of commodity exchange as \u2018a very Eden of the innate rights of man\u2019 \u2013 the realm of Freedom, Equality, Property andBentham:\nThus according to Robert Fine, Marx's basic criticism was that within political society people were seen as co-operative, while in their economic roles they were competitive, individualistic and egoistic. In short, the theory of rights expressed the division and alienation of human beings.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Critiques of human rights", "sub_heading": "Marxist Critique of Human Rights", "_id": "36--5--2---1", "title": "Marxism and the Jewish Question"}
{"qas": [{"question": "What is MacIntyre's argument against the existence of human rights?", "answer": ""}, {"question": "In which work by alasdair macintyre do we find the concept of?", "answer": "After Virtue", "ae_score": -0.4695047632552282, "qg_score": null}, {"question": "In which work by alasdair macintyre do we find the concept of?", "answer": "After Virtue", "ae_score": -0.4695047632552282, "qg_score": null}], "content": "Alasdair MacIntyre is a Scottish philosopher who has published a number of works in a variety of philosophical fields, including political philosophy, ethics and metaphysics. MacIntyre criticises the concept of human rights in After Virtue and he famously asserts that \u201cthere are no such rights, and belief in them is one with belief in witches and in unicorns.\u201d\nMacIntyre argues that every attempt at justifying the existence of human rights has failed. The assertions by 18th century philosophers that natural rights are self-evident truths, he argues, are necessarily false as there are no such things as self-evident truths. He says that the plea 20th century philosophers made to intuition show a flaw in philosophical reasoning. MacIntyre then outlines that, although Dworkin is not wrong in asserting that the inability to demonstrate a statement does not necessitate its falsity, the same argument can be applied in relation to witches and unicorns.\nMacIntyre made this critique of human rights in the context of a wider argument about the failure of the Enlightenment to produce a coherent moral system. Philosophers of the enlightenment sought to cast aside the discredited notions of hierarchy and theology as justifications for morality. Instead, MacIntyre argues, the enlightenment placed the individual as the sovereign authority to dictate what is right and wrong. However allegiances to historical notions of morality remained and philosophers sought to find a secular and rational justification for existing beliefs. The problem, MacIntyre maintains, is that theological morality was developed to overcome defects in human nature; to posit an example of the ideal. Without this notion of \u2018perfect humanity\u2019 the only remaining foundation to build a moral theory on was the foundation of imperfect human nature. For MacIntyre, the result was a collection of moral stances, each claiming to have a rational justification and each disputing the findings of the rival notions.\nMacIntyre believes that a number of the moral debates that occur in society can be explained as a result of this failure of the \u201cEnlightenment Project\u201d. Human rights are an example of a moral belief, founded in previous theological beliefs, which make the false claim of being grounded in rationality. To illustrate how the principles lead to conflict, he gives the example of abortion; in this case the right of the mother to exercise control over her body is contrasted with the deprivation of a potential child to the right to life. Although both the right to liberty and the right to life are, on their own, considered morally acceptable claims, conflict arises when we posit them against each other.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Critiques of human rights", "sub_heading": "Alasdair MacIntyre on Human Rights", "_id": "36--5--3---1", "title": "MacIntyre\u2019s Argument for Human Rights"}
{"qas": [{"question": "John Locke?", "answer": ""}, {"question": "Who argued that every person has a property interest in their own body?", "answer": "Henry of Ghent", "ae_score": -0.4553451445459651, "qg_score": null}, {"question": "Who argued that every person has a property interest in their own body?", "answer": "Henry of Ghent", "ae_score": -0.4553451445459651, "qg_score": null}], "content": "Henry of Ghent articulated the theory that every person has a property interest in their own body. John Locke uses the word property in both broad and narrow senses. In a broad sense, it covers a wide range of human interests and aspirations; more narrowly, it refers to material goods. He argues that property is a natural right and it is derived from labour. In addition, property precedes government and government cannot \"dispose of the estates of the subjects arbitrarily.\" To deny valid property rights according to Locke is to deny human rights. The British philosopher had significant impacts upon the development of the Government of the UK and was central to the fundamental founding philosophy of the United States. Karl Marx later critiqued Locke's theory of property in his ''Theories of Surplus Value'', seeing the beginnings of a theory of surplus value in Locke's works. In Locke's ''Second Treatise'' he argued that the right to own private property was unlimited as long as nobody took more than they could use without allowing any of their property to go to waste and that there were enough common resources of comparable quality available for others to create their own property. Locke did believe that some would be more \"industrious and rational\" than others and would amass more property, but believed this would not cause shortages. Though this system could work before the introduction of money, Marx argued in ''Theories of Surplus Value'' that Locke's system would break down and claimed money was a contradiction of the law of nature on which private property was founded.", "page_name": "Philosophy of human rights", "page_id": "Philosophy%20of%20human%20rights", "heading": "Theory of value and property", "sub_heading": "Theory of value and property", "_id": "36--6---1---1", "title": "Locke's Theories of Surplus Value"}
{"qas": [{"question": "How did the name of the rainbow trout come to be?", "answer": ""}, {"question": "Who is the author of the description of rainbow trout?", "answer": "Robert J. Behnke", "ae_score": -0.15002871966878015, "qg_score": null}, {"question": "Who is the author of the description of rainbow trout?", "answer": "Robert J. Behnke", "ae_score": -0.15002871966878015, "qg_score": null}], "content": "The scientific name of the rainbow trout is ''Oncorhynchus mykiss''. The species was originally named by German naturalist and taxonomist Johann Julius Walbaum in 1792 based on type specimens from the Kamchatka Peninsula in Siberia. Walbaum's original species name, ''mykiss'', was derived from the local Kamchatkan name used for the fish, ''mykizha''. The name of the genus is from the Greek ''onkos'' (\"hook\") and ''rynchos'' (\"nose\"), in reference to the hooked jaws of males in the mating season (the \"kype\").<ref name=BehnkeO/>\nSir John Richardson, a Scottish naturalist, named a specimen of this species ''Salmo gairdneri'' in 1836 to honor Meredith Gairdner, a Hudson's Bay Company surgeon at Fort Vancouver on the Columbia River who provided Richardson with specimens. In 1855, William P. Gibbons, the curator of Geology and Mineralogy at the California Academy of Sciences, found a population and named it ''Salmo iridia'' (Latin: rainbow), later corrected to ''Salmo irideus''. These names faded once it was determined that Walbaum's description of type specimens was conspecific and therefore had precedence. In 1989, morphological and genetic studies indicated that trout of the Pacific basin were genetically closer to Pacific salmon (''Oncorhynchus'' species) than to the ''Salmos'' \u2013 brown trout (''Salmo trutta'') or Atlantic salmon (''Salmo salar'') of the Atlantic basin.<ref>{{cite journal |title=The Classification and Scientific Names of Rainbow and Cutthroat Trouts |journal=Fisheries |volume=14 |year=1989 |pages=4\u201310 |author1=Smith, Gerald R. |author2=Stearley, Ralph F. |issue=1 |doi= 10.1577/1548-8446(1989)014\n  Thus, in 1989, taxonomic authorities moved the rainbow, cutthroat and other Pacific basin trout into the genus ''Oncorhynchus''. Walbaum's name had precedence, so the species name ''Oncorhynchus mykiss'' became the scientific name of the rainbow trout.  The previous species names ''irideus'' and ''gairdneri'' were adopted as subspecies names for the coastal rainbow and Columbia River redband trout, respectively.<ref name=BehnkeO/> Anadromous forms of the coastal rainbow trout (''O. m. irideus'')  or redband trout (''O. m. gairdneri'') are commonly known as steelhead.<ref name=Behnke2002-67/>\nSubspecies of ''Oncorhynchus mykiss'' are listed below as described by fisheries biologist Robert J. Behnke (2002).", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Taxonomy", "sub_heading": "Taxonomy", "_id": "37--0---1---1", "title": "The Classification and Scientific Names of Rainbow and Cutthroat Trouts"}
{"qas": [{"question": "What is the difference between freshwater and lake-dwelling rainbow trout?", "answer": ""}, {"question": "How much does a rainbow trout weigh in pounds?", "answer": "20 lbs", "ae_score": -0.8584959073822669, "qg_score": null}, {"question": "How much does a rainbow trout weigh in pounds?", "answer": "20 lbs", "ae_score": -0.8584959073822669, "qg_score": null}], "content": "Resident freshwater rainbow trout adults average between 1 and in riverine environments, while lake-dwelling and anadromous forms may reach 20 lbs.  Coloration varies widely between regions and subspecies. Adult freshwater forms are generally blue-green or olive green with heavy black spotting over the length of the body.  Adult fish have a broad reddish stripe along the lateral line, from gills to the tail, which is most pronounced in breeding males.<ref name=Behnke2002/> The caudal fin is squarish and only mildly forked. Lake-dwelling and anadromous forms are usually more silvery in color with the reddish stripe almost completely gone.  Juvenile rainbow trout display parr marks (dark vertical bars) typical of most salmonid juveniles. In some redband and golden trout forms parr marks are typically retained into adulthood. Some coastal rainbow trout (''O. m. irideus'') and Columbia River redband trout (''O. m. gairdneri'') populations and cutbow hybrids may also display reddish or pink throat markings similar to cutthroat trout. In many regions, hatchery-bred trout can be distinguished from native trout via fin clips,", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Description", "sub_heading": "Description", "_id": "37--1---1---1", "title": "Rainbow trout coloration and distribution"}
{"qas": [{"question": "Where do rainbow trout come from?", "answer": ""}, {"question": "Where do rainbow trout live in the wild?", "answer": "spring creeks", "ae_score": null, "qg_score": null}, {"question": "Where do rainbow trout live in the wild?", "answer": "spring creeks", "ae_score": null, "qg_score": null}], "content": "Freshwater resident rainbow trout usually inhabit and spawn in small to moderately large, well oxygenated, shallow rivers with gravel bottoms. They are native to the alluvial or freestone streams that are typical tributaries of the Pacific basin, but introduced rainbow trout have established wild, self-sustaining populations in other river types such as bedrock and spring creeks. Lake resident rainbow trout are usually found in moderately deep, cool lakes with adequate shallows and vegetation to support production of sufficient food sources. Lake populations generally require access to gravelly bottomed streams to be self-sustaining.\nSpawning sites are usually a bed of fine gravel in a riffle above a pool. A female trout clears a redd in the gravel by turning on her side and beating her tail up and down. Female rainbow trout usually produce 2000 to 3000 4 to eggs per kilogram of weight. During spawning, the eggs fall into spaces between the gravel, and immediately the female begins digging at the upstream edge of the nest, covering the eggs with the displaced gravel.  As eggs are released by the female, a male moves alongside and deposits milt (sperm) over the eggs to fertilize them. The eggs usually hatch in about four to seven weeks although the time of hatching varies greatly with region and habitat. Newly hatched trout are called sac fry or alevin. In approximately two weeks, the yolk sac is completely consumed and fry commence feeding mainly on zooplankton. The growth rate of rainbow trout is variable with area, habitat, life history and quality and quantity of food. As fry grow, they begin to develop \"parr\" marks or dark vertical bars on their sides. In this juvenile stage, immature trout are often called \"parr\" because of the marks. These small juvenile trout are sometimes called fingerlings because they are approximately the size of a human finger.  In streams where rainbow trout are stocked for sport fishing but no natural reproduction occurs, some of the stocked trout may survive and grow or \"carryover\" for several seasons before they are caught or perish.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Life cycle", "sub_heading": "Life cycle", "_id": "37--2--0---1", "title": "Rainbow Trout \u2014 Species and Habitats"}
{"qas": [{"question": "What is the difference between steelhead and oceangoing?", "answer": ""}, {"question": "What kind of rainbow trout are in canada?", "answer": "steelhead", "ae_score": -0.2372516551650325, "qg_score": null}, {"question": "What kind of rainbow trout are in canada?", "answer": "steelhead", "ae_score": -0.2372516551650325, "qg_score": null}], "content": "The oceangoing (anadromous) form, including those returning for spawning, are known as steelhead in Canada and the U.S. In Tasmania they are commercially propagated in sea cages and are known as '''ocean trout''', although they are the same species.\nLike salmon, steelhead return to their original hatching grounds to spawn. Similar to Atlantic salmon, but unlike their Pacific ''Oncorhynchus'' salmonid kin, steelhead are iteroparous (able to spawn several times, each time separated by months) and make several spawning trips between fresh and salt water, although fewer than 10 percent of native spawning adults survive from one spawning to another. The survival rate for introduced populations in the Great Lakes is as high as 70 percent. As young steelhead transition from freshwater to saltwater, a process called \"smoltification\" occurs where the trout undergoes physiological changes to allow it to survive in sea water. There are genetic differences between freshwater and steelhead populations that may account for the smoltification in steelheads.\nJuvenile steelhead may remain in the river for one to three years before smolting and migrating to sea. Individual steelhead populations leave the ocean and migrate into their freshwater spawning tributaries at different times of the year. Two general forms exist\u2014\"summer-run steelhead\" and \"winter-run steelhead\". Summer-run fish leave the ocean between May and October, before their reproductive organs are fully mature. They mature in fresh water while en route to spawning grounds where they spawn in the spring. Summer-run fish generally spawn in longer, more inland rivers such as the Columbia River. Winter-run fish are ready to spawn when they leave the ocean, typically between November and April, and spawn shortly after returning to fresh water.  Winter-run fish generally spawn in shorter, coastal rivers typically found along the Olympic Peninsula and British Columbia coastline,<ref name=Behnke2002-68/> and summer-run fish are found in some shorter, coastal streams. Once steelhead enter riverine systems and reach suitable spawning grounds, they spawn just like resident freshwater rainbow trout.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Life cycle", "sub_heading": "Steelhead life cycle", "_id": "37--2--1---1", "title": "Rainbow trout | Life cycle | Steelhead life cycle"}
{"qas": [{"question": "What do rainbow trout eat?", "answer": ""}, {"question": "What is the length of a rainbow trout?", "answer": "one-third", "ae_score": null, "qg_score": null}, {"question": "What is the length of a rainbow trout?", "answer": "one-third", "ae_score": null, "qg_score": null}], "content": "Rainbow trout are predators with a varied diet and will eat nearly anything they can capture. They are not as piscivorous or aggressive as brown trout or chars. Rainbow trout, including juvenile steelhead in fresh water, routinely feed on larval, pupal and adult forms of aquatic insects (typically caddisflies, stoneflies, mayflies and aquatic diptera).  They also eat fish eggs and adult forms of terrestrial insects (typically ants, beetles, grasshoppers and crickets) that fall into the water. Other prey include small fish up to one-third of their length, crayfish, shrimp, and other crustaceans. As rainbow trout grow, the proportion of fish consumed increases in most populations. Some lake-dwelling forms may become planktonic feeders. In rivers and streams populated with other salmonid species, rainbow trout eat varied fish eggs, including those of salmon, brown and cutthroat trout, mountain whitefish and the eggs of other rainbow trout. Rainbows also consume decomposing flesh from carcasses of other fish.  Adult steelhead in the ocean feed primarily on other fish, squid and amphipods.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Feeding", "sub_heading": "Feeding", "_id": "37--3---1---1", "title": "Rainbow trout are predators with a varied diet and will eat nearly anything they can"}
{"qas": [{"question": "Why are there so many different types of rainbow trout?", "answer": ""}, {"question": "Where do rainbow trout live in russia?", "answer": "the Kamchatka Peninsula", "ae_score": null, "qg_score": null}, {"question": "Where do rainbow trout live in russia?", "answer": "the Kamchatka Peninsula", "ae_score": null, "qg_score": null}], "content": "The native range of ''Oncorhynchus mykiss'' is in the coastal waters and tributary streams of the Pacific basin, from the Kamchatka Peninsula in Russia, east along the Aleutian Islands, throughout southwest Alaska, the Pacific coast of British Columbia and southeast Alaska, and south along the west coast of the U.S. to northern Mexico. It is claimed that the Mexican forms of ''Oncorhynchus mykiss'' represent the southernmost native range of any trout or salmon (''Salmonidae''), though the Formosan landlocked salmon (''O. masou formosanus'') in Asia inhabits a similar latitude.  The range of coastal rainbow trout (''O. m. irideus'') extends north from the Pacific basin into tributaries of the Bering Sea in northwest Alaska, while forms of the Columbia River redband trout (''O. m. gairdneri'') extend east into the upper Mackenzie River and Peace River watersheds in British Columbia and Alberta, Canada, which eventually drain into the Beaufort Sea, part of the Arctic Ocean. Since 1875, the rainbow trout has been widely introduced into suitable lacustrine and riverine environments throughout the United States and around the world. Many of these introductions have established wild, self-sustaining populations.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Range", "sub_heading": "Range", "_id": "37--4---1---1", "title": "''Oncorhynchus mykiss'' is a rainbow"}
{"qas": [{"question": "How does the U.S. get so much farmed rainbows?", "answer": ""}, {"question": "Where do rainbow trout come from in the us?", "answer": "Idaho", "ae_score": -0.6861725832162663, "qg_score": null}, {"question": "Where do rainbow trout come from in the us?", "answer": "Idaho", "ae_score": -0.6861725832162663, "qg_score": null}], "content": "Rainbow trout are commercially farmed in many countries throughout the world. The practice began in the late 19th century, and since the 1950s commercial production has grown dramatically.  Worldwide, in 2007, 604695 t of farmed rainbow trout were harvested with a value of about US $2.6 billion.<ref name=fao/> The largest producer is Chile. In Chile and Norway, sea cage production of steelhead has expanded to supply export markets. Inland production of rainbow trout to supply domestic markets has increased in countries such as Italy, France, Germany, Denmark and Spain. Other significant trout-producing countries include the U.S., Iran, the United Kingdom,<ref name=fao/> and Lesotho. While the U.S. rainbow trout industry as a whole is viewed as ecologically responsible, trout raised elsewhere are not necessarily farmed with the same methods.\nAbout three-quarters of U.S. production comes from Idaho, particularly the Snake River area, due in part to the quality and temperature of the water available there. California and Washington also produce significant amounts of farmed trout.  In the east, Pennsylvania, North Carolina and West Virginia have farming operations.<ref name=Harlow/> Rainbow trout farming is one of the largest finfish aquaculture industries in the U.S. They are raised inland in facilities where raceways or ponds have continuously flowing water with little pollution and a low risk of escape. The U.S. industry is noted for using best management practices.<ref name=Monterey/> Imports constitute only about 15 percent of farmed rainbows sold in the U.S., and nearly all domestic production is consumed within the country; very little is exported. The U.S. produces about 7 percent of the world's farmed trout. Rainbow trout, especially those raised in farms and hatcheries, are susceptible to enteric redmouth disease. A considerable amount of research has been conducted on redmouth disease, given its serious implications for rainbow trout farming. The disease does not infect humans.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Artificial propagation", "sub_heading": "Artificial propagation", "_id": "37--5--0---1", "title": "The U.S. Rainbow Trout Industry"}
{"qas": [{"question": "Why are rainbow trout considered \"species of concern\"?", "answer": ""}, {"question": "What are rainbow trout called in the wild?", "answer": "cutbows", "ae_score": -0.45516886156132685, "qg_score": null}, {"question": "What are rainbow trout called in the wild?", "answer": "cutbows", "ae_score": -0.45516886156132685, "qg_score": null}], "content": "Rainbow trout, primarily hatchery-raised fish of the coastal rainbow trout subspecies (''O. m. irideus'') introduced into waters inhabited with cutthroat trout, will breed with cutthroats and produce fertile hybrids called cutbows. In the case of the westslope cutthroat trout (''O. clarki lewisi''), hybridization with introduced rainbow and Yellowstone cutthroat trout (''O. clarki bouvieri'') is threatening the westslope cutthroat trout with genomic extinction. Such introductions into the ranges of redband trout (''O. m. gairdneri, newberrii'', and ''stonei'') have severely reduced the range of pure stocks of these subspecies, making them \"species of concern\" in their respective ranges.\nWithin the range of the Kern River golden trout of Southern California, hatchery-bred rainbows introduced into the Kern River have diluted the genetic purity of the Kern River rainbow trout ''(O. m. gilberti)'' and golden trout ''(O. m. aguabonita)'' through intraspecific breeding.  The Beardslee trout, (''O. m. irideus'' var. ''beardsleei''), a genetically unique lake-dwelling variety of the coastal rainbow trout that is isolated in Lake Crescent (Washington), is threatened by the loss of its only spawning grounds in the Lyre River to siltation and other types of habitat degradation.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Conservation", "sub_heading": "Conservation", "_id": "37--6--0---1", "title": "Rainbow and Yellowstone Cutthroat Trout Threatened by Intraspecific Breeding"}
{"qas": [{"question": "Why are rainbow trout so susceptible to diseases like M. cerebralis?", "answer": ""}, {"question": "When was rainbow trout first found in the us?", "answer": "1987", "ae_score": -0.23547743746725294, "qg_score": null}, {"question": "When was rainbow trout first found in the us?", "answer": "1987", "ae_score": -0.23547743746725294, "qg_score": null}], "content": "''Myxobolus cerebralis'' is a myxosporean parasite of salmonids (salmon, trout, and their allies) that causes whirling disease in farmed salmon and trout and also in wild fish populations. It was first described in rainbow trout in Germany a century ago, but its range has spread and it has appeared in most of Europe, northern Asia, the U.S., South Africa and other countries. In the 1980s, ''M. cerebralis'' was found to require ''Tubifex tubifex'' (a kind of segmented worm) to complete its life cycle. The parasite infects its hosts with its cells after piercing them with polar filaments ejected from nematocyst-like capsules.<ref name=wddescription/>\nThis parasite was originally a mild pathogen of brown trout in central Europe and other salmonids in northeast Asia, and the spread of the rainbow trout has greatly increased its impact. Having no innate immunity to ''M. cerebralis'', rainbow trout are particularly susceptible, and can release so many spores that even more resistant species in the same area, such as ''Salmo trutta'', can become overloaded with parasites and incur mortalities of 80 to 90 percent.  Where ''M. cerebralis'' has become well-established, it has caused decline or even elimination of whole cohorts of fish.\nThe parasite ''M. cerebralis'' was first recorded in North America in 1956 in Pennsylvania, but until the 1990s whirling disease was considered a manageable problem only affecting rainbow trout in hatcheries. It eventually became established in natural waters of the Rocky Mountain states (Colorado, Wyoming, Utah, Montana, Idaho, New Mexico), where it is damaging several sport fishing rivers. Some streams in the western U.S. lost 90 percent of their trout. Whirling disease threatens recreational fishing, which is important for the tourism industry, a key component of the economies of some U.S. western states. For example, in 2005 anglers in Montana spent approximately $196,000,000 in activities directly related to trout fishing in the state. Some of the salmonids that ''M. cerebralis'' infects (bull trout, cutthroat trout, and anadromous forms of rainbow trout\u2014steelhead) are already threatened or endangered, and the parasite could worsen their population decline.\nThe New Zealand mud snail (''Potamopyrgus antipodarum''), once endemic to New Zealand, has spread widely and has become naturalised and an invasive species in many areas including: Australia, Tasmania, Asia (Japan), in the Garmat Ali River in Iraq since 2008), Europe (since 1859 in England), and North America (U.S. and Canada: Thunder Bay in Ontario since 2001, British Columbia since July 2007), most likely inadvertently during human activity.<ref name=usgs/> It can reach concentrations greater than 500,000 per m\u00b2, endangering the food chain by outcompeting native snails and water insects for food, leading to sharp declines in native populations. There is evidence North American fishes are unable to digest the tiny but hard shells of the mud snail, and that their presence may result in poor growth outcomes for rainbow trout.\nThe mud snail was first detected in the U.S. in Idaho's Snake River in 1987. Since then, the snail has spread to the Madison River, Firehole River, and other watercourses around Yellowstone National Park, and has been discovered throughout the western U.S. The exact means of transmission is unknown, but it is likely that it was introduced in water transferred with live game fish and has been spread by ship ballast or contaminated recreational equipment such as wading gear.\n''Didymosphenia geminata'', commonly known as didymo or rock snot, is a species of diatom that produces nuisance growths in freshwater rivers and streams with consistently cold water temperatures. In New Zealand, invasive didymo can form large mats on the bottom of rivers and streams in late winter. It is not considered a significant human health risk, but it can affect stream habitats and sources of food for fish, including rainbow trout, and make recreational activities unpleasant. Even though it is native in North America, it is considered a nuisance organism or invasive species.\nEnteric redmouth disease is a bacterial infection of freshwater and marine fish caused by the pathogen ''Yersinia ruckeri''.  It is primarily found in rainbow trout and other cultured salmonids. The disease is characterized by subcutaneous hemorrhaging of the mouth, fins, and eyes. It is most commonly seen in fish farms with poor water quality. Redmouth disease was first discovered in Idaho rainbow trout in the 1950s.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Conservation", "sub_heading": "Invasive species and disease", "_id": "37--6--1---1", "title": "''Myxobolus cerebralis'' and the New Zealand Mud S"}
{"qas": [{"question": "How do they remove rainbow trout from rivers?", "answer": ""}, {"question": "Where do rainbow trout get caught in the smokey mountains?", "answer": "electrofishing", "ae_score": -0.5738130925364672, "qg_score": null}, {"question": "Where do rainbow trout get caught in the smokey mountains?", "answer": "electrofishing", "ae_score": -0.5738130925364672, "qg_score": null}], "content": "Some fisheries are focused on removing rainbow trout in order to reestablish native trout populations.  This can be done by poisoning rivers with chemicals such as  antimycin or rotenone which have been declared safe  in the USA by the Environmental Protection Agency.  Once the chemicals have dissipated native trout are  released into the river.  Another method is to use electrofishing which enable the fish to be caught alive and harvested or re-located.  This technique has been used in the Great Smokey Mountains National Park to rid it of rainbow trout that were introduced in the 1930s and have thrived ever since.  They are hoping to re-establish native brook trout in at least some of the 2100-mile river system. Neither method of control is 100% effective and are best regarded as methods to change the relative population sizes of fish species.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Conservation", "sub_heading": "Removal Methods", "_id": "37--6--2---1", "title": "Rainbow Trout Control in the Great Smokey Mountains"}
{"qas": [{"question": "Why are steelhead populations so low in the U.S.?", "answer": ""}, {"question": "How many distinct population segments are there in washington, oregon, california?", "answer": "15", "ae_score": -0.4730657479873596, "qg_score": null}, {"question": "How many distinct population segments are there in washington, oregon, california?", "answer": "15", "ae_score": -0.4730657479873596, "qg_score": null}], "content": "Steelhead populations in parts of its native range have declined due to a variety of human and natural causes. While populations in Alaska and along the British Columbia coast are considered healthy, populations in Kamchatka and some populations along the U.S. west coast are in decline.The U.S. National Marine Fisheries Service has 15 identified distinct population segments (DPS)s, in Washington, Oregon, and California. Eleven of these DPSs are listed under the U.S. Endangered Species Act, ten as threatened and one as endangered. One DPS on the Oregon Coast is designated a U.S. Species of Concern.<ref name=noaa/>\nThe Southern California DPS, which was listed as endangered in 2011, has been affected by habitat loss due to dams, confinement of streams in concrete channels, water pollution, groundwater pumping, urban heat island effects, and other byproducts of urbanization. Steelhead in the Kamchatka Peninsula are threatened by over-harvest, particularly from poaching and potential development, and are listed in the ''Red Data Book of Russia'' that documents rare and endangered species.\nSeveral studies have shown that almost all California coastal steelhead are of native origin, despite over a century of hatchery stocking. Genetic analysis shows that the South Central California Coast DPS and Southern California DPS from Malibu Creek north, and including the San Gabriel River, Santa Ana River and San Mateo Creek, are not hatchery strains. Steelhead from Topanga Creek and the Sweetwater River were partly, and those from San Juan Creek completely, of hatchery origin. Genetic analysis has also shown that the steelhead in the streams of the Santa Clara County and Monterey Bay basins are not of hatchery origin, including the Coyote Creek, Guadalupe River, Pajaro River, Permanente Creek, Stevens Creek, San Francisquito Creek, San Lorenzo River, and San Tomas Aquino Creek basins. Natural waterfalls and two major dams have isolated Russian River steelhead from freshwater rainbow trout forms above the impassable barriers; a 2007 genetic study of fin samples collected from steelhead at 20 different sites both above and below passage barriers in the watershed found that although 30 million hatchery trout were stocked in the river from 1911 to 1925, the steelhead remain of native and not hatchery origin.\nReleases of conventionally reared hatchery steelhead pose ecological risks to wild steelhead populations. Hatchery steelhead are typically larger than the wild forms and can displace wild-form juveniles from optimal habitats. Dominance of hatchery steelhead for optimal microhabitats within streams may reduce wild steelhead survival as a result of reduced foraging opportunity and increased rates of predation.<ref>{{cite journal |year=1999 |title=Behavioral Interactions Among Hatchery-reared Steelhead Smolts and Wild ''Oncorhynchus mykiss'' in Natural Streams |journal=North American Journal of Fisheries Management 19 |pages=948\u2013956 |author1=McMichael, G. A. |author2=Pearsons, T. N. |author3=Leider, S. A. |doi=10.1577/1548-8675(1999)019", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Conservation", "sub_heading": "Steelhead declines", "_id": "37--6--3---1", "title": "Hatchery Steelhead in the U.S. West Coast"}
{"qas": [{"question": "Why is there no commercial fishing for steelhead?", "answer": ""}, {"question": "What kind of rainbow trout are in puget sound?", "answer": "steelhead", "ae_score": -0.5596676015440977, "qg_score": null}, {"question": "What kind of rainbow trout are in puget sound?", "answer": "steelhead", "ae_score": -0.5596676015440977, "qg_score": null}], "content": "Rainbow trout and steelhead are highly regarded game fish. Rainbow trout are a popular target for fly fishers, and several angling methods are used. The use of lures presented via spinning, casting or trolling techniques is common. Rainbow trout can also be caught on various live and dead natural baits. The International Game Fish Association recognizes the world record for rainbow trout as a fish caught on Saskatchewan's Lake Diefenbaker by Sean Konrad on September 5, 2009. The fish weighed 48 lb and was a genetically modified hatchery escapee. Many anglers consider the rainbow trout the hardest-fighting trout species, as this fish is known for leaping when hooked and putting up a powerful struggle. It is considered one of the top five sport fish in North America and the most important game fish west of the Rocky Mountains.<ref name=fwsRainbow/>\nThere are tribal commercial fisheries for steelhead in Puget Sound, the Washington coast and in the Columbia River, but there has been controversy regarding over-harvesting of native stocks.\nThe highly desirable sporting qualities and adaptability of the rainbow trout to hatchery rearing and new habitats resulted in it being introduced to many countries around the world by or at the behest of sport fishermen.  Many of these introductions have resulted in environmental and ecological problems, as the introduced rainbow trout disrupt local ecosystems and outcompete or eat indigenous fishes. Other introductions to support sport angling in waters either devoid of fish or with seriously depleted native stocks have created world-class fisheries such as in the Firehole River in Yellowstone National Park, and in the Great Lakes. ", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Uses", "sub_heading": "Uses", "_id": "37--7--0---1", "title": "Rainbow trout and steelhead are highly regarded game fish"}
{"qas": [{"question": "Why is rainbow trout so popular in Western cuisine?", "answer": ""}, {"question": "What is the antioxidant in rainbow trout called?", "answer": "Astaxanthin", "ae_score": -0.39982838270153126, "qg_score": null}, {"question": "What is the antioxidant in rainbow trout called?", "answer": "Astaxanthin", "ae_score": -0.39982838270153126, "qg_score": null}], "content": "Rainbow trout is popular in Western cuisine; both wild-caught and farmed fish are eaten. It has tender flesh and a mild, somewhat nutty flavor.<ref name=Harlow/> Wild fish has a stronger, gamier taste than farmed fish.<ref name=Egan/> While the taste of wild-caught trout is often promoted as superior,<ref name=Wright/> it is illegal to sell or market wild-caught rainbow trout, which are legally classified as game fish, in the United States. Thus, rainbow trout and \"steelhead\" sold in American restaurants is farmed.  Farmed rainbow are considered one of the safest fish to eat and are noted for high levels of vitamin B and a generally appealing flavor.  Seafood Watch ranks farmed rainbow as a \"Best Choice\" fish for human consumption.\nThe color and flavor of the flesh depends on the diet and freshness of the trout.  Farmed trout and some populations of wild trout, especially anadromous steelhead, have reddish or orange flesh as a result of high astaxanthin levels in their diets. Astaxanthin is a powerful antioxidant that may be from a natural source or a synthetic trout feed.  Rainbow trout raised to have pinker flesh from a diet high in astaxanthin are sometimes sold in the U.S. with labeling calling them \"steelhead\".  As wild steelhead are in decline in some parts of their range, farmed rainbow are viewed as a preferred alternative.<ref name=Monterey/>  In Chile and Norway, rainbow trout farmed in saltwater sea cages are sold labeled as steelhead.\nTrout can be cooked as soon as they are cleaned, without scaling, skinning or filleting.<ref name=Wright/> If cooked with the skin on, the meat tends to hold together better.<ref name=Harlow/>  While trout sold commercially in Europe is often prepared and served this way, most trout sold commercially in the U.S. have had heads removed and have been fully or partially deboned and filleted. Medium to heavy bodied white wines, such as chardonnay, sauvignon blanc or pinot gris are typical wine pairings for trout.", "page_name": "Rainbow trout", "page_id": "Rainbow%20trout", "heading": "Uses", "sub_heading": "As food", "_id": "37--7--1---1", "title": "Rainbow Trout \u2014 The Best Choice Fish for Human Consumption"}
{"qas": [{"question": "Why are there so many different types of Human Resources Management?", "answer": ""}, {"question": "Who is known as the father of human resource management ( hrm )?", "answer": "Umberto Eco", "ae_score": -0.9188083162682039, "qg_score": null}, {"question": "Who is known as the father of human resource management ( hrm )?", "answer": "Umberto Eco", "ae_score": -0.9188083162682039, "qg_score": null}], "content": "Living within a complex human environment determines the need for specific skills. Managing humans requires a specific set of skills that are very different from those required from managing machines. While many Business Schools favor quantitative approaches for HR management, a different approach based more on qualitative skills as that presented by the European researcher Daniele Trevisani (an early scholar of the semiotician Umberto Eco), identified specific sets and sub-sets of HRM qualitative skills management tools:\nResearch on Human resources management critical accidents has shown that a lack in any of the three pillars, on example an overestimation of how motivation can overcome physical fatigue, or even subtle misunderstanding in team communications and wrong message decoding, can not only decrease performance but generate dramatic failures. An holistic approach to information management, processing and embodied cognition, as experienced in the \"three pillars model\" allows the control of the Cognitive dimension of Human resources management and not only of ots quantitative layer. The cognitive dimension encompasses the minds of those who transmit, receive, and respond to or act on information. It refers to individuals\u2019 or groups\u2019 information processing, perception, judgment, and decision making, and is therefore a higher level of understanding compared to simple data analysis.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Human resources management skills", "sub_heading": "Human resources management skills", "_id": "38--2---1---1", "title": "The Cognitive Dimension of Human resources management"}
{"qas": [{"question": "How did the Human Resources field come to be?", "answer": ""}, {"question": "Who is known as the father of human resource management?", "answer": "Frederick Winslow Taylor", "ae_score": -0.3201757512510372, "qg_score": null}, {"question": "Who is known as the father of human resource management?", "answer": "Frederick Winslow Taylor", "ae_score": -0.3201757512510372, "qg_score": null}], "content": "The Human Resources field evolved first in 18th century Europe from a simple idea by Robert Owen and Charles Babbage during the industrial revolution. These men knew that people were crucial to the success of an organization. They expressed that the wellbeing of employees led to perfect work. Without healthy workers, the organization would not survive.HR later emerged as a specific field in the early 20th century, influenced by Frederick Winslow Taylor (1856-1915). Taylor explored what he termed \"scientific management\" others later referred to \"Taylorism\", striving to improve economic efficiency in manufacturing jobs. He eventually keyed in on one of the principal inputs into the manufacturing process\u2014labor\u2014sparking inquiry into workforce productivity.\nMeanwhile, in England C S Myers, inspired by unexpected problems among soldiers which had alarmed generals and politicians in the First World War, set up a National Institute of Industrial Psychology, setting seeds for the human relations movement, which on both sides of the Atlantic built on the research of Elton Mayo and others to document through the Hawthorne studies (1924-1932) and others how stimuli, unrelated to financial compensation and working conditions, could yield more productive workers.Work by Abraham Maslow (1908-1970), Kurt Lewin (1890-1947), Max Weber (1864-1920), Frederick Herzberg (1923-2000), and David McClelland (1917-1998), forming the basis for studies in industrial and organizational psychology, organizational behavior and organizational theory, was interpreted in such a way as to further claims of legitimacy for an applied discipline.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "History", "sub_heading": "History", "_id": "38--3--0---1", "title": "Human Resources and the Human Relations Movement"}
{"qas": [{"question": "Why is Stalin considered to be one of the greatest leaders in history?", "answer": ""}, {"question": "What does hcm stand for in human resource management?", "answer": "Human capital management", "ae_score": -0.5113159854159361, "qg_score": null}, {"question": "What does hcm stand for in human resource management?", "answer": "Human capital management", "ae_score": -0.5113159854159361, "qg_score": null}], "content": "By the time enough theoretical evidence existed to make a business case for strategic workforce management, changes in the business landscape (\u00e0 la Andrew Carnegie, John Rockefeller) and in public policy (\u00e0 la Sidney and Beatrice Webb, Franklin D. Roosevelt and the New Deal) had transformed the employer-employee relationship, and the discipline became formalized as \"industrial and labor relations\". In 1913 one of the oldest known professional HR associations \u2014 the Chartered Institute of Personnel and Development (CIPD) \u2014 started in England as the ''Welfare Workers' Association''; it changed its name a decade later to the ''Institute of Industrial Welfare Workers'', and again the next decade to ''Institute of Labour Management'' before settling upon its current name in 2000. Likewise in the United States, the world's first institution of higher education dedicated to workplace studies \u2014 the School of Industrial and Labor Relations \u2014 formed at Cornell University in 1945. In 1948, what would later become the largest professional HR association \u2014 the Society for Human Resource Management (SHRM) \u2014 formed as the ''American Society for Personnel Administration'' (ASPA).\nIn the Soviet Union, meanwhile, Stalin's use of patronage exercised through the \"HR Department\" equivalent in the Bolshevik Party, its Orgburo, demonstrated the effectiveness and influence of human-resource policies and practices,and Stalin himself acknowledged the importance of the human resource.\nDuring the latter half of the 20th century, union membership declined significantly, while workforce management continued to expand its influence within organizations. In the USA, the phrase \"industrial and labor relations\" came into use to refer specifically to issues concerning collective representation, and many companies began referring to the proto-HR profession as \"personnel administration\". Many current HR practices originated with the needs of companies in the 1950s to develop and retain talent.\nIn the late 20th century, advances in transportation and communications greatly facilitated workforce mobility and collaboration. Corporations began viewing employees as assets rather than as cogs in a machine. \"Human resources management\" consequently, became the dominant term for the function\u2014the ASPA even changing its name to the Society for Human Resource Management (SHRM) in 1998.\n\"Human capital management\" (HCM)is sometimes used synonymously with HR, although \"human capital\" typically refers to a more narrow view of human resources; i.e., the knowledge the individuals embody and can contribute to an organization. Likewise, other terms sometimes used to describe the field include \"organizational management\", \"manpower management\", \"talent management\", \"personnel management\", and simply \"people management\".", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "History", "sub_heading": "Birth and evolution of the discipline", "_id": "38--3--1---1", "title": "Human Capital Management"}
{"qas": [{"question": "What is the difference between a Human Resources Manager and a Nag?", "answer": ""}, {"question": "Who is the HR representative on the office?", "answer": "Toby Flenderson", "ae_score": -0.5008659888861514, "qg_score": null}, {"question": "Who is the HR representative on the office?", "answer": "Toby Flenderson", "ae_score": -0.5008659888861514, "qg_score": null}], "content": "Several popular media productions have depicted HR. On the U.S. television series of ''The Office'', HR representative Toby Flenderson is sometimes seen as a nag because he constantly reminds coworkers of company policies and government regulations. Long-running American comic strip ''Dilbert''  frequently portrays sadistic HR policies through character Catbert, the \"evil director of human resources\".An HR manager is the title character in the 2010 Israeli film ''The Human Resources Manager'', while an HR intern is the protagonist in 1999 French film ''Ressources humaines''. Additionally, the main character in the BBC sitcom ''dinnerladies'', Philippa, is an HR manager.  The protagonist of the Mexican telenovela ''Ma\u00f1ana Es Para Siempre'' is a Director of Human Resources.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "History", "sub_heading": "In popular media", "_id": "38--3--2---1", "title": "Human Resources in Popular Media"}
{"qas": [{"question": "What exactly is a Human Resources Manager?", "answer": ""}, {"question": "Who is the leader of human resource management?", "answer": "Dave Ulrich", "ae_score": -0.27359478599888715, "qg_score": null}, {"question": "Who is the leader of human resource management?", "answer": "Dave Ulrich", "ae_score": -0.27359478599888715, "qg_score": null}], "content": "Dave Ulrich lists the functions of HR as: aligning HR and business strategy, re-engineering organization processes, listening and responding to employees, and managing transformation and change.\nAt the macro-level, HR is in charge of overseeing organizational leadership and culture. HR also ensures compliance with employment and labor laws, which differ by geography, and often oversees health, safety, and security. In circumstances where employees desire and are legally authorized to hold a collective bargaining agreement, HR will typically also serve as the company's primary liaison with the employee's representatives (usually a labor union). Consequently, HR, usually through representatives, engages in lobbying efforts with governmental agencies (e.g., in the United States, the United States Department of Labor and the National Labor Relations Board) to further its priorities.\nTo look at Human Resource Management more specifically, it has four basic functions: staffing, training and development, motivation and maintenance. Staffing is the recruitment and selection of potential employees, done through interviewing, applications, networking, etc. Training and development is the next step in a continuous process of training and developing competent and adapted employees. Motivation is key to keeping employees highly productive. This function can include employee benefits, performance appraisals and rewards. The last function of maintenance involves keeping the employees' commitment and loyalty to the organization.\nThe discipline may also engage in mobility management, especially pertaining to expatriates; and it is frequently involved in the merger and acquisition process. HR is generally viewed as a support function to the business, helping to minimize costs and reduce risk.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Practice", "sub_heading": "Practice", "_id": "38--4--0---1", "title": "Human Resource Management (HR)"}
{"qas": [{"question": "What is the difference between an HR Director and a Chief Executive Officer?", "answer": ""}, {"question": "How many human resource management professionals are there?", "answer": "half a million", "ae_score": -0.22210290420754666, "qg_score": null}, {"question": "How many human resource management professionals are there?", "answer": "half a million", "ae_score": -0.22210290420754666, "qg_score": null}], "content": "There are half a million HR practitioners in the United States and millions more worldwide. The Chief HR Officer or HR Director is the highest ranking HR executive in most companies and typically reports directly to the Chief Executive Officer and works with the Board of Directors on CEO succession.\nWithin companies, HR positions generally fall into one of two categories: generalist and specialist. Generalists support employees directly with their questions, grievances, and work on a range of projects within the organization. They \"may handle all aspects of human resources work, and thus require an extensive range of knowledge. The responsibilities of human resources generalists can vary widely, depending on their employer's needs.\" Specialists, conversely, work in a specific HR function. Some practitioners will spend an entire career as either a generalist or a specialist while others will obtain experiences from each and choose a path later. Being an HR manager consistently ranks as one of the best jobs, with a #4 ranking by ''CNN Money'' in 2006 and a #20 ranking by the same organization in 2009, due to its pay, personal satisfaction, job security, future growth, and benefit to society.\nHuman resource consulting is a related career path where individuals may work as advisers to companies and complete tasks outsourced from companies. In 2007, there were 950 HR consultancies globally, constituting a USD $18.4 billion market. The top five revenue generating firms were Mercer, Ernst & Young, Deloitte, Watson Wyatt (now part of Towers Watson), Aon (now merged with Hewitt), and PwC consulting. For 2010, HR consulting was ranked the #43 best job in America by ''CNN Money''.\nSome individuals with PhDs in HR and related fields, such as industrial and organizational psychology and management, are professors who teach HR principles at colleges and universities. They are most often found in Colleges of Business in departments of HR or Management. Many professors conduct research on topics that fall within the HR domain, such as financial compensation, recruitment, and training.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Practice", "sub_heading": "Careers", "_id": "38--4--1---1", "title": "The Best Jobs in Human Resources"}
{"qas": [{"question": "How has technology changed the way we work?", "answer": ""}, {"question": "Which aspect of recruitment has been the most influenced by?", "answer": "information technology", "ae_score": -0.6869325479799517, "qg_score": null}, {"question": "Which aspect of recruitment has been the most influenced by?", "answer": "information technology", "ae_score": -0.6869325479799517, "qg_score": null}], "content": "Technology has had a significant impact on human resources practices. Human Resources is transitioning to a more technology based profession because utilizing technology makes information more accessible to the whole organization, eliminates time doing administrative tasks, allows businesses to function globally and cuts costs. Information technology has improved HR practices in the following areas:\nRecruiting has been the most influenced by information technology. In the past, recruiters had relied on printing in publications and word of mouth to fill open positions. HR professionals were not able to post a job in more than one location and did not have access to millions of people, causing the lead time of new hires to be drawn out and tiresome. With the use of e-recruiting tools, HR professionals can post jobs and track applicants for thousands of jobs in various locations all in one place. Interview feedback, background and drug tests, and onboarding can all be viewed online. This helps the HR professionals keep track of all of their open jobs and applicants in a way that is faster and easier than before. E-recruiting also helps eliminate limitations of geographic location. Jobs can be posted and seen by anyone with internet access. In addition to recruiting portals, HR professionals have a social media presence that allows them to attract employees through the World Wide Web. On social media they can build the company's brand by posting news about the company and photos of fun company events. \nHuman resources professionals generally process a considerable amount of paperwork on a daily basis. This paperwork could be anything from a department transfer request to an employee's confidential tax form. In addition to processing this paperwork, it has to be on file for a considerable period of time. The use of Human Resources Information Systems (HRIS) has made it possible for companies to store and retrieve files in an electronic format for people within the organization to access when needed. This eliminates thousands of files and frees up space within the office. Another benefit of HRIS is that it allows for information to be accessed in a timelier manner. Instead of HR professionals having to dig through files to gain information, it is accessible in seconds via the HRIS. Having all of the information in one place also allows for professionals to analyze data quicker and across multiple locations because the information is in a centralized location. Examples of some Human Resources Information Systems are PeopleSoft, MyTime, SAP, Timeco, and JobsNavigator.\nTechnology makes it possible for human resources professionals to train new staff members in a more efficient manner. This gives employees the ability to access onboarding and training programs from anywhere. This eliminates the need for trainers to meet with new hires face to face when completing necessary paperwork to start. Training in virtual classrooms makes it possible for the HR professionals to train a large number of employees quickly and to assess their progress through computerized testing programs. Some employers even incorporate an instructor with virtual training so that new hires are receiving the most vital training. Employees can take control of their own learning and development by engaging in training at a time and place of their choosing, helping them manage their work-life balance. Managers are able to track the training through the internet as well, which helps to reduce redundancy in training and training costs. Skype, virtual chat rooms, and interactive training sites are all resources that enable a more technological approach to training to enhance the experience for the new hire.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Practice", "sub_heading": "Virtual Human Resources", "_id": "38--4--2---1", "title": "How Technology Has Impacted Human Resources Practices"}
{"qas": [{"question": "How do colleges/universities work?", "answer": ""}, {"question": "Where was the first school for college level study in hr?", "answer": "Cornell University", "ae_score": -0.6687083608170206, "qg_score": null}, {"question": "Where was the first school for college level study in hr?", "answer": "Cornell University", "ae_score": -0.6687083608170206, "qg_score": null}], "content": "Several universities offer programs of study pertaining to HR and related fields. The School of Industrial and Labor Relations at Cornell University was the world's first school for college-level study in HR. It continues to offer education at the undergraduate, graduate, and professional levels; and it operates a joint degree program with the Samuel Curtis Johnson Graduate School of Management. Other universities with entire colleges dedicated to the study of HR include Pennsylvania State University, Rutgers, The State University of New Jersey School of Management and Labor Relations, Michigan State University, Indiana University, Purdue University, University of Minnesota, Xavier Labour Relations Institute at Jamshedpur-India, University of Illinois at Urbana-Champaign, Renmin University of China and the London School of Economics. In Canada, the School of Human Resources Management at York University is leading education and research in the HRM field. Many colleges and universities house departments and institutes related to the field, either within a business school or in another college. Most business schools offer courses in HR, often in their departments of management.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Education", "sub_heading": "Education", "_id": "38--5---1---1", "title": "HR and Related Fields"}
{"qas": [{"question": "What is the difference between a Professional HR Association and a Professional Human Resources Association?", "answer": ""}, {"question": "Where is the chartered institute of personnel and development located?", "answer": "England", "ae_score": -0.45522690452611503, "qg_score": null}, {"question": "Where is the chartered institute of personnel and development located?", "answer": "England", "ae_score": -0.45522690452611503, "qg_score": null}], "content": "There are a number of professional associations, some of which offer training and certification. The Society for Human Resource Management, which is based in the United States, is the largest professional association dedicated to HR, with over 250,000 members in 140 countries. It offers a suite of Professional in Human Resources (PHR) certifications through its HR Certification Institute. The Chartered Institute of Personnel and Development, based in England, is the oldest professional HR association,with its predecessor institution being founded in 1918.\nSeveral associations also serve niches within HR. The Institute of Recruiters (IOR) is a recruitment professional association, offering members education, support and training. WorldatWork focuses on \"total rewards\" (i.e., compensation, benefits, work life, performance, recognition, and career development), offering several certifications and training programs dealing with remuneration and work-life balance. Other niche associations include the American Society for Training & Development and Recognition Professionals International.\nA largely academic organization that is relevant to HR is the Academy of Management that has an HR division. This division is concerned with finding ways to improve the effectiveness of HR. The Academy publishes several journals devoted in part to research on HR, including Academy of Management Journal and Academy of Management Review, and it hosts an annual meeting.", "page_name": "Human resource management", "page_id": "Human%20resource%20management", "heading": "Professional associations", "sub_heading": "Professional associations", "_id": "38--6---1---1", "title": "HR Professional Associations & Certifications"}
{"qas": [{"question": "How do we know that rainwater is a good thing for the environment?", "answer": ""}, {"question": "Which method of providing fresh water during drought is used in developed countries?", "answer": "Rainwater harvesting", "ae_score": -0.6446409170388376, "qg_score": null}, {"question": "Which method of providing fresh water during drought is used in developed countries?", "answer": "Rainwater harvesting", "ae_score": -0.6446409170388376, "qg_score": null}], "content": "Rainwater harvesting provides an independent water supply during regional water restrictions and in developed countries is often used to supplement the main supply. It provides water when there is a drought, can help mitigate flooding of low-lying areas, and reduces demand on  wells which may enable groundwater levels to be sustained. It also helps in the availability of potable water as rainwater is substantially free of salinity and other salts.  Application of rainwater harvesting in urban water system provides a substantial benefit for both water supply and wastewater subsystems by reducing the need for clean water in water distribution system, less generated stormwater in sewer system, as well as a reduction in stormwater runoff polluting freshwater bodies.\nThere has been a large body of work focused on the development of Life Cycle Assessment and Life Cycle Costing methodologies to assess the level of environmental impacts and money that can be saved by implementing rainwater harvesting systems.\nMore development and knowledge is required to understand the benefits rainwater harvesting can provide to agriculture. Many countries especially those with an arid environment use rainwater harvesting as a cheap and reliable source of clean water. To enhance irrigation in arid environments, ridges of soil are constructed in order to trap and prevent rainwater from running down hills and slopes. Even in periods of low rainfall, enough water is collected in order for crops to grow. Water can be collected from roofs, dams, and ponds can be constructed in order to hold large quantities of rainwater so that even on days where there is little to no rainfall, there is enough available to irrigate crops.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "Advantages", "sub_heading": "Advantages", "_id": "39--0---1---1", "title": "Rainwater Harvesting in Urban Water System"}
{"qas": [{"question": "Why is rainwater better for the environment than potable water?", "answer": ""}, {"question": "What is the process of removing sediment from a water tank?", "answer": "Pre-filtration", "ae_score": -1.0619476709173592, "qg_score": null}, {"question": "What is the process of removing sediment from a water tank?", "answer": "Pre-filtration", "ae_score": -1.0619476709173592, "qg_score": null}], "content": "The concentration of contaminants is reduced significantly by diverting the initial flow of run-off water to waste. Improved water quality can also be obtained by using a floating draw-off mechanism (rather than from the base of the tank) and by using a series of tanks, with draw from the last in series. Pre-filtration is a common practice used in the industry to ensure that the water entering the tank is free of large sediment. Pre-filtration is important to keep the system healthy.\nConceptually, a water supply system should match the quality of water with the end use.  However, in most of the developed world high quality potable water is used for all end uses.  This approach wastes money and energy and imposes unnecessary impacts to the environment.  Supplying rainwater that has gone through preliminary filtration measures for non-potable water uses, such as toilet flushing, irrigation, and laundry, may be a significant part of a sustainable water management strategy.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "Quality", "sub_heading": "Quality", "_id": "39--1---1---1", "title": "Pre-Filtration of Rainwater for Non-Potable Water Uses"}
{"qas": [{"question": "How do rainwater harvesting systems work?", "answer": ""}, {"question": "Where does rainwater go in a tank?", "answer": "cisterns", "ae_score": -0.5520021542154674, "qg_score": null}, {"question": "Where does rainwater go in a tank?", "answer": "cisterns", "ae_score": -0.5520021542154674, "qg_score": null}], "content": "Rainwater harvesting systems can range in complexity, from systems that can be installed with minimal skills, to automated systems that require advanced setup and installation. The basic Rainwater harvesting system is more of a plumbing job than a technical job as all the outlets from the building terrace are connected through a pipe to an underground tank that stores water.\nSystems are ideally sized to meet the water demand throughout the dry season since it must be big enough to support daily water consumption. Specifically, the rainfall capturing area such as a building roof must be large enough to maintain adequate flow. The water storage tank size should be large enough to contain the captured water.\nFor low-tech systems, there are many low-tech methods used to capture rainwater: rooftop systems, surface water capture, and pumping the rainwater that has already soaked into the ground or captured in reservoirs and storing it into tanks (cisterns).\nBefore a rainwater harvesting system is built, it is helpful to use digital tools. For instance, if you want to detect if a region has a high rainwater harvesting potential, rainwater harvesting GIS maps can be made using an online interactive tool. Or if you need to estimate how much water is needed to fulfill a community's water needs, the Rain is Gain tool helps with this. Tools like these can save time and money before a commitment to build a system is undertaken, in addition to making the project sustainable and last a long time.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "System setup", "sub_heading": "System setup", "_id": "39--2---1---1", "title": "Rainwater Harvesting Systems \u2014 How to Build a Rainwater Harvesting System"}
{"qas": [{"question": "Why is it better to flush the toilet with rainwater rather than using the same water?", "answer": ""}, {"question": "What is the name of the methodology used to assess the environmental impact of a system?", "answer": "Life Cycle Assessment", "ae_score": -0.466668248656492, "qg_score": null}, {"question": "What is the name of the methodology used to assess the environmental impact of a system?", "answer": "Life Cycle Assessment", "ae_score": -0.466668248656492, "qg_score": null}], "content": "Contemporary system designs require an analysis of not only the economic and technical performance of a system, but also the environmental performance.  Life Cycle Assessment is a methodology used to evaluate the environmental impacts of a precut or systems, from cradle-to-grave of its' lifetime.  Devkota et al., developed such a methodology for rainwater harvesting, and found that the building design (e.g., dimensions) and function (e.g., educational, residential, etc.) play critical roles in the environmental performance of the system.  The Economic and Environmental Analysis of Sanitations Technologies, EEAST model evaluates the greenhouse gas emissions and cost of such systems over the lifetime of a variety of building types.\nTo address the functional parameters of rainwater harvesting systems, a new metric was developed - the demand to supply ratio (D/S) - identifying the ideal building design (supply) and function (demand) in regard to the environmental performance of rainwater harvesting for toilet flushing. With the idea that supply of rainwater not only saves the potable water, but also saves the stormwater entering the combined sewer network (thereby requiring treatment), the savings in environmental emissions were higher if the buildings are connected to a combined sewer network compared to separate one.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "Life Cycle Assessment: Design for Environment", "sub_heading": "Life Cycle Assessment: Design for Environment", "_id": "39--3---1---1", "title": "Environmental Performance of Rainwater Harvesting"}
{"qas": [{"question": "How is rain water harvesting possible?", "answer": ""}, {"question": "Which is the method of harvesting fresh water from forests?", "answer": "Rain water harvesting", "ae_score": -1.187655764585263, "qg_score": null}, {"question": "Which is the method of harvesting fresh water from forests?", "answer": "Rain water harvesting", "ae_score": -1.187655764585263, "qg_score": null}], "content": "Rain water harvesting is possible by growing fresh water flooded forests without losing the income from the used /submerged land. The main purpose of the rain water harvesting is to utilize the locally available rain water to meet water requirements throughout the year without the need of huge capital expenditure. This would facilitate availability of uncontaminated water for domestic, industrial and irrigation needs.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "Rain water harvesting by freshwater flooded forests", "sub_heading": "Rain water harvesting by freshwater flooded forests", "_id": "39--4---1---1", "title": "Rain water harvesting is possible by growing fresh water flooded forests without losing the income"}
{"qas": [{"question": "How do they grow trees in the middle of winter?", "answer": ""}, {"question": "What is the name of the dutch invention used to harvest dew and rainwater?", "answer": "Groasis Waterboxx", "ae_score": -0.3315130418126903, "qg_score": null}, {"question": "What is the name of the dutch invention used to harvest dew and rainwater?", "answer": "Groasis Waterboxx", "ae_score": -0.3315130418126903, "qg_score": null}], "content": "Instead of using the roof for catchment, the RainSaucer, which looks like an upside down umbrella, collects rain straight from the sky. This decreases the potential for contamination and makes potable water for developing countries a potential application. Other applications of this free standing rainwater collection approach are sustainable gardening and small plot farming.\nA Dutch invention called the Groasis Waterboxx is also useful for growing trees with harvested and stored dew and rainwater.\nTraditionally, storm water management using detention basins served a single purpose.  However, Optimized Real-Time Control (OptiRTC) lets this infrastructure double as a source of rainwater harvesting without compromising the existing detention capacity. This has been used in the EPA headquarters to evacuate stored water prior to storm events, thus reducing wet weather flow while ensuring water availability for later reuse.  This has the benefit of increasing water quality released and decreasing the volume of water released during combined sewer overflow events.\nGenerally, check dams are constructed across the streams to enhance the percolation of surface water in to the sub soil strata. The water percolation in the water impounded area of the check dams, can be enhanced artificially many folds by loosening the sub soil strata / overburden by using ANFO explosives as used in open cast mining. Thus local aquifers can be recharged quickly by using the available surface water fully for using in the dry season.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "New approaches", "sub_heading": "New approaches", "_id": "39--5---1---1", "title": "Rainwater Harvesting Using OptiRTC & OptiRTC"}
{"qas": [{"question": "How was rainwater harvesting done in the olden days?", "answer": ""}, {"question": "What type of water is in venice lagoon?", "answer": "brackish water", "ae_score": -0.5260499884029344, "qg_score": null}, {"question": "What type of water is in venice lagoon?", "answer": "brackish water", "ae_score": -0.5260499884029344, "qg_score": null}], "content": "Around the third century BC, the farming communities in Balochistan (now located in Pakistan, Afghanistan and Iran), and Kutch, India, used rainwater harvesting for agriculture and many uses also.In ancient Tamil Nadu , rainwater harvesting was done by Chola kings. Rainwater from the Brihadeeswarar temple (located in Balaganpathy Nagar, Thanjavur, India) was collected in Shivaganga tank. During the later Chola period, the V\u012br\u0101nam tank was built (1011 to 1037 CE) in Cuddalore district of Tamil Nadu to store water for drinking and irrigation purposes. V\u012br\u0101nam is a 16 km long tank with a storage capacity of 1465000000 cuft.\nRainwater harvesting was done in the Indian states of Madhya Pradesh, Maharashtra, and Chhattisgarh in the olden days. Ratanpur, in the state of Chhattisgarh, had around 150 ponds. Most of the tanks or ponds were utilized in agriculture works.\nIt is a little know fact that the town of Venice depended for centuries on rainwater harvesting. The lagoon which surrounds Venice is made of brackish water which is not suitable for human drinking. The ancient inhabitants of Venice established a system of rainwater collection which was based on man-made insulated collection wells. Water would percolate down the specially designed stone flooring, and be filtered by a layer of sand, then collecting at the bottom of the well. Later, as Venice acquired territories on the mainland, it started to import water by boat from local rivers, but the wells remained in use, and were especially important in time of war when access to the mainland water could be blocked by an assailant.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "History", "sub_heading": "History", "_id": "39--6---1---1", "title": "Rainwater Harvesting in India \u2014 A History"}
{"qas": [{"question": "What is the Southwest Center for the Study of Hospital and Healthcare Systems?", "answer": ""}, {"question": "Who is leading the rain water harvesting in sri lanka?", "answer": "Lanka rainwater harvesting forum", "ae_score": -0.4305956219560302, "qg_score": null}, {"question": "Who is leading the rain water harvesting in sri lanka?", "answer": "Lanka rainwater harvesting forum", "ae_score": -0.4305956219560302, "qg_score": null}], "content": "A number of Canadians have started implementing rainwater harvesting systems for use in stormwater reduction, irrigation, laundry, and lavatory plumbing. Substantial reform to Canadian law since the mid 2000s has increased the use of this technology in agricultural, industrial, and residential use; but ambiguity remains amongst legislation in many provinces. Bylaws and local municipal codes often regulate rainwater harvesting.\nThe Mumbai city council is planning to make rainwater harvesting mandatory for large societies.An attempt has been made at the Department of Chemical Engineering, IISc, Bangalore to harvest rainwater using upper surface of a solar still, which was used for water distillation\nThe Southwest Center for the Study of Hospital and Healthcare Systems in cooperation with Rotary International is sponsoring a rainwater harvesting model program across the country. The first rainwater catchment system was installed at an elementary school in Lod, Israel. The project is looking to expand to Haifa in its third phase. The Southwest Center has also partnered with the Water Resources Action Project (WRAP) of Washington D.C. WRAP currently has rainwater harvesting projects in the West Bank.   Rainwater harvesting systems are being installed in local schools for the purpose of educating schoolchildren about water conservation principles and bridging divides between people of different religious and ethnic backgrounds all while addressing the water scarcity issue that the Middle East faces.\nAlthough New Zealand has plentiful rainfall in the West and South, for much of the country, rain water harvesting is the normal practice for most rural housing and is encouraged by most councils \nRainwater harvesting has been a popular method of obtaining water for agriculture and for drinking purposes in rural homes.The legislation to promote rainwater harvesting was enacted through the Urban Development Authority (Amendment) Act, No. 36 of 2007.Lanka rainwater harvesting forum is leading the Sri Lanka's initiative.\nThe South African Water Research Commission has supported research into rainwater harvesting. Reports on this research are available on their 'Knowledge Hub'.Studies in arid, semi-arid and humid regions have confirmed that techniques such as mulching, pitting, ridging and modified run-on plots are effective for small-scale crop production.\nIn the United Kingdom, water butts are often found in domestic gardens  and on allotments to collect rainwater, which is then used to water the garden. However, the British government's Code For Sustainable Homes encouraged fitting large underground tanks to new-build homes to collect rainwater for flushing toilets, watering and washing. Ideal designs had the potential to reduce demand on mains water supply by half. The code was revoked in 2015.", "page_name": "Rainwater harvesting", "page_id": "Rainwater%20harvesting", "heading": "Current use", "sub_heading": "Current use", "_id": "39--7---1---1", "title": "Rainwater Harvesting in the Middle East"}
{"qas": [{"question": "Why is logging bad for the environment?", "answer": ""}, {"question": "Which type of forest is home to rare species such as the northern spotted owl?", "answer": "Old-growth forests", "ae_score": -1.0037335722369551, "qg_score": null}, {"question": "Which type of forest is home to rare species such as the northern spotted owl?", "answer": "Old-growth forests", "ae_score": -1.0037335722369551, "qg_score": null}], "content": "Old-growth forests are often biologically diverse, and home to many rare species, threatened species, and endangered species of plants and animals, such as the northern spotted owl, marbled murrelet and fisher, making them ecologically significant. Levels of biodiversity may be higher or lower in old-growth forests compared to that in second-growth forests, depending on specific circumstances, environmental variables and geographic variables. Logging in old-growth forests is a contentious issue in many parts of the world. Excessive logging reduces biodiversity, affecting not only the old-growth forest itself, but also indigenous species that rely upon old-growth forest habitat.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Characteristics", "_id": "40--0--0---1", "title": "Old-growth forests are important habitats for many rare species, threatened species, endangered species of"}
{"qas": [{"question": "Why do trees age at different rates?", "answer": ""}, {"question": "What is a less stable ecosystem in an old growth forest?", "answer": "uniformly aged stands", "ae_score": -2.101209504377627, "qg_score": null}, {"question": "What is a less stable ecosystem in an old growth forest?", "answer": "uniformly aged stands", "ae_score": -2.101209504377627, "qg_score": null}], "content": "A forest in old-growth stage has a mix of tree ages, due to a distinct regeneration pattern for this stage. New trees regenerate at different times from each other, because each one of them has different spatial location relative to the main canopy and hence each one receives a different amount of light. The mixed age of the forest is an important criterion in ensuring that the forest is a relatively stable ecosystem in the long term. A climax stand that is uniformly aged becomes senescent and degrades within a relatively short time-period to result in a new cycle of forest succession. Thus, uniformly aged stands are a less stable ecosystem.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Mixed age", "_id": "40--0--1---1", "title": "A forest in old-growth stage has a mix of tree ages, due to "}
{"qas": [{"question": "Why do old-growth forests have more biodiversity than other forests?", "answer": ""}, {"question": "What is essential in creating and maintaining mixed-age stands?", "answer": "Forest canopy gaps", "ae_score": -1.0315494247391253, "qg_score": null}, {"question": "What is essential in creating and maintaining mixed-age stands?", "answer": "Forest canopy gaps", "ae_score": -1.0315494247391253, "qg_score": null}], "content": "Forest canopy gaps are essential in creating and maintaining mixed-age stands. Also, some herbaceous plants only become established in canopy openings, but persist beneath an understory. Openings are a result of tree death due to small impact disturbances such as wind, low-intensity fires and tree diseases.\nOld-growth forests are unique, usually having multiple horizontal layers of vegetation representing a variety of tree species, age classes, and sizes, as well as \"pit and mound\" soil shape with well-established fungal nets.Because old-growth forest is structurally diverse it provides higher-diversity habitat than forests in other stages. Thus, sometimes higher biological diversity can be sustained in old-growth forest, or at least a biodiversity that is different from other forest stages.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Canopy openings", "_id": "40--0--2---1", "title": "Old-Growth Forests \u2014 Biological Diversity"}
{"qas": [{"question": "How do old-growth forests grow?", "answer": ""}, {"question": "What are pits in old growth forest called?", "answer": "tree throws", "ae_score": -0.6797900643876745, "qg_score": null}, {"question": "What are pits in old growth forest called?", "answer": "tree throws", "ae_score": -0.6797900643876745, "qg_score": null}], "content": "The characteristic topography of much old-growth forest consists of pits and mounds. Mounds are caused by decaying fallen trees, and pits (tree throws) by the roots pulled out of the ground when trees fall due to natural causes, including being pushed over by animals. Pits expose humus-poor, mineral-rich soil and often collect moisture and fallen leaves, forming a thick organic layer that is able to nurture certain types of organisms. Mounds provide a place free of leaf inundation and saturation, where other types of organisms thrive.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Topography", "_id": "40--0--3---1", "title": "Mounds and Pits in Old-Grown Forests"}
{"qas": [{"question": "What are standing snags and why do they exist?", "answer": ""}, {"question": "What provides food sources and habitat for many types of organisms?", "answer": "Standing snags", "ae_score": -0.33194395923792636, "qg_score": null}, {"question": "What provides food sources and habitat for many types of organisms?", "answer": "Standing snags", "ae_score": -0.33194395923792636, "qg_score": null}], "content": "Standing snags provide food sources and habitat for many types of organisms. In particular, many species of dead-wood predators such as woodpeckers must have standing snags available for feeding. In North America the spotted owl is well known for needing standing snags for nesting habitat.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Standing snags", "_id": "40--0--4---1", "title": "Standing snags provide food sources and habitat for many types of organisms"}
{"qas": [{"question": "What is the purpose of falling timber?", "answer": ""}, {"question": "What do fallen trees become in a rain forest?", "answer": "nurse logs", "ae_score": -0.7132944479740565, "qg_score": null}, {"question": "What do fallen trees become in a rain forest?", "answer": "nurse logs", "ae_score": -0.7132944479740565, "qg_score": null}], "content": "Fallen timber, or coarse woody debris, contributes carbon-rich organic matter directly to the soil, providing a substrate for mosses, fungi, and seedlings, and creating microhabitats by creating relief on the forest floor. In some ecosystems such as the temperate rain forest of the North American Pacific coast, fallen timber may become nurse logs, providing a substrate for seedling trees.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Decaying ground layer", "_id": "40--0--5---1", "title": "Fallen Timber: A Substrate for Mosses, Fungi, and Seed"}
{"qas": [{"question": "What is the difference between an \"intact\" soil and a \"dry\" soil?", "answer": ""}, {"question": "What type of ecosystem is used to recycle nutrients into the environment?", "answer": "Fungal ecosystems", "ae_score": -1.1011728331148416, "qg_score": null}, {"question": "What type of ecosystem is used to recycle nutrients into the environment?", "answer": "Fungal ecosystems", "ae_score": -1.1011728331148416, "qg_score": null}], "content": "Intact soils harbor many life-forms that rely on them. Intact soils generally have very well-defined horizons, or soil profiles. Different organisms may need certain well-defined soil horizons in order to live, while many trees need well-structured soils free of disturbance in order to thrive. Some herbaceous plants in northern hardwood forests must have thick duff layers (which are part of the soil profile). Fungal ecosystems are essential for efficient ''in-situ'' recycling of nutrients back into the entire ecosystem.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Characteristics", "sub_heading": "Soil", "_id": "40--0--6---1", "title": "Intact soils are essential for efficient ''In-Situ''"}
{"qas": [{"question": "What is stand age and how does it work?", "answer": ""}, {"question": "What is the name of the method used to classify old growth forest?", "answer": "Stand age", "ae_score": -0.4727221437956234, "qg_score": null}, {"question": "What is the name of the method used to classify old growth forest?", "answer": "Stand age", "ae_score": -0.4727221437956234, "qg_score": null}], "content": "Stand age can also be used to categorize forest as old-growth. For each geographical area, there is an average time since disturbance when the forest will reach old-growth stage. This method is useful, because it allows quick and objective determination of forest stage. However, this definition does not provide explanation about forest function. It just gives a useful number to measure. Due to that fact, some forests may be excluded from being categorized as old-growth even if they have old-growth attributes just because they are too young. Also, older forests can lack some old-growth attributes and be categorized as old-growth just because they are so old. The idea of using age is also problematic, because human activities can influence the forest in varied ways. For example, after logging of 30% of the trees, we can wait less time for old-growth to come back than after removal of 80% of the trees. Although depending on the species logged, the forest that comes back after a 30% harvest may consist of proportionately less hardwood trees than a forest logged at 80% in which the light competition by less important tree species does not inhibit the regrowth of vital hardwoods.\nFrom a forest dynamics perspective, old-growth forest is a forest in a stage that follows Understory Reinitiation stage. A review of the stages helps to understand the concept:\nOf importance is that while the stand switches from one tree community to another, the stand will not necessarily go through old-growth stage between those stages. Some tree species have relatively open canopy. That allows more shade-tolerant tree species to establish below even before Understory Reinitiation stage. The shade-tolerant trees will eventually out-compete the main canopy trees in stem-exclusion stage. Therefore, the dominant tree species will change, but the forest will still be in Stem-Exclusion stage.\nTree species succession may change tree species composition once the old-growth stage has been achieved. For example, an old boreal forest may contain some large aspen trees, which may die and be replaced by smaller balsam fir or black spruce. Consequently, the forest will switch back to Understory Reinitiation stage. If old growth stage is seen as an end point of stand development, it can be easily evaluated using structural or static attributes. However, in some forest ecosystems this can lead to decisions regarding the preservation of unique stands or attributes that will disappear over the next few decades because of natural succession processes. Consequently, using stand dynamics to define old-growth forest is more useful in cases where the species that constitute old-growth forest can have long life span or in ecosystem where succession is very slow.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Definitions", "sub_heading": "Definitions", "_id": "40--1--0---1", "title": "Old-growth forest: a forest in a stage that follows Understory Reinitiation stage"}
{"qas": [{"question": "What is the difference between a forest and an old-growth forest?", "answer": ""}, {"question": "What is the meaning of old growth forest?", "answer": "wilderness preservation", "ae_score": -1.2758233881480954, "qg_score": null}, {"question": "What is the meaning of old growth forest?", "answer": "wilderness preservation", "ae_score": -1.2758233881480954, "qg_score": null}], "content": "Common cultural definitions and common denominators regarding what comprises old-growth forest, and of the variables that define, constitute and embody old-growth forests include:\nThe debate over old growth definitions has been inextricably linked with a complex range of social perceptions about wilderness preservation, aesthetics and spirituality, as well as economic or industrial values.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Definitions", "sub_heading": "Social and cultural definitions", "_id": "40--1--1---1", "title": "Old Growth Forests and the Cultural Definitions of Old Growth Forests"}
{"qas": [{"question": "Why are there so many second-growth forests in the US?", "answer": ""}, {"question": "Where is most of canada's old growth forest located?", "answer": "British Columbia", "ae_score": -0.5548208751600894, "qg_score": null}, {"question": "Where is most of canada's old growth forest located?", "answer": "British Columbia", "ae_score": -0.5548208751600894, "qg_score": null}], "content": "Old-growth forests were often given harvesting priority because they have the most commercially valuable timber, they are considered to be at greater risk of deterioration through root rot or insect infestation, and they occupy land that could be used for more productive second-growth stands. In some regions, old growth is not the most commercially viable timber \u2013 in British Columbia, Canada, harvesting in the coastal region is moving to younger second-growth stands.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Definitions", "sub_heading": "Economic definitions", "_id": "40--1--2---1", "title": "Old-growth forests are not the most commercially viable timber."}
{"qas": [{"question": "What is the difference between old growth and new growth?", "answer": ""}, {"question": "When was the old growth index created?", "answer": "2001", "ae_score": -0.4922304130212652, "qg_score": null}, {"question": "When was the old growth index created?", "answer": "2001", "ae_score": -0.4922304130212652, "qg_score": null}], "content": "A 2001 scientific symposium in Canada found that defining old growth in a scientifically meaningful, yet policy-relevant, manner presents some basic difficulties, especially if a simple, unambiguous, and rigorous scientific definition is sought. Symposium participants identified some attributes of late-successional, temperate-zone, old-growth forest types that could be considered in developing an index of \"old-growthness\" and for defining old-growth forests:\n'''Structural features:'''\n'''Compositional features:'''\n'''Process features:'''", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Definitions", "sub_heading": "Other definitions", "_id": "40--1--3---1", "title": "Old-growth forest types: a simple, unambiguous, and rigorous scientific definition"}
{"qas": [{"question": "Why are old-growth forests so important?", "answer": ""}, {"question": "What type of forest provides ecosystem services that may be far more important to society than their?", "answer": "Old-growth forests", "ae_score": -0.44771330002757603, "qg_score": null}, {"question": "What type of forest provides ecosystem services that may be far more important to society than their?", "answer": "Old-growth forests", "ae_score": -0.44771330002757603, "qg_score": null}], "content": "Old-growth forests provide ecosystem services that may be far more important to society than their use as a source of raw materials. These services include breathable air, pure water, carbon storage, regeneration of nutrients, maintenance of soils, pest control by insectivorous bats and insects, micro- and macro-climate control, and the storage of a wide variety of genes.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Ecosystem services", "sub_heading": "Ecosystem services", "_id": "40--2---1---1", "title": "Old-growth forest | Ecosystem services"}
{"qas": [{"question": "What are the effects of old-growth forests on global warming?", "answer": ""}, {"question": "Where is the most carbon stored in an old growth forest?", "answer": "Pacific Northwest", "ae_score": -0.4321193084845504, "qg_score": null}, {"question": "Where is the most carbon stored in an old growth forest?", "answer": "Pacific Northwest", "ae_score": -0.4321193084845504, "qg_score": null}], "content": "The effects of old-growth forests in relation to Global Warming has been contested in various studies and journals.\nThe Intergovernmental Panel on Climate Change said in its 2007 report: \u201cIn the long term, a sustainable forest management strategy aimed at maintaining or increasing forest carbon stocks, while producing an annual sustained yield of timber, fibre or energy from the forest, will generate the largest sustained mitigation benefit.\u201d\nCritics note that at old-growth forests are often perceived to be in equilibrium, but could be releasing as much carbon dioxide as they capture, or are currently in a state of decay. Another scientific study concluded that forest harvesting has little or no effect on the amount of carbon stored in the soil. As trees grow, they remove carbon from the atmosphere. As they reach maturity, growth slows and ultimately stops as mortality catches up to growth. Harvesting also removes carbon from the forest but some of it is stored in wood products (preventing its immediate release to the atmosphere) and some is available for use as biomass energy (displacing fossil fuel use), although using biomass as a fuel produces air pollution in the form of carbon monoxide, NOx (nitrogen oxides), VOCs (volatile organic compounds), particulates and other pollutants, in some cases at levels above those from traditional fuel sources such as coal or natural gas. In most North American forests, this drop happens when a tree is between 60 and 150 years old, depending on the species and environmental factors.\nEach forest has a different potential to store carbon. For example, this potential is particularly high in the Pacific Northwest where forests are relatively productive, trees live a long time, decomposition is relatively slow, and fires are infrequent. The differences between forests must therefore be taken into consideration when determining how they should be managed to store carbon.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Climatic impacts", "sub_heading": "Climatic impacts", "_id": "40--3---1---1", "title": "The Impact of Old-growth Forests on Climate Change"}
{"qas": [{"question": "Why are there so many trees in old growth forests?", "answer": ""}, {"question": "What percentage of old growth forests are still left on earth?", "answer": "21%", "ae_score": -0.2784078845229956, "qg_score": null}, {"question": "What percentage of old growth forests are still left on earth?", "answer": "21%", "ae_score": -0.2784078845229956, "qg_score": null}], "content": "According to the World Resources Institute, as of January 2009, only 21% of the original old-growth forests that once existed on earth are remaining. It is estimated that one half of Western Europe's forests were cleared before the Middle Ages, and that 90% of the old-growth forests that existed in the contiguous United States in the 1600s have been cleared.\nThe large trees in old growth forests are economically valuable, and have been subjected to aggressive logging around the world. This has led to much controversy between logging companies and environmental groups. From certain forestry perspectives, fully maintaining an old growth forest is seen as extremely economically unproductive, as timber can only be collected from falling trees, and also potentially damaging to nearby managed groves by creating environments conducive to root rot. From this view, it may be more productive to cut the old growth down and replace the forest with a younger one. On the other hand, old growth forests have significant environmental value, creating a stable ecological environment and promoting biological diversity.\nThe island of Tasmania, just off the south east coast of Australia has the largest amount of temperate old-growth rainforest reserves in Australia with approximately 1,239,000 hectares in total. While the local Regional Forest Agreement (RFA) was originally designed to protect much of this natural wealth, many of the RFA old growth forests protected in Tasmania consist of trees of little use to the timber industry. RFA old growth and high conservation value forests that contain species highly desirable to the forestry industry have been poorly reserved. Only 22% of Tasmania\u2019s original tall-eucalypt forests managed by Forestry Tasmania have been reserved. Ten thousand hectares of tall-eucalypt RFA old growth forest have been lost since 1996, predominantly as a result of industrial logging operations. In 2006, approximately 61,000 hectares of tall-eucalypt RFA old growth forests remained unprotected. Recent logging attempts in the Upper Florentine Valley have sparked a series of protests and media attention over the arrests that have taken place in this area. Additionally, Gunns Limited, the primary forestry contractor in Tasmania has been under recent criticism by political and environmental groups over its practice of woodchipping timber harvested from old growth forests.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Logging in old growth forests", "sub_heading": "Logging in old growth forests", "_id": "40--4---1---1", "title": "Old Growth Forests in Tasmania \u2014 A Case Study"}
{"qas": [{"question": "Why are there so many trees in the woods?", "answer": ""}, {"question": "What does rfa stand for in australia?", "answer": "the Regional Forest Agreement", "ae_score": -0.7997608084286632, "qg_score": null}, {"question": "What does rfa stand for in australia?", "answer": "the Regional Forest Agreement", "ae_score": -0.7997608084286632, "qg_score": null}], "content": "The increased understanding of forest dynamics in the late 20th century has led the scientific community to identify a need to inventory, understand, manage and conserve representative examples of old-growth forests with their associated characteristics and values. The literature around old growth and its management is inconclusive about the best way to capture the true essence of an old growth stand.\nA better understanding of natural systems has resulted in new ideas about forest management, such as managed natural disturbances should be designed to achieve the landscape patterns and habitat conditions that are normally maintained in nature (DeLong 1998; Wong and Iverson 2004). This coarse filter approach to biodiversity conservation recognizes ecological processes and provides for a dynamic distribution of old growth across the landscape.And all seral stages \u2013 young, medium and old \u2013 support forest biodiversity. Plants and animals rely on different forest ecosystem stages to meet their habitat needs.\nIn Australia, the Regional Forest Agreement (RFA) attempted to prevent the clearfelling of defined \"Old Growth Forests\". This led to struggles over what constitutes \"Old Growth\". For example, in Western Australia, the timber industry tried to limit the area of Old Growth in the karri forests of the Southern Forests Region; this led to the creation of the Western Australian Forests Alliance, the splitting of the Liberal Government of Western Australia and the election of the Gallop Labor Government. Old Growth Forests in this region have now been placed inside National Parks. A small proportion of Old Growth Forest also exists in South-West Australia, and is protected by a Federal laws from logging, which hasn't occurred there for more than twenty years.\nIn British Columbia, Canada, old-growth forests must be maintained in each of the province\u2019s ecological units to meet biodiversity needs.", "page_name": "Old-growth forest", "page_id": "Old-growth%20forest", "heading": "Management", "sub_heading": "Management", "_id": "40--5---1---1", "title": "Old Growth Forests in Australia \u2014 A Biodiversity Conservation Approach"}
{"qas": [{"question": "Why is it that when an unconscious person is given IV fluids, they don't have electrolytes in their system?", "answer": ""}, {"question": "What is the name of the medication that causes water intoxication?", "answer": "Oxcarbazepine", "ae_score": -0.32367213173985343, "qg_score": null}, {"question": "What is the name of the medication that causes water intoxication?", "answer": "Oxcarbazepine", "ae_score": -0.32367213173985343, "qg_score": null}], "content": "It can be very easy for children under one year old to absorb too much water, especially if the child is under nine months old. Because of their small body mass, it is easy for them to take in a large amount of water relative to body mass and total body sodium stores.\nMarathon runners are susceptible to water intoxication if they drink too much while running.  This is caused when sodium levels drop below 135 mmol/L when athletes consume large amounts of fluid. This has been noted to be the result of the encouragement of excessive fluid replacement by various guidelines. This has largely been identified in marathon runners as a dilutional hyponatremia. A study conducted on participants of the 2002 Boston marathon found that thirteen percent finished the race with hyponatremia. The study concluded that the strongest predictor of hyponatremia was weight gain while racing (over-hydration), and hyponatremia was just as likely to occur in runners who chose sports drinks as those who chose water. Medical personnel at marathon events are trained to suspect water intoxication immediately when runners collapse or show signs of confusion.\nAny activity or situation that promotes heavy sweating can lead to water intoxication when water is consumed to replace lost fluids. Persons working in extreme heat and/or humidity for long periods must take care to drink and eat in ways that help to maintain electrolyte balance.  People using drugs such as MDMA (often referred to colloquially as \"Ecstasy\") may overexert themselves, perspire heavily, feel increased thirst, and then drink large amounts of water to rehydrate, leading to electrolyte imbalance and water intoxication \u2013 this is compounded by MDMA use increasing the levels of antidiuretic hormone (ADH), decreasing the amount of water lost through urination.  Even people who are resting quietly in extreme heat or humidity may run the risk of water intoxication if they drink large amounts of water over short periods for rehydration.\nPsychogenic polydipsia is the psychiatric condition in which patients feel compelled to drink large quantities of water, thus putting them at risk of water intoxication. This condition can be especially dangerous if the patient also exhibits other psychiatric indications (as is often the case), as the care-takers might misinterpret the hyponatremic symptoms.\nWhen an unconscious person is being fed intravenously (for example, total parenteral nutrition) or via a nasogastric tube, the fluids given must be carefully balanced in composition to match fluids and electrolytes lost.  These fluids are typically hypertonic, and so water is often co-administered.  If the electrolytes are not monitored (even in an ambulatory patient), either hypernatremia or hyponatremia may result.\nSome neurological/psychiatric medications (Oxcarbazepine, among others) have been found to cause hyponatremia in some patients. Patients with diabetes insipidus are particularly vulnerable due to rapid fluid processing.", "page_name": "Water intoxication", "page_id": "Water%20intoxication", "heading": "Risk factors", "sub_heading": "Risk factors", "_id": "41--0---1---1", "title": "Water Intoxication in Marathon Runers"}
{"qas": [{"question": "How does water intoxication work?", "answer": ""}, {"question": "What does icp stand for in water intoxication?", "answer": "intracranial pressure", "ae_score": -0.851745037090714, "qg_score": null}, {"question": "What does icp stand for in water intoxication?", "answer": "intracranial pressure", "ae_score": -0.851745037090714, "qg_score": null}], "content": " At the onset of this condition, fluid outside the cells has an excessively low amount of solutes, such as sodium (hyponatremia) and other electrolytes, in comparison to fluid inside the cells, causing the fluid to move into the cells to balance its concentration. This causes the cells to swell. In the brain, this swelling increases intracranial pressure (ICP), which leads to the first observable symptoms of water intoxication: headache, personality changes, changes in behavior, confusion, irritability, and drowsiness. These are sometimes followed by difficulty breathing during exertion, muscle weakness & pain, twitching, or cramping, nausea, vomiting, thirst, and a dulled ability to perceive and interpret sensory information. As the condition persists, papillary and vital signs may result including bradycardia and widened pulse pressure. The cells in the brain may swell to the point where blood flow is interrupted resulting in cerebral edema. Swollen brain cells may also apply pressure to the brain stem causing central nervous system dysfunction. Both cerebral edema and interference with the central nervous system are dangerous and could result in seizures, brain damage, coma or death.", "page_name": "Water intoxication", "page_id": "Water%20intoxication", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "41--1---1---1", "title": "Water Intoxication Symptoms"}
{"qas": [{"question": "Why is water intoxication so hard to prevent?", "answer": ""}, {"question": "What is it called when you drink too much water?", "answer": "Water intoxication", "ae_score": -0.3500317425689872, "qg_score": null}, {"question": "What is it called when you drink too much water?", "answer": "Water intoxication", "ae_score": -0.3500317425689872, "qg_score": null}], "content": "Water intoxication can be prevented if a person's intake of water does not grossly exceed their losses. Healthy kidneys are able to excrete approximately 800 millilitre to 1 litre of fluid water (0.21 - 0.26 gallons) per hour.<ref name=sa/> However, stress (from prolonged physical exertion), as well as disease states, can greatly reduce this amount.<ref name=sa/>", "page_name": "Water intoxication", "page_id": "Water%20intoxication", "heading": "Prevention", "sub_heading": "Prevention", "_id": "41--2---1---1", "title": "Water intoxication | Prevention"}
{"qas": [{"question": "What is the difference between polyelectrolytes and acids?", "answer": ""}, {"question": "When two oppositely charged polymers are mixed, a bulk complex is formed?", "answer": "precipitate", "ae_score": -0.20044432800240705, "qg_score": null}, {"question": "When two oppositely charged polymers are mixed, a bulk complex is formed?", "answer": "precipitate", "ae_score": -0.20044432800240705, "qg_score": null}], "content": "Acids are classified as either weak or strong (and bases similarly may be either weak or strong). Similarly, polyelectrolytes can be divided into 'weak' and 'strong' types. A 'strong' polyelectrolyte is one which dissociates completely in solution for most reasonable pH values. A 'weak' polyelectrolyte, by contrast, has a dissociation constant (pKa or pKb) in the range of ~2 to ~10, meaning that it will be partially dissociated at intermediate pH. Thus, weak polyelectrolytes are not fully charged in solution, and moreover their fractional charge can be modified by changing the solution pH, counterion concentration, or ionic strength.\nThe physical properties of polyelectrolyte solutions are usually strongly affected by this degree of charging. Since the polyelectrolyte dissociation releases counter-ions, this necessarily affects the solution's ionic strength, and therefore the Debye length. This in turn affects other properties, such as electrical conductivity.\nWhen solutions of two oppositely charged polymers (that is, a solution of '''polycation''' and one of '''polyanion''') are mixed, a bulk complex (precipitate) is usually formed. This occurs because the oppositely-charged polymers attract one another and bind together.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Polyelectrolyte charge", "sub_heading": "Polyelectrolyte charge", "_id": "42--0---1---1", "title": "Polyelectrolyte | Polyelectrolyte charge"}
{"qas": [{"question": "Polyelectrolytes?", "answer": ""}, {"question": "What is used to study the conformational changes of polyelectrolytes?", "answer": "static light scattering", "ae_score": -0.32588618709727285, "qg_score": null}, {"question": "What is used to study the conformational changes of polyelectrolytes?", "answer": "static light scattering", "ae_score": -0.32588618709727285, "qg_score": null}], "content": "The conformation of any polymer is affected by a number of factors: notably the polymer architecture and the solvent affinity. In the case of polyelectrolytes, charge also has an effect. Whereas an uncharged linear polymer chain is usually found in a random conformation in solution (closely approximating a self-avoiding three-dimensional random walk), the charges on a linear polyelectrolyte chain will repel each other  via double layer forces, which causes the chain to adopt a more expanded, rigid-rod-like conformation. If the solution contains a great deal of added salt, the charges will be screened and consequently the polyelectrolyte chain will collapse to a more conventional conformation (essentially identical to a neutral chain in good solvent).\nPolymer conformation of course affects many bulk properties (such as viscosity, turbidity, etc.). Although the statistical conformation of polyelectrolytes can be captured using variants of conventional polymer theory, it is in general quite computationally intensive to properly model polyelectrolyte chains, owing to the long-range nature of the electrostatic interaction.Techniques such as static light scattering can be used to study polyelectrolyte conformation and conformational changes.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Polyelectrolyte conformation", "sub_heading": "Polyelectrolyte conformation", "_id": "42--1---1---1", "title": "Polyelectrolyte Conformation in Solution"}
{"qas": [{"question": "Why does salt dissolve polyelectrolytes?", "answer": ""}, {"question": "What type of groups do polyelectrolytes have?", "answer": "cationic and anionic repeat groups", "ae_score": -1.9627641413968222, "qg_score": null}, {"question": "What type of groups do polyelectrolytes have?", "answer": "cationic and anionic repeat groups", "ae_score": -1.9627641413968222, "qg_score": null}], "content": "Polyelectrolytes which bear both cationic and anionic repeat groups are called '''polyampholytes'''. The competition between the acid-base equilibria of these groups leads to additional complications in their physical behavior. These polymers usually only dissolve when there is sufficient added salt, which screens the interactions between oppositely charged segments. In case of amphoteric macroporous hydrogels action of concentrated salt solution does not lead to dissolution of polyampholyte material due to covalent cross-linking of macromolecules. Synthetic 3-D macroporous hydrogels shows the excellent ability to adsorb heavy metals ions in a wide range of pH from extremely diluted aqua's solutions, which can be later used as an adsorbent for purification of salt water  Preparation and characterization All proteins are polyampholytes, as some amino acids tend to be acidic while others are basic.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Polyampholytes", "sub_heading": "Polyampholytes", "_id": "42--2---1---1", "title": "Polyampholytes \u2014 Synthetic 3-D macroporous hydrogels "}
{"qas": [{"question": "Why are polyelectrolytes so important?", "answer": ""}, {"question": "What property of polyelectrolytes makes them useful in medical applications?", "answer": "water-soluble", "ae_score": -0.7698432504847136, "qg_score": null}, {"question": "What property of polyelectrolytes makes them useful in medical applications?", "answer": "water-soluble", "ae_score": -0.7698432504847136, "qg_score": null}], "content": "Polyelectrolytes have many applications, mostly related to modifying flow and stability properties of aqueous solutions and gels. For instance, they can be used to destabilize a colloidal suspension and to initiate flocculation (precipitation). They can also be used to impart a surface charge to neutral particles, enabling them to be dispersed in aqueous solution. They are thus often used as thickeners, emulsifiers, conditioners, clarifying agents, and even drag reducers. They are used in water treatment and for oil recovery. Many soaps, shampoos, and cosmetics incorporate polyelectrolytes. Furthermore, they are added to many foods and to concrete mixtures (superplasticizer). Some of the polyelectrolytes that appear on food labels are pectin, carrageenan, alginates, and carboxymethyl cellulose. All but the last  are of natural origin. Finally, they are used in a variety of materials, including cement.\nBecause some of them are water-soluble, they are also investigated for biochemical and medical applications. There is currently much research in using biocompatible polyelectrolytes for implant coatings, for controlled drug release, and other applications. Thus, recently, the biocompatible and biodegradable macroporous material composed of polyelectrolyte complex was described, where the material exhibited excellent proliferation of mammalian cells.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Applications", "sub_heading": "Applications", "_id": "42--3---1---1", "title": "Biocompatible Polyelectrolyte Complexes"}
{"qas": [{"question": "How do we know the properties of gold?", "answer": ""}, {"question": "What type of substrate is pem formed on?", "answer": "gold", "ae_score": -0.7404413021349733, "qg_score": null}, {"question": "What type of substrate is pem formed on?", "answer": "gold", "ae_score": -0.7404413021349733, "qg_score": null}], "content": "Recently, polyelectrolytes have been utilized in the formation of new types of materials known as '''polyelectrolyte multilayers''' ('''PEM'''s). These thin films are constructed using a '''layer-by-layer''' ('''LbL''') deposition technique. During LbL deposition, a suitable growth substrate (usually charged) is dipped back and forth between dilute baths of positively and negatively charged polyelectrolyte solutions. During each dip a small amount of polyelectrolyte is adsorbed and the surface charge is reversed, allowing the gradual and controlled build-up of electrostatically cross-linked films of polycation-polyanion layers. Scientists have demonstrated thickness control of such films down to the single-nanometer scale. LbL films can also be constructed by substituting charged species such as nanoparticles or clay platelets in place of or in addition to one of the polyelectrolytes. LbL deposition has also been accomplished using hydrogen bonding instead of electrostatics. For more information on multilayer creation please see polyelectrolyte adsorption. \nAn LbL formation of PEM (PSS-PAH (poly(allylamine) hydrochloride)) on a gold substrate can be seen in the Figure. The formation is measured using Multi-Parametric Surface Plasmon Resonance to determine adsorption kinetics, layer thickness and optical density. \nThe main benefits to PEM coatings are the ability to conformably coat objects (that is, the technique is not limited to coating flat objects), the environmental benefits of using water-based processes, reasonable costs, and the utilization of the particular chemical properties of the film for further modification, such as the synthesis of metal or semiconductor nanoparticles, or porosity phase transitions to create anti-reflective coatings, optical shutters, and superhydrophobic coatings.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Polyelectrolyte multilayers", "sub_heading": "Polyelectrolyte multilayers", "_id": "42--4---1---1", "title": "Polyelectrolyte Multilayers ('''PEM'''"}
{"qas": [{"question": "Why is the polyelectrolyte chain not a conductor of ions?", "answer": ""}, {"question": "The behavior of the polyelectrolyte chain is almost identical to that of?", "answer": "confined unconnected ions", "ae_score": -0.4105808568730658, "qg_score": null}, {"question": "The behavior of the polyelectrolyte chain is almost identical to that of?", "answer": "confined unconnected ions", "ae_score": -0.4105808568730658, "qg_score": null}], "content": "If polyelectrolyte chains are added to a system of charged macroions (i.e. an array of DNA molecules), an interesting phenomenon called the '''polyelectrolyte bridging''' might occur. The term bridging interactions is usually applied to the situation where a single polyelectrolyte chain can adsorb to two (or more) oppositely charged macroions (e.g. DNA molecule) thus establishing molecular bridges and, via its connectivity, mediate attractive interactions between them.\nAt small macroion separations, the chain is squeezed in between the macroions and electrostatic effects in the system are completely dominated by steric effects \u2013 the system is effectively discharged. As we increase the macroion separation, we simultaneously stretch the polyelectrolyte chain adsorbed to them. The stretching of the chain gives rise to the above-mentioned attractive interactions due to chain's rubber elasticity.\nBecause of its connectivity the behaviour of the polyelectrolyte chain bears almost no resemblance to the case of confined unconnected ions.", "page_name": "Polyelectrolyte", "page_id": "Polyelectrolyte", "heading": "Polyelectrolyte bridging", "sub_heading": "Polyelectrolyte bridging", "_id": "42--5---1---1", "title": "Polyelectrolyte | Polyelectrolyte bridging"}
{"qas": [{"question": "What is the difference between norepinephrine and epinephrine?", "answer": ""}, {"question": "What is the chemical name for epinephrine?", "answer": "Norepinephrine", "ae_score": -1.3045722525881371, "qg_score": null}, {"question": "What is the chemical name for epinephrine?", "answer": "Norepinephrine", "ae_score": -1.3045722525881371, "qg_score": null}], "content": "Norepinephrine is a catecholamine and a phenethylamine. Its structure differs from that of epinephrine only in that epinephrine has a methyl group attached to its nitrogen, whereas the methyl group is replaced by a hydrogen atom in norepinephrine.<ref name=PubChem/> The prefix ''nor-'' is derived as an abbreviation of the word \"normal\", used to indicate a demethylated compound.{{multiple image| align     = center| direction = horizontal| header =| header_align =| header_background =| footer =| footer_align =| footer_background =| background color =| image1=Norepinephrine structure.svg| caption1=Norepinephrine structure| alt1=Chemical diagram of the structure of a norepinephrine molecule.| width1=200| image2=Epinephrine structure.svg| caption2=Epinephrine structure| alt2=Chemical diagram of the structure of an epinephrine molecule.| width2=200| image3=Brenzcatechin.svg| caption3=Catechol structure| alt3=Chemical diagram of a catechol structure.| width3=136}}", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Structure", "sub_heading": "Structure", "_id": "43--0---1---1", "title": "Norepinephrine (PubChem) Structure"}
{"qas": [{"question": "What is the difference between norepinephrine and dopamine?", "answer": ""}, {"question": "The precursor to norepinephrine is also known as?", "answer": "dopamine", "ae_score": -0.31046307970894954, "qg_score": null}, {"question": "The precursor to norepinephrine is also known as?", "answer": "dopamine", "ae_score": -0.31046307970894954, "qg_score": null}], "content": "Norepinephrine is synthesized from the amino acid tyrosine by a series of enzymatic steps in the adrenal medulla and postganglionic neurons of the sympathetic nervous system. While the conversion of tyrosine to dopamine occurs predominantly in the cytoplasm, the conversion of dopamine to norepinephrine by dopamine \u03b2-monooxygenase occurs predominantly inside neurotransmitter vesicles.<ref name=Musacchio/> The metabolic pathway is:\nThus the direct precursor of norepinephrine is dopamine, which is synthesized indirectly from the essential amino acid phenylalanine or the non-essential amino acid tyrosine.<ref name=Musacchio/> These amino acids are found in nearly every protein and, as such, are provided by ingestion of protein-containing food, with tyrosine being the most common.\nPhenylalanine is converted into tyrosine by the enzyme phenylalanine hydroxylase, with molecular oxygen (O) and tetrahydrobiopterin as cofactors.  Tyrosine is converted into L-DOPA by the enzyme tyrosine hydroxylase, with tetrahydrobiopterin, O, and probably ferrous iron (Fe) as cofactors. L-DOPA is converted into dopamine by the enzyme aromatic -amino acid decarboxylase (also known as DOPA decarboxylase), with pyridoxal phosphate as cofactor.<ref name=Musacchio/> Dopamine is then converted into norepinephrine by the enzyme dopamine \u03b2-monooxygenase (formerly known as ''dopamine \u03b2-hydroxylase''), with O and ascorbic acid as cofactors.<ref name=Musacchio/>\nNorepinephrine itself can further be converted into epinephrine by the enzyme phenylethanolamine ''N''-methyltransferase with ''S''-adenosyl--methionine as cofactor.<ref name=Musacchio/>\nIn mammals, norepinephrine is rapidly degraded to various metabolites. The initial step in the breakdown can be catalyzed by either of the enzymes monoamine oxidase (mainly monoamine oxidase A) or COMT. From there the breakdown can proceed by a variety of pathways. The principal end products are either Vanillylmandelic acid or a conjugated form of MHPG, both of which are thought to be biologically inactive and are excreted in the urine.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Biochemical mechanisms", "sub_heading": "Biochemical mechanisms", "_id": "43--1---1---1", "title": "Norepinephrine: A Biochemical Approach"}
{"qas": [{"question": "How does norepinephrine work?", "answer": ""}, {"question": "How is norepinephrine broken down in the brain?", "answer": "monoamine oxidase", "ae_score": -0.739200060499905, "qg_score": null}, {"question": "How is norepinephrine broken down in the brain?", "answer": "monoamine oxidase", "ae_score": -0.739200060499905, "qg_score": null}], "content": "Like many other biologically active substances, norepinephrine exerts its effects by binding to and activating receptors located on the surface of cells. Two broad families of norepinephrine receptors have been identified, known as alpha and beta adrenergic receptors.<ref name=Rang&Dale/>  Alpha receptors are divided into subtypes \u03b1 and \u03b1; beta receptors into subtypes \u03b2, \u03b2, and \u03b2.<ref name=Rang&Dale/> All of these function as G protein-coupled receptors, meaning that they exert their effects via a complex second messenger system.<ref name=Rang&Dale/> Alpha-2 receptors usually have inhibitory effects, but many are located pre-synaptically (i.e., on the surface of the cells that release norepinephrine), so the net effect of alpha-2 activation is often a decrease in the amount of norepinephrine released.<ref name=Rang&Dale/>  Alpha-1 receptors and all three types of beta receptors usually have excitatory effects.<ref name=Rang&Dale/>\nInside the brain norepinephrine functions as a neurotransmitter, and is controlled by a set of mechanisms common to all monoamine neurotransmitters. After synthesis, norepinephrine is transported from the cytosol into synaptic vesicles by the vesicular monoamine transporter (VMAT). Norepinephrine is stored in these vesicles until it is ejected into the synaptic cleft, typically after an action potential causes the vesicles to release their contents directly into the synaptic cleft through a process called exocytosis.<ref name=Rang&Dale/>\nOnce in the synapse, norepinephrine binds to and activates receptors.  After an action potential, the norepinephrine molecules quickly become unbound from their receptors. They are then absorbed back into the presynaptic cell, via reuptake mediated primarily by the norepinephrine transporter (NET). Once back in the cytosol, norepinephrine can either be broken down by monoamine oxidase or repackaged into vesicles by VMAT, making it available for future release.<ref name=Eiden/>", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Functions", "sub_heading": "Functions", "_id": "43--2--0---1", "title": "Norepinephrine Activation in the Brain"}
{"qas": [{"question": "What is norepinephrine and how does it work?", "answer": ""}, {"question": "Which hormone is released by the sympathetic nervous system?", "answer": "Norepinephrine", "ae_score": -0.19274904809644183, "qg_score": null}, {"question": "Which hormone is released by the sympathetic nervous system?", "answer": "Norepinephrine", "ae_score": -0.19274904809644183, "qg_score": null}], "content": "Norepinephrine is the main neurotransmitter used by the sympathetic nervous system, which consists of about two dozen sympathetic chain ganglia located next to the spinal cord, plus a set of prevertebral ganglia located in the chest and abdomen.  These sympathetic ganglia are connected to numerous organs, including the eyes, salivary glands, heart, lungs, liver, gallbladder, stomach, intestines, kidneys, urinary bladder, reproductive organs, muscles, skin, and adrenal glands.<ref name=Hamill/>  Sympathetic activation of the adrenal glands causes the part called the adrenal medulla to release norepinephrine into the bloodstream, from which, functioning as a hormone, it gains further access to a wide variety of tissues.<ref name=Hamill/>\nBroadly speaking, the effect of norepinephrine on each target organ is to modify its state in a way that makes it more conducive to active body movement, often at a cost of increased energy use and increased wear and tear.  This can be contrasted with the acetylcholine-mediated effects of the parasympathetic nervous system, which modifies most of the same organs into a state more conducive to rest, recovery, and digestion of food, and usually less costly in terms of energy expenditure.<ref name=Schacter/>\nThe sympathetic effects of norepinephrine include:", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Functions", "sub_heading": "Sympathetic nervous system", "_id": "43--2--1---1", "title": "Norepinephrine Effects on the Organs"}
{"qas": [{"question": "Why is it that when you're in a dream, you can't stop thinking about it until you wake up?", "answer": ""}, {"question": "Where is norepinephrine stored in the brain?", "answer": "locus coeruleus", "ae_score": -0.32245527173217314, "qg_score": null}, {"question": "Where is norepinephrine stored in the brain?", "answer": "locus coeruleus", "ae_score": -0.32245527173217314, "qg_score": null}], "content": "The noradrenergic neurons in the brain form a neurotransmitter system, that, when activated, exerts effects on large areas of the brain. The effects are manifested in alertness, arousal, and readiness for action.\nNoradrenergic neurons (i.e., neurons whose primary neurotransmitter is norepinephrine) are comparatively few in number, and their cell bodies are confined to a few relatively small brain areas, but they send projections to many other brain areas and exert powerful effects on their targets.  These noradrenergic cell groups were first mapped in 1964 by Annica Dahlstr\u00f6m and Kjell Fuxe, who assigned them labels starting with the letter \"A\" (for \"aminergic\").  In their scheme, areas A1 through A7 contain the neurotransmitter norepinephrine (A8 through A14 contain dopamine).  Noradrenergic cell group A1 is located in the caudal ventrolateral part of the medulla, and plays a role in the control of body fluid metabolism. Noradrenergic cell group A2 is located in a brainstem area called the solitary nucleus; these cells have been implicated in a variety of responses, including control of food intake and responses to stress.  Cell groups A5 and A7 project mainly to the spinal cord.\nThe most important source of norepinephrine in the brain is the locus coeruleus, which contains noradrenergic cell group A6 and adjoins cell group A4.  The locus coeruleus is quite small in absolute terms\u2014in primates it is estimated to contain around 15,000 neurons, less than one millionth of the neurons in the brain\u2014but it sends projections to every major part of the brain and also to the spinal cord.\nThe level of activity in the locus coeruleus correlates broadly with vigilance and speed of reaction.  LC activity is low during sleep and drops to virtually nothing during the REM (dreaming) state.  It runs at a baseline level during wakefulness, but increases temporarily when a person is presented with any sort of stimulus that draws attention.  Unpleasant stimuli such as pain, difficulty breathing, bladder distension, heat or cold generate larger increases.  Extremely unpleasant states such as intense fear or intense pain are associated with very high levels of LC activity.<ref name=SaraNeuron/>\nNorepinephrine released by the locus coeruleus affects brain function in a number of ways.  It enhances processing of sensory inputs, enhances attention, enhances formation and retrieval of both long term and working memory, and enhances the ability of the brain to respond to inputs by changing the activity pattern in the prefrontal cortex and other areas.  The control of arousal level is strong enough that drug-induced suppression of the LC has a powerful sedating effect.<ref name=Berridge/>\nThere is great similarity between situations that activate the locus coeruleus in the brain and situations that activate the sympathetic nervous system in the periphery:  the LC essentially mobilizes the brain for action while the sympathetic system mobilizes the body.  It has been argued that this similarity arises because both are to a large degree controlled by the same brain structures, particularly a part of the brainstem called the nucleus gigantocellularis.<ref name=SaraNeuron/>", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Functions", "sub_heading": "Central nervous system", "_id": "43--2--2---1", "title": "Noradrenergic Neurons in the Brain"}
{"qas": [{"question": "What is the difference between sympatholytic and sympathomimetic drugs?", "answer": ""}, {"question": "Drugs that mimic or enhance the effects of norepinephrine?", "answer": "Sympathomimetic drugs", "ae_score": -0.914703143874386, "qg_score": null}, {"question": "Drugs that mimic or enhance the effects of norepinephrine?", "answer": "Sympathomimetic drugs", "ae_score": -0.914703143874386, "qg_score": null}], "content": "Sympathomimetic drugs mimic or enhance at least some of the effects of norepinephrine released by the sympathetic nervous system; sympatholytic drugs, in contrast, block at least some of the effects.  Both of these are large groups with diverse uses, depending on exactly which effects are enhanced or blocked.<ref name=Gardenhire/>  Norepinephrine itself is classified as a sympathomimetic drug:  its effects when given by intravenous injection of increasing heart rate and force and constricting blood vessels make it very useful for treating medical emergencies that involve critically low blood pressure.<ref name=Gardenhire/>", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Pharmacology", "sub_heading": "Pharmacology", "_id": "43--3--0---1", "title": "Sympathomimetic Drugs and Sympathomolytic Drugs"}
{"qas": [{"question": "What are the negative effects of beta blockers?", "answer": ""}, {"question": "What disease can negative effects of norepinephrine be particularly severe?", "answer": "diabetes", "ae_score": -0.4250751493272271, "qg_score": null}, {"question": "What disease can negative effects of norepinephrine be particularly severe?", "answer": "diabetes", "ae_score": -0.4250751493272271, "qg_score": null}], "content": "These are drugs that block the effects of beta noradrenergic receptors while having little or no effect on alpha receptors.  They are sometimes used to treat high blood pressure, atrial fibrillation and congestive heart failure, but recent reviews have concluded that other types of drugs are usually superior for those purposes.  Beta blockers may be a viable choice for other cardiovascular conditions, though, including angina and Marfan syndrome.  They are also widely used to treat glaucoma, either in pill form or in eyedrops.  Because of their effects in reducing anxiety symptoms and tremor, they have sometimes been used by entertainers, public speakers and athletes to reduce performance anxiety, although they are not medically approved for that purpose and are banned by the International Olympic Committee.\nUnfortunately, the usefulness of beta blockers is limited by a range of serious side effects, including slowing of heart rate, a drop in blood pressure, asthma, and reactive hypoglycemia.<ref name=Inoue/>  The negative effects can be particularly severe in people who suffer from diabetes.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Pharmacology", "sub_heading": "Beta blockers", "_id": "43--3--1---1", "title": "Beta blockers are a safe and effective way to treat heart disease"}
{"qas": [{"question": "What are alpha blockers and how do they work?", "answer": ""}, {"question": "What is the best known drug in norepinephrine class?", "answer": "yohimbine", "ae_score": -0.18996048562499718, "qg_score": null}, {"question": "What is the best known drug in norepinephrine class?", "answer": "yohimbine", "ae_score": -0.18996048562499718, "qg_score": null}], "content": "These are drugs that block the effects of noradrenergic alpha receptors while having little or no effect on beta receptors.  Drugs belonging to this group can have very different effects, however, depending on whether they primarily block alpha-1 receptors, alpha-2 receptors, or both.  Alpha-2 receptors, as described elsewhere in this article, are frequently located on norepinephrine-releasing neurons themselves and have inhibitory effects on them; consequently blockage of alpha-2 receptors usually results in an increase in norepinephrine release.<ref name=Lilley/>  Alpha-1 receptors are usually located on target cells and have excitatory effects on them; consequently blockage of alpha-1 receptors usually results in blocking some of the effects of norepinephrine.<ref name=Lilley/>  Drugs such as phentolamine that act on both types of receptors can produce a complex combination of both effects. In most cases when the term \"alpha blocker\" is used without qualification, it refers to a selective alpha-1 antagonist.\nSelective alpha-1 blockers have a variety of uses.  Because one of their effects is to relax the muscles in the neck of the bladder, they are often used to treat benign prostatic hyperplasia, and to help with the expulsion of bladder stones. Their effects on the central nervous system make them useful for treating generalized anxiety disorder, panic disorder, and posttraumatic stress disorder. They may, however, have significant side-effects, including a drop in blood pressure.<ref name=Lilley/>\nSome antidepressants function partly as selective alpha-2 blockers, but the best-known drug in that class is yohimbine, which is extracted from the bark of the African yohimbe tree.  Yohimbine acts as a male potency enhancer, but its usefulness for that purpose is limited by serious side-effects including anxiety and insomnia.<ref name=Corazza/>  Overdoses can cause a dangerous increase in blood pressure.<ref name=Corazza/>  Yohimbine is banned in many countries, but in the United States, because it is extracted from a plant rather than chemically synthesized, it is sold over the counter as a nutritional supplement.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Pharmacology", "sub_heading": "Alpha blockers", "_id": "43--3--2---1", "title": "Norepinephrine | Pharmacology | Alpha blockers"}
{"qas": [{"question": "How do drugs like Clonidine and Xylazine work?", "answer": ""}, {"question": "Which norepinephrine drug is used to treat anxiety disorders and insomnia?", "answer": "Clonidine", "ae_score": -1.1928416477413109, "qg_score": null}, {"question": "Which norepinephrine drug is used to treat anxiety disorders and insomnia?", "answer": "Clonidine", "ae_score": -1.1928416477413109, "qg_score": null}], "content": "These are drugs that activate alpha-2 receptors or enhance their effects.  Because alpha-2 receptors are inhibitory and many are located presynaptically on norepinephrine-releasing cells, the net effect of these drugs is usually to reduce the amount of norepinephrine released.  Drugs in this group that are capable of entering the brain often have strong sedating effects, due to their inhibitory effects on the locus coeruleus.<ref name=Lemke/>  Clonidine, for example, is used for the treatment of anxiety disorders and insomnia, and also as a sedative premedication for patients about to undergo surgery.  Xylazine, another drug in this group, is also a powerful sedative and is often used in combination with ketamine as a general anaesthetic for veterinary surgery\u2014in the United States it has not been approved for use in humans.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Pharmacology", "sub_heading": "Alpha-2 agonists", "_id": "43--3--3---1", "title": "Medications for Sedation in the Brain"}
{"qas": [{"question": "What is the difference between Dopamine and Monoamine oxidase inhibitors?", "answer": ""}, {"question": "Antidepressants that inhibit the release of norepinephrine and serotonin are called?", "answer": "Monoamine oxidase inhibitors", "ae_score": -0.5910100251068245, "qg_score": null}, {"question": "Antidepressants that inhibit the release of norepinephrine and serotonin are called?", "answer": "Monoamine oxidase inhibitors", "ae_score": -0.5910100251068245, "qg_score": null}], "content": "These are drugs whose primary effects are thought to be mediated by different neurotransmitter systems (dopamine for stimulants, serotonin for antidepressants), but many also increase levels of norepinephrine in the brain.  Amphetamine, for example, is a stimulant that increases release of norepinephrine as well as dopamine.  Monoamine oxidase inhibitors are antidepressants that inhibit the metabolic degradation of norepinephrine as well as serotonin.  In some cases it is difficult to distinguish the norepinephrine-mediated effects from the effects related to other neurotransmitters.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Pharmacology", "sub_heading": "Stimulants and antidepressants", "_id": "43--3--4---1", "title": "Norepinephrine-Mediated Effects of Drugs"}
{"qas": [{"question": "Hyperactivation of the sympathetic nervous system?", "answer": ""}, {"question": "Which part of the sympathetic nervous system is norepinephrine responsible for?", "answer": "Hyperactivation", "ae_score": -0.32165685985830156, "qg_score": null}, {"question": "Which part of the sympathetic nervous system is norepinephrine responsible for?", "answer": "Hyperactivation", "ae_score": -0.32165685985830156, "qg_score": null}], "content": "Hyperactivation of the sympathetic nervous system is not a recognized condition in itself, but it is a component of a number of conditions, as well as a possible consequence of taking sympathomimetic drugs.  It causes a distinctive set of symptoms including aches and pains, rapid heartbeat, elevated blood pressure, sweating, palpitations, anxiety, headache, paleness, and a drop in blood glucose.  If sympathetic activity is elevated for an extended time, it can cause weight loss and other stress-related body changes.\nThe list of conditions that can cause sympathetic hyperactivation includes severe brain injury, spinal cord damage, heart failure, high blood pressure, kidney disease, and various types of stress.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Diseases and disorders", "sub_heading": "Diseases and disorders", "_id": "43--4--0---1", "title": "Hyperactivation of the Sympathetic Nervous System"}
{"qas": [{"question": "What is a pheochromocytoma?", "answer": ""}, {"question": "What are the most common symptoms of pheochromocytoma?", "answer": "sympathetic hyperactivation", "ae_score": -0.4860449675645766, "qg_score": null}, {"question": "What are the most common symptoms of pheochromocytoma?", "answer": "sympathetic hyperactivation", "ae_score": -0.4860449675645766, "qg_score": null}], "content": "A pheochromocytoma is a rarely occurring tumor of the adrenal medulla, caused either by genetic factors or certain types of cancer.  The consequence is a massive increase in the amount of norepinephrine and epinephrine released into the bloodstream.  The most obvious symptoms are those of sympathetic hyperactivation, including particularly a rise in blood pressure that can reach fatal levels.  The most effective treatment is surgical removal of the tumor.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Diseases and disorders", "sub_heading": "Pheochromocytoma", "_id": "43--4--1---1", "title": "Pheochromocytoma: A rare tumor of the adrenal medulla"}
{"qas": [{"question": "What does stress actually do to your body?", "answer": ""}, {"question": "The norepinephrine system is activated by what?", "answer": "Stress", "ae_score": -0.5062434274209119, "qg_score": null}, {"question": "The norepinephrine system is activated by what?", "answer": "Stress", "ae_score": -0.5062434274209119, "qg_score": null}], "content": "Stress, to a physiologist, means any situation that threatens the continued stability of the body and its functions. Stress affects a wide variety of body systems:  the two most consistently activated are the hypothalamic-pituitary-adrenal axis and the norepinephrine system, including both the sympathetic nervous system and the locus coeruleus-centered system in the brain.<ref name=Chrousos/>  Stressors of many types evoke increases in noradrenergic activity, which mobilizes the brain and body to meet the threat.<ref name=Chrousos/>  Chronic stress, if continued for a long time, can damage many parts of the body.  A significant part of the damage is due to the effects of sustained norepinephrine release, because of norepinephrine's general function of directing resources away from maintenance, regeneration, and reproduction, and toward systems that are required for active movement.  The consequences can include slowing of growth (in children), sleeplessness, loss of libido, gastrointestinal problems, impaired disease resistance, slower rates of injury healing, depression, and increased vulnerability to addiction.<ref name=Chrousos/>", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Diseases and disorders", "sub_heading": "Stress", "_id": "43--4--2---1", "title": "Norepinephrine | Diseases and disorders | Stress"}
{"qas": [{"question": "What is ADHD?", "answer": ""}, {"question": "What is it called when you have norepinephrine?", "answer": "Attention deficit hyperactivity disorder", "ae_score": -0.3536771799840422, "qg_score": null}, {"question": "What is it called when you have norepinephrine?", "answer": "Attention deficit hyperactivity disorder", "ae_score": -0.3536771799840422, "qg_score": null}], "content": "Attention deficit hyperactivity disorder is a psychiatric condition involving problems with attention, hyperactivity, and impulsiveness. It is most commonly treated using stimulant drugs such as methylphenidate (Ritalin), whose primary effect is to increase dopamine levels in the brain, but drugs in this group also generally increase brain levels of norepinephrine, and it has been difficult to determine whether these actions are involved in their clinical value.  Also there is substantial evidence that many people with ADHD show \"biomarkers\" involving altered norepinephrine processing. Several drugs whose primary effects are on norepinephrine, including guanfacine, clonidine, and atomoxetine, have been tried as treatments for ADHD, and found to have effects comparable to those of stimulants.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Diseases and disorders", "sub_heading": "ADHD", "_id": "43--4--3---1", "title": "Attention Deficit Hyperactivity Disorder (ADHD)"}
{"qas": [{"question": "What causes people to pass out?", "answer": ""}, {"question": "What is it called when you lose neurons in the sympathetic nervous system?", "answer": "pure autonomic failure", "ae_score": -0.7976985841731689, "qg_score": null}, {"question": "What is it called when you lose neurons in the sympathetic nervous system?", "answer": "pure autonomic failure", "ae_score": -0.7976985841731689, "qg_score": null}], "content": "Several conditions, including Parkinson's disease, diabetes and so-called pure autonomic failure, can cause a loss of norepinephrine-secreting neurons in the sympathetic nervous system.  The symptoms are widespread, the most serious being a reduction in heart rate and an extreme drop in resting blood pressure, making it impossible for severely affected people to stand for more than a few seconds without fainting.  Treatment can involve dietary changes or drugs.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Diseases and disorders", "sub_heading": "Autonomic failure", "_id": "43--4--4---1", "title": "Parkinson's Disease Symptoms and Treatment"}
{"qas": [{"question": "What is norepinephrine?", "answer": ""}, {"question": "What chemical replaces norepinephrine in the nervous system of protozoa?", "answer": "octopamine", "ae_score": -0.2586281734210579, "qg_score": null}, {"question": "What chemical replaces norepinephrine in the nervous system of protozoa?", "answer": "octopamine", "ae_score": -0.2586281734210579, "qg_score": null}], "content": "Norepinephrine has been reported to exist in a wide variety of animal species, including protozoa,<ref name=Pfluger/> placozoa and cnidaria (jellyfish and related species), but not in ctenophores (comb jellies), whose nervous systems differ greatly from those of other animals.  It is generally present in deuterostomes (vertebrates, etc.), but in protostomes (arthropods, molluscs, flatworms, nematodes, annelids, etc.) it is replaced by octopamine, a closely related chemical with a closely related synthesis pathway.  In insects, octopamine has alerting and activating functions that correspond (at least roughly) with the functions of norepinephrine in vertebrates. It has been argued that octopamine evolved to replace norepinephrine rather than ''vice versa''; however, the nervous system of amphioxus (a primitive chordate) has been reported to contain octopamine but not norepinephrine, which presents difficulties for that hypothesis.<ref name=Pfluger/>", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "Comparative biology and evolution", "sub_heading": "Comparative biology and evolution", "_id": "43--5---1---1", "title": "Norepinephrine and the Nervous System of Amphioxus"}
{"qas": [{"question": "How do we know that norepinephrine is a sympathetic neurotransmitter?", "answer": ""}, {"question": "When was noradrenaline thought to be a sympathetic transmitter?", "answer": "between 1934 and 1938", "ae_score": null, "qg_score": null}, {"question": "When was noradrenaline thought to be a sympathetic transmitter?", "answer": "between 1934 and 1938", "ae_score": null, "qg_score": null}], "content": "Early in the twentieth century Walter Cannon, who had popularized the idea of a sympatho-adrenal system preparing the body for fight and flight, and his colleague Arturo Rosenblueth developed a theory of two ''sympathins'', ''sympathin E'' (excitatory) and ''sympathin I'' (inhibitory), responsible for these actions.<ref name=Bacq/> The Belgian pharmacologist Z\u00e9non Bacq as well as Canadian and US-American pharmacologists between 1934 and 1938 suggested that noradrenaline might be a sympathetic transmitter. In 1939, Hermann Blaschko and Peter Holtz independently identified the biosynthetic mechanism for norepinephrine in the vertebrate body. In 1945 Ulf von Euler published the first of a series of papers that established the role of norepinephrine as a neurotransmitter.  He demonstrated the presence of norepinephrine in sympathetically innervated tissues and brain, and adduced evidence that it is the ''sympathin'' of Cannon and Rosenblueth.", "page_name": "Norepinephrine", "page_id": "Norepinephrine", "heading": "History", "sub_heading": "History", "_id": "43--6---1---1", "title": "Norepinephrine as a Sympathin"}
{"qas": [{"question": "How did the 2008 financial crisis affect the global economy?", "answer": ""}, {"question": "What type of securities were involved in the subprime mortgage crisis?", "answer": "mortgage-backed securities", "ae_score": -0.2445572279263817, "qg_score": null}, {"question": "The subprime crisis was caused by the rise in interest rates on what?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The immediate cause or trigger of the crisis was the bursting of the United States housing bubble which peaked in approximately 2005\u20132006. An increase in loan incentives such as easy initial terms and a long-term trend of rising housing prices had encouraged borrowers to assume risky mortgages in the anticipation that they would be able to quickly refinance at easier terms. However, once interest rates began to rise and housing prices started to drop moderately in 2006\u20132007 in many parts of the U.S., borrowers were unable to refinance. Defaults and foreclosure activity increased dramatically as easy initial terms expired, home prices fell, and adjustable-rate mortgage (ARM) interest rates reset higher.\nAs housing prices fell, global investor demand for mortgage-related securities evaporated. This became apparent by July 2007, when investment bank Bear Stearns announced that two of its hedge funds had imploded. These funds had invested in securities that derived their value from mortgages. When the value of these securities dropped, investors demanded that these hedge funds provide additional collateral. This created a cascade of selling in these securities, which lowered their value further. Economist Mark Zandi wrote that this 2007 event was \"arguably the proximate catalyst\" for the financial market disruption that followed.\nSeveral other factors set the stage for the rise and fall of housing prices, and related securities widely held by financial firms. In the years leading up to the crisis, the U.S. received large amounts of foreign money from fast-growing economies in Asia and oil-producing/exporting countries. This inflow of funds combined with low U.S. interest rates from 2002 to 2004 contributed to easy credit conditions, which fueled both housing and credit bubbles. Loans of various types (e.g., mortgage, credit card, and auto) were easy to obtain and consumers assumed an unprecedented debt load.\nAs part of the housing and credit booms, the amount of financial agreements called mortgage-backed securities (MBS), which derive their value from mortgage payments and housing prices, greatly increased. Such financial innovation enabled institutions and investors around the world to invest in the U.S. housing market. As housing prices declined, major global financial institutions that had borrowed and invested heavily in MBS reported significant losses. Defaults and losses on other loan types also increased significantly as the crisis expanded from the housing market to other parts of the economy. Total losses were estimated in the trillions of U.S. dollars globally.\nWhile the housing and credit bubbles were growing, a series of factors caused the financial system to become increasingly fragile. Policymakers did not recognize the increasingly important role played by financial institutions such as investment banks and hedge funds, also known as the shadow banking system. These entities were not subject to the same regulations as depository banking. Further, shadow banks were able to mask the extent of their risk taking from investors and regulators through the use of complex, off-balance sheet derivatives and securitizations. Economist Gary Gorton has referred to the 2007\u20132008 aspects of the crisis as a \"run\" on the shadow banking system.\nThe complexity of these off-balance sheet arrangements and the securities held, as well as the interconnection between larger financial institutions, made it virtually impossible to re-organize them via bankruptcy, which contributed to the need for government bailouts. Some experts believe these shadow institutions had become as important as commercial (depository) banks in providing credit to the U.S. economy, but they were not subject to the same regulations. These institutions as well as certain regulated banks had also assumed significant debt burdens while providing the loans described above and did not have a financial cushion sufficient to absorb large loan defaults or MBS losses.\nThe losses experienced by financial institutions on their mortgage-related securities impacted their ability to lend, slowing economic activity. Interbank lending dried-up initially and then loans to non-financial firms were affected. Concerns regarding the stability of key financial institutions drove central banks to take action to provide funds to encourage lending and to restore faith in the commercial paper markets, which are integral to funding business operations. Governments also bailed out key financial institutions, assuming significant additional financial commitments.\nThe risks to the broader economy created by the housing market downturn and subsequent financial market crisis were primary factors in several decisions by central banks around the world to cut interest rates and governments to implement economic stimulus packages. Effects on global stock markets due to the crisis were dramatic. Between 1 January and 11 October 2008, owners of stocks in U.S. corporations suffered about $8 trillion in losses, as their holdings declined in value from $20 trillion to $12 trillion. Losses in other countries averaged about 40%.\nLosses in the stock markets and housing value declines place further downward pressure on consumer spending, a key economic engine. Leaders of the larger developed and emerging nations met in November 2008 and March 2009 to formulate strategies for addressing the crisis. A variety of solutions have been proposed by government officials, central bankers, economists, and business executives. In the U.S., the Dodd\u2013Frank Wall Street Reform and Consumer Protection Act was signed into law in July 2010 to address some of the causes of the crisis.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Background and timeline of events", "sub_heading": "Background and timeline of events", "_id": "44--0---1---1", "title": "The Financial Crisis and the Global Crisis"}
{"qas": [{"question": "What would have happened if the 2008 financial crisis didn't happen?", "answer": ""}, {"question": "What was the main cause of the subprime mortgage crisis?", "answer": "moral hazard", "ae_score": -0.3679365719129897, "qg_score": null}, {"question": "The financial crisis of the late 1990s and early 2000s was caused by the inability?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "The crisis can be attributed to a number of factors pervasive in both housing and credit markets, factors which emerged over a number of years. Causes proposed include the inability of homeowners to make their mortgage payments (due primarily to adjustable-rate mortgages resetting, borrowers overextending, predatory lending, and speculation), overbuilding during the boom period, risky mortgage products, increased power of mortgage originators, high personal and corporate debt levels, financial products that distributed and perhaps concealed the risk of mortgage default, bad monetary and housing policies, international trade imbalances, and inappropriate government regulation. Excessive consumer housing debt was in turn caused by the mortgage-backed security, credit default swap, and collateralized debt obligation sub-sectors of the finance industry, which were offering irrationally low interest rates and irrationally high levels of approval to subprime mortgage consumers because they were calculating aggregate risk using gaussian copula formulas that strictly assumed the independence of individual component mortgages, when in fact the credit-worthiness of almost every new subprime mortgage was highly correlated with that of any other because of linkages through consumer spending levels which fell sharply when property values began to fall during the initial wave of mortgage defaults. Debt consumers were acting in their rational self-interest, because they were unable to audit the finance industry's opaque faulty risk pricing methodology.\nAmong the important catalysts of the subprime crisis were the influx of money from the private sector, the banks entering into the mortgage bond market, government policies aimed at expanding homeownership, speculation by many home buyers, and the predatory lending practices of the mortgage lenders, specifically the adjustable-rate mortgage, 2\u201328 loan, that mortgage lenders sold directly or indirectly via mortgage brokers. On Wall Street and in the financial industry, moral hazard lay at the core of many of the causes.\nIn its \"Declaration of the Summit on Financial Markets and the World Economy,\" dated 15 November 2008, leaders of the Group of 20 cited the following causes:\nFederal Reserve Chair Ben Bernanke testified in September 2010 regarding the causes of the crisis. He wrote that there were shocks or triggers (i.e., particular events that touched off the crisis) and vulnerabilities (i.e., structural weaknesses in the financial system, regulation and supervision) that amplified the shocks. Examples of triggers included: losses on subprime mortgage securities that began in 2007 and a run on the shadow banking system that began in mid-2007, which adversely affected the functioning of money markets. Examples of vulnerabilities in the ''private'' sector included: financial institution dependence on unstable sources of short-term funding such as repurchase agreements or Repos; deficiencies in corporate risk management; excessive use of leverage (borrowing to invest); and inappropriate usage of derivatives as a tool for taking excessive risks. Examples of vulnerabilities in the ''public'' sector included: statutory gaps and conflicts between regulators; ineffective use of regulatory authority; and ineffective crisis management capabilities. Bernanke also discussed \"Too big to fail\" institutions, monetary policy, and trade deficits.\nDuring May 2010, Warren Buffett and Paul Volcker separately described questionable assumptions or judgments underlying the U.S. financial and economic system that contributed to the crisis. These assumptions included: 1) Housing prices would not fall dramatically; 2) Free and open financial markets supported by sophisticated financial engineering would most effectively support market efficiency and stability, directing funds to the most profitable and productive uses; 3) Concepts embedded in mathematics and physics could be directly adapted to markets, in the form of various financial models used to evaluate credit risk; 4) Economic imbalances, such as large trade deficits and low savings rates indicative of over-consumption, were sustainable; and 5) Stronger regulation of the shadow banking system and derivatives markets was not needed.\nThe U.S. Financial Crisis Inquiry Commission reported its findings in January 2011. It concluded that \"the crisis was avoidable and was caused by: widespread failures in financial regulation, including the Federal Reserve\u2019s failure to stem the tide of toxic mortgages; dramatic breakdowns in corporate governance including too many financial firms acting recklessly and taking on too much risk; an explosive mix of excessive borrowing and risk by households and Wall Street that put the financial system on a collision course with crisis; key policy makers ill prepared for the crisis, lacking a full understanding of the financial system they oversaw; and systemic breaches in accountability and ethics at all levels\".", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Causes", "_id": "44--1--0---1", "title": "The U.S. Financial Crisis"}
{"qas": [{"question": "What is the difference between a \"crisis\" and a \"real\" crisis?", "answer": ""}, {"question": "How many subprime mortgage narratives are there?", "answer": "Four", "ae_score": -0.543098922101254, "qg_score": null}, {"question": "How many subprime mortgage narratives are there?", "answer": "Four", "ae_score": -0.543098922101254, "qg_score": null}], "content": "There are several \"narratives\" attempting to place the causes of the crisis into context, with overlapping elements. Four such narratives include:\nUnderlying narratives #1-3 is a hypothesis that growing income inequality and wage stagnation encouraged families to increase their household debt to maintain their desired living standard, fueling the bubble. Further, this greater share of income flowing to the top increased the political power of business interests, who used that power to deregulate or limit regulation of the shadow banking system.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Narratives", "_id": "44--1--1---1", "title": "Four Narratives of the Financial Crisis"}
{"qas": [{"question": "Why is the housing market in the US so bad?", "answer": ""}, {"question": "How many homes were foreclosed in september 2012?", "answer": "57,000", "ae_score": -0.3403503010219664, "qg_score": null}, {"question": "What type of debt did the us have in the late 1990s?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "According to Robert J. Shiller and other economists, housing price increases beyond the general inflation rate are not sustainable in the long term. From the end of World War II to the beginning of the housing bubble in 1997, housing prices in the US remained relatively stable. The bubble was characterized by higher rates of household debt and lower savings rates, slightly higher rates of home ownership, and of course higher housing prices. It was fueled by low interest rates and large inflows of foreign funds that created easy credit conditions.\nBetween 1997 and 2006 (the peak of the housing bubble), the price of the typical American house increased by 124%. From 1980 to 2001, the ratio of median home prices to median household income (a measure of ability to buy a house) fluctuated from 2.9 to 3.1. In 2004 it rose to 4.0, and by 2006 it hit 4.6. The housing bubble was more pronounced in coastal areas where the ability to build new housing was restricted by geography or land use restrictions. This housing bubble resulted in quite a few homeowners refinancing their homes at lower interest rates, or financing consumer spending by taking out second mortgages secured by the price appreciation. US household debt as a percentage of annual disposable personal income was 127% at the end of 2007, versus 77% in 1990.\nWhile housing prices were increasing, consumers were saving less and both borrowing and spending more. Household debt grew from $705 billion at year end 1974, 60% of disposable personal income, to $7.4 trillion at yearend 2000, and finally to $14.5 trillion in midyear 2008, 134% of disposable personal income. During 2008, the typical US household owned 13 credit cards, with 40% of households carrying a balance, up from 6% in 1970.\nFree cash used by consumers from home equity extraction doubled from $627 billion in 2001 to $1,428 billion in 2005 as the housing bubble built, a total of nearly $5 trillion over the period. U.S. home mortgage debt relative to GDP increased from an average of 46% during the 1990s to 73% during 2008, reaching $10.5 trillion. From 2001 to 2007, U.S. mortgage debt almost doubled, and the amount of mortgage debt per household rose more than 63%, from $91,500 to $149,500, with essentially stagnant wages. Economist Tyler Cowen explained that the economy was highly dependent on this home equity extraction: \"In the 1993-1997 period, home owners extracted an amount of equity from their homes equivalent to 2.3% to 3.8% GDP. By 2005, this figure had increased to 11.5% GDP.\"\nThis credit and house price explosion led to a building boom and eventually to a surplus of unsold homes, which caused U.S. housing prices to peak and begin declining in mid-2006. Easy credit, and a belief that house prices would continue to appreciate, had encouraged many subprime borrowers to obtain adjustable-rate mortgages. These mortgages enticed borrowers with a below market interest rate for some predetermined period, followed by market interest rates for the remainder of the mortgage's term.\nThe US home ownership rate increased from 64% in 1994 (about where it had been since 1980) to an all-time high of 69.2% in 2004. Subprime lending was a major contributor to this increase in home ownership rates and in the overall demand for housing, which drove prices higher.\nBorrowers who would not be able to make the higher payments once the initial grace period ended, were planning to refinance their mortgages after a year or two of appreciation. As a result of the depreciating housing prices, borrowers ability to refinance became more difficult. Borrowers who found themselves unable to escape higher monthly payments by refinancing began to default.\nAs more borrowers stopped making their mortgage payments, foreclosures and the supply of homes for sale increased. This placed downward pressure on housing prices, which further lowered homeowners' equity. The decline in mortgage payments also reduced the value of mortgage-backed securities, which eroded the net worth and financial health of banks. This vicious cycle was at the heart of the crisis.\nBy September 2008, average U.S. housing prices had declined by over 20% from their mid-2006 peak. This major and unexpected decline in house prices means that many borrowers have zero or negative equity in their homes, meaning their homes were worth less than their mortgages. As of March 2008, an estimated 8.8 million borrowers \u2013 10.8% of all homeowners \u2013 had negative equity in their homes, a number that is believed to have risen to 12 million by November 2008. By September 2010, 23% of all U.S. homes were worth less than the mortgage loan.\nBorrowers in this situation have an incentive to default on their mortgages as a mortgage is typically nonrecourse debt secured against the property. Economist Stan Leibowitz argued in the Wall Street Journal that although only 12% of homes had negative equity, they comprised 47% of foreclosures during the second half of 2008. He concluded that the extent of equity in the home was the key factor in foreclosure, rather than the type of loan, credit worthiness of the borrower, or ability to pay.\nIncreasing foreclosure rates increases the inventory of houses offered for sale. The number of new homes sold in 2007 was 26.4% less than in the preceding year. By January 2008, the inventory of unsold new homes was 9.8 times the December 2007 sales volume, the highest value of this ratio since 1981. Furthermore, nearly four million existing homes were for sale, of which roughly 2.2 million were vacant.\nThis overhang of unsold homes lowered house prices. As prices declined, more homeowners were at risk of default or foreclosure. House prices are expected to continue declining until this inventory of unsold homes (an instance of excess supply) declines to normal levels. A report in January 2011 stated that U.S. home values dropped by 26 percent from their peak in June 2006 to November 2010, more than the 25.9% drop between 1928 to 1933 when the Great Depression occurred.\nFrom September 2008 to September 2012, there were approximately 4 million completed foreclosures in the U.S. As of September 2012, approximately 1.4 million homes, or 3.3% of all homes with a mortgage, were in some stage of foreclosure compared to 1.5 million, or 3.5%, in September 2011. During September 2012, 57,000 homes completed foreclosure; this is down from 83,000 the prior September but well above the 2000\u20132006 average of 21,000 completed foreclosures per month.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Housing market", "_id": "44--1--2--0", "title": "Why the Housing Bubble Is Not Sustainable in the Long-Term"}
{"qas": [{"question": "What are the negative consequences of not adjusting tax and mortgage policies?", "answer": ""}, {"question": "Who said the housing market was the greatest bubble ever?", "answer": "Warren Buffett", "ae_score": -0.43454654741360965, "qg_score": null}, {"question": "The subprime crisis in the late 1990s was caused by a lack of tax and?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Speculative borrowing in residential real estate has been cited as a contributing factor to the subprime mortgage crisis. During 2006, 22% of homes purchased (1.65 million units) were for investment purposes, with an additional 14% (1.07 million units) purchased as vacation homes. During 2005, these figures were 28% and 12%, respectively. In other words, a record level of nearly 40% of homes purchased were not intended as primary residences. David Lereah, National Association of Realtors's chief economist at the time, stated that the 2006 decline in investment buying was expected: \"Speculators left the market in 2006, which caused investment sales to fall much faster than the primary market.\"\nHousing prices nearly doubled between 2000 and 2006, a vastly different trend from the historical appreciation at roughly the rate of inflation. While homes had not traditionally been treated as investments subject to speculation, this behavior changed during the housing boom. Media widely reported condominiums being purchased while under construction, then being \"flipped\" (sold) for a profit without the seller ever having lived in them. Some mortgage companies identified risks inherent in this activity as early as 2005, after identifying investors assuming highly leveraged positions in multiple properties.\nNicole Gelinas of the Manhattan Institute described the negative consequences of not adjusting tax and mortgage policies to the shifting treatment of a home from conservative inflation hedge to speculative investment. Economist Robert Shiller argued that speculative bubbles are fueled by \"contagious optimism, seemingly impervious to facts, that often takes hold when prices are rising. Bubbles are primarily social phenomena; until we understand and address the psychology that fuels them, they're going to keep forming.\" Keynesian economist Hyman Minsky described how speculative borrowing contributed to rising debt and an eventual collapse of asset values.\nWarren Buffett testified to the Financial Crisis Inquiry Commission: \"There was the greatest bubble I've ever seen in my life...The entire American public eventually was caught up in a belief that housing prices could not fall dramatically.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Homeowner speculation", "_id": "44--1--2--1", "title": "Speculative Borrowing in Residential Real Estate"}
{"qas": [{"question": "Why is it that in the United States, the median down payment for first-time home buyers is $20,000, while in China it is $30,000?", "answer": ""}, {"question": "How many subprime arms were there in 2006?", "answer": "61%", "ae_score": -0.20109285148445571, "qg_score": null}, {"question": "What type of ars were offered to people with credit scores high enough to qualify for?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "In the years before the crisis, the behavior of lenders changed dramatically. Lenders offered more and more loans to higher-risk borrowers, including undocumented immigrants. Lending standards deteriorated particularly between 2004 and 2007, as the government-sponsored enterprise (GSE) mortgage market share (i.e. the share of Fannie Mae and Freddie Mac, which specialized in conventional, conforming, non-subprime mortgages) declined and private securitizers share grew, rising to more than half of mortgage securitizations.\nSubprime mortgages grew from 5% of total originations ($35 billion) in 1994, to 20% ($600 billion) in 2006. Another indicator of a \"classic\" boom-bust credit cycle, was a closing in the difference between subprime and prime mortgage interest rates (the \"subprime markup\") between 2001 and 2007.\nIn addition to considering higher-risk borrowers, lenders had offered progressively riskier loan options and borrowing incentives. In 2005, the median down payment for first-time home buyers was 2%, with 43% of those buyers making no down payment whatsoever. By comparison, China has down payment requirements that exceed 20%, with higher amounts for non-primary residences.\nTo produce more mortgages and more securities, mortgage qualification guidelines became progressively looser. First, \"stated income, verified assets\" (SIVA) loans replaced proof of income with a \"statement\" of it. Then, \"no income, verified assets\" (NIVA) loans eliminated proof of employment requirements. Borrowers needed only to show proof of money in their bank accounts. \"No Income, No Assets\" (NINA) or Ninja loans loans eliminated the need to prove, or even to state any owned assets. All that was required for a mortgage was a credit score.\nTypes of mortgages became more risky as well. The interest-only adjustable-rate mortgage (ARM), allowed the homeowner to pay only the interest (not principal) of the mortgage during an initial \"teaser\" period. Even looser was the \"payment option\" loan, in which the homeowner has the option to make monthly payment that do not even cover the interest for the first two or three year initial period of the loan. Nearly one in 10 mortgage borrowers in 2005 and 2006 took out these \"option ARM\" loans, and an estimated one-third of ARMs originated between 2004 and 2006 had \"teaser\" rates below 4%. After the initial period, monthly payments might double or even triple.\nThe proportion of subprime ARM loans made to people with credit scores high enough to qualify for conventional mortgages with better terms increased from 41% in 2000 to 61% by 2006. In addition, mortgage brokers in some cases received incentives from lenders to offer subprime ARM's even to those with credit ratings that merited a conforming (i.e., non-subprime) loan.\nMortgage underwriting standards declined precipitously during the boom period. The use of automated loan approvals allowed loans to be made without appropriate review and documentation. In 2007, 40% of all subprime loans resulted from automated underwriting. The chairman of the Mortgage Bankers Association claimed that mortgage brokers, while profiting from the home loan boom, did not do enough to examine whether borrowers could repay. Mortgage fraud by lenders and borrowers increased enormously.\nThe Financial Crisis Inquiry Commission reported in January 2011 that many mortgage lenders took eager borrowers\u2019 qualifications on faith, often with a \"willful disregard\" for a borrower\u2019s ability to pay. Nearly 25% of all mortgages made in the first half of 2005 were \"interest-only\" loans. During the same year, 68% of \"option ARM\" loans originated by Countrywide Financial and Washington Mutual had low- or no-documentation requirements.\nAt least one study has suggested that the decline in standards was driven by a shift of mortgage securitization from a tightly controlled duopoly to a competitive market in which mortgage originators held the most sway. The worst mortgage vintage years coincided with the periods during which Government Sponsored Enterprises (specifically Fannie Mae and Freddie Mac) were at their weakest, and mortgage originators and private label securitizers were at their strongest.\nWhy was there a market for these low quality private label securitizations? In a Peabody Award winning program, NPR correspondents argued that a \"Giant Pool of Money\" (represented by $70 trillion in worldwide fixed income investments) sought higher yields than those offered by U.S. Treasury bonds early in the decade. Further, this pool of money had roughly doubled in size from 2000 to 2007, yet the supply of relatively safe, income generating investments had not grown as fast. Investment banks on Wall Street answered this demand with financial innovation such as the mortgage-backed security (MBS) and collateralized debt obligation (CDO), which were assigned safe ratings by the credit rating agencies.\nIn effect, Wall Street connected this pool of money to the mortgage market in the U.S., with enormous fees accruing to those throughout the mortgage supply chain, from the mortgage broker selling the loans, to small banks that funded the brokers, to the giant investment banks behind them. By approximately 2003, the supply of mortgages originated at traditional lending standards had been exhausted. However, continued strong demand for MBS and CDO began to drive down lending standards, as long as mortgages could still be sold along the supply chain. Eventually, this speculative bubble proved unsustainable. NPR described it this way:", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "High-risk mortgage loans and lending/borrowing practices", "_id": "44--1--2--2", "title": "The Boom-Bost Credit Cycle"}
{"qas": [{"question": "What is the difference between a subprime loan and a prime loan?", "answer": ""}, {"question": "What is it called when you default on a subprime loan?", "answer": "foreclosure", "ae_score": -0.21778388121041825, "qg_score": null}, {"question": "The foreclosure crisis in the us in 2007 was caused by a type of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Subprime borrowers typically have weakened credit histories and reduced repayment capacity. Subprime loans have a higher risk of default than loans to prime borrowers. If a borrower is delinquent in making timely mortgage payments to the loan servicer (a bank or other financial firm), the lender may take possession of the property, in a process called foreclosure.\nThe value of American subprime mortgages was estimated at $1.3 trillion as of March 2007, with over 7.5 million first-lien subprime mortgages outstanding. Between 2004 and 2006 the share of subprime mortgages relative to total originations ranged from 18%\u201321%, versus less than 10% in 2001\u20132003 and during 2007. The majority of subprime loans were issued in California. The boom in mortgage lending, including subprime lending, was also driven by a fast expansion of non-bank independent mortgage originators which despite their smaller share (around 25 percent in 2002) in the market have contributed to around 50 percent of the increase in mortgage credit between 2003 and 2005. In the third quarter of 2007, subprime ARMs making up only 6.9% of US mortgages outstanding also accounted for 43% of the foreclosures which began during that quarter.\nBy October 2007, approximately 16% of subprime adjustable-rate mortgages (ARM) were either 90-days delinquent or the lender had begun foreclosure proceedings, roughly triple the rate of 2005. By January 2008, the delinquency rate had risen to 21% and by May 2008 it was 25%.\nAccording to RealtyTrac, the value of all outstanding residential mortgages, owed by U.S. households to purchase residences housing at most four families, was US$9.9 trillion as of year-end 2006, and US$10.6 trillion as of midyear 2008. During 2007, lenders had begun foreclosure proceedings on nearly 1.3 million properties, a 79% increase over 2006. This increased to 2.3 million in 2008, an 81% increase vs. 2007, and again to 2.8 million in 2009, a 21% increase vs. 2008.\nBy August 2008, 9.2% of all U.S. mortgages outstanding were either delinquent or in foreclosure. By September 2009, this had risen to 14.4%.Between August 2007 and October 2008, 936,439 US residences completed foreclosure. Foreclosures are concentrated in particular states both in terms of the number and rate of foreclosure filings. Ten states accounted for 74% of the foreclosure filings during 2008; the top two (California and Florida) represented 41%. Nine states were above the national foreclosure rate average of 1.84% of households.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Subprime mortgage market", "_id": "44--1--2--3", "title": "Subprime Mortgages: The Boom in Mortgage Credit"}
{"qas": [{"question": "Why are there so many reports of mortgage fraud in the US?", "answer": ""}, {"question": "How much money did the subprime mortgage crisis cost?", "answer": "$112 billion", "ae_score": -0.2724843561710138, "qg_score": null}, {"question": "What type of securities are the biggest victims of the subprime crisis?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "\"The FBI defines mortgage fraud as 'the intentional misstatement, misrepresentation, or omission by an applicant or other interest parties, relied on by a lender or underwriter to provide funding for, to purchase, or to insure a mortgage loan.'\" In 2004, the Federal Bureau of Investigation warned of an \"epidemic\" in mortgage fraud, an important credit risk of nonprime mortgage lending, which, they said, could lead to \"a problem that could have as much impact as the S&L crisis\". Despite this, the Bush administration prevented states from investigating and prosecuting predatory lenders by invoking a banking law from 1863 \"to issue formal opinions preempting all state predatory lending laws, thereby rendering them inoperative.\"\nThe Financial Crisis Inquiry Commission reported in January 2011 that: \"... mortgage fraud... flourished in an environment of collapsing lending standards and lax regulation. The number of suspicious activity reports \u2013 reports of possible financial crimes filed by depository banks and their affiliates \u2013 related to mortgage fraud grew 20-fold between 1996 and 2005 and then more than doubled again between 2005 and 2009. One study places the losses resulting from fraud on mortgage loans made between 2005 and 2007 at $112 billion.\n\"Predatory lending describes unfair, deceptive, or fraudulent practices of some lenders during the loan origination process.\"Lenders made loans that they knew borrowers could not afford and that could cause massive losses to investors in mortgage securities.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Mortgage fraud and predatory lending", "_id": "44--1--2--4", "title": "Predatory Lending \u2014 A Problem That Could Have As Much Impact as the S&"}
{"qas": [{"question": "Why did George W. Bush want to bail out the housing market?", "answer": ""}, {"question": "What did the president call the subprime mortgage crisis?", "answer": "malign neglect", "ae_score": -0.06119510780896577, "qg_score": null}, {"question": "What did the president call the subprime mortgage crisis?", "answer": "malign neglect", "ae_score": -0.06119510780896577, "qg_score": null}], "content": "The Financial Crisis Inquiry Commission reported in January 2011:\nIn a June 2008 speech, President of the NY Federal Reserve Bank Timothy Geithner, who later became Secretary of the Treasury, placed significant blame for the freezing of credit markets on a \"run\" on the entities in the \"parallel\" banking system, also called the shadow banking system. These entities became critical to the credit markets underpinning the financial system, but were not subject to the same regulatory controls as depository banks. Further, these entities were vulnerable because they borrowed short-term in liquid markets to purchase long-term, illiquid and risky assets. This meant that disruptions in credit markets would make them subject to rapid deleveraging, selling their long-term assets at depressed prices.\nRepo and other forms of shadow banking accounted for an estimated 60% of the \"overall US banking system,\" according to Paul Krugman,.<ref name=slump/> Geithner described its \"entities\": \n He stated that the \"combined effect of these factors was a financial system vulnerable to self-reinforcing asset price and credit cycles.\"\nNobel laureate economist Paul Krugman described the run on the shadow banking system as the \"core of what happened\" to cause the crisis. \n He referred to this lack of controls as \"malign neglect.\"\nThe securitization markets supported by the shadow banking system started to close down in the spring of 2007 and nearly shut-down in the fall of 2008. More than a third of the private credit markets thus became unavailable as a source of funds. According to the Brookings Institution, the traditional banking system does not have the capital to close this gap as of June 2009: \"It would take a number of years of strong profits to generate sufficient capital to support that additional lending volume.\" The authors also indicate that some forms of securitization are \"likely to vanish forever, having been an artifact of excessively loose credit conditions.\"\nEconomist Gary Gorton wrote in May 2009: \nFed Chair Ben Bernanke stated in an interview with the FCIC during 2009 that 12 of the 13 largest U.S. financial institutions were at risk of failure during 2008. The FCIC report did not identify which of the 13 firms was not considered by Bernanke to be in danger of failure.\nEconomist Mark Zandi testified to the Financial Crisis Inquiry Commission in January 2010:\n''The Economist'' reported in March 2010: \"Bear Stearns and Lehman Brothers were non-banks that were crippled by a silent run among panicky overnight \"repo\" lenders, many of them money market funds uncertain about the quality of securitized collateral they were holding. Mass redemptions from these funds after Lehman's failure froze short-term funding for big firms.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Financial markets", "_id": "44--1--3--0", "title": "The Shadow Banking System"}
{"qas": [{"question": "What is the process used to calculate the probability of a mortgage default?", "answer": ""}, {"question": "What does cdo stand for in securitization?", "answer": "collateralized debt obligation", "ae_score": -0.33291941933952857, "qg_score": null}, {"question": "The subprime crisis of the late 1980s and early 1990s resulted in the collapse?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Securitization \u2013 the bundling of bank loans to create tradeable bonds \u2013 started in the mortgage industry in the 1970s, when Government Sponsored Enterprises (GSEs) began to pool relatively safe, conventional, \"conforming\" or \"prime\" mortgages, create \"mortgage-backed securities\" (MBS) from the pool, sell them to investors, guaranteeing these securities/bonds against default on the underlying mortgages. This \"originate-to-distribute\" model had advantages over the old \"originate-to-hold\" model, where a bank originated a loan to the borrower/homeowner and retained the credit (default) risk. Securitization removed the loans from a bank's books, enabling the bank to remain in compliance with capital requirement laws. More loans could be made with proceeds of the MBS sale. The liquidity of a national and even international mortgage market allowed capital to flow where mortgages were in demand and funding short. However, securitization created a moral hazard \u2013 the bank/institution making the loan no longer had to worry if the mortgage was paid off \u2013 giving them incentive to process mortgage transactions but not to ensure their credit quality. Bankers were no longer around to work out borrower problems and minimize defaults during the course of the mortgage.\nWith the high down payments and credit scores of the conforming mortgages used by GSE, this danger was minimal.Investment banks however, wanted to enter the market and avoid competing with the GSEs. They did so by developing mortgage-backed securities in the riskier non-conforming subprime and Alt-A market. Unlike the GSEs the issuers generally did not guarantee the securities against default of the underlying mortgages.\nWhat these \"private label\" or \"non-agency\" originators did do was to use \"structured finance\" to create securities. Structuring involved \"slicing\" the pooled mortgages into \"tranches\", each having a different priority in the stream of monthly or quarterly principal and interest stream. Tranches were compared to \"buckets\" catching the \"water\" of principle and interest. More senior buckets didn't share water with those below until they were filled to the brim and overflowing. This gave the top buckets/tranches considerable creditworthiness (in theory) that would earn the highest \"triple A\" credit ratings, making them salable to money market and pension funds that would not otherwise deal with subprime mortgage securities.\nTo use up the MBS tranches lower in payback priority that could not be rated triple-A and that a conservative fixed income market would not buy, investment banks developed another security \u2013 known as the collateralized debt obligation (CDO). Although the CDO market was smaller, it was crucial because unless buyers were found for the non-triple-A or \"mezzanine\" tranches, it would not be profitable to make a mortgage-backed security in the first place. These CDOs pooled the leftover BBB, A-, etc. rated tranches, and produced new tranches \u2013 70% to 80% of which were rated triple A by rating agencies. The 20\u201330% remaining mezzanine tranches were sometimes bought up by other CDOs, to make so-called \"CDO-Squared\" securities which also produced tranches rated mostly triple A.\nThis process was later disparaged as \"ratings laundering\" or a way of transforming \"dross into gold\" by some business journalists, but was justified at the time by the belief that home prices would always rise. The model used by underwriters, rating agencies and investors to estimate the probability of mortgage default was based on the history of credit default swaps, which unfortunately went back \"less than a decade, a period when house prices soared\".\nIn addition the model \u2013 which postulated that the correlation of default risks among loans in securitization pools could be measure in a simple, stable, tractable number, suitable for risk management or valuation \u2013 also purported to show that the mortgages in CDO pools were well diversified or \"uncorrelated\". Defaults on mortgages in Orlando, for example, were thought to have no effect on \u2013 i.e. were uncorrelated with \u2013 the real estate market across the country in Laguna Beach. When prices corrected (i.e. the bubble collapsed), the resulting defaults were not only larger in number than predicted but far more correlated.\nStill another innovative security criticized after the bubble burst was the synthetic CDO. Cheaper and easier to create than original \"cash\" CDOs, synthetics did not provide funding for housing, rather synthetic CDO-buying investors were in effect providing insurance (in the form of \"credit default swaps\") against mortgage default. The mortgages they insured were those in \"cash\" CDOs the synthetics \"referenced\". So instead of providing investors with interest and principal payments from MBS tranches, payments were the equivalent of insurance premiums from the insurance \"buyers\". If the referenced CDOs defaulted, investors lost their investment, which was paid out to the insurance buyers.\nUnlike true insurance, credit default swaps were not regulated to insure that providers had the reserves to pay settlements, or that buyers owned the property (MBSs) they were insuring, i.e. were not simply making a bet a security would default. Because synthetics \"referenced\" another (cash) CDO, more than one \u2013 in fact numerous \u2013 synthetics could be made to reference the same original, multiplying the effect if a referenced security defaulted. As with MBS and other CDOs, triple A ratings for \"large chunks\" of synthetics were crucial to the securities' success, because of the buyer/investors' ignorance of the mortgage security market and trust in the credit rating agencies ratings.\nSecuritization began to take off in the mid-1990s. The total amount of mortgage-backed securities issued almost tripled between 1996 and 2007, to $7.3 trillion. The securitized share of subprime mortgages (i.e., those passed to third-party investors via MBS) increased from 54% in 2001, to 75% in 2006. In the mid-2000s as the housing market was peaking, GSE securitization market share declined dramatically, while higher-risk subprime and Alt-A mortgage private label securitization grew sharply. As mortgage defaults began to rise, it was among mortgages securitized by the private banks. GSE mortgages \u2013 securitized or not \u2013 continued to perform better than the rest of the market. Picking up the slack for the dwindling cash CDO market synthetics were the dominant form of CDO's by 2006,<ref name=greatest/> valued \"notionally\" at an estimated $5 trillion.\nBy the autumn of 2008, when the securitization market \"seized up\" and investors would \"no longer lend at any price\", securitized lending made up about $10 trillion of the roughly $25 trillion American credit market, (i.e. what \"American homeowners, consumers, and corporations owed\"). In February 2009, Ben Bernanke stated that securitization markets remained effectively shut, with the exception of conforming mortgages, which could be sold to Fannie Mae and Freddie Mac.\nAccording to economist A. Michael Spence: \"when formerly uncorrelated risks shift and become highly correlated ... diversification models fail.\" \"An important challenge going forward is to better understand these dynamics as the analytical underpinning of an early warning system with respect to financial instability.\"\nCriticizing the argument that complex structured investment securitization was instrumental in the mortgage crisis, Paul Krugman points out that the Wall Street firms issuing the securities \"kept the riskiest assets on their own books\", and that neither of the equally disastrous bubbles in European housing or US commercial property used complex structured securities. Krugman does agree that it is \"arguable is that financial innovation ... spread the bust to financial institutions around the world\" and its inherent fragmentation of loans has made post-bubble \"cleanup\" through debt renegotiation extremely difficult.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Securitization", "_id": "44--1--3--1", "title": "Securitization and the Mortgage Bubble"}
{"qas": [{"question": "What does the new accounting guidance by the Federal Reserve mean for the economy?", "answer": ""}, {"question": "How much money did wall street bankers get in bonuses?", "answer": "$23.9 billion", "ae_score": -0.3023551203042516, "qg_score": null}, {"question": "The subprime crisis in the late 2000s was caused by a lack of understanding of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The Financial Crisis Inquiry Commission reported in January 2011 that: \"From 1978 to 2007, the amount of debt held by the financial sector soared from $3 trillion to $36 trillion, more than doubling as a share of gross domestic product. The very nature of many Wall Street firms changed \u2013 from relatively staid private partnerships to publicly traded corporations taking greater and more diverse kinds of risks. By 2005, the 10 largest U.S. commercial banks held 55% of the industry\u2019s assets, more than double the level held in 1990. On the eve of the crisis in 2006, financial sector profits constituted 27% of all corporate profits in the United States, up from 15% in 1980.\"\nMany financial institutions, investment banks in particular, issued large amounts of debt during 2004\u201307, and invested the proceeds in mortgage-backed securities (MBS), essentially betting that house prices would continue to rise, and that households would continue to make their mortgage payments. Borrowing at a lower interest rate and investing the proceeds at a higher interest rate is a form of financial leverage. This is analogous to an individual taking out a second mortgage on his residence to invest in the stock market. This strategy proved profitable during the housing boom, but resulted in large losses when house prices began to decline and mortgages began to default. Beginning in 2007, financial institutions and individual investors holding MBS also suffered significant losses from mortgage payment defaults and the resulting decline in the value of MBS.\nA 2004 U.S. Securities and Exchange Commission (SEC) decision related to the net capital rule allowed US investment banks to issue substantially more debt, which was then used to purchase MBS. Over 2004\u201307, the top five US investment banks each significantly increased their financial leverage (see diagram), which increased their vulnerability to the declining value of MBSs. These five institutions reported over $4.1 trillion in debt for fiscal year 2007, about 30% of US nominal GDP for 2007. Further, the percentage of subprime mortgages originated to total originations increased from below 10% in 2001\u201303 to between 18\u201320% from 2004 to 2006, due in-part to financing from investment banks.\nDuring 2008, three of the largest U.S. investment banks either went bankrupt (Lehman Brothers) or were sold at fire sale prices to other banks (Bear Stearns and Merrill Lynch). These failures augmented the instability in the global financial system. The remaining two investment banks, Morgan Stanley and Goldman Sachs, opted to become commercial banks, thereby subjecting themselves to more stringent regulation.\nIn the years leading up to the crisis, the top four U.S. depository banks moved an estimated $5.2 trillion in assets and liabilities off-balance sheet into special purpose vehicles or other entities in the shadow banking system. This enabled them to essentially bypass existing regulations regarding minimum capital ratios, thereby increasing leverage and profits during the boom but increasing losses during the crisis. New accounting guidance will require them to put some of these assets back onto their books during 2009, which will significantly reduce their capital ratios. One news agency estimated this amount to be between $500 billion and $1 trillion. This effect was considered as part of the stress tests performed by the government during 2009.\nMartin Wolf wrote in June 2009: \"...an enormous part of what banks did in the early part of this decade \u2013 the off-balance-sheet vehicles, the derivatives and the 'shadow banking system' itself \u2013 was to find a way round regulation.\"\nThe New York State Comptroller's Office has said that in 2006, Wall Street executives took home bonuses totaling $23.9 billion. \"Wall Street traders were thinking of the bonus at the end of the year, not the long-term health of their firm. The whole system \u2013 from mortgage brokers to Wall Street risk managers \u2013 seemed tilted toward taking short-term risks while ignoring long-term obligations. The most damning evidence is that most of the people at the top of the banks didn't really understand how those [investments] worked.\"\nThe incentive compensation of traders was focused on fees generated from assembling financial products, rather than the performance of those products and profits generated over time. Their bonuses were heavily skewed towards cash rather than stock and not subject to \"claw-back\" (recovery of the bonus from the employee by the firm) in the event the MBS or CDO created did not perform. In addition, the increased risk (in the form of financial leverage) taken by the major investment banks was not adequately factored into the compensation of senior executives.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Financial institution debt levels and incentives", "_id": "44--1--3--2", "title": "The Financial Crisis and the Shadow Banks"}
{"qas": [{"question": "What did Goldman Sachs do to cause the 2008 financial crisis?", "answer": ""}, {"question": "Who was involved in the subprime mortgage crisis?", "answer": "Magnetar Capital", "ae_score": -0.28534542576850397, "qg_score": null}, {"question": "What type of credit default swaps were used to hedge against the risk of default?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Credit default swaps (CDS) are financial instruments used as a hedge and protection for debtholders, in particular MBS investors, from the risk of default, or by speculators to profit from default. As the net worth of banks and other financial institutions deteriorated because of losses related to subprime mortgages, the likelihood increased that those providing the protection would have to pay their counterparties. This created uncertainty across the system, as investors wondered which companies would be required to pay to cover mortgage defaults.\nLike all swaps and other financial derivatives, CDS may either be used to hedge risks (specifically, to insure creditors against default) or to profit from speculation. The volume of CDS outstanding increased 100-fold from 1998 to 2008, with estimates of the debt covered by CDS contracts, as of November 2008, ranging from US$33 to $47 trillion. CDS are lightly regulated, largely because of the Commodity Futures Modernization Act of 2000. As of 2008, there was no central clearing house to honor CDS in the event a party to a CDS proved unable to perform his obligations under the CDS contract. Required disclosure of CDS-related obligations has been criticized as inadequate. Insurance companies such as American International Group (AIG), MBIA, and Ambac faced ratings downgrades because widespread mortgage defaults increased their potential exposure to CDS losses. These firms had to obtain additional funds (capital) to offset this exposure. AIG's having CDSs insuring $440 billion of MBS resulted in its seeking and obtaining a Federal government bailout. The monoline insurance companies went out of business in 2008\u20132009.\nWhen investment bank Lehman Brothers went bankrupt in September 2008, there was much uncertainty as to which financial firms would be required to honor the CDS contracts on its $600 billion of bonds outstanding.Merrill Lynch's large losses in 2008 were attributed in part to the drop in value of its unhedged portfolio of collateralized debt obligations (CDOs) after AIG ceased offering CDS on Merrill's CDOs. The loss of confidence of trading partners in Merrill Lynch's solvency and its ability to refinance its short-term debt led to its acquisition by the Bank of America.\nEconomist Joseph Stiglitz summarized how credit default swaps contributed to the systemic meltdown: \"With this complicated intertwining of bets of great magnitude, no one could be sure of the financial position of anyone else-or even of one's own position. Not surprisingly, the credit markets froze.\"\nAuthor Michael Lewis wrote that CDS enabled speculators to stack bets on the same mortgage bonds and CDO's. This is analogous to allowing many persons to buy insurance on the same house. Speculators that bought CDS insurance were betting that significant defaults would occur, while the sellers (such as AIG) bet they would not. A theoretically infinite amount could be wagered on the same housing-related securities, provided buyers and sellers of the CDS could be found.\nDerivatives such as CDS were unregulated or barely regulated. Several sources have noted the failure of the US government to supervise or even require transparency of the financial instruments known as derivatives.<ref name=devils/><ref name=faiola/>A 2008 investigative article in the Washington Post found that leading government officials at the time (Federal Reserve Board Chairman  Alan Greenspan, Treasury Secretary Robert Rubin, and SEC Chairman Arthur Levitt)  vehemently opposed any regulation of derivatives. In 1998 Brooksley E. Born, head of the Commodity Futures Trading Commission, put forth a policy paper asking for feedback from regulators, lobbyists, legislators on the question of whether derivatives should be reported, sold through a central facility, or whether capital requirements should be required of their buyers. Greenspan, Rubin, and Levitt pressured her to withdraw the paper and Greenspan persuaded Congress to pass a resolution preventing CFTC from regulating derivatives for another six months \u2014 when Born's term of office would expire. Ultimately, it was the collapse of a specific kind of derivative, the mortgage-backed security, that triggered the economic crisis of 2008.\nIn addition, Chicago Public Radio, Huffington Post, and ProPublica reported in April 2010 that market participants, including a hedge fund called Magnetar Capital, encouraged the creation of CDO's containing low quality mortgages, so they could bet against them using CDS. NPR reported that Magnetar encouraged investors to purchase CDO's while simultaneously betting against them, without disclosing the latter bet. Instruments called synthetic CDO, which are portfolios of credit default swaps, were also involved in allegations by the SEC against Goldman-Sachs in April 2010.\nThe Financial Crisis Inquiry Commission reported in January 2011 that CDS contributed significantly to the crisis. Companies were able to sell protection to investors against the default of mortgage-backed securities, helping to launch and expand the market for new, complex instruments such as CDO's. This further fueled the housing bubble. They also amplified the losses from the collapse of the housing bubble by allowing multiple bets on the same securities and helped spread these bets throughout the financial system. Companies selling protection, such as AIG, were not required to set aside sufficient capital to cover their obligations when significant defaults occurred. Because many CDS were not traded on exchanges, the obligations of key financial institutions became hard to measure, creating uncertainty in the financial system.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Credit default swaps", "_id": "44--1--3--3", "title": "Credit-Default Swaps and the Housing Bubble"}
{"qas": [{"question": "Why are credit rating agencies such as Moody's, Standard & Poor's, and Fitch rated so poorly?", "answer": ""}, {"question": "How much money did banks lose in the subprime mortgage crisis?", "answer": "$523 billion", "ae_score": -0.294156729757987, "qg_score": null}, {"question": "The 2007 financial crisis was caused by the misreporting of the ratings of what type of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Credit rating agencies \u2013 firms which rate debt instruments/securities according to the debtor's ability to pay lenders back \u2013 have come under scrutiny during and after the financial crisis for having given investment-grade ratings to MBSs and CDOs based on risky subprime mortgage loans that later defaulted. Dozens of lawsuits have been filed by investors against the \"Big Three\" rating agencies \u2013 Moody's Investors Service, Standard & Poor's, and Fitch Ratings. The Financial Crisis Inquiry Commission (FCIC) concluded the \"failures\" of the Big Three rating agencies were \"essential cogs in the wheel of financial destruction\" and \"key enablers of the financial meltdown\".Economist Joseph Stiglitz called them \"one of the key culprits\" of the financial crisis. Others called their ratings \"catastrophically misleading\", (the U.S. Securities and Exchange Commissioner), their performance \"horrendous\" (''The Economist'' magazine). There are indications that some involved in rating subprime-related securities knew at the time that the rating process was faulty.\nThe position of the three agencies \"between the issuers and the investors of securities\" \"transformed\" them into \"key\" players in the housing bubble and financial crisis according to the ''Financial Crisis Inquiry Report''. Most investors in the fixed income market had no experience with the mortgage business \u2013 let alone dealing with the complexity of pools of mortgages and tranche priority of MBS and CDO securities \u2013 and were simply looking for an independent party who could rate securities. The putatively independent parties meanwhile were paid \"handsome fees\" by investment banks \"to obtain the desired ratings\", according to one expert.\nIn addition, a large section of the debt securities market \u2013 many money markets and pension funds \u2013 were restricted in their bylaws to holding only the safest securities \u2013 i.e securities the rating agencies designated \"triple-A\". Hence non-prime securities could not be sold without ratings by (usually two of) the three agencies.\nFrom 2000 to 2007, one of the largest agencies \u2013 Moody's \u2013 rated nearly 45,000 mortgage-related securities<ref name=nber/> \u2013 more than half of those it rated \u2013 as triple-A. By December 2008, there were over $11 trillion structured finance securities outstanding in the U.S. bond market debt. But as the boom matured, mortgage underwriting standards deteriorated. By 2007 an estimated $3.2 trillion in loans were made to homebuyers and owners with bad credit and undocumented incomes, bundled into MBSs and CDOs, and given top ratings<ref name=loose/> to appeal to global investors.\nAs these mortgages began to default, the three agencies were compelled to go back and redo their ratings. Between autumn of 2007 and the middle of 2008, agencies downgraded nearly $2 trillion in MBS tranches. By the end of 2008, 80% of the CDOs by value rated \"triple-A\" were downgraded to junk. Bank writedowns and losses on these investments totaled $523 billion.\nCritics such as the Financial Crisis Inquiry Commission argue the mistaken credit ratings stemmed from \"flawed computer models, the pressure from financial firms that paid for the ratings, the relentless drive for market share, the lack of resources to do the job despite record profits, and the absence of meaningful public oversight\".\nStructured investment was very profitable to the agencies and by 2007 accounted for just under half of Moody's total ratings revenue and all of the revenue growth. But profits were not guaranteed, and issuers played the agencies off one another, 'shopping' around to find the best ratings, sometimes openly threatening to cut off business after insufficiently generous ratings. Thus there was a conflict of interest between accommodating clients \u2013 for whom higher ratings meant higher earnings \u2013 and accurately rating the debt for the benefit of the debt buyer/investors \u2013 who provided zero revenue to the agencies.\nDespite the profitability of the three big credit agencies \u2013 Moody's operating margins were consistently over 50%, higher than famously successful Exxon Mobil or Microsoft \u2013 salaries and bonuses for non-management were significantly lower than at Wall Street banks, and its employees complained of overwork.\nThis incentivized agency rating analysts to seek employment at those Wall Street banks who were issuing mortgage securities, and who were particularly interested in the analysts' knowledge of what criteria their former employers used to rate securities.Inside knowledge of interest to security issuers eager to find loopholes included the fact that rating agencies looked at the ''average'' credit score of a pool of borrowers, but not how dispersed it was; that agencies ignored borrower's household income or length of credit history (explaining the large numbers of low income immigrants given mortgages\u2014people \"who had never failed to repay a debt, because they had never been given a loan\"); that agencies were indifferent to credit worthiness issues of adjustable-rate mortgages with low teaser rates, \"silent second\" mortgages, or no-documentation mortgages.\nAs of 2010, virtually all of the investigations of rating agencies, criminal as well as civil, are in their early stages. In New York, state prosecutors are examining whether eight banks duped the credit ratings agencies into inflating the grades of subprime-linked investments. In the dozens of suits filed against them by investors involving claims of inaccurate ratings<ref name=dozens/> the rating agencies have defended themselves using the First Amendment defense\u2014that a credit rating is an opinion protected as free speech. In 2013, McClatchy Newspapers found that \"little competition has emerged\" since the Credit Rating Agency Reform Act of 2006 was passed \"in rating the kinds of complex home-mortgage securities whose implosion led to the 2007 financial crisis\". The Big Three's market share of outstanding credit rating has barely shrunk, moving from 98% to 97%.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Inaccurate credit ratings", "_id": "44--1--3--4", "title": "The Big Three Credit Rating Agencies and the Financial Crisis"}
{"qas": [{"question": "What were the steps taken to prevent the collapse of major banks during the financial crisis?", "answer": ""}, {"question": "What type of swaps were involved in the subprime mortgage crisis?", "answer": "credit default swaps", "ae_score": -0.39141462727491433, "qg_score": null}, {"question": "What type of mortgage crisis was caused by changes in capital reserve calculation rules?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "Several steps were taken to reduce the regulation applied to banking institutions in the years leading up to the crisis. Further, major investment banks which collapsed during the crisis were not subject to the regulations applied to depository banks. In testimony before Congress both the Securities and Exchange Commission (SEC) and Alan Greenspan claimed failure in allowing the self-regulation of investment banks.\nIn 1982, Congress passed the Alternative Mortgage Transactions Parity Act (AMTPA), which allowed non-federally chartered housing creditors to write adjustable-rate mortgages. This bi-partisan legislation was, according to the Urban Institute, intended to \"increase the volume of loan products that reduced the up-front costs to borrowers in order to make homeownership more affordable.\" Among the new mortgage loan types created and gaining in popularity in the early 1980s were adjustable-rate, option adjustable-rate, balloon-payment and interest-only mortgages. Subsequent widespread abuses of predatory lending occurred with the use of adjustable-rate mortgages. Approximately 90% of subprime mortgages issued in 2006 were adjustable-rate mortgages.\nThe Glass-Steagall Act was enacted after the Great Depression. It separated commercial banks and investment banks, in part to avoid potential conflicts of interest between the lending activities of the former and rating activities of the latter. In 1999 Glass-Steagall was repealed by the Gramm-Leach-Bliley Act. Economist Joseph Stiglitz criticized the repeal of Glass Steagall because, in his opinion, it enabled the risk-taking culture of investment banking to dominate the more conservative commercial banking culture, leading to increased levels of risk-taking and leverage during the boom period. President Bill Clinton, who signed the legislation, dismissed its connection to the subprime mortgage crisis, stating (in 2008): \"I don't see that signing that bill had anything to do with the current crisis.\"\nThe Commodity Futures Modernization Act of 2000 was bi-partisan legislation that formally exempted derivatives from regulation, supervision, trading on established exchanges, and capital reserve requirements for major participants. It \"provided a legal safe harbor for treatment already in effect.\" Concerns that counterparties to derivative deals would be unable to pay their obligations caused pervasive uncertainty during the crisis. Particularly relevant to the crisis are credit default swaps (CDS), a derivative in which Party A pays Party B what is essentially an insurance premium, in exchange for payment should Party C default on its obligations. Warren Buffett famously referred to derivatives as \"financial weapons of mass destruction\" in early 2003.\nSome analysts believe the subprime mortgage crisis was due, in part, to a 2004 decision of the SEC that affected 5 large investment banks. The critics believe that changes in the capital reserve calculation rules enabled investment banks to substantially increase the level of debt they were taking on, fueling the growth in mortgage-backed securities supporting subprime mortgages. These banks dramatically increased their risk taking from 2003 to 2007. By the end of 2007, the largest five U.S. investment banks had over $4 trillion in debt with high ratios of debt to equity, meaning only a small decline in the value of their assets would render them insolvent. However, in an April 9, 2009 speech, Erik Sirri, then Director of the SEC's Division of Trading and Markets, argued that the regulatory weaknesses in leverage restrictions originated in the late 1970s: \"The Commission did not undo any leverage restrictions in 2004,\" nor did it intend to make a substantial reduction.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Governmental policies", "_id": "44--1--4--0", "title": "The Subprime Mortgage Crisis and the SEC"}
{"qas": [{"question": "Why did the government bail out the housing market during the 2008 financial crisis?", "answer": ""}, {"question": "Who compiled the national home ownership strategy?", "answer": "Henry Cisneros", "ae_score": -0.14043652373639087, "qg_score": null}, {"question": "The subprime crisis in the 1990s was caused by amendments to the cra act?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Several administrations, both Democratic and Republican, advocated affordable housing policies in the years leading up to the crisis. The Housing and Community Development Act of 1992 established, for the first time, an affordable housing loan purchase mandate for Fannie Mae and Freddie Mac, a mandate to be regulated by the Department of Housing and Urban Development (HUD). Initially, the 1992 legislation required that 30 percent or more of Fannie\u2019s and Freddie\u2019s loan purchases be related to affordable housing. However, HUD was given the power to set future requirements, and eventually (under the Bush Administration) a 56 percent minimum was established. To fulfill the requirements, Fannie Mae and Freddie Mac established programs to purchase $5 trillion in affordable housing loans, and encouraged lenders to relax underwriting standards to produce those loans.\n\"The National Homeownership Strategy: Partners in the American Dream\", was compiled in 1995 by Henry Cisneros, President Clinton\u2019s HUD Secretary. This 100-page document represented the viewpoints of HUD, Fannie Mae, Freddie Mac, leaders of the housing industry, various banks, numerous activist organizations such as ACORN and La Raza, and representatives from several state and local governments.\" In 2001, the independent research company, Graham Fisher & Company, stated: \"While the underlying initiatives of the [strategy] were broad in content, the main theme \u2026 was the relaxation of credit standards.\"\nThe Financial Crisis Inquiry Commission (majority report), Federal Reserve economists, and several academic researchers have stated that government affordable housing policies were not the major cause of the financial crisis. They also state that Community Reinvestment Act loans outperformed other \"subprime\" mortgages, and GSE mortgages performed better than private label securitizations.\nThe Community Reinvestment Act (CRA) was originally enacted under President Jimmy Carter in 1977 in an effort to encourage banks to halt the practice of lending discrimination. In 1995 the Clinton Administration issued regulations that added numerical guidelines, urged lending flexibility, and instructed bank examiners to evaluate a bank\u2019s responsiveness to community activists (such as ACORN) when deciding whether to approve bank merger or expansion requests. Critics claim that the 1995 changes to CRA signaled to banks that relaxed lending standards were appropriate and could minimize potential risk of governmental sanctions.\nConservatives and libertarians have debated the possible effects of the CRA, with detractors claiming that the Act encouraged lending to uncreditworthy borrowers, and defenders claiming a thirty-year history of lending without increased risk. Detractors also claim that amendments to the CRA in the mid-1990s, raised the amount of mortgages issued to otherwise unqualified low-income borrowers, and allowed the securitization of CRA-regulated mortgages, even though a fair number of them were subprime.\nIn its \"Conclusions\" submitted January 2011, the Financial Crisis Inquiry Commission reported that\n Critics claim that the use of the high-interest-rate proxy distorts results because government programs generally promote low-interest rate loans\u2014even when the loans are to borrowers who are clearly subprime. However, several economists maintain that Community Reinvestment Act loans outperformed other \"subprime\" mortgages, and GSE mortgages performed better than private label securitizations.\nHowever, economists at the National Bureau of Economic Research concluded that banks undergoing CRA-related regulatory exams took additional mortgage lending risk. The authors of a study entitled \"Did the Community Reinvestment Act Lead to Risky Lending?\" compared \"the lending behavior of banks undergoing CRA exams within a given census tract in a given month (the treatment group) to the behavior of banks operating in the same census tract-month that did not face these exams (the control group). This comparison clearly indicates that adherence to the CRA led to riskier lending by banks.\" They concluded: \"The evidence shows that around CRA examinations, when incentives to conform to CRA standards are particularly high, banks not only increase lending rates but also appear to originate loans that are markedly riskier.\" Loan delinquency averaged 15% higher in the treatment group than the control group one year after mortgage origination.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Policies to promote affordable housing", "_id": "44--1--4--1", "title": "The Community Reinvestment Act and the Financial Crisis"}
{"qas": [{"question": "What is a Neighborhood Reinvestment Corporation?", "answer": ""}, {"question": "When did the subprime mortgage crisis start?", "answer": "1995", "ae_score": -0.8230043201134541, "qg_score": null}, {"question": "What is the name of the subprime mortgage crisis?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "As part of the 1995 National Homeownership Strategy, HUD advocated greater involvement of state and local organizations in the promotion of affordable housing. In addition, it promoted the use of low or no-down payment loans and second, unsecured loans to the borrower to pay their down payments (if any) and closing costs. This idea manifested itself in \"silent second\" loans that became popular in several states such as California, and in scores of cities such as San Francisco. Using federal funds and their own funds, these states and cities offered borrowers loans that would defray the cost of the down payment. The loans were called \"silent\" because the primary lender was not supposed to know about them. A Neighborhood Reinvestment Corporation (affiliated with HUD) publicity sheet explicitly described the desired secrecy: \"[The NRC affiliates] hold the second mortgages. Instead of going to the family, the monthly voucher is paid to [the NRC affiliates]. In this way the voucher is \"invisible\" to the traditional lender and the family (emphasis added).", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "State and local governmental programs", "_id": "44--1--4--2", "title": "Silent Second Loans"}
{"qas": [{"question": "What is the difference between Fannie Mae and Freddie Mac?", "answer": ""}, {"question": "How much money did central banks buy in the last quarter of 2008?", "answer": "US$2.5 trillion", "ae_score": -0.5457633556027129, "qg_score": null}, {"question": "Fannie mae and freddie mac are government sponsored enterprises (gse)?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Fannie Mae and Freddie Mac are government sponsored enterprises (GSE) that purchase mortgages, buy and sell mortgage-backed securities (MBS), and guarantee nearly half of the mortgages in the U.S. A variety of political and competitive pressures resulted in the GSEs ramping up their purchase and guarantee of risky mortgages in 2005 and 2006, justas the housing market was peaking. Fannie and Freddie were both under political pressure to expand purchases of higher-risk affordable housing mortgage types, and under significant competitive pressure from large investment banks and mortgage lenders.\nIn a nine-day period from Oct. 1\u20139, the S&P 500 fell a staggering 251 points, losing 21.6% of its value. The week of Oct. 6\u201310 saw the largest percentage drop in the history of the Dow Jones Industrial Average \u2013 even worse than any single week in the Great Depression.\nThe response of the US Federal Reserve, the European Central Bank, and other central banks was dramatic. During the last quarter of 2008, these central banks purchased US$2.5 trillion of government debt and troubled private assets from banks. This was the largest liquidity injection into the credit market, and the largest monetary policy action, in world history. The governments of European nations and the US also raised the capital of their national banking systems by $1.5 trillion, by purchasing newly issued preferred stock in their major banks. On Dec. 16, 2008, the Federal Reserve cut the Federal funds rate to 0\u20130.25%, where it remained until December 2015; this period of zero interest-rate policy was unprecedented in U.S. history.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Causes", "sub_heading": "Role of Fannie Mae and Freddie Mac", "_id": "44--1--5---1", "title": "The Great Depression: A Brief History of the US Federal Reserve"}
{"qas": [{"question": "What happened to the US economy in 2008?", "answer": ""}, {"question": "How many cars were sold in the us during the subprime mortgage crisis?", "answer": "12 million", "ae_score": -0.33356471628716744, "qg_score": null}, {"question": "The subprime crisis in the us was caused by the default rate of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Between June 2007 and November 2008, Americans lost more than a quarter of their net worth. By early November 2008, a broad U.S. stock index, the S&P 500, was down 45 percent from its 2007 high. Housing prices had dropped 20% from their 2006 peak, with futures markets signaling a 30\u201335% potential drop. Total home equity in the United States, which was valued at $13 trillion at its peak in 2006, had dropped to $8.8 trillion by mid-2008 and was still falling in late 2008. Total retirement assets, Americans' second-largest household asset, dropped by 22 percent, from $10.3 trillion in 2006 to $8 trillion in mid-2008. During the same period, savings and investment assets (apart from retirement savings) lost $1.2 trillion and pension assets lost $1.3 trillion. Taken together, these losses total $8.3 trillion.\nMembers of US minority groups received a disproportionate number of subprime mortgages, and so have experienced a disproportionate level of the resulting foreclosures. Recent research shows that complex mortgages were chosen by prime borrowers with high income levels seeking to purchase expensive houses relative to their incomes. Borrowers with complex mortgages experienced substantially higher default rates than borrowers with traditional mortgages with similar characteristics. The crisis had a devastating effect on the U.S. auto industry. New vehicle sales, which peaked at 17 million in 2005, recovered to only 12 million by 2010.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Impacts", "sub_heading": "Impacts", "_id": "44--2--0---1", "title": "The U.S. Housing Crisis and the U.S. Consumer Price Index"}
{"qas": [{"question": "How did the European Union manage to reduce its budget deficit so quickly?", "answer": ""}, {"question": "What was the debt to gdp ratio in 2008?", "answer": "70.1%", "ae_score": -0.5046981832271331, "qg_score": null}, {"question": "What was the debt to gdp ratio in 2008?", "answer": "70.1%", "ae_score": -0.5046981832271331, "qg_score": null}], "content": "The crisis in Europe generally progressed from banking system crises to sovereign debt crises, as many countries elected to bail out their banking systems using taxpayer money. Greece was different in that it concealed large public debts in addition to issues within its banking system. Several countries received bailout packages from the \"troika\" (European Commission, European Central Bank, International Monetary Fund), which also implemented a series of emergency measures.\nMany European countries embarked on austerity programs, reducing their budget deficits relative to GDP from 2010 to 2011. For example, according to the ''CIA World Factbook'' Greece improved its budget deficit from 10.4% GDP in 2010 to 9.6% in 2011. Iceland, Italy, Ireland, Portugal, France, and Spain also improved their budget deficits from 2010 to 2011 relative to GDP.\nHowever, with the exception of Germany, each of these countries had public-debt-to-GDP ratios that increased (i.e., worsened) from 2010 to 2011, as indicated in the chart shown here. Greece's public-debt-to-GDP ratio increased from 143% in 2010 to 165% in 2011. This indicates that despite improving budget deficits, GDP growth was not sufficient to support a decline (improvement) in the debt-to-GDP ratio for these countries during this period. Eurostat reported that the debt to GDP ratio for the 17 Euro area countries together was 70.1% in 2008, 79.9% in 2009, 85.3% in 2010, and 87.2% in 2011.\nUnemployment is another variable that might be considered in evaluating austerity measures. According to the ''CIA World Factbook'', from 2010 to 2011, the unemployment rates in Spain, Greece, Ireland, Portugal, and the UK increased. France and Italy had no significant changes, while in Germany and Iceland the unemployment rate declined. Eurostat reported that Eurozone unemployment reached record levels in September 2012 at 11.6%, up from 10.3% the prior year. Unemployment varied significantly by country.\nEconomist Martin Wolf analyzed the relationship between cumulative GDP growth from 2008 to 2012 and total reduction in budget deficits due to austerity policies (see chart) in several European countries during April 2012. He concluded that: \"In all, there is no evidence here that large fiscal contractions [budget deficit reductions] bring benefits to confidence and growth that offset the direct effects of the contractions. They bring exactly what one would expect: small contractions bring recessions and big contractions bring depressions.\" Changes in budget balances (deficits or surpluses) explained approximately 53% of the change in GDP, according to the equation derived from the IMF data used in his analysis.\nEconomist Paul Krugman analyzed the relationship between GDP and reduction in budget deficits for several European countries in April 2012 and concluded that austerity was slowing growth, similar to Martin Wolf. He also wrote: \"this also implies that 1 euro of austerity yields only about 0.4 euros of reduced deficit, even in the short run. No wonder, then, that the whole austerity enterprise is spiraling into disaster.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Impacts", "sub_heading": "Impact on Europe", "_id": "44--2--1---1", "title": "Greece's Austerity Crisis"}
{"qas": [{"question": "What are the effects of the Fed cutting interest rates on the economy?", "answer": ""}, {"question": "How many jobs were lost during the subprime mortgage crisis?", "answer": "8.5 million", "ae_score": -0.3410645948052008, "qg_score": null}, {"question": "The subprime crisis in the us was caused by a lack of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The crisis had a significant and long-lasting impact on U.S. employment. During the Great Recession, 8.5 million jobs were lost from the peak employment in early 2008 of approximately 138 million to the trough in February 2010 of 129 million, roughly 6% of the workforce. From February 2010 to September 2012, approximately 4.3 million jobs were added, offsetting roughly half the losses.\nIn Spring 2011 there were about a million homes in foreclosure in the United States, several million more in the pipeline, and 872,000 previously foreclosed homes in the hands of banks. Sales were slow; economists estimated that it would take three years to clear the backlogged inventory. According to Mark Zandi of Moody's Analytics, home prices were falling and could be expected to fall further during 2011. However, the rate of new borrowers falling behind in mortgage payments had begun to decrease.\nThe ''New York Times'' reported in January 2015 that: \"About 17% of all homeowners are still 'upside down' on their mortgages ... That\u2019s down from 21% in the third quarter of 2013, and the 2012 peak of 31%.\" Foreclosures as of October 2014 were down 26% from the prior year, at 41,000 completed foreclosures. That was 65% below the peak in September 2010 (roughly 117,000), but still above the pre-crisis (2000-2006) average of 21,000 per month.\nResearch indicates recovery from financial crises can be protracted, with lengthy periods of high unemployment and substandard economic growth. Economist Carmen Reinhart stated in August 2011: \"Debt de-leveraging [reduction] takes about seven years ... And in the decade following severe financial crises, you tend to grow by 1 to 1.5 percentage points less than in the decade before, because the decade before was fueled by a boom in private borrowing, and not all of that growth was real. The unemployment figures in advanced economies after falls are also very dark. Unemployment remains anchored about five percentage points above what it was in the decade before.\"\nDuring the crisis and ensuing recession, U.S. consumers increased their savings as they paid down debt (\"deleveraged\") but corporations simultaneously were reducing their investment. In a healthy economy, private sector savings placed into the banking system is borrowed and invested by companies. This investment is one of the major components of GDP. A private sector financial deficit from 2004 to 2008 transitioned to a large surplus of savings over investment that exceeded $1 trillion by early 2009 and remained above $800 billion as of September 2012. Part of this investment reduction related to the housing market, a major component of investment in the GDP computation. This surplus explains how even significant government deficit spending would not increase interest rates and how Federal Reserve action to increase the money supply does not result in inflation, because the economy is awash with savings with no place to go.\nEconomist Richard Koo described similar effects for several of the developed world economies in December 2011: \"Today private sectors in the U.S., the U.K., Spain, and Ireland (but not Greece) are undergoing massive deleveraging [paying down debt rather than spending] in spite of record low interest rates. This means these countries are all in serious balance sheet recessions. The private sectors in Japan and Germany are not borrowing, either. With borrowers disappearing and banks reluctant to lend, it is no wonder that, after nearly three years of record low interest rates and massive liquidity injections, industrial economies are still doing so poorly. Flow of funds data for the U.S. show a massive shift away from borrowing to savings by the private sector since the housing bubble burst in 2007. The shift for the private sector as a whole represents over 9 percent of U.S. GDP at a time of zero interest rates. Moreover, this increase in private sector savings exceeds the increase in government borrowings (5.8 percent of GDP), which suggests that the government is not doing enough to offset private sector deleveraging.\"\nEconomist Martin Wolf explained in July 2012 that government fiscal balance is one of three major financial sectoral balances in the U.S. economy, the others being the foreign financial sector and the private financial sector. The sum of the surpluses or deficits across these three sectors must be zero by definition. In the U.S., a foreign financial surplus (or capital surplus) exists because capital is imported (net) to fund the trade deficit. Further, there is a private sector financial surplus due to household savings exceeding business investment. By definition, there must therefore exist a government budget deficit so all three net to zero. The government sector includes federal, state and local. For example, the government budget deficit in 2011 was approximately 10% GDP (8.6% GDP of which was federal), offsetting a capital surplus of 4% GDP and a private sector surplus of 6% GDP.\nWolf argued that the sudden shift in the private sector from deficit to surplus forced the government balance into deficit, writing: \"The financial balance of the private sector shifted towards surplus by the almost unbelievable cumulative total of 11.2 per cent of gross domestic product between the third quarter of 2007 and the second quarter of 2009, which was when the financial deficit of US government (federal and state) reached its peak...No fiscal policy changes explain the collapse into massive fiscal deficit between 2007 and 2009, because there was none of any importance. The collapse is explained by the massive shift of the private sector from financial deficit into surplus or, in other words, from boom to bust.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Impacts", "sub_heading": "Sustained effects", "_id": "44--2--2---1", "title": "Why the U.S. Economy Is Still Doing So Poorly"}
{"qas": [{"question": "What does it mean when the Federal Reserve \"expands its balance sheet\"?", "answer": ""}, {"question": "Who was responsible for the subprime mortgage crisis?", "answer": "The Federal Reserve Bank", "ae_score": -0.02073160612705881, "qg_score": null}, {"question": "Where did the subprime mortgage crisis take place?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The central bank of the US, the Federal Reserve, in partnership with central banks around the world, took several steps to address the crisis. Federal Reserve Chairman Ben Bernanke stated in early 2008: \"Broadly, the Federal Reserve's response followed two tracks: efforts to support market liquidity and functioning and the pursuit of our macroeconomic objectives through monetary policy.\"\nThe Federal Reserve Bank:\nAccording to Ben Bernanke, expansion of the Fed balance sheet means the Fed is electronically creating money, necessary \"... because our economy is very weak and inflation is very low. When the economy begins to recover, that will be the time that we need to unwind those programs, raise interest rates, reduce the money supply, and make sure that we have a recovery that does not involve inflation.\"\nThe ''New York Times'' reported in February 2013 that the Fed continued to support the economy with various monetary stimulus measures: \"The Fed, which has amassed almost $3 trillion in Treasury and mortgage-backed securities to promote more borrowing and lending, is expanding those holdings by $85 billion a month until it sees clear improvement in the labor market. It plans to hold short-term interest rates near zero even longer, at least until the unemployment rate falls below 6.5 percent.\"", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Responses", "sub_heading": "Responses", "_id": "44--3--0---1", "title": "The Federal Reserve's response to the economic crisis"}
{"qas": [{"question": "What is the \"Obama Housing Plan\" and how does it work?", "answer": ""}, {"question": "How much money did the stimulus package give to the housing market?", "answer": "$168 billion", "ae_score": -0.3235607170038674, "qg_score": null}, {"question": "How much money did the stimulus package give to the housing market?", "answer": "$168 billion", "ae_score": -0.3235607170038674, "qg_score": null}], "content": "On 13 February 2008, President George W. Bush signed into law a $168 billion economic stimulus package, mainly taking the form of income tax rebate checks mailed directly to taxpayers. Checks were mailed starting the week of 28 April 2008. However, this rebate coincided with an unexpected jump in gasoline and food prices. This coincidence led some to wonder whether the stimulus package would have the intended effect, or whether consumers would simply spend their rebates to cover higher food and fuel prices.\nOn 17 February 2009, U.S. President Barack Obama signed the American Recovery and Reinvestment Act of 2009, an $787 billion stimulus package with a broad spectrum of spending and tax cuts. Over $75 billion of the package was specifically allocated to programs which help struggling homeowners. This program is referred to as the Homeowner Affordability and Stability Plan.\nThe U.S. government continued to run large deficits post-crisis, with the national debt rising from $10.0 trillion as of September 2008 to $16.1 trillion by September 2012. The debt increases were $1.89 trillion in fiscal year 2009, $1.65 trillion in 2010, $1.23 trillion in 2011, and $1.26 trillion in 2012.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Responses", "sub_heading": "Economic stimulus", "_id": "44--3--1---1", "title": "The U.S. Economy After the Great Depression"}
{"qas": [{"question": "How much money did the US government actually lose from the 2008 financial crisis?", "answer": ""}, {"question": "How much did the us taxpayers lose in the subprime mortgage crisis?", "answer": "$60 billion", "ae_score": -0.3251747385350675, "qg_score": null}, {"question": "The subprime crisis in the late 1990s was caused by the loss of?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Losses on mortgage-backed securities and other assets purchased with borrowed money have dramatically reduced the capital base of financial institutions, rendering many either insolvent or less capable of lending. Governments have provided funds to banks. Some banks have taken significant steps to acquire additional capital from private sources.\nThe U.S. government passed the Emergency Economic Stabilization Act of 2008 (EESA or TARP) during October 2008. This law included $700 billion in funding for the \"Troubled Assets Relief Program\" (TARP). Following a model initiated by the United Kingdom bank rescue package, $205 billion was used in the Capital Purchase Program to lend funds to banks in exchange for dividend-paying preferred stock.\nAnother method of recapitalizing banks is for government and private investors to provide cash in exchange for mortgage-related assets (i.e., \"toxic\" or \"legacy\" assets), improving the quality of bank capital while reducing uncertainty regarding the financial position of banks. U.S. Treasury Secretary Timothy Geithner announced a plan during March 2009 to purchase \"legacy\" or \"toxic\" assets from banks. The Public-Private Partnership Investment Program involves government loans and guarantees to encourage private investors to provide funds to purchase toxic assets from banks.\nAs of April 2012, the government had recovered $300 billion of the $414 billion that was ultimately distributed to them via TARP. Some elements of TARP such as foreclosure prevention aid will not be paid back. Estimated taxpayer losses were $60 billion.\nFor a summary of U.S. government financial commitments and investments related to the crisis, see CNN \u2013 Bailout Scorecard.\nFor a summary of TARP funds provided to U.S. banks as of December 2008, see Reuters-TARP Funds.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Responses", "sub_heading": "Bank solvency and capital replenishment", "_id": "44--3--2---1", "title": "U.S. Banks Recapitalize Banks During the Financial Crisis"}
{"qas": [{"question": "What happened to the major financial institutions during the 2008 financial crisis?", "answer": ""}, {"question": "What was the value of the subprime mortgage crisis?", "answer": "$13 billion", "ae_score": -0.2397595770752789, "qg_score": null}, {"question": "What type of securities were the biggest losers in the credit crisis?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Several major financial institutions either failed, were bailed out by governments, or merged (voluntarily or otherwise) during the crisis. While the specific circumstances varied, in general the decline in the value of mortgage-backed securities held by these companies resulted in either their insolvency, the equivalent of bank runs as investors pulled funds from them, or inability to secure new funding in the credit markets. These firms had typically borrowed and invested large sums of money relative to their cash or equity capital, meaning they were highly leveraged and vulnerable to unanticipated credit market disruptions.\nThe five largest U.S. investment banks, with combined liabilities or debts of $4 trillion, either went bankrupt (Lehman Brothers), were taken over by other companies (Bear Stearns and Merrill Lynch), or were bailed out by the U.S. government (Goldman Sachs and Morgan Stanley) during 2008. Government-sponsored enterprises (GSE) Fannie Mae and Freddie Mac either directly owed or guaranteed nearly $5 trillion in mortgage obligations, with a similarly weak capital base, when they were placed into receivership in September 2008. For scale, this $9 trillion in obligations concentrated in seven highly leveraged institutions can be compared to the $14 trillion size of the U.S. economy (GDP) or to the total national debt of $10 trillion in September 2008.\nMajor depository banks around the world had also used financial innovations such as structured investment vehicles to circumvent capital ratio regulations. Notable global failures included Northern Rock, which was nationalized at an estimated cost of \u00a387 billion ($150 billion). In the U.S., Washington Mutual (WaMu) was seized in September 2008 by the US Office of Thrift Supervision (OTS). This would be followed by the \"shotgun wedding\" of Wells Fargo and Wachovia after it was speculated that without the merger Wachovia was also going to fail. Dozens of U.S. banks received funds as part of the TARP or $700 billion bailout. The TARP funds gained some controversy after PNC Financial Services received TARP money, only to turn around hours later and purchase the struggling National City Corp., which itself had become a victim of the subprime crisis.\nAs a result of the financial crisis in 2008, twenty-five U.S. banks became insolvent and were taken over by the FDIC. As of August 14, 2009, an additional 77 banks became insolvent. This seven-month tally surpasses the 50 banks that were seized in all of 1993, but is still much smaller than the number of failed banking institutions in 1992, 1991, and 1990. The United States has lost over 6 million jobs since the recession began in December 2007.\nThe FDIC deposit insurance fund, supported by fees on insured banks, fell to $13 billion in the first quarter of 2009. That is the lowest total since September 1993.\nAccording to some, the bailouts could be traced directly to Alan Greenspan's efforts to reflate the stock market and the economy after the tech stock bust, and specifically to a February 23, 2004 speech Mr. Greenspan made to the Mortgage Bankers Association where he suggested that the time had come to push average American borrowers into more exotic loans with variable rates, or deferred interest. This argument suggests that Mr. Greenspan sought to enlist banks to expand lending and debt to stimulate asset prices and that the Federal Reserve and US Treasury Department would back any losses that might result. As early as March 2007 some commentators predicted that a bailout of the banks would exceed $1 trillion, at a time when Ben Bernanke, Alan Greenspan and Henry Paulson all claimed that mortgage problems were \"contained\" to the subprime market and no bailout of the financial sector would be necessary.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Responses", "sub_heading": "Bailouts and failures of financial firms", "_id": "44--3--3---1", "title": "Bankruptcy and the Financial Crisis in the United States"}
{"qas": [{"question": "What would happen if everyone in the US decided to foreclose their homes?", "answer": ""}, {"question": "What is the most common outcome of a subprime mortgage crisis?", "answer": "foreclosure", "ae_score": -0.3060224930215519, "qg_score": null}, {"question": "What is the most common source of income for a subprime borrower?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Both lenders and borrowers may benefit from avoiding foreclosure, which is a costly and lengthy process. Some lenders have offered troubled borrowers more favorable mortgage terms (e.g. refinancing, loan modification or loss mitigation). Borrowers have also been encouraged to contact their lenders to discuss alternatives.\nThe Economist described the issue this way: \"No part of the financial crisis has received so much attention, with so little to show for it, as the tidal wave of home foreclosures sweeping over America. Government programmes have been ineffectual, and private efforts not much better.\" Up to 9 million homes may enter foreclosure over the 2009-2011 period, versus one million in a typical year. At roughly U.S. $50,000 per foreclosure according to a 2006 study by the Chicago Federal Reserve Bank, 9 million foreclosures represents $450 billion in losses.\nA variety of voluntary private and government-administered or supported programs were implemented during 2007\u20132009 to assist homeowners with case-by-case mortgage assistance, to mitigate the foreclosure crisis engulfing the U.S. One example is the Hope Now Alliance, an ongoing collaborative effort between the US Government and private industry to help certain subprime borrowers. In February 2008, the Alliance reported that during the second half of 2007, it had helped 545,000 subprime borrowers with shaky credit, or 7.7% of 7.1 million subprime loans outstanding as of September 2007. A spokesperson for the Alliance acknowledged that much more must be done.\nDuring late 2008, major banks and both Fannie Mae and Freddie Mac established moratoriums (delays) on foreclosures, to give homeowners time to work towards refinancing.\nCritics have argued that the case-by-case loan modification method is ineffective, with too few homeowners assisted relative to the number of foreclosures and with nearly 40% of those assisted homeowners again becoming delinquent within 8 months. In December 2008, the U.S. FDIC reported that more than half of mortgages modified during the first half of 2008 were delinquent again, in many cases because payments were not reduced or mortgage debt was not forgiven. This is further evidence that case-by-case loan modification is not effective as a policy tool.\nIn February 2009, economists Nouriel Roubini and Mark Zandi recommended an \"across the board\" (systemic) reduction of mortgage principal balances by as much as 20\u201330%. Lowering the mortgage balance would help lower monthly payments and also address an estimated 20 million homeowners that may have a financial incentive to enter voluntary foreclosure because they are \"underwater\" (i.e. the mortgage balance is larger than the home value).\nA study by the Federal Reserve Bank of Boston indicated that banks were reluctant to modify loans. Only 3% of seriously delinquent homeowners had their mortgage payments reduced during 2008. In addition, investors who hold MBS and have a say in mortgage modifications have not been a significant impediment; the study found no difference in the rate of assistance whether the loans were controlled by the bank or by investors. Commenting on the study, economists Dean Baker and Paul Willen both advocated providing funds directly to homeowners instead of banks.\nThe ''Los Angeles Times'' reported the results of a study that found homeowners with high credit scores at the time of entering the mortgage are 50% more likely to \"strategically default\" \u2013 abruptly and intentionally pull the plug and abandon the mortgage \u2013 compared with lower-scoring borrowers. Such strategic defaults were heavily concentrated in markets with the highest price declines. An estimated 588,000 strategic defaults occurred nationwide during 2008, more than double the total in 2007. They represented 18% of all serious delinquencies that extended for more than 60 days in the fourth quarter of 2008.\nOn 18 February 2009, U.S. President Barack Obama announced a $73 billion program to help up to nine million homeowners avoid foreclosure, which was supplemented by $200 billion in additional funding for Fannie Mae and Freddie Mac to purchase and more easily refinance mortgages. The plan is funded mostly from the EESA's $700 billion financial bailout fund. It uses cost sharing and incentives to encourage lenders to reduce homeowner's monthly payments to 31 percent of their monthly income. Under the program, a lender would be responsible for reducing monthly payments to no more than 38 percent of a borrower\u2019s income, with government sharing the cost to further cut the rate to 31 percent. The plan also involves forgiving a portion of the borrower\u2019s mortgage balance. Companies that service mortgages will get incentives to modify loans and to help the homeowner stay current.\nWhen the mortgage loan securitization scheme collapsed in 2008, and foreclosures spiked dramatically, the investors in the private label REMICs increasingly demanded to see the contents of these trusts. Since 2008, when trust content is discussed in the mainstream media, there has been a fixation solely on the quality of the loans (more specifically, the poor quality). On the fringes of the media, there has been a different but more relevant discussion: one of loan quantity rather than quality. The banks did not anticipate that by failing to execute those mortgage assignments to the private label REMICs, foreclosures in the future could not legally be accomplished. Many of these REMICs were devoid of loans when they were created and sold in shares; and they never were populated with loans after the shares were all sold. When that fact eventually came to light in 2008 or so, the media message was that these failures to assign were oversights or sloppy accounting or something of that nature. The drumbeat of that message continues to this day. However, this process had all the earmarks of a classic Ponzi scheme.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Responses", "sub_heading": "Homeowner assistance", "_id": "44--3--4---1", "title": "How Private Label Mortgage Trusts Can Help Homeowners Avoid Foreclosure"}
{"qas": [{"question": "What happened to the financial crisis of 2008?", "answer": ""}, {"question": "What was the name of the largest subprime mortgage modification company in the us?", "answer": "Amerimod", "ae_score": -0.5553276430942693, "qg_score": null}, {"question": "What kind of securities did bank of america sell in the subprime crisis?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "Significant law enforcement action and litigation resulted from the crisis. The U.S. Federal Bureau of Investigation probed the possibility of fraud by mortgage financing companies Fannie Mae and Freddie Mac, Lehman Brothers, and insurer American International Group, among others. New York Attorney General Andrew Cuomo sued Long Island based Amerimod, one of the nation's largest loan modification corporations for fraud, and issued numerous subpoenas to other similar companies. The FBI assigned more agents to mortgage-related crimes and its caseload dramatically increased. The FBI began a probe of Countrywide Financial in March 2008 for possible fraudulent lending practices and securities fraud.\nSeveral hundred civil lawsuits were filed in federal courts beginning in 2007 related to the subprime crisis. The number of filings in state courts was not quantified but was also believed to be significant. In August 2014, Bank of America agreed to a near-$17 billion deal to settle claims against it relating to the sale of toxic mortgage-linked securities including subprime home loans, in what was believed to be the largest settlement in U.S. corporate history. The deal with the U.S. Justice Department topped a deal the regulator made the previous year with JPMorgan Chase over similar issues. Morgan Stanley paid $2.6 billion to settle claims in February 2015, without reaching closure on homeowner relief and state claim", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Regulatory proposals and long-term solutions", "sub_heading": "Regulatory proposals and long-term solutions", "_id": "44--4--0---1", "title": "The Subprime Crisis: A Year in Review"}
{"qas": [{"question": "How did the US government get away with paying so much money to the banks?", "answer": ""}, {"question": "How many u.s. attorneys were involved in the subprime mortgage crisis?", "answer": "94", "ae_score": -0.6904079150168968, "qg_score": null}, {"question": "What were the major banks involved in the subprime crisis?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "U.S. banks have paid considerable fines from legal settlements due to mortgage-related activities. ''The Economist'' estimated that from 2008 through October 2013, U.S. banks had agreed to $95 billion in mortgage-related penalties. Settlement amounts included Bank of America ($47.2B), JP Morgan Chase ($22.3B), Wells Fargo ($9.8B), Citigroup ($6.2B) and Goldman-Sachs ($0.9B). Bloomberg reported that from the end of 2010 to October 2013, the six largest Wall St. banks had agreed to pay $67 billion. CNBC reported in April 2015 that banking fines and penalties totaled $150 billion between 2007 and 2014, versus $700 billion in profits over that time.\nMany of these fines were obtained via the efforts of President Obama's Financial Fraud Enforcement Task Force (FFETF), which was created in November 2009 to investigate and prosecute financial crimes. The FFETF involves over 20 federal agencies, 94 U.S. Attorney's offices, and state and local partners. One of its eight working groups, the Residential Mortgage Backed Securities (RMBS) Working Group, was created in 2012 and is involved in investigating and negotiating many of the fines and penalties described above.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Regulatory proposals and long-term solutions", "sub_heading": "Bank fines and penalties", "_id": "44--4--1---1", "title": "U.S. Banks Paid $95 Billion in Mortgage Penalties"}
{"qas": [{"question": "The financial crisis of 2008?", "answer": ""}, {"question": "Who wrote the book too big to fail?", "answer": "Andrew Ross Sorkin", "ae_score": -0.39572460160590195, "qg_score": null}, {"question": "Who wrote the book too big to fail?", "answer": "Andrew Ross Sorkin", "ae_score": -0.39572460160590195, "qg_score": null}], "content": "Several books written about the crisis were made into movies. Examples include ''The Big Short'' by Michael Lewis and ''Too Big to Fail'' by Andrew Ross Sorkin. The former tells the story from the perspective of several investors who bet against the housing market, while the latter follows key government and banking officials focusing on the critical events of September 2008, when many large financial institutions faced or experienced collapse.", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "In popular culture", "sub_heading": "In popular culture", "_id": "44--5---1---1", "title": "''Too Big to Fail'' by Andrew Ross Sorkin"}
{"qas": [{"question": "How did the U.S. Federal Reserve get involved in the 2008 financial crisis?", "answer": ""}, {"question": "Who said the subprime mortgage crisis could force americans to live within their means?", "answer": "Fareed Zakaria", "ae_score": -0.09875948963603777, "qg_score": null}, {"question": "What type of financial asset was used as collateral during the subprime crisis?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Estimates of impact have continued to climb. During April 2008, International Monetary Fund (IMF) estimated that global losses for financial institutions would approach $1 trillion. One year later, the IMF estimated cumulative losses of banks and other financial institutions globally would exceed $4 trillion.\nFrancis Fukuyama has argued that the crisis represents the end of Reaganism in the financial sector, which was characterized by lighter regulation, pared-back government, and lower taxes. Significant financial sector regulatory changes are expected as a result of the crisis.\nFareed Zakaria believes that the crisis may force Americans and their government to live within their means. Further, some of the best minds may be redeployed from financial engineering to more valuable business activities, or to science and technology.\nRoger Altman wrote that \"the crash of 2008 has inflicted profound damage on [the U.S.] financial system, its economy, and its standing in the world; the crisis is an important geopolitical setback...the crisis has coincided with historical forces that were already shifting the world's focus away from the United States. Over the medium term, the United States will have to operate from a smaller global platform \u2013 while others, especially China, will have a chance to rise faster.\"\nGE CEO Jeffrey Immelt has argued that U.S. trade deficits and budget deficits are unsustainable. America must regain its competitiveness through innovative products, training of production workers, and business leadership. He advocates specific national goals related to energy security or independence, specific technologies, expansion of the manufacturing job base, and net exporter status. \"The world has been reset. Now we must lead an aggressive American renewal to win in the future.\" Of critical importance, he said, is the need to focus on technology and manufacturing. \"Many bought into the idea that America could go from a technology-based, export-oriented powerhouse to a services-led, consumption-based economy \u2013 and somehow still expect to prosper,\" Jeff said. \"That idea was flat wrong.\"\nEconomist Paul Krugman wrote in 2009: \"The prosperity of a few years ago, such as it was \u2013 profits were terrific, wages not so much \u2013 depended on a huge bubble in housing, which replaced an earlier huge bubble in stocks. And since the housing bubble isn\u2019t coming back, the spending that sustained the economy in the pre-crisis years isn\u2019t coming back either.\" Niall Ferguson stated that excluding the effect of home equity extraction, the U.S. economy grew at a 1% rate during the Bush years. Microsoft CEO Steve Ballmer has argued that this is an economic reset at a lower level, rather than a recession, meaning that no quick recovery to pre-recession levels can be expected.\nThe U.S. Federal government's efforts to support the global financial system have resulted in significant new financial commitments, totaling $7 trillion by November, 2008. These commitments can be characterized as investments, loans, and loan guarantees, rather than direct expenditures. In many cases, the government purchased financial assets such as commercial paper, mortgage-backed securities, or other types of asset-backed paper, to enhance liquidity in frozen markets. As the crisis has progressed, the Fed has expanded the collateral against which it is willing to lend to include higher-risk assets.\nThe Economist wrote in May 2009: \"Having spent a fortune bailing out their banks, Western governments will have to pay a price in terms of higher taxes to meet the interest on that debt. In the case of countries (like Britain and America) that have trade as well as budget deficits, those higher taxes will be needed to meet the claims of foreign creditors. Given the political implications of such austerity, the temptation will be to default by stealth, by letting their currencies depreciate. Investors are increasingly alive to this danger...\"\nThe crisis has cast doubt on the legacy of Alan Greenspan, the Chairman of the Federal Reserve System from 1986 to January 2006. Senator Chris Dodd claimed that Greenspan created the \"perfect storm\". When asked to comment on the crisis, Greenspan spoke as follows:", "page_name": "Subprime mortgage crisis", "page_id": "Subprime%20mortgage%20crisis", "heading": "Implications", "sub_heading": "Implications", "_id": "44--6---1---1", "title": "The U.S. Financial Crisis Is a Reset"}
{"qas": [{"question": "Why is New South Wales the only place in Australia to have a \"Standard for Quality Natural Resource Management\"?", "answer": ""}, {"question": "When was the standard for quality natural resource management established?", "answer": "2005", "ae_score": -0.3260460040692429, "qg_score": null}, {"question": "When was the standard for quality natural resource management established?", "answer": "2005", "ae_score": -0.3260460040692429, "qg_score": null}], "content": "The emphasis on sustainability can be traced back to early attempts to understand the ecological nature of North American rangelands in the late 19th century, and the resource conservation movement of the same time.  This type of analysis coalesced in the 20th century with recognition that preservationist conservation strategies had not been effective in halting the decline of natural resources. A more integrated approach was implemented recognising the intertwined social, cultural, economic and political aspects of resource management. A more holistic, national and even global form evolved, from the Brundtland Commission and the advocacy of sustainable development.\nIn 2005 the government of New South Wales, established a ''Standard for Quality Natural Resource Management'', to improve the consistency of practice, based on an adaptive management approach.\nIn the United States, the most active areas of natural resource management are wildlife management often associated with ecotourism and rangeland management. In Australia, water sharing, such as the Murray Darling Basin Plan and catchment management are also significant.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "History", "sub_heading": "History", "_id": "45--0---1---1", "title": "Sustainable Natural Resource Management"}
{"qas": [{"question": "What is the difference between ownership and control over the use of resources?", "answer": ""}, {"question": "What is an example of a natural resource management system?", "answer": "lake fishery", "ae_score": -0.2680705562049549, "qg_score": null}, {"question": "What is an example of a natural resource management system?", "answer": "lake fishery", "ae_score": -0.2680705562049549, "qg_score": null}], "content": "Natural resource management approaches can be categorised according to the kind and right of stakeholders, natural resources:\nOwnership and control over the use of resources is in hands of the state. Individuals or groups may be able to make use of the resources, but only at the permission of the state. National forest, National parks and military reservations are some US  examples.\nAny property owned by a defined individual or corporate entity. Both the benefit and duties to the resources fall to the owner(s). Private land is the most common example.\nIt is a private property of a group. The group may vary in size, nature and internal structure e.g. indigenous neighbours of village. Some examples of common property are community forests.\nThere is no definite owner of these properties. Each potential user has equal ability to use it as they wish. These areas are the most exploited. It is said that \"Everybody's property is nobody's property\". An example is a lake fishery. Common land may exist without ownership, in which case in the UK it is vested in a local authority.\nMany ownership regimes governing natural resources will contain parts of more than one of the regimes described above, so natural resource managers need to consider the impact of hybrid regimes. An example of such a hybrid is native vegetation management in NSW, Australia, where legislation recognises a public interest in the preservation of native vegetation, but where most native vegetation exists on private land.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Ownership regimes", "sub_heading": "Ownership regimes", "_id": "45--1---1---1", "title": "Natural resource management: Ownership and control"}
{"qas": [{"question": "Why do we use the term \"stakeholder analysis\" when referring to natural resource management?", "answer": ""}, {"question": "What is an example of a natural resource management system?", "answer": "community forestry", "ae_score": -0.23998597787162051, "qg_score": null}, {"question": "What is an example of a natural resource management system?", "answer": "community forestry", "ae_score": -0.23998597787162051, "qg_score": null}], "content": "Stakeholder analysis originated from business management practices and has been incorporated into natural resource management in ever growing popularity. Stakeholder analysis in the context of natural resource management identifies distinctive interest groups affected in the utilisation and conservation of natural resources.\nThere is no definitive definition of a stakeholder as illustrated in the table below. Especially in natural resource management as it is difficult to determine who has a stake and this will differ according to each potential stakeholder.\n'''Different approaches to who is a stakeholder:'''\nTherefore, it is dependent upon the circumstances of the stakeholders involved with natural resource as to which definition and subsequent theory is utilised.\nBillgrena and Holme identified the aims of stakeholder analysis in natural resource management:\nThis gives transparency and clarity to policy making allowing stakeholders to recognise conflicts of interest and facilitate resolutions.There are numerous stakeholder theories such as Mitchell et al. however Grimble created a framework of stages for a Stakeholder Analysis in natural resource management. Grimble  designed this framework to ensure that the analysis is specific to the essential aspects of natural resource management.\n'''Stages in Stakeholder analysis:'''\n'''Application:'''\nGrimble and Wellard established that Stakeholder analysis in natural resource management is most relevant where issued can be characterised as;\n'''Case Studies'''\nIn the case of the Bwindi Impenetrable National Park, a comprehensive stakeholder analysis would have been relevant and the Batwa people would have potentially been acknowledged as stakeholders preventing the loss of people's livelihoods and loss of life.\nNepal, Indonesia and Koreas' community forestry are successful examples of how stakeholder analysis can be incorporated into the management of natural resources. This allowed the stakeholders to identify their needs and level of involvement with the forests.\n'''Criticisms:'''\n'''Alternatives/ Complementary forms of analysis:'''", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Stakeholder analysis", "sub_heading": "Stakeholder analysis", "_id": "45--2---1---1", "title": "Stakeholder Analysis in Natural Resource Management"}
{"qas": [{"question": "How is it possible for the United States to have so many different types of food stamps?", "answer": ""}, {"question": "How many state government bodies are involved in natural resource management?", "answer": "56", "ae_score": -0.12689996322100727, "qg_score": null}, {"question": "How many state government bodies are involved in natural resource management?", "answer": "56", "ae_score": -0.12689996322100727, "qg_score": null}], "content": "The community-based natural resource management (CBNRM) approach combines conservation objectives with the generation of economic benefits for rural communities. The three key assumptions being that: locals are better placed to conserve natural resources, people will conserve a resource only if benefits exceed the costs of conservation, and people will conserve a resource that is linked directly to their quality of life. When a local people's quality of life is enhanced, their efforts and commitment to ensure the future well-being of the resource are also enhanced. Regional and community based natural resource management is also based on the principle of subsidiarity.\nThe United Nations advocates CBNRM in the Convention on Biodiversity and the Convention to Combat Desertification. Unless clearly defined, decentralised NRM can result an ambiguous socio-legal environment with local communities racing to exploit natural resources while they can e.g. forest communities in central Kalimantan (Indonesia).\nA problem of CBNRM is the difficulty of reconciling and harmonising the objectives of socioeconomic development, biodiversity protection and sustainable resource utilisation. The concept and conflicting interests of CBNRM, show how the motives behind the participation are differentiated as either people-centred (active or participatory results that are truly empowering) or planner-centred (nominal and results in passive recipients). Understanding power relations is crucial to the success of community based NRM. Locals may be reluctant to challenge government recommendations for fear of losing promised benefits.\nCBNRM is based particularly on advocacy by nongovernmental organizations working with local groups and communities, on the one hand, and national and transnational organizations, on the other, to build and extend new versions of environmental and social advocacy that link social justice and environmental management agendas with both direct and indirect benefits observed including a share of revenues, employment, diversification of livelihoods and increased pride and identity. CBNRM has raised new challenges, as concepts of community, territory, conservation, and indigenous are worked into politically varied plans and programs in disparate sites. Warner and Jones address strategies for effectively managing conflict in CBNRM.\nThe capacity of indigenous communities to conserve natural resources has been acknowledged by the Australian Government with the Caring for Country Program. Caring for our Country is an Australian Government initiative jointly administered by the Australian Government Department of Agriculture, Fisheries and Forestry and the Department of the Environment, Water, Heritage and the Arts. These Departments share responsibility for delivery of the Australian Government's environment and sustainable agriculture programs, which have traditionally been broadly referred to under the banner of \u2018natural resource management\u2019.\nThese programs have been delivered regionally, through 56 State government bodies, successfully allowing regional communities to decide the natural resource priorities for their regions.\nGovernance is seen as a key consideration for delivering community-based or regional natural resource management. In the State of NSW, the 13 catchment management authorities (CMAs) are overseen by the Natural Resources Commission (NRC), responsible for undertaking audits of the effectiveness of regional natural resource management programs.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Management of the resources", "sub_heading": "Management of the resources", "_id": "45--3--0---1", "title": "Community-based Natural Resource Management"}
{"qas": [{"question": "What is the difference between natural resources management and adaptive management?", "answer": ""}, {"question": "How many key components should be considered for quality natural resource management practice?", "answer": "seven", "ae_score": -0.31300414102260804, "qg_score": null}, {"question": "How many key components should be considered for quality natural resource management practice?", "answer": "seven", "ae_score": -0.31300414102260804, "qg_score": null}], "content": "The primary methodological approach adopted by catchment management authorities (CMAs) for regional natural resource management in Australia is adaptive management.\nThis approach includes recognition that adaption occurs through a process of \u2018plan-do-review-act\u2019. It also recognises seven key components that should be considered for quality natural resource management practice:", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Management of the resources", "sub_heading": "Adaptive management", "_id": "45--3--1---1", "title": "Adaptive management for regional natural resource management in Australia"}
{"qas": [{"question": "Integrated Natural Resource Management?", "answer": ""}, {"question": "The process of managing natural resources in a systematic way is called?", "answer": "Integrated natural resource management", "ae_score": -0.5372031768730589, "qg_score": null}, {"question": "The process of managing natural resources in a systematic way is called?", "answer": "Integrated natural resource management", "ae_score": -0.5372031768730589, "qg_score": null}], "content": "Integrated natural resource management (INRM) is a process of managing natural resources in a systematic way, which includes multiple aspects of natural resource use (biophysical, socio-political, and economic) meet production goals of producers and other direct users (e.g., food security, profitability, risk aversion) as well as goals of the wider community (e.g., poverty alleviation, welfare of future generations, environmental conservation). It focuses on sustainability and at the same time tries to incorporate all possible stakeholders from the planning level itself, reducing possible future conflicts. The conceptual basis of INRM has evolved in recent years through the convergence of research in diverse areas such as sustainable land use, participatory planning, integrated watershed management, and adaptive management. INRM is being used extensively and been successful in regional and community based natural management.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Management of the resources", "sub_heading": "Integrated natural resource management", "_id": "45--3--2---1", "title": "Integrated Natural Resource Management (INRM)"}
{"qas": [{"question": "What is the difference between natural resources management and adaptive management?", "answer": ""}, {"question": "How many key components should be considered for quality natural resource management practice?", "answer": "seven", "ae_score": -0.31300414102260804, "qg_score": null}, {"question": "How many key components should be considered for quality natural resource management practice?", "answer": "seven", "ae_score": -0.31300414102260804, "qg_score": null}], "content": "The primary methodological approach adopted by catchment management authorities (CMAs) for regional natural resource management in Australia is adaptive management.\nThis approach includes recognition that adaption occurs through a process of \u2018plan-do-review-act\u2019. It also recognises seven key components that should be considered for quality natural resource management practice:", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Management of the resources", "sub_heading": "Adaptive management", "_id": "45--3--3---1", "title": "Adaptive management for regional natural resource management"}
{"qas": [{"question": "Integrated Natural Resource Management?", "answer": ""}, {"question": "The process of managing natural resources in a systematic way is called?", "answer": "Integrated natural resource management", "ae_score": -0.5372031768730589, "qg_score": null}, {"question": "The process of managing natural resources in a systematic way is called?", "answer": "Integrated natural resource management", "ae_score": -0.5372031768730589, "qg_score": null}], "content": "Integrated natural resource management (INRM) is a process of managing natural resources in a systematic way, which includes multiple aspects of natural resource use (biophysical, socio-political, and economic) meet production goals of producers and other direct users (e.g., food security, profitability, risk aversion) as well as goals of the wider community (e.g., poverty alleviation, welfare of future generations, environmental conservation). It focuses on sustainability and at the same time tries to incorporate all possible stakeholders from the planning level itself, reducing possible future conflicts. The conceptual basis of INRM has evolved in recent years through the convergence of research in diverse areas such as sustainable land use, participatory planning, integrated watershed management, and adaptive management. INRM is being used extensively and been successful in regional and community based natural management.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Management of the resources", "sub_heading": "Integrated natural resource management", "_id": "45--3--4---1", "title": "Integrated Natural Resource Management (INRM)"}
{"qas": [{"question": "Why is Australia's greenhouse gas emissions so low compared to other countries?", "answer": ""}, {"question": "What is the name of the australian plan to manage water?", "answer": "Murray Darling Basin Plan", "ae_score": -0.4339364004895769, "qg_score": null}, {"question": "What is the name of the australian plan to manage water?", "answer": "Murray Darling Basin Plan", "ae_score": -0.4339364004895769, "qg_score": null}], "content": "There are various frameworks and computer models developed to assist natural resource management.\n'''Geographic Information Systems (GIS)'''\nGIS is a powerful analytical tool as it is capable of overlaying datasets to identify links. A bush regeneration scheme can be informed by the overlay of rainfall, cleared land and erosion. In Australia, Metadata Directories such as NDAR provide data on Australian natural resources such as vegetation, fisheries, soils and water. These are limited by the potential for subjective input and data manipulation.\n'''Natural Resources Management Audit Frameworks'''\nThe NSW Government in Australia has published an audit framework for natural resource management, to assist the establishment of a performance audit role in the governance of regional natural resource management. This audit framework builds from other established audit methodologies, including performance audit, environmental audit and internal audit. Audits undertaken using this framework have provided confidence to stakeholders, identified areas for improvement and described policy expectations for the general public.\nThe Australian Government has established a framework for auditing greenhouse emissions and energy reporting, which closely follows Australian Standards for Assurance Engagements.\nThe Australian Government is also currently preparing an audit framework for auditing water management, focussing on the implementation of the Murray Darling Basin Plan.", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Frameworks and modelling", "sub_heading": "Frameworks and modelling", "_id": "45--4---1---1", "title": "'''Natural Resources Management Audit Frameworks'''"}
{"qas": [{"question": "Why do we have to take a breathalyzer to see if it's safe to drink?", "answer": ""}, {"question": "How many methods are there to manage biodiversity?", "answer": "4", "ae_score": -0.19656312308315751, "qg_score": null}, {"question": "How many methods are there to manage biodiversity?", "answer": "4", "ae_score": -0.19656312308315751, "qg_score": null}], "content": "The issue of biodiversity conservation is regarded as an important element in natural resource management. What is biodiversity? Biodiversity is a comprehensive concept, which is a description of the extent of natural diversity. Gaston and Spicer (p. 3) point out that biodiversity is \"the variety of life\" and relate to different kinds of \"biodiversity organization\". According to Gray (p. 154), the first widespread use of the definition of biodiversity, was put forward by the United Nations in 1992, involving different aspects of biological diversity.\nThe \"threats\" wreaking havoc on biodiversity include; habitat fragmentation, putting a strain on the already stretched biological resources; forest deterioration and deforestation; the invasion of \"alien species\" and \"climate change\"( p. 2). Since these threats have received increasing attention from environmentalists and the public, the precautionary management of biodiversity becomes an important part of natural resources management. According to Cooney, there are material measures to carry out precautionary management of biodiversity in natural resource management.\nCooney claims that the policy making is dependent on \"evidences\", relating to \"high standard of proof\", the forbidding of special \"activities\" and \"information and monitoring requirements\". Before making the policy of precaution, categorical evidence is needed. When the potential menace of \"activities\" is regarded as a critical and \"irreversible\" endangerment, these \"activities\" should be forbidden. For example, since explosives and toxicants will have serious consequences to endanger human and natural environment, the South Africa Marine Living Resources Act promulgated a series of policies on completely forbidding to \"catch fish\" by using explosives and toxicants.\nAccording to Cooney, there are 4 methods to manage the precaution of biodiversity in natural resources management;\n1. \"Ecosystem based Management\" including \"more risk-averse and precautionary management\", where \"given prevailing uncertainty regarding ecosystem structure, function, and inter-specific interactions, precaution demands an ecosystem rather than single-species approach to management\".\n2. \"Adaptive management\" is \"a management approach that expressly tackles the uncertainty and dynamism of complex systems\".\n3. \"Environmental impact assessment\" and exposure ratings decrease the \"uncertainties\" of precaution, even though it has deficiencies, and\n4. \"Protectionist approaches\", which \"most frequently links to\" biodiversity conservation in natural resources management.\nIn order to have a sustainable environment, understanding and using appropriate management strategies is important. In terms of understanding, Young emphasises some important points of land management:\nDale et al. (2000) study has shown that there are five fundamental and helpful ecological principles for the land manager and people who need them. The ecological principles relate to time, place, species, disturbance and the landscape and they interact in many ways.It is suggested that land managers could follow these guidelines:", "page_name": "Natural resource management", "page_id": "Natural%20resource%20management", "heading": "Other elements", "sub_heading": "Other elements", "_id": "45--5---1---1", "title": "Conservation of Biodiversity in Natural Resources Management"}
{"qas": [{"question": "Why is Agriprocessors such a big deal in the US?", "answer": ""}, {"question": "Who is the largest kosher meat producer in the us?", "answer": "Agriprocessors", "ae_score": -0.041713271164864604, "qg_score": null}, {"question": "Who is the largest kosher meat producer in the us?", "answer": "Agriprocessors", "ae_score": -0.041713271164864604, "qg_score": null}], "content": "In the 1980s Aaron Rubashkin, a Russian-born Lubavitcher Hasidic butcher from Brooklyn, decided to take advantage of economic structural changes to bring mass-production to the kosher meat production business. In 1987 he bought an abandoned slaughterhouse outside Postville, a town undergoing a major employment crisis in northeastern Iowa and opened a processing plant creating some 350 jobs. He sent two of his sons to Postville to oversee day-to-day operations.  Sholom Rubashkin, the second youngest, served as CEO, and Heshy Rubashkin, the youngest, as vice president of marketing and sales. In 1992, Agriprocessors added poultry to its offerings. At its peak the plant employed over 800 people, killing more than 500 head of cattle each day in kosher production. The sales, according to numbers given to ''Cattle Buyers Weekly'', rose from $80 million in 1997 to $180 million in 2002 and may have reached $250 million or more.\nRubashkin brought modern industrial methods to what has historically been a small, almost boutique craft, developing retail-ready glatt kosher products being sold both in supermarkets and in small, local grocery stores and meat markets around the United States. Agriprocessors was the largest (glatt) kosher meat producer in the United States and the only one authorized by Israel's Orthodox rabbinate to export beef to Israel.\nIn the 20 years it operated in Postville, Agriprocessors had a major impact on the town, creating new jobs, attracting immigrants from many different countries, and bringing an influx of Orthodox Jews to a part of the United States where Jews had been practically unknown.\nThe Rubashkin family opened another processing plant for bison, cattle and lamb called ''Local Pride Plant'' in conjunction with the Oglala Lakota native-American tribe of the Pine Ridge Indian Reservation in Gordon, Nebraska in 2006 employing some 100 locals. The presence of the plant near an Indian reservation provided considerable tax breaks for Rubashkin. Governor Dave Heineman presented a $505,000 gratuity check to Rubashkin on behalf of the city of Gordon, as part of an incentive package that brought the factory to the town.\nAgriprocessors had two distribution sites, one in Brooklyn, New York, and one in Miami, Florida, both managed by members of the Rubashkin family. It also operated slaughter facilities in South America.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "History", "sub_heading": "History", "_id": "46--0---1---1", "title": "Agriprocessors: A History of Kosher Meat Production"}
{"qas": [{"question": "Why is the US Department of Agriculture so concerned with animal cruelty?", "answer": ""}, {"question": "What is the name of the expert who said agriprocessors procedures are an ab?", "answer": "Dr. Temple Grandin", "ae_score": -0.1794307034372078, "qg_score": null}, {"question": "What is the name of the expert who said agriprocessors procedures are an ab?", "answer": "Dr. Temple Grandin", "ae_score": -0.1794307034372078, "qg_score": null}], "content": "In late 2004, People for the Ethical Treatment of Animals (PETA) released a video filmed undercover at Agriprocessors, showing gory details of cattle having their tracheas and esophagi being ripped out of their necks and surviving for minutes after shechita (ritual slaughter). Noted animal welfare expert and meat scientist Dr. Temple Grandin called Agriprocessors procedures an \"atrocious abomination\" and worse than anything she had ever seen in over 30 kosher abattoirs.\nJewish authorities were split, with former Chief Rabbi of Ireland, David Rosen, and Shechita UK, along with many non-Orthodox rabbis from the Conservative movement, criticizing Agriprocessors, while Orthodox kashrut organizations continued to stand by the kashrut of the meat. Under pressure from the Agriculture Department, the Orthodox Union kosher certification authority, and Israel's chief rabbinate, the plant changed its practices.\nIn 2005 an internal report from the USDA not only held that Agriprocessors engaged in acts of inhumane slaughter, but that USDA inspectors were sleeping on the job, playing computer games, and had accepted bribes of free meat to ignore violations at the plant.\nOn June 27, 2006, at the suggestion of Rabbi Menachem Genack of the Orthodox Union, Dr. Grandin toured the facility.  According to the Orthodox Union, Dr. Grandin was satisfied with what she saw. In 2008, though, Grandin reported that Agriprocessors had again become \"sloppy\" in their slaughter operation and was \"in the bottom 10%\" of slaughterhouses.\nAnother PETA undercover video, reportedly taken on August 13, 2008, showed violations of the Humane Methods of Livestock Slaughter Act, including the use of saw-like, multiple, hacking cuts in the necks of still-conscious animals. Dr. Grandin said the second cuts would \u201cdefinitely cause the animal pain.\u201d The episode led Grandin to state that slaughterhouse visits were useless for determining proper animal treatment. Grandin suggested that Agriprocessors install internet video cams on the killing floor for constant, independent, oversight.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Controversies", "_id": "46--1--0---1", "title": "Agriprocessors: The Atrocious Abhorrence of Animals"}
{"qas": [{"question": "What is Agriprocessors and why is it such a big deal?", "answer": ""}, {"question": "How much did agriprocessors pay in fines?", "answer": "$600,000", "ae_score": -0.6223836286947514, "qg_score": null}, {"question": "How much did agriprocessors pay in fines?", "answer": "$600,000", "ae_score": -0.6223836286947514, "qg_score": null}], "content": "In 2004, city authorities started an investigation against Agriprocessors due to complaints from local residents that the firm routinely deposited untreated effluent into local rivers in breach of regulations. On August 31, 2006, Agriprocessors signed a consent decree where they essentially admitted discharging untreated slaughtering wastewater into the Postville sewer system, in violation of Federal and Iowa State law and paid a $600,000 fine for violating waste-water regulations. Untreated wastewater from abattoirs is a heavy burden on wastewater treatment plants because of its high biochemical oxygen demand and high concentration of FOG (Fats, oils, and grease) which can form insoluble plaques in sewage pipes.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Pollution", "_id": "46--1--1---1", "title": "Agriprocessors vs. Postville"}
{"qas": [{"question": "Why are Agriprocessors allowed to operate in Iowa?", "answer": ""}, {"question": "How much did agriprocessors pay in fines?", "answer": "$9.99 million", "ae_score": -0.14375702700901727, "qg_score": null}, {"question": "How much did agriprocessors pay in fines?", "answer": "$9.99 million", "ae_score": -0.14375702700901727, "qg_score": null}], "content": "In September 2005, workers at Agriprocessors\u2019 distribution site in Brooklyn voted to join the United Food and Commercial Workers union. The company did not recognize the vote, arguing that it was invalid because management had discovered that many of the workers who participated were in the US illegally, making their votes invalid despite protection granted undocumented workers in the National Labor Relations Act. A National Labor Relations Board judge decided against the company and ordered it to recognize the vote. Workers alleged that Agriprocessors paid low wages, failed to pay overtime and immediately terminated employment of workers who complained about conditions or wages.\nOn August 20, 2008, Jewish employees at Agriprocessors were reported to have staged a 30-minute walkout over delayed payment of wages and other compensation issues.\nIn October 2008, the Iowa Labor Commission fined Agriprocessors $9.99 million for various violations of state labor law, including illegally deducting money from employees for safety equipment and failing to pay employees.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Labor relations", "_id": "46--1--2---1", "title": "Agriprocessors v. United Food and Commercial Workers"}
{"qas": [{"question": "What is the Rubashkin Scandal?", "answer": ""}, {"question": "What was the rubashkins accused of in the village voice?", "answer": "sharp business practices", "ae_score": -1.8414173111945662, "qg_score": null}, {"question": "What was the rubashkins accused of in the village voice?", "answer": "sharp business practices", "ae_score": -1.8414173111945662, "qg_score": null}], "content": "A December 2008 story in the ''Village Voice'' featured allegations of sharp business practices by the Rubashkins: intimidating rivals (with threats of physical violence), manipulation of the kosher certification system, collusion with suppliers to withhold supplies from competitors, etc.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Anti-competitive practices", "_id": "46--1--3---1", "title": "''Village Voice'' \u2014 The Rubashkins"}
{"qas": [{"question": "What exactly is going on with the undocumented immigrants in the US?", "answer": ""}, {"question": "How many immigrants were arrested in the 2008 raid?", "answer": "389", "ae_score": -0.27069026654973344, "qg_score": null}, {"question": "How many immigrants were arrested in the 2008 raid?", "answer": "389", "ae_score": -0.27069026654973344, "qg_score": null}], "content": "On 12 May 2008, U.S. Immigration and Customs Enforcement (ICE) staged a raid that was described as \u201clargest criminal worksite enforcement operation in U.S. history\u201d. Federal authorities arrested 389 immigrant workers during the raid, 305 of them on criminal charges, 297 were sentenced on federal felony charges for fraud-related offenses. ICE spokesman Tim Counts said that \u201cthe raid was aimed at seeking evidence of identity theft, stolen Social Security numbers and for people who are in the country illegally\u201d. According to the U.S. attorney's office for the Northern District of Iowa, those arrested \u201cinclude 290 Guatemalans, 93 Mexicans, 2 Israelis and 4 Ukrainians\u201d.\nSources quoted in the affidavit and application for search warrant alleged the existence of a methamphetamine laboratory at the slaughterhouse, and that employees carried weapons to work. However, later press reports do not indicate that a methamphetamine laboratory was found during the search.\nIn late July, members of the Congressional Hispanic Caucus met with workers and community leaders, after a United States House of Representatives' subcommittee had heard testimony about the raid and its impact on the families and the town, and a rally with some 1,500 participants, organized by the Jewish Council on Urban Affairs, ''Jewish Community Action'' and St. Bridget's Roman Catholic Church was held in Postville in support of the detained Agriprocessors workers and their families.\nThe Rubashkin family was reported to have denied any criminal activity; Aaron Rubashkin said that \u201che had no idea that his workers were illegal and that they had produced what appeared to be legitimate work documents\u201d. Nevertheless, he announced shortly after the raid that he intends to replace his son as the company's CEO. Sholom Rubashkin remained in charge though. He was finally replaced as CEO in September 2008 by Bernard Feldman, a New York attorney who had worked as counsel for the family, after child labor charges against Aaron and Sholom Rubashkin had been announced, and the Orthodox Union had threatened to withdraw their kosher certification.\nThe ICE raid left the company lacking employees, and it hired Labor Ready to supply \"about 150 workers\", but these workers stopped working because of alleged safety issues. The Jacobson Staffing company took the job of staffing the plant shortly thereafter. In June 2008, Agriprocessors began hiring workers from homeless shelters in Texas to replace employees detained in the federal immigration raid.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Federal immigration raid", "_id": "46--1--4---1", "title": "Agriprocessors Raid in Iowa: The Impact on the Rubashkin Family"}
{"qas": [{"question": "What is \"astroturfing\"?", "answer": ""}, {"question": "What website claimed to be a blog by people who live and work in postville,?", "answer": "PostvilleVoices.com", "ae_score": -0.1379861596289011, "qg_score": null}, {"question": "What website claimed to be a blog by people who live and work in postville,?", "answer": "PostvilleVoices.com", "ae_score": -0.1379861596289011, "qg_score": null}], "content": "In May 2008, following the federal immigration raid, PostvilleVoices.com, a site that claimed to be \"a blog by people who live and work in Postville\" and defended the firm's hiring practices, saying that \"the people that run Agriprocessors are good, decent, honest people\". After Postville residents suspected that this was a case of \u201castroturfing\u201d, Getzel Rubashkin, son of Sholom Rubashkin, admitted he and two friends created the site.\nIn June 2008, Agriprocessors retained Jim Martin, a former U.S. Attorney, as the company's outside CCO, hired 5W Public Relations to repair its public image, and Lubicom, a kosher consulting and PR firm headed by Menachem Lubinsky, to present its case to the New York Jewish community. Lubinsky was quoted as saying he \u201cexpected 5W to deal with negative publicity and blogs\u201d. Shortly thereafter, suspicious posts defending the company appeared on Jewish blogs critical of the company. Shmarya Rosenberg, author of the ''Failed Messiah'' blog, uncovered that two posts under the name of Rabbi Morris Allen of Hechsher Tzedek, a critic of Agriprocessors, were part of a sockpuppeting scheme. Similar comments impersonating Rabbi Allen were found on the websites of the Jewish Telegraphic Agency (JTA) and Vos Iz Neias. Ronn Torossian, CEO of 5W, admitted that a \u201csenior staff member failed to be transparent in dealing with client matters.\u201d", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Public relations", "_id": "46--1--5---1", "title": "PostvilleVoices.com defended Agriprocessors as \u201ca blog"}
{"qas": [{"question": "Why did the FBI raid the Postville plant?", "answer": ""}, {"question": "Who was the governor of iowa when agriprocessors was raided?", "answer": "Chet Culver", "ae_score": -0.7794423206692577, "qg_score": null}, {"question": "Who was the governor of iowa when agriprocessors was raided?", "answer": "Chet Culver", "ae_score": -0.7794423206692577, "qg_score": null}], "content": "In August 2008, Iowa Governor Chet Culver commented on Agriprocessors:Before the federal raid, Agriprocessors already had a history of sanctions by Iowa\u2019s state regulatory agencies for water pollution, as well as health and safety law violations. Alarming information about working conditions at the Postville plant - including allegations ranging from the use of child labor in prohibited jobs to sexual and physical abuse by supervisors; from the nonpayment of regular and overtime wages to the denial of immediate medical attention for workplace injuries - brought to national attention by the raid forces me to believe that, in contrast to our state\u2019s overall economic-development strategy, this company\u2019s owners have deliberately chosen to take the low road in its business practices. He also directed Iowa state agencies to prohibit Agriprocessors from listing their jobs on state job lists, and ordered his Attorney General to prosecute all violations backed by sufficient evidence.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Controversies", "sub_heading": "Comments by Iowa Governor", "_id": "46--1--6---1", "title": "Agriprocessors: Agriprocessors is a low-wage enterprise"}
{"qas": [{"question": "Why did the price of kosher meat go down so much in the past few years?", "answer": ""}, {"question": "What is the largest us producer of kosher poultry?", "answer": "Empire Kosher", "ae_score": -0.14898799521010717, "qg_score": null}, {"question": "What is the largest us producer of kosher poultry?", "answer": "Empire Kosher", "ae_score": -0.14898799521010717, "qg_score": null}], "content": "On November 5, 2008 Agriprocessor filed for Chapter 11 bankruptcy. Factors cited included a loss of most of the workforce due to the May 2008 immigration raid, declining demand for the firm's products, and increased costs in the aftermath of the raid.The Associated Press reported that \u201cAgriprocessors in its bankruptcy filing said the company owed $50 million to $100 million to creditors. The move appears to be an effort to pre-empt foreclosure by a St. Louis bank, which sued Agriprocessors for defaulting on a $35 million loan\u201d.\nIn December, the bankruptcy court approved a $2.5 million loan for Agriprocessors to allow it to resume poultry processing through at least January 9, 2009 (about 750,000 chickens). The company was run by Chapter 11 bankruptcy trustee Joseph E. Sarachek of Triax Capital Advisors.\nAgriprocessor's problems led to a shortage of kosher meat and higher prices nationwide. Empire Kosher, the largest US producer of kosher poultry, doubled its production capacity in response.\nAgriprocessors was bought at auction in July 2009 by SHF Industries, a company formed by Canadian plastics manufacturer Hershey Friedman, an observant Orthodox Jew, and his son-in-law, Daniel Hirsch. The plant has resumed business under the new name ''Agri Star Meat & Poultry, LLC''.", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Bankruptcy", "sub_heading": "Bankruptcy", "_id": "46--2---1---1", "title": "Agriprocessors Files for Chapter 11 Bankruptcy"}
{"qas": [{"question": "What is the history of the postville culture?", "answer": ""}, {"question": "What was the name of the slaughter house featured in cnn's american greed?", "answer": "The Slaughter House", "ae_score": -0.20395124423257446, "qg_score": null}, {"question": "What was the name of the slaughter house featured in cnn's american greed?", "answer": "The Slaughter House", "ae_score": -0.20395124423257446, "qg_score": null}], "content": "The town of Postville and Agriprocessors have been widely covered by the media in the USA and Israel, particularly since the ICE raid in May 2008, mostly focusing on the Jewish element. Postville and Agriprocessors are also the subject of two books, a play, documentary films and an episode of American Greed.\n''Postville: A Clash of Cultures in Heartland America'' by journalist Stephen G. Bloom, was published in 2000, the documentary film ''Postville: When Cultures Collide'' based on it was released in 2001. ''Postville U.S.A.: Surviving Diversity in Small-Town America'', written by Mark Grey and Michele Devlin, sociologists at the University of Northern Iowa, together with Aaron Goldsmith, a Lubavitcher Hasid and former member of the Postville City Council, came out in 2009, as well as the documentary film on the ICE-raid ''abUSed''. In the same year, seven men who were arrested in the raid wrote a play in Spanish, ''la Historia de Nuestras Vida'' (The Story of Our Lives) and performed it at  Lutheran churches in Decorah, IA and Minneapolis.\nOn March 23, 2011 CNBC's American Greed aired an episode related to this story entitled \"The Slaughter House\".", "page_name": "Agriprocessors", "page_id": "Agriprocessors", "heading": "Media", "sub_heading": "Media", "_id": "46--3---1---1", "title": "Postville and Agriprocessors are the subject of two books, a play,"}
{"qas": [{"question": "How did the concept of maximum sustained yield come to be?", "answer": ""}, {"question": "What percentage of north american large mammal species disappeared within 1000 years of the arrival of?", "answer": "80%", "ae_score": -0.3767611530616936, "qg_score": null}, {"question": "What percentage of north american large mammal species disappeared within 1000 years of the arrival of?", "answer": "80%", "ae_score": -0.3767611530616936, "qg_score": null}], "content": "Concern about overexploitation is relatively recent, though overexploitation itself is not a new phenomenon. It has been observed for millennia. For example, ceremonial cloaks worn by the Hawaiian kings were made from the mamo bird; a single cloak used the feathers of 70,000 birds of this now-extinct species. The dodo, a flightless bird from Mauritius, is another well-known example of overexploitation.  As with many island species, it was naive about certain predators, allowing humans to approach and kill it with ease.\nFrom the earliest of times, hunting has been an important human activity as a means of survival. There is a whole history of overexploitation in the form of overhunting. The overkill hypothesis (Quaternary extinction events) explains why the megafaunal extinctions occurred within a relatively short period of time. This can be traced with human migration. The most convincing evidence of this theory is that 80% of the North American large mammal species disappeared within 1000 years of the arrival of humans on the western hemisphere continents.  The fastest ever recorded extinction of megafauna occurred in New Zealand, where by 1500 AD, just 200 years after settling the islands, ten species of the giant moa birds were hunted to extinction by the M\u0101ori. A second wave of extinctions occurred later with European settlement.\nIn more recent times, overexploitation has resulted in the gradual emergence of the concepts of sustainability and sustainable development, which has built on other concepts, such as sustainable yield,<ref>{{cite journal |last=Larkin |first=P. A. |year=1977 |title=An epitaph for the concept of maximum sustained yield |journal=Transactions of the American Fisheries Society |volume=106 |issue=1 |pages=1\u201311 |doi=10.1577/1548-8659(1977)106\n eco-development and deep ecology.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "History", "sub_heading": "History", "_id": "47--0---1---1", "title": "Eco-development and deep ecology"}
{"qas": [{"question": "How does overexploitation lead to the destruction of resources?", "answer": ""}, {"question": "What is the name of the wild palm tree that is overharvested and over?", "answer": "footstool palm", "ae_score": -0.190155289175073, "qg_score": null}, {"question": "What is the name of the wild palm tree that is overharvested and over?", "answer": "footstool palm", "ae_score": -0.190155289175073, "qg_score": null}], "content": "Overexploitation doesn't necessarily lead to the destruction of the resource, nor is it necessarily unsustainable. However, depleting the numbers or amount of the resource can change its quality. For example, footstool palm is a wild palm tree found in Southeast Asia. Its leaves are used for thatching and food wrapping, and overharvesting has resulted in its leaf size becoming smaller.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Overview", "sub_heading": "Overview", "_id": "47--1---1---1", "title": "How Overexploitation Can Change the Quality of Food"}
{"qas": [{"question": "What is the tragedy of the commons?", "answer": ""}, {"question": "Who was the author of the 1968 article 'the tragedy of the commons'?", "answer": "Garrett Hardin", "ae_score": -0.18448046928115855, "qg_score": null}, {"question": "Who was the author of the 1968 article 'the tragedy of the commons'?", "answer": "Garrett Hardin", "ae_score": -0.18448046928115855, "qg_score": null}], "content": "The tragedy of the commons refers to a dilemma described in an article by that name written by Garrett Hardin and first published in the journal ''Science'' in 1968.\nCentral to Hardin's essay is an example which is a useful parable for understanding how overexploitation can occur. This example was first sketched in an 1833 pamphlet by William Forster Lloyd, as a hypothetical and simplified situation based on medieval land tenure in Europe, of herders sharing a common on which they are each entitled to let their cows graze. In Hardin's example, it is in each herder's interest to put each succeeding cow he acquires onto the land, even if the carrying capacity of the common is exceeded and it is temporarily or permanently damaged for all as a result. The herder receives all of the benefits from an additional cow, while the damage to the common is shared by the entire group. If all herders make this individually rational economic decision, the common will be overexploited or even destroyed to the detriment of all. However, since all herders reach the same rational conclusion, overexploitation in the form of overgrazing occurs, with immediate losses, and the pasture may be degraded to the point where it gives very little return.\nIn the course of his essay, Hardin develops the theme, drawing in many examples of latter day commons, such as national parks, the atmosphere, oceans, rivers and fish stocks. The example of fish stocks had led some to call this the \"tragedy of the fishers\". A major theme running through the essay is the growth of human populations, with the Earth's finite resources being the general common.\nThe tragedy of the commons has intellectual roots tracing back to Aristotle, who noted that \"what is common to the greatest number has the least care bestowed upon it\", as well as to Hobbes and his ''Leviathan''. The opposite situation to a tragedy of the commons is sometimes referred to as a tragedy of the anticommons: a situation in which rational individuals, acting separately, collectively waste a given resource by underutilizing it.\nThe tragedy of the commons can be avoided if it is appropriately regulated. Hardin's use of \"commons\" has frequently been misunderstood, leading Hardin to later remark that he should have titled his work \"The tragedy of the unregulated commons\".", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Tragedy of the commons", "sub_heading": "Tragedy of the commons", "_id": "47--2---1---1", "title": "The tragedy of the commons: a tragedy of the anticommons"}
{"qas": [{"question": "How is it possible for a fish to be over-harvested?", "answer": ""}, {"question": "What percentage of world fisheries are overexploited?", "answer": "25%", "ae_score": -0.27242078607054765, "qg_score": null}, {"question": "What percentage of world fisheries are overexploited?", "answer": "25%", "ae_score": -0.27242078607054765, "qg_score": null}], "content": "In wild fisheries, overexploitation or overfishing occurs when a fish stock has been fished down \"below the size that, on average, would support the long-term maximum sustainable yield of the fishery\". However, overexploitation can be sustainable.\nWhen a fishery starts harvesting fish from a previously unexploited stock, the biomass of the fish stock will decrease, since harvesting means fish are being removed. For sustainability, the rate at which the fish replenish biomass through reproduction must balance the rate at which the fish are being harvested. If the harvest rate is increased, then the stock biomass will further decrease. At a certain point, the maximum harvest yield that can be sustained will be reached, and further attempts to increase the harvest rate will result in the collapse of the fishery. This point is called the maximum sustainable yield, and in practice, usually occurs when the fishery has been fished down to about 30% of the biomass it had before harvesting started.\nIt is possible to fish the stock down further to, say, 15% of the pre-harvest biomass, and then adjust the harvest rate so the biomass remains at that level. In this case, the fishery is sustainable, but is now overexploited, because the stock has been run down to the point where the sustainable yield is less than it could be.\nFish stocks are said to \"collapse\" if their biomass declines by more than 95 percent of their maximum historical biomass. Atlantic cod stocks were severely overexploited in the 1970s and 1980s, leading to their abrupt collapse in 1992. Even though fishing has ceased, the cod stocks have failed to recover.<ref name=Frank/> The absence of cod as the apex predator in many areas has led to trophic cascades.<ref name=Frank/>\nAbout 25% of world fisheries are now overexploited to the point where their current biomass is less than the level that maximizes their sustainable yield. These depleted fisheries can often recover if fishing pressure is reduced until the stock biomass returns to the optimal biomass. At this point, harvesting can be resumed near the maximum sustainable yield.\nThe tragedy of the commons can be avoided within the context of fisheries if fishing effort and practices are regulated appropriately by fisheries management. One effective approach may be assigning some measure of ownership in the form of  individual transferable quotas (ITQs) to fishermen. In 2008, a large scale study of fisheries that used ITQs, and ones that didn't, provided strong evidence that ITQs help prevent collapses and restore fisheries that appear to be in decline.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Fisheries", "sub_heading": "Fisheries", "_id": "47--3---1---1", "title": "The tragedy of the commons \u2014 a fisheries management approach"}
{"qas": [{"question": "What is overexploitation?", "answer": ""}, {"question": "Which aquifer is an example of a natural resource that is overexploited?", "answer": "Ogallala Aquifer", "ae_score": null, "qg_score": null}, {"question": "Which aquifer is an example of a natural resource that is overexploited?", "answer": "Ogallala Aquifer", "ae_score": null, "qg_score": null}], "content": "Water resources, such as lakes and aquifers, are usually renewable resources which naturally recharge (the term fossil water is sometimes used to describe aquifers which don't recharge). Overexploitation occurs if a water resource, such as the Ogallala Aquifer, is mined or extracted at a rate that exceeds the recharge rate, that is, at a rate that exceeds the practical sustained yield. Recharge usually comes from area streams, rivers and lakes. An aquifer which has been overexploited is said to be overdrafted or depleted.  Forests enhance the recharge of aquifers in some locales, although generally forests are a major source of aquifer depletion. Depleted aquifers can become polluted with contaminants such as nitrates, or permanently damaged through subsidence or through saline intrusion from the ocean.\nThis turns much of the world's underground water and lakes into finite resources with peak usage debates similar to oil. These debates usually centre around agriculture and suburban water usage but generation of electricity from nuclear energy or coal and tar sands mining is also water resource intensive. A modified Hubbert curve applies to any resource that can be harvested faster than it can be replaced. Though Hubbert's original analysis did not apply to renewable resources, their overexploitation can result in a Hubbert-like peak. This has led to the concept of peak water.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Water resources", "sub_heading": "Water resources", "_id": "47--4---1---1", "title": "Peak Water \u2014 The Hubbert Curve"}
{"qas": [{"question": "Why are forests over overexploited?", "answer": ""}, {"question": "Which country is the most affected by overexploitation?", "answer": "Madagascar", "ae_score": null, "qg_score": null}, {"question": "Which country is the most affected by overexploitation?", "answer": "Madagascar", "ae_score": null, "qg_score": null}], "content": "Forests are overexploited when they are logged at a rate faster than reforestation takes place. Reforestation competes with other land uses such as food production, livestock grazing, and living space for further economic growth. Historically utilization of forest products, including timber and fuel wood, have played a key role in human societies, comparable to the roles of water and cultivable land. Today, developed countries continue to utilize timber for building houses, and wood pulp for paper. In developing countries almost three billion people rely on wood for heating and cooking. Short-term economic gains made by conversion of forest to agriculture, or overexploitation of wood products, typically leads to loss of long-term income and long term biological productivity. West Africa, Madagascar, Southeast Asia and many other regions have experienced lower revenue because of overexploitation and the consequent declining timber harvests.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Forest resources", "sub_heading": "Forest resources", "_id": "47--5---1---1", "title": "Overexploitation of Forests"}
{"qas": [{"question": "Why is Overexploitation such a threat to global biodiversity?", "answer": ""}, {"question": "What is one of the main threats to biodiversity?", "answer": "Overexploitation", "ae_score": -0.08172300587784466, "qg_score": null}, {"question": "What is one of the main threats to biodiversity?", "answer": "Overexploitation", "ae_score": -0.08172300587784466, "qg_score": null}], "content": "Overexploitation is one of the main threats to global biodiversity. Other threats include pollution, introduced and invasive species, habitat fragmentation, habitat destruction, uncontrolled hybridization, global warming, ocean acidification and the driver behind many of these, human overpopulation.\nOne of the key health issues associated with biodiversity is drug discovery and the availability of medicinal resources. A significant proportion of drugs are natural products derived, directly or indirectly, from biological sources. Marine ecosystems are of particular interest in this regard. However unregulated and inappropriate bioprospecting could potentially lead to overexploitation, ecosystem degradation and loss of biodiversity.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Biodiversity", "sub_heading": "Biodiversity", "_id": "47--6---1---1", "title": "Biodiversity and Bioprospecting"}
{"qas": [{"question": "What would happen if all the animals in the world suddenly disappeared?", "answer": ""}, {"question": "What is the scientific name for overexploitation?", "answer": "overexploitation", "ae_score": -0.07860184103483393, "qg_score": null}, {"question": "What is the scientific name for overexploitation?", "answer": "overexploitation", "ae_score": -0.07860184103483393, "qg_score": null}], "content": "Overexploitation threatens one-third of endangered vertebrates, as well as other groups. Excluding edible fish, the illegal trade in wildlife is valued at $10 billion per year.  Industries responsible for this include the trade in bushmeat, the trade in Chinese medicine, and the fur trade. The Convention for International Trade in Endangered Species of Wild Fauna and Flora, or CITES was set up in order to control and regulate the trade in endangered animals.  It currently protects, to a varying degree, some 33,000 species of animals and plants. It is estimated that a quarter of the endangered vertebrates in the United States of America and half of the endangered mammals is attributed to overexploitation.\nAll living organisms require resources to survive. Overexploitation of these resources for protracted periods can deplete natural stocks to the point where they are unable to recover within a short time frame. Humans have always harvested food and other resources they have needed to survive.  Human populations, historically, were small, and methods of collection limited to small quantities. With an exponential increase in human population, expanding markets and increasing demand, combined with improved access and techniques for capture, are causing the exploitation of many species beyond sustainable levels.  In practical terms, if continued, it reduces valuable resources to such low levels that their exploitation is no longer sustainable and can lead to the extinction of a species, in addition to having dramatic, unforeseen effects, on the ecosystem. Overexploitation often occurs rapidly as markets open, utilising previously untapped resources, or locally used species.\nToday, overexploitation and misuse of natural resources is an ever-present threat for species richness.  This is more prevalent when looking at island ecology and the species that inhabit them, as islands can be viewed as the world in miniature.  Island endemic populations are more prone to extinction from overexploitation, as they often exist at low densities with reduced reproductive rates.  A good example of this are island snails, such as the Hawaiian ''Achatinella'' and the French Polynesian ''Partula''.  Achatinelline snails have 15 species listed as extinct and 24 critically endangered while 60 species of partulidae are considered extinct with 14 listed as critically endangered. The WCMC have attributed over-collecting and very low lifetime fecundity for the extreme vulnerability exhibited among these species.\nAs another example, when the humble hedgehog was introduced to the Scottish island of Uist, the population greatly expanded and took to consuming and overexploiting shorebird eggs, with drastic consequences for their breeding success.  Twelve species of avifauna are affected, with some species numbers being reduced by 39%.\nWhere there is substantial human migration, civil unrest, or war, controls may no longer exist.  With civil unrest, for example in the Congo and Rwanda, firearms have become common and the breakdown of food distribution networks in such countries leaves the resources of the natural environment vulnerable.  Animals are even killed as target practice, or simply to spite the government.  Populations of large primates, such as gorillas and chimpanzees, ungulates and other mammals, may be reduced by 80% or more by hunting, and certain species may be eliminated altogether.  This decline has been called the bushmeat crisis.\nOverall, 50 bird species that have become extinct since 1500 (approximately 40% of the total) have been subject to overexploitation, including:\nOther species affected by overexploitation include: ", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Endangered species", "sub_heading": "Endangered species", "_id": "47--7---1---1", "title": "Overexploitation and the Threats to the Ecosystem"}
{"qas": [{"question": "How did the extinction of sea otters occur?", "answer": ""}, {"question": "What is it called when a species loses its apex predator?", "answer": "Overexploitation", "ae_score": -0.38189043588869537, "qg_score": null}, {"question": "What is it called when a species loses its apex predator?", "answer": "Overexploitation", "ae_score": -0.38189043588869537, "qg_score": null}], "content": "Overexploitation of species can result in knock-on or cascade effects. This can particularly apply if, through overexploitation, a habitat loses its apex predator. Because of the loss of the top predator, a dramatic increase in their prey species can occur. In turn, the unchecked prey can then overexploit their own food resources until population numbers dwindle, possibly to the point of extinction.\nA classic example of cascade effects occurred with sea otters. Starting before the 17th century and not phased out until 1911, sea otters were hunted aggressively for their exceptionally warm and valuable pelts, which could fetch up to $2500 US. This caused cascade effects through the kelp forest ecosystems along the Pacific Coast of North America.\nOne of the sea otters\u2019 primary food sources is the sea urchin. When hunters caused sea otter populations to decline, an ecological release of sea urchin populations occurred. The sea urchins then overexploited their main food source, kelp, creating urchin barrens, areas of seabed denuded of kelp, but carpeted with urchins. No longer having food to eat, the sea urchin became locally extinct as well. Also, since kelp forest ecosystems are homes to many other species, the loss of the kelp caused other cascade effects of secondary extinctions.\nIn 1911, when only one small group of 32 sea otters survived in a remote cove, an international treaty was signed to prevent further exploitation of the sea otters. Under heavy protection, the otters multiplied and repopulated the depleted areas, which slowly recovered. More recently, with declining numbers of fish stocks, again due to overexploitation, killer whales have experienced a food shortage and have been observed feeding on sea otters, again reducing their numbers.", "page_name": "Overexploitation", "page_id": "Overexploitation", "heading": "Cascade effects", "sub_heading": "Cascade effects", "_id": "47--8---1---1", "title": "Cascade Effects in the Sea Otters"}
{"qas": [{"question": "Why is it that when I listen to a song in my head, I can't hear it in my peripheral vision?", "answer": ""}, {"question": "What term is used to describe the effects that personal expectations, prejudices, and predispos?", "answer": "psychoacoustics", "ae_score": -0.33632111677963483, "qg_score": null}, {"question": "What term is used to describe the effects that personal expectations, prejudices, and predispos?", "answer": "psychoacoustics", "ae_score": -0.33632111677963483, "qg_score": null}], "content": "Hearing is not a purely mechanical phenomenon of wave propagation, but is also a sensory and perceptual event; in other words, when a person hears something, that something arrives at the ear as a mechanical sound wave traveling through the air, but within the ear it is transformed into neural action potentials. These nerve pulses then travel to the brain where they are perceived. Hence, in many problems in acoustics, such as for audio processing, it is advantageous to take into account not just the mechanics of the environment, but also the fact that both the ear and the brain are involved in a person\u2019s listening experience.\nThe inner ear, for example, does significant signal processing in converting sound waveforms into neural stimuli, so certain differences between waveforms may be imperceptible.   Data compression techniques, such as MP3, make use of this fact. In addition, the ear has a nonlinear response to sounds of different intensity levels; this nonlinear response is called loudness. Telephone networks and audio noise reduction systems make use of this fact by nonlinearly compressing data samples before transmission, and then expanding them for playback.    Another effect of the ear's nonlinear response is that sounds that are close in frequency produce phantom beat notes, or intermodulation distortion products.\nThe term \"psychoacoustics\" also arises in discussions about cognitive psychology and the effects that personal expectations, prejudices, and predispositions may have on listeners' relative evaluations and comparisons of sonic aesthetics and acuity and on listeners' varying determinations about the relative qualities of various musical instruments and performers. The expression that one \"hears what one wants (or expects) to hear\" may pertain in such discussions.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Background", "sub_heading": "Background", "_id": "48--0---1---1", "title": "Hearing is not a mechanical phenomenon of wave propagation; it is a sensory and per"}
{"qas": [{"question": "What is happening when I hear a beat in my ear?", "answer": ""}, {"question": "What were the robinson-dadson curves standardized as in 1986?", "answer": "ISO 226", "ae_score": -0.2610475143093463, "qg_score": null}, {"question": "What were the robinson-dadson curves standardized as in 1986?", "answer": "ISO 226", "ae_score": -0.2610475143093463, "qg_score": null}], "content": "The human ear can nominally hear sounds in the range 20 Hz (0.02 kHz) to 20,000 Hz (20 kHz).  The upper limit tends to decrease with age; most adults are unable to hear above 16 kHz. The lowest frequency that has been identified as a musical tone is 12 Hz under ideal laboratory conditions.<ref name=Olson/> Tones between 4 and 16 Hz can be perceived via the body's sense of touch.\nFrequency resolution of the ear is 3.6 Hz within the octave of 1000 \u2013 2000 Hz.  That is, changes in pitch larger than 3.6 Hz can be perceived in a clinical setting. However, even smaller pitch differences can be perceived through other means. For example, the interference of two pitches can often be heard as a repetitive variation in volume of the tone. This amplitude modulation occurs with a frequency equal to the difference in frequencies of the two tones and is known as beating.\nThe semitone scale used in Western musical notation is not a linear frequency scale but logarithmic. Other scales have been derived directly from experiments on human hearing perception, such as the mel scale and Bark scale (these are used in studying perception, but not usually in musical composition), and these are approximately logarithmic in frequency at the high-frequency end, but nearly linear at the low-frequency end.\nThe intensity range of audible sounds is enormous. Human ear drums are sensitive to variations in the sound pressure, and can detect pressure changes from as small as a few micropascals to greater than 1 bar.  For this reason, sound pressure level is also measured logarithmically, with all pressures referenced to 20 \u00b5Pa (or 1.97385\u00d710 atm). The lower limit of audibility is therefore defined as 0 dB, but the upper limit is not as clearly defined. The upper limit is more a question of the limit where the ear will be physically harmed or with the potential to cause noise-induced hearing loss.\nA more rigorous exploration of the lower limits of audibility determines that the minimum threshold at which a sound can be heard is frequency dependent.  By measuring this minimum intensity for testing tones of various frequencies, a frequency dependent absolute threshold of hearing (ATH) curve may be derived.  Typically, the ear shows a peak of sensitivity (i.e., its lowest ATH) between 1\u20135 kHz, though the threshold changes with age, with older ears showing decreased sensitivity above 2 kHz.\nThe ATH is the lowest of the equal-loudness contours. Equal-loudness contours indicate the sound pressure level (dB SPL), over the range of audible frequencies, that are perceived as being of equal loudness.  Equal-loudness contours were first measured by Fletcher and Munson at Bell Labs in 1933 using pure tones reproduced via headphones, and the data they collected are called Fletcher\u2013Munson curves.  Because subjective loudness was difficult to measure, the Fletcher\u2013Munson curves were averaged over many subjects.\nRobinson and Dadson refined the process in 1956 to obtain a new set of equal-loudness curves for a frontal sound source measured in an anechoic chamber. The Robinson-Dadson curves were standardized as ISO 226 in 1986. In 2003, ISO 226 was revised as equal-loudness contour using data collected from 12 international studies.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Limits of perception", "sub_heading": "Limits of perception", "_id": "48--1---1---1", "title": "The Human Ear \u2014 The Equal-Loudness Curve"}
{"qas": [{"question": "How does the human ear \"localize\" sound?", "answer": ""}, {"question": "What is the process of determining the location of a sound source?", "answer": "Sound localization", "ae_score": -0.40680848946075016, "qg_score": null}, {"question": "What is the process of determining the location of a sound source?", "answer": "Sound localization", "ae_score": -0.40680848946075016, "qg_score": null}], "content": "Sound localization is the process of determining the location of a sound source. The brain utilizes subtle differences in loudness, tone and timing between the two ears to allow us to localize sound sources. Localization can be described in terms of three-dimensional position: the azimuth or horizontal angle, the zenith or vertical angle, and the distance (for static sounds) or velocity (for moving sounds). Humans, as most four-legged animals, are adept at detecting direction in the horizontal, but less so in the vertical due to the ears being placed symmetrically. Some species of owls have their ears placed asymmetrically, and can detect sound in all three planes, an adaption to hunt small mammals in the dark.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Sound localization", "sub_heading": "Sound localization", "_id": "48--2---1---1", "title": "Sound Localization in the Human Brain"}
{"qas": [{"question": "What is a masking effect and how does it work?", "answer": ""}, {"question": "What type of masking is weaker than forward masking?", "answer": "backward masking", "ae_score": -2.0010173897936925, "qg_score": null}, {"question": "What type of masking is weaker than forward masking?", "answer": "backward masking", "ae_score": -2.0010173897936925, "qg_score": null}], "content": "Suppose a listener cannot hear a given acoustical signal under silent condition. When a signal is playing while another sound is being played (a masker) the signal has to be stronger for the listener to hear it. The masker does not need to have the frequency components of the original signal for masking to happen. A masked signal can be heard even though it is weaker than the masker. Masking happens when a signal and a masker are played together. It also happens when a masker starts after a signal stops playing. The effects of backward masking is weaker than forward masking. The masking effect has been widely used in psychoacoustical research. With masking you can change the levels of the masker and measure the threshold, then create a diagram of a psychophysical tuning curve that will reveal similar features. Masking effects are also used for audio encoding. The masking effect is used in lossy encoders. It can eliminate some of the weaker sounds, so the listener can not hear the difference. This technique has been used in MP3's.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Masking effects", "sub_heading": "Masking effects", "_id": "48--3---1---1", "title": "Masking Effects in Audio Encoders"}
{"qas": [{"question": "Why does the sound of nails on a chalkboard sound so loud in a quiet library?", "answer": ""}, {"question": "What is the study of the ear's limitations?", "answer": "Psychoacoustics", "ae_score": -0.9264440244581226, "qg_score": null}, {"question": "What is the study of the ear's limitations?", "answer": "Psychoacoustics", "ae_score": -0.9264440244581226, "qg_score": null}], "content": "The psychoacoustic model provides for high quality lossy signal compression by describing which parts of a given digital audio signal can be removed (or aggressively compressed) safely\u2014that is, without significant losses in the (consciously) perceived quality of the sound.\nIt can explain how a sharp clap of the hands might seem painfully loud in a quiet library, but is hardly noticeable after a car backfires on a busy, urban street.  This provides great benefit to the overall compression ratio, and psychoacoustic analysis routinely leads to compressed music files that are 1/10th to 1/12th the size of high quality masters, but with discernibly less proportional quality loss. Such compression is a feature of nearly all modern lossy audio compression formats. Some of these formats include Dolby Digital (AC-3), MP3, Opus, Ogg Vorbis, AAC, WMA, MPEG-1 Layer II (used for digital audio broadcasting in several countries) and ATRAC, the compression used in MiniDisc and some Walkman models.\nPsychoacoustics is based heavily on human anatomy, especially the ear's limitations in perceiving sound as outlined previously.  To summarize, these limitations are:\nGiven that the ear will not be at peak perceptive capacity when dealing with these limitations, a compression algorithm can assign a lower priority to sounds outside the range of human hearing.  By carefully shifting bits away from the unimportant components and toward the important ones, the algorithm ensures that the sounds a listener is most likely to perceive are of the highest quality.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Software", "sub_heading": "Software", "_id": "48--5---1---1", "title": "Psychoacoustic Analysis: The Human Ear's Limitations in Perception"}
{"qas": [{"question": "Why are there so many different types of music?", "answer": ""}, {"question": "What is the name of the field of music psychology and music therapy?", "answer": "Psychoacoustics", "ae_score": -0.34029139630594263, "qg_score": null}, {"question": "What is the name of the field of music psychology and music therapy?", "answer": "Psychoacoustics", "ae_score": -0.34029139630594263, "qg_score": null}], "content": "Psychoacoustics includes topics and studies that are relevant to music psychology and music therapy. Theorists such as Benjamin Boretz consider some of the results of psychoacoustics to be meaningful only in a musical context.\nIrv Teibel's ''Environments series'' LPs (1969\u201379) are an early example of commercially available sounds released expressly for enhancing psychological abilities.", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Music", "sub_heading": "Music", "_id": "48--6---1---1", "title": "Psychoacoustics and Music Therapy"}
{"qas": [{"question": "Why is it that when I'm listening to music, I can sometimes hear my own voice in my head, but when I listen to a song I can't?", "answer": ""}, {"question": "Which field of acoustics has had a symbiotic relationship with computer science, computer?", "answer": "Psychoacoustics", "ae_score": -0.8911671187438316, "qg_score": null}, {"question": "Which field of acoustics has had a symbiotic relationship with computer science, computer?", "answer": "Psychoacoustics", "ae_score": -0.8911671187438316, "qg_score": null}], "content": "Psychoacoustics has long enjoyed a symbiotic relationship with computer science, computer engineering, and computer networking. Internet pioneers J. C. R. Licklider and Bob Taylor both completed graduate-level work in psychoacoustics, while BBN Technologies originally specialized in consulting on acoustics issues before it began building the first packet-switched computer networks.\nLicklider wrote a paper entitled \"A duplex theory of pitch perception\".\nPsychoacoustics is applied within many fields from software development, where developers map proven and experimental mathematical patterns; in digital signal processing, where many audio compression codecs such as MP3 and Opus use a psychoacoustic model to increase compression ratios; in the design of (high end) audio systems for accurate reproduction of music in theatres and homes; as well as defense systems where scientists have experimented with limited success in creating new acoustic weapons, which emit frequencies that may impair, harm, or kill. It is also applied today within music, where musicians and artists continue to create new auditory experiences by masking unwanted frequencies of instruments, causing other frequencies to be enhanced. Yet another application is in the design of small or lower-quality loudspeakers, which can use the phenomenon of missing fundamentals to give the effect of bass notes at lower frequencies than the loudspeakers are physically able to produce (see references).", "page_name": "Psychoacoustics", "page_id": "Psychoacoustics", "heading": "Applied psychoacoustics", "sub_heading": "Applied psychoacoustics", "_id": "48--7---1---1", "title": "Psychoacoustics and Computer Science \u2014 Part 1"}
{"qas": [{"question": "Why are there so many different types of moles in Mexico?", "answer": ""}, {"question": "Who invented the dish of mole sauce?", "answer": "monk Fray Pascual", "ae_score": -0.4303643758531027, "qg_score": null}, {"question": "Who invented the dish of mole sauce?", "answer": "monk Fray Pascual", "ae_score": -0.4303643758531027, "qg_score": null}], "content": "Three states in Mexico claim to be the origin of mole: Puebla, Oaxaca, and Tlaxcala. The states with the best known moles are Puebla and Oaxaca, but other regions in Mexico also make various types of mole sauces.\nMoles come in various flavors and ingredients, with chili peppers as the common factor. However, the classic mole version is the variety called ''mole poblano'', which is a dark red or brown sauce served over meat. The dish has become a culinary symbol of Mexico\u2019s mestizaje, or mixed indigenous and European heritage, both for the types of ingredients it contains, as well as the legends surrounding its origin.\nA common legend of its creation takes place at the Convent of Santa Rosa in Puebla early in the colonial period. Upon hearing that the archbishop was going to visit, the convent nuns went into a panic because they were poor and had almost nothing to prepare. The nuns prayed and brought together the little bits of what they did have, including chili peppers, spices, day-old bread, nuts, and a little chocolate. They killed an old turkey, cooked it and put the sauce on top; the archbishop loved it. When one of the nuns was asked the name of the dish, she replied, \"I made a mole.\" ''Mole'' was the ancient word for mix; now this word mostly refers to the dish, and is rarely used to signify other kinds of mixes in Spanish.\nA similar version of the story says that monk Fray Pascual invented the dish, again to serve the archbishop of Puebla. In this version, spices were knocked over or blown over into pots in which turkeys were cooking. Other versions of the story substitute the viceroy of New Spain, such as Juan de Palafox y Mendoza in place of the archbishop.\nModern mole is a mixture of ingredients from North America, Europe and Africa, making it the first international dish created in the Americas. Its base, however, is indigenous. Nahuatl speakers had a preparation they called ''m\u014dlli'' (), meaning \"sauce\", or ''ch\u012blm\u014dlli'' () for chili sauce. In the book ''General History of the Things of New Spain'', Bernardino de Sahag\u00fan says that mollis were used in a number of dishes, including those for fish, game and vegetables. Theories about the origins of mole have supposed that it was something imposed upon the natives or that it was the product of the baroque artistry of Puebla, but there is not enough evidence for definitive answers. Coincidence or not, the word \"m\u014dlli\" seems to resemble the Portuguese word ''molho'', which means \"sauce\". \nWhile chili pepper sauces existed in pre-Hispanic Mexico, the complicated moles of today did not. They did not contain chocolate, which was used as a beverage, and in all of the writings of Sahag\u00fan, there is no mention at all of it being used to flavor food. Most likely what occurred was a gradual modification of the original molli sauce, adding more and different ingredients depending on the location. This diversified the resulting sauces into various types. Ingredients that have been added into moles include nuts (such as almonds, peanuts, or pine nuts), seeds (such as sesame seeds, pumpkin seeds, or squash seeds), cilantro, seedless grapes, plantains, garlic, onions, cinnamon, and chocolate. What remained the same was the use of chili peppers, especially ancho, pasilla, mulato and chipotle, and the consistency of the sauce. The true story of how mole developed may never be truly known, as the first recipes did not appear until after the Mexican War of Independence in 1810. The Nahuatl origin of the name probably defines its Mesoamerican origin.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "History", "sub_heading": "History", "_id": "49--0---1---1", "title": "The Origin of Mole in Mexico"}
{"qas": [{"question": "Why is leftover mole sauce so much better than pre-made mole sauce?", "answer": ""}, {"question": "Who makes mole poblano sauce in mexico?", "answer": "Patricia Quintana", "ae_score": -0.3957844456139615, "qg_score": null}, {"question": "Who makes mole poblano sauce in mexico?", "answer": "Patricia Quintana", "ae_score": -0.3957844456139615, "qg_score": null}], "content": "All mole preparations begin with one or more types of chili pepper. The classic moles of Central Mexico and Oaxaca, such as ''mole poblano'' and ''mole negro'', include two or more of the following types of chili pepper: ancho, pasilla, mulato and chipotle. Other ingredients can include black pepper, ''achiote'', ''guaje'' (''Leucaena leucocephala''), cumin, cloves, anise, tomatoes, tomatillos, garlic, sesame seeds, dried fruit, ''hoja santa'', and many others. ''Mole poblano'' has an average of 20 ingredients; mole almendrado has an average of 26, and Oaxacan moles can have over 30. Chocolate, if used, is added at the end of cooking. According to Rick Bayless, the ingredients of mole can be grouped into five distinct classes: chiles, sour (tomatillos), sweet (dried fruits and sugar), spices, and thickeners (nuts and tortillas).\nThe ingredients are roasted and ground into a fine powder or paste. This roasting and grinding process is extremely laborious and takes at least a day to accomplish by hand. Traditionally, this work was shared by several generations of women in the family, but after the arrival of electric mills, it became more common to take the ingredients to be ground. Many families have their own varieties of mole passed down for generations, with their preparation reserved for special events in large batches.\nThe resulting powder or paste is mixed with water, or more often broth, and simmered until it is pungent and very thick. It is most often prepared in a ''cazuela'' () or a thick heavy clay cauldron and stirred almost constantly to prevent burning. The thickness of the sauce has prompted some, such as Mexican-food authority Patricia Quintana, to claim it is too substantial to be called a sauce. However, like a sauce, it is always served over something and never eaten alone. ''Mole poblano'' is most traditionally served with turkey, but it and many others are also served with chicken, pork, or other meats (such as lamb).\nA number of mole powders and pastes can be prepared ahead of time and sold, such as ''mole poblano'', ''mole negro'', and ''mole colorado''. Many markets in Mexico sell mole pastes and powders in packages or by the kilogram. These mole mixes are heavy with a strong odor, so much so that security agents at the Mexico City airport once admitted that mole can register a positive when they check for explosives.\nPrepared mole sauce will keep for about three days in the refrigerator and it freezes well. The paste will keep six months in the refrigerator and about a year in the freezer. Leftover sauce is often used for the making of tamales and enchiladas (often called ''enmoladas'') or over eggs at brunch.\nThe term mole is most often associated with thick, dark, brownish-red sauces, but the term is really more general than that. Mole can be anything from dark and thick to soup-like and bright green, with red, yellow and black moles each claiming fans in different regions.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "Preparation and consumption", "sub_heading": "Preparation and consumption", "_id": "49--1---1---1", "title": "Mole Poblano Mole Colorado "}
{"qas": [{"question": "Why is mole poblano so popular in Mexico?", "answer": ""}, {"question": "What is the best known mole sauce in mexico?", "answer": "Mole poblano", "ae_score": -0.4827056182004587, "qg_score": null}, {"question": "What is the best known mole sauce in mexico?", "answer": "Mole poblano", "ae_score": -0.4827056182004587, "qg_score": null}], "content": "''Mole poblano'' is the best known of all mole varieties and has been ranked as number one of \"typical\" Mexican dishes. It has also been called the \"national dish\" of Mexico. The state of Puebla is identified with ''mole poblano''. ''Mole poblano'' has been described as an ancient dish.\n''Mole poblano'' contains about 20 ingredients, including chili peppers and chocolate, which works to counteract the heat of the chili peppers, but the chocolate does not dominate. It helps give the sauce its dark color, but this is also provided by the mulato peppers. This sauce is most often served over turkey at weddings, birthdays and baptisms, or at Christmas with ''romero'' over shrimp cakes. The sauce is also served with chicken, pork, or other meats. Another time when the sauce is prominent is Cinco de Mayo. While this holiday is not celebrated much in the rest of Mexico, it is a major celebration in Puebla.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "Varieties", "sub_heading": "Varieties", "_id": "49--2--0---1", "title": "''Mole Poblano'' is the most famous Mexican dish"}
{"qas": [{"question": "What is the difference between moles and mole verde?", "answer": ""}, {"question": "What kind of food is mancha manteles?", "answer": "chicken and fruit stew", "ae_score": -0.8230008599451777, "qg_score": null}, {"question": "What kind of food is mancha manteles?", "answer": "chicken and fruit stew", "ae_score": -0.8230008599451777, "qg_score": null}], "content": "The state of Oaxaca is large and very mountainous with various indigenous ethnicities and microclimates, making for a number of regional variations in the food. The state is called \"the land of the seven moles\", with these being named ''mole negro, colorado, amarillo, verde, chichilo, coloradito'', and ''mancha manteles'' (or tablecloth stainer), all differently colored and flavored, based on the use of distinctive chilis and herbs. The last, ''mancha manteles'', is really just a chicken and fruit stew, and although Oaxaca claims it as the seventh mole, some, such as Susan Trilling in her book ''My Search for the Seventh Mole: A Story with Recipes from Oaxaca, Mexico'', question whether it is a true mole. In addition, those from Puebla claim this dish as their own.\nThe best known of Oaxaca's moles is ''mole negro'', which is darker than ''mole poblano'' and just as thick and rich. It also includes chocolate, as well as chili peppers, onions, garlic and more, but what makes it distinct is the addition of a plant called ''hoja santa''. It is the most complex and difficult to make of the sauces. ''Mole coloradito'' is another popular preparation, often simplified and sold as an enchilada sauce. ''Mole verde'' is always made fresh with herbs native to the region.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "Varieties", "sub_heading": "Oaxaca", "_id": "49--2--1---1", "title": "Oaxaca, Mexico: The Land of the Seventh Mole"}
{"qas": [{"question": "How did San Pedro Atocpan become so successful?", "answer": ""}, {"question": "What percentage of mole is produced in mexico?", "answer": "60%", "ae_score": -0.4816167250638803, "qg_score": null}, {"question": "What percentage of mole is produced in mexico?", "answer": "60%", "ae_score": -0.4816167250638803, "qg_score": null}], "content": "Until the mid-20th century, San Pedro Atocpan, located in the mountains south of Mexico City proper (but still part of the Federal District) was similar to the other agricultural communities surrounding it, growing corn, fava beans and ''nopales'' (prickly pear cactus). Electricity and other modern conveniences arrived late, allowing the community to retain more of its traditions later.In 1940, Father Damian Sartes San Roman came to the parish of San Pedro Atocpan and saw the potential in marketing the product to raise living standards in the area. At that time, only four neighborhoods prepared mole for town festivals: Panchimalco, Ocotitla, Nuztla and Tula, but those who prepared it were generally prominent women in their communities. In the 1940s, one family made the long trek to Mexico City proper to sell some of their mole at the La Merced Market. It was successful, but they brought with them only two kilograms since it was made by hand grinding the ingredients on a ''metate''. The arrival of electricity in the late 1940s made the use of a powered mill possible, and better roads made the trek to the city easier. Some of these mills were bought or financed by Father Sartes, but the mole was still cooked in a clay pot over a wood fire. In the 1970s, he was part of a small group which became a cooperative, which constructed the Las Cazuelas restaurant. This is where the first Mole Exhibition was held in 1978.\nThe care and tradition that went into the moles from there made them popular and made the town famous in the Mexico City area. Today, San Pedro Atocpan produces 60% of the moles consumed in Mexico and 89% of the moles consumed in Mexico City, with a total estimated production of between 28,000 and 30,000 tons each year. Ninety-two percent of the town's population makes a living preparing mole powders and pastes, all in family businesses. Prices for mole run between 80 and 160 pesos per kilogram, depending on the maker and the type. A number of moles are made in the town, but ''mole almendrado'' (mole with almonds) is signature to the area. Producers in Atocpan have their own versions of the various types of mole, often keeping recipes strictly secret. The production in the town has become very competitive, especially in quality. Twenty-two brands are permitted to print \"Made in San Pedro Atocpan\" on their labels.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "Varieties", "sub_heading": "San Pedro Atocpan", "_id": "49--2--2---1", "title": "San Pedro Atocpan \u2014 A History of Moles"}
{"qas": [{"question": "Why are there so many variations of moles in Mexico?", "answer": ""}, {"question": "When do you eat mole sauce in mexico?", "answer": "celebrations", "ae_score": -0.3317455049271181, "qg_score": null}, {"question": "When do you eat mole sauce in mexico?", "answer": "celebrations", "ae_score": -0.3317455049271181, "qg_score": null}], "content": "Mole is one of the most representative dishes of Mexico, especially for major celebrations. Ninety-nine percent of Mexicans have tried at least one type of mole. The dish enjoys its greatest popularity in central and southern Mexico, but simpler versions of ''mole poblano'' did make their way north. However, northern versions are far less complex and generally used to make enchiladas.\nThe consumption of mole is strongly associated with celebrations. In Mexico, to say \"to go to a mole\" (ir a un mole) means to go to a wedding. Mole has a strong flavor, especially the dark ones and is considered to be an acquired taste for most. This has spawned another saying, \"en su mero mole\", which means something like \"one's cup of tea\".\nTo promote their regional versions of the sauce, a number of places host festivals dedicated to it. The ''Feria Nacional del Mole'' (National Festival of Mole) was begun in 1977 in San Pedro Atocpan, and is held each year in October. It began outside the town, in the small community of Yenhuitlalpan, in May. The four restaurants there decided to take advantage of the festival of the ''Se\u00f1or de las Misericordias'' (Lord of the Mercies) to promote their moles. Despite their success, a number in the village did not like that they were using a religious festival for commercial ends, so a separate mole festival was created for October.  Today, 37 restaurants and mole producers participate in the event. The most popular variety is the ''mole almendrado''. Originally, the October version of the fair was held in the town proper, but after it became too big, it was moved to prepared fairgrounds outside along the highway.\nThe city of Puebla also holds an annual mole festival, whose proceeds are shared among the Santa Rosa, Santa In\u00e9s and Santa Catarina convents. The world's record for the largest pot of mole was broken at the city's 2005 festival. The pot was 1.4 meters in diameter at the base, 1.9 meters high, with a diameter of 2.5 meters at the top. Four hundred people participated in its preparation, using 800 kilos of mole paste, 2,500 kilos of chicken, 500 kilos of tortillas and 1,600 kilos of broth. The resulting food fed 11,000 people.\nThe women of Santa Mar\u00eda Magdalena in Quer\u00e9taro have been locally known for their mole for about 100 years. In 1993, they decided to hold a contest for the best mole.  This was the beginning of the ''Feria del Mole y Tortilla'' (Mole and Tortilla Festival), which has been held every year since then. It still features a mole cook-off and attracts hundreds of visitors from the state. The community of Coatepec de Morelos in the municipality of Zit\u00e1cuaro, Michoac\u00e1n, holds an annual ''Feria de Mole'' in April.\nMole has become a popular and widely available prepared food product in the United States. Several brands of mole paste are available in the United States and can be found online. Chicago has an annual mole festival for Mexican immigrants at the Universidad Popular community center. The event is a cooking contest, which had over 40 entries, with the winner taking away US$500.\nWhile mole has traditionally been eaten by all levels of Mexican society, especially at celebrations, the upper classes have begun to stop preparing and consuming the dish. According to one survey of upper-class housewives between 30 and 50 years of age, 95% had never cooked it from scratch. They had only eaten it at home at their children's requests after hearing about it. This is in contrast to their mothers and grandmothers for whom mole symbolized being Mexican. The dish is being less seen in the traditional celebrations, as well. The problem is that those in this stratum of society have come to prefer foreign foods. The owners of La California, a mole producer in Guanajuato, state it is harder to market regional mole in Mexico than in the exterior. They say that many in Mexico do not consider it a gourmet product, or something that can be consumed with wine. In Mexico, the preferences of the upper classes are often eventually copied in the lower classes. Some people, such as Lula Bertr\u00e1n of the C\u00edrculo Mexicano de Arte Culinario, see this as a warning sign for the dish.", "page_name": "Mole sauce", "page_id": "Mole%20sauce", "heading": "Popularity", "sub_heading": "Popularity", "_id": "49--3---1---1", "title": "Why Mexicans are not eating mole at celebrations"}
{"qas": [{"question": "Why is corona discharge used to remove particles from aerosol cans?", "answer": ""}, {"question": "Who invented the first electrostatic precipitator in 1824?", "answer": "Hohlfeld", "ae_score": -0.19851452014803503, "qg_score": null}, {"question": "Who invented the first electrostatic precipitator in 1824?", "answer": "Hohlfeld", "ae_score": -0.19851452014803503, "qg_score": null}], "content": "The first use of corona discharge to remove particles from an aerosol was by Hohlfeld in 1824. However, it was not commercialized until almost a century later.\nIn 1907 Frederick Gardner Cottrell, a professor of chemistry at the University of California, Berkeley, applied for a patent on a device for charging particles and then collecting them through electrostatic attraction\u2014the first electrostatic precipitator. Cottrell first applied the device to the collection of sulphuric acid mist and lead oxide fumes emitted from various acid-making and smelting activities. Wine-producing vineyards in northern California were being adversely affected by the lead emissions.\nAt the time of Cottrell's invention, the theoretical basis for operation was not understood. The operational theory was developed later in Germany, with the work of Walter Deutsch and the formation of the Lurgi company.\nCottrell used proceeds from his invention to fund scientific research through the creation of a foundation called Research Corporation in 1912, to which he assigned the patents. The intent of the organization was to bring inventions made by educators (such as Cottrell) into the commercial world for the benefit of society at large. The operation of Research Corporation is funded by royalties paid by commercial firms after commercialization occurs. Research Corporation has provided vital funding to many scientific projects: Goddard's rocketry experiments, Lawrence's cyclotron, production methods for vitamins A and B, among many others.\nBy a decision of the US Supreme Court, the Corporation had to be split into several entities. The Research Corporation was separated from two commercial firms making the hardware: Research-Cottrell Inc. (operating east of the Mississippi River) and Western Precipitation (operating in the western states). The Research Corporation continues to be active to this day, and the two companies formed to commercialize the invention for industrial and utility applications are still in business as well.\nElectrophoresis is the term used for migration of gas-suspended charged particles in a direct-current electrostatic field. Traditional CRT television sets tend to accumulate dust on the screen because of this phenomenon (a CRT is a direct-current machine operating at about 35 kilovolts).", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Invention of the electrostatic precipitator", "sub_heading": "Invention of the electrostatic precipitator", "_id": "50--0---1---1", "title": "The Origins of Electrophoresis"}
{"qas": [{"question": "How does an electric circuit work?", "answer": ""}, {"question": "Where do the ionized particles go in a precipitator?", "answer": "grounded plates", "ae_score": -0.6646509666110321, "qg_score": null}, {"question": "Where do the ionized particles go in a precipitator?", "answer": "grounded plates", "ae_score": -0.6646509666110321, "qg_score": null}], "content": "The most basic precipitator contains a row of thin vertical wires, and followed by a stack of large flat metal plates oriented vertically, with the plates typically spaced about 1 cm to 18 cm apart, depending on the application. The air stream flows horizontally through the spaces between the wires, and then passes through the stack of plates.\nA negative voltage of several thousand volts is applied between wire and plate. If the applied voltage is high enough, an electric corona discharge ionizes the air around the electrodes, which then ionizes the particles in the air stream.\nThe ionized particles, due to the electrostatic force, are diverted towards the grounded plates. Particles build up on the collection plates and are removed from the air stream.\nA two-stage design (separate charging section ahead of collecting section) has the benefit of minimizing ozone production, which would adversely affect health of personnel working in enclosed spaces. For shipboard engine rooms where gearboxes generate an oil mist, two-stage ESP's are used to clean the air, improving the operating environment and preventing buildup of flammable oil fog accumulations. Collected oil is returned to the gear lubricating system.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Plate precipitator", "sub_heading": "Plate precipitator", "_id": "50--1---1---1", "title": "Precipitation Systems for Shipboard Engines"}
{"qas": [{"question": "Why does dust create a strong electric field?", "answer": ""}, {"question": "What is the maximum voltage of an electrostatic precipitator?", "answer": "10,000 volts", "ae_score": -0.5709153888679606, "qg_score": null}, {"question": "What is the maximum voltage of an electrostatic precipitator?", "answer": "10,000 volts", "ae_score": -0.5709153888679606, "qg_score": null}], "content": "resistance affects electrical conditions in the dust layer by a potential electric field (voltage drop) being formed across the layer as negatively charged particles arrive at its surface and leak their electrical charges to the collection plate. At the metal surface of the electrically grounded collection plate, the voltage is zero, whereas at the outer surface of the dust layer, where new particles and ions are arriving, the electrostatic voltage caused by the gas ions can be quite high. The strength of this electric field depends on the resistance and thickness of the dust layer.\nIn high-resistance dust layers, the dust is not sufficiently conductive, so electrical charges have difficulty moving through the dust layer. Consequently, electrical charges accumulate on and beneath the dust layer surface, creating a strong electric field.\nVoltages can be greater than 10,000 volts. Dust particles with high resistance are held too strongly to the plate, making them difficult to remove and causing rapping problems.\nIn low resistance dust layers, the corona current is readily passed to the grounded collection electrode. Therefore, a relatively weak electric field, of several thousand volts, is maintained across the dust layer. Collected dust particles with low resistance do not adhere strongly enough to the collection plate. They are easily dislodged and become retained in the gas stream.\nThe electrical conductivity of a bulk layer of particles depends on both surface and volume factors.  Volume conduction, or the motions of electrical charges through the interiors of particles, depends mainly on the composition and temperature of the particles.  In the higher temperature regions, above 500 \u00b0F, volume conduction controls the conduction mechanism.  Volume conduction also involves ancillary factors, such as compression of the particle layer, particle size and shape, and surface properties.\nVolume conduction is represented in the figures as a straight-line at temperatures above 500 \u00b0F.  At temperatures below about 450 \u00b0F, electrical charges begin to flow across surface moisture and chemical films adsorbed onto the particles.  Surface conduction begins to lower the resistivity values and bend the curve downward at temperatures below 500 \u00b0F.\nThese films usually differ both physically and chemically from the interiors of the particles owing to adsorption phenomena.  Theoretical calculations indicate that moisture films only a few molecules thick are adequate to provide the desired surface conductivity.  Surface conduction on particles is closely related to surface-leakage currents occurring on electrical insulators, which have been extensively studied.  An interesting practical application of surface-leakage is the determination of dew point by measurement of the current between adjacent electrodes mounted on a glass surface.  A sharp rise in current signals the formation of a moisture film on the glass.  This method has been used effectively for determining the marked rise in dew point, which occurs when small amounts of sulfuric acid vapor are added to an atmosphere (commercial Dewpoint Meters are available on the market).\nThe following discussion of normal, high, and low resistance applies to ESPs operated in a dry state; resistance is not a problem in the operation of wet ESPs because of the moisture concentration in the ESP. The relationship between moisture content and resistance is explained later in this work.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Collection efficiency (''R'')", "sub_heading": "Collection efficiency (''R'')", "_id": "50--2--0---1", "title": "The Effects of Surface Conduction on Dust Layers"}
{"qas": [{"question": "How do dust collection plates work?", "answer": ""}, {"question": "What type of dust is used in electrostatic precipitator?", "answer": "fly ash", "ae_score": -0.35562928832287727, "qg_score": null}, {"question": "What type of dust is used in electrostatic precipitator?", "answer": "fly ash", "ae_score": -0.35562928832287727, "qg_score": null}], "content": "As stated above, ESPs work best under normal resistivity conditions. Particles with normal resistivity do not rapidly lose their charge on arrival at the collection electrode. These particles slowly leak their charge to grounded plates and are retained on the collection plates by intermolecular adhesive and cohesive forces. This allows a particulate layer to be built up and then dislodged from the plates by rapping. Within the range of normal dust resistivity (between 10 and 2 x 10 ohm-cm), fly ash is collected more easily than dust having either low or high resistivity.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Collection efficiency (''R'')", "sub_heading": "Normal resistivity", "_id": "50--2--1---1", "title": "ESPs work best under normal dust resistivity conditions"}
{"qas": [{"question": "Why is it that when I take a picture of a fly ash, it looks like it's coming from a different direction than it actually is?", "answer": ""}, {"question": "What is the name of the dust layer of electrostatic precipitator?", "answer": "back corona", "ae_score": -0.25262383182034803, "qg_score": null}, {"question": "What is the name of the dust layer of electrostatic precipitator?", "answer": "back corona", "ae_score": -0.25262383182034803, "qg_score": null}], "content": "If the voltage drop across the dust layer becomes too high, several adverse effects can occur. First, the high voltage drop reduces the voltage difference between the discharge electrode and collection electrode, and thereby reduces the electrostatic field strength used to drive the gas ion-charged particles over to the collected dust layer.  As the dust layer builds up, and the electrical charges accumulate on the surface of the dust layer, the voltage difference between the discharge and collection electrodes decreases. The migration velocities of small particles are especially affected by the reduced electric field strength.\nAnother problem that occurs with high resistivity dust layers is called back corona.  This occurs when the potential drop across the dust layer is so great that corona discharges begin to appear in the gas that is trapped within the dust layer. The dust layer breaks down electrically, producing small holes or craters from which back corona discharges occur. Positive gas ions are generated within the dust layer and are accelerated toward the \"negatively charged\" discharge electrode. The positive ions reduce some of the negative charges on the dust layer and neutralize some of the negative ions on the \"charged particles\" heading toward the collection electrode. Disruptions of the normal corona process greatly reduce the ESP's collection efficiency, which in severe cases, may fall below 50% .  When back corona is present, the dust particles build up on the electrodes forming a layer of insulation.  Often this can not be repaired without bringing the unit offline.\nThe third, and generally most common problem with high resistivity dust is increased electrical sparking. When the sparking rate exceeds the \"set spark rate limit,\" the automatic controllers limit the operating voltage of the field. This causes reduced particle charging and reduced migration velocities toward the collection electrode. High resistivity can generally be reduced by doing the following:\nThin dust layers and high-resistivity dust especially favor the formation of back corona craters.  Severe back corona has been observed with dust layers as thin as 0.1 mm, but a dust layer just over one particle thick can reduce the sparking voltage by 50%.  The most marked effects of back corona on the current-voltage characteristics are:\nThe Figure below and to the left shows the variation in resistivity with changing gas temperature for six different industrial dusts along with three coal-fired fly ashes.  The Figure on the right illustrates resistivity values measured for various chemical compounds that were prepared in the laboratory.\nResults for Fly Ash A (in the figure to the left) were acquired in the ascending temperature mode.  These data are typical for a moderate to high combustibles content ash.  Data for Fly Ash B are from the same sample, acquired during the descending temperature mode.\nThe differences between the ascending and descending temperature modes are due to the presence of unburned combustibles in the sample. Between the two test modes, the samples are equilibrated in dry air for 14 hours (overnight) at 850 \u00b0F.  This overnight annealing process typically removes between 60% and 90% of any unburned combustibles present in the samples. Exactly how carbon works as a charge carrier is not fully understood, but it is known to significantly reduce the resistivity of a dust.\nCarbon can act, at first, like a high resistivity dust in the precipitator.  Higher voltages can be required in order for corona generation to begin.  These higher voltages can be problematic for the TR-Set controls.  The problem lies in onset of corona causing large amounts of current to surge through the (low resistivity) dust layer.  The controls sense this surge as a spark.  As precipitators are operated in spark-limiting mode, power is terminated and the corona generation cycle re-initiates.  Thus, lower power (current) readings are noted with relatively high voltage readings.\nThe same thing is believed to occur in laboratory measurements.  Parallel plate geometry is used in laboratory measurements without corona generation.  A stainless steel cup holds the sample.  Another stainless steel electrode weight sits on top of the sample (direct contact with the dust layer).  As voltage is increased from small amounts (e.g. 20 V), no current is measured.  Then, a threshold voltage level is reached.  At this level, current surges through the sample... so much so that the voltage supply unit can trip off.  After removal of the unburned combustibles during the above-mentioned annealing procedure, the descending temperature mode curve shows the typical inverted \u201cV\u201d shape one might expect.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Collection efficiency (''R'')", "sub_heading": "High resistivity", "_id": "50--2--2---1", "title": "High-Resistivity Dust Detection with TR-Set Controls"}
{"qas": [{"question": "Why does the temperature of a flue gas stream affect particle resistivity?", "answer": ""}, {"question": "What is the chemical name for hydrostatic precipitator?", "answer": "Sulfuric acid vapor", "ae_score": -0.3402811155077985, "qg_score": null}, {"question": "What is the chemical name for hydrostatic precipitator?", "answer": "Sulfuric acid vapor", "ae_score": -0.3402811155077985, "qg_score": null}], "content": "Particles that have low resistivity are difficult to collect because they are easily charged (very conductive) and rapidly lose their charge on arrival at the collection electrode. The particles take on the charge of the collection electrode, bounce off the plates, and become re-entrained in the gas stream. Thus, attractive and repulsive electrical forces that are normally at work at normal and higher resistivities are lacking, and the binding forces to the plate are considerably lessened. Examples of low-resistivity dusts are unburned carbon in fly ash and carbon black.\nIf these conductive particles are coarse, they can be removed upstream of the precipitator by using a device such as a cyclone mechanical collector.\nThe addition of liquid ammonia (NH) into the gas stream as a conditioning agent has found wide use in recent years. It is theorized that ammonia reacts with HSO contained in the flue gas to form an ammonium sulfate compound that increases the cohesivity of the dust.  This additional cohesivity makes up for the loss of electrical attraction forces.\nThe table below summarizes the characteristics associated with low, normal and high resistivity dusts.\nThe moisture content of the flue gas stream also affects particle resistivity. Increasing the moisture content of the gas stream by spraying water or injecting steam into the duct work preceding the ESP lowers the resistivity. In both temperature adjustment and moisture conditioning, one must maintain gas conditions above the dew point to prevent corrosion problems in the ESP or downstream equipment.  The figure to the right shows the effect of temperature and moisture on the resistivity of a cement dust. As the percentage of moisture in the gas stream increases from 6 to 20%, the resistivity of the dust dramatically decreases. Also, raising or lowering the temperature can decrease cement dust resistivity for all the moisture percentages represented.\nThe presence of SO in the gas stream has been shown to favor the electrostatic precipitation process when problems with high resistivity occur. Most of the sulfur content in the coal burned for combustion sources converts to SO. However, approximately 1% of the sulfur converts to SO. The amount of SO in the flue gas normally increases with increasing sulfur content of the coal. The resistivity of the particles decreases as the sulfur content of the coal increases.\nOther conditioning agents, such as sulfuric acid, ammonia, sodium chloride, and soda ash (sometimes as raw trona), have also been used to reduce particle resistivity.  Therefore, the chemical composition of the flue gas stream is important with regard to the resistivity of the particles to be collected in the ESP.  The table below lists various conditioning agents and their mechanisms of operation.\nIf injection of ammonium sulfate occurs at a temperature greater than about 600 \u00b0F, dissociation into ammonia and sulfur trioxide results.  Depending on the ash, SO may preferentially interact with fly ash as SO conditioning.  The remainder recombines with ammonia to add to the space charge as well as increase cohesiveness of the ash.\nMore recently, it has been recognized that a major reason for loss of efficiency of the electrostatic precipitator is due to particle buildup on the charging wires in addition to the collection plates (Davidson and McKinney, 1998).  This is easily remedied by making sure that the wires themselves are cleaned at the same time that the collecting plates are cleaned.\nSulfuric acid vapor (SO) enhances the effects of water vapor on surface conduction.  It is physically adsorbed within the layer of moisture on the particle  surfaces.  The effects of relatively small amounts of acid vapor can be seen in the figure below and to the right.\nThe inherent resistivity of the sample at 300 \u00b0F is 5\u00d710 ohm-cm.  An equilibrium concentration of just 1.9 ppm sulfuric acid vapor lowers that value to about 7 x 10 ohm-cm.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Collection efficiency (''R'')", "sub_heading": "Low resistivity", "_id": "50--2--3---1", "title": "The Effects of Ammonia on Particle Resistivity in the Electrostatic Precip"}
{"qas": [{"question": "Why do power lines have spikes on them?", "answer": ""}, {"question": "How many acm does an electrostatic precipitator collect?", "answer": "2.5 million", "ae_score": null, "qg_score": null}, {"question": "How many acm does an electrostatic precipitator collect?", "answer": "2.5 million", "ae_score": null, "qg_score": null}], "content": "ESPs continue to be excellent devices for control of many industrial particulate emissions, including smoke from electricity-generating utilities (coal and oil fired), salt cake collection from black liquor boilers in pulp mills, and catalyst collection from fluidized bed catalytic cracker units in oil refineries to name a few. These devices treat gas volumes from several hundred thousand ACFM to 2.5 million ACFM (1,180 m\u00b3/s) in the largest coal-fired boiler applications. For a coal-fired boiler the collection is usually performed downstream of the air preheater at about 160 \u00b0C which provides optimal resistivity of the coal-ash particles. For some difficult applications with low-sulfur fuel hot-end units have been built operating above 370 \u00b0C.\nThe original parallel plate\u2013weighted wire design has evolved as more efficient (and robust) discharge electrode designs were developed, today focusing on rigid (pipe-frame) discharge electrodes to which many sharpened spikes are attached (barbed wire), maximizing corona production. Transformer-rectifier systems apply voltages of 50\u2013100 kV at relatively high current densities. Modern controls, such as an automatic voltage control, minimize electric sparking and prevent arcing (sparks are quenched within 1/2 cycle of the TR set), avoiding damage to the components. Automatic plate-rapping systems and hopper-evacuation systems remove the collected particulate matter while on line, theoretically allowing ESPs to stay in continuous operation for years at a time.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Modern industrial electrostatic precipitators", "sub_heading": "Modern industrial electrostatic precipitators", "_id": "50--3---1---1", "title": "ESPs: The future of industrial particulate collection"}
{"qas": [{"question": "What is the difference between an Electrostatic precipitator and a Precipitator?", "answer": ""}, {"question": "What type of instruments are used to sample aerosol?", "answer": "Electrostatic precipitators", "ae_score": -0.4810666056309176, "qg_score": null}, {"question": "What type of instruments are used to sample aerosol?", "answer": "Electrostatic precipitators", "ae_score": -0.4810666056309176, "qg_score": null}], "content": "Electrostatic precipitators can be used to sample airborne particles or aerosol for analysis purposes. Precipitator designs with a liquid counterelectrode can be used to sample biological particles, e.g. viruses, directly into a small liquid volume to reduce unnecessary sample dilution.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Electrostatic air sampling", "sub_heading": "Electrostatic air sampling", "_id": "50--4---1---1", "title": "Electrostatic Precipitators are used to sample airborne particles or aerosol for analysis purposes"}
{"qas": [{"question": "What is the difference between a wet paper towel and a dry paper towel?", "answer": ""}, {"question": "What type of slide is used in electrostatic precipitator?", "answer": "downflow tubular design", "ae_score": -0.5707029808477323, "qg_score": null}, {"question": "What type of slide is used in electrostatic precipitator?", "answer": "downflow tubular design", "ae_score": -0.5707029808477323, "qg_score": null}], "content": "A wet electrostatic precipitator (WESP or wet ESP) operates with water vapor saturated air streams (100% relative humidity). WESPs are commonly used to remove liquid droplets such as sulfuric acid mist from industrial process gas streams. The WESP is also commonly used where the gases are high in moisture content, contain combustible particulate, or have particles that are sticky in nature.\nThe preferred and most modern type of WESP is a downflow tubular design. This design allows the collected moisture and particulate to form a moving slurry that helps to keep the collection surfaces clean. Plate style and upflow design WESPs are very unreliable and should not be used in applications where particulate is sticky in nature.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Wet electrostatic precipitator", "sub_heading": "Wet electrostatic precipitator", "_id": "50--5---1---1", "title": "Wet Electrostatic Precipitator (WESP)"}
{"qas": [{"question": "Why do collection plates need to be washed and scrubbed?", "answer": ""}, {"question": "Who developed the first portable electrostatic air filter system?", "answer": "Raytheon", "ae_score": -0.09042844718020565, "qg_score": null}, {"question": "Who developed the first portable electrostatic air filter system?", "answer": "Raytheon", "ae_score": -0.09042844718020565, "qg_score": null}], "content": "Plate precipitators are commonly marketed to the public as air purifier devices or as a permanent replacement for furnace filters, but all have the undesirable attribute of being somewhat messy to clean.  A negative side-effect of electrostatic precipitation devices is the potential production of toxic ozone and NO.  However, electrostatic precipitators offer benefits over other air purifications technologies, such as HEPA filtration, which require expensive filters and can become \"production sinks\" for many harmful forms of bacteria.\nWith electrostatic precipitators, if the collection plates are allowed to accumulate large amounts of particulate matter, the particles can sometimes bond so tightly to the metal plates that vigorous washing and scrubbing may be required to completely clean the collection plates. The close spacing of the plates can make thorough cleaning difficult, and the stack of plates often cannot be easily disassembled for cleaning. One solution, suggested by several manufacturers, is to wash the collector plates in a dishwasher.\nSome consumer precipitation filters are sold with special soak-off cleaners, where the entire plate array is removed from the precipitator and soaked in a large container overnight, to help loosen the tightly bonded particulates.\nA study by the Canada Mortgage and Housing Corporation testing a variety of forced-air furnace filters found that ESP filters provided the best, and most cost-effective means of cleaning air using a forced-air system.\nThe first portable electrostatic air filter systems for homes was marketed in 1954 by Raytheon.", "page_name": "Electrostatic precipitator", "page_id": "Electrostatic%20precipitator", "heading": "Consumer-oriented electrostatic air cleaners", "sub_heading": "Consumer-oriented electrostatic air cleaners", "_id": "50--6---1---1", "title": "Electrostatic Precipitation Filters"}
{"qas": [{"question": "What is the difference between the Geneva Convention and the Universal Declaration of Human Rights?", "answer": ""}, {"question": "Who developed the laws that protect children from being trafficked?", "answer": "the United Nations", "ae_score": -0.6245349601480266, "qg_score": null}, {"question": "Who developed the laws that protect children from being trafficked?", "answer": "the United Nations", "ae_score": -0.6245349601480266, "qg_score": null}], "content": "The first major international instrument dealing with the trafficking of children is part of the 2000 United Nations Palermo protocols, titled the Protocol to Prevent, Suppress and Punish Trafficking in Persons, especially Women and Children. Article 3(a) of this document defines child trafficking as the \"recruitment, transportation, transfer, harboring and/or receipt\" of a child for the purpose of exploitation. The definition for child trafficking given here applies only to cases of trafficking that are transnational and/or involve organized criminal groups; in spite of this, child trafficking is now typically recognized well outside these parameters. The International Labour Organization expands upon this definition by asserting that movement and exploitation are key aspects of child trafficking. The definition of \"child\" used here is that listed in the 1989 U.N. Convention on the Rights of the Child which states, \"a child means every human being below the age of 18 years, unless, under the law applicable to the child, majority is attained earlier.\" The distinction outlined in this definition is important, because some countries have chosen to set the \"age of majority\" lower than 18, thus influencing exactly what legally constitutes child trafficking.\nMany international, regional, and national instruments deal with the trafficking of children. These instruments are used to define what legally constitutes trafficking of children, such that appropriate legal action can be taken against those who engage in and promote this practice. These legal instruments are called by a variety of terms, including conventions, protocols, memorandums, joint actions, recommendations, and declarations. The most significant instruments are listed below:\nThese legal instruments were developed by the United Nations in an effort to protect international human rights and, more specifically, children's rights.\nThe trafficking of children often involves both labour and migration. As such, these international frameworks clarify instances in which these practices are illegal.\nA variety of regional instruments have also been developed to guide countries in decisions regarding child trafficking. Below are some of the major instruments, though many others exist:\nNational laws pertaining to child trafficking continue to develop worldwide, based on the international principles that have been established. Anti-trafficking legislation has been lauded as critical by the United Nations Global Initiative to Fight Human Trafficking, because it ensures that traffickers and trafficking victims are treated accordingly: for example, \"if migration laws are used to pursue traffickers, it is often the case that the victims too are prosecuted as illegal migrants, whereas if there is a specific category of 'trafficker' and 'trafficked person,' then it is more likely that the victim will be treated as such.\" The existence of national laws regarding child trafficking also enables trafficking victims and/or their families to take appropriate civil action.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Definition", "sub_heading": "Definition", "_id": "51--0---1---1", "title": "International, Regional, and National Instruments on Child Trafficking"}
{"qas": [{"question": "What is the objective of child trafficking?", "answer": ""}, {"question": "How many children are involved in the sex or drug trade?", "answer": "115 million", "ae_score": -0.37169857683436236, "qg_score": null}, {"question": "How many children are involved in the sex or drug trade?", "answer": "115 million", "ae_score": -0.37169857683436236, "qg_score": null}], "content": "The objective of child trafficking is often forced child labour. Child labour refers specifically to children under a stipulated minimum age, usually 14 at the lowest, being required to work. UNICEF estimates that, in 2011, 150 million children aged 5\u201314 in developing countries were involved in child labour. Within this number, the International Labour Organization reports that 60% of child workers work in agriculture. The ILO also estimates that 115 million children are engaged in hazardous work, such as the sex or drug trade.  Overall, child labor can take many forms, including domestic servitude, work in agriculture, service, and manufacturing industries. Also, according to several researchers, most children are forced into cheap and controllable labor, and work in homes, farms, factories, restaurants, and much more (Beyrer 16; Gozdziak and MacDonnell 171; Vinkovic 88). Trafficked children may be sexually exploited, used in the armed forces and drug trades, and in child begging. In terms of global trends, the ILO estimates that in 2004\u20132008, there was a 3% reduction in the incidence of child labor; this stands in contrast to a previous ILO report which found that in 2000\u20132004, there was a 10% reduction in child labor. The ILO contends that, globally, child labour is slowly declining, except in sub-Saharan Africa, where the number of child workers has remained relatively constant: 1 in 4 children aged 5\u201317 work in this region. Another major global trend concerns the number of child laborers in the 15-17 age group: in the past five years, a 20% increase in the number of these child workers has been reported. A surprised example has occurred in the United States as McCabe (2008) indicates that in the 1990s, huge companies such as Gap and Nike were using industries \u201csweatshops\u201d that use trafficked children to make their desired products (p. 81).", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Types of child trafficking", "_id": "51--1--0---1", "title": "Child Trafficking in the United States and Europe"}
{"qas": [{"question": "What is the Optional Protocol on the Sale of Children, Child Prostitution and Child Pornography?", "answer": ""}, {"question": "When was the Optional protocol on the sale of children, child prostitution and child pornography adopted?", "answer": "2000", "ae_score": -0.23826847489325806, "qg_score": null}, {"question": "When was the Optional protocol on the sale of children, child prostitution and child pornography adopted?", "answer": "2000", "ae_score": -0.23826847489325806, "qg_score": null}], "content": "The Optional Protocol on the Sale of Children, Child Prostitution and Child Pornography is a protocol of the Convention on the Rights of the Child, formally adopted by the United Nations in 2000. Essentially, this protocol formally requires states to prohibit the sale of children, child prostitution, and child pornography. According to the International Labour Organization, sexual exploitation of children includes all of the following practices and activities: \nThough measuring the extent of this practice is difficult due to its criminal and covert nature, the International Labour Organization estimates that there are as many as 1.8 million children sexually trafficked worldwide, while UNICEF's 2006 State of the World's Children Report reports this number to be 2 million. The International Labour Organization has found that girls involved in other forms of child labour - such as domestic service or street vending - are at the highest risk of being pulled into commercial child sex trafficking. Likewise, Kendall and Funk justifies how \u201cyoung girls age 12 and under are malleable and more easily trained into their prospective roles as prostitutes, and because virginity is highly prized by certain consumers willing to pay a premium\u201d (31).A variety of sources, including the I.L.O, and scholars Erin Kunze and D.M. Hughes, also contend that the increased use and availability of the Internet has served as a major resource for traffickers, ultimately increasing the incidence of child sex trafficking. In fact, in 2009, Illinois Sheriff Thomas J. Dart sued the owners of Craigslist, a popular online classifieds website, for its \"allowance\" and \"facilitation\" of prostitution, particularly in children. In response to public and legal pressure, Craigslist has since blocked all access to its \"Adult Services\" section.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Sexual exploitation", "_id": "51--1--1---1", "title": "Child Sexual Exploitation: The International Labour Organization"}
{"qas": [{"question": "The Optional Protocol on the Involvement of Children in Armed Conflict?", "answer": ""}, {"question": "When was the Optional protocol on the involvement of children in armed conflict adopted?", "answer": "2000", "ae_score": -0.32116850533768093, "qg_score": null}, {"question": "When was the Optional protocol on the involvement of children in armed conflict adopted?", "answer": "2000", "ae_score": -0.32116850533768093, "qg_score": null}], "content": "The Optional Protocol on the Involvement of Children in Armed Conflict is a protocol of the Convention on the Rights of the Child, formally adopted by the United Nations in 2000. Essentially, the protocol states that while volunteers below the age of 18 can voluntarily join the armed forces, they cannot be conscripted. As the Protocol reads, \"State parties shall take all feasible measures to ensure that member of their armed forces who have not attained the age of 18 years do not take a direct part in hostilities.\" Despite this, the International Labour Organization estimates that \"tens of thousands\" of girls and boys are currently forcibly enlisted in the armed forces in at least 17 countries around the world. Children conscripted into the armed forces can then be used in three distinct ways: \nRecent research conducted by the Coalition to Stop the Use of Child Soldiers has also noted that girl soldiers must be uniquely recognized, in that they are especially vulnerable to acts of sexual violence. The incidence of child soldiers was the focus of  the Kony 2012 movement, that aimed  to arrest Joseph Kony, a Ugandan war criminal who is responsible for the trafficking of thousands of child soldiers and sex slaves.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Children in armed forces", "_id": "51--1--2---1", "title": "The Optional Protocol on the Involvement of Children in Armed Conflict (OPIC"}
{"qas": [{"question": "Why are children used in the drug trade?", "answer": ""}, {"question": "Who investigated the use of afghan children in the heroin trade?", "answer": "I.L.O", "ae_score": null, "qg_score": null}, {"question": "Who investigated the use of afghan children in the heroin trade?", "answer": "I.L.O", "ae_score": null, "qg_score": null}], "content": "Children are also used in drug trades in all regions of the world. Specifically, children are often trafficked into exploitation as either drug couriers or dealers, and then 'paid' in drugs, such that they become addicted and further entrapped. Due to the illicit nature of drug trafficking, children who are apprehended are often treated as criminals, when in reality they are often the ones in need of legal assistance. While comprehensive worldwide statistics regarding the prevalence of this practice are unknown, several useful regional studies have been conducted. For example, the I.L.O has recently investigated the use of Afghan children in the heroin trade and child involvement in the drug trades of Brazil. Scholar Luke Dowdney specifically studied children in the drug trade in Rio de Janeiro, Brazil; he found that children involved in the drug trades are at significantly higher risk of engaging in violence, particularly murder.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Children in drug trades", "_id": "51--1--3---1", "title": "Child Trafficking in Drug Trades"}
{"qas": [{"question": "Why are there so many more boys than girls in the world?", "answer": ""}, {"question": "What is the highest number of people who are believed to be involved in forced begging?", "answer": "500 or greater", "ae_score": -0.33699763910206576, "qg_score": null}, {"question": "What is the highest number of people who are believed to be involved in forced begging?", "answer": "500 or greater", "ae_score": -0.33699763910206576, "qg_score": null}], "content": "By definition child begging occurs in persons younger than eighteen, though forced begging has been found by UNICEF to exist among children as young as the age of two.  Incidences of this practice have been recorded by the World Bank in South and Central Asia, Europe, Latin America, the Caribbean, the Middle East, and West Africa.\nMost research, such as studies done by UNICEF, suggests that boys are much more likely than girls to be trafficked for the purposes of begging; experts presume this is because there is a greater female presence in trafficking for the purposes of sexual exploitation. In Albania, where forced begging is a common practice, seventy percent of victims are male.\nWhile concrete figures are difficult to determine, the International Labour Organization (ILO) recently reported that there are at least 600,000 children involved in forced begging. The problem may be much more extensive, however, with China's Ministry of Civil Affairs reporting that as many as 1.5 million children are forced into begging. Additionally, a recent study done in Senegal by Human Rights Watch projected that a minimum of 50,000 children within the country and neighboring nations have been trafficked for the purposes of begging. Begging is often the primary source of income for street children in a number of countries, with a current study conducted by UNICEF finding that 45.7% of children who work on the streets of Zimbabwe engaged in begging, though there is no way of knowing whether it was through forced means.\nGang networks involving forced begging have been found to occur in populations of 500 or greater.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Child begging", "_id": "51--1--4--0", "title": "Child Beating: The Problem of Child Trafficking in the Middle East and Africa"}
{"qas": [{"question": "What is the cultural reason for the death of a loved one?", "answer": ""}, {"question": "In which country is child begging especially prominent?", "answer": "Zimbabwe", "ae_score": -0.673200940748319, "qg_score": null}, {"question": "In which country is child begging especially prominent?", "answer": "Zimbabwe", "ae_score": -0.673200940748319, "qg_score": null}], "content": "Forced begging is a profitable practice in which exploiters are motivated by economic incentives. The business structures of major rings of children trafficked for the purpose of begging have been examined as comparable to a medium-size business enterprise. In the most severe cases networks of children forced to beg may generate $30\u201340,000 USD for the profiteer. Though family networks are not nearly as extensive, a study conducted in Albania showed that a family with multiple children begging can earn up to fifteen euros a day, an amount greater than the average national teacher salary. Anti-Slavery International asserts that because this income is relatively high many families believe it is the best option available given the lack of existing capabilities. Capability deprivation, meaning the routine absence of adequate resources that serve in facilitating opportunities, may account for cross-generational begging practices within families. UNICEF studies have found that begging is especially prevalent among families in which parents are incapacitated in some way, leading children to be the sole providers.\nAccording to the World Bank forced begging is most commonly found in the Middle East and countries of West Africa, where laws prohibiting begging are scarce and heavy regulation of trafficking absent. In Zimbabwe, where child begging is especially prominent, the United Nations has indicated many contradictions between the Labour Act of Zimbabwe and the United Nations Convention on the Rights of the Child. Many nations, such as Indonesia, have laws against begging on the books, but the repercussions for such entail temporary detainment and eventual release back onto the streets, which does little to combat the issue.\nThere are several cultural factors that support begging. In Europe begging is found in a number of minority cultures, especially popular within Roma and nomadic communities. In Turkey familial networks of beggars have been documented across three generations, making it deeply ingrained within their survival schemas. It is important to note that while these may be culturally rooted practices, juvenile begging by way of familial pressure still falls under the realm of forced begging. The transport of children, even one's own, for the purposes of exploitation through begging is a form of trafficking outlined by the United Nations.\nAnother cultural practice is the resolution of familial debts through the kidnapping and exploitation of one of their children.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Causes", "_id": "51--1--4--1", "title": "The Role of Beggars in Family Beating"}
{"qas": [{"question": "Why are children forced to beg for money?", "answer": ""}, {"question": "What are children turned into when they are forced begging?", "answer": "drug addicts", "ae_score": -0.4816176135570966, "qg_score": null}, {"question": "What are children turned into when they are forced begging?", "answer": "drug addicts", "ae_score": -0.4816176135570966, "qg_score": null}], "content": "UNICEF has found that children who are forced to beg by third parties are often removed from their families, surrender the majority of their income to their exploiter, endure unsafe work and living conditions, and are at times maimed to increase profits. The process of maiming, popularized by the film ''Slumdog Millionaire'', is common given that according to the Buffalo Human Rights Law Review children with apparent special needs often make upwards of three times as much as other children who beg. In addition to inflictions such as blindness and loss of limbs, other physical abuses for the purposes of heightening profits include pouring chili pepper on a child's tongue to give the appearance of impeded speech, the use of opium to elicit cries, and administering forced injections of drugs that will increase a child's energy and alertness. Testimonies against trafficking ring gang leaders have discussed the detainment of individuals in small cells devoid of food, water, and light to make victims weak and feeble, and thus more likely to elicit donations.\nThe conditions in which begging takes place commonly expose children to further physical and verbal abuse, including sexual victimization and police brutality. Research completed by Human Rights Watch revealed that when begging hours are completed for the day children often do not have proper shelter, adequate food, or access to healthcare where they reside. Furthermore, many of the gangs which run networks of forced begging have heavy drug involvement, thus the children under their control are often turned into drug addicts in order for them to become further reliant on their exploiters.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "General abuses", "_id": "51--1--4--2", "title": "''Slumdog Millionaire'': Children who are forced to beg are"}
{"qas": [{"question": "Why are children forced into begging?", "answer": ""}, {"question": "What do children who beg in the streets get?", "answer": "little to no education", "ae_score": -1.2327813555641065, "qg_score": null}, {"question": "What do children who beg in the streets get?", "answer": "little to no education", "ae_score": -1.2327813555641065, "qg_score": null}], "content": "Studies have shown that children forced into begging primarily receive little to no education, with upwards of sixteen hours a day dedicated to time on the streets. With education being a leading method in escaping poverty child beggars have been shown to engage in a cyclical process of continuing this practice cross-generationally. Interviews conducted by UNICEF show that children who beg have little hope for the future and do not believe their circumstances will improve. Children who work on the streets typically have little or no knowledge of their rights, leaving them especially susceptible to exploitation both as juveniles and later as adults. Children who beg have also been found by UNICEF to have much higher instances of HIV-infection due to lack of awareness and supervision on the streets.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Long-term implications", "_id": "51--1--4--3", "title": "Child Beggars: The Role of Beggars in the Endangered"}
{"qas": [{"question": "Why are there so many child adoptions in Zimbabwe?", "answer": ""}, {"question": "When was the law passed banning child prostitution in bangladesh?", "answer": "2009", "ae_score": -0.25797160909535616, "qg_score": null}, {"question": "When was the law passed banning child prostitution in bangladesh?", "answer": "2009", "ae_score": -0.25797160909535616, "qg_score": null}], "content": "A victim-centered human rights approach to combating trafficking has been internationally renowned as the best possible strategy when addressing this issue, with recourse focusing on punishing the exploiter and rehabilitating the child. Some countries who emphasize this method include the United States, with the U.S. Trafficking Victims Protection Act of 2000 affirming \"victims of severe forms of trafficking should not be inappropriately incarcerated, fined, or otherwise penalized solely for unlawful acts committed as a direct result of being trafficked.\"\nOther supported methods, such as those outlined by the Buffalo Human Rights Law Review, include relying on three Ps: protection, prosecution, and prevention. Protection starts with enforcing strict measures on the matters of both trafficking and begging. For many nations the first step is the criminalization of begging and trafficking. Prosecution should be instituted in the form of greater legal ramifications for traffickers, with punishment focused on the exploiter rather than the exploited. This becomes difficult with respect to victims of familial trafficking, considering this would require changes in care placement and strict monitoring of each displaced child's welfare. Many organizations affirm that prevention begins with discouraging donations and improving services so that children, and families as a whole, have greater capabilities. Though well-intentioned, by giving child beggars money, individuals only make this practice more profitable, and soon these funds find their way into the hands of the child's abuser.\nIn Senegal, where the abuses against  talibes are extensive, there have been several initiatives with the help of the World Bank to put an end this exploitation. First, there is intervention on a community level with education on the validity of some of these Quranic institutions provided to rural villages that typically send their children there. This is supplemented by improved regulation of schools within the nation to ensure that they remain places of education, followed by a greater enforcement of preexisting laws banning trafficking and exploitative begging. Finally, rehabilitation services have been provided with the help of CSOs to recovered children to provide them with the capabilities they have been denied.\nIn Zimbabwe policy has adapted to ensure the safety of all persons under the age of sixteen with the Children's Protection and Adoption Act, however, the government admits that a lack of resources and capital play a critical role in inadequate enforcement.\nIn Bangladesh, where there are an estimated 700,000 beggars, a law passed in 2009 banning the practice, though officials report some trouble with enforcement.\nIn China, the Ministry of Public Security has established a department that solely focuses on child trafficking. Recently the department has instituted a hotline where the public dials 110 to report suspected incidences of forced begging, which law enforcement officials are expected to investigate further. The police are trained to take the children into custody if a blood relationship with their guardian cannot be established, and educate parents on the illegality and dangers of begging if they are those responsible for the child's action. This policy instituted in April 2009 has since led to the recovery of 9,300 children.\nMany NGOs have initiated movements focusing on informing the public on the dangers of donations. As recently reported by UNICEF  \"certain behaviors, such as giving money to child beggars can also indirectly motivate traffickers and controller to demand children.\" The Mirror Foundation's Stop Child Begging Project of Thailand is one such organization that emphasizes eliminating the demand. Their initiatives are focused on educating passersby on the forced begging of trafficked Cambodians within their country to decrease the likelihood of donations.\nIn China, where the kidnapping and forced begging of children has been routinely documented, a multi-media movement has begun. Here, blogs are utilized to publicize over 3,000 photos of children whose families believe have been abducted for the purpose of begging, with hundreds of thousands of followers who remain on the look out for these children in major urban centers. This campaign has enabled at least six children to be recovered and reunited with their families.\nIn instances where begging is religiously sanctioned it has been suggested by USAid that religious leaders should outwardly condemn this practice. For talibes religious leaders have been asked to take a stance against begging using passages sited in the Quran, such as \"Except paradise, you should not beg anything for the sake of Allah\" (8:23), which would help strip the practice of its religious foundation. In addition, during the time of president Clinton - a former president of the United States-, he took the responsibility of providing protection against child abuse through Internet Service providers (ISP) that can help the law enforcement tracking any suspicious activities including child pornography (McCabe, 2008, p. 247).", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Solutions", "_id": "51--1--4--4", "title": "A Human Rights Approach to Combating Child Trafficking"}
{"qas": [{"question": "Why is it so common for children to be adopted?", "answer": ""}, {"question": "What is it called when a child is trafficked?", "answer": "re-homing", "ae_score": -0.35647903047865126, "qg_score": null}, {"question": "What is it called when a child is trafficked?", "answer": "re-homing", "ae_score": -0.35647903047865126, "qg_score": null}], "content": "In China, in response to adult starvation, some children were exchanged, killed, and eaten. According to Robyn Meredith, \"peasants [in the People's Republic of China (possibly in ''ca.'' 1958)] turned into skeletons. The nation's farmers, including the residents of Xiaogang, .... [among some] starving families[,] resorted to a practice called ''yi zi er shi'' [meaning \"exchanging children to eat\"]:... they traded a child for a neighbor's child, then killed and ate the skinny youngster, with the sickening knowledge that their neighbors were devouring their own.\"\nThe practice is also known as \"re-homing\" or \"adoption from disruption\".", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Child exchange", "_id": "51--1--5---1", "title": "In response to adult starvation, some children were traded, killed, and eaten."}
{"qas": [{"question": "Where did the idea of selling your children come from?", "answer": ""}, {"question": "Who wrote that there were indigent parents selling children because they needed the cash?", "answer": "Augustine", "ae_score": -0.5682158166248176, "qg_score": null}, {"question": "Who wrote that there were indigent parents selling children because they needed the cash?", "answer": "Augustine", "ae_score": -0.5682158166248176, "qg_score": null}], "content": "In ancient Rome, according to Keith Bradley, Augustine wrote that \"there were indigent parents selling their children because they needed the cash.\"\nIn contemporary Nepal, parents of poor families sell their children to orphanages (or sometimes simply hand them over without any payment). The orphanage then misrepresent them as \"orphans\", ensuring an income for the orphanages.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Types of child trafficking", "sub_heading": "Sales motivated by cash", "_id": "51--1--6---1", "title": "In Nepal, poor families sell their children to orphanages"}
{"qas": [{"question": "What is the difference between human trafficking and child trafficking?", "answer": ""}, {"question": "What is the economic model for child trafficking?", "answer": "supply and demand", "ae_score": -0.976609431060237, "qg_score": null}, {"question": "What is the economic model for child trafficking?", "answer": "supply and demand", "ae_score": -0.976609431060237, "qg_score": null}], "content": "Child trafficking is often conceptualized using the economic model of supply and demand. Specifically, those who are trafficked constitute the \"demand\", while the traffickers, and all those who profit from the exploitation, provide the \"demand\". Two types of demand are defined: consumer demand and derived demand. Consumer demand is generated by people who actively or passively buy the products or services of trafficked labor. An example of this would be a tourist purchasing a T-shirt that has been made by a trafficked child. Derived demand, on the other hand, is generated by people who directly profit from the practice of trafficking, such as pimps or corrupt factory owners. Scholar Kevin Bales has extensively studied the application of this economic framework to instances of human trafficking; he contends that it is central to an accurate understanding of how trafficking is initiated and sustained. Bales, along with scholars Elizabeth M. Wheaton, Edward J. Schauer, and Thomas V. Galli, have asserted that national governments should more actively implement policies that reduce both types of demand, thus working towards the elimination of trafficking.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Mechanisms", "sub_heading": "Mechanisms", "_id": "51--2--0---1", "title": "The Economics of Child Trafficking"}
{"qas": [{"question": "Why is child trafficking more prevalent in poor countries than in rich ones?", "answer": ""}, {"question": "Who is an advocate for the protection of children from being trafficked?", "answer": "Una Murray", "ae_score": null, "qg_score": null}, {"question": "Who is an advocate for the protection of children from being trafficked?", "answer": "Una Murray", "ae_score": null, "qg_score": null}], "content": "Various international organizations, including the International Labour Organization and the United Nations Global Initiative to Fight Human Trafficking have linked child trafficking to poverty: Living in poverty has been found to increase children's vulnerability to trafficking. However, poverty is only one of many social \"risk factors\" that can lead to trafficking. As UNICEF and the World Bank note, \"Often children experience several risk factors at the same time, and one of them may act as a trigger that sets the trafficking event in motion. This is sometimes called 'poverty plus,' a situation in which poverty does not by itself lead to a person being trafficked, but where a 'plus' factor such as illness combines with poverty to increase vulnerability.\" UNICEF, UN.GIFT and several scholars, including Una Murray and Mike Dottridge, also contend that an accurate understanding of child trafficking must incorporate an analysis of gender inequality. Specifically, in many countries, girls are at a higher risk of being trafficked, particularly into sexual exploitation. In addition, these international agencies and scholars contend that giving women and men an equal voice in anti-trafficking policy is critical to reducing the incidence of child trafficking.\nStudies throughout Europe have identified risks that make children vulnerable to exploitation that are also causes and contributing factors of child trafficking. These include social and economic marginalisation, dysfunctional family backgrounds, experiences of neglect, abuse or violence within the family or in institutions, exploitative relationships, gender-based violence and discrimination, experiences of living or working on the streets, precarious and irregular migration situations, aspirations to work and to earn money and limited opportunities to enter or remain in school, vocational training or regular employment. As the efforts of national governments to improve social safety nets can lessen many of these risks, child trafficking is considered not only a result of criminal activities but also as indicating weaknesses in the national government's ability to effectively safeguard children\u2019s rights to a safe and healthy development.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Mechanisms", "sub_heading": "Social mechanisms", "_id": "51--2--1---1", "title": "Child Trafficking and Poverty in Europe"}
{"qas": [{"question": "How does the process of identifying a child as a victim of trafficking work?", "answer": ""}, {"question": "Which clause protects children who have been exploited?", "answer": "non-punishment clause", "ae_score": -0.8299445123328852, "qg_score": null}, {"question": "Which clause protects children who have been exploited?", "answer": "non-punishment clause", "ae_score": -0.8299445123328852, "qg_score": null}], "content": "The complex definition of child trafficking and the differences in national laws and interpretations makes the identification of child victims of trafficking challenging. For example, the European debate on child trafficking lacks consensus on how child trafficking is to be distinguished from other contexts of exploitation, from social dumping of migrants, the sale of children and the smuggling of migrants.\nOnce a potential victim has come into contact with state authorities, identifying the child as a victim of trafficking takes time. The process often benefits from a thorough understanding of the child\u2019s story. For a child who is in trouble with the law, hearing the child's full story helps caseworkers and officers determine if the child is actually a victim of a crime herself, such as exploitation, abuse, or trafficking. For a child in an administrative process, such as an asylum procedure, hearing the child's full story helps caseworkers to detect cases of trafficking. Children may be hesitant to share their complete stories with authorities and appointed child welfare professionals. Some service providers have found that establishing trust and a stable relationship with the child encourages increased disclosure of experiences of exploitation and trafficking that might otherwise not be detected. The trust building process can include granting assistance and support services to ensure safety, well-being and development.\nIdentified victims of child trafficking are entitled to special safeguards that all child victims of crimes are entitled to under international law. These safeguards include the right to guardianship, legal assistance and representation, safety and protection, support for physical and psychological recovery and social reintegration, regularisation of immigration status, the right to compensation, and the right to act as a party, or plaintiff, in criminal proceedings. An important safeguard for trafficked children who have been exploited in illegal or criminal activities is the \u2018non-punishment clause\u2019. It means that child victims of criminal offences, including human trafficking, are to be protected from sanctions or prosecution for acts that they committed in relation to their situation as victims.\nArticles 19 and 32-36 of the UN Convention on the Rights of the Child prohibits the exploitation of children in any form and in any context. Any child who is exposed to violence, exploitation or abuse can be considered a victim of crime and enjoys the correlated rights and entitlements, including access to assistance, protection and support, services for recovery and rehabilitation, access to justice, with due procedural safeguards in any related legal or administrative proceedings. Children at risk of exploitation have to be identified and recognised as being at risk. This implies that they have a right to assistance and support in order to prevent their exploitation or any other harm resulting from the risks. Considering the difficulties of identifying children who have been trafficked and the broad protection against all forms and contexts of exploitation afforded under the Convention, a child rights-based approach prioritises the identification of child victims of exploitation or other crime and children at risk. Whether or not exploitation takes place in a context of trafficking is of subordinate relevance for the child rights and protection context. It may interest primarily the law enforcement investigations and the prosecution.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Identification", "sub_heading": "Identification", "_id": "51--3---1---1", "title": "Identifying Child Victims of Trafficking"}
{"qas": [{"question": "Why is there so much child trafficking in the world?", "answer": ""}, {"question": "How many children are trafficked each year?", "answer": "1.2 million", "ae_score": -0.26827382450702747, "qg_score": null}, {"question": "How many children are trafficked each year?", "answer": "1.2 million", "ae_score": -0.26827382450702747, "qg_score": null}], "content": "It is difficult to obtain reliable estimates concerning the number of children trafficked each year, primarily due to the covert and criminal nature of this practice. It often takes years to gather and compile estimates regarding child trafficking and, as a result, data can seem both inadequate and outdated. This process of gathering data is only complicated by the fact that very few countries publish national estimates of child trafficking. As a result, the available statistics are widely thought to underestimate the actual scope of the problem.\nTrafficking of children has been documented in every region of the world. The most reliable figure regarding the prevalence of this practice is provided by the International Labour Organization, which estimates that 1.2 million children are trafficked each year; this estimate includes cross-border and internal trafficking.\nRegionally, the International Labour Organization has provided the following estimates for trafficking of children by region per year:\nAs the numbers above indicate, child trafficking occurs the most frequently in Latin America and the Caribbean. Child trafficking is also the most prevalent in developing countries, though it does occur in developed and industrialized economies as well. Notably, the United States Department of State publishes an annual \"Trafficking in Persons\" report which provides ample data regarding the prevalence of human and child trafficking in the majority of countries.  The University of Pennsylvania School of Social Work released a study that estimated as many as 300,000 American youth may be at risk of commercial sexual exploitation at any time.\nAccording to anthropologist Samuel Pyeatt Menefee, in the late 17th and 18th centuries, in Britain, parents in poverty \"sold their children (actually, their children's services, but to all intents and purposes their persons as well)\". Sale motivations were more economic than for wife sales and prices, drawing from limited data, \"appear to have been fairly high\". Many of the boys sold were climbing boys for chimney sweeps until they were no longer small enough. Prostitution was another reason for selling a child, usually a girl. One sale was of a niece; another was the sale by a man of the daughter of a woman domestic partner who also ran his business. Some children were stolen and then sold. Purchasing was apparently also done through \"baby-farming operations\".", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Prevalence", "sub_heading": "Prevalence", "_id": "51--4---1---1", "title": "Child Trafficking in the United States and the Caribbean"}
{"qas": [{"question": "How does child trafficking affect a child's life?", "answer": ""}, {"question": "Who has found that certain forms of trafficking bring shame to families?", "answer": "UN.GIFT", "ae_score": -0.6914138796918724, "qg_score": null}, {"question": "Who has found that certain forms of trafficking bring shame to families?", "answer": "UN.GIFT", "ae_score": -0.6914138796918724, "qg_score": null}], "content": "According to UN.GIFT, child trafficking has the most significant impact on trafficked children and their families. First, trafficking can result in the death or permanent injury of the trafficked child. This can stem from a dangerous \"movement\" stage of trafficking or from specific aspects of the \"exploitation\" stage, such as hazardous working conditions. Moreover, trafficked children are often denied access to healthcare, effectively increasing their chances of serious injury and death. Trafficked children are also often subject to domestic violence; they may be beaten or starved in order to ensure obedience.  In addition, these children frequently encounter substance abuse; they may be given drugs as \"payment\" or to ensure that they become addicted and thus dependent on their trafficker(s). As opposed to many other forms of crime, the trauma experienced by children who are trafficked is often prolonged and repeated, leading to severe psychological impacts. UN.GIFT reports that trafficked children often suffer from depression, anxiety, and post-traumatic stress disorder, among other conditions.\nEffects on families are also severe. Some families believe that sending or allowing their children to relocate in order to find work will bring in additional income, while in reality many families will never see their trafficked children again. In addition, UN.GIFT has found that certain forms of trafficking, particularly sexual exploitation in girls, bring \"shame\" to families.  Thus, in certain cases, children who are able to escape trafficking may return to their families only to find that they are rejected and ostracized.\nChild trafficking has also been shown to have a major effect on communities. If multiple children in a community are trafficked, it can result in the entire community being corrupted, and thus devastated, by trafficking. Social development efforts are hindered, as trafficked children's educations are cut short. As a result of this lack of education, children who escape trafficking may be less able to secure employment later in life. In addition, trafficked girls face special obstacles, in that their prospects for marriage might be diminished if the community becomes aware that they have been trafficked, particularly into sexual exploitation.\nOn a national level, economic development is severely hindered by the lack of education of trafficked children; this results in a major loss of potentially productive future workers. Children who are able to successfully return to their families often pose a significant financial burden, due to their lack of education, and the illnesses and injuries they may have incurred during trafficking work. There are major costs associated with the rehabilitation of these trafficked children, so that they are able to successfully participate in their communities. Furthermore, the persistence of child trafficking indicates the presence of sustained criminal activity and criminal networks, which, in most cases, are also associated with drugs and violence. As a result, UN.GIFT has cited child trafficking as a significant indicator of national and global security threats.", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Impacts", "sub_heading": "Impacts", "_id": "51--5---1---1", "title": "UN.GIFT: Child Trafficking"}
{"qas": [{"question": "Why is child trafficking illegal?", "answer": ""}, {"question": "What do these organizations want to do with child trafficking?", "answer": "eradication", "ae_score": -0.38957153047350174, "qg_score": null}, {"question": "What do these organizations want to do with child trafficking?", "answer": "eradication", "ae_score": -0.38957153047350174, "qg_score": null}], "content": "Many organizations have proposed potential solutions to child trafficking. These organizations continue to conduct research concerning this practice and policies that can be implemented to work towards its eradication. The most internationally recognized of these organizations include: ", "page_name": "Trafficking of children", "page_id": "Trafficking%20of%20children", "heading": "Proposed solutions", "sub_heading": "Proposed solutions", "_id": "51--6--0---1", "title": "Child Trafficking and Child Trafficking in the United States"}
{"qas": [{"question": "Why is there so much biodiversity in the wild?", "answer": ""}, {"question": "What virus is a gene from ethiopia that protects barley crop from?", "answer": "yellow dwarf virus", "ae_score": -0.4149961644844384, "qg_score": null}, {"question": "What virus is a gene from ethiopia that protects barley crop from?", "answer": "yellow dwarf virus", "ae_score": -0.4149961644844384, "qg_score": null}], "content": "Conservation and management of broad-based genetic diversity within the domesticated species have been improving agricultural production for 10,000 years. However, diverse natural populations have been providing food and other products for much longer. High Biodiversity can maximize the production levels, which is sustained through beneficial impact of ecosystem services for agricultural, modified and natural ecosystems.\nWild subspecies of tomatoes (''Solanum lycopersicum chmielewskii'') was crossbreed with cultivated tomato species.After 10 generations, New tomatoes strain with larger fruits were produced. There was a marked increase in pigmentation. The content of soluble solid, mainly fructose, glucose and other sugar are increased.\nA barley plant from Ethiopia provides a gene that protects the barley crop from the lethal yellow dwarf virus.\nHost resistance gene, Xa21,from ''Oryza longistaminata'' is integrated into the genome of ''Oryza sativa'' for the board range resistance of rice blight disease caused by ''Xanthomonas oryzae pv. oryzae'' ", "page_name": "Biodiversity and food", "page_id": "Biodiversity%20and%20food", "heading": "Productivity", "sub_heading": "Productivity", "_id": "52--0---1---1", "title": "Biodiversity in Agriculture and Natural Environments"}
{"qas": [{"question": "Why are there so many endangered species in the world?", "answer": ""}, {"question": "What are biologically diverse populations necessary for the production of?", "answer": "food", "ae_score": -0.853413738460244, "qg_score": null}, {"question": "What are biologically diverse populations necessary for the production of?", "answer": "food", "ae_score": -0.853413738460244, "qg_score": null}], "content": "A wide range of biologically diverse populations in natural ecosystems and in near agricultural ecosystems maintain essential ecological functions which are necessary for the production of food. For example, nutrient cycling, decomposition of organic matter, crusted or degraded soil rehabilitation, pest and disease regulation, maintaining water quality, and pollination.Maintaining this diversity of species and building on and enhancing ecosystem functions reduces external input requirements by increased nutrient availability, improved water use and soil structure, and natural control of pests.", "page_name": "Biodiversity and food", "page_id": "Biodiversity%20and%20food", "heading": "Maintenance of Food Production", "sub_heading": "Maintenance of Food Production", "_id": "52--1---1---1", "title": "Biologically Diverse Populations in Natural Ecosystems and Near Agriculture"}
{"qas": [{"question": "How did the world become so homogeneous?", "answer": ""}, {"question": "Between 1961 and 2009, the differences between the foods eaten in different countries were reduced by?", "answer": "68%", "ae_score": -0.6434956719357284, "qg_score": null}, {"question": "Between 1961 and 2009, the differences between the foods eaten in different countries were reduced by?", "answer": "68%", "ae_score": -0.6434956719357284, "qg_score": null}], "content": "Since 1961, human diets across the world have become more diverse in the consumption of major commodity staple crops, with a corollary decline in consumption of local or regionally important crops, and thus have become more homogeneous globally. The differences between the foods eaten in different countries were reduced by 68% between 1961 and 2009. The modern \"global standard\"<ref name=Khoury/> diet contains an increasingly large percentage of a relatively small number of major staple commodity crops, which have increased substantially in the share of the total food energy (calories), protein, fat, and food weight that they provide to the world's human population, including wheat, rice, sugar, maize, soybean (by +284%<ref name=Kinver/>), palm oil (by +173%<ref name=Kinver/>), and sunflower (by +246%<ref name=Kinver/>). Whereas nations used to consume greater proportions of locally or regionally important crops, wheat has become a staple in over 97% of countries, with the other global staples showing similar dominance worldwide. Other crops have declined sharply over the same period, including rye, yam, sweet potato (by -45%<ref name=Kinver/>), cassava (by -38%<ref name=Kinver/>), coconut, sorghum (by -52%<ref name=Kinver/>) and millets (by -45%<ref name=Kinver/>).<ref name=Khoury/>", "page_name": "Biodiversity and food", "page_id": "Biodiversity%20and%20food", "heading": "Change in biodiversity in human diets", "sub_heading": "Change in biodiversity in human diets", "_id": "52--2---1---1", "title": "Biodiversity and food | Change in biodiversity in human diets"}
{"qas": [{"question": "Why are there so few plant species in the world?", "answer": ""}, {"question": "What is being found in the rest of plant species to widen the diversity of food source?", "answer": "New crops", "ae_score": -0.6573080326048171, "qg_score": null}, {"question": "What is being found in the rest of plant species to widen the diversity of food source?", "answer": "New crops", "ae_score": -0.6573080326048171, "qg_score": null}], "content": "Very small proportion of plant species have been the food source on a large scales.Relying on too few species of crops and animals is a threat to the survival of Human. It is illustrated by the Great Irish Potato Famine.Potatoes were introduced into Ireland from the New World in about 1600 and it became the major food source of most of the Irish people eventually. The wind-borne Potato blight fungus spread throughout the country In 1845-1847. and caused almost complete failure of the potato crop. It is estimated that 1 million people died of starvation, cholera and typhoid.\nNew crops are being found in the rest of plant species to widen the diversity of food source, which avoid to rely on few species too much.", "page_name": "Biodiversity and food", "page_id": "Biodiversity%20and%20food", "heading": "New Crops and Biodiversity", "sub_heading": "New Crops and Biodiversity", "_id": "52--3---1---1", "title": "The Great Irish Potato Famine"}
{"qas": [{"question": "Why are there so many indigenous people in the world?", "answer": ""}, {"question": "What percentage of national food supplies as a global mean were derived from foreign crops?", "answer": "68.7%", "ae_score": -0.7144019856023185, "qg_score": null}, {"question": "What percentage of national food supplies as a global mean were derived from foreign crops?", "answer": "68.7%", "ae_score": -0.7144019856023185, "qg_score": null}], "content": "In 2016, researchers linked the centers and primary regions of diversity (\"areas typically including the locations of the initial domestication of crops, encompassing the primary geographical zones of crop variation generated since that time, and containing relatively high species richness in crop wild relatives\") of food and agricultural crops with their current importance around the world in modern national food supplies and agricultural production. The results indicated that countries are highly interconnected with regard to primary regions of diversity of the crops they cultivate and/or consume. Foreign crops (crops entirely from regions of diversity outside the location of the country) were extensively used in food supplies (68.7% of national food supplies as a global mean were derived from foreign crops) and production systems (69.3% of crops grown were foreign). Foreign crop usage was shown to have increased significantly over the past 50 years, including in countries with high indigenous crop diversity.", "page_name": "Biodiversity and food", "page_id": "Biodiversity%20and%20food", "heading": "Geographic patterns of biodiversity and food", "sub_heading": "Geographic patterns of biodiversity and food", "_id": "52--4---1---1", "title": "Food and Agriculture Crops in the Global Food Supply and Production Systems"}
{"qas": [{"question": "How does credit rationing work?", "answer": ""}, {"question": "What is it called when you ration food in times of war?", "answer": "Credit rationing", "ae_score": -0.6663405600783918, "qg_score": null}, {"question": "What is it called when you ration food in times of war?", "answer": "Credit rationing", "ae_score": -0.6663405600783918, "qg_score": null}], "content": "Credit rationing is not the same phenomenon as the better-known case of food rationing, common in times of war. In that case, shortages lead governments to control the food portions allocated to individuals, who would be willing to pay higher prices for more portions. However, credit rationing is not necessarily the result of credit shortages but rather of asymmetric information. More importantly, food rationing is a result of direct government action, while credit rationing is a market outcome.Three main types of credit rationing can usually be distinguished:", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Forms of Credit Rationing", "sub_heading": "Forms of Credit Rationing", "_id": "53--0---1---1", "title": "Credit Rationing \u2014 Credit Rrationing"}
{"qas": [{"question": "How does the credit market work?", "answer": ""}, {"question": "What is the role of the market in credit rationing?", "answer": "allocational", "ae_score": -0.30477099506589356, "qg_score": null}, {"question": "What is the role of the market in credit rationing?", "answer": "allocational", "ae_score": -0.30477099506589356, "qg_score": null}], "content": "One of the main roles markets play is allocational; they allocate goods to the buyers with the highest valuation. Market equilibrium occurs when the demand of a good at the equilibrium price is equal to the supply of the good. If prices are deemed \"too high\" by the consumers, supply will exceed demand, and sellers will have to reduce their prices until the market clears (i.e. equilibrium is reached). On the other hand, if prices are \"too low\", then demand will be higher than supply, and prices will have to be raised to obtain market clearing.\nThe graph to the right shows this simplified case for the credit market. The interest rate is denoted by r, and S and I denote savings and investment respectively. This is a highly stylised example, where one abstracts from changes in output, and where the economy is in financial autarky (and, consequently, savings and investment express the supply and demand of loanable funds, respectively).\nEquilibrium will be attained at the point where S=I, at the equilibrium interest rate r*. At r>r*, credit is \"too expensive\", as the interest rate is effectively the price of credit, and there is a resulting excess supply of credit. The interest rate will have to fall in order to clear the market.\nThe more mundane case of credit rationing occurs when the credit market is, for one reason or another, out of equilibrium. This could be either because of some friction in the market, or some government policy (such as anti-usury laws), which prevent supply and demand from being equalised. This has hardly a precise definition, but one should think of disequilibrium outcomes as temporary adjustments to shocks as the economy moves back to the long run equilibrium i.e. the equilibrium that will attain over some indeterminate amount of time in the absence of more external shocks. The main distinguishing factor between equilibrium and disequilibrium rationing in the credit markets is that the latter is not a long term feature, and can be alleviated through changes in policy or simply through time, and does not necessarily reflect chronic or structural features of the credit market. The most important contribution in this vein was by Dwight Jaffee and Franco Modigliani, who first introduced this idea within a supply and demand framework.\nThe more interesting case, that of equilibrium credit rationing, is the result of structural features of the market (in particular, adverse selection), and will characterise long run market outcomes (barring some technological breakthrough), and is analysed below.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Theoretical background", "sub_heading": "Theoretical background", "_id": "53--1---1---1", "title": "Credit rationing in the Credit Market"}
{"qas": [{"question": "What does it mean for the banks when they say that the interest rates are going to rise?", "answer": ""}, {"question": "What is the interest rate on which credit is rationed?", "answer": "r1", "ae_score": -0.2852506524619677, "qg_score": null}, {"question": "What is the interest rate on which credit is rationed?", "answer": "r1", "ae_score": -0.2852506524619677, "qg_score": null}], "content": "In a framework similar to Stiglitz and Weiss, one can imagine a group of individuals, prospective borrowers, who want to borrow funds in order to finance a project, which yields uncertain returns. Let there be two types of individuals, who are observationally identical, and only differ in the riskiness of their projects. Assume type A individuals are low risk compared to type B, in the sense that the expected return on type B projects is a mean preserving spread of type A projects; they have the same expected return, but higher variance.\nFor example, imagine that type A returns are uniformly distributed (meaning that all possible values have the same probability of occurring) from $75 to $125, so that the value of type A projects is at least $75 and at most $125, and the expected value (mean) is $100.\nNow, assume type B project returns are also uniformly distributed, but their range is from $50 to $150. Type B project returns also have an expected value of $100, but are more risky.\nNow assume that the bank knows that two types exist, and even knows what fraction of the potential borrowers applying for loans belong to each group, but cannot tell whether an individual applicant is type A or B. The implication to the bank of the difference in the riskiness of these projects is that each borrower has a different probability of repaying the loan, and this affects the bank's expected return. The bank would thus like to be able to identify (screen) the borrower types, and in the absence of other instruments to do so, it will use the interest rate.\nThis was the main intuitive observation of Stiglitz and Weiss. They realised that an individual that is willing to accept a higher interest rate in her loan is doing so because she knows that the riskiness of her project is such that there is lower probability of repaying the loan. In a limited liability setting, where the personal assets of the borrower might not be taken as collateral, the borrower might not object to paying a high enough interest rate, as she knows that the probability of the project succeeding is low, so probability of repayment is low. Even if the project does succeed, the returns will be high enough for a profit to be left after repaying the loan. The safe borrowers have a high probability of repaying their loan, so even a modest interest rate, relative to their expected return, is likely to result in an unprofitable contract.\nWhat this implies for the banks is that there will be a range of relatively low interest rates below which all the applicants will accept the loan, and a cut off point above which the safe borrowers decide to drop, as expected repayment becomes too high. In fact, as interest rates rise, the critical value of the project (think of it as expected return), above which the borrower is willing to borrow the money, also rises. Naturally, there exists a (higher) cut off point for the risky types as well, above which even they would not be willing to borrow.\nThis situation should show that the interest rate has two effects on banks' expected return. On the one hand, higher interest rates imply that, for a given loan, the repayment (if it does take place) will be higher, and this increases bank profits; this is the direct effect. On the other hand, and crucially for credit rationing, a higher interest rate might mean that the safe types are not anymore willing to accept the loans, and drop out of the market; this is the adverse selection effect.\nThese two effects together give an odd shape to the bank's expected return. It is strictly rising with the interest rate when the latter is low enough; at the point where the safe types drop out of the market (call it r1), expected return falls sharply, and then rises again, until the point where the risky types drop out as well (r2), falling to zero, as no one is accepting loans. Technically speaking, the expected return is non-monotonic in the interest rate, as it rising, then falling sharply, then rising again until it falls sharply to zero.\nIt follows then that if the level of the interest rate that maximises the bank's expected return is lower than the level after which risky types drop out, there might be credit rationing, if the supply of funds is low enough. If the optimal rate (from the point of view of the bank) is between r1 and r2, then only some of the risky types will be rationed (the safe types are unwilling to borrow at such a rate); they will not be given credit even at higher rates. If the optimal rate is below r1, then borrowers of both types will be rationed.\nIt might be more intuitive to imagine a situation with a very large number of types (continuum). In that case, the expected return function of the bank will become smooth, rising for low levels of the interest rate, until the optimal rate, and then falling smoothly until it reaches zero. Types that would be willing to borrow at rates higher than the optimal might be rationed.\nIt is important to note that as the supply of funds to the bank rises, some of the rationed people will get a loan, but at the same interest rate, which is still at the profit maximising level. For a sufficient rise in supply, everyone will receive loans, at which point the interest rate will have to fall.\nFinally, if the optimal rate is high enough, we might have no rationing. This will happen if the level of the interest rate such that current supply of funds equal demand for funds is lower than the optimal rate, and equal to r1.  All the borrowers will receive funds at that rate.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Equilibrium credit rationing - Stiglitz and Weiss", "sub_heading": "Equilibrium credit rationing - Stiglitz and Weiss", "_id": "53--2--0---1", "title": "How the interest rate affects the bank's expected return"}
{"qas": [{"question": "Why is it that type 1 borrowers can get credit, but type 2 borrowers can't?", "answer": ""}, {"question": "What is it called when credit is rationed?", "answer": "Redlining", "ae_score": -0.5598090153721519, "qg_score": null}, {"question": "What is it called when credit is rationed?", "answer": "Redlining", "ae_score": -0.5598090153721519, "qg_score": null}], "content": "Redlining is a different situation, as it is not the result of adverse selection. In fact, the bank can perfectly distinguish between the different types of buyers according to some criterion. Each type is assumed to have a different expected return function (from the point of view of the bank).\nAs an illustration, consider the case of three types, 1, 2 and 3, which are ranked according to the maximum expected return they give to the bank, from lowest to highest. The maximum expected return a type 3 borrower can give to the bank (at the optimal interest rate for the borrower) is higher than that of type 2, which is higher than that of type 1.\nFor a sufficiently high cost of obtaining funds, only type 3 borrowers will receive credit. This will occur if the maximum expected return from type 2 borrowers is lower than that cost. If costs fall by enough, type 2 borrowers will obtain credit, and if they fall further so will type 1 borrowers. Every type that receives credit will be charged different interest rates, but the expected return to the bank will be equal for each type, as long as there is competition between banks.\nIt is important to note that type 1 borrowers obtain credit only if type 2 borrowers are not rationed, and so on.\nThis argument is quite pertinent in the context of the subprime mortgage crisis. Low interest rate setting by the Federal Reserve made the cost of loanable funds extremely low. On the other hand, the securitization practices of firms in the credit markets significantly raised the profitability of loans to people with poor credit ratings (type 1 in the example above), and thus contributed to massive leveraging of borrowers who would ordinarily have had a hard time receiving even modest loans.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Equilibrium credit rationing - Stiglitz and Weiss", "sub_heading": "Redlining", "_id": "53--2--1---1", "title": "Redlining is not a result of adverse selection"}
{"qas": [{"question": "Why is it that if the supply of funds is increasing in the rate of return on deposits, there will be more investment?", "answer": ""}, {"question": "Who came up with the theory of credit rationing?", "answer": "David De Meza", "ae_score": null, "qg_score": null}, {"question": "Who came up with the theory of credit rationing?", "answer": "David De Meza", "ae_score": null, "qg_score": null}], "content": "David De Meza and David C. Webb argued the possibility that adverse selection could lead to the flip side of what Stiglitz and Weiss considered, namely over-investment. Their argument runs along the same lines as Akerlof's market for lemons. In this setting, prospective buyers of used cars do not know the quality of the car they are thinking of purchasing; sellers know the value of their own cars. Assuming they know the distribution of car quality across the market, prospective buyers come to a maximum price they are willing to pay for the car. For example, suppose there are only two qualities, good cars (\"peaches\") and bad cars (\"lemons\"), worth $5000 and $1000, respectively. The buyer knows that half the cars are peaches and half are lemons. If she offers $5000, the sellers of either type surely accept, but the expected value of the car will only be equal to $3000 ($1000 with 50% probability and $5000 with 50% probability), so she will make expected losses of $2000. If she offers $3000, sellers of bad cars will accept but sellers of good cars will not (assuming that sellers are never willing to accept losses to liquidate the value of their cars). Every car she can buy for any price less than $5000 is therefore a lemon worth only $1000. Hence, she will only be willing to pay $1000; only the sellers of bad cars will accept, so the buyer will either end up with a bad car or with nothing. In this case, the adverse selection problem drives the good cars out of the market. Extending this logic to more qualities, under certain conditions, the market might completely collapse.\nApplying this framework to the market for credit, asymmetric information concerning the types of projects to be financed might lead to bad projects driving out good projects. De Meza and Webb's contribution is to show how the opposite might happen \u2013 that is, how good projects might draw in bad. Under some plausible conditions, the most crucial being that expected returns differ between different projects (whereas all projects in the Stiglitz and Weiss model have the same expected return but different levels of riskiness), they show that there cannot be a credit-rationing equilibrium. So the main difference here compared to Stiglitz and Weiss is that there is no specific level of the interest rate at which banks maximise profits \u2013 a small rise in interest rates if there is excess demand for credit will attract entrepreneurs and will not drive away existing borrowers.\nAs long as the supply of funds is increasing in the rate of return on deposits, there will be more investment compared to what the efficient solution would imply, that is, the level of investment that would take place if there were no asymmetry of information, and only the projects that should be financed are financed. The intuition is straightforward. If investment were lower than the efficient level, so would be the return on deposits. In addition, as less investment is taking place, the \"worst\" project that is financed must be better from the bank's point of view than the worst project that would be financed if investment were optimal. But if the bank is making a profit on the worst project that is financed, it will also be making profits on even worse projects (which were not financed before), leading to oversupply of credit and thus overinvestment.\nWhen comparing their model to Stiglitz and Weiss, De Meza and Webb show that if credit rationing occurs in Stiglitz and Weiss, the volume of lending is actually higher than it would have been in the absence of rationing. This prompted a sister paper by the same authors, where they show that, on the one hand, credit rationing can occur even under symmetric information, and, on the other, that it might not imply a market failure. This severely limits the scope of government intervention.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Other contributions", "sub_heading": "Other contributions", "_id": "53--3--0---1", "title": "Asymmetric Information in the Market for Credit: A Case Study"}
{"qas": [{"question": "Why is it necessary for banks to observe the borrower's behavior in order to make a loan?", "answer": ""}, {"question": "What is the main cause of credit rationing?", "answer": "moral hazard", "ae_score": -0.6272006959124834, "qg_score": null}, {"question": "What is the main cause of credit rationing?", "answer": "moral hazard", "ae_score": -0.6272006959124834, "qg_score": null}], "content": "Bengt Holmstrom and Jean Tirole (1998) provide an example of credit rationing where asymmetric information does not lead to adverse selection, but instead moral hazard, the situation where deliberate actions by one of the parties of the contract, after the contract is signed, might affect outcomes. In their model, there are many entrepreneurs-borrower firms of only one type, who want to finance an investment opportunity, and have an initial level of assets that falls short of the amount needed for the investment. The twist in this model, compared to the cases described above, is that entrepreneurs can influence the outcome of the investment, by exerting high or low effort. High effort implies a high probability of a successful outcome, and low effort implies a lower one, but also gives a benefit to each borrower, in terms of higher leisure. So there is an incentive by borrowers not to exert high effort, even though doing so will result in higher probability of a successful outcome.\nCompetition between lenders and high effort by borrowers ensure positive outcomes for the society, so investment should take place. However, the fact that the lenders cannot observe the borrowers' behaviour implies that there is a minimum level of firm assets needed for banks to provide the loan. The firms will have to provide some of the project financing \"out of their own pocket\" and thus incur some of the investment risk. This will provide the bank with the necessary guarantee that the borrower has personal stakes in the success of the investment, and stands to make losses if it is unsuccessful, so that she will be interested in exerting high effort, making the bank willing to make the loan.\nIf a firm does not have the minimum amount of assets available (call it ''X''), then its project will not be financed, and we will have credit rationing. This is the result of moral hazard, which creates what is termed in the literature as an agency cost, and can be thought of as arising from the benefit the borrower makes by exerting low effort. Higher agency cost and lower initial assets lead to more credit rationing.\nMoral hazard in credit markets was likely a major contributor to the subprime mortgage crisis and the ensuing credit crunch. In the context of this model, one can think of borrowers being real estate investors (or simply home owners investing in property) that used their current housing holdings as collateral assets when applying for loans. With rising house prices, and, more importantly, with the ''expectation'' of future rises in housing price, the expected return on the project to be financed was perceived to be higher than suggested by fundamentals, leading, on the one hand, to ever lower required ''X'' by banks in order to make loans, and, on the other, to inflated estimates of the value of the borrowers' initial assets. This led to less credit rationing, to the extent that good investments that should be undertaken got their financing, but also to subprime lending, where bad loans to poor projects were made. When the housing bubble burst, housing prices plummeted, so the expected return on projects fell, implying that banks needed very large initial assets holding, making lending scarcer and more difficult, resulting in a credit crunch. This provides a framework under which some credit rationing might be optimal, as a way of screening potentially harmful investments.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Other contributions", "sub_heading": "Moral hazard and credit rationing", "_id": "53--3--1---1", "title": "Credit rationing in the context of moral hazard"}
{"qas": [{"question": "Why do some countries default on their debts?", "answer": ""}, {"question": "If a country is unable or unwilling to pay its debts, what can international lenders do?", "answer": "renegotiate", "ae_score": -0.5341482960768219, "qg_score": null}, {"question": "If a country is unable or unwilling to pay its debts, what can international lenders do?", "answer": "renegotiate", "ae_score": -0.5341482960768219, "qg_score": null}], "content": "Finally, it is worthwhile to consider how credit rationing might arise as a feature of sovereign (government) lending, that is, lending to countries. Sovereign lending is a very different story than domestic lending, due to the absence of enforcement mechanisms in the case of bankruptcy, as there is no internationally acknowledged agency for such issues. If a country for one reason or another announces that it is either unable or unwilling to pay its debts, the most international lenders can do is renegotiate. Some experts believe that the threat of the country being shut off from financial markets if it defaults is not credible, as it has to be the case that absolutely no-one is willing to lend. Others stress that though this might be true for the short trem, there are other reputational reasons why a country might want to avoid debt repudiation, mainly pertaining to the maintenance of good foreign relations, which allows access to international trade and technological innovations\nWith these caveats, it is worthwhile to consider how reputation concerns can lead to credit rationing. The seminal contribution is by Jonathan Eaton and Mark Gersovitz, who consider a simple model of international lending for a small open economy. Lenders set a maximum amount they are willing to lend (credit ceiling), which might be smaller or larger than the borrowing needs of the country. Countries face a penalty if they default, and whenever they are supposed to make debt payments, they consider whether they would be better off by defaulting, paying the penalty, and be forever barred from international credit markets, or pay the debt installment, borrowing again, and making the same decision next period.\nAs the probability of default is higher when debt is higher, there exists a level of lending that maximises expected return to the lender, and so the credit ceiling will depend on the probability of default. If desired lending is higher than the credit ceiling, some countries will not receive funds, and credit rationing will occur. This setting is reminiscent of Stiglitz and Weiss, as the interest rate has an incentive effect, and does not play the standard allocational role prices are supposed to play. As in that case, the allocation mechanism in Eaton and Gersovitz is credit rationing, which is not related to interest rate (the price of credit); at the going rate, countries want to borrow more but credit is denied.", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Other contributions", "sub_heading": "Credit rationing in sovereign lending", "_id": "53--3--2---1", "title": "Credit Rationing in Sovereign (Governmental) Lending"}
{"qas": [{"question": "Why was David Harrod so skeptical about the Federal Reserve's interest rate?", "answer": ""}, {"question": "What is the process through which interest rates curtailed economic activity called?", "answer": "credit rationing", "ae_score": -0.13021422519354195, "qg_score": null}, {"question": "What is the process through which interest rates curtailed economic activity called?", "answer": "credit rationing", "ae_score": -0.13021422519354195, "qg_score": null}], "content": "Roy Harrod pointed to the existence of credit rationing early on. In his book ''Money'' he wrote that capital markets are highly imperfect and that in many markets there is no market price for certain customers. He argued that this was because these markets were characterized by negotiation processes that were liable to break down before a market price could be reached.\nHarrod was also skeptical about the traditional transmission mechanism of monetary policy. Drawing on the famous Oxford surveys of businessmen in the 1930s he argued that it was likely that changes in the interest rate did not have a substantial effect on investment decisions. Harrod went on to argue that the main channel through which interest rates curtailed economic activity was through the process of what is now known as credit rationing. He wrote that: \"It is essentially the imperfection of the capital market that makes monetary policy a powerful weapon.\" ", "page_name": "Credit rationing", "page_id": "Credit%20rationing", "heading": "Other contributions", "sub_heading": "Roy Harrod and the Effectiveness of Monetary Policy", "_id": "53--3--3---1", "title": "''Money'' and Credit Rationalization"}
{"qas": [{"question": "Why are there so many different types of feed additives for farm animals?", "answer": ""}, {"question": "What are the different categories of feed additives for farm animals called?", "answer": "natural growth promoters", "ae_score": -0.43334687137611033, "qg_score": null}, {"question": "What are the different categories of feed additives for farm animals called?", "answer": "natural growth promoters", "ae_score": -0.43334687137611033, "qg_score": null}], "content": "Different categories of feed additives for farm animals are referred to as natural growth promoters (NGPs) or non-antibiotic growth promoters. They are commonly regarded as favorable alternatives to antibiotic growth promoters (AGPs) in livestock production.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Definition", "sub_heading": "Definition", "_id": "54--0---1---1", "title": "Natural Growth Promoters (NGPs) and Non-Antibiotic Growth Promoters ("}
{"qas": [{"question": "What are Natural Foods?", "answer": ""}, {"question": "What is the term for a natural growth promoter?", "answer": "NGPs", "ae_score": -1.330020443172377, "qg_score": null}, {"question": "What is the term for a natural growth promoter?", "answer": "NGPs", "ae_score": -1.330020443172377, "qg_score": null}], "content": "NGPs include predominantly organic acids, probiotics, prebiotics, synbiotics, phytogenics, tannins, feed enzymes and immune stimulants., an ongoing search for alternatives has created a large variety of NGPs for pigs, poultry, ruminants and aquatic species.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Categories", "sub_heading": "Categories", "_id": "54--1---1---1", "title": "NGPs for pigs, poultry, ruminants, aquatic species"}
{"qas": [{"question": "What are the advantages and disadvantages of NGPs over AGPs?", "answer": ""}, {"question": "What is the main risk of using npos in farm animals?", "answer": "bacterial resistance", "ae_score": -1.7184338237637953, "qg_score": null}, {"question": "What is the main risk of using npos in farm animals?", "answer": "bacterial resistance", "ae_score": -1.7184338237637953, "qg_score": null}], "content": "The main advantage of NGPs over AGPs is that they do usually not bear any risk regarding bacterial resistance or undesired residues in animal products such as meat, milk or eggs. Addition of NGPs to feeds of farm animals may have a number of beneficial effects, including:", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "General benefits", "sub_heading": "General benefits", "_id": "54--2---1---1", "title": "NGPs and AGPs in Animal Feeds and Feeds"}
{"qas": [{"question": "What are acidifiers and how do they work?", "answer": ""}, {"question": "What type of conditions are beneficial to the growth of bacteria?", "answer": "low gastrointestinal pH", "ae_score": -1.7028286564283919, "qg_score": null, "filter_answer": "acidifiers"}, {"question": "What type of conditions are beneficial to the growth of bacteria?", "answer": "low gastrointestinal pH", "ae_score": -1.7028286564283919, "qg_score": null, "filter_answer": "acidifiers"}], "content": "Acidifiers, such as organic acids or their salts, are used to prevent microbial degradation of raw materials or finished feeds, especially under poor storage conditions (e.g. high moisture content, high levels of contamination with molds). Moreover, acidifiers may improve growth performance through establishment of low gastrointestinal pH conditions which support endogenous digestive enzymes and reduce undesired gut microorganisms. Many dietary acidifiers are based on propionic acid, formic acid, lactic acid and others, either as single components or in combination. Some acidifiers also contain inorganic acids (e.g. phosphoric acid).", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Mode of action", "_id": "54--3--0---1", "title": "Acidifiers for Food Production"}
{"qas": [{"question": "What are probiotics and how do they work?", "answer": ""}, {"question": "How are bacteria able to promote growth in the gut?", "answer": "blocking receptors on the gut wall", "ae_score": -1.306175119157998, "qg_score": null}, {"question": "How are bacteria able to promote growth in the gut?", "answer": "blocking receptors on the gut wall", "ae_score": -1.306175119157998, "qg_score": null}], "content": "Probiotics are live microorganisms or viable spores which support the development of a beneficial gut microflora. Probiotic bacteria (e.g. from the genera ''Lactobacillus'', ''Bifidobacterium'', ''Enterococcus'') counteract undesired microorganisms such as ''Salmonella'' or ''E. coli'' by blocking receptors on the gut wall, production of antimicrobial substances or activation of the immune system.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Probiotics", "_id": "54--3--1---1", "title": "Probiotics are live microorganisms or viable spores which support "}
{"qas": [{"question": "What is the difference between prebiotics and probiotics?", "answer": ""}, {"question": "A natural growth promoter that is fermented by beneficial gut bacteria is?", "answer": "Prebiotics", "ae_score": -0.7064034091748175, "qg_score": null}, {"question": "A natural growth promoter that is fermented by beneficial gut bacteria is?", "answer": "Prebiotics", "ae_score": -0.7064034091748175, "qg_score": null}], "content": "Prebiotics are carbohydrates which are indigestible for the host animal. On the other hand, they are selectively fermented by beneficial gut bacteria and, therefore, support a healthy gut microflora. These include fructose oligosaccharides (FOS) including inulin, transgalactose oligosaccharides (GOS), xylooligosaccharides (XOS) and soy oligosaccharides such as stachyose, verbose and raffinose.  Mannan oligosaccharides are sometimes included as prebiotics but are not fermentable.  This was confirmed by Smiricky-Tjardes ''et al.'' at the University of Illinois and so might be more appropriately termed immunosaccharides since they act as decoys for pathogen attachment (''Salmonella'' and ''E. Coli'') and result in increased immunoglobulins (IgAs) at intestinal level.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Prebiotics", "_id": "54--3--2---1", "title": "Prebiotics and Immunoglobulins in the Gut"}
{"qas": [{"question": "What are phytogenics and how do they work?", "answer": ""}, {"question": "A natural growth promoter that increases palatability of the feed is called?", "answer": "Phytogenics", "ae_score": -0.6157567706608104, "qg_score": null}, {"question": "A natural growth promoter that increases palatability of the feed is called?", "answer": "Phytogenics", "ae_score": -0.6157567706608104, "qg_score": null}], "content": "Phytogenics are derived from herbs, spices or aromatic plants and have shown antimicrobial, antifungal, antiviral, antioxidant or sedative properties. They are known for their appetizing effects, since they increase the palatability of the feed and stimulate endogenous digestive enzymes. Moreover, phytogenics have a pronounced impact on the gut microflora.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Phytogenics", "_id": "54--3--4---1", "title": "Phytogenics are derived from herbs, spices or aromatic plants and have shown their"}
{"qas": [{"question": "What are tannins and how do they work?", "answer": ""}, {"question": "What is the most common source of tannins in a plant?", "answer": "chestnut", "ae_score": -0.6327160995178175, "qg_score": null}, {"question": "What is the most common source of tannins in a plant?", "answer": "chestnut", "ae_score": -0.6327160995178175, "qg_score": null}], "content": "Tannins are polyphenolic compounds produced by plants, ranging in concentrations from <2% to more than 20% of dry weight and may protect plants from herbivore, increase resistance against pathogens, or protect tissues such as wood against decay. In-vitro and in-vivo results suggest that two of the most abundant and common source of tannins, chestnut (''Castanea sativa''; hydrolyzable tannins) and quebracho (''Schinopsis lorentzii'', condensed tannins) extracts, are effective to reduce and control infection. Moreover are considered a natural alternative to AGPs due to the difficulty of bacteria to develop resistance against the diverse range of molecules that contain these plant compounds.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Tannins", "_id": "54--3--5---1", "title": "Tannins are a natural alternative to AGPs"}
{"qas": [{"question": "How do animal feeds work?", "answer": ""}, {"question": "What are some natural growth promoters that can be found in young animals?", "answer": "lipases", "ae_score": -1.9772212616526974, "qg_score": null}, {"question": "What are some natural growth promoters that can be found in young animals?", "answer": "lipases", "ae_score": -1.9772212616526974, "qg_score": null}], "content": "Animal feeds contain varying levels of indigestible nutrients and undesired components such as fiber, phytate or proteins with antigenic effects. Different feed enzymes such as, carbohydrases, phytases or proteases, can be included in feeds to improve the utilization of energy and nutrients or to degrade several undesired components. Moreover, some enzymes (e.g. amylases, lipases) can be added to the feed of young animals in order to support the endogenous enzyme secretions.", "page_name": "Natural growth promoter", "page_id": "Natural%20growth%20promoter", "heading": "Mode of action", "sub_heading": "Feed enzymes", "_id": "54--3--6---1", "title": "Animal Feed Enzymes"}
{"qas": [{"question": "What is gaffkaemia?", "answer": ""}, {"question": "When was gaffkaemia first discovered in the wild?", "answer": "1947", "ae_score": -0.265312981592015, "qg_score": null}, {"question": "When was gaffkaemia first discovered in the wild?", "answer": "1947", "ae_score": -0.265312981592015, "qg_score": null}], "content": "Gaffkaemia was first discovered in 1947 in American lobsters (''Homarus americanus'') in a holding tank in Maine. It was originally described as \"''Gaffkya homari''\" by Hitcher and Snieszko, but the genus name ''Gaffkya'' was rejected in 1971, and the gaffkaemia bacterium was recognised as a subspecies or variety of ''Aerococcus viridans'' by Kelly and Evans in 1974.", "page_name": "Gaffkaemia", "page_id": "Gaffkaemia", "heading": "Discovery", "sub_heading": "Discovery", "_id": "55--0---1---1", "title": "''Gaffkya homari'' \u2014 Gaffkaemia"}
{"qas": [{"question": "What happens to a lobster when it has a heart attack?", "answer": ""}, {"question": "How many bacteria can cause gaffkaemia in a lobster?", "answer": "five", "ae_score": -0.7858994645452811, "qg_score": null}, {"question": "How many bacteria can cause gaffkaemia in a lobster?", "answer": "five", "ae_score": -0.7858994645452811, "qg_score": null}], "content": "The effects of gaffkaemia infection include lethargy (typically seen as a drooping tail), anorexia and a pink colour on the ventral side of the abdomen, which gives the disease its alternative common name of ''red tail disease''. When lobsters are moribund, they may lie on their sides, and frequently lose appendages. The effects of gaffkaemia are slowed by low temperatures, such that death can occur within two days of infection at 20 C, but can take over 60 days at 3 C.\nAs few as five bacteria can lead to clinical disease. When they enter the host, the bacteria colonise the heart and hepatopancreas. They may be engulfed by phagocytosis into the lobster's blood cells, but continue to survive within the blood cells, feeding on the cytoplasm. The lobster's blood cell count drops, and the infection develops into septicaemia. The stores of glycogen in the hepatopancreas become depleted, concentrations of glucose and lactic acid in the blood drop, and concentrations of adenosine triphosphate (ATP) in muscles also fall. In a severe infection, the ability of the lobster's blood pigment haemocyanin to carry oxygen may be reduced by up to 50%.", "page_name": "Gaffkaemia", "page_id": "Gaffkaemia", "heading": "Effects", "sub_heading": "Effects", "_id": "55--1---1---1", "title": "Gaffkaemia in Lobsters \u2014 Symptoms, Causes and Treatment"}
{"qas": [{"question": "How do we know that haemolymph is a virus?", "answer": ""}, {"question": "What is the name of the method used to diagnose gaffkaemia?", "answer": "indirect fluorescent antibody technique", "ae_score": -0.2395120367169272, "qg_score": null}, {"question": "What is the name of the method used to diagnose gaffkaemia?", "answer": "indirect fluorescent antibody technique", "ae_score": -0.2395120367169272, "qg_score": null}], "content": "The classical method of diagnosis is to culture aliquots of haemolymph in phenylethyl alcohol broth. Cultures containing ''A. viridans'' var. ''homari'' change colour from purple to yellow, and form tetrads of cocci. To reduce the four-day waiting time needed for diagnosis, a method using the indirect fluorescent antibody technique (IFAT) was developed, and, more recently, PCR-based methods have been developed.", "page_name": "Gaffkaemia", "page_id": "Gaffkaemia", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "55--2---1---1", "title": "''A. viridans'' var. ''homari'"}
{"qas": [{"question": "How does gaffkaemia affect lobsters?", "answer": ""}, {"question": "What disease is caused by the bacterium homarus gammarus?", "answer": "Gaffkaemia", "ae_score": -0.916805636288881, "qg_score": null}, {"question": "What disease is caused by the bacterium homarus gammarus?", "answer": "Gaffkaemia", "ae_score": -0.916805636288881, "qg_score": null}], "content": "Gaffkaemia is enzootic in North America, and causes little harm to wild populations of ''H. americanus''. In the European or common lobster, ''Homarus gammarus'', however, it is far more destructive. European lobsters held in the same tanks as American lobsters can be killed within days. A number of other crustacean species can be infected with ''A. v.'' var. ''homari'', but do not develop severe disease. They include the shrimp ''Pandalus platyceros'', and the crabs ''Cancer borealis'', ''Cancer irroratus'', ''Metacarcinus magister'', ''Libinia emarginata'', ''Chionoecetes opilio'' and ''Chaceon quinquedens''. Spiny lobsters appear to be either immune or resistant to gaffkaemia.", "page_name": "Gaffkaemia", "page_id": "Gaffkaemia", "heading": "Virulence", "sub_heading": "Virulence", "_id": "55--3---1---1", "title": "Gaffkaemia in the European Lobster"}
{"qas": [{"question": "How do lobsters prevent gaffkaemia?", "answer": ""}, {"question": "What is the main treatment for gaffkaemia?", "answer": "improved hygiene", "ae_score": -0.4912991039704237, "qg_score": null}, {"question": "What is the main treatment for gaffkaemia?", "answer": "improved hygiene", "ae_score": -0.4912991039704237, "qg_score": null}], "content": "The primary method for controlling the incidence of gaffkaemia is improved hygiene. Other measures include limiting damage to the exoskeleton (preventing the bacterium's entry), reducing the water temperature, and reducing the stocking density. Antibiotics may be effective against the bacterium, but only tetracycline is currently approved by the U.S Food and Drug Administration for use in American lobsters.", "page_name": "Gaffkaemia", "page_id": "Gaffkaemia", "heading": "Control", "sub_heading": "Control", "_id": "55--4---1---1", "title": "Gaffkaemia in American lobsters"}
{"qas": [{"question": "Why does ice water feel so much colder than normal water?", "answer": ""}, {"question": "Who was the first woman to take an ice bath?", "answer": "Karyn Marshall", "ae_score": -0.2526642853319495, "qg_score": null}, {"question": "Who was the first woman to take an ice bath?", "answer": "Karyn Marshall", "ae_score": -0.2526642853319495, "qg_score": null}], "content": "It is done by standing or sitting in a bucket or bath of icy water. One writer advised: \"don't overdo it.\"<ref name=twsAugN31x/> Wearing rubberized \"dive booties\" on the feet (to protect toes) as well as rubber briefs to warm the midsection have been recommended. Champion weightlifter Karyn Marshall, who won the world women's weightlifting championship in 1987, described what it was like to take an ice bath after a day of competition at the CrossFit Games in 2011 in Los Angeles:\nOne report suggested that if ice water is circulating, it's even colder such that the water will be colder than measured by a thermometer, and that athletes should avoid overexposure. Physical therapist Nikki Kimball explained a way to make the bath more endurable:\nSome athletes use a technique known as contrast water therapy or contrast bath therapy, in which cold water and warmer water are alternated.<ref name=twsAugN31x/> One method of doing this was to have two tubs\u2013\u2013one cold (10\u201315 degrees Celsius) and another hot (37\u201340 degrees Celsius) \u2013\u2013and to do one minute in the cold tub followed by two minutes in a hot tub, and to repeat this procedure three times.<ref name=twsAugN31x/>\nThe temperature can vary, but is usually in the range of 50\u201359 degrees Fahrenheit<ref name=twsM36/><ref name=twsAugN27/> or between 12 and 15 degrees Celsius.<ref name=twsAugN31x/> Some athletes wear booties to keep their toes warm<ref name=twsM36/> or rubberized coverings around their midsection while immersed. Some drink a warm beverage such as tea.<ref name=twsM36/> One report suggested that \"ten minutes immersed in 15 degree Celsius water\" was sufficient.<ref name=twsAugN31x/>\nAccounts vary about how long to be immersed and how often to do them. One adviser suggested that an athlete should take ten two-minute ice bath treatments over a two-week period. One account suggested immersion times should be between ten and twenty minutes.<ref name=twsAugN27/> Another suggested that immersion run from five to ten minutes, and sometimes to twenty minutes.<ref name=twsAugN31x/> There were no sources advocating being immersed for longer than twenty minutes.\nSeveral sources suggest that cold baths (60\u201375 degrees Fahrenheit) were preferable to ice baths. Physiotherapist Tony Wilson of the University of Southampton said that extremely cold temperatures were unnecessary and a \"cold bath\" would be just as effective as an ice bath.<ref name=twsM46/> Another agreed that a mere cold bath is preferable to ice baths which are \"unnecessary.\"<ref name=twsAugN31x/> A third report suggested that cool water (60\u201375 degrees Fahrenheit) was just as good as cold water (54\u201360 degrees Fahrenheit) and that eight to ten minutes should be sufficient time, and warned against exceeding ten minutes.<ref name=twsAugN32/>", "page_name": "Ice bath", "page_id": "Ice%20bath", "heading": "Techniques", "sub_heading": "Techniques", "_id": "56--0---1---1", "title": "ICE BATHS ARE NOT THERE TO BE"}
{"qas": [{"question": "Why are ice baths so dangerous?", "answer": ""}, {"question": "What are the risks of taking an ice bath?", "answer": "hypothermia", "ae_score": -0.4531584125096251, "qg_score": null}, {"question": "What are the risks of taking an ice bath?", "answer": "hypothermia", "ae_score": -0.4531584125096251, "qg_score": null}], "content": "There is agreement in the medical and scientific communities that ice baths can pose serious risks to health. Risks include hypothermia,<ref name=twsHypoT1/> shock<ref name=twsFallSkinTemp/> and the possibility of sudden cardiac death.<ref name=twsHypoT1/><ref name=twsColdShock2/><ref name=twsCardiac/>", "page_name": "Ice bath", "page_id": "Ice%20bath", "heading": "Safety", "sub_heading": "Safety", "_id": "56--2---1---1", "title": "Ice bath | Safety"}
{"qas": [{"question": "Why do people ice swim in the middle of winter?", "answer": ""}, {"question": "Which british marathon runner said \u2018it\u2019s absolute agony and i?", "answer": "Paula Radcliffe", "ae_score": -0.18988985972186292, "qg_score": null}, {"question": "Which british marathon runner said \u2018it\u2019s absolute agony and i?", "answer": "Paula Radcliffe", "ae_score": -0.18988985972186292, "qg_score": null}], "content": "There have been traditions of people ice swimming in the middle of winter on a lake for short stretches, sometimes as part of a Polar Bear Club. Sometimes people taking short swims for thirty seconds or so have felt invigorated afterwards.<ref name=twsM46/> The Coney Island Polar Bear Club was founded in 1903. A Polar Bear member explained:\nIn the 1890s, Russian immigrant Professor Louis Sugarman of Little Falls, New York, brought his practice of ice bathing to the United States.  He attracted worldwide attention for his daily plunge in the Mohawk River, even when the thermostat hit 23 below zero, earning him the nickname \"the human polar bear\".\nIn 1899, an Iowa woman filed for divorce from her husband because he had forced her to undergo ice baths. There has been a tradition in American football of pouring a large bucket of ice water on the winning coach as a victory celebration. And physical therapists have applied ice packs to selected areas of the body to prevent swelling.\nUntil recently, however, bathing in ice was seen as unusual.  One account suggested that ice bath therapy did not become popular until 2002, when marathon runner Paula Radcliffe won the championship in Europe and attributed her victory to its use. She reportedly said \"It's absolute agony, and I dread it, but it allows my body to recover so much more quickly.\" She reported taking ice baths before racing and preferred her pre-race bath temperature to be \"very cold.\"<ref name=twsM46/> After the Radcliffe comment, the technique has grown in popularity.<ref name=twsM42/> It is gaining in popularity among athletes,<ref name=twsM36/><ref name=twsM51/><ref name=twsM42/> such that some athletes \"swear by it\"<ref name=twsM42/> but other accounts suggest it may be a fad.<ref name=twsM46/><ref name=twsM42/> It has been used by athletes such as A. J. Soares<ref name=twsAugN13/> and Olympic swimmer Michael Phelps as well as other celebrity endorsers and is getting to become \"common practice\" among athletes<ref name=twsAugN31/> from different sports, including American football, association football (soccer), long distance running,<ref name=twsM36/><ref name=twsM37/> rugby,<ref name=twsM42/> tennis, volleyball, and other sports. There was a report that sports equipment manufacturers are considering different designs for ice baths. In the summer of 2014, as a fundraising method, the nonprofit ALS Association, which raises money for research and public awareness of amyotrophic lateral sclerosis or ALS, also known as Lou Gehrig's Disease, began the Ice Bucket Challenge which involved donors filming themselves and challenging other donors to participate and then being doused with a bucket of ice cold water; as a fundraising effort, it raised $16 million over a 22-day period.\nThere are indications that ice baths may be gaining popularity with groups outside sports, such as dance. The ''Pittsburgh Post-Gazette'' reported that some Radio City Rockettes, a precision dance company performing in New York City, use ice baths after a long day of performing as a way to \"unwind\" and cope with \"aches and pains.\" One report suggested that entertainer Madonna used ice baths after her performances. And there are indications that use of ice baths is spreading to amateur sports, such as high school football.\nIce baths are a part of a broader phenomenon known as cryotherapy\u2013\u2013the Greek word ''cryo'' (\u03ba\u03c1\u03c5\u03bf) means ''cold''\u2013\u2013which describes a variety of treatments when cold temperatures are used therapeutically. Cryotherapy includes procedures where a person is placed in a room with \"cold, dry air at temperatures as low as \u2212135 \u00b0C\" for short periods of time, and which has been used in hospitals in Poland as well as a center in London to treat not only muscular ailments, but psychological problems such as depression.<ref name=twsM46/> Basketball player Manny Harris reportedly used a Cryon-X machine featuring extreme low temperatures around minus 166 degrees Fahrenheit, but used it with wet socks resulting in a serious freezer burn.\nOccasionally ice baths have been an ill-advised treatment of fever in young children, but that doctors were counseled not to use this technique because of the risk of hypothermia. Ice baths have been suggested as a way to prevent muscle soreness after shoveling snow.<ref name=twsM51/>\nIn addition, there have been instances of ice bathing as an extreme bodily test by persons vying for an endurance record, such as Dutch ''Iceman'' Wim Hof, and Chinese record-holders Chen Kecai and Jin Songhao. According to reports, doctors and scientists are studying how these people can spend an hour and a half submerged in an ice bath, and survive; for almost all humans, such tasks are impossible.", "page_name": "Ice bath", "page_id": "Ice%20bath", "heading": "History", "sub_heading": "History", "_id": "56--3---1---1", "title": "Ice Baths Are Increasing in Popularity among Sports"}
{"qas": [{"question": "Why are there so many different types of Vaccinium?", "answer": ""}, {"question": "Where do blueberries come from in the world?", "answer": "North America", "ae_score": -0.6130213994715515, "qg_score": null}, {"question": "Where do blueberries come from in the world?", "answer": "North America", "ae_score": -0.6130213994715515, "qg_score": null}], "content": "The genus ''Vaccinium'' has a mostly circumpolar distribution, with species mainly being present in North America, Europe, Asia and \nMany commercially sold species with English common names including \"blueberry\" are currently classified in section ''Cyanococcus'' of the genus ''Vaccinium'' and come predominantly from North America. Many North American native species of blueberries are grown commercially in the Southern Hemisphere in Australia, New Zealand and South American nations.\nSeveral other wild shrubs of the genus ''Vaccinium'' also produce commonly eaten blue berries, such as the predominantly European ''Vaccinium myrtillus'' and other bilberries, which in many languages have a name that translates to \"blueberry\" in English. See the Identification section for more information.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Origins", "sub_heading": "Origins", "_id": "57--0---1---1", "title": "Vaccinium genus ''Vaccinium''"}
{"qas": [{"question": "How do they determine the size of a plant?", "answer": ""}, {"question": "What is the scientific name for blueberry?", "answer": "Vaccinium", "ae_score": -0.14406172872964604, "qg_score": null}, {"question": "What is the scientific name for blueberry?", "answer": "Vaccinium", "ae_score": -0.14406172872964604, "qg_score": null}], "content": "Note: habitat and range summaries are from the ''Flora of New Brunswick'', published in 1986 by Harold R. Hinds and ''Plants of the Pacific Northwest coast'', published in 1994 by Pojar and MacKinnon\nSome other blue-fruited species of ''Vaccinium:''", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Species", "sub_heading": "Species", "_id": "57--1---1---1", "title": "''Vaccinium:'' Blue-fruited Vaccinium:''"}
{"qas": [{"question": "Why are blueberries blue, but bilberries green?", "answer": ""}, {"question": "What is the scientific name for blueberries?", "answer": "Cyanococcus", "ae_score": -0.7063946489511294, "qg_score": null}, {"question": "What is the scientific name for blueberries?", "answer": "Cyanococcus", "ae_score": -0.7063946489511294, "qg_score": null}], "content": "Commercially offered blueberries are usually from species that naturally occur only in eastern and north-central North America. Other sections in the genus, native to other parts of the world, including the Pacific Northwest and southern United States, South America, Europe, and Asia, include other wild shrubs producing similar-looking edible berries, such as huckleberries and whortleberries (North America) and bilberries (Europe). These species are sometimes called \"blueberries\" and sold as blueberry jam or other products.\nThe names of blueberries in languages other than English often translate as \"blueberry\", ''e.g.'', Scots ''blaeberry'' and Norwegian ''bl\u00e5b\u00e6r''. ''Blaeberry'', ''bl\u00e5b\u00e6r'' and French ''myrtilles'' usually refer to the European native bilberry (''V. myrtillus''), while ''bleuets'' refers to the North American blueberry. Russian ''\u0433\u043e\u043b\u0443\u0431\u0438\u043a\u0430'' (\"blue berry\") does not refer to blueberries, which are non-native and nearly unknown in Russia, but rather to their close relatives, bog bilberries (''V. uliginosum'').\n''Cyanococcus'' blueberries can be distinguished from the nearly identical-looking bilberries by their flesh color when cut in half. Ripe blueberries have light green flesh, while bilberries, whortleberries and huckleberries are red or purple throughout.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Identification", "sub_heading": "Identification", "_id": "57--2---1---1", "title": "Blueberries are a genus of wild shrubs that produce blueberries"}
{"qas": [{"question": "What is the difference between a blueberry and a redberry?", "answer": ""}, {"question": "What term has been adopted as a marketing term for harvests of managed native stands?", "answer": "Wild", "ae_score": -0.43994956926742296, "qg_score": null}, {"question": "What term has been adopted as a marketing term for harvests of managed native stands?", "answer": "Wild", "ae_score": -0.43994956926742296, "qg_score": null}], "content": "Blueberries may be cultivated, or they may be picked from semiwild or wild bushes. In North America, the most common cultivated species is ''V. corymbosum'', the northern highbush blueberry. Hybrids of this with other ''Vaccinium'' species adapted to southern U.S. climates are known collectively as southern highbush blueberries.\nSo-called \"wild\" (lowbush) blueberries, smaller than cultivated highbush ones, have intense color. The lowbush blueberry, ''V. angustifolium'', is found from the Atlantic provinces westward to Quebec and southward to Michigan and West Virginia. In some areas, it produces natural \"blueberry barrens\", where it is the dominant species covering large areas. Several First Nations communities in Ontario are involved in harvesting wild blueberries.\n\"Wild\" has been adopted as a marketing term for harvests of managed native stands of lowbush blueberries. The bushes are not planted or genetically manipulated, but they are pruned or burned over every two years, and pests are \"managed\".\nNumerous highbush cultivars of blueberries are available, with diversity among them, each having individual qualities. A blueberry breeding program has been established by the USDA-ARS breeding program at Beltsville, Maryland, and Chatsworth, New Jersey. This program began when Frederick Vernon Coville of the USDA-ARS collaborated with Elizabeth Coleman White of New Jersey. In the early part of the 20th century, White offered pineland residents cash for wild blueberry plants with unusually large fruit.  After 1910 Coville began to work on blueberry, and was the first to discover the importance of soil acidity (blueberries need highly acidic soil), that blueberries do not self-pollinate, and the effects of cold on blueberries and other plant. In 1911, he began a program of research in conjunction with White, daughter of the owner of the extensive cranberry bogs at Whitesbog in the New Jersey Pine Barrens. His work doubled the size of some strains' fruit, and by 1916, he had succeeded in cultivating blueberries, making them a valuable crop in the Northeastern United States. For this work he received the George Roberts White Medal of Honor from the Massachusetts Horticultural Society.\nThe rabbiteye blueberry (''Vaccinium virgatum'' syn. ''V. ashei'') is a southern type of blueberry produced from the Carolinas to the Gulf Coast states. Other important species in North America include ''V. pallidum'', the hillside or dryland blueberry. It is native to the eastern U.S., and common in the Appalachians and the Piedmont of the Southeast. Sparkleberry, ''V. arboreum'', is a common wild species on sandy soils in the Southeast.\nSuccessful blueberry cultivation requires attention to soil pH (acidity) measurements in the acidic range.\nBlueberry bushes often require supplemental fertilization,<ref name=purdue/> but over-fertilzation with nitrogen can damage plant health shown by nitrogen-burn visible on the leaves.<ref name=msu/><ref name=purdue/>", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Cultivation", "sub_heading": "Cultivation", "_id": "57--3---1---1", "title": "Blueberries in the Northeastern U.S."}
{"qas": [{"question": "Why are blueberries the leading crop in the US?", "answer": ""}, {"question": "Where is the most blueberries grown in the united states?", "answer": "Michigan", "ae_score": -0.24251823634349218, "qg_score": null}, {"question": "Where is the most blueberries grown in the united states?", "answer": "Michigan", "ae_score": -0.24251823634349218, "qg_score": null}], "content": "According to a 2014 report by US Department of Agriculture, Washington was the nation's largest producer of blueberries with 96.1 million pounds, followed in order of \"utilized production\" volume by Michigan and Georgia, Oregon, New Jersey, California and North Carolina.\nIn terms of acres harvested for blueberries in 2014, the leading state was Michigan (19,000 acres) followed by Georgia, Oregon, Washington and New Jersey.<ref name=eklund/>\nHammonton, New Jersey claims to be the \"Blueberry Capital of the World, with over 80% of New Jersey's blueberries coming from this town. Every year the town hosts a large festival that draws thousands of people to celebrate the fruit.\nResulting from cultivation of both lowbush (wild) and highbush blueberries, Maine accounts for 10% of all blueberries grown in North America with 44,000 ha farmed, but only half of this acreage is harvested each year due to variations in pruning practices. Wild blueberry is the official fruit of Maine.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Growing areas", "sub_heading": "Growing areas", "_id": "57--4--0---1", "title": "The Blueberry Capital of the World, with over 80% of New Jersey's blueberries"}
{"qas": [{"question": "Why is Canada the largest producer of blueberries?", "answer": ""}, {"question": "What is the value of blueberries in canada?", "answer": "$262 million", "ae_score": -0.07878499281044031, "qg_score": null}, {"question": "What is the value of blueberries in canada?", "answer": "$262 million", "ae_score": -0.07878499281044031, "qg_score": null}], "content": "Canadian production of wild and cultivated blueberries in 2015 was 166,000 tonnes valued at $262 million, the largest fruit crop produced nationally accounting for 29% of all fruit value.\nBritish Columbia was the largest Canadian producer of cultivated blueberries, yielding 70,000 tonnes in 2015, the world's largest production of blueberries by region.\nAtlantic Canada contributes approximately half of the total North American wild/lowbush annual production with New Brunswick having the largest in 2015, an amount expanding in 2016. Nova Scotia, Prince Edward Island and Qu\u00e9bec are also major producers. Nova Scotia recognizes the wild blueberry as its official provincial berry, with the town of Oxford, Nova Scotia known as the Wild Blueberry Capital of Canada.\nQu\u00e9bec is a major producer of wild blueberries, especially in the regions of Saguenay-Lac-Saint-Jean (where a popular name for inhabitants of the regions is ''bleuets'', or \"blueberries\") and C\u00f4te-Nord, which together provide 40% of Qu\u00e9bec's total provincial production. This wild blueberry commerce benefits from vertical integration of growing, processing, frozen storage, marketing and transportation within relatively small regions of the province. On average, 80% of Qu\u00e9bec wild blueberries are harvested on farms (21 million kg), the remaining 20% being harvested from public forests (5 million kg).<ref name=quebec/> Some 95% of the wild blueberry crop in Qu\u00e9bec is frozen for export out of the province.<ref name=quebec/>", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Growing areas", "sub_heading": "Canada", "_id": "57--4--1---1", "title": "Canada's Wild Blueberry Industry"}
{"qas": [{"question": "Where did the first blueberries come from?", "answer": ""}, {"question": "Who is the founder of turkish blueberry cultivation?", "answer": "Dr. Huseyin Celik", "ae_score": -0.3682785933510441, "qg_score": null}, {"question": "Who is the founder of turkish blueberry cultivation?", "answer": "Dr. Huseyin Celik", "ae_score": -0.3682785933510441, "qg_score": null}], "content": "The northeastern part of Turkey is one of the main sources of Caucasian whortleberry (''V. arctostaphylos''), bilberry (''V. myrtillus'') and bog blueberry, bog whortleberry or bog bilberry (''V. uliginosum''). This region from Artvin to K\u0131rklareli, as well as parts of Bursa (including Rize, Trabzon, Ordu, Giresun, Samsun, Sinop, Kastamonu, Zonguldak, \u0130stanbul, \u0130zmit and Adapazari) have rainy, humid growing periods and naturally acidic soils suitable for blueberries (\u00c7elik, 2005, 2006 and 2007).\nNative ''Vaccinium'' species and open-pollinated types have been grown for over a hundred years around the Black Sea region of Turkey. These native blueberries are eaten locally as jelly or dried or fresh fruit (\u00c7elik, 2005).  Highbush blueberry cultivation started around the year 2000. The first commercial blueberry orchard was established by Osman Nuri Yildiz and supervised by Dr. Huseyin Celik, the founder of Turkish blueberry cultivation.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Growing areas", "sub_heading": "Asia", "_id": "57--4--3---1", "title": "elik, 2005, 2006 and 2007"}
{"qas": [{"question": "Why is blueberry so much more popular in Australia than in New Zealand?", "answer": ""}, {"question": "Where did the blueberry industry start in the 1980s?", "answer": "New Zealand", "ae_score": -0.06153928585998797, "qg_score": null}, {"question": "Where did the blueberry industry start in the 1980s?", "answer": "New Zealand", "ae_score": -0.06153928585998797, "qg_score": null}], "content": "In the Southern Hemisphere, Peru, Chile, Argentina, Uruguay, South Africa, New Zealand, and Australia now export blueberries.\nBlueberries were first introduced to Australia in the 1950s, but the effort was unsuccessful. In the early 1970s, David Jones from the Victorian Department of Agriculture imported seed from the U.S. and a selection trial was started. This work was continued by Ridley Bell, who imported more American varieties. In the mid-1970s, the Australian Blueberry Growers' Association was formed.\nBy the early 1980s, the blueberry industry was started in New Zealand and is still growing. \nThe industry is new to Argentina: \"Argentine blueberry production has increased over the last three years with planted area up to 400 percent\", according to a 2005 report by the U.S. Department of Agriculture. \"Argentine blueberry production has thrived in four different regions: the province of Entre Rios in northeastern Argentina, the province of Tucuman, the province of Buenos Aires and the southern Patagonian valleys\", according to the report. In the Bureau of International Labor Affairs report of 2014 on child labor and forced labor, blueberries were listed among the goods produced in such working conditions in Argentina.\nChile is the biggest producer in South America and the largest exporter to the Northern Hemisphere, with an estimated area of 14,500 ha in 2014. Chile exported about 104,505 tons of blueberry in the 2014/2015 season.\nIntroduction of the first plants into Chile started in the early 1980s, brought from US and New Zealand, and commercial production started in the 1990s in the southern part of the country. Today, production ranges from Copiap\u00f3 in the north to Puerto Montt in the south, allowing the country to offer blueberries from October through late March. Production has evolved rapidly in the last decade, becoming the fourth most important fruit exported in value terms. Blueberries are exported mainly to North America (79%), followed by Europe (17%), and Asia (South Korea, China and Japan).\nIn Peru, there are several private initiatives for the development of the crop. Also, the government through its agency Sierra Exportadora, has launched the program \"''Peru Berries''\" to take advantage of the existence of the ideal soil and climate required by the blueberry.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Growing areas", "sub_heading": "Southern Hemisphere", "_id": "57--4--4---1", "title": "Chile, Argentina, Uruguay, South Africa, South Africa, New Zealand and Australia Export Blueberries"}
{"qas": [{"question": "Why is the blueberry harvest in North America so long?", "answer": ""}, {"question": "When does the blueberry season end in north america?", "answer": "late summer", "ae_score": -0.5856105871100861, "qg_score": null}, {"question": "When does the blueberry season end in north america?", "answer": "late summer", "ae_score": -0.5856105871100861, "qg_score": null}], "content": "The blueberry harvest in North America varies. It can start as early as May and usually ends in late summer. The principal areas of production in the Southern Hemisphere (Australia, Chile, New Zealand and Argentina) have long periods of harvest. In Australia, for example, due to the geographic spread of blueberry farms and the development of new cultivation techniques, the industry is able to provide fresh blueberries for 10 months of the year \u2013 from July through to April. Similar to other fruits and vegetables, climate-controlled storage allows growers to preserve picked blueberries. Harvest in the UK is from June to August. Mexico also can harvest from October to February.\nAlthough blueberries were traditionally hand-picked with berry-picking rakes, modern farmers use machine harvesters that shake the fruit off the bush of cultivated highbush blueberries, while new machines are being developed for wild, lowbush blueberries. The fruit is then brought to a cleaning/packaging facility where it is cleaned, packaged, then sold. In Mexico, each farmer packs on site and sells directly, or may transport to a warehouse for storage until the berries are sold.. Tunnels are often used to grow blueberries in Europe and this makes the season longer. This creates an opportunity to move crops into earlier or later markets to get better prices.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Harvesting", "sub_heading": "Harvesting", "_id": "57--5---1---1", "title": "The Blueberry Harvest in North America"}
{"qas": [{"question": "What is the difference between blueberry jam and blueberry sauce?", "answer": ""}, {"question": "What is the name of the sweet sauce made from blueberries?", "answer": "Blueberry sauce", "ae_score": -0.22109496806370696, "qg_score": null}, {"question": "What is the name of the sweet sauce made from blueberries?", "answer": "Blueberry sauce", "ae_score": -0.22109496806370696, "qg_score": null}], "content": "Blueberries are sold fresh or processed as individually quick frozen (IQF) fruit, pur\u00e9e, juice, or dried or infused berries, which in turn may be used in a variety of consumer goods, such as jellies, jams, blueberry pies, muffins, snack foods and an additive to breakfast cereals.\nBlueberry jam is made from blueberries, sugar, water, and fruit pectin. Blueberry sauce is a sweet sauce prepared using blueberries as a primary ingredient.\nBlueberry wine is made from the flesh and skin of the berry, which is fermented and then matured; usually the lowbush variety is used.\nBlueberries consist of 14% carbohydrates, 0.7% protein, 0.3% fat and 84% water (table). They contain only negligible amounts of micronutrients, with moderate levels (relative to respective Daily Values) (DV) of the essential dietary mineral manganese, vitamin C, vitamin K and dietary fiber (table). Generally, nutrient contents of blueberries are a low percentage of the DV (table). One serving provides a relatively low caloric value of 57 kcal per 100 g serving and glycemic load score of 6 out of 100 per day.<ref name=nd/>\nBlueberries contain anthocyanins, other polyphenols and various phytochemicals under preliminary research for their potential role in the human body. Most polyphenol studies have been conducted using the highbush cultivar of blueberries (''V. corymbosum''), while content of polyphenols and anthocyanins in lowbush (wild) blueberries (''V. angustifolium'') exceeds values found in highbush cultivars.", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Uses", "sub_heading": "Uses", "_id": "57--6---1---1", "title": "Blueberry | Uses"}
{"qas": [{"question": "Why are blueberries considered a significant concern for the environment?", "answer": ""}, {"question": "Who rated blueberries as a significant concern?", "answer": "The Environmental Working Group", "ae_score": -0.4506280333223454, "qg_score": null}, {"question": "Who rated blueberries as a significant concern?", "answer": "The Environmental Working Group", "ae_score": -0.4506280333223454, "qg_score": null}], "content": "The application of pesticides is common in large-scale blueberry monoculture in Maine. Because \"wild\" is a marketing term generally used for all low-bush blueberries, it is not an indication that such blueberries are free from pesticides.\nThe Environmental Working Group, referencing the USDA, rates blueberries as a \"significant concern\".", "page_name": "Blueberry", "page_id": "Blueberry", "heading": "Pesticides", "sub_heading": "Pesticides", "_id": "57--7---1---1", "title": "Blueberry Monoculture in Maine \u2014 Pesticides and Pesticides"}
{"qas": [{"question": "How do we know the age of trees at higher altitudes?", "answer": ""}, {"question": "At higher elevations, what is more likely to produce neutrons?", "answer": "lightning", "ae_score": -0.5023861370406472, "qg_score": null}, {"question": "Which type of radiocarbon dates are older than true dates for the last 2,?", "answer": "radiocarbon", "ae_score": null, "qg_score": null}], "content": "Two different trends can be seen in the tree ring series. First, there is a long-term oscillation with a period of about 9,000 years, which causes radiocarbon dates to be older than true dates for the last 2,000 years and too young before that. The known fluctuations in the strength of the earth's magnetic field match up quite well with this oscillation: cosmic rays are deflected by magnetic fields, so when there is a weaker magnetic field, more  is produced, leading to a younger apparent age for samples from those periods. Conversely, a stronger magnetic field leads to lower  production and an older apparent age. A secondary oscillation is thought to be caused by variations in sunspot activity, which has two separate periods: a longer-term, 200-year oscillation, and a shorter 11-year cycle. Sunspots cause changes in the solar system's magnetic field and corresponding changes to the cosmic ray flux, and hence to the production of .\nThere are two kinds of geophysical event which can affect  production: geomagnetic reversals and polarity excursions. In a geomagnetic reversal, the Earth's geomagnetic field weakens and stays weak for thousands of years during the transition to the opposite magnetic polarity and then regains strength as the reversal completes. A polarity excursion, which can be either global or local, is a shorter-lived version of a geomagnetic reversal. A local excursion would not significantly affect 14C production. During either a geomagnetic reversal or a global polarity excursion,  production increases during the period when the geomagnetic field is weak. It is fairly certain, though, that in the last 50,000 years there have been no geomagnetic reversals or global polarity excursions.\nSince the earth's magnetic field varies with latitude, the rate of  production changes with latitude, too, but atmospheric mixing is rapid enough that these variations amount to less than 0.5% of the global  concentration. This is close to the limit of detectability in most years, but the effect can be seen clearly in tree rings from years such as 1963, when  from nuclear testing rose sharply through the year. The latitudinal variation in  was much larger than normal that year, and tree rings from different latitudes show corresponding variations in their  content.\n can also be produced at ground level, primarily by cosmic rays that penetrate the atmosphere as far as the earth's surface, but also by spontaneous fission of naturally occurring uranium. These sources of neutrons only produce  at a rate of 1 x 10 atoms per gram per second, which is not enough to have a significant effect on dating. At higher altitudes, the neutron flux can be substantially higher, and in addition, trees at higher altitude are more likely to be struck by lightning, which produces neutrons. However, experiments in which wood samples have been irradiated with neutrons indicate that the effect on  content is minor, though for very old trees (such as some bristlecone pines) that grow at altitude some effect can be seen.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Atmospheric variation", "sub_heading": "Atmospheric variation", "_id": "58--0--0---1", "title": "The Tree Rings: A Geophysical Investigation"}
{"qas": [{"question": "How would the melting of glaciers affect radiocarbon dating?", "answer": ""}, {"question": "What would the changes in climate cause in the atmosphere?", "answer": "changes in the biosphere", "ae_score": -1.5566949420714167, "qg_score": null}, {"question": "What type of radiocarbon is used to date the earth's surface?", "answer": "radiocarbon", "ae_score": null, "qg_score": null}], "content": "Because the solubility of  in water increases with lower temperatures, glacial periods would have led to the faster absorption of atmospheric  by the oceans. In addition, any carbon stored in the glaciers would be depleted in  over the life of the glacier; when the glacier melted as the climate warmed, the depleted carbon would be released, reducing the global / ratio. The changes in climate would also cause changes in the biosphere, with warmer periods leading to more plant and animal life. The effect of these factors on radiocarbon dating is not known.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Atmospheric variation", "sub_heading": "Effect of climatic cycles", "_id": "58--0--1---1", "title": "Radiocarbon Dating in the Arctic"}
{"qas": [{"question": "How much of the carbon in the atmosphere is caused by nuclear testing?", "answer": ""}, {"question": "What is another name for the fossil fuel effect?", "answer": "Suess effect", "ae_score": -0.7168381292021303, "qg_score": null}, {"question": "What is released by nuclear testing that results in radiocarbon dating?", "answer": "neutrons", "ae_score": null, "qg_score": null}], "content": "Coal and oil began to be burned in large quantities during the 19th century. Both are sufficiently old that they contain little detectable  and, as a result, the  released substantially diluted the atmospheric / ratio. Dating an object from the early 20th century hence gives an apparent date older than the true date.  For the same reason,  concentrations in the neighbourhood of large cities are lower than the atmospheric average. This fossil fuel effect (also known as the Suess effect, after Hans Suess, who first reported it in 1955) would only amount to a reduction of 0.2% in  activity if the additional carbon from fossil fuels were distributed throughout the carbon exchange reservoir, but because of the long delay in mixing with the deep ocean, the actual effect is a 3% reduction.\nA much larger effect comes from above-ground nuclear testing, which released large numbers of neutrons and created . From about 1950 until 1963, when atmospheric nuclear testing was banned, it is estimated that several tonnes of  were created. If all this extra  had immediately been spread across the entire carbon exchange reservoir, it would have led to an increase in the / ratio of only a few per cent, but the immediate effect was to almost double the amount of  in the atmosphere, with the peak level occurring in about 1965. The level has since dropped, as this bomb pulse or \"bomb carbon\" (as it is sometimes called) percolates into the rest of the reservoir.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Atmospheric variation", "sub_heading": "Effects of human activity", "_id": "58--0--2---1", "title": "The Suess Effect"}
{"qas": [{"question": "How do we know how much carbon is in a sample?", "answer": ""}, {"question": "What is the standard ratio for radiocarbon dating?", "answer": "PDB", "ae_score": -0.23570788765977344, "qg_score": null}, {"question": "The carbon exchange between atmospheric and carbonate at the ocean surface is subject to what?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "Photosynthesis is the primary process by which carbon moves from the atmosphere into living things. Two different photosynthetic processes exist: the C3 pathway and the C4 pathway. About 90% of all plant life uses the C3 process; the remaining plants either use C4 or are CAM plants, which can use either C3 or C4 depending on the environmental conditions. Both the C3 and C4 photosynthesis pathways show a preference for lighter carbon, with  being absorbed slightly more easily than , which in turn is more easily absorbed than . The differential uptake of the three carbon isotopes leads to / and / ratios in plants that differ from the ratios in the atmosphere. This effect is known as isotopic fractionation.\nTo determine the degree of fractionation that takes place in a given plant, the amounts of both  and  are measured, and the resulting / ratio is then compared to a standard ratio known as PDB.  (The / ratio is used because it is much easier to measure than the / ratio, and the / ratio can be easily derived from it.)  The resulting value, known as , is calculated as follows:\nwhere the \u2030 (permil) sign indicates parts per thousand.  Because the PDB standard contains an unusually high proportion of , most measured  values are negative. Values for C3 plants typically range from \u221230\u2030 to \u221222\u2030, with an average of \u221227\u2030; for C4 plants the range is \u221215\u2030 to \u22129\u2030, and the average is \u221213\u2030. Atmospheric  has a  of \u22128\u2030.\nFor marine organisms, the details of the photosynthesis reactions are less well understood. Measured  values for marine plankton range from \u221231\u2030 to \u221210\u2030; most lie between \u221222\u2030 and \u221217\u2030. The  values for marine photosynthetic organisms also depend on temperature. At higher temperatures,  has poor solubility in water, which means there is less  available for the photosynthetic reactions. Under these conditions, fractionation is reduced, and at temperatures above 14 \u00b0C the  values are correspondingly higher, reaching \u221213\u2030. At lower temperatures,  becomes more soluble and hence more available to the marine organisms; fractionation increases and  values can be as low as \u221232\u2030.\nThe  value for animals depends on their diet. An animal that eats food with high  values will have a higher  than one that eats food with lower  values. The animal's own biochemical processes can also affect the results: for example, both bone minerals and bone collagen typically have a higher concentration of  than is found in the animal's diet, though for different biochemical reasons. The enrichment of bone  also implies that excreted material is depleted in  relative to the diet.\nSince  makes up about 1% of the carbon in a sample, the / ratio can be accurately measured by mass spectrometry. Typical values of  have been found by experiment for many plants, as well as for different parts of animals such as bone collagen, but when dating a given sample it is better to determine the  value for that sample directly than to rely on the published values. The depletion of  relative to  is proportional to the difference in the atomic masses of the two isotopes, so once the  value is known, the depletion for  can be calculated: it will be twice the depletion of .\nThe carbon exchange between atmospheric  and carbonate at the ocean surface is also subject to fractionation, with  in the atmosphere more likely than  to dissolve in the ocean. The result is an overall increase in the / ratio in the ocean of 1.5%, relative to the / ratio in the atmosphere. This increase in  concentration almost exactly cancels out the decrease caused by the upwelling of water (containing old, and hence  depleted, carbon) from the deep ocean, so that direct measurements of  radiation are similar to measurements for the rest of the biosphere. Correcting for isotopic fractionation, as is done for all radiocarbon dates to allow comparison between results from different parts of the biosphere, gives an apparent age of about 400 years for ocean surface water.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Isotopic fractionation", "sub_heading": "Isotopic fractionation", "_id": "58--1---1---1", "title": "Radiocarbon dating considerations | Isotopic fractionation"}
{"qas": [{"question": "How does the age of the ocean work?", "answer": ""}, {"question": "What is the main mechanism that brings deep water to the surface?", "answer": "upwelling", "ae_score": -0.2077142746246237, "qg_score": null}, {"question": "What are the two main ions that transfer radiocarbon from the atmosphere to the ocean?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "The  in the atmosphere transfers to the ocean by dissolving in the surface water as carbonate and bicarbonate ions; at the same time the carbonate ions in the water are returning to the air as . This exchange process brings from the atmosphere into the surface waters of the ocean, but the  thus introduced takes a long time to percolate through the entire volume of the ocean. The deepest parts of the ocean mix very slowly with the surface waters, and the mixing is known to be uneven. The main mechanism that brings deep water to the surface is upwelling. Upwelling is more common in regions closer to the equator; it is also influenced by other factors such as the topography of the local ocean bottom and coastlines, the climate, and wind patterns. Overall, the mixing of deep and surface waters takes far longer than the mixing of atmospheric  with the surface waters, and as a result water from some deep ocean areas has an apparent radiocarbon age of several thousand years. Upwelling mixes this \"old\" water with the surface water, giving the surface water an apparent age of about several hundred years (after correcting for fractionation). This effect is not uniform\u2014the average effect is about 440 years, but there are local deviations of several hundred years for areas that are geographically close to each other. The effect also applies to marine organisms such as shells, and marine mammals such as whales and seals, which have radiocarbon ages that appear to be hundreds of years old. These marine reservoir effects vary over time as well as geographically; for example, there is evidence that during the Younger Dryas, a period of cold climatic conditions about 12,000 years ago, the apparent difference between the age of surface water and the contemporary atmosphere increased from between 400 and 600 years to about 900 years until the climate warmed again.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Reservoir effects", "sub_heading": "Reservoir effects", "_id": "58--2--0---1", "title": "The Effect of Upwelling on the Ocean"}
{"qas": [{"question": "Why does carbonated water age faster than non-carbonated water?", "answer": ""}, {"question": "What is the effect of calcium ions in freshwater called?", "answer": "hard water effect", "ae_score": -0.6923056031952902, "qg_score": null}, {"question": "What type of calcium is found in limestone?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "If the carbon in freshwater is partly acquired from aged carbon, such as rocks, then the result will be a reduction in the / ratio in the water. For example, rivers that pass over limestone, which is mostly composed of calcium carbonate, will acquire carbonate ions. Similarly, groundwater can contain carbon derived from the rocks through which it has passed. These rocks are usually so old that they no longer contain any measurable , so this carbon lowers the / ratio of the water it enters, which can lead to apparent ages of thousands of years for both the affected water and the plants and freshwater organisms that live in it. This is known as the hard water effect, because it is often associated with calcium ions, which are characteristic of hard water; however, there can be other sources of carbon that have the same effect, such as humus. The effect is not necessarily confined to freshwater species\u2014at a river mouth, the outflow may affect marine organisms. It can also affect terrestrial snails that feed in areas where there is a high chalk content, though no measurable effect has been found for land plants in soil with a high carbonate content\u2014it appears that almost all the carbon for these plants is derived from photosynthesis and not from the soil.\nIt is not possible to deduce the effect of the effect by determining the hardness of the water: the aged carbon is not necessarily immediately incorporated into the plants and animals that are affected, and the delay affects their apparent age. The effect is very variable and there is no general offset that can be applied; the usual way to determine the size of the effect is to measure the apparent age offset of a modern sample.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Reservoir effects", "sub_heading": "Hard water effect", "_id": "58--2--1---1", "title": "The Hard Water Effect (Part 1)"}
{"qas": [{"question": "How do we know the age of volcanoes?", "answer": ""}, {"question": "On which greek island is the town of akrotiri?", "answer": "Santorini", "ae_score": -0.8187948433368525, "qg_score": null}, {"question": "What type of radiocarbon is used to date the remains of a town on s?", "answer": "radiocarbon", "ae_score": null, "qg_score": null}], "content": "Volcanic eruptions eject large amounts of carbon into the air. The carbon is of geological origin and has no detectable , so the / ratio in the vicinity of the volcano is depressed relative to surrounding areas. Dormant volcanoes can also emit aged carbon. Plants that photosynthesize this carbon also have lower / ratios: for example, plants on the Greek island of Santorini, near the volcano, have apparent ages of up to a thousand years. These effects are hard to predict \u2013 the town of Akrotiri, on Santorini, was destroyed in a volcanic eruption thousands of years ago, but radiocarbon dates for objects recovered from the ruins of the town show surprisingly close agreement with dates derived from other means. If the dates for Akrotiri are confirmed, it would indicate that the volcanic effect in this case was minimal.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Reservoir effects", "sub_heading": "Volcanoes", "_id": "58--2--2---1", "title": "Volcanic eruptions eject large amounts of carbon into the air."}
{"qas": [{"question": "Why is the average age of radiocarbon dating in the northern hemisphere so much lower than in the southern hemisphere?", "answer": ""}, {"question": "What is the average age for radiocarbon dating in the southern hemisphere?", "answer": "30 years", "ae_score": -0.5263159029682357, "qg_score": null}, {"question": "What type of radiocarbon is used to date the earth's crust?", "answer": "radiocarbon", "ae_score": null, "qg_score": null}], "content": "The northern and southern hemispheres have atmospheric circulation systems that are sufficiently independent of each other that there is a noticeable time lag in mixing between the two. The atmospheric / ratio is lower in the southern hemisphere, with an apparent additional age of 30 years for radiocarbon results from the south as compared to the north. This is probably because the greater surface area of ocean in the southern hemisphere means that there is more carbon exchanged between the ocean and the atmosphere than in the north. Since the surface ocean is depleted in  because of the marine effect,  is removed from the southern atmosphere more quickly than in the north.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Reservoir effects", "sub_heading": "Hemisphere effect", "_id": "58--2--3---1", "title": "The Southern hemisphere vs. the Northern hemisphere."}
{"qas": [{"question": "Is there an island effect?", "answer": ""}, {"question": "How many calibration curves are assembled in seattle and belfast labs?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "What is the carbon exchange between the atmosphere and water called?", "answer": "carbon exchange reservoir", "ae_score": null, "qg_score": null}], "content": "It has been suggested that an \"island effect\" might exist, by analogy with the mechanism thought to explain the hemisphere effect: since islands are surrounded by water, the carbon exchange between the water and atmosphere might reduce the / ratio on an island. Within a hemisphere, however, atmospheric mixing is apparently rapid enough that no such effect exists: two calibration curves assembled in Seattle and Belfast laboratories, with results from North American trees and Irish trees, respectively, are in close agreement, instead of the Irish samples appearing to be older, as would be the case if there were an island effect.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Reservoir effects", "sub_heading": "Island effect", "_id": "58--2--4---1", "title": "The Island Effect"}
{"qas": [{"question": "How does carbon dating work?", "answer": ""}, {"question": "What does 1% of a sample contaminated with modern carbon look like?", "answer": "600 years younger", "ae_score": -0.8812887452326545, "qg_score": null}, {"question": "What is one chemical that can be used in radiocarbon dating?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "Any addition of carbon to a sample of a different age will cause the measured date to be inaccurate. Contamination with modern carbon causes a sample to appear to be younger than it really is: the effect is greater for older samples. If a sample that is in fact 17,000 years old is contaminated so that 1% of the sample is actually modern carbon, it will appear to be 600 years younger; for a sample that is 34,000 years old the same amount of contamination would cause an error of 4,000 years. Contamination with old carbon, with no remaining , causes an error in the other direction, which does not depend on age\u2014a sample that has been contaminated with 1% old carbon will appear to be about 80 years older than it really is, regardless of the date of the sample.\nContamination can occur if the sample is brought into contact with or packed in materials that contain carbon. Cotton wool, cigarette ash, paper labels, cloth bags, and some conservation chemicals such as polyvinyl acetate can all be sources of modern carbon. Labels should be added to the outside of the container, not placed inside the bag or vial with the sample. Glass wool is acceptable as packing material instead of cotton wool. Samples should be packed in glass vials or aluminium foil if possible; polyethylene bags are also acceptable but some plastics, such as PVC, can contaminate the sample. Contamination can also occur before the sample is collected: humic acids or carbonate from the soil can leach into a sample, and for some sample types, such as shells, there is the possibility of carbon exchange between the sample and the environment, depleting the sample's  content.", "page_name": "Radiocarbon dating considerations", "page_id": "Radiocarbon%20dating%20considerations", "heading": "Contamination", "sub_heading": "Contamination", "_id": "58--3---1---1", "title": "Contamination with Carbon"}
{"qas": [{"question": "What is the difference between egg white and water?", "answer": ""}, {"question": "What is the most abundant protein in egg white?", "answer": "Ovalbumin", "ae_score": -0.32561263435467164, "qg_score": null}, {"question": "What is the most abundant protein in egg white?", "answer": "Ovalbumin", "ae_score": -0.32561263435467164, "qg_score": null}], "content": "Egg white makes up around two-thirds of a chicken egg by weight. Water constitutes 92% of this, with protein, trace minerals, fatty material, vitamins, and glucose contributing the remaining 8%.  A raw U.S. large egg contains around 33 grams of egg white with 3.6 grams of protein, 0.24 grams of carbohydrate and 55 milligrams of sodium. It contains no cholesterol and the energy content is about 17 Calories. Egg white is an alkaline solution and contains approximately 148 proteins. The table below lists the major proteins in egg whites by percentage and their natural functions.\nOvalbumin is the most abundant protein in albumen. Classed as phosphoglycoprotein. During storage ovalbumin converts into s-ovalbumin (5% at the time of laying) can reach up to 80% after six months of cold storage. Ovalbumin in solution is heat-resistant. Denatured temperature is around 84 \u00b0Celsius, but can be easily denatured by physical stresses.Conalbumin/Ovotransferrin is a glycoprotein which has the capacity to bind the bi- and trivalent metal cations into complex and is more heat sensitive than ovalbumin. At its isoelectric pH (6.5) it can bind two cations and assume a red or yellow color.  These metal complexes are more heat stable than the native state. Ovomucoid is the major allergen from egg white and is a heat-resistant glycoprotein found to be a trypsin inhibitor.  Lysozyme is a holoprotein which can lyse the wall of certain gram positive bacteria and is found at high levels in the chalaziferous layer and the chalazae which anchor the yolk towards the middle of the egg. Ovomucin is a glycoprotein which may contribute to the gel-like structure of thick albumen. The amount of ovomucin in the thick albumen is four times greater than in the thin albumen.", "page_name": "Egg white", "page_id": "Egg%20white", "heading": "Composition", "sub_heading": "Composition", "_id": "59--0---1---1", "title": "Proteins in Egg Whites"}
{"qas": [{"question": "Why do egg whites get hard when boiled, but not when they are boiled?", "answer": ""}, {"question": "How many stages are there in egg white?", "answer": "three", "ae_score": -0.8060763199901824, "qg_score": null}, {"question": "How many stages are there in egg white?", "answer": "three", "ae_score": -0.8060763199901824, "qg_score": null}], "content": "The physical stress of beating egg whites can create a foam.  Two types of physical stress are caused by beating them with a whisk, the first of which occurs as the whisk drags the liquid through itself, creating a force that unfolds the protein molecules. This process is called denaturation. The second stress comes from the mixing of air into the whites, which causes the proteins to come out of their natural state.  These denatured proteins gather together where the air and water meet and create multiple bonds with the other unraveled proteins, and thus become a foam, holding the incorporated air in place. This is because the proteins consist of amino acids; some are hydrophilic (attracted to water) and some are hydrophobic (repelled by water). This process is called coagulation.\nWhen beating egg whites, they are classified in three stages according to the peaks they form when the beater is lifted: soft, firm, and stiff peaks.  Overbeaten eggs take on a dry appearance, and will eventually collapse. Egg whites will not beat up correctly if they are exposed to any form of fat, such as cooking oils or the fats contained in egg yolk.\nCopper bowls have been used in France since the eighteenth century to stabilize egg foams. The copper in the bowl assists in creating a tighter bond in reactive sulfur items such as egg whites.  The bond created is so tight that the sulfurs are prevented from reacting with any other material.  A silver-plated bowl will have the same result as the copper bowl as will a pinch of powdered copper supplement from a health store used in a glass bowl.  Drawbacks of the copper bowl include the expense of the bowl itself, as well as the fact that the bowls are difficult to keep clean.  Copper contamination from the bowl is minimal, as a cup of foam will contain a tenth of one's daily normal intake level.", "page_name": "Egg white", "page_id": "Egg%20white", "heading": "Foam", "sub_heading": "Foam", "_id": "59--1---1---1", "title": "Copper Bowls and Egg Whites"}
{"qas": [{"question": "Why are egg yolks so bad for you?", "answer": ""}, {"question": "How old do you have to be to eat egg whites?", "answer": "five", "ae_score": -0.47879724479504, "qg_score": null}, {"question": "How old do you have to be to eat egg whites?", "answer": "five", "ae_score": -0.47879724479504, "qg_score": null}], "content": "Although egg whites are prized as a source of low-fat, high-protein nutrition, a small number of people cannot eat them.  Egg allergy is more common among infants than adults, and most children will outgrow it by the age of five.  Allergic reactions against egg white are more common than reactions against egg yolks.  In addition to true allergic reactions, some people experience a food intolerance to egg whites.\nEggs are susceptible to ''Salmonella'' contamination. Thorough cooking eliminates the direct threat (i.e. cooked egg whites that are solid and not runny), but the threat of cross-contamination remains if people handle contaminated eggs and then touch other foods or items in the kitchen, thus spreading the bacteria. In August 2010, the FDA ordered the recall of 380 million eggs because of possible ''Salmonella'' contamination.", "page_name": "Egg white", "page_id": "Egg%20white", "heading": "Health issues", "sub_heading": "Health issues", "_id": "59--2---1---1", "title": "''Salmonella'' Contamination of Eggs"}
{"qas": [{"question": "What is the purpose of egg white?", "answer": ""}, {"question": "What is the fining agent used in wine?", "answer": "Egg white", "ae_score": -0.1835675763483466, "qg_score": null}, {"question": "What is the fining agent used in wine?", "answer": "Egg white", "ae_score": -0.1835675763483466, "qg_score": null}], "content": "Egg white is a fining agent that can be used in the clarification and stabilization of wine. Whites can also be added to shaken cocktails to create a delicate froth. Some protein powders also use egg whites as a primary source of protein.\nIn the 1750s, egg whites were believed to prevent swelling, and were used for that purpose. To help soothe areas of skin that were afflicted, egg white mixed with Armenic bole could help restore the fibers. Egg whites were also used in the bookbinding process, to attach the gold to a bound spine, known as glairing, and also to give a book cover shine.<ref>Vandenesse, Urbain de, \"Egg White.\" The Encyclopedia of Diderot & d'Alembert Collaborative Translation Project. Translated by Abigail Wendler Bainbridge. Ann Arbor: Michigan Publishing, University of Michigan Library, 2011. Web. Accessed 31 March 2015. ", "page_name": "Egg white", "page_id": "Egg%20white", "heading": "Uses", "sub_heading": "Uses", "_id": "59--3---1---1", "title": "Egg White \u2014 Diderot & d'Alembert Collaborative"}
{"qas": [{"question": "How do we know how many species of fish are in the ocean?", "answer": ""}, {"question": "How many species of finfish in the south atlantic rock shrimp fishery?", "answer": "166", "ae_score": -0.2315957028548099, "qg_score": null}, {"question": "How many species of finfish in the south atlantic rock shrimp fishery?", "answer": "166", "ae_score": -0.2315957028548099, "qg_score": null}], "content": "The highest rates of incidental catch of non-target species are associated with tropical shrimp trawling. In 1997, the Food and Agriculture Organization of the United Nations (FAO) documented the estimated bycatch and discard levels from shrimp fisheries around the world. They found discard rates (bycatch to catch ratios) as high as 20:1 with a world average of 5.7:1.\nShrimp trawl fisheries catch 2% of the world total catch of all fish by weight, but produce more than one-third of the world total bycatch. American shrimp trawlers produce bycatch ratios between 3:1 (3 bycatch:1 shrimp) and 15:1(15 bycatch:1 shrimp).\nTrawl nets in general, and shrimp trawls in particular, have been identified as sources of mortality for cetacean and finfish species. When bycatch is discarded (returned to the sea), it is often dead or dying.\nTropical shrimp trawlers often make trips of several months without coming to port. A typical haul may last 4 hours after which the net is pulled in. Just before it is pulled on board the net is washed by zigzagging at full speed. The contents are then dumped on deck and are sorted. An average of 5.7:1 means that for every kilogram of shrimp there are 5.7 kg of bycatch. In tropical inshore waters the bycatch usually consists of small fish. The shrimps are frozen and stored on-board; the bycatch is discarded.\nRecent sampling in the South Atlantic rock shrimp fishery found 166 species of finfish, 37 crustacean species, and 29 other species of invertebrate among the bycatch in the trawls. Another sampling of the same fishery over a two-year period found that rock shrimp amounted to only 10% of total catch weight. Iridescent swimming crab, dusky flounder, inshore lizardfish, spot, brown shrimp, longspine swimming crabs, and other bycatch made up the rest.\nDespite the use of bycatch reduction devices, the shrimp fishery in the Gulf of Mexico removes about 25\u201345 million red snapper annually as bycatch, nearly one half the amount taken in directed recreational and commercial snapper fisheries.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Examples", "sub_heading": "Shrimp trawling", "_id": "60--0--1---1", "title": "Shrimp Trawls: The Catch and Disposal of Non-Target"}
{"qas": [{"question": "Why is fishing so bad for marine mammals?", "answer": ""}, {"question": "What kind of animals are caught as bycatch?", "answer": "cetaceans", "ae_score": -0.7382239822086082, "qg_score": null}, {"question": "What kind of animals are caught as bycatch?", "answer": "cetaceans", "ae_score": -0.7382239822086082, "qg_score": null}], "content": "Cetaceans, such as dolphins, porpoises, and whales, can be seriously affected by entanglement in fishing nets and lines, or direct capture by hooks or in trawl nets. Cetacean bycatch is increasing in intensity and frequency.<ref name=\"Demaster (2001)\">{{cite journal|last1=Demaster |first1=DJ |last2=Fowler |first2=CW |last3=Perry |first3=SL |first4=ME |last4=Richlen |year=2001|title=Predation and competition: the impact of fisheries on marine mammal populations over the next one hundred years|journal=Journal of Mammalogy|volume=82|issue=3|pages=641\u2013651 |doi=10.1644/1545-1542(2001)082\n In some fisheries, cetaceans are captured as bycatch but then retained because of their value as food or bait. In this fashion, cetaceans can become a target of fisheries.\nOne example of bycatch is dolphins caught in tuna nets. As dolphins are mammals and do not have gills they may drown while stuck in nets underwater. This bycatch issue has been one of the reasons of the growing ecolabelling industry, where fish producers mark their packagings with disclaimers such as \"dolphin friendly\" to reassure buyers. However, \"dolphin friendly\" does not mean that dolphins were not killed in the production of a particular tin of tuna, but that the fleet which caught the tuna did not ''specifically'' target a feeding pod of dolphins, but relied on other methods to spot tuna schools.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Examples", "sub_heading": "Cetacean", "_id": "60--0--2---1", "title": "The impact of fisheries on marine mammal populations over the next one hundred years."}
{"qas": [{"question": "Why are albatross so threatened?", "answer": ""}, {"question": "How many albatross species are threatened by fishing?", "answer": "19", "ae_score": -0.3762993719264624, "qg_score": null}, {"question": "How many albatross species are threatened by fishing?", "answer": "19", "ae_score": -0.3762993719264624, "qg_score": null}], "content": "Of the 21 albatross species recognised by IUCN on their Red List, 19 are threatened, and the other two are ''near threatened''. Two species are considered critically endangered: the Amsterdam albatross and the Chatham albatross. One of the main threats is commercial long-line fishing, because the albatrosses and other seabirds which readily feed on offal are attracted to the set bait, become hooked on the lines and drown. An estimated 100,000 albatross per year are killed in this fashion. Unregulated pirate fisheries exacerbate the problem.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Examples", "sub_heading": "Albatross", "_id": "60--0--3---1", "title": "The albatross is a critically endangered species"}
{"qas": [{"question": "How do shrimp trawl nets kill sea turtles?", "answer": ""}, {"question": "What is the mortality rate for sea turtles?", "answer": "less than one percent", "ae_score": -0.5384653575023223, "qg_score": null}, {"question": "What is the mortality rate for sea turtles?", "answer": "less than one percent", "ae_score": -0.5384653575023223, "qg_score": null}], "content": "Sea turtles, already critically endangered, have been killed in large numbers in shrimp trawl nets. Estimates indicate that thousands of Kemp's ridley, loggerhead, green and leatherback sea turtles are caught in shrimp trawl fisheries in the Gulf of Mexico and the US Atlantic annually The speed and length of the trawl method is significant because, \u201cfor a tow duration of less than 10 minutes, the mortality rate for sea turtles is less than one percent, whereas for tows greater than sixty minutes the mortality rate rapidly increases to fifty to one hundred percent\u201d\nSea turtles can sometimes escape from the trawls. In the Gulf of Mexico, the Kemp\u2019s ridley turtles recorded most interactions, followed in order by loggerhead, green, and leatherback sea turtles. In the US Atlantic, the interactions were greatest for loggerheads, followed in order by Kemp\u2019s ridley, leatherback, and green sea turtles.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Examples", "sub_heading": "Sea turtles", "_id": "60--0--4---1", "title": "Kemp\u2019s Ridley, Loggerhead, Green and Leatherback Sea Turtles Die"}
{"qas": [{"question": "Why is it so difficult to eliminate by-catch by fishing?", "answer": ""}, {"question": "What has been successfully implemented in some fisheries?", "answer": "Mitigation methods", "ae_score": -0.3461126651633212, "qg_score": null}, {"question": "What has been successfully implemented in some fisheries?", "answer": "Mitigation methods", "ae_score": -0.3461126651633212, "qg_score": null}], "content": "Concern about bycatch has led fishermen and scientists to seek ways of reducing unwanted catch. There are two main approaches.\nOne approach is to ban fishing in areas where bycatch is unacceptably high. Such area closures can be permanent, seasonal, or for a specific period when a bycatch problem is registered. Temporary area closures are common in some bottom-trawl fisheries where undersized fish or non-target species are caught unpredictably. In some cases fishermen are required to relocate when a bycatch problem occurs.\nThe other approach is alternative fishing gear. A technically simple solution is to use nets with a larger mesh size, allowing smaller species and smaller individuals to escape. However, this usually requires replacing the existing gear. In other cases, it is possible to modify gear. The \"Bycatch Reduction Device\" (BRD) and the Nordmore grate are net modifications that help fish escape from shrimp nets.\nBRDs allow many commercial finfish species to escape. The US government has approved BRDs that reduce finfish bycatch by 30%. Spanish mackerel and weakfish bycatch in the South Atlantic was reduced by 40%. However, recent surveys suggest BRDs may be less effective than previously thought. A rock shrimp fishery off Florida found the devices did not exclude 166 species of fish, 37 crustacean species, and 29 species of other invertebrates.\nIn 1978, the National Marine Fisheries Service (NMFS) started to develop turtle excluder devices (TEDs). A TED uses a grid which deflects turtles and other big animals, so they exit from the trawl net through an opening above the grid. US shrimp trawlers and foreign fleets which market shrimp in the US are required to use TEDs. Not all nations enforce the use of TEDs.\nFor the most part, when they are used, TEDs have been successful reducing sea turtle bycatch. However, they are not completely effective, and some turtles are still captured. NMFS certifies TED designs if they are 97% effective. In heavily trawled areas, the same sea turtle may pass repeatedly through TEDs. Recent studies indicate recapture rates of twenty percent or more, but it is not clear how many turtles survive the escape process.\nThe size selectivity of trawl nets is controlled by the size of the net openings, especially in the \"cod end\". The larger the openings, the more easily small fish can escape. The development and testing of modifications to fishing gear to improve selectivity and decrease impact is called \"conservation engineering.\"\nLongline fishing is controversial in some areas because of by-catch. Mitigation methods have been successfully implemented in some fisheries. These include:\nHowever, gear modifications do not eliminate by-catch of many species. In March 2006, the Hawaii longline swordfish fishing season was closed due to excessive loggerhead sea turtle by-catch after being open only a few months, despite using modified circle hooks.\nOne solution that Norway came up with to reduce bycatch is to, \u201cadopt a \u2018no discards\u2019 policy\u201d. This means that the fishermen must keep everything they catch. This policy has helped to, \u201cencourage [bycatch] research\u201d, which, in turn has helped \u201cencourage behavioral changes in fishers\u201d and \u201creduce the waste of life\u201d as well.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Mitigation", "sub_heading": "Mitigation", "_id": "60--1---1---1", "title": "How to Reduce Sea Turtle Bycatch in Longline Fishing"}
{"qas": [{"question": "What happens to the fish that is caught in the ocean?", "answer": ""}, {"question": "Where is bycatch used as raw material for fish sauce?", "answer": "Southeast Asia", "ae_score": null, "qg_score": null}, {"question": "Where is bycatch used as raw material for fish sauce?", "answer": "Southeast Asia", "ae_score": null, "qg_score": null}], "content": "Some fisheries retain bycatch, rather than throwing the fish back into the ocean. Sometimes bycatch are sorted and sold as food, especially in Asia, Africa and Latin America where cost of labour is cheaper. Bycatch can also be sold in frozen bags as \"assorted seafood\" or \"seafood medley\" at cheaper prices. Bycatch can be converted into fish hydrolysate (ground up fish carcasses) for use as a soil amendment in organic agriculture or it can be used as an ingredient in fish meal. In Southeast Asia bycatch is sometimes used as a raw material for fish sauce production. Bycatch is also commonly de-boned, de-shelled, ground and blended into fish paste or moulded into fish cakes (surimi) and sold either fresh (for domestic use) or frozen (for export). This is commonly the case in Asia or by Asian fisheries. Sometimes bycatch are sold to fish farms to feed farmed fish, especially in Asia.\nIf bycatch is quickly released, predators and scavengers may consume it.", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Alternative to release", "sub_heading": "Alternative to release", "_id": "60--2---1---1", "title": "Bycatch in Asia, Africa, Latin America"}
{"qas": [{"question": "What is the purpose of the term \"bycatch\"?", "answer": ""}, {"question": "What is it called when small insects are caught in traps?", "answer": "bycatch", "ae_score": -0.7032892031988963, "qg_score": null}, {"question": "What is it called when small insects are caught in traps?", "answer": "bycatch", "ae_score": -0.7032892031988963, "qg_score": null}], "content": "The term \"bycatch\" is used also in contexts other than fisheries. Examples are insect collecting with pitfall traps or flight interception traps for either financial, controlling or scientific purposes (where the bycatch may either be small vertebrates or untargeted insects) and control of introduced vertebrates which have become pest species like the muskrat in Europe (where the bycatch in traps may be e.g. European mink or waterfowl).", "page_name": "Bycatch", "page_id": "Bycatch", "heading": "Non-fisheries bycatch", "sub_heading": "Non-fisheries bycatch", "_id": "60--3---1---1", "title": "Bycatch in Fisheries"}
{"qas": [{"question": "Why are there so many coffeehouses in Mecca?", "answer": ""}, {"question": "Which french traveler and writer gave a lively description of the persian coffeehouse scene?", "answer": "Jean Chardin", "ae_score": -0.057383700147718195, "qg_score": null}, {"question": "Which french traveler and writer gave a lively description of the persian coffeehouse scene?", "answer": "Jean Chardin", "ae_score": -0.057383700147718195, "qg_score": null}], "content": "Coffeehouses in Mecca became a concern as places for political gatherings to the imams, who banned them, as well as  the drink, for Muslims between 1512 and 1524. In 1530, the first coffeehouse was opened in Damascus and not long after there were many coffeehouses in Cairo.\nThe Ottoman chronicler \u0130brahim Pe\u00e7evi reports in his writings (1642\u201349) about the opening of the first coffeehouse in Istanbul:\nVarious legends involving the introduction of coffee to Istanbul at a \"Kiva Han\" in the late 15th century circulate in culinary tradition, but with no documentation.\nThe 17th-century French traveler and writer Jean Chardin gave a lively description of the Persian coffeehouse scene:\nThe most common English spelling, ''caf\u00e9'', is the French, Portuguese and Spanish spelling, and was adopted by English-speaking countries in the late 19th century. As English generally makes little use of diacritical marks, anglicisation includes a tendency to omit them and to place the onus on the readers to remember how it is pronounced, without being given the accents. Thus the spelling ''cafe'' has become very common in English-language usage throughout the world, especially for the less formal, i.e. \"greasy spoon\" variety (although orthographic prescriptivists often disapprove of it). The Italian spelling, ''caff\u00e8'', is also sometimes used in English. In southern England, especially around London in the 1950s, the French pronunciation was often facetiously altered to  and spelt ''caff''.\nThe English words ''coffee'' and ''caf\u00e9'' both descend from the Italian word for coffee, ''caff\u00e8''\u2014first attested as ''cave\u00e9'' in Venice in 1570\u2014 and in turn derived from the Arabic ''qahuwa'' (\u0642\u0647\u0648\u0629).  The Arabic term ''qahuwa'' originally referred to a type of wine but after the wine ban by Mohammed, the name was transferred to coffee because of the similar rousing effect it induced. The European awareness of coffee (the plant, its seeds, and the beverage made from the seeds) came  through Europeans' contact with Turkey, likely via Venetian-Ottoman trade relations.\nThe translingual word root /kafe/ appears in many European languages with various naturalized spellings, including; Portuguese, Spanish, and French (''caf\u00e9''); German (''Kaffee''); Polish (''kawa''); Ukrainian (''\u043a\u0430\u0432\u0430'', 'kava'); and others.", "page_name": "Coffeehouse", "page_id": "Coffeehouse", "heading": "History", "sub_heading": "History", "_id": "61--0---1---1", "title": "Coffeehouse | History"}
{"qas": [{"question": "What is the difference between a cafe and a coffee shop?", "answer": ""}, {"question": "In which country are caf\u00e9s similar to those found in france known as 'bar?", "answer": "Italy", "ae_score": -0.6248531968438746, "qg_score": null}, {"question": "In which country are caf\u00e9s similar to those found in france known as 'bar?", "answer": "Italy", "ae_score": -0.6248531968438746, "qg_score": null}], "content": "In most European countries, such as Austria, Denmark, Germany, Norway, Sweden, Portugal, and others, the term ''caf\u00e9'' means a restaurant primarily serving coffee as well as pastries such as cakes, tarts, pies, Danish pastries, or buns. Many caf\u00e9s also serve light meals such as sandwiches. European caf\u00e9s often have tables on the pavement (sidewalk) as well as indoors. Some caf\u00e9s also serve alcoholic beverages, particularly in Southern Europe.\nIn the Netherlands and Belgium, a ''caf\u00e9'' is the equivalent of a bar, and also sells alcoholic beverages. In the Netherlands a '''' serves coffee, while a coffee shop (using the English term) sells soft drugs (cannabis and hashish) and is generally not allowed to sell alcoholic beverages. In France, most caf\u00e9s serve as lunch restaurants in the day, and bars in the evening. They generally do not have pastries except during mornings, where a croissant or pain au chocolat can be purchased with breakfast coffee.\nIn Italy, caf\u00e9s are similar to those found in France and known as ''bar''.  They typically serve a variety of espresso coffee, cakes and alcoholic drinks. Bars in city centres usually have different prices for consumption at the bar and consumption at a table.", "page_name": "Coffeehouse", "page_id": "Coffeehouse", "heading": "Europe", "sub_heading": "Europe", "_id": "61--1--0---1", "title": "'''Caf\u00e9''' in Europe \u2014 A Dictionary"}
{"qas": [{"question": "What is the difference between a coffeehouse and a true coffeehouse?", "answer": ""}, {"question": "Who wrote the book a coffeehouse manual?", "answer": "David Wilkerson", "ae_score": -0.9312150267384837, "qg_score": null}, {"question": "Who wrote the book a coffeehouse manual?", "answer": "David Wilkerson", "ae_score": -0.9312150267384837, "qg_score": null}], "content": "Coffee shops in the United States arose from the espresso- and pastry-centered Italian coffeehouses of the Italian American immigrant communities in the major U.S. cities, notably New York City's Little Italy and Greenwich Village, Boston's North End, and San Francisco's North Beach. From the late 1950s onward, coffeehouses also served as a venue for entertainment, most commonly folk performers during the American folk music revival. This was likely due to the ease at accommodating in a small space a lone performer accompanying himself or herself with only a guitar. Both Greenwich Village and North Beach became major haunts of the Beats, who were highly identified with these coffeehouses.\nAs the youth culture of the 1960s evolved, non-Italians consciously copied these coffeehouses. The political nature of much of 1960s folk music made the music a natural tie-in with coffeehouses with their association with political action. A number of well known performers like Joan Baez and Bob Dylan began their careers performing in coffeehouses. Blues singer Lightnin' Hopkins bemoaned his woman's inattentiveness to her domestic situation due to her overindulgence in coffeehouse socializing in his 1969 song \"Coffeehouse Blues\". Starting in 1967 with the opening of the historic Last Exit on Brooklyn coffeehouse, Seattle became known for its thriving countercultural coffeehouse scene; the Starbucks chain later standardized and mainstreamed this  espresso bar model.\nFrom the 1960s through the mid-1980s, churches and individuals in the United States used the coffeehouse concept for outreach. They were often storefronts and had names like ''The Lost Coin'' (Greenwich Village), ''The Gathering Place'' (Riverside, CA), ''Catacomb Chapel'' (New York City), and ''Jesus For You'' (Buffalo, NY). Christian music (often guitar-based) was performed, coffee and food was provided, and Bible studies were convened as people of varying backgrounds gathered in a casual setting that was purposefully different than the traditional church. An out-of-print book, published by the ministry of David Wilkerson, titled, ''A Coffeehouse Manual'', served as a guide for Christian coffeehouses, including a list of name suggestions for coffeehouses.\nIn general, prior to about 1990, true coffeehouses were little known in most American cities, apart from those located on or near college campuses, or in districts associated with writers, artists, or the counterculture.   During this time the word \"coffeeshop\" usually denoted family-style restaurants that served full meals, and of whose revenue coffee represented only a small portion.   More recently that usage of the word has waned and now \"coffeeshop\" often refers to a true coffeehouse.", "page_name": "Coffeehouse", "page_id": "Coffeehouse", "heading": "United States", "sub_heading": "United States", "_id": "61--2---1---1", "title": "Coffeehouses and the Counterculture"}
{"qas": [{"question": "What is the difference between a breakfast and a coffee shop?", "answer": ""}, {"question": "When did the first tomoca coffeehouse open?", "answer": "1953", "ae_score": -0.46562801175431, "qg_score": null}, {"question": "When did the first tomoca coffeehouse open?", "answer": "1953", "ae_score": -0.46562801175431, "qg_score": null}], "content": "In the Middle East, the coffeehouse (\u0645\u0642\u0647\u0649 ''maqha''; \u0642\u0647\u0648\u0647 \u062e\u0627\u0646\u0647 ''qahveh-khaneh''; kahvehane'' or ''k\u0131r\u00e2thane) serves as an important social gathering place for men. Men assemble in coffeehouses to drink coffee (usually Arabic coffee) and tea. In addition, men go there to listen to music, read books, play chess and backgammon, watch TV and enjoy other social activities around the Arab world and in Turkey. Hookah (shisha) is traditionally served as well.\nCoffeehouses in Egypt are colloquially called '''ahwah'' //, which is the dialectal pronunciation of \u0642\u064e\u0647\u0652\u0648\u0629 ''qahwah'' (literally \"coffee\") (\n)Also commonly served in '''ahwah'' are tea (''sh\u0101y'') and herbal teas, especially the highly popular hibiscus blend (Egyptian Arabic: ''karkadeh'' or ''ennab'').The first '''ahwah'' opened around the 1850s and were originally patronized mostly by older people, with youths frequenting but not always ordering. There were associated by the 1920s with clubs (Cairo), ''bursa''  (Alexandria) and ''gharza'' (rural inns). In the early 20th century, some of them became crucial venues for political and social debates.\nIn China, an abundance of recently started domestic coffeehouse chains may be seen accommodating business people for conspicuous consumption, with coffee prices are sometimes even higher than in the West.\nIn India, coffee culture has expanded in the past twenty years. Chains like Indian Coffee House, Caf\u00e9 Coffee Day, Barista Lavazza have become very popular. Cafes are considered good venues to conduct office meetings and for friends to meet.\nIn Malaysia and Singapore, traditional breakfast and coffee shops are called ''kopi tiam''. The word is a portmanteau of the Malay word for coffee (as borrowed and altered from English) and the Hokkien dialect word for shop (\u5e97; POJ: ti\u00e0m). Menus typically feature simple offerings: a variety of foods based on egg, toast, and coconut jam, plus coffee, tea, and Milo, a malted chocolate drink which is extremely popular in Southeast Asia and Australasia, particularly Singapore and Malaysia.\nSingapore also has coffeeshops known as cafes and in the past few years, there has a been a rise in cafe culture with urbanites seeking out specialty coffees. Even with popular joints such as Starbucks and Coffee Bean, the millennials in particular sought for gourmet coffees as well as the relaxing and cosy ambience amidst the hustle and bustle of the city. Moreover, cafes have also changed the social scenes of Singapore. Instead of crowding at shopping malls, the youngsters could now hang out at cafes.\nIn the Philippines, coffeeshops chains like Starbucks became prevalent in upper and middle class professionals especially in Makati. However, Carinderias also serve coffee alongside viands. Events such as \"Kapihan\" often officiated at bakeshops and restaurants that also served coffee for breakfast and merienda.\nIn Australia, coffee-shops are generally called ''caf\u00e9s''. Since the post-World War II influx of Italian immigrants introduced espresso coffee machines to Australia in the 1950s, there has been a steady rise in caf\u00e9 culture. In 1956 \"The Legend Cafe\" was established by Nicolades family replacing an \"Anglo-American Caf\u00e9\" at 239 Bourke Street in Melbourne. Nicolades family first introduced a jazz band in the cafe to play and entertain his customers. Since then the past decade has seen a rapid rise in demand for locally (or on-site)-roasted specialty coffee, particularly in Sydney and Melbourne, with the \"flat white\" remaining a popular coffee drink.\nIn Cairo, the capital of Egypt, most caf\u00e9s have shisha (waterpipe). Most Egyptians indulge in the habit of smoking shisha while hanging out at the caf\u00e9, watching a match, studying, or even sometimes finishing some work.In Addis Ababa, the capital of Ethiopia, independent coffeehouses that struggled prior to 1991 have become popular with young professionals who do not have time for traditional coffee roasting at home. One establishment which has become well-known is the Tomoca coffee shop, which opened in 1953.", "page_name": "Coffeehouse", "page_id": "Coffeehouse", "heading": "Format", "sub_heading": "Format", "_id": "61--3--0---1", "title": "Coffeehouse | Format"}
{"qas": [{"question": "Why are espresso bars so popular in London?", "answer": ""}, {"question": "What was the name of the first english coffee house?", "answer": "The Angel", "ae_score": -0.06587151933368521, "qg_score": null}, {"question": "What was the name of the first english coffee house?", "answer": "The Angel", "ae_score": -0.06587151933368521, "qg_score": null}], "content": "Haunts for teenagers in particular, Italian-run espresso bars and their formica-topped tables were a feature of 1950s Soho that provided a backdrop as well as a title for Cliff Richard's 1960 film ''Expresso Bongo''. The first was The Moka in Frith Street, opened by Gina Lollobrigida in 1953. With their \"exotic Gaggia coffee machine[s],...Coke, Pepsi, weak frothy coffee and...Suncrush orange fountain[s]\" they spread to other urban centres during the 1960s, providing cheap, warm places for young people to congregate and an ambience far removed from the global coffee bar standard which would be established in the final decades of the century by chains such as Starbucks and Pret a Manger.\nThe first coffee house in England was The Angel, which opened in Oxford in 1650.", "page_name": "Coffeehouse", "page_id": "Coffeehouse", "heading": "Espresso bar", "sub_heading": "Espresso bar", "_id": "61--4--0---1", "title": "''Expresso Bongo'': The Italian-run Espresso Bars"}
{"qas": [{"question": "Why are wedding cakes so expensive?", "answer": ""}, {"question": "What is the cost of a wedding cake?", "answer": "a few dollars", "ae_score": null, "qg_score": null}, {"question": "What is the cost of a wedding cake?", "answer": "a few dollars", "ae_score": null, "qg_score": null}], "content": "Wedding cakes come in a variety of sizes,  depending on the number of guests the cake will serve. Modern pastry chefs and cake designers use various ingredients and tools to create a cake that usually reflects the personalities of the couple. Marzipan, fondant, gum paste, buttercream, and chocolate are among the popular ingredients used.  Cakes range in price along with size and components. Cakes are usually priced on a per-person, or per-slice, basis. Prices can range from a few dollars to a few hundred dollars per-person or slice, depending on the pastry chef who is hired to make the cake. Wedding cakes and cake decorating in general have become a certain pop culture symbol in western society.  In America, TV shows such as Cake Boss or Amazing Wedding Cakes have become popular and are trending in today\u2019s popular culture.\nWedding cake was originally a luxury item, and a sign of celebration and social status.  The bigger the cake, the higher the social standing.  Wedding cakes in England and early America were traditionally fruit cakes, often  topped with marzipan and icing with tiers,  Cutting the cake was an important part of the reception. Today, many flavors and configurations are available  in addition to the traditional all-white tiered cake.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "Basic information", "sub_heading": "Basic information", "_id": "62--0---1---1", "title": "Wedding Cakes & Cake Decorating"}
{"qas": [{"question": "How did the idea of a wedding cake come about?", "answer": ""}, {"question": "Who designed the wedding cake in 1703?", "answer": "Thomas Rich", "ae_score": -0.201816937342089, "qg_score": null}, {"question": "Who designed the wedding cake in 1703?", "answer": "Thomas Rich", "ae_score": -0.201816937342089, "qg_score": null}], "content": "The contemporary wedding cake has grown out of several different ethnic traditions. One of the first traditions began in Ancient Rome where bread was broken over the bride\u2019s head to bring good fortune to the couple. In Medieval England cakes were stacked as high as possible for the bride and groom to kiss over.  A successful kiss meant they were guaranteed a prosperous life together.  From this the Croquembouche was created. The myth behind this cake tells of a Pastry chef, visiting Medieval England who witnessed their tradition of piling sweet rolls between the bride and groom, which they attempted to kiss over without knocking them all down. The pastry chef then went back to France and piled sweet rolls up into a tower to make the first Croquembouche. The modern croquembouche is still very popular in France, where it is now common to place the croquembouche tower on a bed of cake and make it a top tier. This traditional French wedding cake is built from Profiteroles and given a halo of spun sugar.\nIn 1703, Thomas Rich, a baker's apprentice from Ludgate Hill, fell in love with his employer's daughter and asked her to marry him. He wanted to make an extravagant cake, so he drew on St Bride's Church, on Fleet Street in London for inspiration.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "History", "sub_heading": "History", "_id": "62--1--0---1", "title": "The Croquembouche and the Croquembouche Tower"}
{"qas": [{"question": "What is the origin of the \"bride's pie\" tradition?", "answer": ""}, {"question": "When was the first wedding cake made?", "answer": "1882", "ae_score": -0.25422894384403144, "qg_score": null}, {"question": "When was the first wedding cake made?", "answer": "1882", "ae_score": -0.25422894384403144, "qg_score": null}], "content": "Traditionally the bride would place a ring inside the couple's portion of the cake to symbolise acceptance of the proposal. During the mid-17th century to the beginning of the 19th, the \u201cbride's pie\u201d was served at most weddings. Guests were expected to have a piece out of politeness.  It was considered very rude and bad luck not to eat the bride\u2019s pie. One tradition of bride\u2019s pie was to place a glass ring in the middle of the dessert and the maiden who found it would be the next to marry, similar to the modern tradition of catching the Flower bouquet. Bride\u2019s pie eventually developed into the bride\u2019s cake. At this point the dessert was no longer in the form of a pie and was sweeter than its predecessor. The bride cake was traditionally a plum or fruit cake.  The myth that eating the pie would bring good luck was still common but the glass ring slowly died out and the flower bouquet toss replaced it.\nFruit cakes were a sign of fertility and prosperity, which helped them gain popularity because married men wanted to have plenty of children. The bride\u2019s cake eventually transformed into the modern wedding cake we know today. In the 17th century, two cakes were made, one for the bride and one for the groom. The groom's cake eventually died out and the bride's cake turned into the main cake for the event. When the two cakes were served together, the groom's cake was typically the darker colored, rich fruit cake and generally much smaller than the bride's cake. The bride\u2019s cake was usually a simple pound cake with white icing because white was a sign of virginity and purity.  In the early 19th century, when the bride\u2019s cakes became popular, sugar became easier to obtain. The more refined and whiter sugars were still very expensive. so only wealthy families could afford to have a very pure white frosting.  This showed wealth and social status of the family.  When Queen Victoria used white icing on her cake it gained a new title, royal icing.\nThe modern wedding cake as we know it now originated at the wedding of Prince Leopold, Duke of Albany, in 1882; his wedding cake was the first to actually be completely edible. Pillars between cake tiers did not begin to appear until about 20 years later. The pillars were very poorly made from broomsticks covered in icing. The tiers represented prosperity and were a status symbol because only wealthy families could afford to include them in the cake. Prince Leopold\u2019s wedding cake was created in separate layers with very dense icing. When the icing hardened the tiers were then stacked; this method had never been used before, and it was a groundbreaking innovation for wedding cakes at the time. Modern wedding cakes still use this method, but because of the size of today\u2019s cakes, internal support is added to each layer in the form of dowels.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "History", "sub_heading": "Later history", "_id": "62--1--1---1", "title": "The Bride\u2019s Cake \u2014 The Modern Wedding Cake"}
{"qas": [{"question": "Why does the bride and groom share a piece of cake?", "answer": ""}, {"question": "What is the name of the oldest wedding cake?", "answer": "Banbury cake", "ae_score": -0.46921718128524054, "qg_score": null}, {"question": "What is the name of the oldest wedding cake?", "answer": "Banbury cake", "ae_score": -0.46921718128524054, "qg_score": null}], "content": "Wedding cakes have been present at wedding ceremonies for centuries. They were not always the focus of the event and often came in different forms, like pies or bread. There has always been a lot of symbolism associated with the wedding cake. The earliest known sweet wedding cake is known as a Banbury cake, which became popular in 1655. During the Roman era unsweetened barley bread was used as the wedding food and the groom would break the piece of bread in half over the brides head symbolizing \u201cbreaking of the bride\u2019s virginal state and the subsequent dominance of the groom over her.\" One of the most obvious symbolic traditions is the cake\u2019s white color to symbolize virginity and purity. The white color has been attached to wedding ceremonies since the Victorian era when Queen Victoria chose to wear a white wedding dress at her wedding to Prince Albert in 1840. Queen Victoria accentuated an existing symbol, the color white is frequently associated with virginity and purity. The wedding cake was originally known as the brides cake therefore the color white became common because the cake needed to reflect the bride.\nThe cutting of the cake is a task full of symbolism. The cake was originally intended to be distributed among the guests by only the bride because consuming the cake would ensure fertility. As weddings grew and the number of guests increased this task became a joint venture, the groom needed to help cut the growing cake and distribute it among their guests. Layers of cakes began to pile up and the icing would need to support the weight of the cake making is very difficult for one person to cut. The groom would assist the bride in this process. Once this tradition began the bride and groom would share a piece of cake before distributing it to the guests to symbolize their union and their promise to forever provide for each other.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "Symbolism", "sub_heading": "Symbolism", "_id": "62--2---1---1", "title": "Wedding Cakes Symbolism and the White Color"}
{"qas": [{"question": "Why do people eat the crumbs of the wedding cake?", "answer": ""}, {"question": "Where does the fruit in wedding cake come from?", "answer": "wine", "ae_score": -0.9669427516782088, "qg_score": null}, {"question": "Where does the fruit in wedding cake come from?", "answer": "wine", "ae_score": -0.9669427516782088, "qg_score": null}], "content": "The wedding cake is surrounded by superstitions. In a traditional American wedding, maidens would be invited to pull ribbons that are attached to the bottom layer of the wedding cake. Out of all the ribbons, only one contains a charm or a ring, and whoever gets the charm will be the next person to marry. In other countries, the wedding cake is broken over the bride\u2019s head to ensure fertility and bring good fortune to the couple.  Also, some people today think that eating the crumbs of the wedding cake would give them good luck because the wedding cake symbolizes happiness and good life to the newlywed couple.\nThere are also myths that most bridesmaids have on dreaming their future husbands. Hopeful bridesmaids would take a piece of cake home and place it under the pillow. Some bridesmaids would sleep with the pieces of cake in their left stocking and the rest are under their pillows after passing the pieces of cake through the bride\u2019s wedding ring.\nIn the medieval era, wedding cakes were constructed in rolls and buns that were laid on top of each other. The groom and bride would attempt to share a passionate kiss on top of the stack of rolls to ensure fertility and have good fortune. In the 18th century, newlywed couples would try to keep the cake until their first anniversary to prevent them from marriage problems in the future. This is one of the reasons why cakes in the 18th century were made of fruits and blended with wine.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "Superstitions", "sub_heading": "Superstitions", "_id": "62--3---1---1", "title": "The Wedding Cake Is surrounded by Myths and Myths"}
{"qas": [{"question": "What is the difference between a wedding cake and a regular cake?", "answer": ""}, {"question": "What is the most traditional type of wedding cake?", "answer": "White cake", "ae_score": -0.20664760716374847, "qg_score": null}, {"question": "What is the most traditional type of wedding cake?", "answer": "White cake", "ae_score": -0.20664760716374847, "qg_score": null}], "content": "Wedding cakes come in several types, such as traditional wedding cakes, wedding cakes based on flavor, smaller cakes or individual cakes, frosted cakes, and cupcakes. Traditional wedding cakes are white, including decoration and icing varieties such as buttercream, almond. etc.  Wedding cakes based on flavor include chocolate, vanilla, or strawberry.  Smaller cakes or individual cakes can be more efficient in terms of price.  Frosted cakes are popular due to the large amount of cream.\nIn modern society, the most popular wedding cake is called \u201cTraditional stack cake.\" This consists of layers of tiers\u2013 which can be a different flavors\u2013 positioned directly on top of the last\u201d. The traditional stack wedding cake is similar to the tiered cake.  Often they are filled with flowers or columns to add visual impact and height.  Separators can include jewels, shells, flowers and the like or can be completely separated by using traditional chrome stands.\nWhite cake is currently the most traditional wedding cake flavor, but different flavors of filling can be added between layers. Chocolate, carrot, Italian Rum and Italian Cream are also popular choices.  Frosting can be a classic smooth surface or combined with drizzle, swirls, or chips.\nFondant is a creative form of frosting style that is rolled out and draped over tiers.  Its smooth, firm sugar icing is often embellished with appliqu\u00e9s, gum-paste flowers, or royal-icing details. Fondant can be cut into designs, formed into shapes, flavored or tinted. Poured fondant is used to glaze petits fours and other detailed confections.  Such fondant gives a glossy finish and a sweet sugary taste.\nRoyal icing is made with sugar and egg white or meringue powder. It hardens to a firm finish that can be piped or thinned for \u201cflood work.\u201d  It hardens fast and is ideal for making detailed shapes ahead of time. It can also be piped directly onto cake tiers and works beautifully for delicate work.\nIn some areas, particularly the American South, two cakes are presented at weddings.  The more traditional tiered cake is the Bride's Cake, and a second flavor choice is called the \"Groom's Cake.\"  This tradition was brought over from England by early American colonists, who considered the white-iced \"Bride's Cake\" too light for masculinity.  The groom's cake was usually a dark, liquor-soaked fruitcake, particularly in Virginia.  Today Groom's Cakes are usually chocolate, although the groom often choose another of his favorite flavors.  The groom's cake is usually decorated or shaped as something significant to him, such as a hobby item, sports team or symbol of his occupation.  The movie \"Steel Magnolias\" features a red velvet groom's cake in the shape of a giant armadillo.  The Groom's Cake is served at the reception as a second flavor choice for the guests, although in some regions it is served at the rehearsal dinner.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "Types of wedding cakes", "sub_heading": "Types of wedding cakes", "_id": "62--4---1---1", "title": "Wedding Cakes: Traditional Wedding Cakes, Fondant Cakes, and Cupcakes."}
{"qas": [{"question": "What is the difference between a wedding cake and a normal cake?", "answer": ""}, {"question": "What is the most elaborate wedding cake in the uk?", "answer": "Royal wedding cakes", "ae_score": -0.3107826851457497, "qg_score": null}, {"question": "What is the most elaborate wedding cake in the uk?", "answer": "Royal wedding cakes", "ae_score": -0.3107826851457497, "qg_score": null}], "content": "Wedding cake toppers are models or art pieces that sit atop the cake.  The most common type of cake topper features a representation of a bride and groom in wedding attire.  This custom was dominant in US weddings in the 1950s, where it represented togetherness.  Wedding toppers today are often figures that indicate shared hobbies or other passions, if they are used at all. Some are humorous, or may represent the couple's hobby or occupation.  Some couples use a piece of art which will be displayed in their home later, such as a statuette or Christmas ornament.  Some couples skip the topper altogether or decorate the top tier with flowers.\nIn the United Kingdom, the traditional wedding cake is made from a rich fruitcake whose ingredients last without degrading. This allowed the top tier to be stored after the wedding, to be eaten at the christening of the first child.  Many modern cakes now consist of flavors such as vanilla sponge, chocolate sponge or carrot cake.\nMost cakes are between three and five tiers in height.  Royal wedding cakes are among the more elaborate cakes seen in the United Kingdom.", "page_name": "Wedding cake", "page_id": "Wedding%20cake", "heading": "Modern adaptations", "sub_heading": "Modern adaptations", "_id": "62--5---1---1", "title": "Wedding Cake Toppers in the United Kingdom"}
{"qas": [{"question": "Why is condensed milk so much more caloric than regular milk?", "answer": ""}, {"question": "What is the name of the brand of condensed milk sold in the usa?", "answer": "Eagle Brand", "ae_score": -0.3621083451663636, "qg_score": null}, {"question": "What is the name of the brand of condensed milk sold in the usa?", "answer": "Eagle Brand", "ae_score": -0.3621083451663636, "qg_score": null}], "content": "According to the writings of Marco Polo, in the 13th century the Tatars were able to condense milk. Marco Polo reported that ten pounds (4.5 kg) of milk paste was carried by each man, who would subsequently mix the product with water. However, this probably refers to the soft Tatar curd (katyk), which can be made into a drink (''ayran'') by diluting it, and therefore refers to fermented, not fresh, milk concentrate.\nNicolas Appert condensed milk in France in 1820, and Gail Borden, Jr., in the United States in 1853, in reaction to difficulties in storing milk for more than a few hours. Before this development, milk could only be kept fresh for a short while and was only available in the immediate vicinity of a cow. While returning from a trip to England in 1851, Borden was devastated by the deaths of several children, apparently from poor milk obtained from shipboard cows. With less than a year of schooling and following a series of failures, both of his own and of others, Borden was inspired by the vacuum pan he had seen being used by Shakers to condense fruit juice and managed to reduce milk without scorching or curdling it. Even then his first two factories failed and only the third, built with new partner Jeremiah Milbank in Wassaic, New York, produced a usable milk derivative that was long-lasting and needed no refrigeration.\nProbably of equal importance for the future of milk production were Borden's requirements (the \"Dairyman's Ten Commandments\") for farmers who wanted to sell him raw milk: they were required to wash the cows' udders before milking, keep barns swept clean, and scald and dry their strainers morning and night. By 1858, Borden's milk, sold as Eagle Brand, had gained a reputation for purity, durability and economy.\nIn 1864, Gail Borden's New York Condensed Milk Company constructed the New York Milk Condensery in Brewster, New York. This was the largest and most advanced milk factory of its day and was Borden's first commercially successful plant. Over 200 dairy farmers supplied 20,000 gallons (76,000 litres) of milk daily to the Brewster plant as demand increased driven by the American Civil War.\nThe U.S. government ordered huge amounts of condensed milk as a field ration for Union soldiers during the war. This was an extraordinary field ration for the 19th century: a typical 10 oz (300 ml) can contained 1,300 calories (5440 kJ), 1 oz (28 g) each of protein and fat, and more than 7 oz (200 g) of carbohydrate.\nSoldiers returning home from the war soon spread the word, and by the late 1860s condensed milk was a major product. The first Canadian condensery was built at Truro, Nova Scotia, in 1871. In 1899, E. B. Stuart opened the first Pacific Coast Condensed Milk Company (later known as the Carnation Milk Products Company) plant in Kent, Washington. The condensed milk market developed into a bubble, with too many manufacturers chasing too little demand. By 1912, high stocks of condensed milk led to a drop in price and many condenseries went out of business. In 1911, Nestl\u00e9 constructed the world's largest condensed milk plant in Dennington, Victoria, Australia.\nIn 1914, Otto F. Hunziker, head of Purdue University's dairy department, self-published ''Condensed Milk and Milk Powder: Prepared for the Use of Milk Condenseries, Dairy Students and Pure Food Departments''. This text, along with the additional work of  Hunziker and others involved with the American Dairy Science Association, standardized and improved condensery operations in the United States and internationally. Hunziker's book was republished in a seventh edition in October 2007 by Cartwright Press.\nThe First World War regenerated interest in, and the market for, condensed milk, primarily due to its storage and transportation benefits. In the US the higher price for raw milk paid by condenseries created significant problems for the cheese industry.", "page_name": "Condensed milk", "page_id": "Condensed%20milk", "heading": "History", "sub_heading": "History", "_id": "63--0---1---1", "title": "Condensed Milk and Milk Powder"}
{"qas": [{"question": "How does condensed milk work?", "answer": ""}, {"question": "What is added to sweetened condensed milk to reduce osmotic pressure?", "answer": "Sucrose", "ae_score": -0.5288333549291249, "qg_score": null}, {"question": "What is added to sweetened condensed milk to reduce osmotic pressure?", "answer": "Sucrose", "ae_score": -0.5288333549291249, "qg_score": null}], "content": "Raw milk is clarified and standardised, and is then heated to 85 \u2013 for several seconds. This heating process destroys some microorganisms, decreases fat separation and inhibits oxidation. Some water is evaporated from the milk and sugar is added until a 9:11 (nearly half) ratio of sugar to (evaporated) milk is reached. The sugar extends the shelf life of sweetened condensed milk. Sucrose increases the liquid's osmotic pressure, which prevents microorganism growth. The sweetened evaporated milk is cooled and lactose crystallization is induced.", "page_name": "Condensed milk", "page_id": "Condensed%20milk", "heading": "Production", "sub_heading": "Production", "_id": "63--1---1---1", "title": "Sweetened Condensed Milk \u2014 a Natural Alternative to Sugar"}
{"qas": [{"question": "Why does milk turn into Dulce de leche when left to simmer?", "answer": ""}, {"question": "Which jamaican drink is made from condensed milk mixed with bottled stout?", "answer": "Guinness Punch", "ae_score": -0.4122327088564163, "qg_score": null}, {"question": "Which jamaican drink is made from condensed milk mixed with bottled stout?", "answer": "Guinness Punch", "ae_score": -0.4122327088564163, "qg_score": null}], "content": "Condensed milk is used in recipes for the popular Brazilian candy ''brigadeiro'' (where condensed milk is the main ingredient), key lime pie, caramel candies, and other desserts.\nWhen a can of sweetened condensed milk is completely covered (at all times) by water, and is left to simmer, the content will turn into ''dulce de leche''. The simmering time may vary between 50 minutes to several hours depending on the pan used.\nIn parts of Asia and Europe, sweetened condensed milk is the preferred milk to be added to coffee or tea. Many countries in Southeast Asia, such as Vietnam and Cambodia, use condensed milk to flavour their coffee. In Malaysia, ''teh tarik'' is made from tea mixed with condensed milk, and condensed milk is an integral element in Hong Kong tea culture. In the Canary Islands, it is served as the bottom stripe in a glass of the local ''caf\u00e9 con leche'' and in Valencia it is served as a caf\u00e9 bomb\u00f3n. A popular treat in Asia is to put condensed milk on toast and eat it in a similar way as jam and toast. In West Yorkshire, in the years after World War II, condensed milk was an alternative to jam. Nestl\u00e9 has even produced a squeeze bottle similar to Smucker's jam squeeze bottles for this very purpose. Condensed milk is a major ingredient in many Indian desserts and sweets. While most Indians start with normal milk to reduce and sweeten it, packaged condensed milk has also become popular.\nIn New Orleans, sweetened condensed milk is commonly used as a topping on chocolate or similarly cream-flavored snowballs. In Scotland, it is mixed with sugar and butter then boiled to form a popular sweet candy called tablet or Swiss-milk-tablet, this recipe being very similar to another version of the Brazilian candy brigadeiro called ''branquinho''. In some parts of the Southern United States, condensed milk is a key ingredient in lemon ice box pie, a sort of cream pie. In the Philippines, condensed milk is mixed with some evaporated milk and eggs, spooned into shallow metal containers over liquid caramelized sugar, and then steamed to make a stiffer and more filling version of ''cr\u00e8me'' caramel known as ''leche flan'', also common in Brazil under the name ''pudim de leite''.\nIn Mexico, sweetened condensed milk is one of the main ingredients of the cold cake dessert (the leading brand is \"La Lechera\", the local version of Swiss ''Milch M\u00e4dchen'' by Nestl\u00e9), combined with evaporated milk, Marie biscuits, lemon juice, and tropical fruit. In Brazil, this recipe is also done exchanging fruit for puddings, most commonly vanilla and chocolate, known as ''torta de bolacha''. It is also used to make homemade ''dulce de leche'' by baking it in an oven. In Brazil, this is done by baking the unopened can in a ''bain-marie'', the result being ''doce de leite''. In Britain and Ireland, the contents of a boiled can is used as the layer between biscuit base and the banana and cream level in banoffee. In Latin American and Central American countries, condensed milk (along with evaporated milk and whole milk or canned cream) is used as a key ingredient in the popular tres leches cake dessert.\nIn Jamaica, Guinness Punch is prepared using  condensed milk mixed with  bottled stout. This is often flavoured with nutmeg and cocoa.\nDuring the communism era in Poland, it was common to boil a can of condensed milk in water for about three hours. The resulting product \u2013 a sweet semi-liquid substance which can be used as a cake icing or put between dry wafers \u2013 essentially the same as ''dulce de leche'', is called ''kajmak'' (although the original kaymak is a product similar to clotted cream). Homemade kajmak is less common nowadays, but recently some manufacturers of condensed milk introduced canned, ready-made ''kajmak'' which now is widely commercially produced, and is a national favourite for the sweets fillings.In Russia, the same product is called ''\u0432\u0430\u0440\u0451\u043d\u0430\u044f \u0441\u0433\u0443\u0449\u0451\u043d\u043a\u0430'' (''varionaya sguschyonka'', translates as \"boiled condensed milk\"). One of Russia's most famous cakes, \"bird's milk cake\", is often made with condensed milk.\nOther drinks containing condensed milk are the Vietnamese iced coffee, a coffee recipe from Vietnam, and the ''Asi\u00e1tico'', a popular drink of the Campo de Cartagena.", "page_name": "Condensed milk", "page_id": "Condensed%20milk", "heading": "Current use", "sub_heading": "Current use", "_id": "63--2---1---1", "title": "Condensed Milk and Desserts"}
{"qas": [{"question": "How does condensed milk work?", "answer": ""}, {"question": "What percentage of evaporated milk is reduced in condensed milk?", "answer": "60%", "ae_score": -0.34290726370751057, "qg_score": null}, {"question": "What percentage of evaporated milk is reduced in condensed milk?", "answer": "60%", "ae_score": -0.34290726370751057, "qg_score": null}], "content": "Condensed milk can be made from evaporated milk by mixing one measure of evaporated milk with one and a quarter measures of sugar in a saucepan, then heating and stirring the mixture until the sugar is completely dissolved, then cooling. It can also be made by simmering regular milk and sugar, until it is reduced by 60%.", "page_name": "Condensed milk", "page_id": "Condensed%20milk", "heading": "Substitutions", "sub_heading": "Substitutions", "_id": "63--3---1---1", "title": "Condensed Milk \u2014 Condensed Milk"}
{"qas": [{"question": "Why is there such a big paradigm shift in the way firms utilize the temporary worker?", "answer": ""}, {"question": "How many temporary workers were there in the us in 2000?", "answer": "over 3.5 million", "ae_score": -0.3214102364915745, "qg_score": null}, {"question": "How many temporary workers were there in the us in 2000?", "answer": "over 3.5 million", "ae_score": -0.3214102364915745, "qg_score": null}], "content": " The staffing industry in the United States began after World War II with small agencies in urban areas employing housewives for part-time work as office workers. Over the years the advantages of having workers who could be hired and fired on short notice and were exempt from paperwork and regulatory requirements resulted in a gradual but substantial increase in the use of temporary workers, with over 3.5 million temporary workers employed in the United States by 2000.\nThere has indeed been a great paradigm shift since the 1940s in the way firms utilize the temporary worker. Throughout the Fordist era, temporary workers made up a rather marginal proportion of the total labor force in North America. Typically, temporary workers were white women in pink collar, clerical positions who provided companies with a stop-gap solution for permanent workers who needed a leave of absence, when on vacation or in illness. In contrast, in the Post-Fordist period, characterized by neoliberalism, deindustrialization and the dismantling of the welfare state, these understandings of temporary labor began to shift. In this paradigm, the idea of the temporary worker as a stopgap solution to permanent labor became an entirely normative employment alternative to permanent work.\nTherefore, temporary workers no longer represented a substitute for permanent workers on leave but became semi-permanent, precarious positions routinely subject to the threat of elimination because of fluctuations in a company's products. In the context of today's temporary labor force, both people and positions have become temporary, and temporary agencies use the temporary worker in a systematic and planned, as opposed to impromptu manner.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "History", "sub_heading": "History", "_id": "64--0---1---1", "title": "The Temporary Worker in the Post-Fordist Era"}
{"qas": [{"question": "Why are there so many job applications for temporary workers?", "answer": ""}, {"question": "Where did temporary work become illegal in the 20th century?", "answer": "Western Europe", "ae_score": null, "qg_score": null}, {"question": "Where did temporary work become illegal in the 20th century?", "answer": "Western Europe", "ae_score": null, "qg_score": null}], "content": "As the market began to transform from Fordism to a post-Order regime of capital accumulation, the social regulation of labor markets and the very nature of work began to shift. This transformation has been characterized by an economic restructuring that emphasized flexibility within spaces of work, labor markets, employment relationships, wages and benefits. Most governments in Western Europe started to deregulate temporary work. And indeed, global processes of neoliberalism and market rule contributed greatly to this increasing pressure put on local labor markets towards flexibility. This greater flexibility within labor markets is important at the global level, particularly within OECD countries and liberal market economies (see liberal market economy).\nThe temporary labor industry is worth over \u20ac157 billion per year, and the largest agencies are spread across over 60 nations. The biggest temporary work agencies are most profitable in ''emerging'' economies of the Global North, and those that have undergone market liberalization, deregulation and (re)regulation.\nThe desire to market flexible, adaptable temporary workers has become a driving, monetary oriented objective of the temporary work industry. This has caused individual agencies to adopt practices that focus on competition with other firms, that promote \u201ctry before you buy\u201d practices and that maximize their ability to produce a product: the temporary worker. Through this process, the ideal temporary worker has today become largely imagined, produced and marketed by temporary agencies.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "Post-Fordism", "sub_heading": "Post-Fordism", "_id": "64--1---1---1", "title": "The Temporary Work Industry"}
{"qas": [{"question": "How do temp agencies work?", "answer": ""}, {"question": "Who do temp workers replace in a firm?", "answer": "a missing regular employee", "ae_score": -2.1105173481940755, "qg_score": null}, {"question": "Who do temp workers replace in a firm?", "answer": "a missing regular employee", "ae_score": -2.1105173481940755, "qg_score": null}], "content": "There are a number of reasons as to why a firm utilizes temp agencies. They provide employers a way to add more workers for a short term increase in the workforce. Using temps allows firms to replace a missing regular employee. A temp worker\u2019s competency and value can be determined without the inflexibility of hiring a new person and seeing how they work out. Utilizing temp workers can also be a way of not having to pay benefits and the increased salaries of a regular employees. A firm can also use temp workers to vary compensation in what would normally be an illegal or impossible manner. The role of temp workers in the work space can also have the effects of coercing regular employees into taking more work for less pay. Additionally, temp workers are less likely to sue over mistreatment, which allows firms to reduce the costs of employment in high-stress, regulated jobs.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "Agencies", "sub_heading": "Agencies", "_id": "64--2--0---1", "title": "Why Employers Utilize Temporary Workers"}
{"qas": [{"question": "Why are there so many temp agencies in the US?", "answer": ""}, {"question": "How much did the number of temporary workers increase from 1961-1971?", "answer": "16 percent", "ae_score": -0.8411494399531395, "qg_score": null}, {"question": "How much did the number of temporary workers increase from 1961-1971?", "answer": "16 percent", "ae_score": -0.8411494399531395, "qg_score": null}], "content": "Temp agencies are a growing part of industrial economies. From 1961-1971 the number of employees sent out by temporary staffing agencies increased by 16 percent. Temporary staffing industry payrolls increased by 166 percent from 1971 to 1981, and 206 percent from 1981 to 1991, and 278 percent from 1991 to 1999. The temporary staffing sector accounted for 1 out of 12 new jobs in the 90\u2019s. In 1996, $105 billion, worldwide,in staffing agency revenues. By 2008, $300 billion was generated, worldwide, in revenues for staffing agencies. The Temporary Staffing Industry accounts for 16% of job growth in the U.S. since the great recession ended, even though it only accounts for 2% of all-farm jobs.This growth has occurred for a number of reasons. Demand in temporary employment can be primarily attributed to demand by employers and not employees  A large driver of demand was in European labor market. Previously, temporary employment agencies were considered quasi-legal entities. This reputation shied potential client employers away. However, in the later half of the 20th century, there would be shift predominated by legal protections and closer relationships with primary employers. This combined with the tendency for growth of the TSI in countries where there are strict regulations on dismissal of hired employees but loose regulations on temporary work, growth is much faster compared to industrialized nations without these labor conditions.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "Agencies", "sub_heading": "Growth of temporary staffing", "_id": "64--2--1---1", "title": "Temporary Staffing Industry"}
{"qas": [{"question": "What is the difference between a temp worker and a regular employee?", "answer": ""}, {"question": "What do temps have to deal with?", "answer": "sexual harassment", "ae_score": -0.3424443940473623, "qg_score": null}, {"question": "What do temps have to deal with?", "answer": "sexual harassment", "ae_score": -0.3424443940473623, "qg_score": null}], "content": "Staffing agencies are prone to improper behavior just like any other employer. There have been cases of some temp agencies that have created and reinforced an ethnic hierarchy that determines who gets what jobs. \nTemps have been told to be a \u201cguest\u201d and not a worker, which can lead to worker exploitation. One ramification is that temps have to deal with sexual harassment and are sometimes encouraged not to report it, and in some rare cases encouraged to make themselves \u201csexually available\u201d. \nAn additional ramification of temp workers \u201cguest\u201d status is being at the bottom of the workplace hierarchy, which is visually identifiable on ID cards, in different colored uniforms, as well as the encouragement of more \u201cprovocative dress\u201d. Their \u201cguest\u201d status often means, temp Workers are unable to access on-site workplace accommodations and aren\u2019t included in meetings despite the length of their time working at the client firm. \nThis is all compounded by a work system in which temps must file complaints about clients through the temp agencies, which, often enough, not only disqualifies them from another assignment at that firm, it disqualifies them from receiving an assignment from that temporary agency upon review. Since a client firm is harder to replace than a client employee and there is no disincentive to not giving a complaining employee, an assignment; there is an incentive for agencies to find employees who are willing to go along with the conditions for client firms, as opposed to severing ties with firms that routinely violate the law.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "Agencies", "sub_heading": "Abuse in the temporary staffing industry", "_id": "64--2--2---1", "title": "The Role of Temporary Workers in Staffing Agencies."}
{"qas": [{"question": "What is the difference between temporary and permanent work?", "answer": ""}, {"question": "What type of policies have led to the erosion of the standard employment relationship in canada?", "answer": "neoliberal policies", "ae_score": -0.6033902537279329, "qg_score": null}, {"question": "What type of policies have led to the erosion of the standard employment relationship in canada?", "answer": "neoliberal policies", "ae_score": -0.6033902537279329, "qg_score": null}], "content": "Scholars have argued that neoliberal policies have been a prominent component in the erosion of the standard employment relationship. This precarious new model of employment has greatly reduced the worker\u2019s ability to negotiate and, in particular, with the introduction of advanced technology (that can easily replace the worker), reduced the temp\u2019s bargaining power. It has been suggested that labour regulations in North America do little in addressing labour market insecurities and the precarious nature of temporary labour. In many cases, legislation has done little to acknowledge or adapt to the growth of non-standard employment in Canada.\nIn the European Union, temporary work is regulated by the Temporary Agency Work Directive and the Member States' laws implementing that directive.", "page_name": "Temporary work", "page_id": "Temporary%20work", "heading": "Legal issues", "sub_heading": "Legal issues", "_id": "64--3---1---1", "title": "Temporary Work in Canada"}
{"qas": [{"question": "What is the difference between Mazpon and Christmas candy?", "answer": ""}, {"question": "Where does marzipan come from in latin american cuisine?", "answer": "Spain", "ae_score": -0.27350457471672485, "qg_score": null}, {"question": "Where does marzipan come from in latin american cuisine?", "answer": "Spain", "ae_score": -0.27350457471672485, "qg_score": null}], "content": "In Italy, particularly in Palermo, marzipan (''marzapane'') is often shaped and painted with food colourings to resemble fruit\u2014''Frutta martorana''\u2014especially during the Christmas season and on ''Il Giorno dei Morti'' (All Souls' Day) on November 2. May 9 and 10 are also special days for eating marzipan in Sicily. In Portugal, where the confection has been traditionally made by nuns, marzipan (''ma\u00e7ap\u00e3o'') is used to make fruit-shaped sweets; in the Algarve region in particular it is a very common sweet. There are other regions, as Toledo in Spain in which marzipan is shaped into simple animal shapes, and sometimes filled in with egg yolk (''yema'') and sugar. In Greece and Cyprus, marzipan is made in a variety of shapes and sizes and is almost always left white. In the islands of the Aegean in particular, white marzipan is considered a wedding treat and is served to guests at wedding feasts.In Malta marzipan is used as a filling in the traditional Maltese Easter treats called Figolla.\nIn the Netherlands and Belgium, marzipan figures are given as presents to children during Saint Nicholas's Eve. In Germany, it is common to give marzipan in the shape of a bread, which is called \"Marzipanbrot\" during Christmastime and shaped as small potatoes (Marzipankartoffeln). One traditional new year present is known as a ''Gl\u00fccksschwein'' (\"lucky pig\"). In Denmark and Norway, it is common to eat marzipan pigs for Christmas and marzipan shaped as eggs for Easter. In Geneva, a traditional part of the celebration of L'Escalade is the ritual smashing of a chocolate cauldron filled with marzipan vegetables, a reference to a Savoyard siege of the city which was supposedly foiled by a housewife with a cauldron of boiling soup. In Tallinn, in Maiasmokk caf\u00e9, there is a small museum dedicated to the history and manufacture of marzipan.\nIn the Middle East, marzipan (known as ''lozina'', which is derived from the word ''lawz'', the word used in several languages of Middle East for almonds) is flavoured with orange-flower water and shaped into roses and other delicate flowers before they are baked. Marzipan can also be made from oatmeal, farina, or semolina.In Iran, marzipan fruit is a traditional Passover treat, replacing biscuits and cakes.\nIn Latin American cuisine, marzipan was brought from Spain and is known by the ''Castilian'' (Spanish) word ''mazap\u00e1n'' and is also traditionally eaten at Christmas, although Latin American ''mazap\u00e1n'' is generally made with peanuts in place of almonds as the Spanish ''mazap\u00e1n''.\nIn the Indian state of Goa, the Goan Catholic dish ''Mazpon'' replaces almonds with cashew nuts and is used to make easter eggs and Christmas sweets. Christmas sweets would be of various shapes like fruits, flowers, stars, tree, santa, snow man and other designs. In the Philippines, ''mazap\u00e1n de pili'' (Spanish for \"pili marzipan\") is made from pili nuts.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "Around the world", "sub_heading": "Around the world", "_id": "65--0---1---1", "title": "The History of Marzipan in the Middle East"}
{"qas": [{"question": "Why are almonds the main ingredient in Christmas candy?", "answer": ""}, {"question": "Where does marzipan come from in the world?", "answer": "China", "ae_score": -0.3176915766892045, "qg_score": null}, {"question": "Where does marzipan come from in the world?", "answer": "China", "ae_score": -0.3176915766892045, "qg_score": null}], "content": "There are two proposed lines of origin for marzipan; they are not necessarily contradictory and may be complementary, as there have always been Mediterranean trade and cooking influences. Other sources establish the origin of marzipan in China, from where the recipe moved on to the Middle East and then to Europe through Al-Andalus.\nAlthough it is believed to have been introduced to Eastern Europe through the Turks (''badem ezmesi'' in Turkish, and most notably produced in Edirne),  there is some dispute between Hungary and Italy over its origin. In Sicily it was (1193) known as ''panis martius'' or ''marzapane'', ''i.e.'', March Bread. Marzipan became a specialty of the Hanseatic League port towns. In particular, the cities of L\u00fcbeck and Tallinn have a proud tradition of marzipan manufacture. Examples include L\u00fcbecker Marzipan (''PGI''). The city's manufacturers like Niederegger still guarantee their marzipan to contain two-thirds almonds by weight, which results in a product of highest quality. Historically, the city of K\u00f6nigsberg in East Prussia was also renowned for its distinctive marzipan production. K\u00f6nigsberg marzipan remains a special type of marzipan in Germany that is golden brown on its surface and sometimes embedded with marmalade at its centre.\nAnother possible geographic origin is in Spain, then known as Al-Andalus. In Toledo (850-900, though more probably 1150 during the reign of Alfonso VII) this specialty was known as ''Postre Regio'' (instead of ''Mazap\u00e1n'') and there are also mentions in The Book of One Thousand and One Nights of an almond paste eaten during Ramadan and as an aphrodisiac.Mazap\u00e1n is Toledo's most famous dessert, often created for Christmas, and has PGI status. Almonds have to be at least 50% of the total weight, following the directives of ''Mazap\u00e1n de Toledo'' regulator counseil.Another idea to support this line is the important tradition of another Spanish almond-based Christmas confectionery, the turron.\nUnder EU law, marzipan must have   a minimum almond oil content of 14% and a maximum moisture content of 8.5%. Optional additional ingredients are rosewater, honey, pistachios, preservatives, and sometimes hazelnut. In the U.S., marzipan is not officially defined, but it is generally made with a higher ratio of sugar to almonds than almond paste. One brand, for instance, has 28% almonds in its marzipan, and 45% almonds in its almond paste. However, in Sweden and Finland almond paste refers to a marzipan that contains 50% ground almonds, a much higher quality than regular marzipan. In Germany, L\u00fcbecker Marzipan is known for its quality. It contains 66% almonds. The original manually produced Mozartkugeln are made from green pistachio marzipan.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "History", "sub_heading": "History", "_id": "65--1---1---1", "title": "Marzipan Origins and Origins"}
{"qas": [{"question": "What is the difference between marzipan and persipan?", "answer": ""}, {"question": "What percentage of almonds are used in marzipan?", "answer": "less than 1%", "ae_score": null, "qg_score": null}, {"question": "What percentage of almonds are used in marzipan?", "answer": "less than 1%", "ae_score": null, "qg_score": null}], "content": "Persipan is a similar, yet less expensive product, in which the almonds are replaced by apricot or peach kernels. Many confectionery products sold as marzipan are made from less expensive materials, such as soy paste and almond essence. To control and detect the authenticity of marzipan, polymerase chain reaction methods can differentiate almonds from substitutes and adulterants at concentrations less than 1%. German marzipan is made by grinding whole almonds with sugar and partially drying the paste, and French marzipan (called 'massepain') is made by combining ground almonds with sugar syrup. Some marzipan is flavoured with rosewater. Spanish marzipan is made without bitter almonds. Sugar free marzipan can be made by replacing sugar with polyols such as maltitol.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "Variations", "sub_heading": "Variations", "_id": "65--2---1---1", "title": "Marzipan \u2014 Authenticity of Marzipan"}
{"qas": [{"question": "Why is the Spanish word \"mazap\u00e1n\" used to describe the Spanish language?", "answer": ""}, {"question": "What is the name of the almond-flavoured sweetmeats in venet?", "answer": "marzipan", "ae_score": -0.7023954083378113, "qg_score": null}, {"question": "What is the name of the almond-flavoured sweetmeats in venet?", "answer": "marzipan", "ae_score": -0.7023954083378113, "qg_score": null}], "content": "The German name has largely ousted the original English name ''marchpane'' with the same apparent derivation: \"March bread\". (The word ''marchpane'' occurs in Shakespeare's ''Romeo and Juliet'', Act 1, Scene 5, Line 9.) ''Marzapane'' is documented earlier in Italian than in any other language, and the sense \"bread\" for ''pan'' is Romance. The origin could be from the Latin term \"martius panis\", which means ''bread of March''. However, the ultimate etymology is unclear; for example, the Italian word derives from the Latin words \"Massa\" (itself from Greek \u039c\u03ac\u03b6\u03b1 \"Maza\") meaning pastry and \"Pan\" meaning bread, this can be particularly seen in the Proven\u00e7al ''massapan'', the Portuguese ''ma\u00e7ap\u00e3o'' (where '\u00e7' is an alternative form for the phoneme 'ss') and old Spanish ''mazap\u00e1n'' - the change from 'ss' to 'z' in Latin words was common in old Spanish and the 'r' appeared later. Though, it could also be derived from martis pan, bread of March. Among the other possible etymologies set forth in the Oxford English Dictionary, one theory proposes that the word \"marzipan\" may be a corruption of Martaban, a Burmese city famous for its jars.\nThe Real Academia Espa\u00f1ola suggests the idea of the Spanish word mazap\u00e1n to be derived from the Hispanic Arabic \u0628\u0633\u0645\u0629 pi\u010dm\u00e1\u1e6d, which is derived from the Greek \u03c0\u03b1\u03be\u03b1\u03bc\u03ac\u03b4\u03b9\u03bf\u03bd.\nAnother source could be from Arabic \u0645\u0648\u062b\u0627\u0628\u0627\u0646  ''mawth\u0101b\u0101n'' \"king who sits still\". The Arabic, Latinised as ''matapanus'', was used to describe a Venetian coin depicting an enthroned Christ the King. These coins were stored in ornate boxes. From about the fifteenth century, when the coins were no longer in circulation, the boxes became decorative containers for storing and serving luxury sweetmeats. One such luxury that crept into the box in the sixteenth century is the now-famous almond-flavoured marzipan, named (at least proximately) after the box in which it was stored.\nHowever, if marzipan has its origin in Persia, it is not unlikely that the name may come from Marzban (in Persian: \u0645\u0631\u0632\u0628\u0627\u0646, derived from the words Marz \u0645\u0631\u0632 meaning \"border\" or \"boundary\" and the suffix -b\u0101n \u0628\u0627\u0646 meaning guardian), a class of margraves or military commanders in charge of border provinces of the Sassanid Empire of Persia (Iran) between the 3rd and 7th centuries.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "Etymology", "sub_heading": "Etymology", "_id": "65--3---1---1", "title": "Marzipane \u2014 The Bread of March"}
{"qas": [{"question": "How do they make marzipan?", "answer": ""}, {"question": "How is marzipan made from almonds boiled?", "answer": "blanching", "ae_score": -0.2453965387781861, "qg_score": null}, {"question": "How is marzipan made from almonds boiled?", "answer": "blanching", "ae_score": -0.2453965387781861, "qg_score": null}], "content": "To produce marzipan, raw almonds are cleaned \"by sieving, air elutriation, and other electronic or mechanical devices\", then immersed in water with a temperature just below the boiling point for about five minutes, in a process known as blanching. This loosens the almonds' skin, which is removed by passing the almonds through rubber-covered rotating cylinders. This process reduces HCN concentration and increases water content. They are then cooled, after which they are coarsely chopped and ground, with up to 35% sugar, into almond flour.\nThe almond flour mixture is roasted and cooled, after which sucrose (table sugar) and possibly a binding agent such as starch syrup or sorbitol are added. It may then be moulded into any shape. Marzipan must be covered in an airtight container to prevent it from hardening and dehydrating. It should be protected from direct light to prevent rancidity of almond oil, a result of lipid oxidation.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "Production", "sub_heading": "Production", "_id": "65--4---1---1", "title": "Marzipan is a type of almond flour"}
{"qas": [{"question": "Why does marzipan taste so much better than almonds?", "answer": ""}, {"question": "Where does marzipan get its flavor from?", "answer": "benzaldehyde", "ae_score": -0.06258369578087168, "qg_score": null}, {"question": "Where does marzipan get its flavor from?", "answer": "benzaldehyde", "ae_score": -0.06258369578087168, "qg_score": null}], "content": "The aroma and flavor of marzipan can partially be attributed to benzaldehyde, which is found naturally in almonds.\nMarzipan is a food emulsion that contains 4 phases: a solid phase of suspended particles including almonds and sugars, a suspended air pocket phase formed from incorporated air during mixing, a water phase, and a lipid phase from almond oil. The phases can separate when left alone for long periods of time. It is stabilized by the phospholipids and triglycerides found in the almond cells. The fatty acids found in almonds include saturated fats such as stearic acid and unsaturated fats such as linoleic acid. Emulsifiers can be added during production to increase shelf life.\nMarzipan's softness is a balance between the solid and liquid components. It should have a moisture content of less than 10%.", "page_name": "Marzipan", "page_id": "Marzipan", "heading": "Science", "sub_heading": "Science", "_id": "65--5---1---1", "title": "Marzipan is a food emulsion that contains 4 phases."}
{"qas": [{"question": "What are the tubers on the bottom of a beer bottle made of?", "answer": ""}, {"question": "What colour are the flowers of jerusalem artichoke?", "answer": "yellow", "ae_score": -0.39311863896180227, "qg_score": null}, {"question": "What colour are the flowers of jerusalem artichoke?", "answer": "yellow", "ae_score": -0.39311863896180227, "qg_score": null}], "content": "''Helianthus tuberosus'' is a herbaceous perennial plant growing to 1.5 \u2013 tall with opposite leaves on the upper part of the stem but alternate below. The leaves have a rough, hairy texture. Larger leaves on the lower stem are broad ovoid-acute and can be up to 30 cm long. Leaves higher on the stem are smaller and narrower.<ref name=lilly/>\nThe flowers are yellow and produced in capitate flowerheads, which are 5 \u2013 in diameter, with 10\u201320 ray florets and 60 or more small disc florets.<ref name=lilly/>\nThe tubers are elongated and uneven, typically 7.5 \u2013 long and 3 \u2013 thick, and vaguely resembling ginger root in appearance, with a crisp texture when raw. They vary in colour from pale brown to white, red, or purple.<ref name=purdue/>", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "Description", "sub_heading": "Description", "_id": "66--0---1---1", "title": "''Helianthus tuberosus'' \u2014 A Herbaceous Per"}
{"qas": [{"question": "Why is Jerusalem artichoke considered a healthy choice for type 2 diabetes?", "answer": ""}, {"question": "What is the main ingredient in jerusalem artichoke?", "answer": "fructose", "ae_score": -0.31158597402154764, "qg_score": null}, {"question": "What is the main ingredient in jerusalem artichoke?", "answer": "fructose", "ae_score": -0.31158597402154764, "qg_score": null}], "content": "Before the arrival of Europeans, Native Americans cultivated ''Helianthus tuberosus'' as a food source. The tribes who first grew it traded it to other tribes in other regions. The tubers persist for years after being planted, so that the species expanded its range from central North America to the eastern and western regions. Early European colonists learned of this, and sent tubers back to Europe, where it became a popular crop and naturalized there. It later gradually fell into obscurity in North America, but attempts to market it commercially have been successful in the late 1900s and early 2000s.\nThe artichoke contains about 2% protein, no oil, and a surprising lack of starch. It is rich in the carbohydrate inulin (76%), which is a polymer of the monosaccharide fructose. Tubers stored for any length of time will convert their inulin into its component fructose. Jerusalem artichokes have an underlying sweet taste because of the fructose, which is about one and a half times as sweet as sucrose.\nJerusalem artichokes have also been promoted as a healthy choice for type 2 diabetics, because fructose is better tolerated by people who are type 2 diabetic. It has also been reported as a folk remedy for diabetes.  Temperature variances have been shown to affect the amount of inulin the Jerusalem artichoke can produce. When not in tropical regions, it has been shown to make less inulin than when it is in a warmer region.", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "Food use", "sub_heading": "Food use", "_id": "66--1---1---1", "title": "Jerusalem Artichoke \u2014 A Healthy Choice for Type 2 Diabetes"}
{"qas": [{"question": "Why is Jerusalem artichoke called \"artichoke\"?", "answer": ""}, {"question": "Which french explorer sent the first samples of the jerusalem artichoke?", "answer": "Samuel de Champlain", "ae_score": -0.07394774061970046, "qg_score": null}, {"question": "Which french explorer sent the first samples of the jerusalem artichoke?", "answer": "Samuel de Champlain", "ae_score": -0.07394774061970046, "qg_score": null}], "content": "Despite its name, the Jerusalem artichoke has no relation to Jerusalem, and it is not a type of artichoke, though the two are distantly related as members of the daisy family. The origin of the \"Jerusalem\" part of the name is uncertain. Italian settlers in the United States called the plant ''girasole'', the Italian word for sunflower, because of its resemblance to the garden sunflower (both plants are members of the genus ''Helianthus''). Over time, the name ''girasole'' (pronounced closer to  in southern Italian dialects) may have been changed to Jerusalem.  The English later corrupted girasole artichoke (meaning, \"sunflower artichoke\") to Jerusalem artichoke. Another explanation for the name is that the Puritans, when they came to the New World, named the plant with regard to the \"New Jerusalem\" they believed they were creating in the wilderness. There have also been various other names applied to the plant, such as the French or Canada potato, topinambour, and lambchoke. Sunchoke, a name by which it is still known today, was invented in the 1960s by Frieda Caplan, a produce wholesaler who was trying to revive the plant's appeal.\nThe artichoke part of the Jerusalem artichoke's name comes from the taste of its edible tuber. Samuel de Champlain, the French explorer, sent the first samples of the plant to France, noting its taste was similar to that of an artichoke.\nThe name \"topinambur\", in one account, dates from 1615, when a member of the Brazilian coastal tribe called the Tupinamb\u00e1 visited the Vatican at the same time that a sample of the tuber from Canada was on display there, presented as a critical food source that helped French Canadian settlers survive the winter. The New World connection resulted in the name topinambur being applied to the tuber, the word now used in French, German, Italian, Romanian, Russian, and Spanish.", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "Etymology", "sub_heading": "Etymology", "_id": "66--2---1---1", "title": "Jerusalem Artichoke \u2014 A New World Connection"}
{"qas": [{"question": "How did Jerusalem artichokes become so popular?", "answer": ""}, {"question": "What are jerusalem artichokes called in canada?", "answer": "Canadian truffle", "ae_score": -0.4972856425736654, "qg_score": null}, {"question": "What are jerusalem artichokes called in canada?", "answer": "Canadian truffle", "ae_score": -0.4972856425736654, "qg_score": null}], "content": "Jerusalem artichokes were first cultivated by the Native Americans long before the arrival of the Europeans; this extensive cultivation obscures the exact native range of the species.<ref name=grin/> The French explorer Samuel de Champlain found domestically grown plants at Cape Cod in 1605. He then brought the plant back with him to France. By the mid-1600s, the Jerusalem artichoke had become a very common vegetable for human consumption in Europe and the Americas and was also used for livestock feed in Europe and colonial America.  The French in particular were especially fond of the vegetable, which reached its peak popularity at the turn of the 19th century.  The Jerusalem artichoke was titled 'best soup vegetable' in the 2002 Nice Festival for the Heritage of the French Cuisine.\nThey have also been called the \"Canadian truffle\". In France they are associated, along with rutabagas, with the deprivations of the years of Nazi Occupation during World War II, where the rationing and scarcity of traditional foods made them a regular part of the French diet until at the end of the war they returned to their customary role as animal feed.", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "History", "sub_heading": "History", "_id": "66--3---1---1", "title": "The Jerusalem Artichoke"}
{"qas": [{"question": "What is the difference between Jerusalem artichoke brandy and red Rossler?", "answer": ""}, {"question": "How much of the jerusalem artichoke crop is grown in baden-w?", "answer": "over 90%", "ae_score": -0.32618405476875784, "qg_score": null}, {"question": "How much of the jerusalem artichoke crop is grown in baden-w?", "answer": "over 90%", "ae_score": -0.32618405476875784, "qg_score": null}], "content": "In Baden-W\u00fcrttemberg, Germany, over 90% of the Jerusalem artichoke crop is used to produce a spirit called \"\", \"Topi\" or \"Rossler\".By the end of the 19th-century, Jerusalem artichokes were being used in Baden to make a spirit called  \"Jerusalem Artichoke Brandy\", \"Jerusalem Artichoke\", \"Topi\", \"Erd\u00e4pfler\", \"Rossler\",  or \"Borbel\".\nJerusalem artichoke brandy smells fruity and has a slight nutty-sweet flavour. It is characterised by an intense, pleasing, earthy note. The tubers are washed and dried in an oven before being fermented and distilled. It can be further refined to make \"Red Rossler\" by adding common tormentil, and other ingredients such as currants, to produce a somewhat bitter and astringent decoction. It is used as digestif, as well as a remedy for diarrhoea or abdominal pain.", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "Cultivation and use", "sub_heading": "Cultivation and use", "_id": "66--4--0---1", "title": "Jerusalem Artichoke Brandy \u2014 Topi, Rossler, Erd\u00e4pfl"}
{"qas": [{"question": "The Jerusalem artichoke scandal?", "answer": ""}, {"question": "Where did jerusalem artichoke get its name?", "answer": "agricultural pyramid scheme", "ae_score": -1.0350464788078795, "qg_score": null}, {"question": "Where did jerusalem artichoke get its name?", "answer": "agricultural pyramid scheme", "ae_score": -1.0350464788078795, "qg_score": null}], "content": "In the 1980s, the Jerusalem artichoke also gained some notoriety when its seeds were planted by midwestern US farmers at the prodding of an agricultural pyramid scheme. There was little market for the tuber in that part of the US at the time, but farmers were assured it would soon appear on the commodities market. The only profits were realized by the initial distributors and the first few levels of farmers (who sold their seeds to subsequent levels of the pyramid). As a result, many of the farms that had planted large quantities of the crop were ruined.", "page_name": "Jerusalem artichoke", "page_id": "Jerusalem%20artichoke", "heading": "Pyramid scheme", "sub_heading": "Pyramid scheme", "_id": "66--5---1---1", "title": "The Jerusalem Artichoke: The Jerusalem Artichoke"}
{"qas": [{"question": "What is happening in our body when we get the urge to do something physical?", "answer": ""}, {"question": "What hormone is released during fight or flight?", "answer": "norepinephrine", "ae_score": -0.5687812506805592, "qg_score": null}, {"question": "What hormone is released during fight or flight?", "answer": "norepinephrine", "ae_score": -0.5687812506805592, "qg_score": null}], "content": "The autonomic nervous system is a control system that acts largely unconsciously and regulates heart rate, digestion, respiratory rate, pupillary response, urination, and sexual arousal. This system is the primary mechanism in control of the fight-or-flight response and its role is mediated by two different components.\nThe sympathetic nervous system originates in the spinal cord and its main function is to activate the physiological changes that occur during the fight-or-flight response. This component of the autonomic nervous system utilizes and activates the release of norepinephrine in the reaction.\nThe parasympathetic nervous system originates in the spinal cord and medulla and works in concert with the sympathetic nervous system. Its main function is to activate the \"rest and digest\" response and return the body to homeostasis after the fight or flight response. This system utilizes and activates the release of the neurotransmitter acetylcholine.\nThe reaction begins in the amygdala, which triggers a neural response in the hypothalamus. The initial reaction is followed by activation of the pituitary gland and secretion of the hormone ACTH. The adrenal gland is activated almost simultaneously and releases the hormone epinephrine. The release of chemical messengers results in the production of the hormone cortisol, which increases blood pressure, blood sugar, and suppresses the immune system. The initial response and subsequent reactions are triggered in an effort to create a boost of energy. This boost of energy is activated by epinephrine binding to liver cells and the subsequent production of glucose. Additionally, the circulation of cortisol functions to turn fatty acids into available energy, which prepares muscles throughout the body for response. Catecholamine hormones, such as adrenaline (epinephrine) or noradrenaline (norepinephrine), facilitate immediate physical reactions associated with a preparation for violent muscular action. These include the following:\nThe physiological changes that occur during the fight or flight response are activated in order to give the body increased strength and speed in anticipation of fighting or running. Some of the specific physiological changes and their functions include:", "page_name": "Fight-or-flight response", "page_id": "Fight-or-flight%20response", "heading": "Physiology", "sub_heading": "Physiology", "_id": "67--0---1---1", "title": "The Fight-or-Flight Response and its Functions"}
{"qas": [{"question": "Why is it that when we are in a fight or flight situation, we feel the urge to cry?", "answer": ""}, {"question": "What are the risk factors for a fight or flight response?", "answer": "anxiety and aggression", "ae_score": -0.327886460009073, "qg_score": null}, {"question": "What are the risk factors for a fight or flight response?", "answer": "anxiety and aggression", "ae_score": -0.327886460009073, "qg_score": null}], "content": "In the context of the fight or flight response, emotional regulation is used proactively to avoid threats of stress or to control the level of emotional arousal.\nDuring the reaction, the intensity of emotion that is brought on by the stimulus will also determine the nature and intensity of the behavioral response. Individuals with higher levels of emotional reactivity may be prone to anxiety and aggression, which illustrates the implications of appropriate emotional reaction in the fight or flight response.", "page_name": "Fight-or-flight response", "page_id": "Fight-or-flight%20response", "heading": "Emotional components", "sub_heading": "Emotional components", "_id": "67--1---1---1", "title": "Emotional Regulation in the Fight or Flight Response"}
{"qas": [{"question": "Why is it that when we are in a fight or flight situation, we tend to think of negative things?", "answer": ""}, {"question": "Where does the fight or flight response come from?", "answer": "Perceived control", "ae_score": -0.2948642355660595, "qg_score": null}, {"question": "Where does the fight or flight response come from?", "answer": "Perceived control", "ae_score": -0.2948642355660595, "qg_score": null}], "content": "The specific components of cognitions in the fight or flight response seem to be largely negative. These negative cognitions may be characterized by: attention to negative stimuli, the perception of ambiguous situations as negative, and the recurrence of recalling negative words. There also may be specific negative thoughts associated with emotions commonly seen in the reaction.\nPerceived control relates to an individual's thoughts about control over situations and events. Perceived control should be differentiated from actual control because an individual's beliefs about their abilities may not reflect their actual abilities. Therefore, overestimation or underestimation of perceived control can lead to anxiety and aggression.\nThe social information processing model proposes a variety of factors that determine behavior in the context of social situations and preexisting thoughts. The attribution of hostility, especially in ambiguous situations, seems to be one of the most important cognitive factors associated with the fight or flight response because of its implications towards aggression.", "page_name": "Fight-or-flight response", "page_id": "Fight-or-flight%20response", "heading": "Cognitive components", "sub_heading": "Cognitive components", "_id": "67--2---1---1", "title": "The fight or flight response"}
{"qas": [{"question": "Why is it that when we are stressed out, we feel the urge to fight?", "answer": ""}, {"question": "What type of animal will fight when threatened?", "answer": "Rats", "ae_score": -0.2727552991552918, "qg_score": null}, {"question": "What type of animal will fight when threatened?", "answer": "Rats", "ae_score": -0.2727552991552918, "qg_score": null}], "content": "An evolutionary psychology explanation is that early animals had to react to threatening stimuli quickly and did not have time to psychologically and physically prepare themselves. The fight or flight response provided them with the mechanisms to rapidly respond to threats against survival.\nA typical example of the stress response is a grazing zebra. If the zebra sees a lion closing in for the kill, the stress response is activated. The escape requires intense muscular effort, supported by all of the body\u2019s systems. The sympathetic nervous system\u2019s activation rarely provides for these needs. A similar example involving fight is of a cat about to be attacked by a dog. The cat shows accelerated heartbeat, piloerection (hair standing on end, normally to dissipate heat), and pupil dilation, all signs of sympathetic arousal. Note that the zebra and cat still maintain homeostasis in all states.\nAnimals respond to threats in many complex ways. Rats, for instance, try to escape when threatened, but will fight when cornered. Some animals stand perfectly still so that predators will not see them. Many animals freeze or play dead when touched in the hope that the predator will lose interest.\nOther animals have alternative self-protection methods. Some species of cold-blooded animals change color swiftly, to camouflage themselves. These responses are triggered by the sympathetic nervous system, but, in order to fit the model of fight or flight, the idea of flight must be broadened to include escaping capture either in a physical or sensory way. Thus, flight can be disappearing to another location or just disappearing in place. And often both fight and flight are combined in a given situation.\nThe fight or flight actions also have polarity \u2013 the individual can either fight or flee against something that is threatening, such as a hungry lion, or fight for or fly towards something that is needed, such as the safety of the shore from a raging river.\nA threat from another animal does not always result in immediate fight or flight. There may be a period of heightened awareness, during which each animal interprets behavioral signals from the other. Signs such as paling, piloerection, immobility, sounds, and body language communicate the status and intentions of each animal. There may be a sort of negotiation, after which fight or flight may ensue, but which might also result in playing, mating, or nothing at all. An example of this is kittens playing: each kitten shows the signs of sympathetic arousal, but they never inflict real damage.", "page_name": "Fight-or-flight response", "page_id": "Fight-or-flight%20response", "heading": "Other animals", "sub_heading": "Other animals", "_id": "67--3---1---1", "title": "How Animals Respond to Threats and Threats"}
{"qas": [{"question": "What is the difference between disinfectant and non disinfectant?", "answer": ""}, {"question": "What is the name of the bitter substance that most modern household disinfectants contain?", "answer": "Bitrex", "ae_score": -0.21276687850184708, "qg_score": null}, {"question": "What is the name of the bitter substance that most modern household disinfectants contain?", "answer": "Bitrex", "ae_score": -0.21276687850184708, "qg_score": null}], "content": "A perfect disinfectant would also offer complete and full microbiological sterilisation, without harming humans and useful form of life, be inexpensive, and noncorrosive. However, most disinfectants are also, by nature, potentially harmful (even toxic) to humans or animals. Most modern household disinfectants contain Bitrex, an exceptionally bitter substance added to discourage ingestion, as a safety measure. Those that are used indoors should never be mixed with other cleaning products as chemical reactions can occur.The choice of disinfectant to be used depends on the particular situation. Some disinfectants have a wide spectrum (kill many different types of microorganisms), while others kill a smaller range of disease-causing organisms but are preferred for other properties (they may be non-corrosive, non-toxic, or inexpensive).There are arguments for creating or maintaining conditions that are not conducive to bacterial survival and multiplication, rather than attempting to kill them with chemicals. Bacteria can increase in number very quickly, which enables them to evolve rapidly. Should some bacteria survive a chemical attack, they give rise to new generations composed completely of bacteria that have resistance to the particular chemical used. Under a sustained chemical attack, the surviving bacteria in successive generations are increasingly resistant to the chemical used, and ultimately the chemical is rendered ineffective. For this reason, some question the wisdom of impregnating cloths, cutting boards and worktops in the home with bactericidal chemicals.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Properties", "sub_heading": "Properties", "_id": "68--0---1---1", "title": "How to Choose the Right Disinfectant for Your Home"}
{"qas": [{"question": "Why is it so difficult to use glycol disinfectants in real life?", "answer": ""}, {"question": "In what year was mists of dilute bleach discovered?", "answer": "1928", "ae_score": -0.4383005216045658, "qg_score": null}, {"question": "In what year was mists of dilute bleach discovered?", "answer": "1928", "ae_score": -0.4383005216045658, "qg_score": null}], "content": "Air disinfectants are typically chemical substances capable of disinfecting microorganisms suspended in the air. Disinfectants are generally assumed to be limited to use on surfaces, but that is not the case.  In 1928, a study found that airborne microorganisms could be killed using mists of dilute bleach. An air disinfectant must be dispersed either as an aerosol or vapour at a sufficient concentration in the air to cause the number of viable infectious microorganisms to be significantly reduced.\nIn the 1940s and early 1950s, further studies showed inactivation of diverse bacteria, influenza virus, and ''Penicillium chrysogenum'' (previously ''P. notatum'') mold fungus using various glycols, principally propylene glycol and triethylene glycol.  In principle, these chemical substances are ideal air disinfectants because they have both high lethality to microorganisms and low mammalian toxicity.\nAlthough glycols are effective air disinfectants in controlled laboratory environments, it is more difficult to use them effectively in real-world environments because the disinfection of air is sensitive to continuous action.  Continuous action in real-world environments with outside air exchanges at door, HVAC, and window interfaces, and in the presence of materials that adsorb and remove glycols from the air, poses engineering challenges that are not critical for surface disinfection.  The engineering challenge associated with creating a sufficient concentration of the glycol vapours in the air have not to date been sufficiently addressed.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Types", "_id": "68--1--0---1", "title": "Air Disinfectants in Real-World Environments"}
{"qas": [{"question": "How does alcohol disinfect surfaces?", "answer": ""}, {"question": "What is the name of ammonium cation based compound?", "answer": "Quaternary", "ae_score": null, "qg_score": null}, {"question": "What is the name of ammonium cation based compound?", "answer": "Quaternary", "ae_score": null, "qg_score": null}], "content": "Alcohol and alcohol plus Quaternary ammonium cation based compounds comprise a class of proven surface sanitizers and disinfectants approved by the EPA and the Centers for Disease Control for use as a hospital grade disinfectant. Alcohols are most effective when combined with distilled water to facilitate diffusion through the cell membrane; 100% alcohol typically denatures only external membrane proteins.  A mixture of 70% ethanol or isopropanol diluted in water is effective against a wide spectrum of bacteria, though higher concentrations are often needed to disinfect wet surfaces.  Additionally, high-concentration mixtures (such as 80% ethanol + 5% isopropanol) are required to effectively inactivate lipid-enveloped viruses (such as HIV, hepatitis B, and hepatitis C).  The efficacy of alcohol is enhanced when in solution with the wetting agent dodecanoic acid (coconut soap).  The synergistic effect of 29.4% ethanol with dodecanoic acid is effective against a broad spectrum of bacteria, fungi, and viruses.  Further testing is being performed against Clostridium difficile (C.Diff) spores with higher concentrations of ethanol and dodecanoic acid, which proved effective with a contact time of ten minutes.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Alcohols", "_id": "68--1--1---1", "title": "Alcohol and Alcohol Plus Quaternary Ammonium Cation based compounds"}
{"qas": [{"question": "What is the difference between Aldehydes and Fungi?", "answer": ""}, {"question": "What is an example of a fungicidal disinfectant?", "answer": "Aldehydes", "ae_score": -0.5477393035913434, "qg_score": null}, {"question": "What is an example of a fungicidal disinfectant?", "answer": "Aldehydes", "ae_score": -0.5477393035913434, "qg_score": null}], "content": "Aldehydes, such as formaldehyde and glutaraldehyde, have a wide microbiocidal activity and are sporicidal and fungicidal. They are partly inactivated by organic matter and have slight residual activity.\nSome bacteria have developed resistance to glutaraldehyde, and it has been found that glutaraldehyde can cause asthma and other health hazards, hence ortho-phthalaldehyde is replacing glutaraldehyde.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Aldehydes", "_id": "68--1--2---1", "title": "Aldehyde is an Aldehyde"}
{"qas": [{"question": "How do disinfectants work?", "answer": ""}, {"question": "What happens to cell lysis and death?", "answer": "loss of structure", "ae_score": -1.7965915883365016, "qg_score": null}, {"question": "What happens to cell lysis and death?", "answer": "loss of structure", "ae_score": -1.7965915883365016, "qg_score": null}], "content": "Oxidizing agents act by oxidizing the cell membrane of microorganisms, which results in a loss of structure and leads to cell lysis and death.  A large number of disinfectants operate in this way. Chlorine and oxygen are strong oxidizers, so their compounds figure heavily here.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Oxidizing agents", "_id": "68--1--3---1", "title": "Oxidizing agents act by oxidizing the membrane of microorganisms."}
{"qas": [{"question": "Quaternary ammonium compounds?", "answer": ""}, {"question": "What is an example of a quaternary ammonium compound?", "answer": "benzalkonium chloride", "ae_score": -0.6984023111138797, "qg_score": null}, {"question": "What is an example of a quaternary ammonium compound?", "answer": "benzalkonium chloride", "ae_score": -0.6984023111138797, "qg_score": null}], "content": "Quaternary ammonium compounds (\"quats\"), such as benzalkonium chloride, are a large group of related compounds. Some concentrated formulations have been shown to be effective low-level disinfectants. Quaternary Ammonia at or above 200ppm plus Alcohol solutions exhibit efficacy against difficult to kill non-enveloped viruses such as norovirus, rotavirus, or polio virus.  Newer synergous, low-alcohol formulations are highly effective broad-spectrum disinfectants with quick contact times (3\u20135 minutes) against bacteria, enveloped viruses, pathogenic fungi, and mycobacteria.  Quats are biocides that also kill algae and are used as an additive in large-scale industrial water systems to minimize undesired biological growth.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Quaternary ammonium compounds", "_id": "68--1--5---1", "title": "Quaternary Ammonium Compounds"}
{"qas": [{"question": "What is silver dihydrogen citrate and how does it work?", "answer": ""}, {"question": "How many studies did the cochrane Collaboration review?", "answer": "26", "ae_score": -0.3768432272830597, "qg_score": null}, {"question": "How many studies did the cochrane Collaboration review?", "answer": "26", "ae_score": -0.3768432272830597, "qg_score": null}], "content": "Silver has antimicrobial properties, but compounds suitable for disinfection are usually unstable and have a limited shelf-life. Silver dihydrogen citrate (SDC) is a chelated form of silver that maintains its stability. SDC kills microorganisms by two modes of action: 1) the silver ion deactivates structural and metabolic membrane proteins, leading to microbial death; 2) the microbes view SDC as a food source, allowing the silver ion to enter the microbe. Once inside the organism, the silver ion denatures the DNA, which halts the microbe's ability to replicate, leading to its death. This dual action makes SDC highly and quickly effective against a broad spectrum of microbes.  SDC is non-toxic, non-caustic, colorless, odorless, and tasteless, and does not produce toxic fumes. SDC is non-toxic to humans and animals: the United States Environmental Protection Agency classifies it into the lowest toxicity category for disinfectants, category IV.\nA meta-analysis of 26 studies by the Cochrane Collaboration found that, most were small and of poor quality, and that there was not enough evidence to support the use of silver-containing dressings or creams, as generally these treatments did not promote wound healing or prevent wound infections. Some evidence suggested that silver sulphadiazine had no effect on infection, and actually slowed healing.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Silver", "_id": "68--1--6---1", "title": "Silver Dihydrogen Citrate (SDC) is a chelated form of silver"}
{"qas": [{"question": "What is the difference between copper and zinc alloy?", "answer": ""}, {"question": "What organization has approved a long list of antimicrobial copper products?", "answer": "EPA", "ae_score": null, "qg_score": null}, {"question": "What organization has approved a long list of antimicrobial copper products?", "answer": "EPA", "ae_score": null, "qg_score": null}], "content": "These copper alloys were granted EPA registrations as \"antimicrobial materials with public health benefits,\" which allows manufacturers to legally make claims regarding the positive public health benefits of products made with registered antimicrobial copper alloys. EPA has approved a long list of antimicrobial copper products made from these alloys, such as bedrails, handrails, over-bed tables, sinks, faucets, door knobs, toilet hardware, computer keyboards, health club equipment, shopping cart handles, etc. (for a comprehensive list of products, see: Antimicrobial copper-alloy touch surfaces). Antimicrobial copper alloy products are now being installed in healthcare facilities in the U.K., Ireland, Japan, Korea, France, Denmark, and Brazil and in the subway transit system in Santiago, Chile, where copper-zinc alloy handrails will be installed in some 30 stations between 2011 and 2014.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Copper alloy surfaces", "_id": "68--1--7---1", "title": "Antimicrobial Copper Alloys"}
{"qas": [{"question": "How does thyme essential oils work?", "answer": ""}, {"question": "What phenolic chemical is found in thyme?", "answer": "Thymol", "ae_score": -0.21880323934351306, "qg_score": null}, {"question": "What phenolic chemical is found in thyme?", "answer": "Thymol", "ae_score": -0.21880323934351306, "qg_score": null}], "content": "Thymol, a phenolic chemical found in thyme, can be as effective as bleach in terms of disinfecting as both are considered an intermediate level disinfectant. Thyme essential oils have bacteriostatic activity against a variety of microorganisms, including ''E. coli'' and ''S. aureus''.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Types", "sub_heading": "Thymol-based disinfectant", "_id": "68--1--8---1", "title": "Thymol, a phenolic chemical found in thyme essential oils can"}
{"qas": [{"question": "How do they determine the percentage of disinfectant in a disinfectant?", "answer": ""}, {"question": "What is an alternative way to measure the minimum inhibitory concentrations of disinfectants against selected?", "answer": "microbroth dilution testing", "ae_score": -0.21297542718444826, "qg_score": null}, {"question": "What is an alternative way to measure the minimum inhibitory concentrations of disinfectants against selected?", "answer": "microbroth dilution testing", "ae_score": -0.21297542718444826, "qg_score": null}], "content": "One way to compare disinfectants is to compare how well they do against a known disinfectant and rate them accordingly. Phenol is the standard, and the corresponding rating system is called the \"Phenol coefficient\". The disinfectant to be tested is compared with phenol on a standard microbe (usually ''Salmonella typhi'' or ''Staphylococcus aureus''). Disinfectants that are more effective than phenol have a coefficient > 1. Those that are less effective have a coefficient < 1.\nThe standard European approach for disinfectant validation consists of a basic suspension test, a quantitative suspension test (with low and high levels of organic material added to act as \u2018interfering substances\u2019) and a two part simulated-use surface test.\nA less specific measurement of effectiveness is the United States Environmental Protection Agency (EPA) classification into either ''high'', ''intermediate'' or ''low'' levels of disinfection. \"High-level disinfection kills all organisms, except high levels of bacterial spores\" and is done with a chemical germicide marketed as a sterilant by the U.S. Food and Drug Administration (FDA). \"Intermediate-level disinfection kills mycobacteria, most viruses, and bacteria with a chemical germicide registered as a 'tuberculocide' by the Environmental Protection Agency. Low-level disinfection kills some viruses and bacteria with a chemical germicide registered as a hospital disinfectant by the EPA.\"\nAn alternative assessment is to measure the Minimum inhibitory concentrations (MICs) of disinfectants against selected (and representative) microbial species, such as through the use of microbroth dilution testing.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Measurements of effectiveness", "sub_heading": "Measurements of effectiveness", "_id": "68--2---1---1", "title": "Disinfectant Validation Using Phenol"}
{"qas": [{"question": "Why does bleach kill 99.9% of germs but alcohol doesn't?", "answer": ""}, {"question": "What is the most cost effective disinfectant?", "answer": "chlorine bleach", "ae_score": -0.2171643673620356, "qg_score": null}, {"question": "What is the most cost effective disinfectant?", "answer": "chlorine bleach", "ae_score": -0.2171643673620356, "qg_score": null}], "content": "By far the most cost-effective home disinfectant is the commonly used chlorine bleach (a 5% solution of sodium hypochlorite), which is effective against most common pathogens, including difficult organisms such as tuberculosis (mycobacterium tuberculosis), hepatitis B and C, fungi, and antibiotic-resistant strains of staphylococcus and enterococcus. It even has some disinfectant action against parasitic organisms.\nPositives are that it kills the widest range of pathogens of any inexpensive disinfectant, is extremely powerful against viruses and bacteria at room temperature, is commonly available and inexpensive, and breaks down quickly into harmless components (primarily table salt and oxygen).\nNegatives are that it is caustic to the skin, lungs, and eyes (especially at higher concentrations); like many common disinfectants, it degrades in the presence of organic substances; it has a strong odor; it is not effective against ''Giardia lamblia'' and ''Cryptosporidium''; and extreme caution must be taken not to combine it with ammonia or any acid (such as vinegar), as this can cause noxious gases to be formed. The best practice is not to add anything to household bleach except water.\nTo use chlorine bleach effectively, the surface or item to be disinfected must be clean. In the bathroom or when cleaning after pets, special caution must be taken to wipe up urine first, before applying chlorine, to avoid reaction with the ammonia in urine, causing toxic gas by-products. A 1-to-20 solution in water is effective simply by being wiped on and left to dry. The user should wear rubber gloves and, in tight airless spaces, goggles. If parasitic organisms are suspected, it should be applied at 1-to-1 concentration, or even undiluted.  Extreme caution must be taken to avoid contact with eyes and mucous membranes. Protective goggles and good ventilation are mandatory when applying concentrated bleach.\nCommercial bleach tends to lose strength over time, whenever the container is opened.  Old containers of partially used bleach may no longer have the labeled concentration.\nWhere one does not want to risk the corrosive effects of bleach, alcohol-based disinfectants are reasonably inexpensive and quite safe. The great drawback to them is their rapid evaporation; sometimes effective disinfection can be obtained only by immersing an object in the alcohol.\nThe use of some antimicrobials such as triclosan, in particular in the uncontrolled home environment, is controversial because it may lead to the germs becoming resistant.  Chlorine bleach and alcohol do not cause resistance because they are so completely lethal, in a very direct physical way.", "page_name": "Disinfectant", "page_id": "Disinfectant", "heading": "Home disinfectants", "sub_heading": "Home disinfectants", "_id": "68--3---1---1", "title": "Home Disinfectants \u2014 A Guide"}
{"qas": [{"question": "Why is there so much overfishing in the world?", "answer": ""}, {"question": "Who is a fisheries scientist known for pioneering work on the human impacts on global fisheries?", "answer": "Daniel Pauly", "ae_score": -0.180206447664422, "qg_score": null}, {"question": "Who is a fisheries scientist known for pioneering work on the human impacts on global fisheries?", "answer": "Daniel Pauly", "ae_score": -0.180206447664422, "qg_score": null}], "content": "Overfishing has significantly affected many fisheries around the world. As much as 85% of the world's fisheries may be over-exploited, depleted, fully exploited or in recovery from exploitation. Significant overfishing has been observed in pre-industrial times. In particular, the overfishing of the western Atlantic Ocean from the earliest days of European colonisation of the Americas has been well documented. Following World War Two, industrial fishing rapidly expanded with rapid increases in worldwide fishing catches. However, many fisheries have either collapsed or degraded to a point where increased catches are no longer possible.\nDaniel Pauly, a fisheries scientist known for pioneering work on the human impacts on global fisheries, has commented:", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Global overfishing", "sub_heading": "Global overfishing", "_id": "69--0---1---1", "title": "Overfishing is affecting fisheries around the world."}
{"qas": [{"question": "How did the United States manage to manage its own fisheries?", "answer": ""}, {"question": "The relationship between ownership or stewardship and sustainability is known as what?", "answer": "the tragedy of the commons", "ae_score": -0.532630794988141, "qg_score": null}, {"question": "The relationship between ownership or stewardship and sustainability is known as what?", "answer": "the tragedy of the commons", "ae_score": -0.532630794988141, "qg_score": null}], "content": "Examples of overfishing exist in areas such as the North Sea, the Grand Banks of Newfoundland and the East China Sea. In these locations, overfishing has not only proved disastrous to fish stocks but also to the fishing communities relying on the harvest. Like other extractive industries such as forestry and hunting, fisheries are susceptible to economic interaction between ownership or stewardship and sustainability, otherwise known as the tragedy of the commons.\nSeveral countries are now effectively managing their fisheries. Examples include Iceland and New Zealand. The United States has turned many of its fisheries around from being in a highly depleted state.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Examples of overfishing", "sub_heading": "Examples of overfishing", "_id": "69--1---1---1", "title": "The tragedy of the commons"}
{"qas": [{"question": "Why are there so many jellyfish in the world?", "answer": ""}, {"question": "How much money are the world's fishing fleets losing each year?", "answer": "US$50 billion", "ae_score": -0.45608510885805054, "qg_score": null}, {"question": "How much money are the world's fishing fleets losing each year?", "answer": "US$50 billion", "ae_score": -0.45608510885805054, "qg_score": null}], "content": "According to a 2008 UN report, the world's fishing fleets are losing US$50 billion each year through depleted stocks and poor fisheries management. The report, produced jointly by the World Bank and the UN Food and Agriculture Organization (FAO), asserts that half the world's fishing fleet could be scrapped with no change in catch. In addition, the biomass of global fish stocks have been allowed to run down to the point where it is no longer possible to catch the amount of fish that could be caught. Increased incidence of schistosomiasis in Africa has been linked to declines of fish species that eat the snails carrying the disease-causing parasites.  Massive growth of jellyfish populations threaten fish stocks, as they compete with fish for food, eat fish eggs, and poison or swarm fish, and can survive in oxygen depleted environments where fish cannot; they wreak massive havoc on commercial fisheries.  Overfishing eliminates a major jellyfish competitor and predator exacerbating the jellyfish population explosion. Both climate change and a restructuring of the ecosystem have been found to be major roles in an increase in jellyfish population in the Irish Sea in the 1990's.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Consequences", "sub_heading": "Consequences", "_id": "69--2---1---1", "title": "The Jellyfish Population Explosion in the Irish Sea"}
{"qas": [{"question": "How does overfishing work?", "answer": ""}, {"question": "What are the three types of overfishing?", "answer": "growth overfishing", "ae_score": -0.3172275856262389, "qg_score": null}, {"question": "What are the three types of overfishing?", "answer": "growth overfishing", "ae_score": -0.3172275856262389, "qg_score": null}], "content": "There are three recognized types of biological overfishing: growth overfishing, recruit overfishing and ecosystem overfishing.\nGrowth overfishing occurs when fish are harvested at an average size that is smaller than the size that would produce the maximum yield per recruit. A recruit is an individual that makes it to maturity, or into the limits specified by a fishery, which are usually size or age. This makes the total yield less than it would be if the fish were allowed to grow to an appropriate size. It can be countered by reducing fishing mortality to lower levels and increasing the average size of harvested fish to a size that will allow maximum yield per recruit.\nRecruitment overfishing occurs when the mature adult (spawning biomass) population is depleted to a level where it no longer has the reproductive capacity to replenish itselfthere are not enough adults to produce offspring. Increasing the spawning stock biomass to a target level is the approach taken by managers to restore an overfished population to sustainable levels. This is generally accomplished by placing moratoriums, quotas and minimum size limits on a fish population.\nEcosystem overfishing occurs when the balance of the ecosystem is altered by overfishing. With declines in the abundance of large predatory species, the abundance of small forage type increases causing a shift in the balance of the ecosystem towards smaller fish species.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Types", "sub_heading": "Types", "_id": "69--3---1---1", "title": "The Three Types of Biochemical Overfishing"}
{"qas": [{"question": "How do they predict how much fish are in a certain area of the world?", "answer": ""}, {"question": "What is assumed to be necessary to attain the maximum catch?", "answer": "Technical efficiency", "ae_score": -0.19885773805060575, "qg_score": null}, {"question": "What is assumed to be necessary to attain the maximum catch?", "answer": "Technical efficiency", "ae_score": -0.19885773805060575, "qg_score": null}], "content": "The notion of overfishing hinges on what is meant by an '''acceptable level''' of fishing.  More precise biological and bioeconomic terms define acceptable level as follows:\nA model proposed in 2010 for predicting acceptable levels of fishing is the Harvest Control Rule (HCR), which is a set of tools and protocols with which management has some direct control of harvest rates and strategies in relation to predicting stock status, and long-term maximum sustainable yields. Constant catch and constant fishing mortality are two types of simple harvest control rules.\nFishing capacity can also be defined using an input or output orientation.\nTechnical efficiency of each vessel of the fleet is assumed necessary to attain this maximum catch. The degree of capacity utilization results from the comparison of the actual level of output (input) and the capacity output (input) of a vessel or a fleet.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Acceptable levels", "sub_heading": "Acceptable levels", "_id": "69--4---1---1", "title": "Overfishing | Acceptable levels"}
{"qas": [{"question": "Why can't we create a marine protected area for fish?", "answer": ""}, {"question": "When did a large-scale study of fisheries use itqs?", "answer": "2008", "ae_score": -0.402162888726614, "qg_score": null}, {"question": "When did a large-scale study of fisheries use itqs?", "answer": "2008", "ae_score": -0.402162888726614, "qg_score": null}], "content": "Many regulatory measures are available for controlling overfishing. These measures include fishing quotas, bag limits, licensing, closed seasons, size limits and the creation of marine reserves and other marine protected areas.\nA model of the interaction between fish and fishers showed that when an area is closed to fishers, but there are no catch regulations such as individual transferable quotas, fish catches are temporarily increased but overall fish biomass is reduced, resulting in the opposite outcome from the one desired for fisheries. Thus, a displacement of the fleet from one locality to another will generally have little effect if the same quota is taken. As a result, management measures such as temporary closures or establishing a marine protected area of fishing areas are ineffective when not combined with individual fishing quotas. An inherent problem with quotas is that fish populations vary from year to year. A study has found that fish populations rise dramatically after stormy years due to more nutrients reaching the surface and therefore greater primary production. To fish sustainably, quotas need to be changed each year to account for fish population.\nIndividual transferable quotas (ITQs) are fishery rationalization instruments defined under the Magnuson-Stevens Fishery Conservation and Management Act as limited access permits to harvest quantities of fish. Fisheries scientists decide the optimal amount of fish (total allowable catch) to be harvested in a certain fishery. The decision considers carrying capacity, regeneration rates and future values. Under ITQs, members of a fishery are granted rights to a percentage of the total allowable catch that can be harvested each year.  These quotas can be fished, bought, sold, or leased allowing for the least cost vessels to be used. ITQs are used in New Zealand, Australia, Iceland, Canada, and the United States. Only three ITQ programs have been implemented in the United States due to a moratorium supported by Ted Stevens.\nIn 2008, a large-scale study of fisheries that used ITQs compared to ones that didn't provided strong evidence that ITQs can help to prevent collapses and restore fisheries that appear to be in decline.\nChina bans fishing in the South China Sea for a period each year.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Mitigation", "_id": "69--5--0---1", "title": "Fishing quotas and quotas in the South China Sea"}
{"qas": [{"question": "How do deep sea fishing companies make money?", "answer": ""}, {"question": "How much money would global deep-sea fisheries lose each year?", "answer": "$50 million", "ae_score": -0.37107325878883746, "qg_score": null}, {"question": "How much money would global deep-sea fisheries lose each year?", "answer": "$50 million", "ae_score": -0.37107325878883746, "qg_score": null}], "content": "Several scientists have called for an end to subsidies paid to deep sea fisheries. In international waters beyond the 200 nautical mile exclusive economic zones of coastal countries, many fisheries are unregulated, and fishing fleets plunder the depths with state-of-the-art technology. In a few hours, massive nets weighing up to 15 tons,  dragged along the bottom by deep-water trawlers, can destroy deep-sea corals and sponge beds that have taken centuries or millennia to grow. The trawlers can target orange roughy, grenadiers, or sharks. These fish are usually long-lived and late maturing, and their populations take decades, even centuries to recover.\nFisheries scientist Daniel Pauly and economist Ussif Rashid Sumaila have examined subsidies paid to bottom trawl fleets around the world. They found that US$152 million per year are paid to deep-sea fisheries. Without these subsidies, global deep-sea fisheries would operate at a loss of $50 million a year. A great deal of the subsidies paid to deep-sea trawlers is to subsidize the large amount of fuel required to travel beyond the 200-mile limit and drag weighted nets.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Removal of subsidies", "_id": "69--5--1---1", "title": "Deep-Sea Fisheries Subsidies Should End"}
{"qas": [{"question": "How does fishing work?", "answer": ""}, {"question": "What can sea turtles and other megafauna escape from shrimp trawls?", "answer": "turtle excluder device", "ae_score": -0.6168072020555887, "qg_score": null}, {"question": "What can sea turtles and other megafauna escape from shrimp trawls?", "answer": "turtle excluder device", "ae_score": -0.6168072020555887, "qg_score": null}], "content": "Fishing techniques may be altered to minimize bycatch and reduce impacts on marine habitats. These techniques include using varied gear types depending on target species and habitat type. For example, a net with larger holes will allow undersized fish to avoid capture. A turtle excluder device (TED) allows sea turtles and other megafauna to escape from shrimp trawls. Avoiding fishing in spawning grounds may allow fish stocks to rebuild by giving adults a chance to reproduce.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Minimizing fishing impact", "_id": "69--5--2---1", "title": "Fishing Techniques to Reduce bycatch and Impact on Marine Habitats"}
{"qas": [{"question": "How can fish be bred in captivity?", "answer": ""}, {"question": "When did the rate of wild capture plateau?", "answer": "1990s", "ae_score": -0.39336396409156893, "qg_score": null}, {"question": "When did the rate of wild capture plateau?", "answer": "1990s", "ae_score": -0.39336396409156893, "qg_score": null}], "content": "Aquaculture involves the farming of fish in captivity. This approach effectively privatizes fish stocks and creates incentives for farmers to conserve their stocks. It also reduces environmental impact. However, farming carnivorous fish, such as salmon, does not always reduce pressure on wild fisheries, since carnivorous farmed fish are usually fed fishmeal and fish oil extracted from wild forage fish.\nAquaculture played a minor role in the harvesting of marine organisms until the 1970s. Growth in aquaculture increased rapidly in 1990s when the rate of wild capture plateaued. Aquaculture now provides approximately half of all harvested aquatic organisms. Aquaculture production rates continue to grow while wild harvest remains steady.\nFish farming can enclose the entire breeding cycle of the fish, with fish being bred in captivity. Some fish prove difficult to breed in captivity and can be caught in the wild as juveniles and brought into captivity to increase their weight. With scientific progress more species are being made to breed in captivity.  This was the case with southern bluefin tuna, which were first bred in captivity in 2009.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Aquaculture", "_id": "69--5--3---1", "title": "Aquaculture \u2014 The Future of Captivity Fish"}
{"qas": [{"question": "What is the seafood industry and how does it work?", "answer": ""}, {"question": "What is the name of the website launched by google and oceana in 2016?", "answer": "Global Fishing Watch", "ae_score": -0.07238401229011822, "qg_score": null}, {"question": "What is the name of the website launched by google and oceana in 2016?", "answer": "Global Fishing Watch", "ae_score": -0.07238401229011822, "qg_score": null}], "content": "Sustainable seafood is a movement that has gained momentum as more people become aware of overfishing and environmentally destructive fishing methods. Sustainable seafood is seafood from either fished or farmed sources that can maintain or increase production in the future without jeopardizing the ecosystems from which it was acquired. In general, slow-growing fish that reproduce late in life, such as orange roughy, are vulnerable to overfishing.  Seafood species that grow quickly and breed young, such as anchovies and sardines, are much more resistant to overfishing. Several organizations, including the Marine Stewardship Council (MSC), and Friend of the Sea, certify seafood fisheries as sustainable.\nThe Marine Stewardship Council has developed an environmental standard for sustainable and well-managed fisheries. Environmentally responsible fisheries management and practices are rewarded with the use of its blue product ecolabel. Consumers concerned about overfishing and its consequences are increasingly able to choose seafood products that have been independently assessed against the MSC's environmental standard. This enables consumers to play a part in reversing the decline of fish stocks. As of February 2012, over 100 fisheries around the world have been independently assessed and certified as meeting the MSC standard. Their where-to-buy page lists the currently available certified seafood. As of February 2012 over 13,000 MSC-labelled products are available in 74 countries around the world. Fish & Kids is an MSC project to teach schoolchildren about marine environmental issues, including overfishing.\nThe Monterey Bay Aquarium's Seafood Watch Program, although not an official certifying body like the MSC, also provides guidance on the sustainability of certain fish species. Some seafood restaurants have begun to offer more sustainable seafood options. The Seafood Choices Alliance is an organization whose members include chefs that serve sustainable seafood at their establishments. In the US, the Sustainable Fisheries Act defines sustainable practices through national standards. Although there is no official certifying body like the MSC, the National Oceanic and Atmospheric Administration has created FishWatch to help guide concerned consumers to sustainable seafood choices. See also a guide to good fish guides.\nIn September 2016, a partnership of Google and Oceana and Skytruth introduced Global Fishing Watch, a website designed to assist citizens of the globe in monitoring fishing activities.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Consumer awareness", "_id": "69--5--4---1", "title": "Sustainable Seafood: A Movement to Reverse Overfishing"}
{"qas": [{"question": "How does the fishing industry benefit from overfishing?", "answer": ""}, {"question": "Improving awareness of what can improve compliance?", "answer": "regulations", "ae_score": -1.1218345823219944, "qg_score": null}, {"question": "Improving awareness of what can improve compliance?", "answer": "regulations", "ae_score": -1.1218345823219944, "qg_score": null}], "content": "Creating awareness of overfishing and effective measures can be effective in fisheries management. Improving awareness of regulations can improve compliance. Also, creating public awareness of environmental impacts of fishing can lead to fishermen voluntarily engaging in practices such as catch and release.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Mitigation", "sub_heading": "Awareness in the fishing community", "_id": "69--5--5---1", "title": "Creating awareness of overfishing and effective measures can be effective in fisheries management."}
{"qas": [{"question": "How is the fishing capacity problem related to the conservation of fish stocks?", "answer": ""}, {"question": "What is difficult to control outside of the exclusive economic zones?", "answer": "fishing", "ae_score": -0.6029557509861768, "qg_score": null}, {"question": "What is difficult to control outside of the exclusive economic zones?", "answer": "fishing", "ae_score": -0.6029557509861768, "qg_score": null}], "content": "The fishing industry has a strong financial incentive to oppose some measures aimed at improving the sustainability of fish stocks. Recreational fisherman also have an interest in maintaining access to fish stocks. This leads to extensive lobbying that can block or water down government policies intended to prevent overfishing.\nOutside of countries' exclusive economic zones, fishing is difficult to control. Large oceangoing fishing boats are free to exploit fish stocks at will.\nIn waters that are the subject of territorial disputes, countries may actively encourage overfishing. A notable example is the cod wars where Britain used its navy to protect its trawlers fishing in Iceland's exclusive economic zone. Fish are highly transitory. Many species will freely move through different jurisdictions. The conservation efforts of one country can then be exploited by another.\nWhile governments can create regulations to control people's behaviours this can be undermined by illegal fishing activity. Estimates of the size of the illegal catch range from 11 to 26 million tonnes, which represents 14-33% of the world's reported catch. Illegal fishing can take many forms. In some developing countries, large numbers of poor people are dependent on fishing. It can prove difficult to regulate this kind of overfishing, especially for weak governments. Even in regulated environments, illegal fishing may occur. While industrial fishing is often effectively controlled, smaller scale and recreational fishermen can often break regulations such as bag limits and seasonal closures. Fisherman can also easily fish illegally by doing things such as underreporting the amount of fish they caught or reporting that they caught one type of fish while actually catching another. There is also a large problem with surveillance of illegal fishing activity. In 2001, the UN Food and Agriculture Organization (FAO), passed the International Plan of Action to Prevent, Deter and Eliminate Illegal, Unreported and Unregulated Fishing (IPOA-IUU). This is an agreement with the intention to stop port states from allowing boats to dock that participated in illegal, unreported or unregulated fishing. It also gives details for port states on effective measures of inspecting and reporting illegal fishing. Some illegal fishing takes place on an industrial scale with financed commercial operations.\nThe fishing capacity problem is not only related to the conservation of fish stocks but also to the sustainability of fishing activity. Causes of the fishing problem can be found in the property rights regime of fishing resources. Overexploitation and rent dissipation of fishermen arise in open-access fisheries as was shown in Gordon.\nIn open-access resources like fish stocks, in the absence of a system like individual transferable quotas, the impossibility of excluding others provokes the fishermen who want to increase catch to do so effectively by taking someone else' share, intensifying competition. This tragedy of the commons provokes a capitalization process that leads them to increase their costs until they are equal to their revenue, dissipating their rent completely.", "page_name": "Overfishing", "page_id": "Overfishing", "heading": "Barriers to effective fishery management", "sub_heading": "Barriers to effective fishery management", "_id": "69--6---1---1", "title": "The Fishing Capacity Problem"}
{"qas": [{"question": "What is the difference between perspective taking and empathy?", "answer": ""}, {"question": "What field of study studies the theory of mind?", "answer": "social neuroscience", "ae_score": -0.37077948341685896, "qg_score": null}, {"question": "A person who has a theory of mind is an example of?", "answer": "mind development", "ae_score": null, "qg_score": null}], "content": "Theory of mind is a theory insofar as the mind is not directly observable. The presumption that others have a mind is termed a theory of mind because each human can only intuit the existence of their own mind through introspection, and no one has direct access to the mind of another. It is typically assumed that others have minds by analogy with one's own, and this assumption is based on the reciprocal, social interaction, as observed in joint attention, the functional use of language, and the understanding of others' emotions and actions. Having a theory of mind allows one to attribute thoughts, desires, and intentions to others, to predict or explain their actions, and to posit their intentions. As originally defined, it enables one to understand that mental states can be the cause of\u2014and thus be used to explain and predict\u2014the behavior of others. Being able to attribute mental states to others and understanding them as causes of behavior implies, in part, that one must be able to conceive of the mind as a \"generator of representations\". If a person does not have a complete theory of mind it may be a sign of cognitive or developmental impairment.\nTheory of mind appears to be an innate potential ability in primates including humans, that requires social and other experience over many years for its full development. Different people may develop more, or less, effective theories of mind. Empathy is a related concept, meaning the recognition and understanding of the states of mind of others, including their beliefs, desires and particularly emotions.  This is often characterized as the ability to \"put oneself into another's shoes\". Recent neuro ethological studies of animal behaviour suggest that even rodents may exhibit ethical or empathetic abilities. Neo-Piagetian theories of cognitive development maintain that theory of mind is a byproduct of a broader hypercognitive ability of the human mind to register, monitor, and represent its own functioning.\nResearch on theory of mind, in humans and animals, adults and children, normally and atypically developing, has grown rapidly in the 35 years since Premack and Guy Woodruff's paper, \"Does the chimpanzee have a theory of mind?\". The emerging field of social neuroscience has also begun to address this debate, by imaging the brains of humans while they perform tasks demanding the understanding of an intention, belief or other mental state in others.\nAn alternative account of theory of mind is given within operant psychology and provides significant empirical evidence for a functional account of both perspective taking and empathy. The most developed operant approach is founded on research on derived relational responding and is subsumed within what is called, \"Relational Frame Theory\". According to this view, empathy and perspective taking comprise a complex set of derived relational abilities based on learning to discriminate and respond  verbally to ever more complex relations between self, others, place, and time, and through established relations.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Definition", "sub_heading": "Definition", "_id": "70--0---1---1", "title": "Theory of Mind and Empathy"}
{"qas": [{"question": "Why is it that some people are more \"minded\" than others?", "answer": ""}, {"question": "Who came up with the theory of mind?", "answer": "Daniel Dennett", "ae_score": -0.4800653160589929, "qg_score": null}, {"question": "The theory of mind is related to what?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Contemporary discussions of ToM have their roots in philosophical debate\u2014most broadly, from the time of Descartes' ''Second Meditation'', which set the groundwork for considering the science of the mind. Most prominent recently are two contrasting approaches in the philosophical literature, to theory of mind: '''theory-theory''' and '''simulation theory'''. The theory-theorist imagines a veritable theory\u2014\"folk psychology\"\u2014used to reason about others' minds. The theory is developed automatically and innately, though instantiated through social interactions.  It is also closely related to  person perception and  attribution theory from social psychology.\nThe intuitive assumption that others are minded is an apparent tendency we all share. We anthropomorphize non-human animals, inanimate objects, and even natural phenomena. Daniel Dennett referred to this tendency as taking an \"intentional stance\" toward things: we assume they have intentions, to help predict future behavior. However, there is an important distinction between taking an \"intentional stance\" toward something and entering a \"shared world\" with it. The intentional stance is a detached and functional theory we resort to during interpersonal interactions. A shared world is directly perceived and its existence structures reality itself for the perceiver. It is not just automatically applied to perception; it in many ways constitutes perception.\nThe philosophical roots of the Relational Frame Theory (RFT) account of ToM arise from contextual psychology and refer to the study of organisms (both human and non-human) interacting in and with a historical and current situational context. It is an approach based on contextualism, a philosophy in which any event is interpreted as an ongoing act inseparable from its current and historical context and in which a radically functional approach to truth and meaning is adopted. As a variant of contextualism, RFT focuses on the construction of practical, scientific knowledge. This scientific form of contextual psychology is virtually synonymous with the philosophy of operant psychology.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Philosophical and psychological roots", "sub_heading": "Philosophical and psychological roots", "_id": "70--1---1---1", "title": "Relational Frame Theory: The Philosophy of Mind"}
{"qas": [{"question": "Why do some people think the world is flat while others think it is flat?", "answer": ""}, {"question": "The development of theory of mind is closely related to what?", "answer": "language development", "ae_score": -0.6070757467306459, "qg_score": null}, {"question": "The ability to distinguish a whole sentence from its embedded complement is related to what theory of?", "answer": "mind development", "ae_score": null, "qg_score": null}], "content": "There is evidence to believe that the development of theory of mind is closely intertwined with language development in humans. One meta-analysis (Milligan, Astington, & Dack, 2007) showed a moderate to strong correlation (''r'' = 0.43) between performance on theory of mind and language tasks. One might argue that this relationship is due solely to the fact that both language and theory of mind seem to begin to develop substantially around the same time in children (between ages 2\u20135). However, many other abilities develop during this same time period as well, and do not produce such high correlations with one another nor with theory of mind. There must be something else going on to explain the relationship between theory of mind and language.\nMiller (2006) posed a few possible explanations for this relationship. One idea was that the extent of verbal communication and conversation involving children in a family could explain theory of mind development. The belief is that this type of language exposure could help introduce a child to the different mental states and perspectives of others. This has been suggested empirically by findings indicating that participation in family discussion predict scores on theory of mind tasks (Ruffman, Slade, & Crowe, 2002), as well as findings showing that deaf children who have hearing parents and may not be able to communicate with their parents much during early years of development tend to score lower on theory of mind tasks (Wolfe, Want, & Siegal, 2002).\nAnother explanation of the relationship between language and theory of mind development has to do with a child\u2019s understanding of mental state words such as \"''think''\" and \"''believe''.\" Since a mental state is not something that one can observe from behavior, children must learn the meanings of words denoting mental states from verbal explanations alone, requiring knowledge of the syntactic rules, semantic systems, and pragmatics of a language (Miller, 2006). Studies have shown that understanding of these mental state words predicts theory of mind in four-year-olds (Moore, Pure, & Furrow, 1990).\nLastly, a third hypothesis is that the ability to distinguish a whole sentence (\"Jimmy thinks the world is flat\") from its embedded complement (\"the world is flat\") and understand that one can be true while the other can be false is related to a theory of mind development. Recognizing these sentential complements as being independent of one another is a relatively complex syntactic skill and has been shown to be related to increased scores on theory of mind tasks in children (de Villiers & Pyers, 2002).", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Development", "sub_heading": "Development", "_id": "70--2--0---1", "title": "Theory of Mind vs. Language Development"}
{"qas": [{"question": "Why is it that as an adult, I have a hard time believing things that I've heard in my entire life, but as I get older, I'm able to believe things I've never heard before?", "answer": ""}, {"question": "What percentage of children diagnosed with autism were unable to pass the theory of mind test?", "answer": "80%", "ae_score": -0.2046851351529262, "qg_score": null}, {"question": "The tendency to see events as being more predictable is an example of?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "One of the most important milestones in theory of mind development is gaining the ability to attribute ''false belief'': that is, to recognize that others can have beliefs about the world that are diverging. To do this, it is suggested, one must understand how knowledge is formed, that people's beliefs are based on their knowledge, that mental states can differ from reality, and that people\u2019s behavior can be predicted by their mental states.  Numerous versions of the false-belief task have been developed, based on the initial task done by Wimmer and Perner (1983).\nIn the most common version of the false-belief task (often called the \"'Sally-Anne' test\" or \"'Sally-Anne' task\"), children are told or shown a story involving two characters. For example, the child is shown two dolls, Sally and Anne, who have a basket and a box, respectively. Sally also has a marble, which she places into her basket, and then leaves the room. While she is out of the room, Anne takes the marble from the basket and puts it into the box. Sally returns, and the child is then asked where Sally will look for the marble. The child passes the task if she answers that Sally will look in the basket, where Sally put the marble; the child fails the task if she answers that Sally will look in the box, where the child knows the marble is hidden, even though Sally cannot know this, since she did not see it hidden there. To pass the task, the child must be able to understand that another\u2019s mental representation of the situation is different from their own, and the child must be able to predict behavior based on that understanding.\nAnother example is when a boy leaves chocolate on a shelf and then leaves the room. His mother puts it in the fridge. To pass the task, the child must understand that the boy upon returning holds the false belief that his chocolate is still on the shelf.\nThe results of research using false-belief tasks have been fairly consistent: most normally developing children are able to pass the tasks from around age four.  Notably, while most children, including those with Down syndrome, are able to pass this test, in one study, 80% of children diagnosed with autism were ''unable'' to do so.\nAlso adults can experience problems with false beliefs, for instance when they show hindsight bias, defined as: \"the inclination to see events that have already happened as being more predictable than they were before they took place.\" For instance, in an experiment by Fischhoff in 1975, adult subjects who were asked for an independent assessment were unable to disregard information on actual outcome. Also in experiments with complicated situations, when assessing others' thinking, adults can be unable to disregard certain information that they have been given.<ref name = Mitchell/>", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Empirical investigation", "sub_heading": "Empirical investigation", "_id": "70--3--0---1", "title": "The False Belief Task"}
{"qas": [{"question": "How do false-belief tests work?", "answer": ""}, {"question": "According to the theory of mind, what did the candy in the box contain?", "answer": "pencils", "ae_score": -0.6890483695601436, "qg_score": null}, {"question": "The ability of a child to guess the contents of a candy is called?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "Other tasks have been developed to try to solve the problems inherent in the false-belief task. In the \"Unexpected contents\", or \"Smarties\" task, experimenters ask children what they believe to be the contents of a box that looks as though it holds a candy called \"Smarties\". After the child guesses (usually) \"Smarties\", it is shown that the box in fact contained pencils. The experimenter then re-closes the box and asks the child what she thinks another person, who has not been shown the true contents of the box, will think is inside. The child passes the task if he/she responds that another person will think that \"Smarties\" exist in the box, but fails the task if she responds that another person will think that the box contains pencils. Gopnik & Astington (1988) found that children pass this test at age four or five years.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Empirical investigation", "sub_heading": "Unexpected contents", "_id": "70--3--1---1", "title": "The False Belief Test"}
{"qas": [{"question": "Why is it so difficult for animals to understand and perform theory of mind?", "answer": ""}, {"question": "What type of camera is used in the location-change task?", "answer": "Polaroid", "ae_score": null, "qg_score": null}, {"question": "The theory of mind is used in the treatment of?", "answer": "mind autism", "ae_score": null, "qg_score": null}], "content": "The \"false-photograph\" task is another task that serves as a measure of theory of mind development. In this task, children must reason about what is represented in a photograph that differs from the current state of affairs.  Within the false-photograph task, either a location or identity change exists. In the location-change task, the examiner puts an object in one location (''e.g.'', chocolate in an open green cupboard), whereupon the child takes a Polaroid photograph of the scene.  While the photograph is developing, the examiner moves the object to a different location (''e.g.'', a blue cupboard), allowing the child to view the examiner's action.  The examiner asks the child two control questions: \"When we first took the picture, where was the object?\" and \"Where is the object now?\".  The subject is also asked a \"false-photograph\" question: \"Where is the object in the picture?\" The child passes the task if he/she correctly identifies the location of the object in the picture and the actual location of the object at the time of the question. However, the last question might be misinterpreted as: \"Where in this room is the object that the picture depicts?\" and therefore some examiners use an alternative phrasing.\nTo make it easier for animals, young children, and individuals with classical (Kanner-type) autism to understand and perform theory-of-mind tasks, researchers have developed tests in which verbal communication is de-emphasized:  some whose administration does not involve verbal communication on the part of the examiner, some whose successful completion does not require verbal communication on the part of the subject, and some that meet both of the foregoing standards.  One category of tasks uses a preferential looking paradigm, with looking time as the dependent variable. For instance, 9-month-old infants prefer looking at behaviors performed by a human hand over those made by an inanimate hand-like object. Other paradigms look at rates of imitative behavior, the ability to replicate and complete unfinished goal-directed acts, and rates of pretend play.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Empirical investigation", "sub_heading": "Other tasks", "_id": "70--3--2---1", "title": "Theory-of-Mind Tests for Autism"}
{"qas": [{"question": "Why do some people look longer than others?", "answer": ""}, {"question": "The theory of mind of an infant is affected by?", "answer": "violation of expectation procedure", "ae_score": -0.7400223171256469, "qg_score": null}, {"question": "According to the theory of mind, what is the most important part of a person '?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Recent research on the early precursors of theory of mind have looked at innovative ways at capturing prelinguistic infants' understanding of other people's mental states, including perception and beliefs. Using a variety of experimental procedures, studies have shown that infants in their second year of life have an implicit understanding what other people see and what they know. A popular paradigm used to study infants' theory of mind is the violation of expectation procedure, which predicates on infants' tendency to look longer at unexpected and surprising events compared to familiar and expected events. Therefore, their looking times measures would give researchers an indication of what infants might be inferring, or their implicit understanding of events. One recent study using this paradigm found that 16-month-olds tend to attribute beliefs to a person whose visual perception was previously witnessed as being \"reliable\" compared to someone whose visual perception was \"unreliable\". Specifically, 16-month-olds were trained to expect a person's excited vocalization and gaze into a container to be associated with finding a toy in the reliable looker condition or an absence of a toy in the unreliable looker condition. Following this training phase, infants witnessed, in an object-search task, the same person either searching for a toy in the correct or incorrect location after they both witnessed the location of where the toy was hidden. Infants who experienced the reliable looker were surprised and therefore looked longer when the person searched for the toy in the incorrect location compared to the correct location. In contrast, the looking time for infants who experienced the unreliable looker did not differ for either search locations. These findings suggest that 16-month-old infants can differentially attribute beliefs about a toy's location based on the person's prior record of visual perception.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Empirical investigation", "sub_heading": "Early precursors", "_id": "70--3--3---1", "title": "Prelinguistic Infants' Theory of Mind"}
{"qas": [{"question": "Why do people with autism have such a hard time understanding their own thoughts?", "answer": ""}, {"question": "When was the theory of mind first used?", "answer": "1985", "ae_score": -0.36987842973777457, "qg_score": null}, {"question": "A person with autism is born with a set of skills that later lets them comprehend and?", "answer": "mind development", "ae_score": null, "qg_score": null}], "content": "In 1985 Simon Baron-Cohen, Alan M. Leslie and Uta Frith suggested that children with autism do not employ a theory of mind, and suggested that children with autism have particular difficulties with tasks requiring the child to understand another person's beliefs. These difficulties persist when children are matched for verbal skills and have been taken as a key feature of autism.\nMany individuals classified as having autism have severe difficulty assigning mental states to others, and they seem to lack theory of mind capabilities. Researchers who study the relationship between autism and theory of mind attempt to explain the connection in a variety of ways. One account assumes that theory of mind plays a role in the attribution of mental states to others and in childhood pretend play. According to Leslie,<ref name=Leslie/> theory of mind is the capacity to mentally represent thoughts, beliefs, and desires, regardless of whether or not the circumstances involved are real. This might explain why individuals with autism show extreme deficits in both theory of mind and pretend play. However, Hobson proposes a social-affective justification, which suggests that a person with autism deficits in theory of mind result from a distortion in understanding and responding to emotions.  He suggests that typically developing human beings, unlike individuals with autism, are born with a set of skills (such as social referencing ability) that later lets them comprehend and react to other people\u2019s feelings.  Other scholars emphasize that autism involves a specific developmental delay, so that children with the impairment vary in their deficiencies, because they experience difficulty in different stages of growth. Very early setbacks can alter proper advancement of joint-attention behaviors, which may lead to a failure to form a full theory of mind.\nIt has been speculated that ToM exists on a continuum as opposed to the traditional view of a discrete presence or absence. While some research has suggested that some autistic populations are unable to attribute mental states to others, recent evidence points to the possibility of coping mechanisms that facilitate a spectrum of mindful behavior.Tine et al. suggest that children with autism score substantially lower on measures of social theory of mind in comparison to  children with Asperger syndrome.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Deficits", "sub_heading": "Deficits", "_id": "70--4--0---1", "title": "Autism and the Theory of Mind"}
{"qas": [{"question": "Why is it that schizophrenic patients seem to be more prone to depression than other schizophrenics?", "answer": ""}, {"question": "What type of effects do neuroleptic medications have on schizophrenic patients?", "answer": "neurotoxic", "ae_score": -0.47754863558577676, "qg_score": null}, {"question": "The ability of a person to understand the world is called?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "Individuals with the diagnosis of schizophrenia can show deficits in theory of mind. Mirjam Sprong and colleagues investigated the impairment by examining 29 different studies, with a total of over 1500 participants (All on medications that affect the mind) . This meta-analysis showed significant and stable deficit of theory of mind in people with schizophrenia. They performed poorly on false-belief tasks, which test the ability to understand that others can hold false beliefs about events in the world, and also on intention-inference tasks, which assess the ability to infer a character\u2019s intention from reading a short story. Schizophrenia patients with negative symptoms, such as lack of emotion, motivation, or speech, have the most impairment in theory of mind and are unable to represent the mental states of themselves and of others. Paranoid schizophrenic patients also perform poorly because they have difficulty accurately interpreting others\u2019 intentions. The meta-analysis additionally showed that IQ, gender, and age of the participants does not significantly affect the performance of theory of mind tasks. The circular logic of medications that affect the mind, that produce symptoms of schizophrenia is not questioned.\nCurrent research suggests that impairment in theory of mind negatively affects clinical insight, the patient\u2019s awareness of their mental illness. Insight requires theory of mind\u2014a patient must be able to adopt a third-person perspective and see the self as others do. A patient with good insight would be able to accurately self-represent, by comparing oneself with others and by viewing oneself from the perspective of others. Insight allows a patient to recognize and react appropriately to their symptoms; however, a patient who lacks insight would not realize that he has a mental illness, because of their inability to accurately self-represent. Therapies that teach patients perspective-taking and self-reflection skills can improve abilities in reading social cues and taking the perspective of another person.\nThe majority of the current literature supports the argument that the theory of mind deficit is a stable trait-characteristic rather than a state-characteristic of schizophrenia. The meta-analysis conducted by Sprong et al. showed that patients in remission still had impairment in theory of mind. The results indicate that the deficit is not merely a consequence of the active phase of schizophrenia.\nSchizophrenic patients' deficit in theory of mind impairs their daily interactions with others. An example of a disrupted interaction is one between a schizophrenic parent and a child. Theory of mind is particularly important for parents, who must understand the thoughts and behaviors of their children and react accordingly. Dysfunctional parenting is associated with deficits in the first-order theory of mind, the ability to understand another person's thoughts, and the second-order theory of mind, the ability to infer what one person thinks about another person's thoughts. Compared with healthy mothers, mothers with schizophrenia are found to be more remote, quiet, self-absorbed, insensitive, unresponsive, and to have fewer satisfying interactions with their children. They also tend to misinterpret their children\u2019s emotional cues, and often misunderstand neutral faces as negative. Activities such as role-playing and individual or group-based sessions are effective interventions that help the parents improve on perspective-taking and theory of mind. Although there is a strong association between theory of mind deficit and parental role dysfunction, future studies could strengthen the relationship by possibly establishing a causal role of theory of mind on parenting abilities.\nThe neurotoxic effects of neuroleptic medications on the brain of schizophrenic patients is ignored.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Deficits", "sub_heading": "Schizophrenia", "_id": "70--4--1---1", "title": "The Theory of Mind Deficit in Schizophrenia Patients"}
{"qas": [{"question": "Why do some people get drunk and others don't?", "answer": ""}, {"question": "Which disease has a negative effect on the theory of mind?", "answer": "alcoholism", "ae_score": -0.25605879540188053, "qg_score": null}, {"question": "Which disease has a negative effect on the theory of mind?", "answer": "alcoholism", "ae_score": -0.25605879540188053, "qg_score": null}], "content": "Impairments in theory of mind, as well as other social-cognitive deficits are commonly found in people suffering from alcoholism, due to the neurotoxic effects of alcohol on the brain, particularly the prefrontal cortex.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Deficits", "sub_heading": "Alcohol use disorders", "_id": "70--4--2---1", "title": "Impaired Theory of Mind"}
{"qas": [{"question": "Why do people with depression look so different?", "answer": ""}, {"question": "What is the disorder mdd characterized by?", "answer": "social impairment", "ae_score": -0.642750412542627, "qg_score": null}, {"question": "What is the disorder mdd characterized by?", "answer": "social impairment", "ae_score": -0.642750412542627, "qg_score": null}], "content": "Individuals in a current major depressive episode (MDD), a disorder characterized by social impairment, show deficits in theory of mind decoding. Theory of mind decoding is the ability to use information available in the immediate environment (e.g., facial expression, tone of voice, body posture) to accurately label the mental states of others. The opposite pattern, enhanced theory of mind, is observed in individuals vulnerable to depression, including those individuals with past MDD, dysphoric individuals, and individuals with a maternal history of MDD.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Deficits", "sub_heading": "Depression and dysphoria", "_id": "70--4--3---1", "title": "Deficient Theory of Mind Decoding in Major Depressive Episodes"}
{"qas": [{"question": "How does language development work?", "answer": ""}, {"question": "What is it called when a child has a specific language impairment?", "answer": "SLI", "ae_score": null, "qg_score": null}, {"question": "Language development is related to what theory of mind?", "answer": "mind development", "ae_score": null, "qg_score": null}], "content": "Children diagnosed with specific language impairment (SLI) exhibit much lower scores on reading and writing sections of standardized tests, but have a normal nonverbal IQ.  These language deficits can be any specific deficits in lexical semantics, syntax, or pragmatics, or a combination of multiple problems. A recent meta-analysis found that children with SLI have substantially lower scores on theory of mind tasks compared to typically developing children (Nilsson & Lopez, 2015). This strengthens the claim that language development is related to theory of mind.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Deficits", "sub_heading": "Specific language impairment", "_id": "70--4--4---1", "title": "Language Development in Children with Specific Language Impairment"}
{"qas": [{"question": "Why is it that when we think about something, we tend to think of it as something else?", "answer": ""}, {"question": "What part of the brain is implicated in the perception of intentionality in human action?", "answer": "posterior superior temporal sulcus", "ae_score": -0.9787191771705586, "qg_score": null}, {"question": "The posterior superior temporal sulcus is implicated in the perception of what in action?", "answer": "intentionality", "ae_score": null, "qg_score": null}], "content": "Research on theory of mind in autism led to the view that mentalizing abilities are subserved by dedicated mechanisms that can (in some cases) be impaired while general cognitive function remains largely intact.  Neuroimaging research has supported this view, demonstrating specific brain regions consistently engaged during theory of mind tasks.  Early PET research on theory of mind, using verbal and pictorial story comprehension tasks, identified a set of regions including the medial prefrontal cortex (mPFC), and area around posterior superior temporal sulcus (pSTS), and sometimes precuneus and amygdala/temporopolar cortex.  Subsequently, research on the neural basis of theory of mind has diversified, with separate lines of research focused on the understanding of beliefs, intentions, and more complex properties of minds such as psychological traits.\nStudies from Rebecca Saxe's lab at MIT, using a false belief versus false photograph task contrast aimed to isolate the mentalizing component of the false belief task, have very consistently found activation in mPFC, precuneus, and temporo-parietal junction (TPJ), right-lateralized.  In particular, it has been proposed that the right TPJ (rTPJ) is selectively involved in representing the beliefs of others.  However, some debate exists, as some scientists have noted that the same rTPJ region has been consistently activated during spatial reorienting of visual attention; Jean Decety from the University of Chicago and Jason Mitchell from Harvard have thus proposed that the rTPJ subserves a more general function involved in both false belief understanding and attentional reorienting, rather than a mechanism specialized for social cognition. However, it is possible that the observation of overlapping regions for representing beliefs and attentional reorienting may simply be due to adjacent but distinct neuronal populations that code for each. The resolution of typical fMRI studies may not be good enough to show that distinct/adjacent neuronal populations code for each of these processes. In a study following Decety and Mitchell, Saxe and colleagues used higher-resolution fMRI and showed that the peak of activation for attentional reorienting is approximately 6-10mm above the peak for representing beliefs. Further corroborating that differing populations of neurons may code for each process, they found no similarity in the patterning of fMRI response across space.\nFunctional imaging has also been used to study the detection of mental state information in Heider-Simmel-esque animations of moving geometric shapes, which typical humans automatically perceive as social interactions laden with intention and emotion.  Three studies found remarkably similar patterns of activation during the perception of such animations versus a random or deterministic motion control: mPFC, pSTS, fusiform face area (FFA), and amygdala were selectively engaged during the ToM condition.  Another study presented subjects with an animation of two dots moving with a parameterized degree of intentionality (quantifying the extent to which the dots chased each other), and found that pSTS activation correlated with this parameter.\nA separate body of research has implicated the posterior superior temporal sulcus in the perception of intentionality in human action; this area is also involved in perceiving biological motion, including body, eye, mouth, and point-light display motion. One study found increased pSTS activation while watching a human lift his hand versus having his hand pushed up by a piston (intentional versus unintentional action).  Several studies have found increased pSTS activation when subjects perceive a human action that is incongruent with the action expected from the actor's context and inferred intention: for instance, a human performing a reach-to-grasp motion on empty space next to an object, versus grasping the object; a human shifting eye gaze toward empty space next to a checkerboard target versus shifting gaze toward the target; an unladen human turning on a light with his knee, versus turning on a light with his knee while carrying a pile of books; and a walking human pausing as he passes behind a bookshelf, versus walking at a constant speed.  In these studies, actions in the \"congruent\" case have a straightforward goal, and are easy to explain in terms of the actor's intention; the incongruent actions, on the other hand, require further explanation (why would someone twist empty space next to a gear?), and apparently demand more processing in the STS.  Note that this region is distinct from the temporo-parietal area activated during false belief tasks.<ref name=Saxe4/>  Also note that pSTS activation in most of the above studies was largely right-lateralized, following the general trend in neuroimaging studies of social cognition and perception: also right-lateralized are the TPJ activation during false belief tasks, the STS response to biological motion, and the FFA response to faces.\nNeuropsychological evidence has provided support for neuroimaging results on the neural basis of theory of mind.  Studies with patients suffering from a lesion of the frontal lobes and the temporoparietal junction of the brain (between the temporal lobe and parietal lobe) reported that they have difficulty with some theory of mind tasks.  This shows that theory of mind abilities are associated with specific parts of the human brain. However, the fact that the medial prefrontal cortex and temporoparietal junction are necessary for theory of mind tasks does not imply that these regions are specific to that function.<ref name=DecLamm/>  TPJ and mPFC may subserve more general functions necessary for ToM.\nResearch by Vittorio Gallese, Luciano Fadiga and Giacomo Rizzolatti (reviewed in) has shown that some sensorimotor neurons, which are referred to as mirror neurons, first discovered in the premotor cortex of rhesus monkeys, may be involved in action understanding.  Single-electrode recording revealed that these neurons fired when a monkey performed an action and when the monkey viewed another agent carrying out the same task.  Similarly, fMRI studies with human participants have shown brain regions (assumed to contain mirror neurons) are active when one person sees another person's goal-directed action.  These data have led some authors to suggest that mirror neurons may provide the basis for theory of mind in the brain, and to support simulation theory of mind reading (see above).\nHowever, there is also evidence against the link between mirror neurons and theory of mind.  First, macaque monkeys have mirror neurons but do not seem to have a 'human-like' capacity to understand theory of mind and belief.  Second, fMRI studies of theory of mind typically report activation in the mPFC, temporal poles and TPJ or STS, but these brain areas are not part of the mirror neuron system.  Some investigators, like developmental psychologist Andrew Meltzoff and neuroscientist Jean Decety, believe that mirror neurons merely facilitate learning through imitation and may provide a precursor to the development of ToM.  Others, like philosopher Shaun Gallagher, suggest that mirror-neuron activation, on a number of counts, fails to meet the definition of simulation as proposed by the simulation theory of mindreading.\nThat being said, in a recent paper, Keren Haroush and Ziv Williams outline the case for a group of neurons in the primate brain that uniquely predicted the choice selection of their interacting partner. These neurons, located in the anterior cingulate cortex of rhesus monkeys, were observed using single-unit recording while the monkeys played a variant of the iterative prisoner's dilemma game. By identifying cells that represent the yet unknown intentions of a game partner, this study supports the idea that Theory of Mind may be a fundamental and generalized process, and suggests that anterior cingulate cortex neurons may potentially act to complement the function of mirror neurons during social interchange.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Brain mechanisms", "sub_heading": "Brain mechanisms", "_id": "70--5--0---1", "title": "Theory of Mind in the Human Brain: Evidence for Mirror Neurons"}
{"qas": [{"question": "Why is it that some people with autism are more susceptible to mentalizing than others?", "answer": ""}, {"question": "When was the theory of mind first studied?", "answer": "2011", "ae_score": -0.7184565001264356, "qg_score": null}, {"question": "The theory of mind is used to explain?", "answer": "mind autism", "ae_score": null, "qg_score": null}], "content": "Several neuroimaging studies have looked at the neural basis theory of mind impairment in subjects with Asperger syndrome and high-functioning autism (HFA).  The first PET study of theory of mind in autism (also the first neuroimaging study using a task-induced activation paradigm in autism) employed a story comprehension task, replicating a prior study in normal individuals.  This study found displaced and diminished mPFC activation in subjects with autism.  However, because the study used only six subjects with autism, and because the spatial resolution of PET imaging is relatively poor, these results should be considered preliminary.\nA subsequent fMRI study scanned normally developing adults and adults with HFA while performing a \"reading the mind in the eyes\" task\u2014viewing a photo of a human\u2019s eyes and choosing which of two adjectives better describes the person\u2019s mental state, versus a gender discrimination control.  The authors found activity in orbitofrontal cortex, STS, and amygdala in normal subjects, and found no amygdala activation and abnormal STS activation in subjects with autism.\nA more recent PET study looked at brain activity in individuals with HFA and Asperger syndrome while viewing Heider-Simmel animations (see above) versus a random motion control.  In contrast to normally developing subjects, those with autism showed no STS or FFA activation, and significantly less mPFC and amygdala activation.  Activity in extrastriate regions V3 and LO was identical across the two groups, suggesting intact lower-level visual processing in the subjects with autism.  The study also reported significantly less functional connectivity between STS and V3 in the autism group.  Note, however, that decreased temporal correlation between activity in STS and V3 would be expected simply from the lack of an evoked response in STS to intent-laden animations in subjects with autism; a more informative analysis would be to compute functional connectivity after regressing out evoked responses from all-time series.\nA subsequent study, using the incongruent/congruent gaze shift paradigm described above, found that in high-functioning adults with autism, posterior STS (pSTS) activation was undifferentiated while watching a human shift gaze toward a target and toward adjacent empty space.  The lack of additional STS processing in the incongruent state may suggest that these subjects fail to form an expectation of what the actor should do given contextual information, or that information about the violation of this expectation doesn\u2019t reach STS; both explanations involve an impairment in the ability to link eye gaze shifts with intentional explanations.  This study also found a significant anticorrelation between STS activation in the incongruent-congruent contrast and social subscale score on the Autism Diagnostic Interview-Revised, but not scores on the other subscales.\nIn 2011, an fMRI study demonstrated that right temporoparietal junction (rTPJ) of higher-functioning adults with autism was not selectively activated more for mentalizing judgments when compared to physical judgments about self and other.  rTPJ selectivity for mentalizing was also related to individual variation on clinical measures of social impairment; individuals whose rTPJ was increasingly more active for mentalizing compared to physical judgments were less socially impaired, while those who showed little to no difference in response to mentalizing or physical judgments were the most socially impaired. This evidence builds on work in typical development that suggests rTPJ is critical for representing mental state information, irrespective of whether it is about oneself or others. It also points to an explanation at the neural level for the pervasive mind-blindness difficulties in autism that are evident throughout the lifespan.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Brain mechanisms", "sub_heading": "In autism", "_id": "70--5--1---1", "title": "The Neurological Basis of Mind Impairment in Autism and HFA"}
{"qas": [{"question": "What is the difference between theory of mind and social dysfunction?", "answer": ""}, {"question": "The reduced activity in the mpfc of individuals with schizophrenia is associated with what?", "answer": "theory of mind deficit", "ae_score": -1.2944181796097387, "qg_score": null}, {"question": "The reduced activity in the mpfc of individuals with schizophrenia is associated with what?", "answer": "theory of mind deficit", "ae_score": -1.2944181796097387, "qg_score": null}], "content": "The brain regions associated with theory of mind include the superior temporal gyrus (STS), the temporoparietal junction (TPJ), the medial prefrontal cortex (MPFC), the precuneus, and the amygdala. The reduced activity in the MPFC of individuals with schizophrenia is associated with the theory of mind deficit (not the psychiatric medications) and may explain impairments in social function among people with schizophrenia. Increased neural activity in MPFC is related to better perspective-taking, emotion management, and increased social functioning. Disrupted brain activities ( due to psychiatric medications) in areas related to theory of mind may increase social stress or disinterest in social interaction, and contribute to the social dysfunction of schizophrenia.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Brain mechanisms", "sub_heading": "In schizophrenia", "_id": "70--5--2---1", "title": "The Theory of Mind Deficit in People with Schizophrenia"}
{"qas": [{"question": "What is the difference between group intelligence and individual intelligence?", "answer": ""}, {"question": "What test is used to measure the theory of mind?", "answer": "Reading the Mind in the Eyes test", "ae_score": -0.32994820227798227, "qg_score": null}, {"question": "What test is used to measure the theory of mind?", "answer": "Reading the Mind in the Eyes test", "ae_score": -0.32994820227798227, "qg_score": null}], "content": "Group member average scores of Theory of Mind abilities, measured with the Reading the Mind in the Eyes test (RME), are suggested as driver of successful group performance. In particular, high group average scores on the RME are shown to be correlated with the collective intelligence factor ''c'' defined as a group\u2019s ability to perform a wide range of mental tasks, a group intelligence measure similar to the ''g'' factor for general individual intelligence. RME is a ToM test for adults that shows sufficient test-retest reliability and constantly differentiates control groups from individuals with functional autism or Asperger Syndrome. It is one of the most widely accepted and well-validated tests for ToM abilities within adults.", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Practical validity", "sub_heading": "Practical validity", "_id": "70--6---1---1", "title": "Reading the Mind in the Eyes Test: A Theory of Mind Test for Adults"}
{"qas": [{"question": "What is the difference between theory of mind and mental states?", "answer": ""}, {"question": "Who discovered the theory of mind in primates?", "answer": "Christopher Krupenye", "ae_score": -0.2192173342862496, "qg_score": null}, {"question": "What is the study of the evolution of the theory of mind?", "answer": "mind development", "ae_score": null, "qg_score": null}], "content": "An open question is if other animals besides humans have a genetic endowment and social environment that allows them to acquire a theory of mind in the same way that human children do. This is a contentious issue because of the problem of inferring from animal behavior the existence of thinking, of the existence of a concept of self or self-awareness, or of particular thoughts.  One difficulty with non-human studies of ToM is the lack of sufficient numbers of naturalistic observations, giving insight into what the evolutionary pressures might be on a species' development of theory of mind.\nNon-human research still has a major place in this field, however, and is especially useful in illuminating which nonverbal behaviors signify components of theory of mind, and in pointing to possible stepping points in the evolution of what many claim to be a uniquely human aspect of social cognition. While it is difficult to study human-like theory of mind and mental states in species of whose potential mental states we have an incomplete understanding, researchers can focus on simpler components of more complex capabilities. For example, many researchers focus on animals' understanding of intention, gaze, perspective, or knowledge (or rather, what another being has seen). Call and Tomasello's study that looked at understanding of intention in orangutans, chimpanzees and children showed that all three species understood the difference between accidental and intentional acts. Part of the difficulty in this line of research is that observed phenomena can often be explained as simple stimulus-response learning, as it is in the nature of any theorizers of mind to have to extrapolate internal mental states from observable behavior. Recently, most non-human theory of mind research has focused on monkeys and great apes, who are of most interest in the study of the evolution of human social cognition. Other studies relevant to attributions theory of mind have been conducted using plovers and dogs, and have shown preliminary evidence of understanding attention\u2014one precursor of theory of mind\u2014in others.\nThere has been some controversy over the interpretation of evidence purporting to show theory of mind ability\u2014or inability\u2014in animals. Two examples serve as demonstration: first, Povinelli ''et al.'' (1990) presented chimpanzees with the choice of two experimenters from which to request food: one who had seen where food was hidden, and one who, by virtue of one of a variety of mechanisms (having a bucket or bag over his head; a blindfold over his eyes; or being turned away from the baiting) does not know, and can only guess. They found that the animals failed in most cases to differentially request food from the \"knower\". By contrast, Hare, Call, and Tomasello (2001) found that subordinate chimpanzees were able to use the knowledge state of dominant rival chimpanzees to determine which container of hidden food they approached. William Field and Sue Savage-Rumbaugh have no doubt that bonobos have developed ToM and cite their communications with a well known captive bonobo, Kanzi, as evidence.\nIn 2016 experiment ravens ''Corvus corax'' were shown to take into account visual access of unseen conspecifics. It is suspected that \"ravens can generalize from their own perceptual experience to infer the possibility of being seen\".\nA 2016 study published by evolutionary anthropologist Christopher Krupenye brings new light to the existence of ToM, and particularly false beliefs, in non-human primates. ", "page_name": "Theory of mind", "page_id": "Theory%20of%20mind", "heading": "Non-human", "sub_heading": "Non-human", "_id": "70--7---1---1", "title": "The Evolution of Theory of Mind in Non-Human Animals"}
{"qas": [{"question": "Why are migrant workers more likely to be deported than non-migrant workers?", "answer": ""}, {"question": "What is it called when a worker has travelled far from his home country?", "answer": "Unfree labour", "ae_score": -0.4229516983450059, "qg_score": null}, {"question": "What is it called when a worker has travelled far from his home country?", "answer": "Unfree labour", "ae_score": -0.4229516983450059, "qg_score": null}], "content": "If payment occurs, it may be in one or more of the following forms:\nUnfree labour is often more easily instituted and enforced on migrant workers, who have travelled far from their homelands and who are easily identified because of their physical, ethnic, linguistic, or cultural differences from the general population, since they are unable or unlikely to report their conditions to the authorities.\nAccording to the Marxian economics, under capitalism, workers never keep all of the wealth they create, as some of it goes to the profit of capitalists. By contrast with modern subjective theory of value (as used by neoclassical economists), the wages offered necessarily represent the marginal utility of the labour, and any profit (or loss) is also due to other inputs provided, such as capital, time value of money, or risk.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Payment for unfree labour", "sub_heading": "Payment for unfree labour", "_id": "71--0---1---1", "title": "Unfree labour | Payment for unfree labour"}
{"qas": [{"question": "Why is it illegal for Japanese people to be forced into indentured labor?", "answer": ""}, {"question": "What is the most common form of unfree labour?", "answer": "chattel slavery", "ae_score": -0.17009400468729471, "qg_score": null}, {"question": "What is the most common form of unfree labour?", "answer": "chattel slavery", "ae_score": -0.17009400468729471, "qg_score": null}], "content": "The archetypal and best-known form of unfree labour is chattel slavery, in which individual workers are ''legally'' owned throughout their lives, and may be bought, sold or otherwise exchanged by owners, while never or rarely receiving any personal benefit from their labour. Slavery was common in many ancient societies, including ancient Greece, ancient Rome, ancient Israel, ancient China, classical Arab states, as well as many societies in Africa and the Americas. Being sold into slavery was a common fate of populations conquered in wars. Perhaps the most prominent example of chattel slavery was the enslavement of many millions of black people in Africa, as well as their forced transplantation to the Americas, Asia or Europe where their status as slaves was usually inherited by their descendants.\nThe term ''slavery'' is often applied to situations which do not meet the above definitions, but which are other, closely related forms of unfree labour, such as debt slavery or debt-bondage (although not all repayment of debts through labour constitutes unfree labour). Examples are the Repartimiento system in the Spanish Empire, or the work of Indigenous Australians in northern Australia on sheep or cattle ''stations'' (ranches), from the mid-19th to the mid-20th century. In the latter case, workers were rarely or never paid, and were restricted by regulations and/or police intervention to regions around their places of work.\nIn late 16th century Japan, \"unfree labour\" or slavery was officially banned; but forms of contract and indentured labour persisted alongside the period penal codes' forced labour. Somewhat later, the Edo period penal laws prescribed \"non-free labour\" for the immediate family of executed criminals in Article 17 of the ''Got\u014dke reij\u014d'' (Tokugawa House Laws), but the practice never became common. The 1711 ''Got\u014dke reij\u014d'' was compiled from over 600 statutes promulgated between 1597 and 1696.\nAccording to Kevin Bales, in ''Disposable People: New Slavery in the Global Economy'' (1999), there are now an estimated 27 million slaves in the world.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Forms", "_id": "71--1--0---1", "title": "Slavery in the Age of Unfree Labour"}
{"qas": [{"question": "How do indentured workers work?", "answer": ""}, {"question": "What is another form of free labour?", "answer": "indenture", "ae_score": -0.2108624528176132, "qg_score": null}, {"question": "What is another form of free labour?", "answer": "indenture", "ae_score": -0.2108624528176132, "qg_score": null}], "content": "A more common form in modern society is indenture, or ''bonded labour'', under which workers sign contracts to work for a specific period of time, for which they are paid only with accommodation and sustenance, or these essentials in addition to limited benefits such as cancellation of a debt, or transportation to a desired country.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Indentured and bonded labour", "_id": "71--1--1---1", "title": "Indenture, or ''Bond Labour''"}
{"qas": [{"question": "Why did the Japanese enslave so many people in Java?", "answer": ""}, {"question": "How many australian convicts were sent to australia between 1788 and?", "answer": "More than 165,000", "ae_score": -0.2584113006933635, "qg_score": null}, {"question": "How many australian convicts were sent to australia between 1788 and?", "answer": "More than 165,000", "ae_score": -0.2584113006933635, "qg_score": null}], "content": "Convict or prison labour is another classic form of unfree labour. The forced labour of convicts has often been regarded with lack of sympathy, because of the social stigma attached to people regarded as \"common criminals\". In some countries and historical periods, however, prison labour has been forced upon people who have been victims of prejudice, convicted of political crimes, convicted of \"victimless crimes\", or people who committed theft or related offences because they lacked any other means of subsistence \u2014 categories of people who typically call for compassion according to current ethical ideas.\nThree British colonies in Australia \u2014 New South Wales, Van Diemen's Land (Tasmania) and Western Australia \u2014 provide probably the best examples of the state use of convict labour.  Australia received thousands of convict labourers in the eighteenth and nineteenth centuries who were given sentences for crimes which ranged from what we now consider to be minor misdemeanours to such serious offences as murder, rape and incest.  A considerable number of Irish convicts were sentenced to transportation for 'treason' while fighting for Irish independence from British rule.\nMore than 165,000 convicts were transported to Australian colonies from 1788 to 1868. Most British or Irish convicts who were sentenced to transportation, however, completed their sentences in British jails and were not transported at all.  It is estimated that in the last 50 years more than 50 million people have been sent to Chinese ''laogai'' camps.\nAnother historically significant example of forced labour was that of political prisoners, people from conquered or occupied countries, members of persecuted minorities, and prisoners of war, especially during the 20th century. The best-known example of this are the concentration camp system run by Nazi Germany in Europe during World War II, the ''Gulag'' camps run by the Soviet Union, and the forced labour used by the military of the Empire of Japan, especially during the Pacific War (such as the Burma Railway). Roughly 4,000,000 German POWs were used as \"reparations labour\" by the Allies for several years after the German surrender; this was permitted under the Third Geneva Convention provided they were accorded proper treatment. China's ''Laogai'' (\"labour reform\") system and North Korea's Kwalliso camps are current examples.\nAbout 12 million forced labourers, most of whom were Poles and Soviet citizens ''(Ost-Arbeiter)'', were employed in the German war economy inside Nazi Germany. More than 2000 German companies profited from slave labour during the Nazi era, including Daimler, Deutsche Bank, Siemens, Volkswagen, Hoechst, Dresdner Bank, Krupp, Allianz, BASF, Bayer, BMW, and Degussa.\nIn Asia, according to a joint study of historians featuring Zhifen Ju, Mark Peattie, Toru Kubo, and Mitsuyoshi Himeta, more than 10 million Chinese were mobilized by the Japanese army and enslaved by the K\u014da-in for slave labour in Manchukuo and north China. The U.S. Library of Congress estimates that in Java, between 4 and 10 million ''romusha'' (Japanese: \"manual laborer\") were forced to work by the Japanese military. About 270,000 of these Javanese laborers were sent to other Japanese-held areas in South East Asia. Only 52,000 were repatriated to Java, meaning that there was a death rate of 80%.\nKerja rodi, Heerensteinten, was the term for forced labor in indonesia, during Dutch East Indies colonisation\nThe Khmer Rouge attempted to turn Cambodia into a classless society by depopulating cities and forcing the urban population (\"New People\") into agricultural communes. The entire population was forced to become farmers in labour camps.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Penal labour", "_id": "71--1--2---1", "title": "Convicts and Prisons: A History of Convicts and Prisons"}
{"qas": [{"question": "Why is it illegal to pay for a truck?", "answer": ""}, {"question": "When was the song sixteen tons written?", "answer": "1947", "ae_score": -0.37524547077515363, "qg_score": null}, {"question": "When was the song sixteen tons written?", "answer": "1947", "ae_score": -0.37524547077515363, "qg_score": null}], "content": "A truck system, in the specific sense in which the term is used by labour historians, refers to an unpopular or even exploitative form of payment associated with small, isolated and/or rural communities, in which workers or self-employed small producers are paid in either: goods, a form of payment known as truck wages, or tokens, private currency (\"scrip\") or direct credit, to be used at a '''company store''', owned by their employers. A specific kind of truck system, in which credit advances are made against future work, is known in the U.S. as debt bondage.\nMany scholars have suggested that employers use such systems to exploit workers and/or indebt them. This could occur, for example, if employers were able to pay workers with goods which had a market value below the level of subsistence, or by selling items to workers at inflated prices. Others argue that truck wages, at least in some cases, were a convenient way for isolated communities to operate, when official currency was scarce.\nBy the early 20th century, truck systems were widely seen, in industrialised countries, as exploitative; perhaps the most well-known example of this view was a 1947 U.S. hit song \"Sixteen Tons\". Many countries have Truck Act legislation that outlaws truck systems and requires payment in cash.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Truck system", "_id": "71--1--3---1", "title": "Truck Systems: Exploitative, Exploitative, Exploitative, Exploitative,"}
{"qas": [{"question": "How did the Philippines get away with paying their laborers so little?", "answer": ""}, {"question": "Who did governments impose unpaid labor on?", "answer": "lower social classes", "ae_score": -0.8918817757934072, "qg_score": null}, {"question": "Who did governments impose unpaid labor on?", "answer": "lower social classes", "ae_score": -0.8918817757934072, "qg_score": null}], "content": "Though most closely associated with Medieval Europe, governments throughout human history have imposed regular short stints of unpaid labor upon lower social classes.  These might be annual obligations of a few weeks or something similarly regular that lasted for the laborer's entire working life .  As the system developed in the Philippines and elsewhere, the laborer could pay an appropriate fee and be exempted from the obligation.\nIn '''Vetti-chakiri''' and '''begar''' lower castes have only had obligations or duties to render free services to the upper caste community also called as Vetti or Vetti chakiri.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Corv\u00e9e", "_id": "71--1--4---1", "title": "'''Vetti Chakiri''' and '''Begar"}
{"qas": [{"question": "Why do some countries have a system of civil conscription while others do not?", "answer": ""}, {"question": "Who has the right to refuse military service?", "answer": "conscripts", "ae_score": -0.70445463779741, "qg_score": null}, {"question": "Who has the right to refuse military service?", "answer": "conscripts", "ae_score": -0.70445463779741, "qg_score": null}], "content": "Some countries have mandatory military service. While sometimes paid, conscripts are not free to decline enlistment and draft dodging or desertion are often met with severe punishment. Even in countries which prohibit other forms of unfree labour, conscription is generally justified as being necessary in the national interest.\nSome governments, such as Greece, also have a system of civil conscription.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Forms", "sub_heading": "Conscription", "_id": "71--1--5---1", "title": "Military Conscription in Greece"}
{"qas": [{"question": "What is the difference between trafficking and prostitution?", "answer": ""}, {"question": "What is the term for recruiting, harbouring, obtaining and transportation of a person by?", "answer": "Trafficking", "ae_score": -0.6772528725455201, "qg_score": null}, {"question": "What is the term for recruiting, harbouring, obtaining and transportation of a person by?", "answer": "Trafficking", "ae_score": -0.6772528725455201, "qg_score": null}], "content": "Trafficking is a term to define the recruiting, harbouring, obtaining and transportation of a person by use of force, fraud, or coercion for the purpose of subjecting them to involuntary acts, such as acts related to commercial sexual exploitation (including forced prostitution) or involuntary labour.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "Trafficking", "sub_heading": "Trafficking", "_id": "71--2---1---1", "title": "Trafficking in Humans"}
{"qas": [{"question": "Where does the money come from when it comes to human trafficking?", "answer": ""}, {"question": "How many people worldwide are victims of forced labour?", "answer": "12.3 million", "ae_score": -0.4742718930051068, "qg_score": null}, {"question": "How many people worldwide are victims of forced labour?", "answer": "12.3 million", "ae_score": -0.4742718930051068, "qg_score": null}], "content": "Unfree labor re-emerged as an issue in the debate about rural development during the years following the end of the 1939-45 war, when a political concern of Keynesian theory was not just economic reconstruction (mainly in Europe and Asia) but also planning (in the Third World). A crucial aspect of the ensuing discussion concerned the extent to which different relational forms constituted obstacles to capitalist development, and why.\nDuring the 1960s and 1970s unfree labor was regarded as incompatible with capitalist accumulation, and thus an obstacle to economic growth, an interpretation advanced by exponents of the then-dominant semi-feudal thesis. From the 1980s onwards, however, another and very different Marxist view emerged, arguing that evidence from Latin America and India suggested agribusiness enterprises, commercial farmers and rich peasants reproduced, introduced or reintroduced unfree relations.\nHowever, recent contributions to this debate have attempted to exclude Marxism from the discussion. These contributions maintain that, because Marxist theory failed to understand the centrality of unfreedom to modern capitalism, a new explanation of this link is needed. This claim has been questioned by Tom Brass (2014), \u2018Debating Capitalist Dynamics and Unfree Labour: A Missing Link?\u2019, The Journal of Development Studies, 50:4, 570-582. He argues that many of these new characteristics are in fact no different from those identified earlier by Marxist theory and that the exclusion of the latter approach from the debate is thus unwarranted.\nThe  International Labour Organization (ILO) estimates that at least 12.3 million people are victims of forced labour worldwide; of these, 9.8 million  are exploited by private agents and more than 2.4 million are trafficked. Other 2.5 million are forced to work by the state or by rebel military groups. From an international law perspective, countries that allow forced labor are violating international labour standards as set forth in the Abolition of Forced Labour Convention (C105), one of the fundamental conventions of the ILO.\nAccording to the ''ILO Special Action Programme to Combat Forced Labour'' (SAP-FL), global  profits from forced trafficked labour exploited by private agents are estimated at US$44,3 billion per year. About 70% of this value (US$31.6 billion) come from trafficked victims. At least the half of  this sum (more than US$15 billion) comes from industrialized countries.", "page_name": "Unfree labour", "page_id": "Unfree%20labour", "heading": "The present situation", "sub_heading": "The present situation", "_id": "71--3---1---1", "title": "Marxism and Unfree Labour: A Missing Link?"}
{"qas": [{"question": "What is the difference between the four dominant bacterial phyla in the human gut?", "answer": ""}, {"question": "What percentage of bacteria are anaerobes in the gut?", "answer": "Over 99%", "ae_score": -0.19180298569742626, "qg_score": null}, {"question": "What percentage of bacteria are anaerobes in the gut?", "answer": "Over 99%", "ae_score": -0.19180298569742626, "qg_score": null}], "content": "The microbial composition of the gut flora varies across the digestive tract. In the stomach and small intestine, relatively few species of bacteria are generally present. The colon, in contrast, contains a densely-populated microbial ecosystem with up to 10 cells per gram of intestinal content. These bacteria represent between 300 and 1000 different species.<ref name=Sears/> However, 99% of the bacteria come from about 30 or 40 species. As a consequence of their abundance in the intestine, bacteria also make up to 60% of the dry mass of feces. Fungi, archaea, and viruses are also present in the gut flora, but less is known about their activities.\nOver 99% of the bacteria in the gut are anaerobes, but in the cecum, aerobic bacteria reach high densities.<ref name=Prescotts/> It is estimated that these gut flora have around a hundred times as many genes in total as there are in the human genome.\nMany species in the gut have not been studied outside of their hosts because most cannot be cultured.<ref name=Sears/> While there are a small number of core species of microbes shared by most individuals, populations of microbes can vary widely among different individuals. Within an individual, microbe populations stay fairly constant over time, even though some alterations may occur with changes in lifestyle, diet and age.<ref name=OHara06/> The Human microbiome project has set out to better describe the microflora of the human gut and other body locations.\nThe four dominant bacterial phyla in the human gut are Firmicutes, Bacteroidetes, Actinobacteria, and Proteobacteria. Most bacteria belong to the genera ''Bacteroides'', ''Clostridium'', ''Faecalibacterium'', ''Eubacterium'', ''Ruminococcus'', ''Peptococcus'', ''Peptostreptococcus'', and ''Bifidobacterium''. Other genera, such as ''Escherichia'' and ''Lactobacillus'', are present to a lesser extent. Species from the genus ''Bacteroides'' alone constitute about 30% of all bacteria in the gut, suggesting that this genus is especially important in the functioning of the host.<ref name=Sears/>\nFungal genera that have been detected in the gut include ''Candida'', ''Saccharomyces'', ''Aspergillus'', ''Penicillium'', ''Rhodotorula'', ''Trametes'', ''Pleospora'', ''Sclerotinia'', ''Bullera'', and ''Galactomyces'', among others. ''Rhodotorula'' is most frequently found in individuals with inflammatory bowel disease while ''Candida'' is most frequently found in individuals with hepatitis B cirrhosis and chronic hepatitis B.\nArchaea constitute another large class of gut flora which are important in the metabolism of the bacterial products of fermentation.\nAn enterotype is a classification of living organisms based on its bacteriological ecosystem in the human gut microbiome not dictated by age, gender, body weight, or national divisions. There are indications that long-term diet influences enterotype. Three human enterotypes have been discovered.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Types", "sub_heading": "Types", "_id": "72--0---1---1", "title": "The Human Microbiome"}
{"qas": [{"question": "What is the difference between the small intestine and the large intestine?", "answer": ""}, {"question": "Where does the bacteria in the small intestine come from?", "answer": "proximity and influence of the stomach", "ae_score": -0.7417761218399104, "qg_score": null}, {"question": "Where does the bacteria in the small intestine come from?", "answer": "proximity and influence of the stomach", "ae_score": -0.7417761218399104, "qg_score": null}], "content": "Due to the high acidity of the stomach, most microorganisms cannot survive. The main bacterial inhabitants of the stomach include: ''Streptococcus'', ''Staphylococcus'', ''Lactobacillus'', ''Peptostreptococcus'', and types of yeast. ''Helicobacter pylori'' is a Gram-negative spiral organism that establishes on gastric mucosa causing chronic gastritis and peptic ulcer disease and is a carcinogen for gastric cancer.\nThe small intestine contains a trace amount of microorganisms due to the proximity and influence of the stomach. Gram positive cocci and rod shaped bacteria are the predominant microorganisms found in the small intestine. However, in the distal portion of the small intestine alkaline conditions support gram-positive bacteria of the ''Enterobacteriaceae''. The bacterial flora of the small intestine aid in a wide range of intestinal functions. The bacterial flora provide regulatory signals that enable the development and utility of the gut. Overgrowth of bacteria in the small intestine can lead to intestinal failure. In addition the large intestine contains the largest bacterial ecosystem in the human body. Factors that disrupt the microorganism population of the large intestine include antibiotics, stress, and parasites.\nBacteria make up most of the flora in the colon and 60% of the dry mass of feces. This fact makes feces an ideal source to test for gut flora for any tests and experiments by extracting the nucleic acid from fecal specimens, and bacterial 16S rRNA gene sequences are generated with bacterial primers. This form of testing is also often preferable to more invasive techniques, such as biopsies. Somewhere between 300 and 1000 different species live in the gut, with most estimates at about 500. However, it is probable that 99% of the bacteria come from about 30 or 40 species, with ''Faecalibacterium prausnitzii'' being the most common species in healthy adults. Fungi and protozoa also make up a part of the gut flora, but little is known about their activities. The virome is mostly bacteriophages.\nResearch suggests that the relationship between gut flora and humans is not merely commensal (a non-harmful coexistence), but rather is a mutualistic, symbiotic relationship.  Though people can (barely) survive with no gut flora, the microorganisms perform a host of useful functions, such as fermenting unused energy substrates, training the immune system via end products of metabolism like propionate and acetate, preventing growth of harmful species, regulating the development of the gut, producing vitamins for the host (such as biotin and vitamin K), and producing hormones to direct the host to store fats.  Extensive modification and imbalances of the gut microbiota and its microbiome or gene collection are associated with obesity.  However, in certain conditions, some species are thought to be capable of causing disease by causing infection or increasing cancer risk for the host.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Flora composition", "sub_heading": "Flora composition", "_id": "72--1--0---1", "title": "Gut flora and the intestine"}
{"qas": [{"question": "Why is the microbiome so diverse in humans?", "answer": ""}, {"question": "When does the gut flora become an adult?", "answer": "three first years of life", "ae_score": -1.3342880255117626, "qg_score": null}, {"question": "When does the gut flora become an adult?", "answer": "three first years of life", "ae_score": -1.3342880255117626, "qg_score": null}], "content": "It has been demonstrated that there are common patterns of microbiome composition evolution during life. In general, the diversity of microbiota composition of fecal samples is significantly higher in adults than in children, although interpersonal differences are higher in children than in adults. Much of the maturation of microbiota into an adult-like configuration happens during the three first years of life.\nAs the microbiome composition changes, so does the composition of bacterial proteins produced in the gut. In adult microbiomes, a high prevalence of enzymes involved in fermentation, methanogenesis and the metabolism of arginine, glutamate, aspartate and lysine have been found. In contrast, in infant microbiomes the dominant enzymes are involved in cysteine metabolism and fermentation pathways.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Flora composition", "sub_heading": "Age", "_id": "72--1--1---1", "title": "The Evolution of Microbiome Composition"}
{"qas": [{"question": "Why are malnourished children more likely to die from malnutrition than healthy children?", "answer": ""}, {"question": "What is in the mouth and throat of malnourished children?", "answer": "yeast", "ae_score": -0.577170264709868, "qg_score": null}, {"question": "What is in the mouth and throat of malnourished children?", "answer": "yeast", "ae_score": -0.577170264709868, "qg_score": null}], "content": "Studies and statistical analyses have identified the different bacterial genera in gut microbiota and their associations with nutrient intake. Gut microflora is mainly composed of three enterotypes: ''Prevotella'', ''Bacteroides'', and ''Ruminococcus''. There is an association between the concentration of each microbial community and diet. For example, ''Prevotella'' is related to carbohydrates and simple sugars, while ''Bacteroides'' is associated with proteins, amino acids, and saturated fats. One enterotype will dominate depending on the diet. Altering the diet will result in a corresponding change in the numbers of species.\nMalnourished human children have less mature and less diverse gut microbiota than healthy children, and changes in the microbiome associated with nutrient scarcity can in turn be a pathophysiological cause of malnutrition. Malnourished children also typically have more potentially pathogenic gut flora, and more yeast in their mouths and throats.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Flora composition", "sub_heading": "Diet", "_id": "72--1--2---1", "title": "Gut Microbiota and Nutrition"}
{"qas": [{"question": "Why does the U.S. have such a high gut bacterial composition compared to other countries?", "answer": ""}, {"question": "What determines the composition of the gut flora?", "answer": "geographic origin of populations", "ae_score": -0.821576268523704, "qg_score": null}, {"question": "What determines the composition of the gut flora?", "answer": "geographic origin of populations", "ae_score": -0.821576268523704, "qg_score": null}], "content": "Gut microbiome composition depends on the geographic origin of populations. Variations in trade off of ''Prevotella'', the representation of the urease gene, and the representation of genes encoding glutamate synthase/degradation or other enzymes involved in amino acids degradation or vitamin biosynthesis show significant differences between populations from USA, Malawi or Amerindian origin.\nThe US population has a high representation of enzymes encoding the degradation of glutamine and enzymes involved in vitamin and lipoic acid biosynthesis; whereas Malawi and Amerindian populations have a high representation of enzymes encoding glutamate synthase and they also have an overrepresentation of \u03b1-amylase in their microbiomes. As the US population has a diet richer in fats than Amerindian or Malawian populations which have a corn-rich diet, the diet is probably a main determinant of gut bacterial composition.\nFurther studies have indicated a large difference in the composition of microbiota between European and rural African children. The fecal bacteria of children from Florence were compared to that of children from the small rural village of Boulpon in Burkina Faso. The diet of a typical child living in this village is largely lacking in fats and animal proteins and rich in polysaccharides and plant proteins. The fecal bacteria of European children was dominated by ''Firmicutes'' and showed a marked reduction in biodiversity, while the fecal bacteria of the Boulpon children was dominated by ''Bacteroidetes''. The increased biodiversity and different composition of gut flora in African populations may aid in the digestion of normally indigestible plant polysaccharides and also may result in a reduced incidence of non-infectious colonic diseases.\nOn a smaller scale, it has been shown that sharing numerous common environmental exposures in a family is a strong determinant of individual microbiome composition. This effect has no genetic influence and it is consistently observed in culturally different populations.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Flora composition", "sub_heading": "Geography", "_id": "72--1--3---1", "title": "Gut Microbiome Composition"}
{"qas": [{"question": "How does the gut flora of an infant differ from that of an adult?", "answer": ""}, {"question": "What type of bacteria are in the gut?", "answer": "facultative anaerobic organisms", "ae_score": -0.7889282896596564, "qg_score": null}, {"question": "What type of bacteria are in the gut?", "answer": "facultative anaerobic organisms", "ae_score": -0.7889282896596564, "qg_score": null}], "content": "In humans, a gut flora similar to an adult's is formed within one to two years of birth.<ref name=Sommer2013rev/> The gastrointestinal tract of a normal fetus has been considered to be sterile, however recently it has been acknowledged that microbial colonisation may occur in the fetus. During birth and rapidly thereafter, bacteria from the mother and the surrounding environment colonize the infant's gut.<ref name=Sommer2013rev/> As of 2013, it was unclear whether most of colonizing arise from the mother or not.<ref name=Sommer2013rev/>  Infants born by caesarean section may also be exposed to their mothers' microflora, but the initial exposure is most likely to be from the surrounding environment such as the air, other infants, and the nursing staff, which serve as vectors for transfer.<ref name=Matamoros2013rev/>  During the first year of life, the composition of the gut flora is generally simple and it changes a great deal with time and is not the same across individuals.<ref name=Sommer2013rev/>\nThe initial bacterial population are generally facultative anaerobic organisms; investigators believe that these initial colonizers decrease the oxygen concentration in the gut, which in turn allows purely aneorobic bacteria like ''Bacteroides'', ''Actinobacteria'', and ''Firmicutes'' to become established and thrive.<ref name=Sommer2013rev/>  Breast-fed babies become dominated by bifidobacteria, possibly due to the contents of bifidobacterial growth factors in breast milk. In contrast, the microbiota of formula-fed infants is more diverse, with high numbers of ''Enterobacteriaceae'', enterococci, bifidobacteria, ''Bacteroides'', and clostridia.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Acquisition of gut flora in human infants", "sub_heading": "Acquisition of gut flora in human infants", "_id": "72--2---1---1", "title": "Gut flora | Acquisition of gut flora in human infants"}
{"qas": [{"question": "What is the purpose of the gut flora?", "answer": ""}, {"question": "What does the gut flora make use of?", "answer": "all available nutrients", "ae_score": -1.433860769469218, "qg_score": null}, {"question": "What does the gut flora make use of?", "answer": "all available nutrients", "ae_score": -1.433860769469218, "qg_score": null}], "content": "The gut flora community plays a direct role in defending against pathogens by fully colonizing the space, making use of all available nutrients, and by secreting compounds that kill or inhibit unwelcome organisms that would compete for nutrients with it.  Disruption of the gut flora allows competing organisms like ''Clostridium difficile'' to become established that otherwise are kept in abeyance.<ref name=Yoon2014rev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Functions", "sub_heading": "Functions", "_id": "72--3--0---1", "title": "Gut flora | Functions"}
{"qas": [{"question": "How does the immune system work?", "answer": ""}, {"question": "Where does the immune system sense the presence of bacteria?", "answer": "Gut flora", "ae_score": -0.9852658939193761, "qg_score": null}, {"question": "Where does the immune system sense the presence of bacteria?", "answer": "Gut flora", "ae_score": -0.9852658939193761, "qg_score": null}], "content": "In humans, a gut flora similar to an adult's is formed within one to two years of birth.<ref name=Sommer2013rev/>  As the gut flora gets established, the lining of the intestines \u2013 the intestinal epithelium and the intestinal mucosal barrier that it secretes \u2013 develop as well, in a way that is tolerant to, and even supportive of, commensurate microorganisms to a certain extent and also provides a barrier to pathogenic ones.<ref name=Sommer2013rev/> Specifically, goblet cells that produce the muscosa proliferate, and the mucosa layer thickens, providing an outside mucosal layer in which \"friendly\" microorganisms can anchor and feed, and an inner layer that even these organisms cannot penetrate.<ref name=Sommer2013rev/><ref name=Faderl2015rev/> Additionally, the development of gut-associated lymphoid tissue (GALT), which forms part of the intestinal epithelium and which detects and reacts to pathogens, appears and develops during the time that the gut flora develops and established.<ref name=Sommer2013rev/>  The GALT that develops is tolerant to gut flora species, but not to other microorganisms.<ref name=Sommer2013rev/>  GALT also normally becomes tolerant to food to which the infant is exposed, as well as digestive products of food, and gut flora's metabolites produced from food.<ref name=Sommer2013rev/>\nThe human immune system creates cytokines that can drive the immune system to produce inflammation in order to protect itself, and that can tamp down the immune response to maintain homeostasis and allow healing after insult or injury.<ref name=Sommer2013rev/> Different bacterial species that appear in gut flora have been shown to be able to drive the immune system to create cytokines selectively; for example ''Bacteroides fragilis'' and some ''Clostridia'' species appear to drive an anti-inflammatory response, while some segmented filamentous bacteria drive the production of inflammatory cytokines.<ref name=Sommer2013rev/>  Gut flora can also regulate the production of antibodies by the immune system.<ref name=Sommer2013rev/>  These cytokines and antibodies can have effects outside the gut, in the lungs and other tissues.<ref name=Sommer2013rev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Functions", "sub_heading": "Development of enteric protection and immune system", "_id": "72--3--1---1", "title": "Gut flora | Functions | Development of enteric protection and immune system"}
{"qas": [{"question": "What would happen to the human body if it had no gut flora?", "answer": ""}, {"question": "What does scfas stand for in the gut?", "answer": "short-chain fatty acids", "ae_score": -0.6291188753098752, "qg_score": null}, {"question": "What does scfas stand for in the gut?", "answer": "short-chain fatty acids", "ae_score": -0.6291188753098752, "qg_score": null}], "content": "Without gut flora, the human body would be unable to utilize some of the undigested carbohydrates it consumes, because some types of gut flora have enzymes that human cells lack for breaking down certain polysaccharides.<ref name=Clarke2014rev/>  Rodents raised in a sterile environment and lacking in gut flora need to eat 30% more calories just to remain the same weight as their normal counterparts.<ref name=Clarke2014rev/>  Carbohydrates that humans cannot digest without bacterial help include certain starches, fiber, oligosaccharides, and sugars that the body failed to digest and absorb like lactose in the case of lactose intolerance and sugar alcohols, mucus produced by the gut, and proteins.<ref name=Quigley2013rev/><ref name=Clarke2014rev/>\nBacteria turn carbohydrates they ferment into short-chain fatty acids (SCFAs)<ref name=gibson/> by a form of fermentation called saccharolytic fermentation.<ref name=gibson/> Products include acetic acid, propionic acid and butyric acid.<ref name=gibson/> These materials can be used by host cells, providing a major source of useful energy and nutrients for humans,<ref name=gibson/> as well as helping the body to absorb essential dietary minerals such as calcium, magnesium and iron. Gases and organic acids, such as lactic acid, are also produced by saccharolytic fermentation. Acetic acid is used by muscle, propionic acid helps the liver produce ATP, and butyric acid provides energy to gut cells and may prevent cancer.<ref name=gibson/> Evidence also indicates that bacteria enhance the absorption and storage of lipids<ref name=Sears/> and produce and then facilitate the body to absorb needed vitamins like vitamin K.\nGut flora also synthesize vitamins like biotin and folate, and help with absorption of dietary elements including magnesium, calcium and iron. Methanogenic archae such as ''Methanobrevibacter smithii'' are involved in the removal of end products of bacterial fermentation such as hydrogen.<ref name=Prescotts/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Functions", "sub_heading": "Metabolism", "_id": "72--3--2---1", "title": "Gut flora | Functions | Metabolism"}
{"qas": [{"question": "What is the difference between the gut and the brain?", "answer": ""}, {"question": "When was the first study done on gut flora?", "answer": "2004", "ae_score": -0.5449300269396609, "qg_score": null}, {"question": "When was the first study done on gut flora?", "answer": "2004", "ae_score": -0.5449300269396609, "qg_score": null}], "content": "The gut\u2013brain axis is the biochemical signaling that takes place between the gastrointestinal tract  and the central nervous system.<ref name=2014Wangrev/>  That term has been expanded to include the role of the gut flora in the interplay; the term \"microbiome-gut-brain axis\" is sometimes used to describe paradigms explicitly including the gut flora.<ref name=2014Wangrev/>\nBroadly defined, the gut-brain axis includes the central nervous system, neuroendocrine and neuroimmune systems including the hypothalamic\u2013pituitary\u2013adrenal axis (HPA axis), sympathetic and parasympathetic arms of the autonomic nervous system including the enteric nervous system, the vagus nerve, and the gut microbiota.<ref name=2014Wangrev/>\nInterest in the field was sparked by a 2004 study showing that germ-free mice showed an exaggerated HPA axis response to stress compared to non-GF laboratory mice.<ref name=2014Wangrev/>  As of January 2016, most of the work that has been done on the role of gut flora in the gut-brain axis had been conducted in animals, or characterizing the various neuroactive compounds that gut flora can produce, and studies with humans measuring differences between people with various psychiatric and neurological differences, or changes to gut flora in response to stress, or measuring effects of various probiotics (dubbed \"psychobiotics in this context), had generally been small and could not be generalized; whether changes to gut flora are a result of disease, a cause of disease, or both in any number of possible feedback loops in the gut-brain axis, remained unclear.<ref name=2014Wangrev/>\nA systematic review from 2016 examined the preclinical and small human trials that have been conducted with certain commercially available strains of probiotic bacteria and found that among those tested, ''Bifidobacterium'' and ''Lactobacillus'' genera (''B. longum'', ''B. breve'', ''B. infantis'', ''L. helveticus'', ''L. rhamnosus'', ''L. plantarum'', and ''L. casei''), had the most potential to be useful for certain central nervous system disorders.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Functions", "sub_heading": "Gut-brain axis", "_id": "72--3--3---1", "title": "Gut flora and the gut\u2013brain axis"}
{"qas": [{"question": "What is the difference between probiotics and antibiotics?", "answer": ""}, {"question": "What is the success rate of transplants of c difficile bacteria?", "answer": "90%", "ae_score": -0.27627766362186046, "qg_score": null}, {"question": "What is the success rate of transplants of c difficile bacteria?", "answer": "90%", "ae_score": -0.27627766362186046, "qg_score": null}], "content": "Altering the numbers of gut bacteria, for example by taking broad-spectrum antibiotics, may affect the host's health and ability to digest food. Antibiotics can cause antibiotic-associated diarrhea (AAD) by irritating the bowel directly, changing the levels of gut flora, or allowing pathogenic bacteria to grow. Another harmful effect of antibiotics is the increase in numbers of antibiotic-resistant bacteria found after their use, which, when they invade the host, cause illnesses that are difficult to treat with antibiotics.<ref name=Carman/>\nChanging the numbers and species of gut flora can reduce the body's ability to ferment carbohydrates and metabolize bile acids and may cause diarrhea. Carbohydrates that are not broken down may absorb too much water and cause runny stools, or lack of SCFAs produced by gut flora could cause the diarrhea.\nA reduction in levels of native bacterial species also disrupts their ability to inhibit the growth of harmful species such as ''C. difficile'' and ''Salmonella kedougou'', and these species can get out of hand, though their overgrowth may be incidental and not be the true cause of diarrhea.<ref name=Carman/> Emerging treatment protocols for C. difficile infections involve fecal microbiota transplantation of donor feces. (see Fecal transplant). Initial reports of treatment describe success rates of 90%, with few side effects. Efficacy is speculated to result from restoring bacterial balances of bacteroides and firmicutes classes of bacteria.\nGut flora composition also changes in severe illnesses, due not only to antibiotic use but also to such factors as ischemia of the gut, failure to eat, and immune compromise. Negative effects from this have led to interest in selective digestive tract decontamination (SDD), a treatment to kill only pathogenic bacteria and allow the re-establishment of healthy ones.\nAntibiotics alter the population of the gastrointestinal (GI) tract microbiota, may change the intra-community metabolic interactions, modify caloric intake by using carbohydrates, and globally affects host metabolic, hormonal and immune homeostasis.<ref name= cho2012/>\nThere is reasonable evidence that taking probiotics containing ''Lactobacillus'' species may help prevent antibiotic-associated diarrhea and that taking probiotics with ''Saccharomyces'' (e.g., ''Saccharomyces boulardii '') may help to prevent ''Clostridium difficile'' infection following systemic antibiotic treatment.<ref name=JFP2016rev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Alterations in flora balance", "sub_heading": "Alterations in flora balance", "_id": "72--4--0---1", "title": "Gut flora | Alterations in flora balance"}
{"qas": [{"question": "How does a woman's gut flora change as she gets older?", "answer": ""}, {"question": "Where does the mother's gut flora come from?", "answer": "first-trimester samples", "ae_score": -1.3838545592439881, "qg_score": null}, {"question": "Where does the mother's gut flora come from?", "answer": "first-trimester samples", "ae_score": -1.3838545592439881, "qg_score": null}], "content": "Women's gut microbiota change as pregnancy advances, with the changes similar to those seen in metabolic syndromes such as diabetes. The change in gut flora causes no ill effects. The newborn's gut biota resemble the mother's first-trimester samples. The diversity of the flora decreases from the first to third trimester, as the numbers of certain species go up.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Alterations in flora balance", "sub_heading": "Pregnancy", "_id": "72--4--1---1", "title": "Women's Gut Microbiota Change As Pregnancy Advances"}
{"qas": [{"question": "Why do ulcerative colitis patients have a sore throat?", "answer": ""}, {"question": "What is the term for the combination of probiotics and prebiotics?", "answer": "Synbiotics", "ae_score": -0.17142009387915066, "qg_score": null}, {"question": "What is the term for the combination of probiotics and prebiotics?", "answer": "Synbiotics", "ae_score": -0.17142009387915066, "qg_score": null}], "content": "Probiotics are microorganisms that are believed to provide health benefits when consumed.  With regard to gut flora, prebiotics are typically non-digestible, fiber compounds that pass undigested through the upper part of the gastrointestinal tract and stimulate the growth or activity of advantageous gut flora by acting as substrate for them.\nSynbiotics refers to food ingredients or dietary supplements combining probiotics and prebiotics in a form of synergism.\nThe term \"pharmabiotics\" is used in various ways, to mean: pharmaceutical formulations (standardized manufacturing that can obtain regulatory approval as a drug) of probiotics, prebiotics, or synbiotics; probiotics that have been genetically engineered or otherwise optimized for best performance (shelf life, survival in the digestive tract, etc.); and the natural products of gut flora metabolism (vitamins, etc.).\nThere is some evidence that treatment with some probiotic strains of bacteria may be effective in irritable bowel syndrome and chronic idiopathic constipation. Those organisms most likely to result in a decrease of symptoms have included:\nGram positive bacteria present in the lumen may be associated with extending the duration of relapse for ulcerative colitis.<ref name=Ghouri2014/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Alterations in flora balance", "sub_heading": "Probiotics, prebiotics, synbiotics, and pharmabiotics", "_id": "72--4--2---1", "title": "Probiotics and Synbiotics"}
{"qas": [{"question": "How do stomach ulcers work?", "answer": ""}, {"question": "What bacterium causes ulcers in the stomach?", "answer": "Helicobacter pylori", "ae_score": -0.9462077734177106, "qg_score": null}, {"question": "What bacterium causes ulcers in the stomach?", "answer": "Helicobacter pylori", "ae_score": -0.9462077734177106, "qg_score": null}], "content": "''Helicobacter pylori'' can cause stomach ulcers by crossing the epithelial lining of the stomach. Here the body produces an immune response. During this response parietal cells are stimulated and release extra hydrochloric acid (HCl) into the stomach. However, the response does not stimulate the mucus-secreting cells that protect and line the epithelium of the stomach. The extra acid sears holes into the epithelial lining of the stomach, resulting in stomach ulcers.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Role in disease", "_id": "72--5--0---1", "title": "''Helicobacter pylori'' Causes Stomach Ul"}
{"qas": [{"question": "Why do people with Crohn's Disease have such a large gut flora compared to healthy people?", "answer": ""}, {"question": "How many types of inflammatory bowel disease are there?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many types of inflammatory bowel disease are there?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "The two main types of inflammatory bowel diseases, Crohn's disease and ulcerative colitis, are chronic inflammatory disorders of the gut; the causes of these disease are unknown and issues with the gut flora and its relationship with the host have been implicated in these conditions.<ref name=Shen2016rev/>  Additionally, it appears that interactions of gut flora with the gut-brain axis have a role in IBD, with physiological stress mediated through the hypothalamic\u2013pituitary\u2013adrenal axis driving changes to intestinal epithelium and the gut flora in turn releasing factors and metabolites that trigger sigalling in the enteric nervous system and the vagus nerve.<ref name=Saxena2016/>\nThe diversity of gut flora appears to be significantly diminished in people with inflammatory bowel diseases compared to healthy people; additionally, in people with ulcerative colitis, Proteobacteria and Actinobacteria appear to dominate;  in people with Crohn's, ''Enterococcus faecium'' and several Proteobacteria appear to be over-represented.<ref name=Saxena2016/>\nThere is reasonable evidence that correcting gut flora imbalances by taking probiotics with ''Lactobacilli'' and ''Bifidobacteria'' can reduce visceral pain and gut inflammation in IBD.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Inflammatory bowel diseases", "_id": "72--5--1---1", "title": "Gut flora imbalances in Crohn's Disease and Ulcerative Colitis"}
{"qas": [{"question": "How does irritable bowel syndrome work?", "answer": ""}, {"question": "What is it called when the gut flora changes?", "answer": "Irritable bowel syndrome", "ae_score": -0.8623192310788258, "qg_score": null}, {"question": "What is it called when the gut flora changes?", "answer": "Irritable bowel syndrome", "ae_score": -0.8623192310788258, "qg_score": null}], "content": "Irritable bowel syndrome is a result of stress and chronic activation of the HPA axis; its symptoms include abdominal pain, changes in bowel movements, and an increase in proinflammatory cytokines. Overall, studies have found that the luminal and mucosal microbiota are changed in irritable bowel syndrome individuals, and these changes can relate to the type of irritation such as diarrhea or constipation. Also, there is a decrease in the diversity of the microbiome with low levels of fecal Lactobacilli and Bifidobacteria, high levels of facultative anaerobic bacteria such as Escherichia coli, and increased ratios of Firmicutes:Bacteroidetes.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Irritable bowel syndrome", "_id": "72--5--2---1", "title": "Irritable Bowel Syndrome Symptoms"}
{"qas": [{"question": "Why do some people have allergies and others don't?", "answer": ""}, {"question": "Which hypothesis states that children in the developed world are exposed to a wide range of pathogens?", "answer": "the hygiene hypothesis", "ae_score": -0.6128717613807507, "qg_score": null}, {"question": "Which hypothesis states that children in the developed world are exposed to a wide range of pathogens?", "answer": "the hygiene hypothesis", "ae_score": -0.6128717613807507, "qg_score": null}], "content": "Allergy, asthma and Diabetes mellitus type 1 are autoimmune and inflammatory disorders' the causes of these disease are unknown and issues with the gut flora and its relationship with the host have been implicated in these conditions.<ref name=Shen2016rev/>\nTwo hypotheses have been posed to explain the rising prevalence of these diseases in the developed world: the hygiene hypothesis, which posits that children in the developed world are not exposed to a wide enough range of pathogens and end up with an overreactive immune system, and the role of the Western pattern diet which lacks whole grains and fiber and has an overabundance of simple sugars.<ref name=Shen2016rev/>   Both hypotheses converge on the changes in the gut flora and its role in modulating the immune system, and as of 2016 this was an active area of research.<ref name=Shen2016rev/>\nSimilar hypotheses have been posited for the rise of food and other allergies.\nAs of 2016 it was not clear if changes to the gut flora cause these auto-immune and inflammatory disorders or are a product of them or adaptation to them.<ref name=Shen2016rev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Other inflammatory or autoimmune conditions", "_id": "72--5--3---1", "title": "Allergy, asthma and Diabetes mellitus type 1 are autoimmune and "}
{"qas": [{"question": "Why does the liver have a dominant role in blood glucose homeostasis?", "answer": ""}, {"question": "Which part of the body controls glucose homeostasis?", "answer": "intestinal lipids", "ae_score": -0.8711580352572407, "qg_score": null}, {"question": "Which part of the body controls glucose homeostasis?", "answer": "intestinal lipids", "ae_score": -0.8711580352572407, "qg_score": null}], "content": "The gut flora has also been implicated in obesity and metabolic syndrome due to the key role it plays in the digestive process; the Western pattern diet appears to drive and maintain changes in the gut flora that in turn change how much energy is derived from food and how that energy is used.<ref name=2016BoulangeRev/>  One aspect of a healthy diet that is often lacking in the Western-pattern diet is fiber and other complex carbohydrates that a healthy gut flora require to flourish; changes to gut flora in response to a Western-pattern diet appear to increase the amount of energy generated by the gut flora which may contribute to obesity and metabolic syndrome.<ref name=JFP2016rev/>  There is also evidence that microbiota influence eating behaviors based on the preferences of the microbiota, which can lead to the host consuming more food eventually resulting in obesity. It has generally been observed that with higher gut microbiome diversity, the microbiota will spend energy and resources on competing with other microbiota and less on manipulating the host. The opposite is seen with lower gut microbiome diversity, and these microbiotas may work together for to create host food cravings.\nAdditionally, the liver plays a dominant role in blood glucose homeostasis by maintaining a balance between the uptake and storage of glucose through the metabolic pathways of glycogenesis and gluconeogenesis. In recent studies, it is illustrated that intestinal lipids regulate glucose homeostasis involving a gut-brain-liver axis. The direct administration of lipids into the upper intestine increases the long chain fatty acyl-coenzyme A (LCFA-CoA) levels in the upper intestines and suppresses glucose production even under sub diaphragmatic vagotomy or gut vagal deafferentation. This interrupts the neural connection between the brain and the gut and blocks the upper intestinal lipids\u2019 ability to inhibit glucose production. The gut-brain-liver axis and gut microbiota composition can regulate the glucose homeostasis in the liver and provide potential therapeutic methods to treat obesity and diabetes.\nJust as gut flora can function in a feedback loop that can drive the development of obesity, there is evidence that restricting intake of calories (i.e. dieting) can drive changes to the composition of the gut flora.<ref name=2016BoulangeRev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Obesity and metabolic syndrome", "_id": "72--5--4---1", "title": "Gut Microbiota and Obesity"}
{"qas": [{"question": "How does the liver get nutrients from the intestines?", "answer": ""}, {"question": "Where does the liver get its nutrition from in the gut?", "answer": "portal vein", "ae_score": -1.0796608558457201, "qg_score": null}, {"question": "Where does the liver get its nutrition from in the gut?", "answer": "portal vein", "ae_score": -1.0796608558457201, "qg_score": null}], "content": "As the liver is fed directly by the portal vein, whatever crosses the intestinal epithelium and the intestinal mucosal barrier enters the liver, as do cytokines generated there. Dysbiosis in the gut flora has been linked with the development of cirrhosis and non-alcoholic fatty liver disease.<ref name=Minemura2015rev/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Liver disease", "_id": "72--5--5---1", "title": "Gut flora | Role in disease | Liver disease"}
{"qas": [{"question": "Why is it bad to have anaerobic bacteria in your gut?", "answer": ""}, {"question": "What type of bacteria are in the gut?", "answer": "Aerobic", "ae_score": -0.6370816769422555, "qg_score": null}, {"question": "What type of bacteria are in the gut?", "answer": "Aerobic", "ae_score": -0.6370816769422555, "qg_score": null}], "content": "Normally-commensal bacteria can be very harmful to the host if they get outside of the intestinal tract.<ref name=Sommer2013rev/><ref name=Faderl2015rev/> Translocation, which occurs when bacteria leave the gut through its mucosal lining, the border between the lumen of the gut and the inside of the body, can occur in a number of different diseases, and can be caused by too much growth of bacteria in the small intestine, reduced immunity of the host, or increased gut lining permeability.<ref name=Faderl2015rev/>\nIf the gut is perforated, bacteria can invade the body, causing a potentially fatal infection. Aerobic bacteria can make an infection worse by using up all available oxygen and creating an environment favorable to anaerobes.<ref name=Prescotts/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Systemic infections", "_id": "72--5--6---1", "title": "Gut flora | Role in disease | Systemic infections"}
{"qas": [{"question": "Why do some bacteria cause cancer and others do not?", "answer": ""}, {"question": "What is the function of bacteria in the gut?", "answer": "prevent tumor formation", "ae_score": -2.0258816140788047, "qg_score": null}, {"question": "What is the function of bacteria in the gut?", "answer": "prevent tumor formation", "ae_score": -2.0258816140788047, "qg_score": null}], "content": "Some genera of bacteria, such as ''Bacteroides'' and ''Clostridium'', have been associated with an increase in tumor growth rate, while other genera, such as ''Lactobacillus'' and ''Bifidobacteria'', are known to prevent tumor formation.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Cancer", "_id": "72--5--7---1", "title": "''Clostridium'' and ''Bacteroides'"}
{"qas": [{"question": "What is the relationship between gut flora and neuropsychiatric issues?", "answer": ""}, {"question": "When was the first study about gut flora done?", "answer": "2004", "ae_score": -0.6754219810708131, "qg_score": null}, {"question": "When was the first study about gut flora done?", "answer": "2004", "ae_score": -0.6754219810708131, "qg_score": null}], "content": "Interest in the relationship between gut flora and neuropsychiatric issues was sparked by a 2004 study showing that germ-free mice showed an exaggerated HPA axis response to stress compared to non-GF laboratory mice.<ref name=2014Wangrev/>  As of January 2016, most of the work that has been done on the role of gut flora in the gut-brain axis had been conducted in animals, or characterizing the various neuroactive compounds that gut flora can produce, and studies with humans measuring differences between people with various psychiatric and neurological differences, or changes to gut flora in response to stress, or measuring effects of various probiotics (dubbed \"psychobiotics in this context), had generally been small and could not be generalized; whether changes to gut flora are a result of disease, a cause of disease, or both in any number of possible feedback loops in the gut-brain axis, remained unclear.<ref name=2014Wangrev/><ref name=JFP2016rev/>\nA systematic review from 2016 examined the preclinical and small human trials that have been conducted with certain commercially available strains of probiotic bacteria and found that among those tested, ''Bifidobacterium'' and ''Lactobacillus'' genera (''B. longum'', ''B. breve'', ''B. infantis'', ''L. helveticus'', ''L. rhamnosus'', ''L. plantarum'', and ''L. casei''), had the most potential to be useful for certain central nervous system disorders.", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Role in disease", "sub_heading": "Neuropsychiatric", "_id": "72--5--8---1", "title": "Gut flora and neuropsychiatric issues"}
{"qas": [{"question": "Why are there so many different species of insects?", "answer": ""}, {"question": "Who studied the role of bacteria in the gut flora?", "answer": "Ilseung Cho", "ae_score": -0.38515209086111407, "qg_score": null}, {"question": "Who studied the role of bacteria in the gut flora?", "answer": "Ilseung Cho", "ae_score": -0.38515209086111407, "qg_score": null}], "content": "Aside from mammals, some insects also possess complex and diverse gut microbiota that play key nutritional roles. Microbial communities associated termites can constitute a majority of the weight of the individuals and perform important roles in the digestion of lignocellulose and nitrogen fixation. These communities are host-specific, and closely related insect species share comparable similarities in gut microbiota composition. In cockroaches, gut microbiota have been shown to assemble in a deterministic fashion, irrespective of the inoculum; the reason for this host-specific assembly remains unclear. Bacterial communities associated with insects like termites and cockroaches are determined by a combination of forces, primarily diet, but there is some indication that host phylogeny may also be playing a role in the selection of lineages.\nFor more than 51 years we have known that the administration of low doses of antibacterial agents promotes the growth of farm animals to increase weight gain.\nIn a study performed on mice by Ilseung Cho,<ref name= cho2012/> the ratio of ''Firmicutes'' and ''Lachnospiraceae'' was significantly elevated in animals treated with subtherapeutic doses of different antibiotics. By analyzing the caloric content of faeces and the concentration of small chain fatty acids (SCFAs) in the GI tract, they concluded that the changes in the composition of microbiota lead to an increased capacity to extract calories from otherwise indigestible constituents, and to an increased production of SCFAs. These findings provide evidence that antibiotics perturb not only the composition of the GI microbiome but also its metabolic capabilities, specifically with respect to SCFAs.<ref name= cho2012/>", "page_name": "Gut flora", "page_id": "Gut%20flora", "heading": "Other animals", "sub_heading": "Other animals", "_id": "72--6---1---1", "title": "Gut flora | Other animals"}
{"qas": [{"question": "How did people make money before the invention of the internet?", "answer": ""}, {"question": "Where did most textile workers work before the industrial revolution?", "answer": "agriculture", "ae_score": -0.1748784262787469, "qg_score": null}, {"question": "Where did most textile workers work before the industrial revolution?", "answer": "agriculture", "ae_score": -0.1748784262787469, "qg_score": null}], "content": "The concept of what is now considered to be a ''job'', where one attends work at fixed hours was rare until the Industrial Revolution. Before then, the predominant regular work was in agriculture. Textile workers would often work from home, buying raw cotton from a merchant, spinning it and weaving it into cloth at home, before selling it on.\nIn the 1770s, cotton mills started to appear in Lancashire, England, using Richard Arkwright's spinning jenny and powered by water wheels. Workers would often work in twelve-hour shifts, six days a week. However, they would still often be paid on a piece work basis, and fines would be deducted from their pay for damage to machinery. Employers could hire and fire pretty much as they pleased, and if employees had any grievance about this, there was very little that they could do about it.\nIndividual workers were powerless to prevent exploitation by their employers. However, the realisation that all workers generally want the same things, and the benefits of collective bargaining, led to the formation of the first trade unions. As trade unions became larger, their sphere of influence increased, and started to involve political lobbying, resulting in much of the employment law that is now taken for granted.\nManufacturing has declined during the 20th century in the Western world. Many manufacturing organisations that employ large numbers of people have relocated their operations to developing nations. As a result, whenever they do hire staff in Europe or North America, they often need to be able to fire them quickly and keep costs as low as possible, to remain competitive. As a result, some employers may look for loopholes in employment law, or ways of engaging staff that allows them to circumvent union-negotiated employment law, creating what is now known as contingent work.", "page_name": "Contingent work", "page_id": "Contingent%20work", "heading": "History", "sub_heading": "History", "_id": "73--0---1---1", "title": "Employment Law in the Industrial Revolution"}
{"qas": [{"question": "How does a knowledge-driven economy contribute to the growth of the contingent workforce?", "answer": ""}, {"question": "What type of economy is contingent work?", "answer": "knowledge-driven economy", "ae_score": -0.7950011695715591, "qg_score": null}, {"question": "What type of economy is contingent work?", "answer": "knowledge-driven economy", "ae_score": -0.7950011695715591, "qg_score": null}], "content": "According to the US Bureau of Labor Statistics (BLS), the nontraditional workforce includes \"multiple job holders, contingent and part-time workers, and people in alternative work arrangements.\" These workers currently represent a substantial portion of the US workforce, and \"nearly four out of five employers, in establishments of all sizes and industries, use some form of nontraditional staffing\". \"People in alternative work arrangements\" includes independent contractors, employees of contract companies, workers who are on call, and temporary workers.\nAmong several other contributing factors, globalization has had a large impact on the growth in using contingent labor. Globalization contributes to rapid growth in industries, increased outsourcing, and a need for flexibility and agility to remain competitive.  By engaging contract workers, organizations are able to be agile and save costs.  The contingent workforce acts as a variable workforce for companies to select from to perform specific projects or complete specialized projects.  Also as organizations make efforts to be more agile and to quickly respond to change in order to be more competitive, they turn to the contingent workforce to have on-demand access to professionals and experts.  Organizations also see the opportunity to reduce benefits and retirement costs by engaging the contingent workforce.<ref name=BoA/>  However, there is risk involved in avoiding these costs if an employee is improperly classified as  a contingent worker. Using the contingent workforce is also cost-effective in that using contingent labor allows for adjustments to employment levels and employment costs depending on what kind of expertise and labor is need and at what time it is needed.\nTrends in the contingent workforce are also impacted by the economy.  A study conducted by the MPS Group shows the relationship between the contingent labor cycle and the state of the economy. In a bullish economy, the demand for contingent labor is strong.  This is most likely because organizations are trying to grow with the economy, and using contingent workers allows them to work with experts when needed, without the long-term costs of hiring them.\nA knowledge-driven economy also contributes to the growth in the use of the contingent workforce because organizations rely more on their specific and expert knowledge and expertise. As demand increases for highly skilled and knowledgeable people, the expertise of contract workers becomes more attractive.", "page_name": "Contingent work", "page_id": "Contingent%20work", "heading": "Trends", "sub_heading": "Trends", "_id": "73--1---1---1", "title": "Concurrency Workforce Trends"}
{"qas": [{"question": "Why is it called a McJobs?", "answer": ""}, {"question": "What is the term for insecure jobs in fast food?", "answer": "McJobs", "ae_score": -0.3282114370458729, "qg_score": null}, {"question": "What is the term for insecure jobs in fast food?", "answer": "McJobs", "ae_score": -0.3282114370458729, "qg_score": null}], "content": "Contingent work jobs are widely referred to as McJobs. This term was made popular by Douglas Coupland's novel Generation X: Tales for an Accelerated Culture, and stems from the notion that jobs in McDonalds and other fast food and retail businesses are frequently insecure.", "page_name": "Contingent work", "page_id": "Contingent%20work", "heading": "In culture", "sub_heading": "In culture", "_id": "73--2---1---1", "title": "McJobs (Contingent Work Jobs)"}
{"qas": [{"question": "Why is contingent work seen as a bad thing?", "answer": ""}, {"question": "Where is contingent work most likely to be found?", "answer": "middle class jobs", "ae_score": -0.5997352812149587, "qg_score": null}, {"question": "Where is contingent work most likely to be found?", "answer": "middle class jobs", "ae_score": -0.5997352812149587, "qg_score": null}], "content": "Critics say that it is unfair to tarnish all employment agencies with the brush of contingent work. Some say that temporary work patterns such as self-employment, consultancy and telecommuting can bring benefits of flexibility not just to employers but also employees, can improve work-life balance, and can make it easier for workers to manage family responsibilities. However, it is argued that such benefits are realised only in middle class jobs, whose entry barriers are too high for most workers with below-average earnings.", "page_name": "Contingent work", "page_id": "Contingent%20work", "heading": "Criticisms", "sub_heading": "Criticisms", "_id": "73--3---1---1", "title": "Employment agencies should be tarnished with the brush of contingent work"}
{"qas": [{"question": "How does resistant starch work?", "answer": ""}, {"question": "When did the concept of resistant starch come about?", "answer": "1970s", "ae_score": -0.43296532982496266, "qg_score": null}, {"question": "When did the concept of resistant starch come about?", "answer": "1970s", "ae_score": -0.43296532982496266, "qg_score": null}], "content": "The concept of resistant starch arose from research in the 1970s and is currently considered to be one of three starch types: rapidly digested starch, slowly digested starch and resistant starch, each of which may affect levels of blood glucose.\nThe Commission of the European Communities has supported research eventually leading to a definition of resistant starch.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Origin and history", "sub_heading": "Origin and history", "_id": "74--0---1---1", "title": "Resistant starch is a starch type that affects blood glucose levels"}
{"qas": [{"question": "How does adding starch to foods reduce the amount of sugar in the food?", "answer": ""}, {"question": "What is the main energy source for colonic cells?", "answer": "butyrate", "ae_score": -0.29585756771902566, "qg_score": null}, {"question": "What is the main energy source for colonic cells?", "answer": "butyrate", "ae_score": -0.29585756771902566, "qg_score": null}], "content": "Internal fermentation of resistant starch can cause gas when high quantities are consumed. One review estimated that the acceptable daily intake of resistant starch may be as high as 45 grams in adults, an amount exceeding the total recommended intake for dietary fiber of 25\u201338 grams per day. Resistant starch may contribute to colon health by increasing regularity, reducing pH, and producing short-chain fatty acids, among which butyrate is a primary energy source for colonic cells.\nIn its various forms, resistant starch is digested and/or fermented variably, leading to preliminary research of resistant starch subtypes on disease risk. For example, although effects on weight management have been implicated, there is no evidence that resistant starch has an effect on human weight or energy balance,<ref name=zhang/> and it is not known if resistant starch has any part to play in helping treat obesity-related disease.\nWhen isolated resistant starch is used to substitute for flour in foods, the glycemic response of that food is reduced. \nThere is preliminary evidence that resistant starch, used as a substitute for refined carbohydrate, may increase insulin sensitivity and may reduce the risk of type 2 diabetes. The U.S. Food and Drug Administration requires claims that resistant starch can reduce the risk of type 2 diabetes to be qualified with a declaration that scientific evidence in support of this claim is limited.\nRS2 resistant starch from high amylose corn helps to treat diarrhea when delivered in oral rehydration solutions to people with cholera, rotavirus, and other diarrheal diseases.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Health effects", "sub_heading": "Health effects", "_id": "74--1---1---1", "title": "Resistant Starch May Reduce the Risk of Type 2 Diabetes."}
{"qas": [{"question": "Why do some foods have more starch than others?", "answer": ""}, {"question": "Why are smaller starch granules better for enzyme digestion?", "answer": "larger percentage of surface area", "ae_score": -1.3773886002517195, "qg_score": null}, {"question": "Why are smaller starch granules better for enzyme digestion?", "answer": "larger percentage of surface area", "ae_score": -1.3773886002517195, "qg_score": null}], "content": "Plants produce starch with different types of structure and shape characteristics which may affect digestion. For instance, smaller starch granules are more available to enzyme digestion because the larger percentage of surface area increases the enzyme binding rate.\nStarch consists of amylose and amylopectin which affect the textural properties of manufactured foods. Starches with high amylose content generally have increased resistant starch.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Starch structure", "sub_heading": "Starch structure", "_id": "74--2---1---1", "title": "Starch \u2014 Types of Structure and Shape"}
{"qas": [{"question": "What is Resistant Starch?", "answer": ""}, {"question": "What does rs stand for in the medical term?", "answer": "Resistant starch", "ae_score": -0.19744676438564582, "qg_score": null}, {"question": "What does rs stand for in the medical term?", "answer": "Resistant starch", "ae_score": -0.19744676438564582, "qg_score": null}], "content": "Resistant starch (RS) is any starch or starch digestion products that are not digested and absorbed in the stomach or small intestine and pass on to the large intestine. RS has been categorized into four types:", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Definition and categorization", "sub_heading": "Definition and categorization", "_id": "74--3---1---1", "title": "Resistant starch (RS) is a starch or starch digestion product that"}
{"qas": [{"question": "Why does boiling a potato make it more resistant to digestive enzymes?", "answer": ""}, {"question": "What is the percentage of resistant starch in milled wheat flour?", "answer": "2%", "ae_score": -0.5798534007476834, "qg_score": null}, {"question": "What is the percentage of resistant starch in milled wheat flour?", "answer": "2%", "ae_score": -0.5798534007476834, "qg_score": null}], "content": "Processing may affect the natural resistant starch content of foods.  In general, processes that break down structural barriers to digestion reduce resistant starch content, with greater reductions resulting from processing. Whole grain wheat may contain as high as 14% resistant starch, while milled wheat flour may contain only 2%. Resistant starch content of cooked rice may decrease due to grinding or cooking.\nOther types of processing increase resistant starch content. If cooking includes excess water, the starch is gelatinized and becomes more digestible. However, if these starch gels are then cooled, they can form starch crystals resistant to digestive enzymes (Type RS3 or retrograded resistant starch), such as those occurring in cooked and cooled cereals or potatoes (e.g., potato salad). Cooling a boiled potato overnight increases the amount of resistant starch.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Processing effects", "sub_heading": "Processing effects", "_id": "74--4---1---1", "title": "Resistant Starch Content of Foods"}
{"qas": [{"question": "What is the difference between resistant starch and regular fiber?", "answer": ""}, {"question": "What are the two types of resistant starch?", "answer": "functional fiber", "ae_score": -0.5063207275108501, "qg_score": null}, {"question": "What are the two types of resistant starch?", "answer": "functional fiber", "ae_score": -0.5063207275108501, "qg_score": null}], "content": "Resistant starch is considered both a dietary fiber and a functional fiber, depending on whether it is naturally in foods or added. Although the U.S. Institute of Medicine has defined total fiber as equal to functional fiber plus dietary fiber, U.S. food labeling does not distinguish between them.\nThe Institute of Medicine Panel on the Definition of Dietary Fiber proposed two definitions: functional fiber as \"isolated, nondigestible carbohydrates that have beneficial physiological effects in humans\", and dietary fiber as \"nondigestible carbohydrates and lignin that are intrinsic and intact in plants.\"  They also proposed that the prior classifications of soluble versus insoluble be phased out and replaced with viscous versus fermentable for each specific fiber.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Nutritional information", "sub_heading": "Nutritional information", "_id": "74--5---1---1", "title": "Dietary Fiber vs. Functional Fiber"}
{"qas": [{"question": "Why do black people eat so much starch compared to white people?", "answer": ""}, {"question": "What is the main source of resistance starch?", "answer": "flour", "ae_score": -0.37167074836572794, "qg_score": null}, {"question": "What is the main source of resistance starch?", "answer": "flour", "ae_score": -0.37167074836572794, "qg_score": null}], "content": "Starch has been consumed by people and animals for thousands of years.  Thus, foods containing resistant starch are already commonly consumed.\nIt has been estimated that average resistant starch intake in developed countries ranges from 3-6 grams/day for Northern Europeans, Australians and Americans., 8.5 grams/day for Italians and 10-15 grams/day in Indian and Chinese diets. The higher consumption of starch-containing foods like pasta and rice likely accounts for higher intake of resistant starch in Italy, India and China.\nSeveral studies have found that the traditional African diet is high in resistant starch. Rural black South Africans consume an average of 38 grams of resistant starch per day by having cooked and cooled corn porridge and beans in their diets.\nIsolated and extracted resistant starch and foods rich in resistant starch have been used to fortify foods to increase their dietary fiber content. Typically, food fortification utilizes RS2 resistant starch from high amylose corn, RS3 resistant starch from cassava and RS4 resistant starch from wheat and potato, as these sources can survive varying degrees of food processing without losing their resistant starch content.\nResistant starch has a small particle size, white appearance, bland flavor and low water-holding capacity. Resistant starch typically replaces flour in foods such as bread and other baked goods, pasta, cereal and batters because it can produce foods with similar color and texture of the original food. It has also been used for its textural properties in imitation cheese.\nSome types of resistant starch are used as dietary supplements in the United States. RS2 from potato starch and green banana starch maintain their resistance as long as they are consumed raw and unheated. If they are heated or baked, these types of starch become rapidly digestible. RS2 resistant starch from high amylose corn can be consumed raw or baked into foods.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Uses", "sub_heading": "Uses", "_id": "74--6---1---1", "title": "Resistant Starch and Foods fortification"}
{"qas": [{"question": "Why does the human colon need so many carbohydrates?", "answer": ""}, {"question": "Where does resistant starch come from in the digestive system?", "answer": "intestinal fermentation", "ae_score": -0.6581829838289498, "qg_score": null}, {"question": "Where does resistant starch come from in the digestive system?", "answer": "intestinal fermentation", "ae_score": -0.6581829838289498, "qg_score": null}], "content": "By definition, resistant starch does not release glucose within the small intestine, but rather reaches the large intestine, where it is consumed or fermented by colonic bacteria (gut microbiota).\nOn a daily basis, human intestinal microbiota encounters more carbohydrates than any other dietary component. This includes resistant starch, non-starch polysaccharide fibers, oligosaccharides, and simple sugars which have significance to colon health.\nThe fermentation of resistant starch produces short-chain fatty acids, including acetate, propionate, and butyrate and increased bacterial cell mass. The short-chain fatty acids are produced in the large intestine where they are rapidly absorbed from the colon, then are metabolized in colonic epithelial cells, liver or other tissues. The fermentation of resistant starch produces more butyrate than other types of dietary fibers.\nModest amounts of gases such as carbon dioxide, methane, and hydrogen are also produced in intestinal fermentation, with one review estimating that daily intake of resistant starch can be as high as 45 grams/day in adults before gas production becomes problematic.", "page_name": "Resistant starch", "page_id": "Resistant%20starch", "heading": "Physiological effects", "sub_heading": "Physiological effects", "_id": "74--7---1---1", "title": "Resistance Starch and the Effects on Colon Health"}
{"qas": [{"question": "What exactly is happening when my ears start ringing?", "answer": ""}, {"question": "What is the largest disability claim in the military?", "answer": "Tinnitus", "ae_score": -0.1867953143338648, "qg_score": null}, {"question": "What is the most common cause of hearing loss in the military?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "An estimated 50 million Americans have some degree of tinnitus in one or both ears; 16 million of them have symptoms serious enough for them to see a doctor or hearing specialist. As many as 2 million become so debilitated by the unrelenting ringing, hissing, chirping, clicking, whooshing or screeching, that they cannot carry out normal daily activities.\nTinnitus is the largest single category for disability claims in the military, with hearing loss a close second. The third largest category is post-traumatic stress disorder, which itself may be accompanied by tinnitus and may exacerbate it.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Signs and symptoms", "sub_heading": "Tinnitus", "_id": "75--0--1---1", "title": "Tinnitus is the largest single category of disability claims in the United States"}
{"qas": [{"question": "Why do people with hearing impairment live longer than people without hearing impairment?", "answer": ""}, {"question": "What percentage of noise-induced hearing loss workers are deaf?", "answer": "13%", "ae_score": -0.7342319064250431, "qg_score": null}, {"question": "What is the effect of hearing loss in the brain?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "NIHL has implications on quality of life that extend beyond related symptoms and the ability to hear. The annual disability-adjusted life years (DALYs) were estimated for noise-exposed U.S. workers.  DALYs represent  the number of healthy years lost due to a disease or other health condition. They were defined by the 2013 Global Burden of Disease (GBD) Study. The DALYs calculation accounts for life limitations experienced because of hearing loss as a lost portion of a healthy year of life. So the results indicate the number of healthy years lost by a group of people over a specific time period.\nNIOSH used DALYs to estimate the impact of hearing loss on quality of life in the CDC ''Morbidity and Mortality Weekly Report'' article \u201cHearing Impairment Among Noise-Exposed Workers in the United States, 2003-2012.\u201d  It reported that 2.5 healthy years were lost each year for every 1,000 noise-exposed U.S. workers because of hearing impairment (hearing loss that impacts day-to-day activities). These lost years were shared among the 13% of workers with hearing impairment (about 130 workers out of each 1,000 workers). Mining, Construction and Manufacturing workers lost more healthy years than workers in other industry sectors; specifically and respectively in those sectors, 3.5, 3.1 and 2.7 healthy years were lost each year for every 1,000 workers.\nThe negative impacts of NIHL on one\u2019s ability to reciprocate communication, socialize and interact with society are largely invisible. Hearing loss, in general, is not just an issue of volume; individuals may experience difficulty in understanding what is said over the phone, when several people are talking at once, in a large space, or when the speaker\u2019s face cannot be seen.  Subsequently, challenging social interactions can negatively lead to decreased self-esteem, shame, and fear. This can be more acutely felt by those who experience hearing impairment or loss earlier in life, rather than later when it is more socially accepted. Such psychosocial states, regardless of age, can lead to social isolation, which is known to negatively impact one\u2019s overall health and well-being. The compounding impacts can also lead to depression, especially if hearing impairment leads to tinnitus. Research suggests that those with hearing impairment or loss may be at a greater risk for deterioration of quality of life, as captured by a quote from Helen Keller: \u201cBlindness cuts us off from things, but deafness cuts us off from people.\u201d Hearing impairment and loss of hearing, regardless of source or age, also limits experiencing the many benefits of sound on quality of life. In addition to the interpersonal social benefits, new studies suggest the effects of nature sounds, such as birds chirping and water, can positively affect an individual\u2019s capacity to recover after being stressed or to increase cognitive focus.\nHearing loss is typically quantified by results from an audiogram; however, the degree of loss of hearing does not predict the impact on one\u2019s quality of life. The impact that NIHL can have on daily life and psychosocial function can be assessed and quantified using a validated questionnaire tool, such as the Hearing Handicap Inventory for the Elderly (HHIE). The HHIE is considered a \u201cuseful tool for quantifying the perceived emotional and social/situational consequences of hearing loss.\u201d The original tool was designed to test adults 65 years of age and older; however, modified versions exist. For adults the Hearing Handicap Inventory for Adults (HHIA) can be used and for adolescents the modified 28-item Hearing Environments And Reflection on Quality of Life (HEAR-QL-28) can be used. The HHIA, for example, is a 25-item questionnaire that asks both social and emotional-specific questions such as: Does a hearing problem cause you to avoid groups of people?\u201d (social) and \u201cDoes a hearing problem cause you to feel frustrated when talking to members of your family?\u201d (emotional). Response options are yes, no and sometimes.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Signs and symptoms", "sub_heading": "Quality of life", "_id": "75--0--3---1", "title": "The Impact of Hearing Impairment and Loss of Hearing on Quality of Life"}
{"qas": [{"question": "What is the difference between acute acoustic trauma and NIHL?", "answer": ""}, {"question": "What is the loudness level from which a sound starts to be felt as too loud?", "answer": "discomfort threshold", "ae_score": -0.45322148764538944, "qg_score": null}, {"question": "What is the loudness level from which a sound starts to be felt as too loud?", "answer": "discomfort threshold", "ae_score": null, "qg_score": null}], "content": "NIHL caused by acute acoustic trauma refers to permanent cochlear damage from a one-time exposure to excessive sound pressure. This form of NIHL commonly results from exposure to high-intensity sounds such as explosions, gunfire, a large drum hit loudly, and firecrackers.\nThe discomfort threshold is the loudness level from which a sound starts to be felt as \"too loud\" and thus painful by an individual. Industry workers tend to have a higher discomfort threshold (i.e. the sounds must be louder to feel painful than for non-industry workers), but the sound is just as harmful to their ears. Industry workers often suffer from NIHL because the discomfort threshold is not a relevant indicator of the harmfulness of a sound.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Cause", "sub_heading": "Cause", "_id": "75--1--0---1", "title": "NIHL Caused by Acute Acoustic Trauma"}
{"qas": [{"question": "Gradually developing NIHL?", "answer": ""}, {"question": "What is the term for permanent cochlear damage from repeated exposure to loud sounds over?", "answer": "Gradually developing NIHL", "ae_score": -0.9531963578231453, "qg_score": null}, {"question": "What is the most common cause of noise-induced hearing loss?", "answer": "acoustic trauma", "ae_score": null, "qg_score": null}], "content": "Gradually developing NIHL refers to permanent cochlear damage from repeated exposure to loud sounds over a period of time. Unlike acoustic trauma, this form of NIHL does not occur from a single exposure to a high-intensity sound pressure level. Gradually developing NIHL can be caused by multiple exposures to excessive noise in the workplace or any source of repetitive, frequent exposures to sounds of  excessive volume, such as home and vehicle stereos, concerts, nightclubs, and personal media players.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Cause", "sub_heading": "Gradually developing", "_id": "75--1--1---1", "title": "Gradually developing NIHL"}
{"qas": [{"question": "Why do people with hearing loss tend to have a harder time hearing than people without hearing loss?", "answer": ""}, {"question": "How long do you have to work to prevent hearing loss?", "answer": "8 hours per day", "ae_score": -0.4285330652530272, "qg_score": null}, {"question": "What is the effect of noise exposure on hearing?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "About 22 million workers are exposed to hazardous noise, with additional millions exposed to solvents and metals that could put them at increased risk for hearing loss. Occupational hearing loss is one of the most common occupational diseases. 49% of male miners have hearing loss by the age of 50. By the age of 60, this number goes up to 70%. Construction workers also suffer an elevated risk. A screening program focused on construction workers employed at US Department of Energy facilities found 58% with significant abnormal hearing loss due to noise exposures at work. Occupational hearing loss is present in up to 33% of workers overall. Occupational exposure to noise causes 16% of adult disabling hearing loss worldwide.\nThe following is a list of occupations that are most susceptible to hearing loss:\nMusicians, from classical orchestras to rock groups, are exposed to high decibel ranges. Some rock musicians experience noise-induced hearing loss from their music, and some studies have found that \"symphonic musicians suffer from hearing impairment and that the impairment might be ascribed to symphonic music.\"\nMusic-induced hearing loss is still a controversial topic for hearing researchers. While some populational studies have shown that the risk for hearing loss increases as music exposure increases, other studies found little to no correlation between the two.<ref name=tm/> Experts at the 2006 \"Noise-Induced Hearing Loss in Children at Work and Play\" Conference agreed that further research into this field was still required before making a broad generalization about music-induced hearing loss.\nGiven the extensive research suggesting that industrial noise exposure can cause sensorineural hearing loss a link between hearing loss and music exposures of similar level and duration (to industrial noise) seems highly plausible. Determining which individuals or groups are at risk for such exposures may be a difficult task. Recent research suggests that despite concerns about the proliferation of personal music players, in fact discos, concerts and live music events may be more hazardous to youth's hearing. People from ages to 6\u201319 have an approximately 15% rate of hearing loss. Recommendations for musicians to protect their hearing have been released in 2015.\nIn the United States, the Occupational Safety and Health Administration (OSHA) describes standards for occupational noise exposure in articles 1910.95 and 1926.52. OSHA states that an employer must implement hearing conservation programs for employees if the noise level of the workplace is equal to or above 85 dB(A) for an averaged eight-hour time period. OSHA also states that \"exposure to impulsive or impact noise should not exceed 140 dB peak sound pressure level\".  The National Institute for Occupational Safety and Health (NIOSH) recommends that all worker exposures to noise should be controlled below a level equivalent to 85 dBA for eight hours to minimize occupational noise induced hearing loss. NIOSH also recommends a 3 dBA exchange rate so that every increase by 3 dBA doubles the amount of the noise and halves the recommended amount of exposure time.The United States Department of Defense (DoD) instruction 605512 has some differences from OSHA 1910.95 standard, for example, OSHA 1910.95 uses a 5 dB exchange rate and DoD instruction 605512 uses a 3 dB exchange rate.\nThere are programs that seek to increase compliance and therefore effectiveness of hearing protection rules; the programs include the use of hearing tests and educating people that loud sound is dangerous\nEmployees are required to wear hearing protection when it is identified that their eight-hour time weighted average (TWA) is above the exposure action value of 90 dB. If subsequent monitoring shows that 85 dB is not surpassed for an eight-hour TWA, the employee is no longer required to wear hearing protection.\nIn the European Union, directive 2003/10/EC mandates that employers shall provide hearing protection at noise levels exceeding 80 dB(A), and that hearing protection is mandatory for noise levels exceeding 85 dB(A). Both values are based on 8 hours per day, with a 3 dB exchange rate.\nA 2012 Cochrane review found low-quality evidence that legislation to reduce noise in the workplace was successful in reducing exposure both immediately and long-term.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Cause", "sub_heading": "Workplace", "_id": "75--1--2---1", "title": "Noise-Induced Hearing Loss in the Workplace"}
{"qas": [{"question": "How does cell death cause hearing loss?", "answer": ""}, {"question": "What can be used to help prevent hearing loss?", "answer": "antioxidant vitamins", "ae_score": -1.002433451668556, "qg_score": null}, {"question": "What type of hearing loss is caused by overstimulation of hair cells?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "When the ear is exposed to excessive sound levels or loud sounds over time, the overstimulation of the hair cells leads to heavy production of reactive oxygen species, leading to oxidative cell death. In animal experiments, antioxidant vitamins have been found to reduce hearing loss even when administered the day after noise exposure. They were not able to fully prevent it. Damage ranges from exhaustion of the \"hair\" (hearing) cells in the ear to loss of those cells NIHL is therefore the consequence of overstimulation of the hair cells and supporting structures. Structural damage to hair cells (primarily the outer hair cells) will result in hearing loss that can be characterized by an attenuation and distortion of incoming auditory stimuli.\nDuring cell death \u2018scars\u2019 develop, which prevent potassium rich fluid on the endolymph from mixing with the fluid on the basal domain. The fluids are kept from mixing because the potassium rich fluid is toxic to the neuronal endings and can damage hearing of the entire ear. If the endolymph fluid mixes with the fluid on the basal domain the neurons become depolarized, causing complete hearing loss. In addition to complete hearing loss, if the area is not sealed and leakage continues further tissue damage will occur. The \u2018scars\u2019 that form to replace the damaged hair cell are caused by supporting hair cells undergoing apoptosis and sealing the reticular lamina, which prevents fluid leakage. The cell death of two supporting hair cells rapidly expands their apical domain, which compresses the hair cell beneath its apical domain.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Mechanisms", "sub_heading": "Mechanisms", "_id": "75--2--0---1", "title": "Hearing Loss During Noise Exposure \u2014 NIHL"}
{"qas": [{"question": "Why do we lose hearing when we listen to music too loud?", "answer": ""}, {"question": "What is it called when a part of the postsynaptic dendrite ruptures?", "answer": "excitotoxicity", "ae_score": -0.34217921450516026, "qg_score": null}, {"question": "What is it called when a part of the postsynaptic dendrite ruptures?", "answer": "excitotoxicity", "ae_score": null, "qg_score": null}], "content": "Recent studies have investigated additional mechanisms of NIHL involving delayed or disabled electrochemical transmission of nerve impulses from the hair cell to and along the auditory nerve. In cases of extreme acute acoustic trauma, a portion of the postsynaptic dendrite (where the hair cell transfers electrochemical signal to the auditory nerve) can rupture from overstimulation, temporarily stopping all transmission of auditory input to the auditory nerve. This is known as excitotoxicity. Usually, this sort of rupture heals within about five days, resulting in functional recovery of that synapse. While healing, an over-expression of glutamate receptors can result in temporary tinnitus, or ringing in the ears. Repeated ruptures at the same synapse may eventually fail to heal, leading to permanent hearing loss.\nAcoustic over-exposure can also result in decreased myelination at specific points on the auditory nerve. Myelin, an insulating sheath surrounding nerve axons, expedites electrical impulses along nerves throughout the nervous system. Thinning of the myelin sheath on the auditory nerve significantly slows the transmission of electrical signals from hair cell to auditory cortex, reducing comprehension of auditory stimuli by delaying auditory perception, particularly in noisy environments.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Mechanisms", "sub_heading": "Nerve damage", "_id": "75--2--1---1", "title": "NIHL and acoustic trauma"}
{"qas": [{"question": "Why is it that when you listen to music at 4000 Hz, you can't hear it in your ears?", "answer": ""}, {"question": "Where did the term noise-induced hearing loss come from?", "answer": "the University of Iowa", "ae_score": null, "qg_score": null}, {"question": "What is the cause of noise induced hearing loss?", "answer": "acoustic trauma", "ae_score": null, "qg_score": null}], "content": "Both NIHL caused by acoustic trauma and gradually-developed-NIHL can often be characterized by a specific pattern presented in audiological findings. NIHL is generally observed to affect a person's hearing sensitivity in the higher frequencies, especially at 4000 Hz. \"Noise-induced impairments are usually associated with a notch-shaped high-frequency sensorineural loss that is worst at 4000 Hz, although the notch often occurs at 3000 or 6000 Hz, as well\". Doctoral students at the University of Iowa have termed this notch, specific to a noise-induced etiology, a \"muna.\" The symptoms of NIHL are usually presented equally in both ears.\nThis typical 4000 Hz notch is due to the transfer function of the ear. Indeed, as any object facing a sound, the ear acts as a passive filter (-although the inner ear is not an absolute passive filter, as the outer hair cells provide active mechanisms). A passive filter is a low pass : the high frequencies are more absorbed by the object, as high frequencies impose a higher pace of compression-decompression to the object. Thus, the high frequency harmonics of a sound are more harmful to the inner-ear.\nHowever, not all audiological results from people with NIHL match this typical notch. Often a decline in hearing sensitivity will occur at frequencies other than at the typical 3000\u20136000 Hz range. Variations arise from differences in people's ear canal resonance, the frequency of the harmful acoustic signal, and the length of exposure. As harmful noise exposure continues, the commonly affected frequencies will broaden and worsen in severity. \"NIHL usually occurs initially at high frequencies (3, 4, or 6 kHz), and then spreads to the low frequencies (0.5, 1, or 2 kHz)\".", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "75--3---1---1", "title": "NIHL : a notch-shaped high-frequency noise-induced hearing loss"}
{"qas": [{"question": "How do noise-cancelling headphones work?", "answer": ""}, {"question": "How much attenuation can earplugs and earmuffs provide?", "answer": "10 dB to 40 dB", "ae_score": -1.2107434547403177, "qg_score": null}, {"question": "How much attenuation can earplugs and earmuffs provide?", "answer": "10 dB to 40 dB", "ae_score": -1.2107434547403177, "qg_score": null}], "content": "Personal noise reduction devices can be passive, active or a combination. Passive ear protection includes earplugs or earmuffs which can block noise up to a specific frequency. Earplugs and earmuffs can provide the wearer with 10 dB to 40 dB of attenuation. However, use of earplugs is only effective if the users have been educated and use them properly; without proper use, protection falls far below manufacturer ratings. Higher consistency of performance has been found with custom-molded earplugs. Because of their ease of use without education, and ease of application or removal, earmuffs have more consistency with both compliance and noise attenuation. Active ear protection (electronic pass-through hearing protection devices or EPHPs) electronically filter out noises of specific frequencies or decibels while allowing the remaining noise to pass through.<ref name=Rajguru/>", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Prevention", "_id": "75--4--0---1", "title": "Noise-induced hearing loss | Prevention"}
{"qas": [{"question": "What is the difference between tailored and tailored hearing aids?", "answer": ""}, {"question": "What percentage of parents did not believe their children were at risk for hearing loss?", "answer": "96.3%", "ae_score": -0.31670298949201053, "qg_score": null}, {"question": "What is the common name for noise-induced hearing loss?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Education is key to prevention. Before hearing protective actions will take place, a person must understand they are at risk for NIHL and know their options for prevention. Hearing protection programs have been hindered by people not wearing the protection for various reasons, including the desire to converse, uncomfortable devices, lack of concern about the need for protection, and social pressure against wearing protection. Although youth are at risk for hearing loss, one study found that 96.3% of parents did not believe their adolescents were at risk, and only 69% had talked to their children about hearing protection; those aware of NIHL risks were more likely to talk to their teens.\nA systematic review of the effectiveness of interventions to promote the use of hearing protection devices such as earplugs and earmuffs among workers found that tailored interventions improve the average use of such devices when compared with no intervention. Tailored interventions involve the use of communication or other types of interventions that are specific to an individual or a group and aim to change behavior. Mixed interventions such as mailings, distribution of hearing protection devices, noise assessments, and hearing testing are also more effective in improving the use of hearing protection devices compared with hearing testing alone. Programs that increased the proportion of workers wearing hearing protection equipment did reduce overall hearing loss. However, a 2012 Cochrane review found that hearing loss prevention programs have not shown as much success with educational messages as with use of hearing protective devices; better implementation and reinforcement of these programs are needed.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Education", "_id": "75--4--1---1", "title": "Hearing Loss Prevention Programs Need to Improve Hearing Protection"}
{"qas": [{"question": "Why is it bad to wear earphones over your ears?", "answer": ""}, {"question": "When did the study on noise-induced hearing loss come out?", "answer": "2012", "ae_score": -0.5893235424834441, "qg_score": null}, {"question": "When did the study on noise-induced hearing loss come out?", "answer": "2012", "ae_score": -0.5893235424834441, "qg_score": null}], "content": "A 2012 study looked at the safety of using personal listening devices as well as the comparative safety of earbuds, in-ear earphones, and supra-aural earphones (over the ear). The study found that since supra-aural earphones blocked out background noise better than the other earphones, sound was listened to at a quieter, and safer volume. Ear buds blocked the least amount of environmental noise and seemed to result in the most noise pressure. Recommendations for safe use of personal listening devices included: keeping the volume at the lowest possible setting, taking care to keep volume below 50% even in loud settings such as buses or airplanes, and selecting an earphone that is better at attenuating environmental noise.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Personal listening devices", "_id": "75--4--2---1", "title": "Ear buds, in-ear earphones, and supra-aural ear"}
{"qas": [{"question": "Why do people in the US have to wear ear protection when they work?", "answer": ""}, {"question": "What does hcp stand for in the workplace?", "answer": "hearing conservation program", "ae_score": -0.8620347120251028, "qg_score": null}, {"question": "What is it called when you hear too much noise?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Workers in general industry who are exposed to noise levels above 85 dBA are required by the Occupational Safety and Health Administration (OSHA) to be in a hearing conservation program (HCP), which includes noise measurement, noise control, periodic audiometric testing, hearing protection, worker education, and record keeping. Twenty-four states, Puerto Rico, and the U.S. Virgin Islands have OSHA-approved state plans and have adopted their own standards and enforcement policies. Most of these state standards are identical to those of federal OSHA. However, some states have adopted different standards or may have different enforcement policies.  Most health and safety regulations are designed to keep damage risk within \u201cacceptable limits\u201d \u2014 that is, some people are likely to incur a hearing loss even when exposed to less than the maximum daily amount of noise specified in a regulation. Hearing conservation programs in other arenas (schools, military) have become more common, and it has been established that unsafe listening behaviors, such as listening to loud noise for extended periods of time without protection, persist despite knowledge of potential hearing loss effects.\nHowever, it is understood that HCPs are designed to change behavior, which is known to be a complex issue that requires a multi-faceted approach. According to Keppler et al. in their 2015 study of such programming, they cite the necessary attitude change towards the susceptibility of risk and degree of severity of hearing loss. Among young adults, the concept of severity is most crucial because it has been found that behavior change may not occur unless an individual experiences NIHL or similarly related NIHL tinnitus,<ref name=Keppler/> furthering warranting a multi-pronged approach based on hearing conservation programming and education.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Hearing conservation programs", "_id": "75--4--3---1", "title": "Hearing Conservation Programs: A Multi-Phase Approach"}
{"qas": [{"question": "How do we know how loud our ears are?", "answer": ""}, {"question": "Who partnered with the national hearing conservation association to establish the safe-in-sound Excellence?", "answer": "The National Institute for Occupational Safety and Health", "ae_score": null, "qg_score": null}, {"question": "What is the medical term for noise induced hearing loss?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "There are a variety of public awareness programs as well as available curricula to teach awareness messages becoming available. One such program is Dangerous Decibels, whose mission is to \u201csignificantly reduce the prevalence of noise induced hearing loss and tinnitus through exhibits, education and research. We\u2019re hEAR for You is a small non-profit that distributes information and ear plugs at concert and music festival venues. The Buy Quiet program was created to combat occupational noise exposures by promoting the purchase of quieter tools and equipment and encourage manufacturers to design quieter equipment. The National Institute for Occupational Safety and Health partnered with the National Hearing Conservation Association in 2007 to establish the Safe-in-Sound Excellence and Innovation in Hearing Loss Prevention Awards to recognize organizations that are successfully implementing hearing loss prevention concepts into their daily routines.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Other initiatives", "_id": "75--4--4---1", "title": "Hearing Loss Prevention Programs & Programs"}
{"qas": [{"question": "Is it possible to reduce hearing loss by taking magnesium supplements?", "answer": ""}, {"question": "What is the most common mineral that can be used to prevent hearing loss?", "answer": "magnesium", "ae_score": -0.7907200749617775, "qg_score": null}, {"question": "What is the medical term for noise-induced hearing loss?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "There is evidence that hearing loss can be minimized by taking high doses of magnesium for a few days, starting as soon as possible after exposure to the loud noise. A magnesium-high diet also seems to be helpful as an NIHL-preventative if taken in advance of exposure to loud noises. Consuming sizable amounts of magnesium can be potentially harmful, so this treatment should be followed with caution.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Pharmacalogical", "_id": "75--4--5---1", "title": "Magnesium-High Diet for Hearing Loss Preventatives"}
{"qas": [{"question": "How does the cochlea not get damaged by loud noises?", "answer": ""}, {"question": "What is the scientific name for noise induced hearing loss?", "answer": "Physiological response", "ae_score": -0.617210514254554, "qg_score": null}, {"question": "The protective effect of exposure to loud noises is known as?", "answer": "noise conditioning", "ae_score": null, "qg_score": null}], "content": "Despite different people having different thresholds for what noises are painful, this pain threshold had no correlation with which noises cause hearing damage. The ear can not get more resistant to noise harmfulness by training it to noise. The cochlea is partially protected by the acoustic reflex, but being frequently exposed to noise does not lower the reflex threshold. It had been observed that noise conditioning (i.e. exposure to loud non-traumatizing noise) several hours prior to the exposure to traumatizing sound level, significantly reduced the damages inflicted to the hair-cells. The same \u201cprotective effect\" was also observed with other stressors such as heat-shock conditioning and stress (by restraint) conditioning. This \u201cprotective effect\" only happens if the traumatizing noise is presented within an optimum interval of time after the sound-conditioning session (-24 hours for a 15 min. sound-conditioning; no more protection after 48 hours).This \u201cprotective effect\u201d had long been thought to involve the active mechanisms of the outer hair cells and the efferent system commanding them. The contractile effect of the outer hair cells, activated by the efferent nervous system has been proven to provide a protective effect against acoustic trauma. \n However, a 2006 study revealed a different protective mechanism for stress conditioning. The study revealed that the stressor (sound, heat, or stress) conditioning increases the receptibility to glucocorticoid, a kind of anti-inflammatory hormone. The effects of glucocorticoid thus mitigate the inflammation from an acoustic trauma that can lead to hearing loss. In fact, high doses of corticoids are often prescribed by physicians after an acoustic-trauma in order to mitigate the inflammatory response.\nSummarized, sound (or other stressor) conditioning is a pre-emptive medication against cochlea inflammation. It does not make the ear more resistant to noise. It reduces the inflammation caused by the acoustic trauma, which would cause subsequent damages to hair cells. While an anti-inflammatory medication would increase the quantity of anti-inflammatory hormone in the whole body, noise conditioning increases the number of receptors for the anti-inflammatory hormone, and only in the areas where it is much needed (i.e. cochlea).\n'''Physiological response'''", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Prevention", "sub_heading": "Sound or stress training", "_id": "75--4--6---1", "title": "Sound, Heat, and Stress Conditioning: A Pre-emptive Medication for Hearing Damage"}
{"qas": [{"question": "Why is it that when you hear a gunshot or a firework, you can feel it in your body?", "answer": ""}, {"question": "Which antioxidant has been shown to reduce tts and pts?", "answer": "Ebselen", "ae_score": -0.48111679699424853, "qg_score": null}, {"question": "What causes hearing loss in the inner ear?", "answer": "overstimulation of hair cells", "ae_score": null, "qg_score": null}], "content": "Treatment options that offer \u201ccures\u201d for NIHL are under research and development. Currently there are no commonly used cures, but rather assistive devices and therapies to try and manage the symptoms of NIHL.\nSeveral clinical trials have been conducted to treat temporary NIHL occurring after a traumatic noise event, such as a gunshot or firework. In 2007, individuals with acute acoustic trauma after firecracker exposure were injected intratympanically with a cell permeable ligand, AM-111. The trial found AM-111 to have a therapeutic effect on at least 2 cases of those with acute trauma. Treatment with a combination of prednisolone and piracetam appeared to rescue patients with acute trauma after exposure to gunshots. However, those who received the treatment within an hour of exposure had higher rates of recovery and significantly lower threshold shifts compared to those who received treatment after 1 hour.\nAdditionally, clinical trials using antioxidants after a traumatic noise event to reduce reactive oxygen species have displayed promising results. Antibiotic injections with allopurinol, lazaroids, \u03b1-D-tocopherol, and mannitol were found to reduce the threshold shift after noise exposure. Another antioxidant, Ebselen, has been shown to have promising results for both TTS and PTS. Ebselen mimics gluthathione peroxide, an enzyme that has many functions, including scavenging hydrogen peroxide and reactive oxygen species. After noise exposure, gluthathione peroxide decreases in the ear. An oral administration of ebselen in both preclinical tests on guinea pigs and human trials indicate that noise induced TTS and PTS was reduced.\nAt the present time, no established clinical treatments exist to reverse the effects of permanent NIHL. However, current research for the possible use of drug and genetic therapies look hopeful. In addition, management options such as hearing aids and counseling exist.\nMany studies have been conducted looking at regeneration of hair cells in the inner ear. While hair cells are generally not replaced through cell regeneration, mechanisms are being studied to induce replacement of these important cells. One study involves the replacement of damaged hair cells with regenerated cells, via the mechanism of gene transfer of atonal gene Math1 to pluripotent stem cells within the inner ear. Other atonal genes are being studied to induce regeneration of hair cells in the inner ear.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Treatment", "sub_heading": "Treatment", "_id": "75--5---1---1", "title": "NIHL Treatment Options and Treatment Options"}
{"qas": [{"question": "What is the prognosis for hearing loss?", "answer": ""}, {"question": "What is sensorineural hearing loss caused by?", "answer": "excessive, loud noise", "ae_score": -0.9889106748127064, "qg_score": null}, {"question": "What is it called when you hear loud noises?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "For people living with NIHL, there are several management options that can improve the ability to communicate including counseling and the use of hearing aids and FM systems. The prognosis has improved with the recent advancements in digital hearing aid technology, such as directional microphones, open-fit hearing aids, and more advanced algorithms. Annual audiological evaluations are recommended to monitor any changes in a patient's hearing and to modify hearing-aid prescriptions.\nA systematic-review conducted by the American Academy of Audiology Task Force On the Health-Related Quality of Life Benefits of Amplification in Adults found the use of hearing aids to increase quality of life. The review pertained to adults who experienced sensorineural hearing loss, which can be caused by excessive, loud noise.", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Management", "sub_heading": "Management", "_id": "75--6---1---1", "title": "Hearing Aids and FM Systems for Hearing Loss"}
{"qas": [{"question": "Why do we lose hearing when we listen to music too loud?", "answer": ""}, {"question": "How many young people are at risk for hearing loss?", "answer": "1.1 billion", "ae_score": -0.3826832663953335, "qg_score": null}, {"question": "What is it called when you hear loud noises?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Currently, the World Health Organization estimates that nearly 360 million people suffer from moderate to profound hearing loss from all causes. Incidence of hearing loss has traditionally been attributed to occupational or firearm-related exposure, however, more recent research suggests that the trend is shifting as prevalence rates increase amongst children and adolescents is increasing. According to a 2015 review, \u201cHearing loss due to recreational exposure to loud sounds\u201d by the WHO World Health Organization (WHO), an estimated 1.1 billion young people may be at risk for hearing loss caused by unsafe listening practices. The over-exposure to excessive loud noise is attributed to recreational exposure, such as the use of personal audio devices with music at high volumes for long durations raises, or social settings such as bars, entertainment and sporting events.\nA review of data from the National Health and Nutrition Examination Survey in the United States found that the prevalence of high frequency hearing loss, which can be noise-induced, among adolescent 12\u201319 years old increased significantly from 3.5% to 5.3% from 1994 until 2006, which equates to 1 in 20 children in the U.S. Although research is still limited, it suggests that increased exposure to loud noise through personal listening devices is a risk factor to this type of acquired hearing loss. The ubiquitous use of smartphones across the world is increasing at a rate \u201cfaster than our ability to assess their potential health consequences.\u201d Despite limited research, it is documented that 90% young adults across U.S. and European surveys have reported use of personal devices for several hours a day at maximum volume. At times, this sound level can be likened to a jet engine, exceeding 120 decibels. Recent research suggests stronger correlations found between extended duration and/or elevated usage of personal listening devices and hearing loss.\nNon-occupational noise exposure is not regulated or governed in the same manner as occupational noise exposure; therefore prevention efforts rely heavily on education awareness campaigns and public policy. The WHO cites that nearly half of those affected by hearing loss could have been prevented through primary prevention efforts such as:", "page_name": "Noise-induced hearing loss", "page_id": "Noise-induced%20hearing%20loss", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "75--7---1---1", "title": "Hearing Loss: The Role of Personal Listening Devices in Hearing Loss Prevention"}
{"qas": [{"question": "What is the difference between a smoothie and a vegetable milkshake?", "answer": ""}, {"question": "What is a dairy smoothie similar to?", "answer": "vegetable milkshake", "ae_score": -0.8719040421795422, "qg_score": null}, {"question": "What is a dairy smoothie similar to?", "answer": "vegetable milkshake", "ae_score": -0.8719040421795422, "qg_score": null}], "content": "In addition to blended fruit/vegetables, smoothies may include other ingredients such as water, crushed ice, fruit juice, sweeteners (e.g. honey, sugar, syrup), dairy products (e.g. milk, yogurt, low fat or cottage cheese, whey powder), plant milk, nuts, nut butter, seeds, tea, chocolate, herbal supplements, or nutritional supplements.\nA smoothie containing dairy products is similar to a vegetable milkshake, though the latter typically contains less fruit and often contains ice cream.", "page_name": "Smoothie", "page_id": "Smoothie", "heading": "Added ingredients", "sub_heading": "Added ingredients", "_id": "76--0---1---1", "title": "Blended Fruit & Vegetable Smoothies"}
{"qas": [{"question": "What is the difference between fruit juice and smoothies?", "answer": ""}, {"question": "What determines the health of a smoothie?", "answer": "ingredients", "ae_score": -0.6275478572002037, "qg_score": null}, {"question": "What determines the health of a smoothie?", "answer": "ingredients", "ae_score": -0.6275478572002037, "qg_score": null}], "content": "The health of a smoothie depends on its ingredients. Many smoothies include large servings of fruits and vegetables which are recommended in a healthful diet. However, too many sweet fruits can lead to too much sugar. Similarly, ingredients such as protein powders, sweeteners, or ice cream are often used in smoothie recipes, but are not necessarily healthful.\nSmoothies include dietary fiber (e.g. pulp, often also skin and seeds) and so are thicker than fruit juice, with a consistency similar to a milkshake. The fiber makes smoothies more healthful than fruit juice alone. Smoothies\u2014particularly green smoothies (which include vegetables)\u2014are often marketed to health-conscious people, for example as a healthier alternative to milkshakes.\nSome commercial smoothies, however, have added sugar, which can more than double their carbohydrate content. The fact that smoothies can be quickly swallowed without chewing makes them less effective in providing a lasting hunger-inhibiting effect than eating the raw fruit/vegetables they contain.", "page_name": "Smoothie", "page_id": "Smoothie", "heading": "Health", "sub_heading": "Health", "_id": "76--1---1---1", "title": "The Health of Smoothies"}
{"qas": [{"question": "Why are green smoothies so popular?", "answer": ""}, {"question": "When did green smoothies start to become popular?", "answer": "early 2000s", "ae_score": -0.19860522379835313, "qg_score": null}, {"question": "When did green smoothies start to become popular?", "answer": "early 2000s", "ae_score": -0.19860522379835313, "qg_score": null}], "content": "Green smoothies consist of typically 40-50% green vegetables\u2014usually raw leafy vegetables such as spinach, kale, swiss chard, collard greens, celery, parsley, or broccoli\u2014the rest being mostly or entirely fruit. Most raw green leafy vegetables are bitter, but this can be ameliorated by suitable choice of vegetables (e.g. baby spinach is almost flavourless) or fruit (e.g. banana softens both the flavour and texture).\nSome blender manufacturers specifically target their products towards making green smoothies, and provide a booklet of green smoothie recipes.\nGreen smoothies have been growing rapidly in popularity since the early 2000s.", "page_name": "Smoothie", "page_id": "Smoothie", "heading": "Green smoothies", "sub_heading": "Green smoothies", "_id": "76--2---1---1", "title": "Green Smoothie Recipes"}
{"qas": [{"question": "What is the difference between a smoothie and a fruit sharbat?", "answer": ""}, {"question": "Who is the founder of smoothie king?", "answer": "Steve Kuhnau", "ae_score": -0.18271266195748495, "qg_score": null}, {"question": "Who is the founder of smoothie king?", "answer": "Steve Kuhnau", "ae_score": -0.18271266195748495, "qg_score": null}], "content": "Smoothies have become increasingly popular worldwide since the 1990s, due in part to being factory-produced (usually in bottles), enabling them to be sold via supermarkets and other mass-market outlets. However, they have a much longer history in various countries.\nHealth food stores on the West Coast of the United States began selling smoothies in the 1930s, thanks to the invention of the electric blender. The actual term 'smoothie' was in use in recipes and trademarks by the mid-1930s.\nBy the late 1960s, smoothies were widely sold across the US by ice cream vendors as well as health food stores. They were mainly made from fruit, fruit juice, and ice, though from the early 1970s, ice milk was sometimes added to create the \"fruit shake\".\nIn 1973 Steve Kuhnau founded Smoothie King. He set up numerous smoothie bars across the United States and popularized adding ingredients such as vitamins and protein powder into the smoothies. As smoothies became more popular and prominent, large companies decided to make pre-bottled smoothies and sell them in supermarkets.\nMany types of smoothie are found in Mediterranean, Middle Eastern and Indian cuisine. Fruit sharbats typically include yogurt and honey. In India, the mango lassi is a smoothie or milkshake including crushed ice, yogurt and sometimes sugar; in South India, pineapple smoothies using crushed ice and sugar (without yogurt) are more popular. Smoothies are also mixed with soft drinks or alcohol to make cocktails.", "page_name": "Smoothie", "page_id": "Smoothie", "heading": "Around the world", "sub_heading": "Around the world", "_id": "76--3---1---1", "title": "Smoothies: A History of the Smoothie Industry"}
{"qas": [{"question": "Why do we get colds?", "answer": ""}, {"question": "How long does it take a febricula to recover?", "answer": "less than a week", "ae_score": -0.39551487465776247, "qg_score": null}, {"question": "How long does it take a febricula to recover?", "answer": "less than a week", "ae_score": -0.39551487465776247, "qg_score": null}], "content": "The pattern of temperature changes may occasionally hint at the diagnosis:\nA neutropenic fever, also called febrile neutropenia, is a fever in the absence of normal immune system function. Because of the lack of infection-fighting neutrophils, a bacterial infection can spread rapidly; this fever is, therefore, usually considered to require urgent medical attention. This kind of fever is more commonly seen in people receiving immune-suppressing chemotherapy than in apparently healthy people.\n''Febricula'' is an old term for a low-grade fever, especially if the cause is unknown, no other symptoms are present, and the patient recovers fully in less than a week.", "page_name": "Fever", "page_id": "Fever", "heading": "Definition", "sub_heading": "Definition", "_id": "77--0--0---1", "title": "''Febricula'' is a low-grade fever"}
{"qas": [{"question": "What is hyperpyrexia?", "answer": ""}, {"question": "What is the medical term for extreme elevation of body temperature?", "answer": "Hyperpyrexia", "ae_score": -0.3861643492801883, "qg_score": null}, {"question": "What is the medical term for extreme elevation of body temperature?", "answer": "Hyperpyrexia", "ae_score": -0.3861643492801883, "qg_score": null}], "content": "Hyperpyrexia is an extreme elevation of body temperature which, depending upon the source, is classified as a core body temperature greater than or equal to 40.0 or. Such a high temperature is considered a medical emergency, as it may indicate a serious underlying condition or lead to significant sequelae (i.e., adverse effects which result from this condition).<ref name=EM01/>  The most common cause of hyperpyrexia is an intracranial hemorrhage.<ref name=Har08/>  Other possible causes include sepsis, Kawasaki syndrome, neuroleptic malignant syndrome, drug overdose, serotonin syndrome, and thyroid storm.  Infections are the most common cause of fevers; however, as the temperature rises other causes become more common.<ref name=EM01/>  Infections commonly associated with hyperpyrexia include roseola, measles and enteroviral infections.  Immediate aggressive cooling to less than 38.9 C has been found to improve survival.<ref name=EM01/>  Hyperpyrexia differs from hyperthermia in that in hyperpyrexia the body's temperature regulation mechanism sets the body temperature above the normal temperature, then generates heat to achieve this temperature, while in hyperthermia the body temperature rises above its set point due to an outside source.", "page_name": "Fever", "page_id": "Fever", "heading": "Definition", "sub_heading": "Hyperpyrexia", "_id": "77--0--1---1", "title": "Hyperpyrexia \u2014 A Medical Emergency"}
{"qas": [{"question": "What is hyperthermia?", "answer": ""}, {"question": "What is the name of a high temperature that is not a fever?", "answer": "Hyperthermia", "ae_score": -0.16087111384849764, "qg_score": null}, {"question": "What is the name of a high temperature that is not a fever?", "answer": "Hyperthermia", "ae_score": -0.16087111384849764, "qg_score": null}], "content": "Hyperthermia is an example of a high temperature that is not a fever.  It occurs from a number of causes including heatstroke, neuroleptic malignant syndrome, malignant hyperthermia, stimulants such as substituted amphetamines and cocaine, idiosyncratic drug reactions, and serotonin syndrome.", "page_name": "Fever", "page_id": "Fever", "heading": "Definition", "sub_heading": "Hyperthermia", "_id": "77--0--2---1", "title": "Hyperthermia is an example of a high temperature that is not a fever,"}
{"qas": [{"question": "What are endogenous cytokines and how do they work?", "answer": ""}, {"question": "What is the substance that causes fever in the body?", "answer": "A pyrogen", "ae_score": -0.5669957703896324, "qg_score": null}, {"question": "What is the substance that causes fever in the body?", "answer": "A pyrogen", "ae_score": -0.5669957703896324, "qg_score": null}], "content": "A pyrogen is a substance that induces fever. These can be either internal (endogenous) or external (exogenous) to the body. The bacterial substance lipopolysaccharide (LPS), present in the cell wall of some bacteria(gram negative), is an example of an exogenous pyrogen. Pyrogenicity can vary: In extreme examples, some bacterial pyrogens known as superantigens can cause rapid and dangerous fevers. Depyrogenation may be achieved through filtration, distillation, chromatography, or inactivation.\nIn essence, all endogenous pyrogens are cytokines, molecules that are a part of the immune system.  They are produced by activated immune cells and cause the increase in the thermoregulatory set point in the hypothalamus. Major endogenous pyrogens are interleukin 1 (\u03b1 and \u03b2) and interleukin 6 (IL-6). Minor endogenous pyrogens include interleukin-8, tumor necrosis factor-\u03b2, macrophage inflammatory protein-\u03b1 and macrophage inflammatory protein-\u03b2 as well as interferon-\u03b1, interferon-\u03b2, and interferon-\u03b3.<ref name=boron-58/> Tumor necrosis factor-\u03b1 also acts as a pyrogen. It is mediated by interleukin 1 (IL-1) release.\nThese cytokine factors are released into general circulation, where they migrate to the circumventricular organs of the brain due to easier absorption caused by the blood\u2013brain barrier's reduced filtration action there. The cytokine factors then bind with endothelial receptors on vessel walls, or interact with local microglial cells. When these cytokine factors bind, the arachidonic acid pathway is then activated.\nOne model for the mechanism of fever caused by exogenous pyrogens includes LPS, which is a cell wall component of gram-negative bacteria. An immunological protein called lipopolysaccharide-binding protein (LBP) binds to LPS. The LBP\u2013LPS complex then binds to the CD14 receptor of a nearby macrophage. This binding results in the synthesis and release of various endogenous cytokine factors, such as interleukin 1 (IL-1), interleukin 6 (IL-6), and the tumor necrosis factor-alpha. In other words, exogenous factors cause release of endogenous factors, which, in turn, activate the arachidonic acid pathway.", "page_name": "Fever", "page_id": "Fever", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "77--3--0---1", "title": "Pyrogenicity of bacterial pyrogens"}
{"qas": [{"question": "How does the febrile response work?", "answer": ""}, {"question": "What is the ultimate mediator of the febrile response?", "answer": "PGE2", "ae_score": -0.24736222496198385, "qg_score": null}, {"question": "What is the ultimate mediator of the febrile response?", "answer": "PGE2", "ae_score": -0.24736222496198385, "qg_score": null}], "content": "PGE2 release comes from the arachidonic acid pathway. This pathway (as it relates to fever), is mediated by the enzymes phospholipase A2 (PLA2), cyclooxygenase-2 (COX-2), and prostaglandin E2 synthase. These enzymes ultimately mediate the synthesis and release of PGE2.\nPGE2 is the ultimate mediator of the febrile response. The set point temperature of the body will remain elevated until PGE2 is no longer present. PGE2 acts on neurons in the preoptic area (POA) through the prostaglandin E receptor 3 (EP3). EP3-expressing neurons in the POA innervate the dorsomedial hypothalamus (DMH), the rostral raphe pallidus nucleus in the medulla oblongata (rRPa), and the paraventricular nucleus (PVN) of the hypothalamus . Fever signals sent to the DMH and rRPa lead to stimulation of the sympathetic output system, which evokes non-shivering thermogenesis to produce body heat and skin vasoconstriction to decrease heat loss from the body surface. It is presumed that the innervation from the POA to the PVN mediates the neuroendocrine effects of fever through the pathway involving pituitary gland and various endocrine organs.", "page_name": "Fever", "page_id": "Fever", "heading": "Pathophysiology", "sub_heading": "PGE2 release", "_id": "77--3--1---1", "title": "The Neuroendocrine Effects of Fever on the Hypothalamus"}
{"qas": [{"question": "Why do we get fever when we exercise?", "answer": ""}, {"question": "What is another name for exercise-associated thermogenesis?", "answer": "non-shivering thermogenesis", "ae_score": -0.780021029059258, "qg_score": null}, {"question": "What is another name for exercise-associated thermogenesis?", "answer": "non-shivering thermogenesis", "ae_score": -0.780021029059258, "qg_score": null}], "content": "The brain ultimately orchestrates heat effector mechanisms via the autonomic nervous system. These may be:\nIn infants, the autonomic nervous system may also activate brown adipose tissue to produce heat (non-exercise-associated thermogenesis, also known as non-shivering thermogenesis). Increased heart rate and vasoconstriction contribute to increased blood pressure in fever.", "page_name": "Fever", "page_id": "Fever", "heading": "Pathophysiology", "sub_heading": "Hypothalamus", "_id": "77--3--2---1", "title": "Heat Effector Mechanisms in the Brain"}
{"qas": [{"question": "Why do we feel the need to take a fever when we are sick?", "answer": ""}, {"question": "What is the medical term for fever?", "answer": "fever", "ae_score": -0.1969114063412204, "qg_score": null}, {"question": "What is the medical term for fever?", "answer": "fever", "ae_score": -0.1969114063412204, "qg_score": null}], "content": "There are arguments for and against the usefulness of fever, and the issue is controversial. There are studies using warm-blooded vertebrates with some suggesting that they recover more rapidly from infections or critical illness due to fever. Studies suggest reduced mortality in bacterial infections when fever was present.\nIn theory, fever can aid in host defense. There are certainly some important immunological reactions that are sped up by temperature, and some pathogens with strict temperature preferences could be hindered.\nResearch has demonstrated that fever assists the healing process in several important ways:", "page_name": "Fever", "page_id": "Fever", "heading": "Pathophysiology", "sub_heading": "Usefulness", "_id": "77--3--3---1", "title": "The Benefits of Fever"}
{"qas": [{"question": "Is it better to keep your body warm when you're sick? If so, how?", "answer": ""}, {"question": "Alternating between paracetamol and ibuprofen is more effective at doing what?", "answer": "decreasing fever", "ae_score": -0.8663865992528168, "qg_score": null}, {"question": "Alternating between paracetamol and ibuprofen is more effective at doing what?", "answer": "decreasing fever", "ae_score": -0.8663865992528168, "qg_score": null}], "content": "Fever should not necessarily be treated. Most people recover without specific medical attention. Although it is unpleasant, fever rarely rises to a dangerous level even if untreated.  Damage to the brain generally does not occur until temperatures reach 42 \u00b0C (107.6 \u00b0F), and it is rare for an untreated fever to exceed 40.6 \u00b0C (105 \u00b0F).\nSome limited evidence supports sponging or bathing feverish children with tepid water. The use of a fan or air conditioning may somewhat reduce the temperature and increase comfort. If the temperature reaches the extremely high level of hyperpyrexia, aggressive cooling is required.<ref name=EM01/> In general, people are advised to keep adequately hydrated. Whether increased fluid intake improves symptoms or shortens respiratory illnesses such as the common cold is not known.\nMedications that lower fevers are called ''antipyretics''.  The antipyretic ibuprofen is effective in reducing fevers in children.  It is more effective than acetaminophen (paracetamol) in children.<ref name=Per2004/> Ibuprofen and acetaminophen may be safely used together in children with fevers.  The efficacy of acetaminophen by itself in children with fevers has been questioned.  Ibuprofen is also superior to aspirin in children with fevers. Additionally, aspirin is not recommended in children and young adults (those under the age of 16 or 19 depending on the country) due to the risk of Reye's syndrome.\nUsing both paracetamol and ibuprofen at the same time or alternating between the two is more effective at decreasing fever than using only paracetamol or ibuprofen.<ref name=Wong2013/> It is not clear if it increases child comfort. Response or nonresponse to medications does not predict whether or not a child has a serious illness.", "page_name": "Fever", "page_id": "Fever", "heading": "Management", "sub_heading": "Management", "_id": "77--4---1---1", "title": "Medications to Reduce Fever in Children"}
{"qas": [{"question": "When did fever become a symptom of disease?", "answer": ""}, {"question": "What was the cause of the first fever?", "answer": "malaria", "ae_score": -0.45492138906734614, "qg_score": null}, {"question": "What was the cause of the first fever?", "answer": "malaria", "ae_score": -0.45492138906734614, "qg_score": null}], "content": "A number of types of fever were known as early as 460 BC to 370 BC when Hippocrates was practicing medicine including that due to malaria (tertian or every 2 days and quartan or every 3 days). It also became clear around this time that fever was a symptom of disease rather than a disease in and of itself.<ref name=Sajadi2012/>", "page_name": "Fever", "page_id": "Fever", "heading": "History", "sub_heading": "History", "_id": "77--6---1---1", "title": "Fever | History"}
{"qas": [{"question": "Why is it so common for parents to give their children fever-reducing medicine when they're sick?", "answer": ""}, {"question": "What is the name given by medical experts to parents' misconceptions about fever in their children?", "answer": "Fever phobia", "ae_score": -0.32991245678472714, "qg_score": null}, {"question": "What is the name given by medical experts to parents' misconceptions about fever in their children?", "answer": "Fever phobia", "ae_score": -0.32991245678472714, "qg_score": null}], "content": "Pyrexia is from the Greek ''pyr'' meaning ''fire''. Febrile is from the Latin word ''febris'', meaning ''fever'', and archaically known as ''ague''.\nFever phobia is the name given by medical experts to parents' misconceptions about fever in their children.  Among them, many parents incorrectly believe that fever is a disease rather than a medical sign, that even low fevers are harmful, and that any temperature even briefly or slightly above the oversimplified \"normal\" number marked on a thermometer is a clinically significant fever.  They are also afraid of harmless side effects like febrile seizures and dramatically overestimate the likelihood of permanent damage from typical fevers.  The underlying problem, according to professor of pediatrics Barton D. Schmitt, is \"as parents we tend to suspect that our children\u2019s brains may melt.\"\nAs a result of these misconceptions parents are anxious, give the child fever-reducing medicine when the temperature is technically normal or only slightly elevated, and interfere with the child's sleep to give the child more medicine.", "page_name": "Fever", "page_id": "Fever", "heading": "Society and culture", "sub_heading": "Society and culture", "_id": "77--7---1---1", "title": "Fever Phobia \u2014 What is it?"}
{"qas": [{"question": "Why do humans have febrile stage?", "answer": ""}, {"question": "What animal has a wide range of temperatures?", "answer": "camels", "ae_score": -0.8718800780305127, "qg_score": null}, {"question": "What animal has a wide range of temperatures?", "answer": "camels", "ae_score": -0.8718800780305127, "qg_score": null}], "content": "Fever is an important feature for the diagnosis of disease in domestic animals. The body temperature of animals, which is taken rectally, is different from one species to another. For example, a horse is said to have a fever above  (). In species that allow the body to have a wide range of \"normal\" temperatures, such as camels, it is sometimes difficult to determine a febrile stage.\nFever can also be behaviorally induced by invertebrates that do not have immune-system based fever. For instance, some species of grasshopper will thermoregulate to achieve body temperatures that are 2\u20135 \u00b0C higher than normal in order to inhibit the growth of fungal pathogens such as ''Beauveria bassiana'' and ''Metarhizium acridum''. Honeybee colonies are also able to induce a fever in response to a fungal parasite ''Ascosphaera apis''.", "page_name": "Fever", "page_id": "Fever", "heading": "Other animals", "sub_heading": "Other animals", "_id": "77--8---1---1", "title": "Fever is an important feature for the diagnosis of disease in domestic animals..."}
{"qas": [{"question": "What is the difference between a certified Italian espresso and a \"certified Italian espresso\"?", "answer": ""}, {"question": "What is the name of the espresso made by forcing hot water through finely ground coffee?", "answer": "Espresso", "ae_score": -0.8848755633397907, "qg_score": null}, {"question": "What is the name of the espresso made by forcing hot water through finely ground coffee?", "answer": "Espresso", "ae_score": -0.8848755633397907, "qg_score": null}], "content": "Espresso is made by forcing very hot  water under high pressure through finely ground, compacted coffee. Tamping down the coffee promotes the water's even penetration of the grounds. This process produces an almost syrupy beverage by extracting both solid and dissolved components. The ''crema''  is produced by emulsifying the oils in the ground coffee into a colloid, which does not occur in other brewing methods. There is no universal standard defining the process of extracting espresso, but there are several published definitions which attempt to place constraints on the amount and type of ground coffee used, the temperature and pressure of the water, and the rate of extraction.  Generally, one uses an espresso machine to make espresso.   The act of producing a shot of espresso is often termed \"pulling\" a shot, originating from lever espresso machines, which require pulling down a handle attached to a spring-loaded piston, forcing hot water through the coffee at high pressure. Today, however, it is more common for the pressure to be generated by an electric pump.\nThe technical parameters outlined by the Italian Espresso National Institute for making a \"certified Italian espresso\" are:", "page_name": "Espresso", "page_id": "Espresso", "heading": "Brewing", "sub_heading": "Brewing", "_id": "78--0---1---1", "title": "The Art of Espresso Making"}
{"qas": [{"question": "What is espresso?", "answer": ""}, {"question": "What is the name of the most popular coffee beverage in italy?", "answer": "Espresso", "ae_score": -0.5645048002276607, "qg_score": null}, {"question": "What is the name of the most popular coffee beverage in italy?", "answer": "Espresso", "ae_score": -0.5645048002276607, "qg_score": null}], "content": "Espresso is both a coffee beverage and a brewing method.  It is not a specific bean, bean blend, or roast level. Any bean or roasting level can be used to produce authentic espresso. For example, in southern Italy, a darker roast is generally preferred.  Farther north, the trend moves toward slightly lighter roasts, while outside Italy, a wide range is popular.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Espresso roast", "sub_heading": "Espresso roast", "_id": "78--1---1---1", "title": "Espresso is a coffee beverage that is both a coffee beverage and a brewing method"}
{"qas": [{"question": "How did espresso become so popular?", "answer": ""}, {"question": "When did the first espresso machine come out?", "answer": "1980s", "ae_score": -0.5608506259683256, "qg_score": null}, {"question": "When did the first espresso machine come out?", "answer": "1980s", "ae_score": -0.5608506259683256, "qg_score": null}], "content": "Espresso has risen in popularity worldwide since the 1980s. In the United States,  caf\u00e9s serve many variations by adding syrup, whipped cream, flavor extracts, soy milk, and spices to their drinks.  The American Pacific Northwest has been viewed as the driver behind this trend. The popularity later spread to shops in other regions and into homes as kitchen-friendly machines became available at moderate cost. In other parts of the world, espresso has long been the customary method of coffee preparation in restaurants, bars and coffee shops.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Popularity", "sub_heading": "Popularity", "_id": "78--2---1---1", "title": "The Rise of Espresso in the Pacific Northwest"}
{"qas": [{"question": "Why is home espresso more popular than brewed coffee?", "answer": ""}, {"question": "What was the name of the first home espresso machine?", "answer": "Gaggia Gilda", "ae_score": -0.4455572119951366, "qg_score": null}, {"question": "What was the name of the first home espresso machine?", "answer": "Gaggia Gilda", "ae_score": -0.4455572119951366, "qg_score": null}], "content": "A distinctive feature of espresso, as opposed to brewed coffee, is espresso's association with caf\u00e9s, due both to the specialized equipment and skill required, thus making the enjoyment of espresso a social experience. Home espresso machines have increased in popularity with the general rise of interest in espresso. Today, a wide range of  home espresso equipment can be found in kitchen and appliance stores, online vendors, and department stores. The first espresso machine for home use was the Gaggia Gilda. Soon afterwards, similar machines such as the Faema Faemina, FE-AR La Peppina and VAM Caravel followed suit in similar form factor and operational principles. These machines still have a small but dedicated share of fans. Until the advent of the first small electrical pump-based espresso machines such as the Gaggia Baby and Quickmill 810, home espresso machines were not widely adopted. In recent years, the increased availability of convenient counter-top fully automatic home espresso makers and pod-based espresso serving systems has increased the quantity of espresso consumed at home. The popularity of home espresso making parallels the increase of home coffee roasting. Some amateurs pursue both home roasting coffee and making espresso.", "page_name": "Espresso", "page_id": "Espresso", "heading": "History", "sub_heading": "History", "_id": "78--3--0---1", "title": "Home Espresso Machines"}
{"qas": [{"question": "Why is the word 'expresso' pronounced 'exresso' instead of'resso'?", "answer": ""}, {"question": "What does crema caff\u00e8 mean in english?", "answer": "cream coffee", "ae_score": -0.7665161770626968, "qg_score": null}, {"question": "What does crema caff\u00e8 mean in english?", "answer": "cream coffee", "ae_score": -0.7665161770626968, "qg_score": null}], "content": "Although some Anglo-American dictionaries simply refer to \"pressed-out\", \"espresso,\" much like the English word \"express\", conveys the senses of \"just for you\" and \"quickly,\" which can be related to the method of espresso preparation.\nAnother source, the ''Online Etymology Dictionary'', favors the \"pressed out\" explanation: \"coffee made under steam pressure, 1945, from Italian (caffe) espresso, from espresso 'pressed out,' past participle of esprimere, from Latin exprimere 'press out, squeeze out' ... [, i]n reference to the steam pressure.\"\nModern espresso, using hot water under pressure, as pioneered by Gaggia in the 1940s, was originally called ''crema caff\u00e8'', in English \"cream coffee\", as can be seen on old Gaggia machines, due to the crema. This term is no longer used, though ''crema caff\u00e8'' and variants (''caff\u00e8 crema, caf\u00e9 crema'') find occasional use in branding.\nThere is a debate over whether the spelling '''expresso''' is incorrect or whether it is an acceptable variant. It is called a less common variant in some sources. Italy uses the term ''espresso'', substituting most ''x'' letters in Latin root words with ''s''; x is not considered part of the standard Italian alphabet. Italian people commonly refer to it simply as ''caff\u00e8'' (coffee), espresso being the ordinary coffee to order; in Spain, while ''caf\u00e9 expreso'' is seen as the more \"formal\" denomination, ''caf\u00e9 solo'' (alone, without milk) is the usual way to ask for it when at an espresso bar. Some sources state that ''expresso'' is an incorrect spelling, including ''Garner's Modern American Usage''.\nWhile the 'expresso' spelling is recognized as mainstream usage in some American dictionaries, some cooking websites call the 'x' variant illegitimate. Oxford Dictionaries online states \"The spelling \"expresso\" is not used in the original Italian and is strictly incorrect, although it is common.\" The ''Oxford English Dictionary'' and ''Merriam-Webster'' call it a variant spelling. The ''Online Etymology Dictionary'' calls \"expresso\" a variant of \"espresso.\" The ''Oxford Dictionary of American Usage and Style'' (2000) describes the spelling ''expresso'' as \"wrong\", and specifies ''espresso'' as the only correct form. The third edition of Fowler's ''Modern English Usage'', published by the Oxford University Press in 1996,  noted that the form ''espresso'' \"has entirely driven out the variant ''expresso'' (which was presumably invented under the impression that It. ''espresso'' meant 'fast, express').\"", "page_name": "Espresso", "page_id": "Espresso", "heading": "Etymology and spelling", "sub_heading": "Etymology and spelling", "_id": "78--4---1---1", "title": "''Espresso'' Is an Incorrect Spelling of Espresso"}
{"qas": [{"question": "What is the difference between a single shot and a double shot?", "answer": ""}, {"question": "What shape are triple baskets in espresso?", "answer": "straight-sided", "ae_score": -0.6675740577773357, "qg_score": null}, {"question": "What shape are triple baskets in espresso?", "answer": "straight-sided", "ae_score": -0.6675740577773357, "qg_score": null}], "content": "The size can be a single, double, or triple, using a proportional amount of ground coffee, roughly 7, 14, and 21 grams; correspondingly sized filter baskets are used. The Italian multiplier term ''doppio'' is often used for a double, with ''solo'' and ''triplo'' being more rarely used for singles and triples. The single shot is the traditional shot size, being the maximum that could easily be pulled on a lever machine, while the double is the standard shot today.\nSingle baskets are sharply tapered or stepped down in diameter to provide comparable depth to the double baskets and, therefore, comparable resistance to water pressure. Most double baskets are gently tapered (the \"Faema model\"), while others, such as the La Marzocco, have straight sides. Triple baskets are normally straight-sided.\nPortafilters will often come with two spouts, usually closely spaced, and a double-size basket \u2013 each spout can optionally dispense into a separate cup, yielding two solo-size (but doppio-brewed) shots, or into a single cup (hence the close spacing). True ''solo'' shots are rare, with a single shot in a caf\u00e9 generally being half of a ''doppio'' shot.\nIn espresso-based drinks, particularly larger milk-based drinks, a drink with three or four shots of espresso will be called a \"triple\" or \"quad\", respectively.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Shot variables", "sub_heading": "Shot variables", "_id": "78--5--0---1", "title": "Doppio \u2014 Single, Double, or Triple Shots"}
{"qas": [{"question": "How do they determine the length of a shot of espresso?", "answer": ""}, {"question": "What is the name of the longer shot ofresso?", "answer": "caff\u00e8 crema", "ae_score": -0.6816385310840752, "qg_score": null}, {"question": "What is the name of the longer shot ofresso?", "answer": "caff\u00e8 crema", "ae_score": -0.6816385310840752, "qg_score": null}], "content": "The length of the shot can be ''ristretto'' (or ''stretto'') (reduced), ''normale''/standard (normal), or ''lungo'' (long): these may correspond to a smaller or larger drink with the same amount of ground coffee and same level of extraction or to different length of extraction. Proportions vary and the volume (and low density) of crema make volume-based comparisons difficult (precise measurement uses the mass of the drink).  Typically ''ristretto'' is half the volume of ''normale'', and ''lungo'' is double to triple the ''normale'' volume.  For a double shot,  (14 grams of dry coffee), a ''normale'' uses about 60 ml of water.  A ''double ristretto,'' a common form associated with artisanal espresso,  uses half the amount of water, about 30 ml.\n''Ristretto, normale'', and ''lungo'' may not simply be the same shot, stopped at different times \u2013 which may result in an underextracted shot (if run too short a time) or an overextracted shot (if run too long a time). Rather, the grind is adjusted (finer for ''ristretto'', coarser for ''lungo'') so the target volume is achieved by the time extraction finishes.\nA significantly longer shot is the ''caff\u00e8 crema'', which is longer than a ''lungo'', ranging in size from 120\u2013240 ml (4\u20138 US fl oz), and brewed in the same way, with a coarser grind.\nThe method of adding hot water produces a milder version of original flavor, while passing more water through the load of ground coffee will add other flavors to the espresso, which might be unpleasant for some people.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Shot variables", "sub_heading": "Length", "_id": "78--5--1---1", "title": "''Ristretto'' vs. Lungo''"}
{"qas": [{"question": "What is cold espresso and how does it work?", "answer": ""}, {"question": "What is the alternative to cappuchino freddo?", "answer": "Cold espresso", "ae_score": -0.8565621577680276, "qg_score": null}, {"question": "What is the alternative to cappuchino freddo?", "answer": "Cold espresso", "ae_score": -0.8565621577680276, "qg_score": null}], "content": "Cold espresso (espresso freddo) is an alternative form of espresso, mostly served in southern Europe. Conceived in Greece, along with cappuchino freddo around the early '90s, freddo espresso enjoys great demand in Greece and its neighbouring countries during summer. The process of making it appears to be simple; after preparing 2 shots of espresso (usually Ristretto), the coffee is being steered in a big iron can along with sugar (if necessary) and 2-3 ice cubes until the can is cold. Then, the blend is put in a glass full of ice cubes.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Cold", "sub_heading": "Cold", "_id": "78--6---1---1", "title": "Cold Espresso (espresso freddo)"}
{"qas": [{"question": "Why is espresso so good for you?", "answer": ""}, {"question": "What mineral does espresso have in it?", "answer": "magnesium", "ae_score": -0.3233561155961334, "qg_score": null}, {"question": "What mineral does espresso have in it?", "answer": "magnesium", "ae_score": -0.3233561155961334, "qg_score": null}], "content": "Likely due to its higher amount of suspended solids than typical coffee which is absent of essential nutrients, espresso has significant contents of the dietary mineral magnesium, the B vitamins niacin and riboflavin, and 212 mg of caffeine per 100 grams of liquid brewed coffee (table).", "page_name": "Espresso", "page_id": "Espresso", "heading": "Nutrition", "sub_heading": "Nutrition", "_id": "78--7---1---1", "title": "Espresso has 212 mg of caffeine per 100 grams of liquid brewed coffee"}
{"qas": [{"question": "What is the difference between a folder and a folder?", "answer": ""}, {"question": "What is the main ingredient in espresso?", "answer": "milk", "ae_score": -0.92052055812071, "qg_score": null}, {"question": "What is the main ingredient in espresso?", "answer": "milk", "ae_score": -0.92052055812071, "qg_score": null}], "content": "In addition to being served alone, espresso is frequently blended, notably with milk - either steamed (without significant foam), wet foamed (\"microfoam\"), or dry foamed, and with hot water. Notable milk-based espresso drinks, in order of size, include: macchiato, cappuccino, flat white, and latte; other milk and espresso combinations include latte macchiato, cortado and gal\u00e3o, which are made primarily with steamed milk with little or no foam. Espresso and water combinations include Americano and long black. Other combinations include coffee with espresso, sometimes called \"red eye\" or \"shot in the dark\".\nIn order of size, these may be organized as follows:\nSome common combinations may be organized graphically as follows:\nMethods of preparation differ between drinks and between baristas. For macchiatos, cappuccino, flat white, and smaller lattes and Americanos, the espresso is brewed into the cup, then the milk or water is poured in. For larger drinks, where a tall glass will not fit under the brew head, the espresso is brewed into a small cup, then poured into the larger cup; for this purpose a demitasse or specialized espresso brew pitcher may be used. This \"pouring into an existing glass\" is a defining characteristic of the latte macchiato and classic renditions of the red eye. Alternatively, a glass with \"existing\" water may have espresso brewed into it \u2013 to preserve the crema \u2013 in the long black. Brewing onto milk is not generally done.", "page_name": "Espresso", "page_id": "Espresso", "heading": "Espresso-based drinks", "sub_heading": "Espresso-based drinks", "_id": "78--8---1---1", "title": "Espresso Drinks \u2014 Tables and Tables"}
{"qas": [{"question": "Why is it that when you dissolve a solid, it becomes a solid?", "answer": ""}, {"question": "Who won the nobel prize for chemistry in 1903 for his explanation of the fact that?", "answer": "Svante Arrhenius", "ae_score": -0.2832362542267037, "qg_score": null}, {"question": "Who won the nobel prize for chemistry in 1903 for his explanation of the fact that?", "answer": "Svante Arrhenius", "ae_score": -0.2832362542267037, "qg_score": null}], "content": "Svante Arrhenius put forth, in his 1884 dissertation, his explanation of the fact that solid crystalline salts disassociate into paired charged particles when dissolved, for which he won the 1903 Nobel Prize in Chemistry.\nArrhenius's explanation was that in forming a solution, the salt dissociates into charged particles, to which Michael Faraday had given the name \"ions\" many years earlier. Faraday's belief had been that ions were produced in the process of electrolysis. Arrhenius proposed that, even in the absence of an electric current, solutions of salts contained ions. He thus proposed that chemical reactions in solution were reactions between ions.", "page_name": "Electrolyte", "page_id": "Electrolyte", "heading": "History", "sub_heading": "History", "_id": "79--1---1---1", "title": "Svante Arrhenius's explanation of the fact that solid crystalline salts"}
{"qas": [{"question": "How is it possible for substances to dissolve in water?", "answer": ""}, {"question": "What process is used to extract constituent elements and compounds from a solution?", "answer": "electrolysis", "ae_score": -0.5540423496288426, "qg_score": null}, {"question": "What process is used to extract constituent elements and compounds from a solution?", "answer": "electrolysis", "ae_score": -0.5540423496288426, "qg_score": null}], "content": "Electrolyte solutions are normally formed when a salt is placed into a solvent such as water and the individual components dissociate due to the thermodynamic interactions between solvent and solute molecules, in a process called \"solvation\". For example, when table salt (sodium chloride), NaCl, is placed in water, the salt (a solid) dissolves into its component ions, according to the dissociation reaction\nIt is also possible for substances to react with water, producing ions.  For example, carbon dioxide gas dissolves in water to produce a solution that contains hydronium, carbonate, and hydrogen carbonate ions.\nMolten salts can also be electrolytes as, for example, when sodium chloride is molten, the liquid conducts electricity. In particular, ionic liquids, which are molten salts with melting points below 100 \u00b0C, are a type of highly conductive non-aqueous electrolytes and thus have found more and more applications in fuel cells and batteries.\nAn electrolyte in a solution may be described as \"concentrated\" if it has a high concentration of ions, or \"diluted\" if it has a low concentration. If a high proportion of the solute dissociates to form free ions, the electrolyte is strong; if most of the solute does not dissociate, the electrolyte is weak. The properties of electrolytes may be exploited using electrolysis to extract constituent elements and compounds contained within the solution.", "page_name": "Electrolyte", "page_id": "Electrolyte", "heading": "Formation", "sub_heading": "Formation", "_id": "79--2---1---1", "title": "Electrolyte Solutions in Fuel Cells, Batteries, and Batteries"}
{"qas": [{"question": "How are electrolytes measured?", "answer": ""}, {"question": "What are the two types of electrolytes used in blood tests?", "answer": "sodium and potassium", "ae_score": -0.39646315434898755, "qg_score": null}, {"question": "What are the two types of electrolytes used in blood tests?", "answer": "sodium and potassium", "ae_score": -0.39646315434898755, "qg_score": null}], "content": "Measurement of electrolytes is a commonly performed diagnostic procedure, performed via blood testing  with ion-selective electrodes or urinalysis by medical technologists. The interpretation of these values is somewhat meaningless without analysis of the clinical history and is often impossible without parallel measurements of renal function. The electrolytes measured most often are sodium and potassium. Chloride levels are rarely measured except for arterial blood gas interpretations, since they are inherently linked to sodium levels. One important test conducted on urine is the specific gravity test to determine the occurrence of an electrolyte imbalance.", "page_name": "Electrolyte", "page_id": "Electrolyte", "heading": "Physiological importance", "sub_heading": "Physiological importance", "_id": "79--3--0---1", "title": "Electrolyte | Physiological importance"}
{"qas": [{"question": "How do electrolyte drinks work?", "answer": ""}, {"question": "What is the name of the protein in fruits?", "answer": "Electrolytes", "ae_score": -0.1974297842728988, "qg_score": null}, {"question": "What is the name of the protein in fruits?", "answer": "Electrolytes", "ae_score": -0.1974297842728988, "qg_score": null}], "content": "In oral rehydration therapy, electrolyte drinks containing sodium and potassium salts replenish the body's water and electrolyte concentrations after dehydration caused by exercise, excessive alcohol consumption, diaphoresis (heavy sweating), diarrhea, vomiting, intoxication or starvation. Athletes exercising in extreme conditions (for three or more hours continuously, e.g. a marathon or triathlon) who do not consume electrolytes risk dehydration (or hyponatremia).\nA home-made electrolyte drink can be made by using water, sugar and salt in precise proportions. Pre-made preparations are also available commercially, and also for veterinary use.\nElectrolytes are commonly found in fruit juices, sports drinks, milk, nuts, and many fruits and vegetables (whole or in juice form) (e.g., potatoes, avocados).", "page_name": "Electrolyte", "page_id": "Electrolyte", "heading": "Physiological importance", "sub_heading": "Rehydration", "_id": "79--3--1---1", "title": "Electrolyte Drinks \u2014 Sodium and potassium salts"}
{"qas": [{"question": "What would happen if you put a balloon in the middle of the air?", "answer": ""}, {"question": "What is the name of the electrolyte reaction?", "answer": "anode reaction", "ae_score": -0.15900005306736556, "qg_score": null}, {"question": "What is the name of the electrolyte reaction?", "answer": "anode reaction", "ae_score": -0.15900005306736556, "qg_score": null}], "content": "When electrodes are placed in an electrolyte and a voltage is applied, the electrolyte will conduct electricity. Lone electrons normally cannot pass through the electrolyte; instead, a chemical reaction occurs at the cathode, providing electrons to the electrolyte.   Another reaction occurs at the anode, consuming electrons from the electrolyte. As a result, a negative charge cloud develops in the electrolyte around the cathode, and a positive charge develops around the anode. The ions in the electrolyte neutralize these charges, enabling the electrons to keep flowing and the reactions to continue.\nFor example, in a solution of ordinary table salt (sodium chloride, NaCl) in water, the cathode reaction will be\nand hydrogen gas will bubble up; the anode reaction is\nand chlorine gas will be liberated. The positively charged sodium ions Na will react toward the cathode, neutralizing the negative charge of OH there, and the negatively charged hydroxide ions OH will react toward the anode, neutralizing the positive charge of Na there. Without the ions from the electrolyte, the charges around the electrode would slow down continued electron flow; diffusion of H and OH through water to the other electrode takes longer than movement of the much more prevalent salt ions.Electrolytes dissociate in water because water molecules are dipoles and the dipoles orient in an energetically favorable manner to solvate the ions.\nIn other systems, the electrode reactions can involve the metals of the electrodes as well as the ions of the electrolyte.\nElectrolytic conductors are used in electronic devices where the chemical reaction at a metal-electrolyte interface yields useful effects.", "page_name": "Electrolyte", "page_id": "Electrolyte", "heading": "Electrochemistry", "sub_heading": "Electrochemistry", "_id": "79--4---1---1", "title": "Electrolytic Conductors \u2014 Electrolytic Conductors"}
{"qas": [{"question": "What is the difference between a pesticide and a plant-derived pesticide?", "answer": ""}, {"question": "What does the food and agriculture organization define as?", "answer": "pesticide", "ae_score": -0.36453378012351273, "qg_score": null}, {"question": "What does the food and agriculture organization define as?", "answer": "pesticide", "ae_score": -0.36453378012351273, "qg_score": null}], "content": "The Food and Agriculture Organization (FAO) has defined ''pesticide'' as:\nPesticides can be classified by target organism (e.g., herbicides, insecticides, fungicides, rodenticides, and pediculicides - see table), chemical structure (e.g., organic, inorganic, synthetic, or biological (biopesticide), although the distinction can sometimes blur), and physical state (e.g. gaseous (fumigant)).<ref name=Council1997/> Biopesticides include microbial pesticides and biochemical pesticides. Plant-derived pesticides, or \"botanicals\", have been developing quickly. These include the pyrethroids, rotenoids, nicotinoids, and a fourth group that includes strychnine and scilliroside.\nMany pesticides can be grouped into chemical families. Prominent insecticide families include organochlorines, organophosphates, and carbamates. Organochlorine hydrocarbons (e.g., DDT) could be separated into dichlorodiphenylethanes, cyclodiene compounds, and other related compounds. They operate by disrupting the sodium/potassium balance of the nerve fiber, forcing the nerve to transmit continuously. Their toxicities vary greatly, but they have been phased out because of their persistence and potential to bioaccumulate.<ref name=Kamrin1997/> Organophosphate and carbamates largely replaced organochlorines. Both operate through inhibiting the enzyme acetylcholinesterase, allowing acetylcholine to transfer nerve impulses indefinitely and causing a variety of symptoms such as weakness or paralysis. Organophosphates are quite toxic to vertebrates, and have in some cases been replaced by less toxic carbamates.<ref name=Kamrin1997/> Thiocarbamate and dithiocarbamates are subclasses of carbamates. Prominent families of herbicides include phenoxy and benzoic acid herbicides (e.g. 2,4-D), triazines (e.g., atrazine), ureas (e.g., diuron), and Chloroacetanilides (e.g., alachlor). Phenoxy compounds tend to selectively kill broad-leaf weeds rather than grasses. The phenoxy and benzoic acid herbicides function similar to plant growth hormones, and grow cells without normal cell division, crushing the plant's nutrient transport system.<ref name=Kamrin1997/> Triazines interfere with photosynthesis.<ref name=Kamrin1997/> Many commonly used pesticides are not included in these families, including glyphosate.\nPesticides can be classified based upon their biological mechanism function or application method. Most pesticides work by poisoning pests. A systemic pesticide moves inside a plant following absorption by the plant. With insecticides and most fungicides, this movement is usually upward (through the xylem) and outward. Increased efficiency may be a result. Systemic insecticides, which poison pollen and nectar in the flowers, may kill bees and other needed pollinators.\nIn 2009, the development of a new class of fungicides called paldoxins was announced. These work by taking advantage of natural defense chemicals released by plants called phytoalexins, which fungi then detoxify using enzymes. The paldoxins inhibit the fungi's detoxification enzymes. They are believed to be safer and greener.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Definition", "sub_heading": "Definition", "_id": "80--0---1---1", "title": "Pesticides & Pesticides"}
{"qas": [{"question": "What is the difference between a pesticide and a herbicide?", "answer": ""}, {"question": "What is used to control organisms that are considered to be harmful?", "answer": "Pesticides", "ae_score": -0.5615027854150559, "qg_score": null}, {"question": "What is used to control organisms that are considered to be harmful?", "answer": "Pesticides", "ae_score": -0.5615027854150559, "qg_score": null}], "content": "Pesticides are used to control organisms that are considered to be harmful. For example, they are used to kill mosquitoes that can transmit potentially deadly diseases like West Nile virus, yellow fever, and malaria. They can also kill bees, wasps or ants that can cause allergic reactions. Insecticides can protect animals from illnesses that can be caused by parasites such as fleas. Pesticides can prevent sickness in humans that could be caused by moldy food or diseased produce. Herbicides can be used to clear roadside weeds, trees and brush. They can also kill invasive weeds that may cause environmental damage. Herbicides are commonly applied in ponds and lakes to control algae and plants such as water grasses that can interfere with activities like swimming and fishing and cause the water to look or smell unpleasant. Uncontrolled pests such as termites and mold can damage structures such as houses. Pesticides are used in grocery stores and food storage facilities to manage rodents and insects that infest food such as grain. Each use of a pesticide carries some associated risk. Proper pesticide use decreases these associated risks to a level deemed acceptable by pesticide regulatory agencies such as the United States Environmental Protection Agency (EPA) and the Pest Management Regulatory Agency (PMRA) of Canada.\nDDT, sprayed on the walls of houses, is an organochlorine that has been used  to fight malaria since the 1950s. Recent policy statements by the World Health Organization have given stronger support to this approach.  However, DDT and other organochlorine pesticides have been banned in most countries worldwide because of their persistence in the environment and human toxicity.  DDT use is not always effective, as resistance to DDT was identified in Africa as early as 1955, and by 1972 nineteen species of mosquito worldwide were resistant to DDT.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Uses", "sub_heading": "Uses", "_id": "80--1---1---1", "title": "Pesticides and Pesticides"}
{"qas": [{"question": "Why is insecticide use so low in the US compared to other developed countries?", "answer": ""}, {"question": "What percentage of the world is used by herbicides?", "answer": "40%", "ae_score": -0.8759435278865682, "qg_score": null}, {"question": "What percentage of the world is used by herbicides?", "answer": "40%", "ae_score": -0.8759435278865682, "qg_score": null}], "content": "In 2006 and 2007, the world used approximately  of pesticides, with herbicides constituting the biggest part of the world pesticide use at 40%, followed by insecticides (17%) and fungicides (10%). In 2006 and 2007 the U.S. used approximately 0.5 Mt of pesticides, accounting for 22% of the world total, including 857 e6lb of conventional pesticides, which are used in the agricultural sector (80% of conventional pesticide use) as well as the industrial, commercial, governmental and home & garden sectors.Pesticides are also found in majority of U.S. households with 78 million out of the 105.5 million households indicating that they use some form of pesticide. As of 2007, there were more than 1,055 active ingredients registered as pesticides, which yield over 20,000 pesticide products that are marketed in the United States.\nThe US used some 1 kg (2.2 pounds) per hectare of arable land compared with: 4.7 kg in China, 1.3 kg in the UK, 0.1 kg in Cameroon, 5.9 kg in Japan and 2.5 kg in Italy. Insecticide use in the US has declined by more than half since 1980, (.6%/yr) mostly due to the near phase-out of organophosphates. In corn fields, the decline was even steeper, due to the switchover to transgenic Bt corn.\nFor the global market of crop protection products, market analysts forecast revenues of over 52 billion US$ in 2019.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Amount used", "sub_heading": "Amount used", "_id": "80--2---1---1", "title": "Pesticides in the U.S."}
{"qas": [{"question": "How does the use of pesticides help farmers?", "answer": ""}, {"question": "What can save farmers money by preventing crop losses?", "answer": "Pesticides", "ae_score": -0.6313032092002195, "qg_score": null}, {"question": "What can save farmers money by preventing crop losses?", "answer": "Pesticides", "ae_score": -0.6313032092002195, "qg_score": null}], "content": "Pesticides can save farmers' money by preventing crop losses to insects and other pests; in the U.S., farmers get an estimated fourfold return on money they spend on pesticides. One study found that not using pesticides reduced crop yields by about 10%.  Another study, conducted in 1999, found that a ban on pesticides in the United States may result in a rise of food prices, loss of jobs, and an increase in world hunger.\nThere are two levels of benefits for pesticide use, primary and secondary. Primary benefits are direct gains from the use of pesticides and secondary benefits are effects that are more long-term.\nEvery dollar ($1) that is spent on pesticides for crops yields four dollars ($4) in crops saved. This means based that, on the amount of money spent per year on pesticides, $10 billion, there is an additional $40 billion savings in crop that would be lost due to damage by insects and weeds. In general, farmers benefit from having an increase in crop yield and from being able to grow a variety of crops throughout the year. Consumers of agricultural products also benefit from being able to afford the vast quantities of produce available year-round. The general public also benefits from the use of pesticides for the control of insect-borne diseases and illnesses, such as malaria. The use of pesticides creates a large job market within the agrichemical sector.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Benefits", "sub_heading": "Benefits", "_id": "80--3---1---1", "title": "Pesticides Can Save Farmers' Money by Preventing Crop Losses to Insec"}
{"qas": [{"question": "Why are there so many pesticide deaths in developing countries?", "answer": ""}, {"question": "What organization recommends limiting exposure to pesticides?", "answer": "The American Academy of Pediatrics", "ae_score": -0.3222674204729851, "qg_score": null}, {"question": "What organization recommends limiting exposure to pesticides?", "answer": "The American Academy of Pediatrics", "ae_score": -0.3222674204729851, "qg_score": null}], "content": "Pesticides may cause acute and delayed health effects in people who are exposed. Pesticide exposure can cause a variety of adverse health effects, ranging from simple irritation of the skin and eyes to more severe effects such as affecting the nervous system, mimicking hormones causing reproductive problems, and also causing cancer. A 2007 systematic review found that \"most studies on non-Hodgkin lymphoma and leukemia showed positive associations with pesticide exposure\" and thus concluded that cosmetic use of pesticides should be decreased.  There is substantial evidence of associations between organophosphate insecticide exposures and neurobehavioral alterations. Limited evidence also exists for other negative outcomes from pesticide exposure including neurological, birth defects, and fetal death.\nThe American Academy of Pediatrics recommends limiting exposure of children to pesticides and using safer alternatives:\nThe World Health Organization and the UN Environment Programme estimate that each year, 3 million workers in agriculture in the developing world experience severe poisoning from pesticides, about 18,000 of whom die. Owing to inadequate regulation and safety precautions, 99% of pesticide related deaths occur in developing countries that account for only 25% of pesticide usage. According to one study, as many as 25 million workers in developing countries may suffer mild pesticide poisoning yearly. There are several careers aside from agriculture that may also put individuals at risk of health effects from pesticide exposure including pet groomers, groundskeepers, and fumigators.\nOne study found pesticide self-poisoning the method of choice in one third of suicides worldwide, and recommended, among other things, more restrictions on the types of pesticides that are most harmful to humans.\nA 2014 epidemiological review found associations between autism and exposure to certain pesticides, but noted that the available evidence was insufficient to conclude that the relationship was causal.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Costs", "sub_heading": "Costs", "_id": "80--4--0---1", "title": "Pesticide Exposure and Health Issues"}
{"qas": [{"question": "Why is the use of pesticides such a big deal?", "answer": ""}, {"question": "What can develop resistance to the pesticide?", "answer": "Pests", "ae_score": -0.4689850060474591, "qg_score": null}, {"question": "What can develop resistance to the pesticide?", "answer": "Pests", "ae_score": -0.4689850060474591, "qg_score": null}], "content": "Pesticide use raises a number of environmental concerns. Over 98% of sprayed insecticides and 95% of herbicides reach a destination other than their target species, including non-target species, air, water and soil. Pesticide drift occurs when pesticides suspended in the air as particles are carried by wind to other areas, potentially contaminating them. Pesticides are one of the causes of water pollution, and some pesticides are persistent organic pollutants and contribute to soil contamination.\nIn addition, pesticide use reduces biodiversity, contributes to pollinator decline, destroys habitat (especially for birds), and threatens endangered species.\nPests can develop a resistance to the pesticide  (pesticide resistance), necessitating a new pesticide. Alternatively a greater dose of the pesticide can be used to counteract the resistance, although this will cause a worsening of the ambient pollution problem.\nSince chlorinated hydrocarbon pesticides dissolve in fats and are not excreted, organisms tend to retain them almost indefinitely. Biological magnification is the process whereby these chlorinated hydrocarbons (pesticides) are more concentrated at each level of the food chain. Among marine animals, pesticide concentrations are higher in carnivorous fishes, and even more so in the fish-eating birds and mammals at the top of the ecological pyramid. Global distillation is the process whereby pesticides are transported from warmer to colder regions of the Earth, in particular the Poles and mountain tops.  Pesticides that evaporate into the atmosphere at relatively high temperature can be carried considerable distances (thousands of kilometers) by the wind to an area of lower temperature, where they condense and are carried back to the ground in rain or snow.\nIn order to reduce negative impacts, it is desirable that pesticides be degradable or at least quickly deactivated in the environment.  Such loss of activity or toxicity of pesticides is due to both innate chemical properties of the compounds and environmental processes or conditions.  For example, the presence of halogens within a chemical structure often slows down degradation in an aerobic environment.  Adsorption to soil may retard pesticide movement, but also may reduce bioavailability to microbial degraders.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Costs", "sub_heading": "Environmental effect", "_id": "80--4--1---1", "title": "Pesticides and the Environmental Impact of Pesticides"}
{"qas": [{"question": "Why are pesticides so bad for the environment?", "answer": ""}, {"question": "What is the estimated human health and environmental cost from pesticides?", "answer": "$9.6 billion", "ae_score": -0.32591325797273507, "qg_score": null}, {"question": "What is the estimated human health and environmental cost from pesticides?", "answer": "$9.6 billion", "ae_score": -0.32591325797273507, "qg_score": null}], "content": "Human health and environmental cost from pesticides in the United States is estimated at $9.6 billion offset by about $40 billion in increased agricultural production:\nAdditional costs include the registration process and the cost of purchasing pesticides. The registration process can take several years to complete (there are 70 different types of field test) and can cost $50\u201370 million for a single pesticide. Annually the United States spends $10 billion on pesticides.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Costs", "sub_heading": "Economics", "_id": "80--4--2---1", "title": "Pesticide Costs in the United States"}
{"qas": [{"question": "Why can't we use the push-pull method to control pests?", "answer": ""}, {"question": "Where was the most successful push-pull technique used?", "answer": "Africa", "ae_score": -0.27828641031642726, "qg_score": null}, {"question": "Where was the most successful push-pull technique used?", "answer": "Africa", "ae_score": -0.27828641031642726, "qg_score": null}], "content": "The term \"push-pull\" was established in 1987 as an approach for integrated pest management (IPM).  This strategy uses a mixture of behavior-modifying stimuli to manipulate the distribution and abundance of insects. \"Push\" means the insects are repelled or deterred away from whatever resource that is being protected.  \"Pull\" means that certain stimuli (semiochemical stimuli, pheromones, food additives, visual stimuli, genetically altered plants, etc.) are used to attract pests to trap crops where they will be killed.  There are numerous different components involved in order to implement a Push-Pull Strategy in IPM.\nMany case studies testing the effectiveness of the push-pull approach have been done across the world.  The most successful push-pull strategy was developed in Africa for subsistence farming.  Another successful case study was performed on the control of ''Helicoverpa'' in cotton crops in Australia.  In Europe, the Middle East, and the United States, push-pull strategies were successfully used in the controlling of ''Sitona lineatus'' in bean fields.<ref name=PushPull/>\nSome advantages of using the push-pull method are less use of chemical or biological materials and better protection against insect habituation to this control method.  Some disadvantages of the push-pull strategy is that if there is a lack of appropriate knowledge of behavioral and chemical ecology of the host-pest interactions then this method becomes unreliable.  Furthermore, because the push-pull method is not a very popular method of IPM operational and registration costs are higher.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Alternatives", "sub_heading": "Alternatives", "_id": "80--5--0---1", "title": "Push-Pull in IPM"}
{"qas": [{"question": "Why is there so much more pesticide resistance than there were in the past?", "answer": ""}, {"question": "Since the 1980s, how much has crop loss increased?", "answer": "13%", "ae_score": -0.40603674445056775, "qg_score": null}, {"question": "Since the 1980s, how much has crop loss increased?", "answer": "13%", "ae_score": -0.40603674445056775, "qg_score": null}], "content": "Some evidence shows that alternatives to pesticides can be equally effective as the use of chemicals. For example, Sweden has halved its use of pesticides with hardly any reduction in crops. In Indonesia, farmers have reduced pesticide use on rice fields by 65% and experienced a 15% crop increase.  A study of Maize fields in northern Florida found that the application of composted yard waste with high carbon to nitrogen ratio to agricultural fields was highly effective at reducing the population of plant-parasitic nematodes and increasing crop yield, with yield increases ranging from 10% to 212%; the observed effects were long-term, often not appearing until the third season of the study.\nHowever, pesticide resistance is increasing. In the 1940s, U.S. farmers lost only 7% of their crops to pests.  Since the 1980s, loss has increased to 13%, even though more pesticides are being used.  Between 500 and 1,000 insect and weed species have developed pesticide resistance since 1945.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Alternatives", "sub_heading": "Effectiveness", "_id": "80--5--1---1", "title": "Pesticide Resistance is Growing"}
{"qas": [{"question": "What is the difference between a pesticide and a pest?", "answer": ""}, {"question": "Canola oil and baking soda are examples of what kind of pesticides?", "answer": "Biopesticides", "ae_score": -0.32072856398185656, "qg_score": null}, {"question": "Canola oil and baking soda are examples of what kind of pesticides?", "answer": "Biopesticides", "ae_score": -0.32072856398185656, "qg_score": null}], "content": "Pesticides are often referred to according to the type of pest they control. Pesticides can also be considered as either biodegradable pesticides, which will be broken down by microbes and other living beings into harmless compounds, or persistent pesticides, which may take months or years before they are broken down: it was the persistence of DDT, for example, which led to its accumulation in the food chain and its killing of birds of prey at the top of the food chain. Another way to think about pesticides is to consider those that are chemical pesticides or are derived from a common source or production method.\nSome examples of chemically-related pesticides are:\nOrganophosphates affect the nervous system by disrupting, acetylcholinesterase activity, the enzyme that regulates acetylcholine, a neurotransmitter. Most organophosphates are insecticides. They were developed during the early 19th century, but their effects on insects, which are similar to their effects on humans, were discovered in 1932. Some are very poisonous. However, they usually are not persistent in the environment.\nCarbamate pesticides affect the nervous system by disrupting an enzyme that regulates acetylcholine, a neurotransmitter. The enzyme effects are usually reversible. There are several subgroups within the carbamates.\nThey were commonly used in the past, but many have been removed from the market due to their health and environmental effects and their persistence (e.g., DDT, chlordane, and toxaphene).\nThey were developed as a synthetic version of the naturally occurring pesticide pyrethrin, which is found in chrysanthemums. They have been modified to increase their stability in the environment. Some synthetic pyrethroids are toxic to the nervous system.\nThe following sulfonylureas have been commercialized for weed control: amidosulfuron, azimsulfuron, bensulfuron-methyl, chlorimuron-ethyl, ethoxysulfuron, flazasulfuron, flupyrsulfuron-methyl-sodium, halosulfuron-methyl, imazosulfuron, nicosulfuron, oxasulfuron, primisulfuron-methyl, pyrazosulfuron-ethyl, rimsulfuron, sulfometuron-methylSulfosulfuron, terbacil, bispyribac-sodium, cyclosulfamuron, and pyrithiobac-sodium.  Nicosulfuron, triflusulfuron methyl, and chlorsulfuron are broad-spectrum herbicides that kill plants by inhibiting the enzyme acetolactate synthase. In the 1960s, more than 1 kg/ha crop protection chemical was typically applied, while sulfonylureates allow as little as 1% as much material to achieve the same effect.\nBiopesticides are certain types of pesticides derived from such natural materials as animals, plants, bacteria, and certain minerals. For example, canola oil and baking soda have pesticidal applications and are considered biopesticides.  Biopesticides fall into three major classes:\nPesticides that are related to the type of pests are:\nThe term pesticide also include these substances:\n'''Defoliants''' : Cause leaves or other foliage to drop from a plant, usually to facilitate harvest.\n'''Desiccants''' : Promote drying of living tissues, such as unwanted plant tops.\n'''Insect growth regulators''' : Disrupt the molting, maturity from pupal stage to adult, or other life processes of insects.\n '''Plant growth regulators''' : Substances (excluding fertilizers or other plant nutrients) that alter the expected growth, flowering, or reproduction rate of plants.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Types", "sub_heading": "Types", "_id": "80--6---1---1", "title": "Pesticides & Pesticides"}
{"qas": [{"question": "What is the difference between pesticide safety education and pesticide applicator regulation?", "answer": ""}, {"question": "Who has to approve pesticides in most countries?", "answer": "a government agency", "ae_score": -0.23739498073926554, "qg_score": null}, {"question": "Who has to approve pesticides in most countries?", "answer": "a government agency", "ae_score": -0.23739498073926554, "qg_score": null}], "content": "In most countries, pesticides must be approved for sale and use by a government agency.\nIn Europe, recent EU legislation has been approved banning the use of highly toxic pesticides including those that are carcinogenic, mutagenic or toxic to reproduction, those that are endocrine-disrupting, and those that are persistent, bioaccumulative and toxic (PBT) or very persistent and very bioaccumulative (vPvB).  Measures were approved to improve the general safety of pesticides across all EU member states.\nThough pesticide regulations differ from country to country, pesticides, and products on which they were used are traded across international borders. To deal with inconsistencies in regulations among countries, delegates to a conference of the United Nations Food and Agriculture Organization adopted an International Code of Conduct on the Distribution and Use of Pesticides in 1985 to create voluntary standards of pesticide regulation for different countries. The Code was updated in 1998 and 2002. The FAO claims that the code has raised awareness about pesticide hazards and decreased the number of countries without restrictions on pesticide use.\nThree other efforts to improve regulation of international pesticide trade are the United Nations London Guidelines for the Exchange of Information on Chemicals in International Trade and the United Nations Codex Alimentarius Commission.  The former seeks to implement procedures for ensuring that prior informed consent exists between countries buying and selling pesticides, while the latter seeks to create uniform standards for maximum levels of pesticide residues among participating countries. Both initiatives operate on a voluntary basis.\nPesticides safety education and pesticide applicator regulation are designed to protect the public from pesticide misuse, but do not eliminate all misuse. Reducing the use of pesticides and choosing less toxic pesticides may reduce risks placed on society and the environment from pesticide use.  Integrated pest management, the use of multiple approaches to control pests, is becoming widespread and has been used with success in countries such as Indonesia, China, Bangladesh, the U.S., Australia, and Mexico. IPM attempts to recognize the more widespread impacts of an action on an ecosystem, so that natural balances are not upset. New pesticides are being developed, including biological and botanical derivatives and alternatives that are thought to reduce health and environmental risks.  In addition, applicators are being encouraged to consider alternative controls and adopt methods that reduce the use of chemical pesticides.\nPesticides can be created that are targeted to a specific pest's lifecycle, which can be environmentally more friendly. For example, potato cyst nematodes emerge from their protective cysts in response to a chemical excreted by potatoes; they feed on the potatoes and damage the crop. A similar chemical can be applied to fields early, before the potatoes are planted, causing the nematodes to emerge early and starve in the absence of potatoes.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Regulation", "sub_heading": "Regulation", "_id": "80--7--0---1", "title": "Integrated Pest Management in the United States"}
{"qas": [{"question": "How does the EPA determine the amount of toxic chemicals in the atmosphere?", "answer": ""}, {"question": "Who can purchase or supervise the use of restricted use pesticides?", "answer": "certified applicators", "ae_score": -0.6004340312153578, "qg_score": null}, {"question": "Who can purchase or supervise the use of restricted use pesticides?", "answer": "certified applicators", "ae_score": -0.6004340312153578, "qg_score": null}], "content": "In the United States, the Environmental Protection Agency (EPA) is responsible for regulating pesticides under the Federal Insecticide, Fungicide, and Rodenticide Act (FIFRA) and the Food Quality Protection Act (FQPA). Studies must be conducted to establish the conditions in which the material is safe to use and the effectiveness against the intended pest(s). The EPA regulates pesticides to ensure that these products do not pose adverse effects to humans or the environment.  Pesticides produced before November 1984 continue to be reassessed in order to meet the current scientific and regulatory standards.  All registered pesticides are reviewed every 15 years to ensure they meet the proper standards. During the registration process, a label is created. The label contains directions for proper use of the material in addition to safety restrictions. Based on acute toxicity, pesticides are assigned to a Toxicity Class.\nSome pesticides are considered too hazardous for sale to the general public and are designated restricted use pesticides.  Only certified applicators, who have passed an exam, may purchase or supervise the application of restricted use pesticides. Records of sales and use are required to be maintained and may be audited by government agencies charged with the enforcement of pesticide regulations. These records must be made available to employees and state or territorial environmental regulatory agencies.\nThe EPA regulates pesticides under two main acts, both of which were amended by the Food Quality Protection Act of 1996. In addition to the EPA, the United States Department of Agriculture (USDA) and the United States Food and Drug Administration (FDA) set standards for the level of pesticide residue that is allowed on or in crops  The EPA looks at what the potential human health and environmental effects might be associated with the use of the pesticide.\nIn addition, the U.S. EPA uses the National Research Council's four-step process for human health risk assessment: (1) Hazard Identification, (2) Dose-Response Assessment, (3) Exposure Assessment, and (4) Risk Characterization.\nRecently Kaua'i County (Hawai'i) passed Bill No. 2491 to add an article to Chapter 22 of the county's code relating to pesticides and GMOs. The bill strengthens protections of local communities in Kaua'i where many large pesticide companies test their products.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "Regulation", "sub_heading": "United States", "_id": "80--7--1---1", "title": "Pesticides and GMOs in the United States"}
{"qas": [{"question": "When and why did the use of pesticides start?", "answer": ""}, {"question": "When was the first federal law regulating pesticides enacted?", "answer": "1910", "ae_score": -0.20716409511873843, "qg_score": null}, {"question": "When was the first federal law regulating pesticides enacted?", "answer": "1910", "ae_score": -0.20716409511873843, "qg_score": null}], "content": "Since before 2000 BC, humans have utilized pesticides to protect their crops. The first known pesticide was elemental sulfur dusting used in ancient Sumer about 4,500 years ago in ancient Mesopotamia. The Rig Veda, which is about 4,000 years old, mentions the use of poisonous plants for pest control. By the 15th century, toxic chemicals such as arsenic, mercury, and lead were being applied to crops to kill pests. In the 17th century, nicotine sulfate was extracted from tobacco leaves for use as an insecticide. The 19th century saw the introduction of two more natural pesticides, pyrethrum, which is derived from chrysanthemums, and rotenone, which is derived from the roots of tropical vegetables. Until the 1950s, arsenic-based pesticides were dominant.  Paul M\u00fcller discovered that DDT was a very effective insecticide. Organochlorines such as DDT were dominant, but they were replaced in the U.S. by organophosphates and carbamates by 1975. Since then, pyrethrin compounds have become the dominant insecticide.<ref name=Pinpointing/> Herbicides became common in the 1960s, led by \"triazine and other nitrogen-based compounds, carboxylic acids such as 2,4-dichlorophenoxyacetic acid, and glyphosate\".<ref name=Pinpointing/>\nThe first legislation providing federal authority for regulating pesticides was enacted in 1910; however, decades later during the 1940s manufacturers began to produce large amounts of synthetic pesticides and their use became widespread. Some sources consider the 1940s and 1950s to have been the start of the \"pesticide era.\" Although the U.S. Environmental Protection Agency was established in 1970 and  amendments to the pesticide law in 1972, pesticide use has increased 50-fold since 1950 and 2.3 million tonnes (2.5 million short tons) of industrial pesticides are now used each year.<ref name=Miller2002/> Seventy-five percent of all pesticides in the world are used in developed countries, but use in developing countries is increasing. A study of USA pesticide use trends through 1997 was published in 2003 by the National Science Foundation's Center for Integrated Pest  Management.<ref name=Pinpointing/>\nIn the 1960s, it was discovered that DDT was preventing many fish-eating birds from reproducing, which was a serious threat to biodiversity. Rachel Carson wrote the best-selling book ''Silent Spring'' about biological magnification. The agricultural use of DDT is now banned under the Stockholm Convention on Persistent Organic Pollutants, but it is still used in some developing nations to prevent malaria and other tropical diseases by spraying on interior walls to kill or repel mosquitoes.", "page_name": "Pesticide", "page_id": "Pesticide", "heading": "History", "sub_heading": "History", "_id": "80--8---1---1", "title": "The Pesticide Era \u2014 A History of Pesticides"}
{"qas": [{"question": "Why is it so hard to develop a safe and effective antiviral drug?", "answer": ""}, {"question": "Why is it difficult to develop antiviral drugs?", "answer": "viral variation", "ae_score": -0.38090391944823515, "qg_score": null}, {"question": "Why is it difficult to develop antiviral drugs?", "answer": "viral variation", "ae_score": -0.38090391944823515, "qg_score": null}], "content": "Most of the antiviral drugs now available are designed to help deal with HIV, herpes viruses, the hepatitis B and C viruses, and influenza A and B viruses. Researchers are working to extend the range of antivirals to other families of pathogens.\nDesigning safe and effective antiviral drugs is difficult, because viruses use the host's cells to replicate. This makes it difficult to find targets for the drug that would interfere with the virus without also harming the host organism's cells. Moreover, the major difficulty in developing vaccines and anti-viral drugs is due to viral variation.\nThe emergence of antivirals is the product of a greatly expanded knowledge of the genetic and molecular function of organisms, allowing biomedical researchers to understand the structure and function of viruses, major advances in the techniques for finding new drugs, and the intense pressure placed on the medical profession to deal with the human immunodeficiency virus (HIV), the cause of the deadly acquired immunodeficiency syndrome (AIDS) pandemic.\nThe first experimental antivirals were developed in the 1960s, mostly to deal with herpes viruses, and were found using traditional trial-and-error drug discovery methods. Researchers grew cultures of cells and infected them with the target virus. They then introduced into the cultures chemicals which they thought might inhibit viral activity, and observed whether the level of virus in the cultures rose or fell. Chemicals that seemed to have an effect were selected for closer study.\nThis was a very time-consuming, hit-or-miss procedure, and in the absence of a good knowledge of how the target virus worked, it was not efficient in discovering effective antivirals which had few side effects. Only in the 1980s, when the full genetic sequences of viruses began to be unraveled, did researchers begin to learn how viruses worked in detail, and   exactly what chemicals were needed to thwart their reproductive cycle.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Medical uses", "sub_heading": "Medical uses", "_id": "81--0---1---1", "title": "Antiviral Drugs for HIV, Herpes, Hepatitis B, C"}
{"qas": [{"question": "How do viruses work?", "answer": ""}, {"question": "What is an example of an antiviral plant?", "answer": "mushrooms", "ae_score": -0.6695881018649245, "qg_score": null}, {"question": "What is an example of an antiviral plant?", "answer": "mushrooms", "ae_score": -0.6695881018649245, "qg_score": null}], "content": "Viruses consist of a genome and sometimes a few enzymes stored in a capsule made of protein (called a capsid), and sometimes covered with a lipid layer (sometimes called an 'envelope'). Viruses cannot reproduce on their own, and instead propagate by subjugating a host cell to produce copies of themselves, thus producing the next generation.\nResearchers working on such \"rational drug design\" strategies for developing antivirals have tried to attack viruses at every stage of their life cycles. Some species of mushrooms have been found to contain multiple antiviral chemicals with similar synergistic effects.Viral life cycles vary in their precise details depending on the type of virus, but they all share a general pattern:", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Virus life cycle", "sub_heading": "Virus life cycle", "_id": "81--1---1---1", "title": "Viruses and their Life Cycles"}
{"qas": [{"question": "Why do we have to pay so much for gas in the US?", "answer": ""}, {"question": "What is the common term for rising costs of antiviral drugs?", "answer": "Rising Costs", "ae_score": -0.20665780047085996, "qg_score": null}, {"question": "What is the common term for rising costs of antiviral drugs?", "answer": "Rising Costs", "ae_score": -0.20665780047085996, "qg_score": null}], "content": "'''Rising Costs'''\nCost is an important factor that limits access to antivirals therapies in the United States and internationally. The recommended treatment regimen for hepatitis C virus infection, for example, includes sofosbuvir-velpatasvir (Epclusa) and ledipasvir-sofosbuvir (Harrvoni). A twelve week supply of these drugs amount to $113,400 and $89,712, respectively. These drugs can be manufactured generically at a cost of $100 - $250 per 12 week treatment.  Pharmaceutical companies attribute the majority of these costs to research and development expenses. On average, the research and development costs required to bring a new drug to market amount to $17.2 billion. However, critics point to monopolistic market conditions that allow manufacturers to increase prices without facing a reduction in sales, leading to higher profits at patient's expense. Intellectual property laws, anti-importation policies, and the slow pace of FDA review limit alternative options.  Recently, private-public research partnerships have been established to promote expedited, cost-effective research.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Limitations and Policy Implications", "sub_heading": "Limitations and Policy Implications", "_id": "81--2--0---1", "title": "Antiviral drug | Limitations and Policy Implications"}
{"qas": [{"question": "Why is it okay for parents to not vaccinate their children, but not okay for their children to be vaccinated?", "answer": ""}, {"question": "What type of drugs are used to treat viral infections?", "answer": "Antiviral drugs", "ae_score": -0.5170416898651911, "qg_score": null}, {"question": "What type of drugs are used to treat viral infections?", "answer": "Antiviral drugs", "ae_score": -0.5170416898651911, "qg_score": null}], "content": "While most antivirals treat viral infection, vaccines are a preemptive first line of defense against pathogens. Vaccination involves the introduction (i.e. via injection) of a small amount of typically inactivated or attenuated antigenic material to stimulate an individual\u2019s immune system. The immune system responds by developing white blood cells to specifically combat the introduced pathogen, resulting in adaptive immunity. Vaccination in a population results in herd immunity and greatly improved population health, with significant reductions in viral infection and disease.\nVaccination policy in the United States consists of public and private vaccination requirements. For instance, public schools require students to receive vaccinations (termed \u201cvaccination schedule\u201d) for viruses such as diphtheria, pertussis, and tetanus (DTaP), measles, mumps, rubella (MMR), varicella (chickenpox), hepatitis B, rotavirus, polio, and more. Private institutions might require annual influenza vaccination. The Center for Disease Control and Prevention has estimated that routine immunization of newborns prevents about 42,000 deaths and 20 million cases of disease each year, saving about $13.6 billion.\nDespite their successes, there is plenty of stigma surrounding vaccines that cause people to be incompletely vaccinated. These \u201cgaps\u201d in vaccination result in unnecessary infection, death, and costs. There are two major reasons for incomplete vaccination:\nAlthough the American Academy of Pediatrics endorses universal immunization, they note that physicians should respect parents\u2019 refusal to vaccinate their children after sufficient advising and provided the child does not face a significant risk of infection. Parents can also cite religious reasons to avoid public school vaccination mandates, but this reduces herd immunity and increases risk of viral infection.<ref name=HDL/>\nVaccines bolster the body's immune system to better attack viruses in the \"complete particle\" stage, outside of the organism's cells. They traditionally consist of an attenuated (a live weakened) or inactivated (killed) version of the virus. These vaccines can, in very rare cases, harm the host by inadvertently infecting the host with a full-blown viral occupancy. Recently \"subunit\" vaccines have been devised that consist strictly of protein targets from the pathogen. They stimulate the immune system without doing serious harm to the host. In either case, when the real pathogen attacks the subject, the immune system responds to it quickly and blocks it.\nVaccines are very effective on stable viruses, but are of limited use in treating a patient who has already been infected. They are also difficult to successfully deploy against rapidly mutating viruses, such as influenza (the vaccine for which is updated every year) and HIV. Antiviral drugs are particularly useful in these cases.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Limitations and Policy Implications", "sub_heading": "Vaccinations and stigma", "_id": "81--2--1---1", "title": "Vaccines and the Importance of Vaccines"}
{"qas": [{"question": "What is the purpose of the black market in the United States?", "answer": ""}, {"question": "What is the meaning of antiviral drug in english?", "answer": "Use and Distribution", "ae_score": -0.08075142081378688, "qg_score": null}, {"question": "What is the meaning of antiviral drug in english?", "answer": "Use and Distribution", "ae_score": -0.08075142081378688, "qg_score": null}], "content": "'''Use and Distribution'''\nGuidelines regarding viral diagnoses and treatments change frequently and limit quality care. Even when physicians diagnose older patients with influenza, use of antiviral treatment can be low. Provider knowledge of antiviral therapies can improve patient care, especially in geriatric medicine. Furthermore, in local health departments (LHDs) with access to antivirals, guidelines may be unclear, causing delays in treatment. With time-sensitive therapies, delays could lead to lack of treatment.Overall, national guidelines regarding infection control and management standardize care and improve patient and health care worker safety. Guidelines such as those provided by the Centers for Disease Control and Prevention (CDC) during the 2009 flu pandemic caused by the H1N1 virus, recommend antiviral treatment regimens, clinical assessment algorithms for coordination of care, and antiviral chemoprophylaxis guidelines for exposed persons, among others. Roles of pharmacists and pharmacies have also expanded to meet the needs of public during public health emergencies.\n'''Stockpiling'''Public Health Emergency Preparedness initiatives are managed by the CDC via the Office of Public Health Preparedness and Response. Funds aim to support communities in preparing for public health emergencies, including pandemic influenza. Also managed by the CDC, the Strategic National Stockpile (SNS) consists of bulk quantities of medicines and supplies for use during such emergencies. Antiviral stockpiles prepare for shortages of antiviral medications in cases of public health emergencies. During the H1N1 pandemic in 2009-2010, guidelines for SNS use by local health departments was unclear, revealing gaps in antiviral planning.<ref name=NACCHO/> For example, local health departments that received antivirals from the SNS did not have transparent guidance on the use of the treatments. The gap made it difficult to create plans and policies for their use and future availabilities, causing delays in treatment.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Limitations and Policy Implications", "sub_heading": "Public policy", "_id": "81--2--2---1", "title": "'''Stockpiling''''Public Health Emergency Prepared"}
{"qas": [{"question": "How do scientists know what the target protein is?", "answer": ""}, {"question": "How to design a drug at the molecular level?", "answer": "computer-aided design program", "ae_score": -0.4011640328444308, "qg_score": null}, {"question": "How to design a drug at the molecular level?", "answer": "computer-aided design program", "ae_score": -0.4011640328444308, "qg_score": null}], "content": "The general idea behind modern antiviral drug design is to identify viral proteins, or parts of proteins, that can be disabled. These \"targets\" should generally be as unlike any proteins or parts of proteins in humans as possible, to reduce the likelihood of side effects. The targets should also be common across many strains of a virus, or even among different species of virus in the same family, so a single drug will have broad effectiveness. For example, a researcher might target a critical enzyme synthesized by the virus, but not the patient, that is common across strains, and see what can be done to interfere with its operation.\nOnce targets are identified, candidate drugs can be selected, either from drugs already known to have appropriate effects, or by actually designing the candidate at the molecular level with a computer-aided design program.\nThe target proteins can be manufactured in the lab for testing with candidate treatments by inserting the gene that synthesizes the target protein into bacteria or other kinds of cells. The cells are then cultured for mass production of the protein, which can then be exposed to various treatment candidates and evaluated with \"rapid screening\" technologies.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Anti-viral targeting", "sub_heading": "Anti-viral targeting", "_id": "81--3---1---1", "title": "Antiviral Drug Design"}
{"qas": [{"question": "Why is it that when you have a viral infection, you can't get rid of it?", "answer": ""}, {"question": "What is the most common cause of the cold?", "answer": "Rhinoviruses", "ae_score": -0.21249024729478624, "qg_score": null}, {"question": "What is the most common cause of the cold?", "answer": "Rhinoviruses", "ae_score": -0.21249024729478624, "qg_score": null}], "content": "One anti-viral strategy is to interfere with the ability of a virus to infiltrate a target cell. The virus must go through a sequence of steps to do this, beginning with binding to a specific \"receptor\" molecule on the surface of the host cell and ending with the virus \"uncoating\" inside the cell and releasing its contents. Viruses that have a lipid envelope must also fuse their envelope with the target cell, or with a vesicle that transports them into the cell, before they can uncoat.\nThis stage of viral replication can be inhibited in two ways:\nThis strategy of designing drugs can be very expensive, and since the process of generating anti-idiotypic antibodies is partly trial and error, it can be a relatively slow process until an adequate molecule is produced.\nA very early stage of viral infection is viral entry, when the virus attaches to and enters the host cell. A number of \"entry-inhibiting\" or \"entry-blocking\" drugs are being developed to fight HIV. HIV most heavily targets the immune system's white blood cells known as \"helper T cells\", and identifies these target cells through T-cell surface receptors designated \"CD4\" and \"CCR5\". Attempts to interfere with the binding of HIV with the CD4 receptor have failed to stop HIV from infecting helper T cells, but research continues on trying to interfere with the binding of HIV to the CCR5 receptor in hopes that it will be more effective.\nHIV infects a cell through fusion with the cell membrane, which requires two different cellular molecular participants, CD4 and a chemokine receptor (differing depending on the cell type).  Approaches to blocking this virus/cell fusion have shown some promise in preventing entry of the virus into a cell.  At least one of theses entry inhibitors\u2014a biomimetic peptide marketed under the brand name Fuzeon\u2014has received FDA approval and has been in use for some time.  Potentially, one of the benefits from the use of an effective entry-blocking or entry-inhibiting agent is that it potentially may not only prevent the spread of the virus within an infected individual but also the spread from an infected to an uninfected individual.\nOne possible advantage of the therapeutic approach of blocking viral entry (as opposed to the currently dominant approach of viral enzyme inhibition) is that it may prove more difficult for the virus to develop resistance to this therapy than for the virus to mutate or evolve its enzymatic protocols.\nInhibitors of uncoating have also been investigated.\nAmantadine and rimantadine have been introduced to combat influenza. These agents act on penetration and uncoating.\nPleconaril works against rhinoviruses, which cause the common cold, by blocking a pocket on the surface of the virus that controls the uncoating process. This pocket is similar in most strains of rhinoviruses and enteroviruses, which can cause diarrhea, meningitis, conjunctivitis, and encephalitis.\nSome scientists are making the case that a vaccine against rhinoviruses, the predominant cause of the common cold, is achievable.Vaccines that combine dozens of varieties of rhinovirus at once are effective in stimulating antiviral antibodies in mice and monkeys, researchers have reported in Nature Communications in 2016.\nThe quest for a vaccine against rhinoviruses may have seemed quixotic, because there are more than 100 varieties circulating around the world.  But the immune system can handle the challenge.\nRhinoviruses are the most common cause of the common cold; other viruses such as respiratory syncytial virus, parainfluenza virus and adenoviruses can cause them too. Rhinoviruses also exacerbate asthma attacks. Although rhinoviruses  come in many varieties, they do not drift to the same degree that influenza viruses do. A  mixture of 50 inactivated rhinovirus types should be able to stimulate neutralizing antibodies against all of them to some degree.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Approaches by life cycle stage", "sub_heading": "Approaches by life cycle stage", "_id": "81--4--0---1", "title": "Vaccines Against Rhinoviruses"}
{"qas": [{"question": "How do we know that our bodies are capable of mutating viruses?", "answer": ""}, {"question": "What is the name for the integration of dna into the host cell genome?", "answer": "integrase", "ae_score": -0.04705738162814625, "qg_score": null}, {"question": "What is the name for the integration of dna into the host cell genome?", "answer": "integrase", "ae_score": -0.04705738162814625, "qg_score": null}], "content": "A second approach is to target the processes that synthesize virus components after a virus invades a cell.\nOne way of doing this is to develop nucleotide or nucleoside analogues that look like the building blocks of RNA or DNA, but deactivate the enzymes that synthesize the RNA or DNA once the analogue is incorporated. This approach is more commonly associated with the inhibition of reverse transcriptase (RNA to DNA) than with \"normal\" transcriptase (DNA to RNA).\nThe first successful antiviral, acyclovir, is a nucleoside analogue, and is effective against herpesvirus infections. The first antiviral drug to be approved for treating HIV, zidovudine (AZT), is also a nucleoside analogue.\nAn improved knowledge of the action of reverse transcriptase has led to better nucleoside analogues to treat HIV infections. One of these drugs, lamivudine, has been approved to treat hepatitis B, which uses reverse transcriptase as part of its replication process. Researchers have gone further and developed inhibitors that do not look like nucleosides, but can still block reverse transcriptase.\nAnother target being considered for HIV antivirals include RNase H \u2013 which is a component of reverse transcriptase that splits the synthesized DNA from the original viral RNA.\nOn 10 August 2011 researchers at MIT announced the publication of a new method of inhibiting RNA, the process selectively affected infected cells. The team named the process \"Double-stranded RNA Activated Caspase Oligomerizer\" (DRACO). According to the lead researcher \"In theory, [DRACO] should work against all viruses.\"\nAnother target is integrase, which integrate the synthesized DNA into the host cell genome.\nOnce a virus genome becomes operational in a host cell, it then generates messenger RNA (mRNA) molecules that direct the synthesis of viral proteins. Production of mRNA is initiated by proteins known as transcription factors. Several antivirals are now being designed to block attachment of transcription factors to viral DNA.\nGenomics has not only helped find targets for many antivirals, it has provided the basis for an entirely new type of drug, based on \"antisense\" molecules. These are segments of DNA or RNA that are designed as complementary molecule to critical sections of viral genomes, and the binding of these antisense segments to these target sections blocks the operation of those genomes. A phosphorothioate antisense drug named fomivirsen has been introduced, used to treat opportunistic eye infections in AIDS patients caused by cytomegalovirus, and other antisense antivirals are in development. An antisense structural type that has proven especially valuable in research is morpholino antisense.\nMorpholino oligos have been used to experimentally suppress many viral types:\nYet another antiviral technique inspired by genomics is a set of drugs based on ribozymes, which are enzymes that will cut apart viral RNA or DNA at selected sites. In their natural course, ribozymes are used as part of the viral manufacturing sequence, but these synthetic ribozymes are designed to cut RNA and DNA at sites that will disable them.\nA ribozyme antiviral to deal with hepatitis C has been suggested, and ribozyme antivirals are being developed to deal with HIV. An interesting variation of this idea is the use of genetically modified cells that can produce custom-tailored ribozymes. This is part of a broader effort to create genetically modified cells that can be injected into a host to attack pathogens by generating specialized proteins that block viral replication at various phases of the viral life cycle.\nInterference with post translational modifications or with targeting of viral proteins in the cell is also possible.\nSome viruses include an enzyme known as a protease that cuts viral protein chains apart so they can be assembled into their final configuration. HIV includes a protease, and so considerable research has been performed to find \"protease inhibitors\" to attack HIV at that phase of its life cycle. Protease inhibitors became available in the 1990s and have proven effective, though they can have unusual side effects, for example causing fat to build up in unusual places. Improved protease inhibitors are now in development.\nProtease inhibitors have also been seen in nature. A protease inhibitor was isolated from the Shiitake mushroom (''Lentinus edodes'').  The presence of this may explain the Shiitake mushrooms noted antiviral activity ''in vitro''.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Approaches by life cycle stage", "sub_heading": "During viral synthesis", "_id": "81--4--1---1", "title": "Antivirals: A New Approach to Antiviral Therapy"}
{"qas": [{"question": "How do antivirals work?", "answer": ""}, {"question": "What is the molecule that is found on the surface of flu viruses?", "answer": "neuraminidase", "ae_score": -0.6599802738416822, "qg_score": null}, {"question": "What is the molecule that is found on the surface of flu viruses?", "answer": "neuraminidase", "ae_score": -0.6599802738416822, "qg_score": null}], "content": "The final stage in the life cycle of a virus is the release of completed viruses from the host cell, and this step has also been targeted by antiviral drug developers. Two drugs named zanamivir (Relenza) and oseltamivir (Tamiflu) that have been recently introduced to treat influenza prevent the release of viral particles by blocking a molecule named neuraminidase that is found on the surface of flu viruses, and also seems to be constant across a wide range of flu strains.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Approaches by life cycle stage", "sub_heading": "Release phase", "_id": "81--4--3---1", "title": "Antiviral Drugs Target the Release of Viral Particles from the Host"}
{"qas": [{"question": "How do anti-viral drugs work?", "answer": ""}, {"question": "What type of antiviral drug inhibits viral synthesis in infected cells?", "answer": "interferons", "ae_score": -0.14389455583870156, "qg_score": null}, {"question": "What type of antiviral drug inhibits viral synthesis in infected cells?", "answer": "interferons", "ae_score": -0.14389455583870156, "qg_score": null}], "content": "A second category of tactics for fighting viruses involves encouraging the body's immune system to attack them, rather than attacking them directly. Some antivirals of this sort do not focus on a specific pathogen, instead stimulating the immune system to attack a range of pathogens.\nOne of the best-known of this class of drugs are interferons, which inhibit viral synthesis in infected cells. One form of human interferon named \"interferon alpha\" is well-established as part of the standard treatment for hepatitis B and C, and other interferons are also being investigated as treatments for various diseases.\nA more specific approach is to synthesize antibodies, protein molecules that can bind to a pathogen and mark it for attack by other elements of the immune system. Once researchers identify a particular target on the pathogen, they can synthesize quantities of identical \"monoclonal\" antibodies to link up that target. A monoclonal drug is now being sold to help fight respiratory syncytial virus in babies, and antibodies purified from infected individuals are also used as a treatment for hepatitis B.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Immune system stimulation", "sub_heading": "Immune system stimulation", "_id": "81--5---1---1", "title": "Antivirals: How to Use Antivirals to Combat Viral Diseases"}
{"qas": [{"question": "Why do some people get sick with the flu and others don't?", "answer": ""}, {"question": "What is the main function of antiviral drugs?", "answer": "Detection of antiviral resistance", "ae_score": -0.1867453131388237, "qg_score": null}, {"question": "What is the main function of antiviral drugs?", "answer": "Detection of antiviral resistance", "ae_score": -0.1867453131388237, "qg_score": null}], "content": "Antiviral resistance can be defined by a decreased susceptibility to a drug through either a minimally effective, or completely ineffective, treatment response to prevent associated illnesses from a particular virus. The issue inevitably remains a major obstacle to antiviral therapy as it has developed to almost all specific and effective antimicrobials, including antiviral agents.\nThe Centers for Disease Control and Prevention (CDC) inclusively recommends those six months and older to get a yearly vaccination to protect from influenza A viruses (H1N1) and (H3N2) and up to two influenza B viruses (depending on the vaccination).<ref name= CDC/> Comprehensive protection starts by ensuring vaccinations are current and complete. The three FDA-approved neuraminidase antiviral flu drugs available in the United States, recommended by the CDC, include: oseltamivir (Tamiflu\u00ae), zanamivir (Relenza\u00ae), and peramivir (Rapivab\u00ae).<ref name= CDC/>\nA study published in 2009 in Nature Biotechnology emphasized the urgent need for augmentation of oseltamivir (Tamiflu\u00ae) stockpiles with additional antiviral drugs including zanamivir (Relenza\u00ae). This finding was based on a performance evaluation of these drugs supposing the 2009 H1N1 'Swine Flu' neuraminidase (NA) were to acquire the Tamiflu-resistance (His274Tyr) mutation which is currently widespread in seasonal H1N1 strains.\n'''Origin of antiviral resistance'''\nThe genetic makeup of viruses is constantly changing and therefore may alter the virus resistant to the treatments currently available. Viruses can become resistant through spontaneous or intermittent mechanisms throughout the course of an antiviral treatment. Immunocompromised patients, more often than immunocompetent patients, hospitalized with pneumonia are at the highest risk of developing oseltamivir resistance during treatment.<ref name= CDC/> Subsequent to exposure to someone else with the flu, those who received oseltamivir for \u201cpost-exposure prophylaxis\u201d are also at higher risk of resistance.\n'''Detection of antiviral resistance'''\nNational and international surveillance is performed by the CDC to determine effectiveness of the current FDA-approved antiviral flu drugs.<ref name= CDC/> Public health officials use this information to make current recommendations about the use of flu antiviral medications. WHO further recommends in-depth epidemiological investigations to control potential transmission of the resistant virus and prevent future progression.  As novel treatments and detection techniques to antiviral resistance are enhanced so can the establishment of strategies to combat the inevitable emergence of antiviral resistance.", "page_name": "Antiviral drug", "page_id": "Antiviral%20drug", "heading": "Acquired resistance", "sub_heading": "Acquired resistance", "_id": "81--6---1---1", "title": "Antiviral Resistance in the United States"}
{"qas": [{"question": "Secretory Diarrhea?", "answer": ""}, {"question": "What is the most common cause of secretory diarrhea?", "answer": "cholera toxin", "ae_score": -0.8500426880815696, "qg_score": null}, {"question": "What is the most common cause of secretory diarrhea?", "answer": "cholera toxin", "ae_score": -0.8500426880815696, "qg_score": null}], "content": "Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption. There is little to no structural damage. The most common cause of this type of diarrhea is a cholera toxin that stimulates the secretion of anions, especially chloride ions. Therefore, to maintain a charge balance in the gastrointestinal tract, sodium is carried with it, along with water. In this type of diarrhea intestinal fluid secretion is isotonic with plasma even during fasting. It continues even when there is no oral food intake.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Definition", "sub_heading": "Definition", "_id": "82--0--0---1", "title": "Secretory Diarrhea Symptoms"}
{"qas": [{"question": "What causes osmotic diarrhea?", "answer": ""}, {"question": "What is it called when water is drawn into the bowels?", "answer": "Osmotic diarrhea", "ae_score": -0.8697674302778355, "qg_score": null}, {"question": "What is it called when water is drawn into the bowels?", "answer": "Osmotic diarrhea", "ae_score": -0.8697674302778355, "qg_score": null}], "content": "Osmotic diarrhea occurs when too much water is drawn into the bowels. If a person drinks solutions with excessive sugar or excessive salt, these can draw water from the body into the bowel and cause osmotic diarrhea. Osmotic diarrhea can also be the result of maldigestion (e.g., pancreatic disease or Coeliac disease), in which the nutrients are left in the lumen to pull in water. Or it can be caused by osmotic laxatives (which work to alleviate constipation by drawing water into the bowels). In healthy individuals, too much magnesium or vitamin C or undigested lactose can produce osmotic diarrhea and distention of the bowel. A person who has lactose intolerance can have difficulty absorbing lactose after an extraordinarily high intake of dairy products. In persons who have fructose malabsorption, excess fructose intake can also cause diarrhea. High-fructose foods that also have a high glucose content are more absorbable and less likely to cause diarrhea. Sugar alcohols such as sorbitol (often found in sugar-free foods) are difficult for the body to absorb and, in large amounts, may lead to osmotic diarrhea. In most of these cases, osmotic diarrhea stops when the offending agent (e.g. milk, sorbitol) is stopped.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Definition", "sub_heading": "Osmotic", "_id": "82--0--1---1", "title": "Osmotic Diarrhea Symptoms and Treatment"}
{"qas": [{"question": "Exudative diarrhea?", "answer": ""}, {"question": "Exudative diarrhea occurs with the presence of what in the stool?", "answer": "blood and pus", "ae_score": -1.369952338076326, "qg_score": null}, {"question": "Exudative diarrhea occurs with the presence of what in the stool?", "answer": "blood and pus", "ae_score": -1.369952338076326, "qg_score": null}], "content": "Exudative diarrhea occurs with the presence of blood and pus in the stool. This occurs with inflammatory bowel diseases, such as Crohn's disease or ulcerative colitis, and other severe infections such as ''E. coli'' or other forms of food poisoning.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Definition", "sub_heading": "Exudative", "_id": "82--0--2---1", "title": "''Exudative Diarrhea'' Symptoms"}
{"qas": [{"question": "What islammatory diarrhea?", "answer": ""}, {"question": "How many types of inflammatory diarrhea are there?", "answer": "three", "ae_score": null, "qg_score": null}, {"question": "How many types of inflammatory diarrhea are there?", "answer": "three", "ae_score": null, "qg_score": null}], "content": "Inflammatory diarrhea occurs when there is damage to the mucosal lining or brush border, which leads to a passive loss of protein-rich fluids and a decreased ability to absorb these lost fluids. Features of all three of the other types of diarrhea can be found in this type of diarrhea. It can be caused by bacterial infections, viral infections, parasitic infections, or autoimmune problems such as inflammatory bowel diseases. It can also be caused by tuberculosis, colon cancer, and enteritis. ", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Definition", "sub_heading": "Inflammatory", "_id": "82--0--3---1", "title": "Inflammatory Diarrhea is a Type of Diarrhea"}
{"qas": [{"question": "Why do we see blood in our stools?", "answer": ""}, {"question": "What is it called if there is blood in the stools?", "answer": "dysentery", "ae_score": -0.19636586345600382, "qg_score": null}, {"question": "What is it called if there is blood in the stools?", "answer": "dysentery", "ae_score": -0.19636586345600382, "qg_score": null}], "content": "If there is blood visible in the stools, it is also known as dysentery. The blood is a trace of an invasion of bowel tissue. Dysentery is a symptom of, among others, ''Shigella'', ''Entamoeba histolytica'', and ''Salmonella''.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Definition", "sub_heading": "Dysentery", "_id": "82--0--4---1", "title": "Dysentery is a symptom of ''Shigella'' and"}
{"qas": [{"question": "Why is diarrhea bad for you?", "answer": ""}, {"question": "What is the main cause of childhood malnutrition?", "answer": "diarrhea", "ae_score": -0.5873723625798111, "qg_score": null}, {"question": "What is the main cause of childhood malnutrition?", "answer": "diarrhea", "ae_score": -0.5873723625798111, "qg_score": null}], "content": "Diarrheal disease may have a negative impact on both physical fitness and mental development. \"Early childhood malnutrition resulting from any cause reduces physical fitness and work productivity in adults,\" and diarrhea is a primary cause of childhood malnutrition. Further, evidence suggests that diarrheal disease has significant impacts on mental development and health; it has been shown that, even when controlling for helminth infection and early breastfeeding, children who had experienced severe diarrhea had significantly lower scores on a series of tests of intelligence.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Health effects", "sub_heading": "Health effects", "_id": "82--1---1---1", "title": "Diarrheal Disease and Mental Health"}
{"qas": [{"question": "Why do some people have diarrhea and others don't?", "answer": ""}, {"question": "What is the most common cause of viral diarrhea in adults?", "answer": "Norovirus", "ae_score": -0.15976177336583033, "qg_score": null}, {"question": "What is the most common cause of viral diarrhea in adults?", "answer": "Norovirus", "ae_score": -0.15976177336583033, "qg_score": null}], "content": "Acute diarrhea is most commonly due to viral gastroenteritis with rotavirus, which accounts for 40% of cases in children under five.<ref name=WHO2010a/> (p. 17) In travelers however bacterial infections predominate. Various toxins such as mushroom poisoning and drugs can also cause acute diarrhea.\nChronic diarrhea can be the part of the presentations of a number of chronic medical conditions affecting the intestine. Common causes include ulcerative colitis, Crohn's disease, microscopic colitis, celiac disease, irritable bowel syndrome and bile acid malabsorption.\nThere are many causes of infectious diarrhea, which include viruses, bacteria and parasites. Infectious diarrhea is frequently referred to as gastroenteritis. Norovirus is the most common cause of viral diarrhea in adults, but rotavirus is the most common cause in children under five years old. Adenovirus types 40 and 41, and astroviruses cause a significant number of infections.\n''Campylobacter'' spp. are a common cause of bacterial diarrhea, but infections by ''Salmonella'' spp., ''Shigella'' spp. and some strains of ''Escherichia coli'' are also a frequent cause.\nIn the elderly, particularly those who have been treated with antibiotics for unrelated infections, a toxin produced by ''Clostridium difficile'' often causes severe diarrhea.\nParasites, particularly protozoa (e.g., ''Cryptosporidium'' spp., ''Giardia'' spp., ''Entamoeba histolytica'', ''Blastocystis'' spp., ''Cyclospora cayetanensis''), are frequently the cause of diarrhea that involves chronic infection. The broad-spectrum antiparasitic agent nitazoxanide has shown efficacy against many diarrhea-causing parasites.\nOther infectious agents, such as parasites or bacterial toxins, may exacerbate symptoms. In sanitary living conditions where there is ample food and a supply of clean water, an otherwise healthy person usually recovers from viral infections in a few days. However, for ill or malnourished individuals, diarrhea can lead to severe dehydration and can become life-threatening.\nMalabsorption is the inability to absorb food fully, mostly from disorders in the small bowel, but also due to maldigestion from diseases of the pancreas.\nCauses include:\nThe two overlapping types here are of unknown origin:\nAnother possible cause of diarrhea is irritable bowel syndrome (IBS), which usually presents with abdominal discomfort relieved by defecation and unusual stool (diarrhea or constipation) for at least 3 days a week over the previous 3 months. Symptoms of diarrhea-predominant IBS can be managed through a combination of dietary changes, soluble fiber supplements, and/or medications such as loperamide or codeine. About 30% of patients with diarrhea-predominant IBS have bile acid malabsorption diagnosed with an abnormal SeHCAT test.\nDiarrhea can be caused by other diseases and conditions, namely: ", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Differential diagnosis", "sub_heading": "Differential diagnosis", "_id": "82--2---1---1", "title": "Causes of Diarrhea in Children and Adults"}
{"qas": [{"question": "Why is it so dangerous to defecate in public?", "answer": ""}, {"question": "What is the leading cause of infectious diarrhea leading to death?", "answer": "Open defecation", "ae_score": -0.0627886976132846, "qg_score": null}, {"question": "What is the leading cause of infectious diarrhea leading to death?", "answer": "Open defecation", "ae_score": -0.0627886976132846, "qg_score": null}], "content": "Open defecation is a leading cause of infectious diarrhea leading to death.\nPoverty is a good indicator of the rate of infectious diarrhea in a population. This association does not stem from poverty itself, but rather from the conditions under which impoverished people live. The absence of certain resources compromises the ability of the poor to defend themselves against infectious diarrhea. \"Poverty is associated with poor housing, crowding, dirt floors, lack of access to clean water or to sanitary disposal of fecal waste (sanitation), cohabitation with domestic animals that may carry human pathogens, and a lack of refrigerated storage for food, all of which increase the frequency of diarrhea... Poverty also restricts the ability to provide age-appropriate, nutritionally balanced diets or to modify diets when diarrhea develops so as to mitigate and repair nutrient losses. The impact is exacerbated by the lack of adequate, available, and affordable medical care.\"\nOne of the most common causes of infectious diarrhea, is a lack of clean water. Often, improper fecal disposal leads to contamination of groundwater. This can lead to widespread infection among a population, especially in the absence of water filtration or purification. Human feces contains a variety of potentially harmful human pathogens.\nProper nutrition is important for health and functioning, including the prevention of infectious diarrhea. It is especially important to young children who do not have a fully developed immune system. Zinc deficiency, a condition often found in children in developing countries can, even in mild cases, have a significant impact on the development and proper functioning of the human immune system. Indeed, this relationship between zinc deficiency and reduced immune functioning corresponds with an increased severity of infectious diarrhea. Children who have lowered levels of zinc have a greater number of instances of diarrhea, severe diarrhea, and diarrhea associated with fever. Similarly, vitamin A deficiency can cause an increase in the severity of diarrheal episodes. However, there is some discrepancy when it comes to the impact of vitamin A deficiency on the rate of disease. While some argue that a relationship does not exist between the rate of disease and vitamin A status, others suggest an increase in the rate associated with deficiency. Given that estimates suggest 127 million preschool children worldwide are vitamin A deficient, this population has the potential for increased risk of disease contraction.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Causes", "sub_heading": "Causes", "_id": "82--3---1---1", "title": "The Impact of Vitamin A Deficiency on Infectious Diarrhea"}
{"qas": [{"question": "Why do some people have diarrhea and others don't?", "answer": ""}, {"question": "In what year was research published that supported nesse and williams' argument?", "answer": "1973", "ae_score": -0.6716466656709803, "qg_score": null}, {"question": "In what year was research published that supported nesse and williams' argument?", "answer": "1973", "ae_score": -0.6716466656709803, "qg_score": null}], "content": "According to two researchers, Nesse and Williams, diarrhea may function as an evolved expulsion defense mechanism. As a result, if it is stopped, there might be a delay in recovery. They cite in support of this argument research published in 1973 that found that treating ''Shigella'' with the anti-diarrhea drug (Co-phenotrope, Lomotil) caused people to stay feverish twice as long as those not so treated. The researchers indeed themselves observed that: \"Lomotil may be contraindicated in shigellosis. Diarrhea may represent a defense mechanism\".", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "82--4---1---1", "title": "Diarrhea may be a defense mechanism"}
{"qas": [{"question": "Why is it bad to wash your hands with soap and water?", "answer": ""}, {"question": "What is chlorine treatment of water shown to reduce?", "answer": "diarrheal disease", "ae_score": -0.24017772095327505, "qg_score": null}, {"question": "What is chlorine treatment of water shown to reduce?", "answer": "diarrheal disease", "ae_score": -0.24017772095327505, "qg_score": null}], "content": "Numerous studies have shown that improvements in drinking water and sanitation (WASH) lead to decreased risks of diarrhoea. Such improvements might include for example use of water filters, provision of high-quality piped water and sewer connections.\nIn institutions, communities, and households, interventions that promote hand washing with soap lead to significant reductions in the incidence of diarrhea. The same applies to preventing open defecation at a community-wide level and providing access to improved sanitation. This includes use of toilets and implementation of the entire sanitation chain connected to the toilets (collection, transport, disposal or reuse of human excreta).\nBasic sanitation techniques can have a profound effect on the transmission of diarrheal disease. The implementation of hand washing using soap and water, for example, has been experimentally shown to reduce the incidence of disease by approximately 42\u201348%. Hand washing in developing countries, however, is compromised by poverty as acknowledged by the CDC: \"Handwashing is integral to disease prevention in all parts of the world; however, access to soap and water is limited in a number of less developed countries. This lack of access is one of many challenges to proper hygiene in less developed countries.\" Solutions to this barrier require the implementation of educational programs that encourage sanitary behaviours.\nGiven that water contamination is a major means of transmitting diarrheal disease, efforts to provide clean water supply and improved sanitation have the potential to dramatically cut the rate of disease incidence. In fact, it has been proposed that we might expect an 88% reduction in child mortality resulting from diarrheal disease as a result of improved water sanitation and hygiene. Similarly, a meta-analysis of numerous studies on improving water supply and sanitation shows a 22\u201327% reduction in disease incidence, and a 21\u201330% reduction in mortality rate associated with diarrheal disease.\nChlorine treatment of water, for example, has been shown to reduce both the risk of diarrheal disease, and of contamination of stored water with diarrheal pathogens.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Prevention", "sub_heading": "Prevention", "_id": "82--6--0---1", "title": "Diarrhoea and the Importance of Improved Water and Sanit"}
{"qas": [{"question": "Why do we have to take antibiotics to prevent diarrhea?", "answer": ""}, {"question": "Along with rotavirus, what other cause of infectious diarrhea is being studied?", "answer": "cholera", "ae_score": -0.6043177938133089, "qg_score": null}, {"question": "Along with rotavirus, what other cause of infectious diarrhea is being studied?", "answer": "cholera", "ae_score": -0.6043177938133089, "qg_score": null}], "content": "Immunization against the pathogens that cause diarrheal disease is a viable prevention strategy, however it does require targeting certain pathogens for vaccination. In the case of Rotavirus, which was responsible for around 6% of diarrheal episodes and 20% of diarrheal disease deaths in the children of developing countries, use of a Rotavirus vaccine in trials in 1985 yielded a slight (2-3%) decrease in total diarrheal disease incidence, while reducing overall mortality by 6-10%. Similarly, a Cholera vaccine showed a strong reduction in morbidity and mortality, though the overall impact of vaccination was minimal as Cholera is not one of the major causative pathogens of diarrheal disease. Since this time, more effective vaccines have been developed that have the potential to save many thousands of lives in developing nations, while reducing the overall cost of treatment, and the costs to society.\nA rotavirus vaccine decrease the rates of diarrhea in a population.<ref name=WHO2010a/> New vaccines against rotavirus, ''Shigella'', Enterotoxigenic Escherichia coli (ETEC), and cholera are under development, as well as other causes of infectious diarrhea.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Prevention", "sub_heading": "Vaccination", "_id": "82--6--1---1", "title": "Rotavirus Vaccine Reduces Diarrhea Rates"}
{"qas": [{"question": "Why is it that in developing countries, people are more likely to have diarrhea than people in the control group?", "answer": ""}, {"question": "What has been shown to have a dramatic effect on the incidence of diarrheal disease?", "answer": "Breastfeeding practices", "ae_score": -0.7054501782293997, "qg_score": null}, {"question": "What has been shown to have a dramatic effect on the incidence of diarrheal disease?", "answer": "Breastfeeding practices", "ae_score": -0.7054501782293997, "qg_score": null}], "content": "Dietary deficiencies in developing countries can be combated by promoting better eating practices. Supplementation with vitamin A and/or zinc. Zinc supplementation proved successful showing a significant decrease in the incidence of diarrheal disease compared to a control group. The majority of the literature suggests that vitamin A supplementation is advantageous in reducing disease incidence. Development of a supplementation strategy should take into consideration the fact that vitamin A supplementation was less effective in reducing diarrhea incidence when compared to vitamin A and zinc supplementation, and that the latter strategy was estimated to be significantly more cost effective.\nBreastfeeding practices have been shown to have a dramatic effect on the incidence of diarrheal disease in poor populations. Studies across a number of developing nations have shown that those who receive exclusive breastfeeding during their first 6 months of life are better protected against infection with diarrheal diseases. Exclusive breastfeeding is currently recommended during, at least, the first six months of an infant's life by the WHO.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Prevention", "sub_heading": "Nutrition", "_id": "82--6--2---1", "title": "Diarrhea in developing countries: a review"}
{"qas": [{"question": "How do you prevent dehydration from drinking too much water?", "answer": ""}, {"question": "What occurs during the first hour or two of treatment with ors?", "answer": "Vomiting", "ae_score": -0.5528075146358277, "qg_score": null}, {"question": "What occurs during the first hour or two of treatment with ors?", "answer": "Vomiting", "ae_score": -0.5528075146358277, "qg_score": null}], "content": "Oral rehydration solution (ORS) (a slightly sweetened and salty water) can be used to prevent dehydration. Standard home solutions such as salted rice water, salted yogurt drinks, vegetable and chicken soups with salt can be given. Home solutions such as water in which cereal has been cooked, unsalted soup, green coconut water, weak tea (unsweetened), and unsweetened fresh fruit juices can have from half a teaspoon to full teaspoon of salt (from one-and-a-half to three grams) added per liter. Clean plain water can also be one of several fluids given.<ref name=WHOtreatmentdiarrhoea2005/> There are commercial solutions such as Pedialyte, and relief agencies such as UNICEF widely distribute packets of salts and sugar. A WHO publication for physicians recommends a homemade ORS consisting of one liter water with one teaspoon salt (3 grams) and two tablespoons sugar (18 grams) added<ref name=WHOtreatmentdiarrhoea2005/> (approximately the \"taste of tears\"). Rehydration Project recommends adding the same amount of sugar but only one-half a teaspoon of salt, stating that this more dilute approach is less risky with very little loss of effectiveness. Both agree that drinks with too much sugar or salt can make dehydration worse.<ref name=WHOtreatmentdiarrhoea2005/><ref name=RehydrationProject/>\nAppropriate amounts of supplemental zinc and potassium should be added if available. But the availability of these should not delay rehydration. As WHO points out, the most important thing is to begin preventing dehydration as early as possible.<ref name=WHOtreatmentdiarrhoea2005/> In another example of prompt ORS hopefully preventing dehydration, CDC recommends for the treatment of cholera continuing to give Oral Rehydration Solution during travel to medical treatment.\nVomiting often occurs during the first hour or two of treatment with ORS, especially if a child drinks the solution too quickly, but this seldom prevents successful rehydration since most of the fluid is still absorbed. WHO recommends that if a child vomits, to wait five or ten minutes and then start to give the solution again more slowly.<ref name=WHOtreatmentdiarrhoea2005/>\nDrinks especially high in simple sugars, such as soft drinks and fruit juices, are not recommended in children under 5 years of age as they may ''increase'' dehydration. A too rich solution in the gut draws water from the rest of the body, just as if the person were to drink sea water.<ref name=WHOtreatmentdiarrhoea2005/> Plain water may be used if more specific and effective ORT preparations are unavailable or are not palatable.<ref name=NICE2009/> Additionally, a mix of both plain water and drinks perhaps too rich in sugar and salt can alternatively be given to the same person, with the goal of providing a medium amount of sodium overall.<ref name=WHOtreatmentdiarrhoea2005/> A nasogastric tube can be used in young children to administer fluids if warranted.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Management", "sub_heading": "Management", "_id": "82--7--0---1", "title": "Preventing Dehydration With Oral Rehydration Solution"}
{"qas": [{"question": "Why is it recommended that a child with diarrhea continue to be fed?", "answer": ""}, {"question": "What organization states that food should never be withheld and should not be diluted?", "answer": "WHO", "ae_score": null, "qg_score": null}, {"question": "What organization states that food should never be withheld and should not be diluted?", "answer": "WHO", "ae_score": null, "qg_score": null}], "content": "WHO recommends a child with diarrhea continue to be fed. Continued feeding speeds the recovery of normal intestinal function. In contrast, children whose food is restricted have diarrhea of longer duration and recover intestinal function more slowly. A child should also continue to be breastfed. The WHO states \"Food should ''never'' be withheld and the child's usual foods should ''not'' be diluted. Breastfeeding should ''always'' be continued.\"<ref name=WHOtreatmentdiarrhoea2005/> And in the specific example of cholera, CDC also makes the same recommendation.<ref name = CDCmanualCholera/> In young children who are not breast-fed and live in the developed world, a lactose-free diet may be useful to speed recovery.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Management", "sub_heading": "Eating", "_id": "82--7--1---1", "title": "WHO recommends a child with diarrhea continue to be fed"}
{"qas": [{"question": "Why is it that people with traveler's diarrhea are more likely to die from diarrhea than people with normal diarrhea?", "answer": ""}, {"question": "What anti-motility agent can reduce the number of stools but not the duration?", "answer": "loperamide", "ae_score": -0.4655054558084621, "qg_score": null}, {"question": "What anti-motility agent can reduce the number of stools but not the duration?", "answer": "loperamide", "ae_score": -0.4655054558084621, "qg_score": null}], "content": "While antibiotics are beneficial in certain types of acute diarrhea, they are usually not used except in specific situations.<ref name=CE08/> There are concerns that antibiotics may increase the risk of hemolytic uremic syndrome in people infected with Escherichia coli O157:H7. In resource-poor countries, treatment with antibiotics may be beneficial. However, some bacteria are developing antibiotic resistance, particularly ''Shigella''. Antibiotics can also cause diarrhea, and antibiotic-associated diarrhea is the most common adverse effect of treatment with general antibiotics.\nWhile bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness. Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease.<ref name=NEJM2014/> These agents should only be used if bloody diarrhea is not present.\nBile acid sequestrants such as cholestyramine can be effective in chronic diarrhea due to bile acid malabsorption. Therapeutic trials of these drugs are indicated in chronic diarrhea if bile acid malabsorption cannot be diagnosed with a specific test, such as SeHCAT retention.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Management", "sub_heading": "Medications", "_id": "82--7--2---1", "title": "Antibiotics in Chronic Diarrhea"}
{"qas": [{"question": "Why is zinc so important for developing countries?", "answer": ""}, {"question": "How much do probiotics reduce the chances of symptoms lasting longer than four days?", "answer": "60%", "ae_score": -0.6794063153071009, "qg_score": null}, {"question": "How much do probiotics reduce the chances of symptoms lasting longer than four days?", "answer": "60%", "ae_score": -0.6794063153071009, "qg_score": null}], "content": "Zinc supplementation benefits children with diarrhea in developing countries, but only in infants over six months old. This supports the World Health Organization guidelines for zinc, but not in the very young.\nProbiotics reduce the duration of symptoms by one day and reduced the chances of symptoms lasting longer than four days by 60%. The probiotic lactobacillus can help prevent antibiotic-associated diarrhea in adults but possibly not children. For those with lactose intolerance, taking digestive enzymes containing lactase when consuming dairy products often improves symptoms.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Management", "sub_heading": "Alternative therapies", "_id": "82--7--3---1", "title": "Diarrhoea in children with diarrhea in developing countries"}
{"qas": [{"question": "Why is diarrhea so common in developing countries?", "answer": ""}, {"question": "How many children died from diarrhea in 2011?", "answer": "0.7 million", "ae_score": -0.34760559988410394, "qg_score": null}, {"question": "How many children died from diarrhea in 2011?", "answer": "0.7 million", "ae_score": -0.34760559988410394, "qg_score": null}], "content": "Worldwide in 2004, approximately 2.5 billion cases of diarrhea occurred, which resulted in 1.5 million deaths among children under the age of five.<ref name=WHO2010a/> Greater than half of these were in Africa and South Asia.<ref name=WHO2010a/> This is down from a death rate of 4.5 million in 1980 for gastroenteritis. Diarrhea remains the second leading cause of infant mortality (16%) after pneumonia (17%) in this age group.<ref name=WHO2010a/>\nThe majority of such cases occur in the developing world, with over half of the recorded cases of childhood diarrhea occurring in Africa and Asia, with 696 million and 1.2 billion cases, respectively, compared to only 480 million in the rest of the world.\nInfectious diarrhea resulted in about 0.7 million deaths in children under five years old in 2011 and 250 million lost school days. In the Americas, diarrheal disease accounts for a total of 10% of deaths among children aged 1\u201359 months while in South East Asia, it accounts for 31.3% of deaths. It is estimated that around 21% of child mortalities in developing countries are due to diarrheal disease.", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "82--8---1---1", "title": "Diarrhea and Child Mortality"}
{"qas": [{"question": "What happens when you get an insect sting?", "answer": ""}, {"question": "What is another name for allergic rhinitis?", "answer": "hay fever", "ae_score": -0.40183430150710986, "qg_score": null}, {"question": "What is another name for allergic rhinitis?", "answer": "hay fever", "ae_score": -0.40183430150710986, "qg_score": null}], "content": "Many allergens such as dust or pollen are airborne particles. In these cases, symptoms arise in areas in contact with air, such as eyes, nose, and lungs. For instance, allergic rhinitis, also known as hay fever, causes irritation of the nose, sneezing, itching, and redness of the eyes. Inhaled allergens can also lead to increased production of mucus in the lungs, shortness of breath, coughing, and wheezing.\nAside from these ambient allergens, allergic reactions can result from foods, insect stings, and reactions to medications like aspirin and antibiotics such as penicillin. Symptoms of food allergy include abdominal pain, bloating, vomiting, diarrhea, itchy skin, and swelling of the skin during hives. Food allergies rarely cause respiratory (asthmatic) reactions, or rhinitis. Insect stings, antibiotics, and certain medicines produce a systemic allergic response that is also called anaphylaxis; multiple organ systems can be affected, including the digestive system, the respiratory system, and the circulatory system. Depending on the rate of severity, it can cause a skin reactions, bronchoconstriction, swelling, low blood pressure, coma, and death. This type of reaction can be triggered suddenly, or the onset can be delayed. The nature of anaphylaxis is such that the reaction can seem to be subsiding, but may recur throughout a period of time.<ref name=tang03/>\nSubstances that come into contact with the skin, such as latex, are also common causes of allergic reactions, known as contact dermatitis or eczema. Skin allergies frequently cause rashes, or swelling and inflammation within the skin, in what is known as a \"wheal and flare\" reaction characteristic of hives and angioedema.\nWith insect stings a large local reaction may occur (an area of skin redness greater than 10 cm in size).<ref name=Lud2015/> It can last one to two days. This reaction may also occur after immunotherapy.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "83--0---1---1", "title": "Symptoms of Food Allergies"}
{"qas": [{"question": "Why are dairy allergies so common in children but not in adults?", "answer": ""}, {"question": "What is the most common food allergy in the us?", "answer": "crustacea", "ae_score": -0.29845837841086614, "qg_score": null}, {"question": "What is the most common food allergy in the us?", "answer": "crustacea", "ae_score": -0.29845837841086614, "qg_score": null}], "content": "A wide variety of foods can cause allergic reactions, but 90% of allergic responses to foods are caused by cow's milk, soy, eggs, wheat, peanuts, tree nuts, fish, and shellfish. Other food allergies, affecting less than 1 person per 10,000 population, may be considered \"rare\".<ref name=Maleki/> The use of hydrolysed milk baby formula versus standard milk baby formula does not appear to change the risk.\nThe most common food allergy in the US population is a sensitivity to crustacea. Although peanut allergies are notorious for their severity, peanut allergies are not the most common food allergy in adults or children. Severe or life-threatening reactions may be triggered by other allergens, and are more common when combined with asthma.\nRates of allergies differ between adults and children. Peanut allergies can sometimes be outgrown by children. Egg allergies affect one to two percent of children but are outgrown by about two-thirds of children by the age of 5. The sensitivity is usually to proteins in the white, rather than the yolk.\nMilk-protein allergies are most common in children. Approximately 60% of milk-protein reactions are immunoglobulin E-mediated, with the remaining usually attributable to inflammation of the colon. Some people are unable to tolerate milk from goats or sheep as well as from cows, and many are also unable to tolerate dairy products such as cheese. Roughly 10% of children with a milk allergy will have a reaction to beef. Beef contains a small amount of protein that is present in cow's milk. Lactose intolerance, a common reaction to milk, is not a form of allergy at all, but rather due to the absence of an enzyme in the digestive tract.\nThose with tree nut allergies may be allergic to one or to many tree nuts, including pecans, pistachios, pine nuts, and walnuts. Also seeds, including sesame seeds and poppy seeds, contain oils in which protein is present, which may elicit an allergic reaction.\nAllergens can be transferred from one food to another through genetic engineering; however genetic modification can also remove allergens. Little research has been done on the natural variation of allergen concentrations in the unmodified crops.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Cause", "_id": "83--1--0---1", "title": "Food Allergens in the United States"}
{"qas": [{"question": "Why do some people have latex allergies while others don't?", "answer": ""}, {"question": "What is the most common allergic reaction to latex?", "answer": "allergic contact dermatitis", "ae_score": -0.4069686046461432, "qg_score": null}, {"question": "What is the most common allergic reaction to latex?", "answer": "allergic contact dermatitis", "ae_score": -0.4069686046461432, "qg_score": null}], "content": "Latex can trigger an IgE-mediated cutaneous, respiratory, and systemic reaction. The prevalence of latex allergy in the general population is believed to be less than one percent. In a hospital study, 1 in 800 surgical patients (0.125 percent) reported latex sensitivity, although the sensitivity among healthcare workers is higher, between seven and ten percent. Researchers attribute this higher level to the exposure of healthcare workers to areas with significant airborne latex allergens, such as operating rooms, intensive-care units, and dental suites. These latex-rich environments may sensitize healthcare workers who regularly inhale allergenic proteins.\nThe most prevalent response to latex is an allergic contact dermatitis, a delayed hypersensitive reaction appearing as dry, crusted lesions. This reaction usually lasts 48\u201396 hours. Sweating or rubbing the area under the glove aggravates the lesions, possibly leading to ulcerations.<ref name=Sussman/> Anaphylactic reactions occur most often in sensitive patients who have been exposed to a surgeon's latex gloves during abdominal surgery, but other mucosal exposures, such as dental procedures, can also produce systemic reactions.<ref name=Sussman/>\nLatex and banana sensitivity may cross-react.  Furthermore, those with latex allergy may also have sensitivities to avocado, kiwifruit, and chestnut. These people often have perioral itching and local urticaria. Only occasionally have these food-induced allergies induced systemic responses. Researchers suspect that the cross-reactivity of latex with banana, avocado, kiwifruit, and chestnut occurs because latex proteins are structurally homologous with some other plant proteins.<ref name=Sussman/>", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Latex", "_id": "83--1--1---1", "title": "Allergy | Cause | Latex"}
{"qas": [{"question": "How many people will have an allergic reaction to urushiol?", "answer": ""}, {"question": "Which poisonous plant is the most virulent?", "answer": "sumac", "ae_score": -0.3095124499847739, "qg_score": null}, {"question": "Which poisonous plant is the most virulent?", "answer": "sumac", "ae_score": -0.3095124499847739, "qg_score": null}], "content": "Another non-food protein reaction, urushiol-induced contact dermatitis, originates after contact with poison ivy, eastern poison oak, western poison oak, or poison sumac. Urushiol, which is not itself a protein, acts as a hapten and chemically reacts with, binds to, and changes the shape of integral membrane proteins on exposed skin cells. The immune system does not recognize the affected cells as normal parts of the body, causing a T-cell\nmediated immune response. Of these poisonous plants, sumac is the most virulent. The resulting dermatological response to the reaction between urushiol and membrane proteins includes redness, swelling, papules, vesicles, blisters, and streaking.\nEstimates vary on the percentage of the population that will have an immune system response. Approximately 25 percent of the population will have a strong allergic response to urushiol. In general, approximately 80 percent to 90 percent of adults will develop a rash if they are exposed to .0050 mg of purified urushiol, but some people are so sensitive that it takes only a molecular trace on the skin to initiate an allergic reaction.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Toxins interacting with proteins", "_id": "83--1--3---1", "title": "Urushiol-Induced Contact Dermatitis"}
{"qas": [{"question": "Why are children more likely to develop allergies than adults?", "answer": ""}, {"question": "What may play a role in some allergies?", "answer": "Ethnicity", "ae_score": -0.4273837347927052, "qg_score": null}, {"question": "What may play a role in some allergies?", "answer": "Ethnicity", "ae_score": -0.4273837347927052, "qg_score": null}], "content": "Allergic diseases are strongly familial: identical twins are likely to have the same allergic diseases about 70% of the time; the same allergy occurs about 40% of the time in non-identical twins. Allergic parents are more likely to have allergic children, and those children's allergies are likely to be more severe than those in children of non-allergic parents. Some allergies, however, are not consistent along genealogies; parents who are allergic to peanuts may have children who are allergic to ragweed. It seems that the likelihood of developing allergies is inherited and related to an irregularity in the immune system, but the specific allergen is not.<ref name=DeSwert/>\nThe risk of allergic sensitization and the development of allergies varies with age, with young children most at risk. Several studies have shown that IgE levels are highest in childhood and fall rapidly between the ages of 10 and 30 years.<ref name=Croner/> The peak prevalence of hay fever is highest in children and young adults and the incidence of asthma is highest in children under 10.\nOverall, boys have a higher risk of developing allergies than girls,<ref name=DeSwert/> although for some diseases, namely asthma in young adults, females are more likely to be affected. These differences between the sexes tend to decrease in adulthood.<ref name=DeSwert/>\nEthnicity may play a role in some allergies; however, racial factors have been difficult to separate from environmental influences and changes due to migration.<ref name=DeSwert/> It has been suggested that different genetic loci are responsible for asthma, to be specific, in people of European, Hispanic, Asian, and African origins.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Genetics", "_id": "83--1--4---1", "title": "Allergy | Cause | Genetics"}
{"qas": [{"question": "Why are there so many more allergies in developing countries than in the industrialized world?", "answer": ""}, {"question": "What type of disease is caused by inappropriate immunological responses to harmless antigens driven?", "answer": "Allergic", "ae_score": null, "qg_score": null}, {"question": "What type of disease is caused by inappropriate immunological responses to harmless antigens driven?", "answer": "Allergic", "ae_score": null, "qg_score": null}], "content": "Allergic diseases are caused by inappropriate immunological responses to harmless antigens driven by a TH2-mediated immune response. Many bacteria and viruses elicit a TH1-mediated immune response, which down-regulates TH2 responses. The first proposed mechanism of action of the hygiene hypothesis was that insufficient stimulation of the TH1 arm of the immune system leads to an overactive TH2 arm, which in turn leads to allergic disease. In other words, individuals living in too sterile an environment are not exposed to enough pathogens to keep the immune system busy. Since our bodies evolved to deal with a certain level of such pathogens, when they are not exposed to this level, the immune system will attack harmless antigens and thus normally benign microbial objects\u2014like pollen\u2014will trigger an immune response.\nThe hygiene hypothesis was developed to explain the observation that hay fever and eczema, both allergic diseases, were less common in children from larger families, which were, it is presumed, exposed to more infectious agents through their siblings, than in children from families with only one child. The hygiene hypothesis has been extensively investigated by immunologists and epidemiologists and has become an important theoretical framework for the study of allergic disorders. It is used to explain the increase in allergic diseases that have been seen since industrialization, and the higher incidence of allergic diseases in more developed countries. The hygiene hypothesis has now expanded to include exposure to symbiotic bacteria and parasites as important modulators of immune system development, along with infectious agents.\nEpidemiological data support the hygiene hypothesis. Studies have shown that various immunological and autoimmune diseases are much less common in the developing world than the industrialized world and that immigrants to the industrialized world from the developing world increasingly develop immunological disorders in relation to the length of time since arrival in the industrialized world. Longitudinal studies in the third world demonstrate an increase in immunological disorders as a country grows more affluent and, it is presumed, cleaner. The use of antibiotics in the first year of life has been linked to asthma and other allergic diseases. The use of antibacterial cleaning products has also been associated with higher incidence of asthma, as has birth by Caesarean section rather than vaginal birth.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Hygiene hypothesis", "_id": "83--1--5---1", "title": "The Hygiene Hypothesis"}
{"qas": [{"question": "Why does stress cause allergies?", "answer": ""}, {"question": "How many different types of t helper are there?", "answer": "2", "ae_score": null, "qg_score": null}, {"question": "How many different types of t helper are there?", "answer": "2", "ae_score": null, "qg_score": null}], "content": "Chronic stress can aggravate allergic conditions. This has been attributed to a T helper 2 (TH2)-predominant response driven by suppression of interleukin 12 by both the autonomic nervous system and the hypothalamic\u2013pituitary\u2013adrenal axis. Stress management in highly susceptible individuals may improve symptoms.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Stress", "_id": "83--1--6---1", "title": "Chronic Stress and Allergy"}
{"qas": [{"question": "Why are allergies so much more common in rural areas than in urban areas?", "answer": ""}, {"question": "What microbe-sensing proteins are found on the surface of cells in the body?", "answer": "Toll-like receptors", "ae_score": -0.4026997634055108, "qg_score": null}, {"question": "What microbe-sensing proteins are found on the surface of cells in the body?", "answer": "Toll-like receptors", "ae_score": -0.4026997634055108, "qg_score": null}], "content": "International differences have been associated with the number of individuals within a population have allergy. Allergic diseases are more common in industrialized countries than in countries that are more traditional or agricultural, and there is a higher rate of allergic disease in urban populations versus rural populations, although these differences are becoming less defined.\nAlterations in exposure to microorganisms is another plausible explanation, at present, for the increase in atopic allergy.<ref name= Janeway/> Endotoxin exposure reduces release of inflammatory cytokines such as TNF-\u03b1, IFN\u03b3, interleukin-10, and interleukin-12 from white blood cells (leukocytes) that circulate in the blood. Certain microbe-sensing proteins, known as Toll-like receptors, found on the surface of cells in the body are also thought to be involved in these processes.\nGutworms and similar parasites are present in untreated drinking water in developing countries, and were present in the water of developed countries until the routine chlorination and purification of drinking water supplies. Recent research has shown that some common parasites, such as intestinal worms (e.g., hookworms), secrete chemicals into the gut wall (and, hence, the bloodstream) that suppress the immune system and prevent the body from attacking the parasite. This gives rise to a new slant on the hygiene hypothesis theory\u2014that co-evolution of humans and parasites has led to an immune system that functions correctly only in the presence of the parasites. Without them, the immune system becomes unbalanced and oversensitive. In particular, research suggests that allergies may coincide with the delayed establishment of gut flora in infants. However, the research to support this theory is conflicting, with some studies performed in China and Ethiopia showing an increase in allergy in people infected with intestinal worms.<ref name=cooper04/> Clinical trials have been initiated to test the effectiveness of certain worms in treating some allergies. It may be that the term 'parasite' could turn out to be inappropriate, and in fact a hitherto unsuspected symbiosis is at work.<ref name=falcone05/> For more information on this topic, see Helminthic therapy.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Cause", "sub_heading": "Other environmental factors", "_id": "83--1--7---1", "title": "The Hygiene Hypothesis"}
{"qas": [{"question": "Why do some allergies last longer than others?", "answer": ""}, {"question": "What process does activated mast cells and basophils undergo?", "answer": "degranulation", "ae_score": -0.29170885410738545, "qg_score": null}, {"question": "What process does activated mast cells and basophils undergo?", "answer": "degranulation", "ae_score": -0.29170885410738545, "qg_score": null}], "content": "In the early stages of allergy, a type I hypersensitivity reaction against an allergen encountered for the first time and presented by a professional antigen-presenting cell causes a response in a type of immune cell called a T2 lymphocyte, which belongs to a subset of T cells that produce a cytokine called interleukin-4 (IL-4). These T2 cells interact with other lymphocytes called B cells, whose role is production of antibodies. Coupled with signals provided by IL-4, this interaction stimulates the B cell to begin production of a large amount of a particular type of antibody known as IgE. Secreted IgE circulates in the blood and binds to an IgE-specific receptor (a kind of Fc receptor called Fc\u03b5RI) on the surface of other kinds of immune cells called mast cells and basophils, which are both involved in the acute inflammatory response. The IgE-coated cells, at this stage, are sensitized to the allergen.<ref name=Janeway/>\nIf later exposure to the same allergen occurs, the allergen can bind to the IgE molecules held on the surface of the mast cells or basophils. Cross-linking of the IgE and Fc receptors occurs when more than one IgE-receptor complex interacts with the same allergenic molecule, and activates the sensitized cell. Activated mast cells and basophils undergo a process called degranulation, during which they release histamine and other inflammatory chemical mediators (cytokines, interleukins, leukotrienes, and prostaglandins) from their granules into the surrounding tissue causing several systemic effects, such as vasodilation, mucous secretion, nerve stimulation, and smooth muscle contraction. This results in rhinorrhea, itchiness, dyspnea, and anaphylaxis. Depending on the individual, allergen, and mode of introduction, the symptoms can be system-wide (classical anaphylaxis), or localized to particular body systems; asthma is localized to the respiratory system and eczema is localized to the dermis.<ref name=Janeway/>\nAfter the chemical mediators of the acute response subside, late-phase responses can often occur due to the migration of other leukocytes such as neutrophils, lymphocytes, eosinophils, and macrophages to the initial site. The reaction is usually seen 2\u201324 hours after the original reaction. Cytokines from mast cells may also play a role in the persistence of long-term effects. Late-phase responses seen in asthma are slightly different from those seen in other allergic responses, although they are still caused by release of mediators from eosinophils, and are still dependent on activity of T2 cells.\nAlthough allergic contact dermatitis is termed an \"allergic\" reaction (which usually refers to type I hypersensitivity), its pathophysiology actually involves a reaction that more correctly corresponds to a type IV hypersensitivity reaction. In type IV hypersensitivity, there is activation of certain types of T cells (CD8+) that destroy target cells on contact, as well as activated macrophages that produce hydrolytic enzymes.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "83--2---1---1", "title": "Symptoms of allergic contact dermatitis: Symptoms of allergic contact derma"}
{"qas": [{"question": "Why is it that when a patient has anaphylactic reaction, they need to get a blood test?", "answer": ""}, {"question": "What tests may not be an option if a patient has widespread skin disease?", "answer": "Skin tests", "ae_score": -0.7260883034843003, "qg_score": null}, {"question": "What tests may not be an option if a patient has widespread skin disease?", "answer": "Skin tests", "ae_score": -0.7260883034843003, "qg_score": null}], "content": "Skin testing is also known as \"puncture testing\" and \"prick testing\" due to the series of tiny punctures or pricks made into the patient's skin. Small amounts of suspected allergens and/or their extracts (''e.g.'', pollen, grass, mite proteins, peanut extract) are introduced to sites on the skin marked with pen or dye (the ink/dye should be carefully selected, lest it cause an allergic response itself). A small plastic or metal device is used to puncture or prick the skin. Sometimes, the allergens are injected \"intradermally\" into the patient's skin, with a needle and syringe. Common areas for testing include the inside forearm and the back.\nIf the patient is allergic to the substance, then a visible inflammatory reaction will usually occur within 30 minutes. This response will range from slight reddening of the skin to a full-blown hive (called \"wheal and flare\") in more sensitive patients similar to a mosquito bite. Interpretation of the results of the skin prick test is normally done by allergists on a scale of severity, with +/\u2212 meaning borderline reactivity, and 4+ being a large reaction. Increasingly, allergists are measuring and recording the diameter of the wheal and flare reaction. Interpretation by well-trained allergists is often guided by relevant literature. Some patients may believe they have determined their own allergic sensitivity from observation, but a skin test has been shown to be much better than patient observation to detect allergy.\nIf a serious life-threatening anaphylactic reaction has brought a patient in for evaluation, some allergists will prefer an initial blood test prior to performing the skin prick test. Skin tests may not be an option if the patient has widespread skin disease, or has taken antihistamines in the last several days.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "83--3--0---1", "title": "Skin prick testing"}
{"qas": [{"question": "What is patch testing and how does it work?", "answer": ""}, {"question": "What test is used to determine the cause of allergic reactions?", "answer": "Patch testing", "ae_score": -0.3567380738414818, "qg_score": null}, {"question": "What test is used to determine the cause of allergic reactions?", "answer": "Patch testing", "ae_score": -0.3567380738414818, "qg_score": null}], "content": "Patch testing is a method used to determine if a specific substance causes allergic inflammation of the skin. It tests for delayed reactions. It is used to help ascertain the cause of skin contact allergy, or contact dermatitis. Adhesive patches, usually treated with a number of common allergic chemicals or skin sensitizers, are applied to the back. The skin is then examined for possible local reactions at least twice, usually at 48 hours after application of the patch, and again two or three days later.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Diagnosis", "sub_heading": "Patch testing", "_id": "83--3--1---1", "title": "Allergy | Diagnosis | Patch testing"}
{"qas": [{"question": "Why do some people have higher IgE levels than others?", "answer": ""}, {"question": "What type of test is used to test for allergies?", "answer": "allergy blood test", "ae_score": -0.554687001721799, "qg_score": null}, {"question": "What type of test is used to test for allergies?", "answer": "allergy blood test", "ae_score": -0.554687001721799, "qg_score": null}], "content": "An allergy blood test is quick and simple, and can be ordered by a licensed health care provider (''e.g.'', an allergy specialist), GP, or PED. Unlike skin-prick testing, a blood test can be performed irrespective of age, skin condition, medication, symptom, disease activity, and pregnancy. Adults and children of any age can take an allergy blood test. For babies and very young children, a single needle stick for allergy blood testing is often more gentle than several skin tests.\nAn allergy blood test is available through most laboratories. A sample of the patient's blood is sent to a laboratory for analysis, and the results are sent back a few days later. Multiple allergens can be detected with a single blood sample. Allergy blood tests are very safe, since the person is not exposed to any allergens during the testing procedure.\nThe test measures the concentration of specific IgE antibodies in the blood. Quantitative IgE test results increase the possibility of ranking how different substances may affect symptoms. A rule of thumb is that the higher the IgE antibody value, the greater the likelihood of symptoms. Allergens found at low levels that today do not result in symptoms can nevertheless help predict future symptom development. The quantitative allergy blood result can help determine what a patient is allergic to, help predict and follow the disease development, estimate the risk of a severe reaction, and explain cross-reactivity.\nA low total IgE level is not adequate to rule out sensitization to commonly inhaled allergens. Statistical methods, such as ROC curves, predictive value calculations, and likelihood ratios have been used to examine the relationship of various testing methods to each other. These methods have shown that patients with a high total IgE have a high probability of allergic sensitization, but further investigation with allergy tests for specific IgE antibodies for a carefully chosen of allergens is often warranted.\nLaboratory methods to measure specific IgE antibodies for allergy testing include enzyme-linked immunosorbent assay (ELISA, or EIA), radioallergosorbent test (RAST)<ref name=webmd/> and fluorescent enzyme immunoassay (FEIA).", "page_name": "Allergy", "page_id": "Allergy", "heading": "Diagnosis", "sub_heading": "Blood testing", "_id": "83--3--2---1", "title": "Allergy Blood Test"}
{"qas": [{"question": "Why is it so important to have an allergy test before a diagnosis is made?", "answer": ""}, {"question": "What disease shares symptoms with allergic rhinitis?", "answer": "Vasomotor rhinitis", "ae_score": -0.21399814101351472, "qg_score": null}, {"question": "What disease shares symptoms with allergic rhinitis?", "answer": "Vasomotor rhinitis", "ae_score": -0.21399814101351472, "qg_score": null}], "content": "Before a diagnosis of allergic disease can be confirmed, other possible causes of the presenting symptoms should be considered. Vasomotor rhinitis, for example, is one of many maladies that shares symptoms with allergic rhinitis, underscoring the need for professional differential diagnosis. Once a diagnosis of asthma, rhinitis, anaphylaxis, or other allergic disease has been made, there are several methods for discovering the causative agent of that allergy.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Diagnosis", "sub_heading": "Differential diagnosis", "_id": "83--3--3---1", "title": "Symptoms of Asthma, Rhinitis, Anaphylaxi"}
{"qas": [{"question": "Why do pregnant women have such a hard time with allergies?", "answer": ""}, {"question": "The consumption of various foods during pregnancy has been linked to what?", "answer": "eczema", "ae_score": -0.5498861164661738, "qg_score": null}, {"question": "The consumption of various foods during pregnancy has been linked to what?", "answer": "eczema", "ae_score": -0.5498861164661738, "qg_score": null}], "content": "The consumption of various foods during pregnancy has been linked to eczema; these include celery, citrus fruit, raw pepper, margarine, and vegetable oil.  A high intake of antioxidants, zinc, and selenium during pregnancy may help prevent allergies.  This is linked to a reduced risk for childhood-onset asthma, wheezing, and eczema.  Further research needs to be conducted.  Probiotic supplements taken during pregnancy or infancy may help to prevent atopic dermatitis. After birth, an early introduction of solid food and high diversity before week 17 could increase a child's risk for allergies. Studies suggest that introduction of solid food and avoidance of highly allergenic food such as peanuts during the first year does not help in allergy prevention.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Prevention", "sub_heading": "Prevention", "_id": "83--4---1---1", "title": "Pregnancy Preventing Allergies"}
{"qas": [{"question": "Is there any scientific evidence that saline nasal irrigation and butterbur are effective?", "answer": ""}, {"question": "What was the opposite of homeopathic remedies?", "answer": "placebo", "ae_score": -0.2231813427531975, "qg_score": null}, {"question": "What was the opposite of homeopathic remedies?", "answer": "placebo", "ae_score": -0.2231813427531975, "qg_score": null}], "content": "Management of allergies typically involves avoiding what triggers the allergy and medications to improve the symptoms.<ref name=NIH2015Imm/> Allergen immunotherapy may be useful for some types of allergies.<ref name=NIH2015Imm/>\nSeveral medications may be used to block the action of allergic mediators, or to prevent activation of cells and degranulation processes. These include antihistamines, glucocorticoids, epinephrine (adrenaline), mast cell stabilizers, and antileukotriene agents are common treatments of allergic diseases. Anti-cholinergics, decongestants, and other compounds thought to impair eosinophil chemotaxis, are also commonly used. Though rare, the severity of anaphylaxis often requires epinephrine injection, and where medical care is unavailable, a device known as an epinephrine autoinjector may be used.<ref name=tang03/>\nAllergen immunotherapy is useful for environmental allergies, allergies to insect bites, and asthma.<ref name=NIH2015Imm/><ref name=Abra2010/> Its benefit for food allergies is unclear and thus not recommended.<ref name=NIH2015Imm/> Immunotherapy involves exposing people to larger and larger amounts of allergen in an affect to change the immune system's response.<ref name=NIH2015Imm/>\nMeta-analyses have found that injections of allergens under the skin is effective in the treatment in allergic rhinitis in children and in asthma. The benefits may last for years after treatment is stopped.<ref name=Canonica09/> It is generally safe and effective for allergic rhinitis and conjunctivitis, allergic forms of asthma, and stinging insects.\nThe evidence also supports the use of sublingual immunotherapy for rhinitis and asthma but it is less strong. For seasonal allergies the benefit is small. In this form the allergen is given under the tongue and people often prefer it to injections.<ref name=Canonica09/> Immunotherapy is not recommended as a stand-alone treatment for asthma.<ref name=Canonica09/>\nAn experimental treatment, enzyme potentiated desensitization (EPD), has been tried for decades but is not generally accepted as effective. EPD uses dilutions of allergen and an enzyme, beta-glucuronidase, to which T-regulatory lymphocytes are supposed to respond by favoring desensitization, or down-regulation, rather than sensitization. EPD has also been tried for the treatment of autoimmune diseases but evidence does not show effectiveness.\nA review found no effectiveness of homeopathic treatments and no difference compared with placebo. The authors concluded that, based on rigorous clinical trials of all types of homeopathy for childhood and adolescence ailments, there is no convincing evidence that supports the use of homeopathic treatments.\nAccording to the NCCIH, the evidence is relatively strong that saline nasal irrigation and butterbur are effective, when compared to other alternative medicine treatments, for which the scientific evidence is weak, negative, or nonexistent, such as honey, acupuncture, omega 3's, probiotics,  astragalus, capsaicin, grape seed extract, Pycnogenol, quercetin, spirulina, stinging nettle, tinospora or guduchi.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Management", "sub_heading": "Management", "_id": "83--5---1---1", "title": "Allergy | Management"}
{"qas": [{"question": "Why are there so many more allergies in developing countries?", "answer": ""}, {"question": "When did increases in allergic asthma and other atopic disorders begin?", "answer": "1960s and 1970s", "ae_score": -0.6945524357948619, "qg_score": null}, {"question": "When did increases in allergic asthma and other atopic disorders begin?", "answer": "1960s and 1970s", "ae_score": -0.6945524357948619, "qg_score": null}], "content": "The allergic diseases\u2014hay fever and asthma\u2014have increased in the Western world over the past 2\u20133 decades. Increases in allergic asthma and other atopic disorders in industrialized nations, it is estimated, began in the 1960s and 1970s, with further increases occurring during the 1980s and 1990s, although some suggest that a steady rise in sensitization has been occurring since the 1920s. The number of new cases per year of atopy in developing countries has, in general, remained much lower.\nAlthough genetic factors govern susceptibility to atopic disease, increases in atopy have occurred within too short a time frame to be explained by a genetic change in the population, thus pointing to environmental or lifestyle changes. Several hypotheses have been identified to explain this increased rate; increased exposure to perennial allergens due to housing changes and increasing time spent indoors, and changes in cleanliness or hygiene that have resulted in the decreased activation of a common immune control mechanism, coupled with dietary changes, obesity and decline in physical exercise.<ref name=Platts/> The hygiene hypothesis maintains that high living standards and hygienic conditions exposes children to fewer infections. It is thought that reduced bacterial and viral infections early in life direct the maturing immune system away from T1 type responses, leading to unrestrained T2 responses that allow for an increase in allergy.<ref name=Yazdanbakhsh02/>\nChanges in rates and types of infection alone however, have been unable to explain the observed increase in allergic disease, and recent evidence has focused attention on the importance of the gastrointestinal microbial environment. Evidence has shown that exposure to food and fecal-oral pathogens, such as hepatitis A, ''Toxoplasma gondii'', and ''Helicobacter pylori'' (which also tend to be more prevalent in developing countries), can reduce the overall risk of atopy by more than 60%, and an increased rate of parasitic infections has been associated with a decreased prevalence of asthma. It is speculated that these infections exert their effect by critically altering T1/T2 regulation. Important elements of newer hygiene hypotheses also include exposure to endotoxins, exposure to pets and growing up on a farm.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "83--6---1---1", "title": "Allergy | Epidemiology"}
{"qas": [{"question": "What is the difference between the new blood test and the old test?", "answer": ""}, {"question": "Who came up with the term allergy?", "answer": "Clemens von Pirquet", "ae_score": -0.18854407153468997, "qg_score": null}, {"question": "Who came up with the term allergy?", "answer": "Clemens von Pirquet", "ae_score": -0.18854407153468997, "qg_score": null}], "content": "The concept of \"allergy\" was originally introduced in 1906 by the Viennese pediatrician Clemens von Pirquet, after he noted that some of his patients were hypersensitive to normally innocuous entities such as dust, pollen, or certain foods. Pirquet called this phenomenon \"allergy\" from the Ancient Greek words \u1f04\u03bb\u03bb\u03bf\u03c2 ''allos'' meaning \"other\" and \u1f14\u03c1\u03b3\u03bf\u03bd ''ergon'' meaning \"work\".\nAll forms of hypersensitivity used to be classified as allergies, and all were thought to be caused by an improper activation of the immune system. Later, it became clear that several different disease mechanisms were implicated, with the common link to a disordered activation of the immune system. In 1963, a new classification scheme was designed by Philip Gell and Robin Coombs that described four types of hypersensitivity reactions, known as Type I to Type IV hypersensitivity. With this new classification, the word \"allergy\" was restricted to type I hypersensitivities (also called immediate hypersensitivity), which are characterized as rapidly developing reactions.\nA major breakthrough in understanding the mechanisms of allergy was the discovery of the antibody class labeled immunoglobulin E (IgE). IgE was simultaneously discovered in 1966\u201367 by two independent groups: Ishizaka's team at the Children's Asthma Research Institute and Hospital in Denver, Colorado, and by Gunnar Johansson and Hans Bennich in Uppsala, Sweden. Their joint paper was published in April 1969.\nRadiometric assays include the radioallergosorbent test (RAST test) method, which uses IgE-binding (anti-IgE) antibodies labeled with radioactive isotopes for quantifying the levels of IgE antibody in the blood. Other newer methods use colorimetric or fluorescence-labeled technology in the place of radioactive isotopes.\nThe RAST methodology was invented and marketed in 1974 by Pharmacia Diagnostics AB, Uppsala, Sweden, and the acronym RAST is actually a brand name. In 1989, Pharmacia Diagnostics AB replaced it with a superior test named the ImmunoCAP Specific IgE blood test, which uses the newer fluorescence-labeled technology.\nAmerican College of Allergy Asthma and Immunology (ACAAI) and the American Academy of Allergy Asthma and Immunology (AAAAI) issued the Joint Task Force Report \"Pearls and pitfalls of allergy diagnostic testing\" in 2008, and is firm in its statement that the term RAST is now obsolete:\nThe new version, the ImmunoCAP Specific IgE blood test, is the only specific IgE assay to receive FDA approval to quantitatively report to its detection limit of 0.1kU/l.", "page_name": "Allergy", "page_id": "Allergy", "heading": "History", "sub_heading": "History", "_id": "83--7---1---1", "title": "ImmunoCAP Specific IgE Blood Test: A New Approach to Allergy Diagnostic"}
{"qas": [{"question": "How do you become an allergy expert?", "answer": ""}, {"question": "In what country can you become an allergist?", "answer": "the United States", "ae_score": null, "qg_score": null}, {"question": "In what country can you become an allergist?", "answer": "the United States", "ae_score": null, "qg_score": null}], "content": "An allergist is a physician specially trained to manage and treat allergies, asthma and the other allergic diseases.In the United States physicians holding certification by the American Board of Allergy and Immunology (ABAI) have successfully completed an accredited educational program and evaluation process, including a proctored examination to demonstrate knowledge, skills, and experience in patient care in allergy and immunology. Becoming an allergist/immunologist requires completion of at least nine years of training. After completing medical school and graduating with a medical degree, a physician will undergo three years of training in internal medicine (to become an internist) or pediatrics (to become a pediatrician). Once physicians have finished training in one of these specialties, they must pass the exam of either the American Board of Pediatrics (ABP), the American Osteopathic Board of Pediatrics (AOBP), the American Board of Internal Medicine (ABIM), or the American Osteopathic Board of Internal Medicine (AOBIM). Internists or pediatricians wishing to focus on the sub-specialty of allergy-immunology then complete at least an additional two years of study, called a fellowship, in an allergy/immunology training program. Allergist/immunologists listed as ABAI-certified have successfully passed the certifying examination of the ABAI following their fellowship.\nIn the United Kingdom, allergy is a subspecialty of general medicine or pediatrics. After obtaining postgraduate exams (MRCP or MRCPCH), a doctor works for several years as a specialist registrar before qualifying for the General Medical Council specialist register. Allergy services may also be delivered by immunologists. A 2003 Royal College of Physicians report presented a case for improvement of what were felt to be inadequate allergy services in the UK. In 2006, the House of Lords convened a subcommittee. It concluded likewise in 2007 that allergy services were insufficient to deal with what the Lords referred to as an \"allergy epidemic\" and its social cost; it made several recommendations.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Medical specialty", "sub_heading": "Medical specialty", "_id": "83--8---1---1", "title": "Allergy and Immunology in the United States"}
{"qas": [{"question": "Why haven't we found a cure for wasp sting yet?", "answer": ""}, {"question": "What is the study of biological particles passively dispersed through the air called?", "answer": "Aerobiology", "ae_score": -0.2682797150931084, "qg_score": null}, {"question": "What is the study of biological particles passively dispersed through the air called?", "answer": "Aerobiology", "ae_score": -0.2682797150931084, "qg_score": null}], "content": "Low-allergen foods are being developed, as are improvements in skin prick test predictions; evaluation of the atopy patch test; in wasp sting outcomes predictions and a rapidly disintegrating epinephrine tablet, and anti-IL-5 for eosinophilic diseases.\nAerobiology is the study of biological particles passively dispersed through the air. One aim is the prevention of allergies due to pollen.", "page_name": "Allergy", "page_id": "Allergy", "heading": "Research", "sub_heading": "Research", "_id": "83--9---1---1", "title": "Allergy | Research"}
{"qas": [{"question": "How did the population of the United States increase from 17% to 72% in the 18th century?", "answer": ""}, {"question": "At the turn of the 20th century, what percentage of the world population lived in?", "answer": "15%", "ae_score": -0.33563102019969876, "qg_score": null}, {"question": "At the turn of the 20th century, what percentage of the world population lived in?", "answer": "15%", "ae_score": -0.33563102019969876, "qg_score": null}], "content": "From the development of the earliest cities in Mesopotamia and Egypt until the 18th century, an equilibrium existed between the vast majority of the population who engaged in subsistence agriculture in a rural context, and small centres of populations in the towns where economic activity consisted primarily of trade at markets and manufactures on a small scale. Due to the primitive and relatively stagnant state of agriculture throughout this period the ratio of rural to urban population remained at a fixed equilibrium, though a significant increase in the persentage of the global urban population can still be traced in the 1st millennium BCE.\nWith the onset of the agricultural and industrial revolution in the late 18th century this relationship was finally broken and an unprecedented growth in urban population took place over the course of the 19th century, both through continued migration from the countryside and due to the tremendous demographic expansion that occurred at that time. In England the proportion of the population living in cities jumped from 17% in 1801 to 72% in 1891 (for other countries the figure was: 37% in France, 41% in Prussia and 28% in the United States).\nAs labourers were freed up from working the land due to higher agricultural productivity they converged on the new industrial cities like Manchester and Birmingham which were experiencing a boom in commerce, trade and industry. Growing trade around the world also allowed cereals to be imported from North America and refrigerated meat from Australasia and South America. Spatially, cities also expanded due to the development of public transport systems, which facilitated commutes of longer distances to the city centre for the working class.\nUrbanization rapidly spread across the Western world and, since the 1950s, it has begun to take hold in the developing world as well. At the turn of the 20th century, just 15% of the world population lived in cities. According to the UN the year 2007 witnessed the turning point when more than 50% of the world population were living in cities, for the first time in human history.\nYale University in June 2016 published urbanization data from the time period 3700 BC to 2000 AD, the data was used to make a video showing the development of cities on the world during the time period.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "History", "sub_heading": "History", "_id": "84--0---1---1", "title": "Urbanization in the 20th Century"}
{"qas": [{"question": "Why are there so many more people in urban areas than rural areas?", "answer": ""}, {"question": "What is a contributing factor to urbanization?", "answer": "Rural flight", "ae_score": -0.3132267434337874, "qg_score": null}, {"question": "What is a contributing factor to urbanization?", "answer": "Rural flight", "ae_score": -0.3132267434337874, "qg_score": null}], "content": "Urbanization occurs as individual, commercial flight, social and government action reduce the time and expense of commuting and transportation and improve opportunities for jobs, education, housing, and transportation. Living in a city can provide opportunities of proximity, diversity, and marketplace competition. As against this, there may be alienation issues, stress, increased cost of living, and negative social aspects that result from mass marginalization. Suburbanization, which is happening in the cities of the largest developing countries, may be regarded as an attempt to balance these negative aspects of urban life while still allowing access to the large extent of shared resources.\nIn cities, money, services, wealth and opportunities are centralized. Many rural inhabitants come to the city to seek their fortune and alter their social position. Businesses, which provide jobs and exchange capital, are more concentrated in urban areas. Whether the source is trade or tourism, it is also through the ports or banking systems, commonly located in cities, that foreign money flows into a country.\nMany people move into cities for the economic opportunities, but this does not fully explain the very high recent urbanization rates in places like China and India. Rural flight is a contributing factor to urbanization. In rural areas, often on small family farms or collective farms in villages, it has historically been difficult to access manufactured goods, though the relative overall quality of life is very subjective, and may certainly surpass that of the city. Farm living has always been susceptible to unpredictable environmental conditions, and in times of drought, flood or pestilence, survival may become extremely problematic.\nIn a New York Times article concerning the acute migration away from farming in Thailand, life as a farmer was described as \"hot and exhausting\". \"Everyone says the farmer works the hardest but gets the least amount of money\". In an effort to counter this impression, the Agriculture Department of Thailand is seeking to promote the impression that farming is \"honorable and secure\".\nHowever, in Thailand, urbanization has also resulted in massive increases in problems such as obesity. City life, especially in modern urban slums of the developing world, is certainly hardly immune to pestilence or climatic disturbances such as floods, yet continues to strongly attract migrants. Examples of this were the 2011 Thailand floods and 2007 Jakarta flood. Urban areas are also far more prone to violence, drugs, and other urban social problems. In the United States, industrialization of agriculture has negatively affected the economy of small and middle-sized farms and strongly reduced the size of the rural labour market.\nParticularly in the developing world, conflict over land rights due to the effects of globalization has led to less politically powerful groups, such as farmers, losing or forfeiting their land, resulting in obligatory migration into cities. In China, where land acquisition measures are forceful, there has been far more extensive and rapid urbanization (54%) than in India (36%), where peasants form militant groups (e.g. Naxalites) to oppose such efforts. Obligatory and unplanned migration often results in rapid growth of slums. This is also similar to areas of violent conflict, where people are driven off their land due to violence. Bogota, Colombia is one example of this.\nCities offer a larger variety of services, including specialist services not found in rural areas. These services requires workers, resulting in more numerous and varied job opportunities. Elderly people may be forced to move to cities where there are doctors and hospitals that can cater for their health needs. Varied and high quality educational opportunities are another factor in urban migration, as well as the opportunity to join, develop, and seek out social communities.\nUrbanization also creates opportunities for women that are not available in rural areas. This creates a gender-related transformation where women are engaged in paid employment and have access to education. This may cause fertility to decline. However, women are sometimes still at a disadvantage due to their unequal position in the labour market, their inability to secure assets independently from male relatives and exposure to violence.\nPeople in cities are more productive than in rural areas. An important question is whether this is due to agglomeration effects or whether cities simply attract those who are more productive. Economists have recently shown that there exists a large productivity gain due to locating in dense agglomerations. It is thus possible that agents locate in cities in order to benefit from these agglomeration effects.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Causes", "sub_heading": "Causes", "_id": "84--1---1---1", "title": "Urbanization and Suburbanization in the developing world"}
{"qas": [{"question": "Why does Japan have such a large population compared to other Asian countries?", "answer": ""}, {"question": "What city is losing population to greater busan-ulsan and greater osaka?", "answer": "Tokyo", "ae_score": -0.6657397718198335, "qg_score": null}, {"question": "What city is losing population to greater busan-ulsan and greater osaka?", "answer": "Tokyo", "ae_score": -0.6657397718198335, "qg_score": null}], "content": "The dominant conurbation(s) of a country can benefit to a greater extent from the same things cities offer, making them magnets for not just the non-urban population, but also urban and suburban population from other cities. Dominant conurbations are quite often primate cities, but do not have to be. For instance Greater Manila is rather a conurbation than a city: its 20 million overall population (over 20% national population) make it very much a primate city, but Quezon City (2.7 million), the largest municipality in Greater Manila, and Manila (1.6 million), the capital, are not. A conurbation's dominance can be measured by output, wealth, and especially population, each expressed as a percentage of an entire country. Greater Seoul is one conurbation with massive dominance over South Korea, it is home to 50% of the entire national population.\nThough Greater Busan-Ulsan (15%, 8 million) and Greater Osaka (14%, 18 million) exhibit strong dominance in their respective countries, yet they are losing population to their even more dominant rivals, Seoul and Tokyo respectively.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Dominant conurbation", "sub_heading": "Dominant conurbation", "_id": "84--2---1---1", "title": "Dominant Conurbations of a Nation"}
{"qas": [{"question": "Why are there so many poor people in urban areas?", "answer": ""}, {"question": "What type of capital is imperative to overcoming economic barriers?", "answer": "human capital", "ae_score": -0.9706592608187995, "qg_score": null}, {"question": "What type of capital is imperative to overcoming economic barriers?", "answer": "human capital", "ae_score": -0.9706592608187995, "qg_score": null}], "content": "As cities develop, effects can include a dramatic increase and change in costs, often pricing the local working class out of the market, including such functionaries as employees of the local municipalities. For example, Eric Hobsbawm's book ''The age of revolution: 1789\u20131848'' (published 1962 and 2005) chapter 11, stated \"Urban development in our period [1789\u20131848] was a gigantic process of class segregation, which pushed the new labouring poor into great morasses of misery outside the centres of government and business and the newly specialized residential areas of the bourgeoisie. The almost universal European division into a 'good' west end and a 'poor' east end of large cities developed in this period.\" This is likely due the prevailing south-west wind which carries coal smoke and other airborne pollutants downwind, making the western edges of towns preferable to the eastern ones.  Similar problems now affect the developing world, rising inequality resulting from rapid urbanization trends. The drive for rapid urban growth and often efficiency can lead to less equitable urban development. Think tanks such as the Overseas Development Institute have proposed policies that encourage labor-intensive growth as a means of absorbing the influx of low-skilled and unskilled labor. One problem these migrant workers are involved with is the growth of slums. In many cases, the rural-urban low skilled or unskilled migrant workers, attracted by economic opportunities in urban areas, cannot find a job and afford housing in cities and have to dwell in slums. Urban problems, along with infrastructure developments, are also fueling suburbanization trends in developing nations, though the trend for core cities in said nations tends to continue to become ever denser. Urbanization is often viewed as a negative trend, but there are positives in the reduction of expenses in commuting and transportation while improving opportunities for jobs, education, housing, and transportation. Living in cities permits individuals and families to take advantage of the opportunities of proximity and diversity. While cities have a greater variety of markets and goods than rural areas, infrastructure congestion, monopolization, high overhead costs, and the inconvenience of cross-town trips frequently combine to make marketplace competition harsher in cities than in rural areas.\nIn many developing countries where economies are growing, the growth is often erratic and based on a small number of industries. For young people in these countries barriers exist such as, lack of access to financial services and business advisory services, difficulty in obtaining credit to start a business, and lack of entrepreneurial skills, in order for them to access opportunities in these industries. Investment in human capital so that young people have access to quality education and infrastructure to enable access to educational facilities is imperative to overcoming economic barriers.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Economic effect", "sub_heading": "Economic effect", "_id": "84--3---1---1", "title": "Urbanization in the developing world"}
{"qas": [{"question": "Why are urban heat islands more common than rural heat islands?", "answer": ""}, {"question": "How much will the amount of food produced by 2050 increase?", "answer": "70%", "ae_score": -0.30226620340256916, "qg_score": null}, {"question": "How much will the amount of food produced by 2050 increase?", "answer": "70%", "ae_score": -0.30226620340256916, "qg_score": null}], "content": "The existence of Urban heat islands has become a growing concern over the years. An urban heat island is formed when industrial and urban areas produce and retain heat. Much of the solar energy that reaches rural areas is consumed by evaporation of water from vegetation and soil. In cities, where there is less vegetation and exposed soil, most of the sun's energy is instead absorbed by buildings and asphalt; leading to higher surface temperatures. Vehicles, factories and industrial and domestic heating and cooling units release even more heat. As a result, cities are often 1 to 3 \u00b0C (1.8 to 5.4 \u00b0F) warmer than surrounding landscapes. Impacts also include reducing soil moisture and a reduction in reabsorption of carbon dioxide emissions.\nThe occurrence of eutrophication in bodies of water is another effect large urban populations have on the environment. When rain occurs in these large cities, the rain filters down the pollutants such as CO and other green house gases in the air onto the ground below. Then, those chemicals are washed directly into rivers, streams and oceans, causing a decline in water quality and damaging marine ecosystems.\nIn his book ''Whole Earth Discipline'', Stewart Brand argues that the effects of urbanization are primarily positive for the environment. First, the birth rate of new urban dwellers falls immediately to replacement rate, and keeps falling, reducing environmental stresses caused by population growth. Secondly, emigration from rural areas reduces destructive subsistence farming techniques, such as improperly implemented slash and burn agriculture.\nIn July 2013 a report issued by the United Nations Department of Economic and Social Affairs warned that with 2.4 billion more people by 2050, the amount of food produced will have to increase by 70%, straining food resources, especially in countries already facing food insecurity due to changing environmental conditions. The mix of changing environmental conditions and the growing population of urban regions, according to UN experts, will strain basic sanitation systems and health care, and potentially cause a humanitarian and environmental disaster.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Environmental effects", "sub_heading": "Environmental effects", "_id": "84--4---1---1", "title": "Urban heat islands and the impact of urbanization on the environment"}
{"qas": [{"question": "Why are urban health levels so much worse than rural health?", "answer": ""}, {"question": "What is a new study on urbanization and globalization?", "answer": "Agriculturist", "ae_score": -0.6328649025107731, "qg_score": null}, {"question": "What is a new study on urbanization and globalization?", "answer": "Agriculturist", "ae_score": -0.6328649025107731, "qg_score": null}], "content": "In the developing world, urbanization does not seem to translate into a significant increase in life expectancy. Rapid urbanization has brought increased mortality from non-communicable diseases associated with lifestyle, including cancer and heart disease. Differences in mortality from contagious diseases vary depending on the particular disease.\nUrban health levels are better in comparison those in rural areas on average. However, residents in poor areas such as slums and informal settlements suffer \"disproportionately from disease, injury, premature death, and the combination of ill-health and poverty entrenches disadvantage over time.\" Many urban poor have difficulty accessing health services due to an increasing requirement to pay for them; so people resort to less qualified and unregulated providers.\nWhile urbanization is associated with improvements in public hygiene, sanitation and access to health care, it also entails changes in occupational, dietary and exercise patterns. It can have mixed effects on health patterns, alleviating some problems and accentuating others. For instance, in children urbanization is associated with a lower risk of under-nutrition but a higher risk of overweight. Overall, body mass index and cholesterol levels increase sharply with national income and the degree of urbanization. Agriculturist has new studied on urbanization and globalization. Fast food is the food of chose which is causing health decline. Easier access to non-traditional foods may lead to less healthy dietary patterns. In India prevalence of diabetes in urban areas appears to be more than twice as high as in rural areas. In general, major risk factors for chronic diseases are more prevalent in urban environments.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Health and social effects", "sub_heading": "Health and social effects", "_id": "84--5---1---1", "title": "Urbanization and Globalization"}
{"qas": [{"question": "Why is it called the \"peripheralization of the core\"?", "answer": ""}, {"question": "The inability of countries to provide adequate housing for rural migrants is related to what?", "answer": "overurbanization", "ae_score": -0.4021131940099685, "qg_score": null}, {"question": "The inability of countries to provide adequate housing for rural migrants is related to what?", "answer": "overurbanization", "ae_score": -0.4021131940099685, "qg_score": null}], "content": "Different forms of urbanization can be classified depending on the style of architecture and planning methods as well as historic growth of areas.\nIn cities of the developed world urbanization traditionally exhibited a concentration of human activities and settlements around the downtown area, the so-called ''in-migration''. In-migration refers to migration from former colonies and similar places. The fact that many immigrants settle in impoverished city centres led to the notion of the \"peripheralization of the core\", which simply describes that people who used to be at the periphery of the former empires now live right in the centre.\nRecent developments, such as inner-city redevelopment schemes, mean that new arrivals in cities no longer necessarily settle in the centre. In some developed regions, the reverse effect, originally called counter urbanization has occurred, with cities losing population to rural areas, and is particularly common for richer families. This has been possible because of improved communications, and has been caused by factors such as the fear of crime and poor urban environments. It has contributed to the phenomenon of shrinking cities experienced by some parts of the industrialized world.\nWhen the residential area shifts outward, this is called suburbanization. A number of researchers and writers suggest that suburbanization has gone so far to form new points of concentration outside the downtown both in developed and developing countries such as India. This networked, poly-centric form of concentration is considered by some emerging pattern of urbanization. It is called variously exurbia, edge city (Garreau, 1991), network city (Batten, 1995), or postmodern city (Dear, 2000). Los Angeles is the best-known example of this type of urbanization. Interestingly, in the United States, this process has reversed as of 2011, with \"re-urbanization\" occurring as ''suburban flight'' due to chronically high transport costs.\nRural migrants are attracted by the possibilities that cities can offer, but often settle in shanty towns and experience extreme poverty. The inability of countries to provide adequate housing for these rural migrants is related to overurbanization, a phenomenon in which the rate of urbanization grows more rapidly that the rate of economic development, leading to high unemployment and high demand for resources. In the 1980s, this was attempted to be tackled with the '''urban bias theory''' which was promoted by Michael Lipton.\nMost of the urban poor in developing countries able to find work can spend their lives in insecure, poorly paid jobs. According to research by the Overseas Development Institute pro-poor urbanization will require labour-intensive growth, supported by labour protection, flexible land use regulation and investments in basic services.'\nUrbanization can be planned urbanization or organic. Planned urbanization, i.e.: planned community or the garden city movement, is based on an advance plan, which can be prepared for military, aesthetic, economic or urban design reasons. Examples can be seen in many ancient cities; although with exploration came the collision of nations, which meant that many invaded cities took on the desired planned characteristics of their occupiers. Many ancient organic cities experienced redevelopment for military and economic purposes, new roads carved through the cities, and new parcels of land were cordoned off serving various planned purposes giving cities distinctive geometric designs. UN agencies prefer to see urban infrastructure installed before urbanization occurs. Landscape planners are responsible for landscape infrastructure (public parks, sustainable urban drainage systems, greenways etc.) which can be planned before urbanization takes place, or afterward to revitalize an area and create greater livability within a region. Concepts of control of the urban expansion are considered in the American Institute of Planners.\nAs the population continues to grow and urbanize at unprecedented rates, new urbanism and smart growth techniques will create a successful transition into developing environmentally, economically, and socially sustainable cities. Smart Growth and New Urbanism\u2019s principles include walkability, mixed-use development, comfortable high-density design, land conservation, social equity, and economic diversity. Mixed-use communities work to fight gentrification with affordable housing to promote social equity, decrease automobile dependency to lower use of fossil fuels, and promote a localized economy. Walkable communities have a 38% higher average GDP per capita than less walkable urban metros (Leinberger, Lynch). By combining economic, environmental, and social sustainability, cities will become equitable, resilient, and more appealing than urban sprawl that overuses land, promotes automobile use, and segregates the population economically.", "page_name": "Urbanization", "page_id": "Urbanization", "heading": "Changing forms", "sub_heading": "Changing forms", "_id": "84--6---1---1", "title": "Smart Growth and New Urbanism"}
{"qas": [{"question": "What is the difference between a leaf and a leaf?", "answer": ""}, {"question": "What is the common name for the flowers produced in clusters on the trunk and older branches?", "answer": "cauliflory", "ae_score": -0.3803160623780978, "qg_score": null}, {"question": "What is the common name for the flowers produced in clusters on the trunk and older branches?", "answer": "cauliflory", "ae_score": -0.3803160623780978, "qg_score": null}], "content": "Leaves are alternate, entire, unlobed, 10 - long and 5 - broad.\nThe flowers are produced in clusters directly on the trunk and older branches; this is known as cauliflory. The flowers are small, 1 - diameter, with pink calyx. The floral formula is \u2736 K5 C5 A(5\u00b0+5\u00b2) (5). While many of the world's flowers are pollinated by bees (Hymenoptera) or butterflies/moths (Lepidoptera), cacao flowers are pollinated by tiny flies, ''Forcipomyia'' midges in the subfamily Forcipomyiinae. The fruit, called a cacao pod, is ovoid, 15 - long and 8 - wide, ripening yellow to orange, and weighs about 500 g when ripe. The pod contains 20 to 60 seeds, usually called \"beans\", embedded in a white pulp. The seeds are the main ingredient of chocolate, while the pulp is used in some countries to prepare refreshing juice, smoothies, jelly, and nata. The fermented pulp, until recently discarded in Ecuador, the Dominican Republic, and Peru, is now being distilled there into a popular alcoholic beverage sold in the United States.  Each seed contains a significant amount of fat (40\u201350%) as cocoa butter. Their most noted active constituent is theobromine, a compound similar to caffeine.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Description", "sub_heading": "Description", "_id": "85--0---1---1", "title": "Cocoa Seeds \u2014 Theobromine, a compound similar to caffeine in cacao"}
{"qas": [{"question": "Where did the generic name for food come from?", "answer": ""}, {"question": "How many species of theobroma are there?", "answer": "22", "ae_score": -0.34016101453259845, "qg_score": null}, {"question": "How many species of theobroma are there?", "answer": "22", "ae_score": -0.34016101453259845, "qg_score": null}], "content": "Cacao (''Theobroma cacao'') belongs to the genus ''Theobroma'' classified under the subfamily Sterculioidea of the mallow family Malvaceae. Cacao is one of 22 species of ''Theobroma''.\nThe generic name is derived from the Greek for \"food of the gods\"; from \u03b8\u03b5\u03cc\u03c2 (''theos''), meaning \"god,\" and \u03b2\u03c1\u1ff6\u03bc\u03b1 (''broma''), meaning \"food\".\nThe specific name ''cacao'' is derived from the native name of the plant in indigenous Mesoamerican languages. The cacao was known as ''kakaw'' in Tzeltal, K\u2019iche\u2019 and Classic Maya; ''kagaw'' in Sayula Popoluca; and ''cacahuatl'' in Nahuatl.\nCupua\u00e7u, ''Theobroma grandiflorum'', is a closely related species found in Brazil, Colombia, Peru and Bolivia. Like cacao, it is also the source for a kind of chocolate known as ''cupulate'' or cupua\u00e7u chocolate. Cupua\u00e7u is considered as having high potential by the food and cosmetics industries.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Taxonomy and nomenclature", "sub_heading": "Taxonomy and nomenclature", "_id": "85--1---1---1", "title": "Theobroma cacao (''Theobroma cacao'') "}
{"qas": [{"question": "Why are cacao trees so hard to distinguish from other trees?", "answer": ""}, {"question": "Theobroma cacao is the latin name for which tree?", "answer": "Cacao", "ae_score": -0.6046703902133606, "qg_score": null}, {"question": "Theobroma cacao is the latin name for which tree?", "answer": "Cacao", "ae_score": -0.6046703902133606, "qg_score": null}], "content": "''T. cacao'' is widely distributed from southeastern Mexico to the Amazon basin. There were originally two hypotheses about its domestication; one said that there were two foci for domestication, one in the Lacandon Jungle area of Mexico and another in lowland South America. More recent studies of patterns of DNA diversity, however, suggest that this is not the case. Motomayor ''et al.'' sampled 1241 trees and classified them into 10 distinct genetic clusters. This study also identified areas, for example around Iquitos in modern Peru, where representatives of several genetic clusters originated. This result suggests that this is where ''T. cacao'' was originally domesticated, probably for the pulp that surrounds the beans, which is eaten as a snack and fermented into a mildly alcoholic beverage. Using the DNA sequences obtained by Motomayor ''et al.'' and comparing them with data derived from climate models and the known conditions suitable for cacao, Thomas ''et al.'' have further refined the view of domestication, linking the area of greatest cacao genetic diversity to a bean-shaped area that encompasses the border between Brazil and Peru and the southern part of the Colombian-Brazilian border. Climate models indicate that at the peak of the last ice age 21,000 years ago, when habitat suitable for cacao was at its most reduced, this area was still suitable, and so provided a refugium for the species. Thomas ''et al.'' speculate that from there people took cacao to Mexico, where selection for the beans took place.\nCacao trees grow well as understory plants in humid forest ecosystems. This is equally true of abandoned cultivated trees, making it difficult to distinguish truly wild trees from those whose parents may originally have been cultivated.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Distribution and domestication", "sub_heading": "Distribution and domestication", "_id": "85--2---1---1", "title": "''T. cacao'' Genetic Diversity"}
{"qas": [{"question": "How did the cacao beans become the currency of the Aztec empire?", "answer": ""}, {"question": "What is the main source of currency in the aztec empire?", "answer": "Cacao beans", "ae_score": -0.5756284400216617, "qg_score": null}, {"question": "What is the main source of currency in the aztec empire?", "answer": "Cacao beans", "ae_score": -0.5756284400216617, "qg_score": null}], "content": "Cultivation, use, and cultural elaboration of cacao were early and extensive in Mesoamerica.  Ceramic vessels with residues from the preparation of cacao beverages have been found at archaeological sites dating back to the Early Formative (1900-900 BC) period. For example, one such vessel found at an Olmec archaeological site on the Gulf Coast of Veracruz, Mexico dates cacao's preparation by pre-Olmec peoples as early as 1750 BC. On the Pacific coast of Chiapas, Mexico, a Mokaya archaeological site provides evidence of cacao beverages dating even earlier, to 1900 BC.The initial domestication was probably related to the making of a fermented, thus alcoholic beverage.\nSeveral mixtures of cacao are described in ancient texts, for ceremonial or medicinal, as well as culinary, purposes. Some mixtures included maize, chili, vanilla (''Vanilla planifolia''), and honey. Archaeological evidence for use of cacao, while relatively sparse, has come from the recovery of whole cacao beans at Uaxactun, Guatemala and from the preservation of wood fragments of the cacao tree at Belize sites including Cuello and Pulltrouser Swamp. In addition, analysis of residues from ceramic vessels has found traces of theobromine and caffeine in early formative vessels from Puerto Escondido, Honduras (1100-900 BC) and in middle formative vessels from Colha, Belize (600-400 BC) using similar techniques to those used to extract chocolate residues from four classic period (''circa'' 400 AD) vessels from a tomb at the Maya archaeological site of Rio Azul. As cacao is the only known commodity from Mesoamerica containing both of these alkaloid compounds, it seems likely these vessels were used as containers for cacao drinks. In addition, cacao is named in a hieroglyphic text on one of the Rio Azul vessels. Cacao was also believed to be ground by the Aztecs and mixed with tobacco for smoking purposes.\nCacao beans constituted both a ritual beverage and a major currency system in pre-Columbian Mesoamerican civilizations.  At one point, the Aztec empire received a yearly tribute of 980 loads (''xiquipil'' in Nahuatl) of cacao, in addition to other goods.  Each load represented exactly 8,000 beans.  The buying power of quality beans was such that 80-100 beans could buy a new cloth mantle. The use of cacao beans as currency is also known to have spawned counterfeiters during the Aztec empire.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "History of cultivation", "sub_heading": "History of cultivation", "_id": "85--3---1---1", "title": "The Origins of Cacao Beans in Mesoamerica"}
{"qas": [{"question": "Why did the Mayan people eat cacao?", "answer": ""}, {"question": "In which month of the year does the mayan festival of the cacao god e?", "answer": "April", "ae_score": -0.6868429333360834, "qg_score": null}, {"question": "In which month of the year does the mayan festival of the cacao god e?", "answer": "April", "ae_score": -0.6868429333360834, "qg_score": null}], "content": "The Maya believed the ''kakaw'' (cacao) was discovered by the gods in a mountain that also contained other delectable foods to be used by them. According to Maya mythology, the Plumed Serpent gave cacao to the Maya after humans were created from maize by divine grandmother goddess Xmucane. The Maya celebrated an annual festival in April to honor their cacao god, Ek Chuah, an event that included the sacrifice of a dog with cacao-colored markings, additional animal sacrifices, offerings of cacao, feathers and incense, and an exchange of gifts. In a similar creation story, the Mexica (Aztec) god Quetzalcoatl discovered cacao (''cacahuatl'': \"bitter water\"), in a mountain filled with other plant foods. Cacao was offered regularly to a pantheon of Mexica deities and the Madrid Codex depicts priests lancing their ear lobes (autosacrifice) and covering the cacao with blood as a suitable sacrifice to the gods. The cacao beverage as ritual was used only by men, as it was believed to be toxic for women and children. ", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Mythology", "sub_heading": "Mythology", "_id": "85--4---1---1", "title": "Maya Mythology: Cacao and the Maya"}
{"qas": [{"question": "Why are there so many different types of coffee?", "answer": ""}, {"question": "Tejate is a pre-hispanic beverage made from?", "answer": "cacao", "ae_score": -0.3353777530789019, "qg_score": null}, {"question": "Tejate is a pre-hispanic beverage made from?", "answer": "cacao", "ae_score": -0.3353777530789019, "qg_score": null}], "content": "The first Europeans to encounter cacao were Christopher Columbus and his crew in 1502, when they captured a canoe at Guanaja that contained a quantity of mysterious-looking \"almonds\". The first real European knowledge about chocolate came in the form of a beverage which was first introduced to the Spanish at their meeting with Moctezuma in the Aztec capital of Tenochtitlan in 1519. Cort\u00e9s and others noted the vast quantities of this beverage the Aztec emperor consumed, and how it was carefully whipped by his attendants beforehand. Examples of cacao beans, along with other agricultural products, were brought back to Spain at that time, but it seems the beverage made from cacao was introduced to the Spanish court in 1544 by Kekchi Maya nobles brought from the New World to Spain by Dominican friars to meet Prince Philip. Within a century, the culinary and medical uses of chocolate had spread to France, England and elsewhere in Western Europe. Demand for this beverage led the French to establish cacao plantations in the Caribbean, while Spain subsequently developed their cacao plantations in their Venezuelan and  Philippine colonies (Bloom 1998, Coe 1996). The Nahuatl-derived Spanish word ''cacao'' entered scientific nomenclature in 1753 after the Swedish naturalist Linnaeus published his taxonomic binomial system and coined the genus and species ''Theobroma cacao''.\nTraditional pre-Hispanic beverages made with cacao are still consumed in Mesoamerica.  These include the Oaxacan beverage known as ''tejate''.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Modern history", "sub_heading": "Modern history", "_id": "85--5---1---1", "title": "The Origins of Cacao"}
{"qas": [{"question": "How do companies like Hershey's, Nestl\u00e9 and Mars get their cocoa beans?", "answer": ""}, {"question": "How much cacao is grown in the world?", "answer": "3.5 million tons", "ae_score": -0.5177028073398057, "qg_score": null}, {"question": "How much cacao is grown in the world?", "answer": "3.5 million tons", "ae_score": -0.5177028073398057, "qg_score": null}], "content": "Cacao is cultivated on roughly 17000000 acre worldwide. According to the Food and Agriculture Organization of the United Nations (FAO), the top 20 cacao-producing countries in 2005 were as follows:\nBased on 1999\u20132001 international prices\nCacao production has increased from 1.5 million tons in 1983-1984 to 3.5 million tons in 2003-2004, almost entirely due to the expansion of the production area rather than to yield increases. Cacao is grown both by large agroindustrial plantations and small producers, the bulk of production coming from millions of farmers who have a few trees each.\nA tree begins to bear when it is four or five years old. A mature tree may have 6,000 flowers in a year, yet only about 20 pods. About 1,200 seeds (40 pods) are required to produce 1 kg (2.2 lb) of cocoa paste.\nHistorically, chocolate makers have recognized three main cultivar groups of cacao beans used to make cocoa and chocolate. The most prized, rare, and expensive is the Criollo group, the cocoa bean used by the Maya. Only 10% of chocolate is made from Criollo, which is arguably less bitter and more aromatic than any other bean. The cacao bean in 80% of chocolate is made using beans of the Forastero group, the main and most ubiquitous variety being the Amenolado variety, while the arriba variety (such as the Nacional variety that was recently discovered) are less commonly found in Forestero produce. Forastero trees are significantly hardier and disease resistant than Criollo trees, resulting in cheaper cacao beans. Trinitario, a hybrid of Criollo and Forastero, is used in about 10% of chocolate. The criollo cacao beans from Chuao in Aragua, Venezuela are widely regarded as some of the finest in the world. In November 2000, the cacao beans coming from said region were awarded an appellation of origin under the title \"Cacao de Chuao\" (from Spanish-''cacao of Chuao'') effectively making this one of the most expensive and sought after types of cacao.\nA new, genetically based classification of 10 groups may well help breeders to create new varieties that are both pest- and disease-resistant and contain valued flavours.\nMajor cocoa bean processors include Hershey's, Nestl\u00e9 and Mars, all of which purchase cocoa beans via various sources.\nIn June 2009, Mars Botanicals, a division of Mars, launched Cirku, a cocoa extract product that provides cocoa \ufb02avanols made with a patented process that contains a high level of phytonutrients.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Cultivation", "sub_heading": "Cultivation", "_id": "85--6---1---1", "title": "Cocoa Beans: The World\u2019s Most Valuable Food"}
{"qas": [{"question": "Why is cacao so endangered?", "answer": ""}, {"question": "Theobroma is the latin name for which fruit?", "answer": "cacao", "ae_score": null, "qg_score": null}, {"question": "Theobroma is the latin name for which fruit?", "answer": "cacao", "ae_score": null, "qg_score": null}], "content": "The pests and diseases to which cacao is subject, along with climate change, mean that new varieties will be needed to respond to these challenges. Breeders rely on the genetic diversity conserved in field genebanks to create new varieties, because cacao has recalcitrant seeds that cannot be stored in a conventional genebank. In an effort to improve the diversity available to breeders, and ensure the future of the field genebanks, experts have drawn up A Global Strategy for the Conservation and Use of Cacao Genetic Resources, as the Foundation for a Sustainable Cocoa Economy. The strategy has been adopted by the cacao producers and their clients, and seeks to improve the characterization of cacao diversity, the sustainability and diversity of the cacao collections, the usefulness of the collections, and to ease access to better information about the conserved material. Some natural areas of cacao diversity are protected by various forms of conservation, for example national parks. However, a recent study of genetic diversity and predicted climates suggests that many of those protected areas will no longer be suitable for cacao by 2050. It also identifies an area around Iquitos in Peru that will remain suitable for cacao and that is home to considerable genetic diversity, and recommends that this area be considered for protection.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Conservation", "sub_heading": "Conservation", "_id": "85--8---1---1", "title": "A Global Strategy for the Conservation and Use of Cacao Genetic Resources"}
{"qas": [{"question": "What is the cacao genome and why is it important?", "answer": ""}, {"question": "How many genes are in the cacao genome?", "answer": "28,798", "ae_score": -0.42729966172947526, "qg_score": null}, {"question": "How many genes are in the cacao genome?", "answer": "28,798", "ae_score": -0.42729966172947526, "qg_score": null}], "content": "The genome of ''T. cacao'' is diploid, its size is 430 Mbp, and it comprises 10 chromosome pairs (2n=2x=20). In September 2010, a team of scientists announced a draft sequence of the cacao genome (Matina1-6 genotype).  In a second, unrelated project, the International Cocoa Genome Sequencing Consortium-ICGS, co-ordinated by CIRAD, first published in December 2010 (online, paper publication in January 2011), the sequence of the cacao genome, of the Criollo cacao (of a landrace from Belize, B97-61/B2). In their publication, they reported a detailed analysis of the genomic and genetic data.\nThe sequence of the cacao genome identified 28,798 protein-coding genes, compared to the roughly 23,000 protein-coding genes of the human genome.  About 20% of the cacao genome consists of transposable elements, a low proportion compared to other plant species. Many genes were identified as coding for flavonoids, aromatic terpenes, theobromine and many other metabolites involved in cocoa flavor and quality traits, among which a relatively high proportion code for polyphenols, which constitute up to 8% of cacao pods dry weight. The cacao genome appears close to the hypothetical hexaploid ancestor of all dicotyledonous plants, and it is proposed as an evolutionary mechanism by which the 21 chromosomes of the dicots' hypothetical hexaploid ancestor underwent major fusions leading to cacao's 10 chromosome pairs.The genome sequence will help accelerate research on cacao molecular biology and breeding for elite varieties through marker-assisted selection, in particular for genetic resistance to fungal, oomycete and viral diseases responsible for huge yield losses each year.", "page_name": "Theobroma cacao", "page_id": "Theobroma%20cacao", "heading": "Cacao genome", "sub_heading": "Cacao genome", "_id": "85--9---1---1", "title": "Genome Sequencing of the Criollo cacao"}
{"qas": [{"question": "What is the difference between the transverse and the posterior side of the colon?", "answer": ""}, {"question": "What is the medical term for examining the large intestine?", "answer": "Sigmoidoscopy", "ae_score": -0.039668045698538, "qg_score": null}, {"question": "What is the medical term for examining the large intestine?", "answer": "Sigmoidoscopy", "ae_score": -0.039668045698538, "qg_score": null}], "content": "In mammals, the colon consists of five sections: the cecum plus the ascending colon, the transverse colon, the descending colon,  the sigmoid colon and the rectum .<ref name='NCILargeIntestineDef'/>\nSections of the colon are:\nThe parts of the colon are either intraperitoneal or behind it in the retroperitoneum. Retroperitoneal organs in general do not have a complete covering of peritoneum, so they are fixed in location. Intraperitoneal organs are completely surrounded by peritoneum and are therefore mobile. Of the colon, the ascending colon, descending colon and rectum are retroperitoneal, while the cecum, appendix, transverse colon and sigmoid colon are intraperitoneal. This is important as it affects which organs can be easily accessed during surgery, such as a laparotomy.\nThe cecum is the first section of the colon and involved in the digestion, while the appendix which develops embryologically from it, is a structure of the colon, not involved in digestion and considered to be part of the gut-associated lymphoid tissue. The function of the appendix is uncertain, but some sources believe that the appendix has a role in housing a sample of the colon's microflora, and is able to help to repopulate the colon with bacteria if the microflora has been damaged during the course of an immune reaction.\nThe ascending colon is the first of four sections of the large intestine. It is connected to the small intestine by a section of bowel called the cecum. The ascending colon runs upwards through the abdominal cavity toward the transverse colon for approximately eight inches (20 cm).\nOne of the main functions of the colon is to remove the water and other key nutrients from waste material and recycle it. As the waste material exits the small intestine through the ileocecal valve, it will move into the cecum and then to the ascending colon where this process of extraction starts. The unwanted waste material is moved upwards toward the transverse colon by the action of peristalsis.The ascending colon is sometimes attached to the appendix via Gerlach's valve. The appendix, traditionally seen as a vestigial organ, has been shown to have a high concentration of lymphatic cells. In ruminants, the ascending colon is known as the '''spiral colon'''.\nThe transverse colon is the part of the colon from the hepatic flexure to the splenic flexure (the turn of the colon by the spleen). The transverse colon hangs off the stomach, attached to it by a large fold of peritoneum  called the greater omentum. On the posterior side, the transverse colon is connected to the posterior abdominal wall by a mesentery known as the transverse mesocolon.\nThe transverse colon is encased in peritoneum, and is therefore mobile (unlike the parts of the colon immediately before and after it). Cancers form more frequently further along the large intestine as the contents become more solid (water is removed) in order to form feces.\nThe proximal two-thirds of the transverse colon is perfused by the middle colic artery, a branch of the superior mesenteric artery (SMA), while the latter third is supplied by branches of the inferior mesenteric artery (IMA). The \"watershed\" area between these two blood supplies, which represents the embryologic division between the midgut and hindgut, is an area sensitive to ischemia.\nThe descending colon is the part of the colon from the splenic flexure to the beginning of the sigmoid colon. One function of the descending colon in the digestive system is to store feces that will be emptied into the rectum. It is retroperitoneal in two-thirds of humans. In the other third, it has a (usually short) mesentery. The arterial supply comes via the left colic artery. The descending colon is also called the ''distal gut'', as it is further along the gastrointestinal tract than the proximal gut. Gut flora are very dense in this region.\nThe '''sigmoid colon''' is the part of the large intestine after the descending colon and before the rectum. The name ''sigmoid'' means S-shaped (see sigmoid; cf. sigmoid sinus). The walls of the sigmoid colon are muscular, and contract to increase the pressure inside the colon, causing the stool to move into the rectum.\nThe sigmoid colon is supplied with blood from several branches (usually between 2 and 6) of the sigmoid arteries, a branch of the IMA. The IMA terminates as the superior rectal artery.\nSigmoidoscopy is a common diagnostic technique used to examine the sigmoid colon.\nThe rectum is the last section of the large intestine. It holds the formed feces awaiting elimination via defecation.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Structure", "sub_heading": "Structure", "_id": "86--0--0---1", "title": "Sigmoidoscopy \u2014 Part 1"}
{"qas": [{"question": "How does a taenia coli cause a shelf in the colon?", "answer": ""}, {"question": "What is the name of the large intestine?", "answer": "cecum", "ae_score": -0.34937326355953474, "qg_score": null}, {"question": "What is the name of the large intestine?", "answer": "cecum", "ae_score": -0.34937326355953474, "qg_score": null}], "content": "The cecum \u2013 the first part of the large intestine  \nThe taenia coli run the length of the large intestine.  Because the taenia coli are shorter than the large bowel itself, the colon becomes ''sacculated'', forming the haustra of the colon which are the shelf-like intraluminal projections.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Structure", "sub_heading": "Appearance", "_id": "86--0--1---1", "title": "The haustra of the colon \u2014 the intraluminal projections of the colon"}
{"qas": [{"question": "What is the arc of the colon?", "answer": ""}, {"question": "Where does ima supply the large intestine?", "answer": "inferior mesenteric artery", "ae_score": -0.9513531634334191, "qg_score": null}, {"question": "Where does ima supply the large intestine?", "answer": "inferior mesenteric artery", "ae_score": -0.9513531634334191, "qg_score": null}], "content": "Arterial supply to the colon comes from branches of the superior mesenteric artery (SMA) and inferior mesenteric artery (IMA). Flow between these two systems communicates via a \"marginal artery\" that runs parallel to the colon for its entire length. Historically, it has been believed that the arc of Riolan, or the meandering mesenteric artery (of Moskowitz), is a variable vessel connecting the proximal SMA to the proximal IMA that can be extremely important if either vessel is occluded. However, recent studies conducted with improved imaging technology have questioned the actual existence of this vessel, with some experts calling for the abolition of the terms from future medical literature.\nVenous drainage usually mirrors colonic arterial supply, with the inferior mesenteric vein draining into the splenic vein, and the superior mesenteric vein joining the splenic vein to form the hepatic portal vein that then enters the liver.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Structure", "sub_heading": "Blood supply", "_id": "86--0--2---1", "title": "Venous Drainage in the Hepatic Portal Vein"}
{"qas": [{"question": "What happens to the lymph in the rectum when the colon is turned upside down?", "answer": ""}, {"question": "Where does the lymph go after the anal canal?", "answer": "superficial inguinal nodes", "ae_score": -1.6710961836368072, "qg_score": null}, {"question": "Where does the lymph go after the anal canal?", "answer": "superficial inguinal nodes", "ae_score": -1.6710961836368072, "qg_score": null}], "content": "Lymphatic drainage from the ascending colon and proximal two-thirds of the transverse colon is to the colic lymph nodes and the superior mesenteric lymph nodes, which drain into the cisterna chyli. The lymph from the distal one-third of the transverse colon, the descending colon, the sigmoid colon, and the upper rectum drain into the inferior mesenteric and colic lymph nodes. The lower rectum to the anal canal above the pectinate line drain to the internal iliac nodes. The anal canal below the pectinate line drains into the superficial inguinal nodes. The pectinate line only roughly marks this transition.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Structure", "sub_heading": "Lymphatic drainage", "_id": "86--0--3---1", "title": "Lymphatic drainage from the ascending colon and proximal two-thirds of"}
{"qas": [{"question": "What are the health consequences of a colonoscopy?", "answer": ""}, {"question": "How long is the colon of the large intestine?", "answer": "up to five metres", "ae_score": null, "qg_score": null}, {"question": "How long is the colon of the large intestine?", "answer": "up to five metres", "ae_score": null, "qg_score": null}], "content": "One variation on the normal anatomy of the colon occurs when extra loops form, resulting in a colon that is up to five metres longer than normal. This condition, referred to as '''redundant colon''', typically has no direct major health consequences, though rarely volvulus occurs, resulting in obstruction and requiring immediate medical attention. A significant indirect health consequence is that use of a standard adult colonoscope is difficult and in some cases impossible when a redundant colon is present, though specialized variants on the instrument (including the pediatric variant) are useful in overcoming this problem.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Structure", "sub_heading": "Variation", "_id": "86--0--4---1", "title": "Redundant colon \u2014 a rare condition"}
{"qas": [{"question": "Why are there so many different types of colonic crypts?", "answer": ""}, {"question": "What percentage of colonic crypts are deficient in women?", "answer": "18%", "ae_score": -0.3829458711155044, "qg_score": null}, {"question": "What percentage of colonic crypts are deficient in women?", "answer": "18%", "ae_score": -0.3829458711155044, "qg_score": null}], "content": "The wall of the large intestine is lined with simple columnar epithelium with invaginations.  The invaginations are called the intestinal glands or colonic crypts.\nThe colon crypts are shaped like microscopic thick walled test tubes with a central hole down the length of the tube (the crypt lumen). Four tissue sections are shown here, two cut across the long axes of the crypts and two cut parallel to the long axes.  In these images the cells have been stained by immunohistochemistry to show a brown-orange color if the cells produce a mitochondrial protein called cytochrome c oxidase subunit I (CCOI).  The nuclei of the cells (located at the outer edges of the cells lining the walls of the crypts) are stained blue-gray with haematoxylin. As seen in panels C and D, crypts are about 75 to about 110 cells long.  Baker et al. found that the average crypt circumference is 23 cells.  Thus, by the images shown here, there are an average of about 1,725 to 2530 cells per colonic crypt.  Nooteboom et al. measuring the number of cells in a small number of crypts reported a range of 1500 to 4900 cells per colonic crypt.  Cells are produced at the crypt base and migrate upward along the crypt axis before being shed into the colonic lumen days later.  There are 5 to 6 stem cells at the bases of the crypts.\nAs estimated from the image in panel A, there are about 100 colonic crypts per square millimeter of the colonic epithelium.  Since the average length of the human colon is 160.5 cm and the average inner circumference of the colon is 6.2 cm. the inner surface epithelial area of the human colon has an average area of about 995 sq cm, which includes 9,950,000 (close to 10 million) crypts.\nIn the four tissue sections shown here, many of the intestinal glands have cells with a mitochondrial DNA mutation in the CCOI gene and appear mostly white, with their main color being the blue-gray staining of the nuclei.  As seen in panel B, a portion of the stem cells of three crypts appear to have a mutation in CCOI, so that 40% to 50% of the cells arising from those stem cells form a white segment in the cross cut area.\nOverall, the percent of crypts deficient for CCOI is less than 1% before age 40, but then increases linearly with age. Colonic crypts deficient for CCOI in women reaches, on average, 18% in women and 23% in men by 80\u201384 years of age.\nCrypts of the colon can reproduce by fission, as seen in panel C, where a crypt is fissioning to form two crypts, and in panel B where at least one crypt appears to be fissioning.  Most crypts deficient in CCOI are in clusters of crypts (clones of crypts) with two or more CCOI-deficient crypts adjacent to each other (see panel D).", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Histology", "sub_heading": "Histology", "_id": "86--1---1---1", "title": "Crypts of the Large intestine"}
{"qas": [{"question": "How does water get to the colon?", "answer": ""}, {"question": "What is the primary function of the large intestine?", "answer": "Water absorption", "ae_score": -1.124604569691568, "qg_score": null}, {"question": "What is the primary function of the large intestine?", "answer": "Water absorption", "ae_score": -1.124604569691568, "qg_score": null}], "content": "Water absorption at the colon typically proceeds against a transmucosal osmotic pressure gradient. The '''standing gradient osmosis''' is the reabsorption of water against the osmotic gradient in the intestines. This hypertonic fluid creates an osmotic pressure that drives water into the lateral intercellular spaces by osmosis via tight junctions and adjacent cells, which then in turn moves across the basement membrane and into the capillaries.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Function", "sub_heading": "Function", "_id": "86--2--0---1", "title": "Water Absorption at the Colon"}
{"qas": [{"question": "How do bacteria in the large intestine produce vitamin D?", "answer": ""}, {"question": "What are the most prevalent bacteria in the large intestine?", "answer": "bacteroides", "ae_score": -0.20700450859155695, "qg_score": null}, {"question": "What are the most prevalent bacteria in the large intestine?", "answer": "bacteroides", "ae_score": -0.20700450859155695, "qg_score": null}], "content": "The large intestine houses over 700 species of bacteria that perform a variety of functions, as well as fungi, protozoa, and archaea. Species diversity varies by geography and diet. The microbes in a human distal gut often number in the vicinity of 100 trillion, and can weigh around 200 grams (0.44 pounds). This mass of mostly symbiotic microbes has recently been called the latest human organ to be \"discovered\" or in other words, the \"forgotten organ\".\nThe large intestine absorbs some of the products formed by the bacteria inhabiting this region. Undigested polysaccharides (fiber) are metabolized to short-chain fatty acids by bacteria in the large intestine and absorbed by passive diffusion. The bicarbonate that the large intestine secretes helps to neutralize the increased acidity resulting from the formation of these fatty acids.\nThese bacteria also produce large amounts of vitamins, especially vitamin K and biotin (a B vitamin), for absorption into the blood. Although this source of vitamins, in general, provides only a small part of the daily requirement, it makes a significant contribution when dietary vitamin intake is low. An individual who depends on absorption of vitamins formed by bacteria in the large intestine may become vitamin-deficient if treated with antibiotics that inhibit the vitamin producing species of bacteria as well as the intended disease-causing bacteria.\nOther bacterial products include gas (flatus), which is a mixture of nitrogen and carbon dioxide, with small amounts of the gases hydrogen, methane, and hydrogen sulfide.  Bacterial fermentation of undigested polysaccharides produces these. Some of the fecal odor is due to indoles, metabolized from the amino acid tryptophan. The normal flora is also essential in the development of certain tissues, including the cecum and lymphatics.\nThey are also involved in the production of cross-reactive antibodies. These are antibodies produced by the immune system against the normal flora, that are also effective against related pathogens, thereby preventing infection or invasion.\nThe most prevalent bacteria are the bacteroides, which have been implicated in the initiation of colitis and colon cancer. Bifidobacteria are also abundant, and are often described as 'friendly bacteria'.\nA mucus layer protects the large intestine from attacks from colonic commensal bacteria.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Function", "sub_heading": "Gut flora", "_id": "86--2--1---1", "title": "The Forgotten Organ"}
{"qas": [{"question": "What is a colonoscopy and how does it work?", "answer": ""}, {"question": "Where is the large intestine located in the body?", "answer": "the colon", "ae_score": -0.07727544713490146, "qg_score": null}, {"question": "Where is the large intestine located in the body?", "answer": "the colon", "ae_score": -0.07727544713490146, "qg_score": null}], "content": "Following are the most common diseases or disorders of the colon:\nColonoscopy is the endoscopic examination of the large intestine and the distal part of the small bowel with a CCD camera or a fiber optic camera on a flexible tube passed through the anus. It can provide a visual diagnosis (e.g. ulceration, polyps) and grants the opportunity for biopsy or removal of suspected colorectal cancer lesions. Colonoscopy can remove polyps as small as one millimetre or less. Once polyps are removed, they can be studied with the aid of a microscope to determine if they are precancerous or not. It takes 15 years or less for a polyp to turn cancerous.\nColonoscopy is similar to sigmoidoscopy\u2014the difference being related to which parts of the colon each can examine. A colonoscopy allows an examination of the entire colon (1200\u20131500 mm in length). A sigmoidoscopy allows an examination of the distal portion (about 600 mm) of the colon, which may be sufficient because benefits to cancer survival of colonoscopy have been limited to the detection of lesions in the distal portion of the colon.\nA sigmoidoscopy is often used as a screening procedure for a full colonoscopy, often done in conjunction with a fecal occult blood test (FOBT).  About 5% of these screened patients are referred to colonoscopy.\nVirtual colonoscopy, which uses 2D and 3D imagery reconstructed from computed tomography (CT) scans or from nuclear magnetic resonance (MR) scans, is also possible, as a totally non-invasive medical test, although it is not standard and still under investigation regarding its diagnostic abilities. Furthermore, virtual colonoscopy does not allow for therapeutic maneuvers such as polyp/tumour removal or biopsy nor visualization of lesions smaller than 5 millimeters.  If a growth or polyp is detected using CT colonography, a standard colonoscopy would still need to be performed. Additionally, surgeons have lately been using the term pouchoscopy to refer to a colonoscopy of the ileo-anal pouch.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Clinical significance", "sub_heading": "Clinical significance", "_id": "86--3---1---1", "title": "Colonoscopy: The most common diseases or disorders of the colon"}
{"qas": [{"question": "What is the difference between the large intestine and the small intestine?", "answer": ""}, {"question": "What type of animal has a large intestine?", "answer": "tetrapods", "ae_score": -0.4463083147462603, "qg_score": null}, {"question": "What type of animal has a large intestine?", "answer": "tetrapods", "ae_score": -0.4463083147462603, "qg_score": null}], "content": "The large intestine is truly distinct only in tetrapods, in which it is almost always separated from the small intestine by an ileocaecal valve. In most vertebrates, however, it is a relatively short structure running directly to the anus, although noticeably wider than the small intestine. Although the caecum is present in most amniotes, only in mammals does the remainder of the large intestine develop into a true colon.\nIn some small mammals, the colon is straight, as it is in other tetrapods, but, in the majority of mammalian species, it is divided into ascending and descending portions; a distinct transverse colon is typically present only in primates. However, the taeniae coli and accompanying haustra are not found in either carnivorans or ruminants. The rectum of mammals (other than monotremes) is derived from the cloaca of other vertebrates, and is, therefore, not truly homologous with the \"rectum\" found in these species.\nIn fish, there is no true large intestine, but simply a short rectum connecting the end of the digestive part of the gut to the cloaca. In sharks, this includes a ''rectal gland'' that secretes salt to help the animal maintain osmotic balance with the seawater. The gland somewhat resembles a caecum in structure, but is not a homologous structure.", "page_name": "Large intestine", "page_id": "Large%20intestine", "heading": "Other animals", "sub_heading": "Other animals", "_id": "86--4---1---1", "title": "The Large intestine and the rectum in mammals"}
{"qas": [{"question": "How does soil erosion work?", "answer": ""}, {"question": "What is it called when water accumulates and rapidly flows in narrow channels during or immediately?", "answer": "Gully erosion", "ae_score": -0.29549024022535453, "qg_score": null}, {"question": "What is it called when water accumulates and rapidly flows in narrow channels during or immediately?", "answer": "Gully erosion", "ae_score": -0.29549024022535453, "qg_score": null}], "content": "Rainfall, and the surface runoff which may result from rainfall, produces four main types of soil erosion: ''splash erosion'', ''sheet erosion'', ''rill erosion'', and ''gully erosion''. Splash erosion is generally seen as the first and least severe stage in the soil erosion process, which is followed by sheet erosion, then rill erosion and finally gully erosion (the most severe of the four).\nIn ''splash erosion'', the impact of a falling raindrop creates a small crater in the soil, ejecting soil particles. The distance these soil particles travel can be as much as 0.6 m (two feet) vertically and 1.5 m (five feet) horizontally on level ground.\nIf the soil is saturated, or if the rainfall rate is greater than the rate at which water can infiltrate into the soil, surface runoff occurs. If the runoff has sufficient flow energy, it will transport loosened soil particles (sediment) down the slope. ''Sheet erosion'' is the transport of loosened soil particles by overland flow.\n''Rill erosion'' refers to the development of small, ephemeral concentrated flow paths which function as both sediment source and sediment delivery systems for erosion on hillslopes. Generally, where water erosion rates on disturbed upland areas are greatest, rills are active. Flow depths in rills are typically of the order of a few centimetres (about an inch) or less and along-channel slopes may be quite steep. This means that rills exhibit hydraulic physics very different from water flowing through the deeper, wider channels of streams and rivers.\n''Gully erosion'' occurs when runoff water accumulates and rapidly flows in narrow channels during or immediately after heavy rains or melting snow, removing soil to a considerable depth.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Physical processes", "sub_heading": "Physical processes", "_id": "87--0--0---1", "title": "''Splash erosion'', ''sheet erosion'', "}
{"qas": [{"question": "What is bank erosion and how is it measured?", "answer": ""}, {"question": "What is the term for changes on the bed of a river?", "answer": "scour", "ae_score": -0.6775498358391816, "qg_score": null}, {"question": "What is the term for changes on the bed of a river?", "answer": "scour", "ae_score": -0.6775498358391816, "qg_score": null}], "content": "''Valley'' or ''stream erosion'' occurs with continued water flow along a linear feature. The erosion is both downward, deepening the valley, and headward, extending the valley into the hillside, creating head cuts and steep banks. In the earliest stage of stream erosion, the erosive activity is dominantly vertical, the valleys have a typical '''V''' cross-section and the stream gradient is relatively steep. When some base level is reached, the erosive activity switches to lateral erosion, which widens the valley floor and creates a narrow floodplain. The stream gradient becomes nearly flat, and lateral deposition of sediments becomes important as the stream meanders across the valley floor. In all stages of stream erosion, by far the most erosion occurs during times of flood, when more and faster-moving water is available to carry a larger sediment load. In such processes, it is not the water alone that erodes: suspended abrasive particles, pebbles and boulders can also act erosively as they traverse a surface, in a process known as ''traction''.\n''Bank erosion'' is the wearing away of the banks of a stream or river. This is distinguished from changes on the bed of the watercourse, which is referred to as ''scour''. Erosion and changes in the form of river banks may be measured by inserting metal rods into the bank and marking the position of the bank surface along the rods at different times.\n''Thermal erosion'' is the result of melting and weakening permafrost due to moving water. It can occur both along rivers and at the coast. Rapid river channel migration observed in the Lena River of Siberia is due to thermal erosion, as these portions of the banks are composed of permafrost-cemented non-cohesive materials. Much of this erosion occurs as the weakened banks fail in large slumps. Thermal erosion also affects the Arctic coast, where wave action and near-shore temperatures combine to undercut permafrost bluffs along the shoreline and cause them to fail. Annual erosion rates along a 100 km segment of the Beaufort Sea shoreline averaged 5.6 m per year from 1955 to 2002.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Physical processes", "sub_heading": "Rivers and streams", "_id": "87--0--1---1", "title": "''Valley'' or ''Valley erosion''"}
{"qas": [{"question": "Why are there so many waterfalls in the U.S.?", "answer": ""}, {"question": "What type of basins are formed by kolks?", "answer": "Rock-cut basins", "ae_score": -0.5217718926385061, "qg_score": null}, {"question": "What type of basins are formed by kolks?", "answer": "Rock-cut basins", "ae_score": -0.5217718926385061, "qg_score": null}], "content": "At extremely high flows, kolks, or vortices are formed by large volumes of rapidly rushing water. Kolks cause extreme local erosion, plucking bedrock and creating pothole-type geographical features called Rock-cut basins. Examples can be seen in the flood regions result from glacial Lake Missoula, which created the channeled scablands in the Columbia Basin region of eastern Washington.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Physical processes", "sub_heading": "Floods", "_id": "87--0--2---1", "title": "Kolks, or Vortices, are formed by large volumes of rapidly rushing"}
{"qas": [{"question": "Why is wind erosion more severe in arid areas than in dry areas?", "answer": ""}, {"question": "What is the cause of soil erosion in arid areas?", "answer": "Wind erosion", "ae_score": -0.1252099316543012, "qg_score": null}, {"question": "What is the cause of soil erosion in arid areas?", "answer": "Wind erosion", "ae_score": -0.1252099316543012, "qg_score": null}], "content": "Wind erosion is a major geomorphological force, especially in arid and semi-arid regions. It is also a major source of land degradation, evaporation, desertification, harmful airborne dust, and crop damage\u2014especially after being increased far above natural rates by human activities such as deforestation, urbanization, and agriculture.\nWind erosion is of two primary varieties: ''deflation'', where the wind picks up and carries away loose particles; and ''abrasion'', where surfaces are worn down as they are struck by airborne particles carried by wind. Deflation is divided into three categories: (1) ''surface creep'', where larger, heavier particles slide or roll along the ground; (2) ''saltation'', where particles are lifted a short height into the air, and bounce and saltate across the surface of the soil; and (3) ''suspension'', where very small and light particles are lifted into the air by the wind, and are often carried for long distances. Saltation is responsible for the majority (50-70%) of wind erosion, followed by suspension (30-40%), and then surface creep (5-25%).\nWind erosion is much more severe in arid areas and during times of drought. For example, in the Great Plains, it is estimated that soil loss due to wind erosion can be as much as 6100 times greater in drought years than in wet years.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Physical processes", "sub_heading": "Wind erosion", "_id": "87--0--3---1", "title": "Wind Erosion: A Major Geomorphological Force"}
{"qas": [{"question": "What is mass movement?", "answer": ""}, {"question": "What is the name for the downward and outward movement of rock and sediments on a?", "answer": "Mass movement", "ae_score": -1.05623918417996, "qg_score": null}, {"question": "What is the name for the downward and outward movement of rock and sediments on a?", "answer": "Mass movement", "ae_score": -1.05623918417996, "qg_score": null}], "content": "''Mass movement'' is the downward and outward movement of rock and sediments on a sloped surface, mainly due to the force of gravity.\nMass movement is an important part of the erosional process, and is often the first stage in the breakdown and transport of weathered materials in mountainous areas. It moves material from higher elevations to lower elevations where other eroding agents such as streams and glaciers can then pick up the material and move it to even lower elevations. Mass-movement processes are always occurring continuously on all slopes; some mass-movement processes act very slowly; others occur very suddenly, often with disastrous results. Any perceptible down-slope movement of rock or sediment is often referred to in general terms as a landslide. However, landslides can be classified in a much more detailed way that reflects the mechanisms responsible for the movement and the velocity at which the movement occurs. One of the visible topographical manifestations of a very slow form of such activity is a scree slope.\n''Slumping'' happens on steep hillsides, occurring along distinct fracture zones, often within materials like clay that, once released, may move quite rapidly downhill. They will often show a spoon-shaped isostatic depression, in which the material has begun to slide downhill. In some cases, the slump is caused by water beneath the slope weakening it. In many cases it is simply the result of poor engineering along highways where it is a regular occurrence.\n''Surface creep'' is the slow movement of soil and rock debris by gravity which is usually not perceptible except through extended observation. However, the term can also describe the rolling of dislodged soil particles 0.5 to in diameter by wind along the soil surface.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Physical processes", "sub_heading": "Mass movement", "_id": "87--0--4---1", "title": "''Surface creep'' and ''Mass movement''"}
{"qas": [{"question": "Why is it that in some parts of the world, runoff and erosion are the main causes of soil erosion?", "answer": ""}, {"question": "What is the main cause of soil erosion?", "answer": "rainfall intensity", "ae_score": -0.40530261188736716, "qg_score": null}, {"question": "What is the main cause of soil erosion?", "answer": "rainfall intensity", "ae_score": -0.40530261188736716, "qg_score": null}], "content": "The amount and intensity of precipitation is the main climatic factor governing soil erosion by water. The relationship is particularly strong if heavy rainfall occurs at times when, or in locations where, the soil's surface is not well protected by vegetation. This might be during periods when agricultural activities leave the soil bare, or in semi-arid regions where vegetation is naturally sparse. Wind erosion requires strong winds, particularly during times of drought when vegetation is sparse and soil is dry (and so is more erodible). Other climatic factors such as average temperature and temperature range may also affect erosion, via their effects on vegetation and soil properties. In general, given similar vegetation and ecosystems, areas with more precipitation (especially high-intensity rainfall), more wind, or more storms are expected to have more erosion.\nIn some areas of the world (e.g. the mid-western USA), rainfall intensity is the primary determinant of erosivity, with higher intensity rainfall generally resulting in more soil erosion by water. The size and velocity of rain drops is also an important factor. Larger and higher-velocity rain drops have greater kinetic energy, and thus their impact will displace soil particles by larger distances than smaller, slower-moving rain drops.\nIn other regions of the world (e.g. western Europe), runoff and erosion result from relatively low intensities of stratiform rainfall falling onto previously saturated soil. In such situations, rainfall amount rather than intensity is the main factor determining the severity of soil erosion by water.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Factors affecting soil erosion", "sub_heading": "Factors affecting soil erosion", "_id": "87--1--0---1", "title": "Soil Erosion by Water \u2014 Part 1"}
{"qas": [{"question": "What determines the erosivity of rainfall?", "answer": ""}, {"question": "Soil with high levels of organic materials is more resistant to?", "answer": "erosion", "ae_score": -2.2462772151113874, "qg_score": null}, {"question": "Soil with high levels of organic materials is more resistant to?", "answer": "erosion", "ae_score": -2.2462772151113874, "qg_score": null}], "content": "The composition, moisture, and compaction of soil are all major factors in determining the erosivity of rainfall. Sediments containing more clay tend to be more resistant to erosion than those with sand or silt, because the clay helps bind soil particles together. Soil containing high levels of organic materials are often more resistant to erosion, because the organic materials coagulate soil colloids and create a stronger, more stable soil structure. The amount of water present in the soil before the precipitation also plays an important role, because it sets limits on the amount of water that can be absorbed by the soil (and hence prevented from flowing on the surface as erosive runoff). Wet, saturated soils will not be able to absorb as much rain water, leading to higher levels of surface runoff and thus higher erosivity for a given volume of rainfall. Soil compaction also affects the permeability of the soil to water, and hence the amount of water that flows away as runoff. More compacted soils will have a larger amount of surface runoff than less compacted soils.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Factors affecting soil erosion", "sub_heading": "Soil structure and composition", "_id": "87--1--1---1", "title": "The Erosivity of Rainfall in the U.S."}
{"qas": [{"question": "How does removing vegetation help with soil erosion?", "answer": ""}, {"question": "What is the main source of soil erosion?", "answer": "Vegetation", "ae_score": -0.5409238874968475, "qg_score": null}, {"question": "What is the main source of soil erosion?", "answer": "Vegetation", "ae_score": -0.5409238874968475, "qg_score": null}], "content": "Vegetation acts as an interface between the atmosphere and the soil. It increases the permeability of the soil to rainwater, thus decreasing runoff. It shelters the soil from winds, which results in decreased wind erosion, as well as advantageous changes in microclimate. The roots of the plants bind the soil together, and interweave with other roots, forming a more solid mass that is less susceptible to both water and wind erosion. The removal of vegetation increases the rate of surface erosion.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Factors affecting soil erosion", "sub_heading": "Vegetative cover", "_id": "87--1--2---1", "title": "Vegetation \u2014 A Natural Interface Between the Atmosphere and the Soil"}
{"qas": [{"question": "Why is it that when it rains, the land is more prone to erosion?", "answer": ""}, {"question": "What determines the rate of soil erosion during heavy rains?", "answer": "topography", "ae_score": -1.1343744855924016, "qg_score": null, "filter_answer": "topography of the land"}, {"question": "What determines the rate of soil erosion during heavy rains?", "answer": "topography", "ae_score": -1.1343744855924016, "qg_score": null, "filter_answer": "topography of the land"}], "content": "The topography of the land determines the velocity at which surface runoff will flow, which in turn determines the erosivity of the runoff. Longer, steeper slopes (especially those without adequate vegetative cover) are more susceptible to very high rates of erosion during heavy rains than shorter, less steep slopes. Steeper terrain is also more prone to mudslides, landslides, and other forms of gravitational erosion processes.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Factors affecting soil erosion", "sub_heading": "Topography", "_id": "87--1--3---1", "title": "The Erosivity of Surface Runoff"}
{"qas": [{"question": "Why is the global soil erosion rate so high?", "answer": ""}, {"question": "What is the cause of soil erosion in the world?", "answer": "Unsustainable agricultural practices", "ae_score": -0.7778715883304115, "qg_score": null}, {"question": "What is the cause of soil erosion in the world?", "answer": "Unsustainable agricultural practices", "ae_score": -0.7778715883304115, "qg_score": null}], "content": "Unsustainable agricultural practices are the single greatest contributor to the global increase in erosion rates.The tillage of agricultural lands, which breaks up soil into finer particles, is one of the primary factors. The problem has been exacerbated in modern times, due to mechanized agricultural equipment that allows for deep plowing, which severely increases the amount of soil that is available for transport by water erosion. Others include mono-cropping, farming on steep slopes, pesticide and chemical fertilizer usage (which kill organisms that bind soil together), row-cropping, and the use of surface irrigation. A complex overall situation with respect to defining nutrient losses from soils, could arise as a result of the size selective nature of soil erosion events. Loss of total phosphorus, for instance, in the finer eroded fraction is greater relative to the whole soil. Extrapolating this evidence to predict subsequent behaviour within receiving aquatic systems, the reason is that this more easily transported material may support a lower solution P concentration compared to coarser sized fractions. Tillage also increases wind erosion rates, by dehydrating the soil and breaking it up into smaller particles that can be picked up by the wind. Exacerbating this is the fact that most of the trees are generally removed from agricultural fields, allowing winds to have long, open runs to travel over at higher speeds. Heavy grazing reduces vegetative cover and causes severe soil compaction, both of which increase erosion rates. ", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Human activities that increase soil erosion", "sub_heading": "Human activities that increase soil erosion", "_id": "87--2--0---1", "title": "The Impact of Tillage on Earth\u2019s Erosion Rates"}
{"qas": [{"question": "How do forest canopies work?", "answer": ""}, {"question": "What is the cause of soil erosion in india?", "answer": "Deforestation", "ae_score": -0.37001008505053984, "qg_score": null}, {"question": "What is the cause of soil erosion in india?", "answer": "Deforestation", "ae_score": -0.37001008505053984, "qg_score": null}], "content": "In an undisturbed forest, the mineral soil is protected by a layer of ''leaf litter'' and an ''humus'' that cover the forest floor. These two layers form a protective mat over the soil that absorbs the impact of rain drops. They are porous and highly permeable to rainfall, and allow rainwater to slow percolate into the soil below, instead of flowing over the surface as runoff. The roots of the trees and plants hold together soil particles, preventing them from being washed away. The vegetative cover acts to reduce the velocity of the raindrops that strike the foliage and stems before hitting the ground, reducing their kinetic energy. However it is the forest floor, more than the canopy, that prevents surface erosion. The terminal velocity of rain drops is reached in about 8 m. Because forest canopies are usually higher than this, rain drops can often regain terminal velocity even after striking the canopy. However, the intact forest floor, with its layers of leaf litter and organic matter, is still able to absorb the impact of the rainfall.\nDeforestation causes increased erosion rates due to exposure of mineral soil by removing the humus and litter layers from the soil surface, removing the vegetative cover that binds soil together, and causing heavy soil compaction from logging equipment. Once trees have been removed by fire or logging, infiltration rates become high and erosion low to the degree the forest floor remains intact. Severe fires can lead to significant further erosion if followed by heavy rainfall.\nGlobally one of the largest contributors to erosive soil loss in the year 2006 is the slash and burn treatment of tropical forests. In a number of regions of the earth, entire sectors of a country have been rendered unproductive. For example, on the Madagascar high central plateau, comprising approximately ten percent of that country's land area, virtually the entire landscape is sterile of vegetation, with gully erosive furrows typically in excess of 50 m deep and 1 km wide. Shifting cultivation is a farming system which sometimes incorporates the slash and burn method in some regions of the world. This degrades the soil and causes the soil to become less and less fertile.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Human activities that increase soil erosion", "sub_heading": "Deforestation", "_id": "87--2--1---1", "title": "The Impact of Deforestation on the Forest Floor"}
{"qas": [{"question": "How does urbanization cause erosion?", "answer": ""}, {"question": "What is the process of soil being compacted by urbanization?", "answer": "erosion", "ae_score": -1.1461671846450592, "qg_score": null}, {"question": "What is the process of soil being compacted by urbanization?", "answer": "erosion", "ae_score": -1.1461671846450592, "qg_score": null}], "content": "Urbanization has major effects on erosion processes\u2014first by denuding the land of vegetative cover, altering drainage patterns, and compacting the soil during construction; and next by covering the land in an impermeable layer of asphalt or concrete that increases the amount of surface runoff and increases surface wind speeds. Much of the sediment carried in runoff from urban areas (especially roads) is highly contaminated with fuel, oil, and other chemicals. This increased runoff, in addition to eroding and degrading the land that it flows over, also causes major disruption to surrounding watersheds by altering the volume and rate of water that flows through them, and filling them with chemically polluted sedimentation. The increased flow of water through local waterways also causes a large increase in the rate of bank erosion.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Human activities that increase soil erosion", "sub_heading": "Roads and urbanization", "_id": "87--2--2---1", "title": "The Impact of Urbanization on Eroding Watersheds"}
{"qas": [{"question": "How much change in the earth's soil is due to climate change?", "answer": ""}, {"question": "Who studies soil erosion and climate change?", "answer": "Pruski and Nearing", "ae_score": -0.3674519003117792, "qg_score": null}, {"question": "Who studies soil erosion and climate change?", "answer": "Pruski and Nearing", "ae_score": -0.3674519003117792, "qg_score": null}], "content": "The warmer atmospheric temperatures observed over the past decades are expected to lead to a more vigorous hydrological cycle, including more extreme rainfall events. The rise in sea levels that has occurred as a result of climate change has also greatly increased coastal erosion rates.\nStudies on soil erosion suggest that increased rainfall amounts and intensities will lead to greater rates of soil erosion. Thus, if rainfall amounts and intensities increase in many parts of the world as expected, erosion will also increase, unless amelioration measures are taken. Soil erosion rates are expected to change in response to changes in climate for a variety of reasons. The most direct is the change in the erosive power of rainfall. Other reasons include: a) changes in plant canopy caused by shifts in plant biomass production associated with moisture regime; b) changes in litter cover on the ground caused by changes in both plant residue decomposition rates driven by temperature and moisture dependent soil microbial activity as well as plant biomass production rates; c) changes in soil moisture due to shifting precipitation regimes and evapo-transpiration rates, which changes infiltration and runoff ratios; d) soil erodibility changes due to decrease in soil organic matter concentrations in soils that lead to a soil structure that is more susceptible to erosion and increased runoff due to increased soil surface sealing and crusting; e) a shift of winter precipitation from non-erosive snow to erosive rainfall due to increasing winter temperatures; f) melting of permafrost, which induces an erodible soil state from a previously non-erodible one; and g) shifts in land use made necessary to accommodate new climatic regimes.\nStudies by Pruski and Nearing indicated that, other factors such as land use unconsidered, it is reasonable to expect approximately a 1.7% change in soil erosion for each 1% change in total precipitation under climate change.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Human activities that increase soil erosion", "sub_heading": "Climate change", "_id": "87--2--3---1", "title": "Soil Erosion Rates Under Climate Change"}
{"qas": [{"question": "Why is land in the US so much worse than it was 100 years ago?", "answer": ""}, {"question": "What percentage of land is eroded by water and wind erosion?", "answer": "84%", "ae_score": -0.18316887270842014, "qg_score": null}, {"question": "What percentage of land is eroded by water and wind erosion?", "answer": "84%", "ae_score": -0.18316887270842014, "qg_score": null}], "content": "Water and wind erosion are now the two primary causes of land degradation; combined, they are responsible for 84% of degraded acreage.\nEach year, about 75 billion tons of soil is eroded from the land\u2014a rate that is about 13-40 times as fast as the natural rate of erosion. Approximately 40% of the world's agricultural land is seriously degraded. According to the United Nations, an area of fertile soil the size of Ukraine is lost every year because of drought, deforestation and climate change. In Africa, if current trends of soil degradation continue, the continent might be able to feed just 25% of its population by 2025, according to UNU's Ghana-based Institute for Natural Resources in Africa.\nThe loss of soil fertility due to erosion is further problematic because the response is often to apply chemical fertilizers, which leads to further water and soil pollution, rather than to allow the land to regenerate.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Global environmental effects", "sub_heading": "Global environmental effects", "_id": "87--3--0---1", "title": "Water and Wind Erosion Are the Two Main Causes of Land Degradation"}
{"qas": [{"question": "What would happen if all the sediment in the ocean was removed?", "answer": ""}, {"question": "What is the leading cause of diffuse water pollution?", "answer": "Soil erosion", "ae_score": -0.21233436651104784, "qg_score": null}, {"question": "What is the leading cause of diffuse water pollution?", "answer": "Soil erosion", "ae_score": -0.21233436651104784, "qg_score": null}], "content": "Soil erosion (especially from agricultural activity) is considered to be the leading global cause of diffuse water pollution, due to the effects of the excess sediments flowing into the world's waterways. The sediments themselves act as pollutants, as well as being carriers for other pollutants, such as attached pesticide molecules or heavy metals.\nThe effect of increased sediments loads on aquatic ecosystems can be catastrophic. Silt can smother the spawning beds of fish, by filling in the space between gravel on the stream bed. It also reduces their food supply, and causes major respiratory issues for them as sediment enters their gills. The biodiversity of aquatic plant and algal life is reduced, and invertebrates are also unable to survive and reproduce. While the sedimentation event itself might be relatively short-lived, the ecological disruption caused by the mass die off often persists long into the future.\nOne of the most serious and long-running water erosion problems worldwide is in the People's Republic of China, on the middle reaches of the Yellow River and the upper reaches of the Yangtze River. From the Yellow River, over 1.6 billion tons of sediment flows into the ocean each year. The sediment originates primarily from water erosion in the Loess Plateau region of the northwest.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Global environmental effects", "sub_heading": "Sedimentation of aquatic ecosystems", "_id": "87--3--1---1", "title": "Water Erosion in China"}
{"qas": [{"question": "Why are there so many red sunsets in the US?", "answer": ""}, {"question": "What causes the color of the sky to change?", "answer": "Dust from erosion", "ae_score": -0.7245285550926437, "qg_score": null}, {"question": "What causes the color of the sky to change?", "answer": "Dust from erosion", "ae_score": -0.7245285550926437, "qg_score": null}], "content": "Soil particles picked up during wind erosion of soil are a major source of air pollution, in the form of airborne particulates\u2014\"dust\". These airborne soil particles are often contaminated with toxic chemicals such as pesticides or petroleum fuels, posing ecological and public health hazards when they later land, or are inhaled/ingested.\nDust from erosion acts to suppress rainfall and changes the sky color from blue to white, which leads to an increase in red sunsets. Dust events have been linked to a decline in the health of coral reefs across the Caribbean and Florida, primarily since the 1970s. Similar dust plumes originate in the Gobi desert, which combined with pollutants, spread large distances downwind, or eastward, into North America.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Global environmental effects", "sub_heading": "Airborne dust pollution", "_id": "87--3--2---1", "title": "Dust from Wind Erosion is a Major Source of Air Pollution in the Caribbean and"}
{"qas": [{"question": "Why is it so difficult to accurately predict the extent of soil erosion?", "answer": ""}, {"question": "What type of soil erosion model is difficult to use numerically?", "answer": "non-linear", "ae_score": -0.6699368462457125, "qg_score": null}, {"question": "What type of soil erosion model is difficult to use numerically?", "answer": "non-linear", "ae_score": -0.6699368462457125, "qg_score": null}], "content": "Monitoring and modeling of erosion processes can help people better understand the causes of soil erosion, make predictions of erosion under a range of possible conditions, and plan the implementation of preventative and restorative strategies for erosion. However, the complexity of erosion processes and the number of scientific disciplines that must be considered to understand and model them (e.g. climatology, hydrology, geology, soil science, agriculture, chemistry, physics, etc.) makes accurate modelling challenging. Erosion models are also non-linear, which makes them difficult to work with numerically, and makes it difficult or impossible to scale up to making predictions about large areas from data collected by sampling smaller plots.\nThe most commonly used model for predicting soil loss from water erosion is the ''Universal Soil Loss Equation (USLE)''. This was developed in the 1960s and 1970s. It estimates the average annual soil loss ''A'' on a plot-sized area as:\nwhere ''R'' is the rainfall erosivity factor, ''K'' is the soil erodibility factor, ''L'' and ''S'' are topographic factors representing length and slope, ''C'' is the cover and management factor and ''P'' is the support practices factor.\nDespite the USLE's plot-scale spatial focus, the model has often been used to estimate soil erosion on much larger areas, such as watersheds or even whole continents. For example, RUSLE has recently been used to quantify soil erosion across the whole of Europe . This is scientifically controversial, for several reasons. One major problem is that the USLE cannot simulate gully erosion, and so erosion from gullies is ignored in any USLE-based assessment of erosion. Yet erosion from gullies can be a substantial proportion (10-80%) of total erosion on cultivated and grazed land.\nDuring the 50 years since the introduction of the USLE, many other soil erosion models have been developed. But because of the complexity of soil erosion and its constituent processes, all erosion models can give unsatisfactory results when validated i.e. when model predictions are compared with real-world measurements of erosion. Thus new soil erosion models continue to be developed. Some of these remain USLE-based, e.g. the G2 model . Other soil erosion models have largely (e.g. the Water Erosion Prediction Project model) or wholly (e.g. the Rangeland Hydrology and Erosion Model) abandoned usage of USLE elements.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Monitoring, measuring and modeling soil erosion", "sub_heading": "Monitoring, measuring and modeling soil erosion", "_id": "87--4---1---1", "title": "Soil Erosion Models \u2014 A Practical Guide"}
{"qas": [{"question": "How do mangrove forests prevent erosion?", "answer": ""}, {"question": "How long has it been used to prevent soil erosion?", "answer": "thousands of years", "ae_score": null, "qg_score": null}, {"question": "How long has it been used to prevent soil erosion?", "answer": "thousands of years", "ae_score": null, "qg_score": null}], "content": "The most effective known method for erosion prevention is to increase vegetative cover on the land, which helps prevent both wind and water erosion. Terracing is an extremely effective means of erosion control, which has been practiced for thousands of years by people all over the world. Windbreaks (also called shelterbelts) are rows of trees and shrubs that are planted along the edges of agricultural fields, to shield the fields against winds. In addition to significantly reducing wind erosion, windbreaks provide many other benefits such as improved microclimates for crops (which are sheltered from the dehydrating and otherwise damaging effects of wind), habitat for beneficial bird species, carbon sequestration, and aesthetic improvements to the agricultural landscape. Traditional planting methods, such as mixed-cropping (instead of monocropping) and crop rotation have also been shown to significantly reduce erosion rates. Crop residues play a role in the mitigation of erosion, because they reduce the impact of raindrops breaking up the soil particles. There is a higher potential for erosion when producing potatoes than when growing cereals, or oilseed crops.  Forages have a fibrous root system, which helps combat erosion by anchoring the plants to the top layer of the soil, and covering the entirety of the field, as it is a non-row crop. In tropical coastal systems, properties of mangroves have been examined as a potential means to reduce soil erosion. Their complex root structures are known to help reduce wave damage from storms and flood impacts while binding and building soils. These roots can slow down water flow, leading to the deposition of sediments and reduced erosion rates. However, in order to maintain sediment balance, adequate mangrove forest width needs to be present.", "page_name": "Soil erosion", "page_id": "Soil%20erosion", "heading": "Prevention and remediation", "sub_heading": "Prevention and remediation", "_id": "87--5---1---1", "title": "How to Reduce Erosion in Tropical Environments"}
{"qas": [{"question": "Why do people with Crohn's Disease have symptoms for years prior to their diagnosis?", "answer": ""}, {"question": "What is the cause of perianal crohn's disease?", "answer": "Fecal incontinence", "ae_score": -0.4120088230148522, "qg_score": null}, {"question": "What is the cause of perianal crohn's disease?", "answer": "Fecal incontinence", "ae_score": -0.4120088230148522, "qg_score": null}], "content": "Many people with Crohn's disease have symptoms for years prior to the diagnosis. The usual onset is between 15 and 30 years of age, but can occur at any age. Because of the 'patchy' nature of the gastrointestinal disease and the depth of tissue involvement, initial symptoms can be more subtle than those of ulcerative colitis. People with Crohn's disease experience chronic recurring periods of flare-ups and remission.\nAbdominal pain may be the initial symptom of Crohn's disease usually in the lower right area. It is often accompanied by diarrhea, especially in those who have had surgery. The diarrhea may or may not be bloody. The nature of the diarrhea in Crohn's disease depends on the part of the small intestine or colon involved. Ileitis typically results in large-volume, watery feces. Colitis may result in a smaller volume of feces of higher frequency. Fecal consistency may range from solid to watery. In severe cases, an individual may have more than 20 bowel movements per day and may need to awaken at night to defecate.<ref name=Baumgart2012/><ref name=emed/><ref name=Podolsky/> Visible bleeding in the feces is less common in Crohn's disease than in ulcerative colitis, but may be seen in the setting of Crohn's colitis.<ref name=Baumgart2012/> Bloody bowel movements typically come and go, and may be bright or dark red in color. In the setting of severe Crohn's colitis, bleeding may be copious.<ref name=emed/> Flatulence and bloating may also add to the intestinal discomfort.<ref name=emed/>\nSymptoms caused by intestinal stenosis are also common in Crohn's disease. Abdominal pain is often most severe in areas of the bowel with stenoses. Persistent vomiting and nausea may indicate stenosis from small bowel obstruction or disease involving the stomach, pylorus, or duodenum. Although the association is greater in the context of ulcerative colitis, Crohn's disease may also be associated with primary sclerosing cholangitis, a type of inflammation of the bile ducts.\nPerianal discomfort may also be prominent in Crohn's disease. Itchiness or pain around the anus may be suggestive of inflammation, fistulization or abscess around the anal area<ref name=Baumgart2012/> or anal fissure. Perianal skin tags are also common in Crohn's disease. Fecal incontinence may accompany perianal Crohn's disease. At the opposite end of the gastrointestinal tract, the mouth may be affected by non-healing sores (aphthous ulcers). Rarely, the esophagus, and stomach may be involved in Crohn's disease. These can cause symptoms including difficulty swallowing (dysphagia), upper abdominal pain, and vomiting.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "88--0--0---1", "title": "Crohn's Disease Symptoms"}
{"qas": [{"question": "What causes Crohn's Disease?", "answer": ""}, {"question": "What is the most common symptom of crohn's disease?", "answer": "growth failure", "ae_score": -0.5670661689651131, "qg_score": null}, {"question": "What is the most common symptom of crohn's disease?", "answer": "growth failure", "ae_score": -0.5670661689651131, "qg_score": null}], "content": "Crohn's disease, like many other chronic, inflammatory diseases, can cause a variety of systemic symptoms.<ref name=Baumgart2012/> Among children, growth failure is common. Many children are first diagnosed with Crohn's disease based on inability to maintain growth.<ref name=Beattie/> As it may manifest at the time of the growth spurt in puberty, up to 30% of children with Crohn's disease may have retardation of growth. Fever may also be present, though fevers greater than 38.5 \u00b0C (101.3 \u00b0F) are uncommon unless there is a complication such as an abscess.<ref name=Baumgart2012/> Among older individuals, Crohn's disease may manifest as weight loss, usually related to decreased food intake, since individuals with intestinal symptoms from Crohn's disease often feel better when they do not eat and might lose their appetite. People with extensive small intestine disease may also have malabsorption of carbohydrates or lipids, which can further exacerbate weight loss.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Signs and symptoms", "sub_heading": "Systemic", "_id": "88--0--1---1", "title": "Crohn's Disease Symptoms and Treatments"}
{"qas": [{"question": "How does Crohn's disease affect the eyes?", "answer": ""}, {"question": "Where does crohn's disease occur in the body?", "answer": "oral cavity", "ae_score": -0.39206368874681374, "qg_score": null}, {"question": "Where does crohn's disease occur in the body?", "answer": "oral cavity", "ae_score": -0.39206368874681374, "qg_score": null}], "content": "In addition to systemic and gastrointestinal involvement, Crohn's disease can affect many other organ systems. Inflammation of the interior portion of the eye, known as uveitis, can cause blurred vision and eye pain, especially when exposed to light (photophobia). Inflammation may also involve the white part of the eye (sclera), a condition called episcleritis. Both episcleritis and uveitis can lead to loss of vision if untreated.\nCrohn's disease that affects the ileum may result in an increased risk for gallstones. This is due to a decrease in bile acid resorption in the ileum and the bile gets excreted in the stool. As a result, the cholesterol/bile ratio increases in the gallbladder, resulting in an increased risk for gallstones.\nCrohn's disease is associated with a type of rheumatologic disease known as seronegative spondyloarthropathy. This group of diseases is characterized by inflammation of one or more joints (arthritis) or muscle insertions (enthesitis). The arthritis in Crohn's disease can be divided into two types. The first type affects larger weight-bearing joints such as the knee (most common), hips, shoulders, wrists, or elbows. The second type symmetrically involves five or more of the small joints of the hands and feet. The arthritis may also involve the spine, leading to ankylosing spondylitis if the entire spine is involved or simply sacroiliitis if only the sacroiliac joint is involved. The symptoms of arthritis include painful, warm, swollen, stiff joints, and loss of joint mobility or function.\nCrohn's disease may also involve the skin, blood, and endocrine system. The most common type of skin manifestation, erythema nodosum, presents as raised, tender red nodules usually appearing on the shins. Erythema nodosum is due to inflammation of the underlying subcutaneous tissue, and is characterized by septal panniculitis. Another skin lesion, pyoderma gangrenosum, is typically a painful ulcerating nodule. Crohn's disease also increases the risk of blood clots; painful swelling of the lower legs can be a sign of deep venous thrombosis, while difficulty breathing may be a result of pulmonary embolism. Autoimmune hemolytic anemia, a condition in which the immune system attacks the red blood cells, is also more common in Crohn's disease and may cause fatigue, a pale appearance, and other symptoms common in anemia. Clubbing, a deformity of the ends of the fingers, may also be a result of Crohn's disease. Finally, Crohn's disease increases the risk of osteoporosis, or thinning of the bones. Individuals with osteoporosis are at increased risk of bone fractures.\nPeople with Crohn's disease often have anemia due to vitamin B, folate, iron deficiency, or due to anemia of chronic disease. The most common is iron deficiency anemia from chronic blood loss, reduced dietary intake, and persistent inflammation leading to increased hepcidin levels, restricting iron absorption in the duodenum. As Crohn's disease most commonly affects the terminal ileum where the vitamin B12/intrinsic factor complex is absorbed, B12 deficiency may be seen. This is particularly common after surgery to remove the ileum. Involvement of the duodenum and jejunum can impair the absorption of many other nutrients including folate. If Crohn's disease affects the stomach, production of intrinsic factor can be reduced.\nCrohn's disease can also cause neurological complications (reportedly in up to 15%). The most common of these are seizures, stroke, myopathy, peripheral neuropathy, headache and depression.\nPeople with Crohn's often also have issues with small bowel bacterial overgrowth syndrome, which has similar symptoms.\nIn the oral cavity people with Crohn's may develop cheilitis granulomatosa and other forms of orofacial granulomatosis, pyostomatitis vegetans, recurrent aphthous stomatitis, geographic tongue, and migratory stomatitis in higher prevalence than the general population.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Signs and symptoms", "sub_heading": "Extraintestinal", "_id": "88--0--2---1", "title": "Crohn's Disease Symptoms and Treatments"}
{"qas": [{"question": "Why are there so many people with Crohn's Disease?", "answer": ""}, {"question": "How many genes are associated with crohn's disease?", "answer": "Over thirty", "ae_score": -0.5236379643723966, "qg_score": null}, {"question": "How many genes are associated with crohn's disease?", "answer": "Over thirty", "ae_score": -0.5236379643723966, "qg_score": null}], "content": "Crohn's has a genetic component. Because of this, siblings of known people with Crohn's are 30 times more likely to develop Crohn's than the general population.\nThe first mutation found to be associated with Crohn's was a frameshift in the NOD2 gene (also known as the CARD15 gene), followed by the discovery of point mutations. Over thirty genes have been associated with Crohn's; a biological function is known for most of them. For example, one association is with mutations in the XBP1 gene, which is involved in the unfolded protein response pathway of the endoplasmatic reticulum. The gene variants of NOD2/CARD15 seem to be related with small-bowel involvement. Other well documented genes which increase the risk of developing Crohn disease are ATG16L1, IL23R, IRGM, and SLC11A1.There is considerable overlap between susceptibility loci for IBD and mycobacterial infections. Recent genome-wide association studies have shown that Crohn\u2019s disease is genetically linked to coeliac disease.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Cause", "sub_heading": "Cause", "_id": "88--1--0---1", "title": "The Genetics of Crohn\u2019s"}
{"qas": [{"question": "Why does Crohn's disease cause so much inflammation?", "answer": ""}, {"question": "What disease is caused by the atg16l1 gene?", "answer": "Crohn's disease", "ae_score": -0.7534525171349443, "qg_score": null}, {"question": "What disease is caused by the atg16l1 gene?", "answer": "Crohn's disease", "ae_score": -0.7534525171349443, "qg_score": null}], "content": "There was a prevailing view that Crohn's disease is a primary T cell autoimmune disorder, however, a newer theory hypothesizes that Crohn's results from an impaired innate immunity. The later hypothesis describes impaired cytokine secretion by macrophages, which contributes to impaired innate immunity and leads to a sustained microbial-induced inflammatory response in the colon, where the bacterial load is high. Another theory is that the inflammation of Crohn's was caused by an overactive T1 and T17 cytokine response.\nIn 2007, the ATG16L1 gene has been implicated in Crohn's disease, which may induce autophagy and hinder the body's ability to attack invasive bacteria. Another study has theorized that the human immune system traditionally evolved with the presence of parasites inside the body, and that the lack thereof due to modern hygiene standards has weakened the immune system. Test subjects were reintroduced to harmless parasites, with positive response.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Cause", "sub_heading": "Immune system", "_id": "88--1--1---1", "title": "Crohn's Disease \u2014 A Newer Hypothesis"}
{"qas": [{"question": "Why do some strains of E.coli cause dysbiosis while others do not?", "answer": ""}, {"question": "What gene is involved in crohn's disease?", "answer": "NOD2", "ae_score": -0.22822972228357813, "qg_score": null}, {"question": "What gene is involved in crohn's disease?", "answer": "NOD2", "ae_score": -0.22822972228357813, "qg_score": null}], "content": "Current thinking is that microorganisms are taking advantage of their host's weakened mucosal layer and inability to clear bacteria from the intestinal walls, which are both symptoms of Crohn's. Different strains found in tissue and different outcomes to antibiotics therapy and resistance suggest Crohn's Disease is not one disease, but an umbrella of diseases related to different pathogens.\nA number of studies have suggested a causal role for ''Mycobacterium avium'' subspecies ''paratuberculosis'' (MAP), which causes a similar disease, Johne's disease, in cattle.\nNOD2 is a gene involved in Crohn's genetic susceptibility. It is associated with macrophages' diminished ability to phagocytize MAP. This same gene may reduce innate and adaptive immunity in gastrointestinal tissue and impair the ability to resist infection by the MAP bacterium. Macrophages that ingest the MAP bacterium are associated with high production of TNF-\u03b1.\nOther studies have linked specific strains of enteroadherent ''E. coli'' to the disease. Adherent-invasive Escherichia coli (AIEC), are more common in people with CD, have the ability to make strong biofilms compared to non-AIEC strains correlating with high adhesion and invasion indices of neutrophils and the ability to block autophagy at the autolysosomal step, which allows for intracellular survival of the bacteria and induction of inflammation. Inflammation drives the proliferation of AIEC and dysbiosis in the ileum, irrespective of genotype. AIEC strains replicate extensively into macrophages inducing the secretion of very large amounts of TNF-\u03b1.\nMouse studies have suggested some symptoms of Crohn's disease, ulcerative colitis, and irritable bowel syndrome have the same underlying cause. Biopsy samples taken from the colons of all three patient groups were found to produce elevated levels of a serine protease. Experimental introduction of the serine protease into mice has been found to produce widespread pain associated with irritable bowel syndrome, as well as colitis, which is associated with all three diseases. Regional and temporal variations in those illnesses follow those associated with infection with the protozoan Blastocystis.\nThe \"cold-chain\" hypothesis is that psychrotrophic bacteria such as ''Yersinia'' and ''Listeria'' species contribute to the disease. A statistical correlation was found between the advent of the use of refrigeration in the United States and various parts of Europe and the rise of the disease.\nThere is an apparent connection between Crohn's disease, ''Mycobacterium'', other pathogenic bacteria, and genetic markers. In many individuals, genetic factors predispose individuals to ''Mycobacterium avium'' subsp.'' paratuberculosis'' infection. This bacterium then produces mannins, which protect both itself and various bacteria from phagocytosis, which causes a variety of secondary infections.\nStill, this relationship between specific types of bacteria and Crohn's disease remains unclear.\nThere is a tentative association between ''Candida'' conlonization and Crohn's disease.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Cause", "sub_heading": "Microbes", "_id": "88--1--2---1", "title": "Crohn's Disease and the Cold-Chase Hypothesis"}
{"qas": [{"question": "Why is Crohn's Disease so common?", "answer": ""}, {"question": "What is the chemical that causes crohn's disease?", "answer": "Isotretinoin", "ae_score": -0.7912165142609832, "qg_score": null}, {"question": "What is the chemical that causes crohn's disease?", "answer": "Isotretinoin", "ae_score": -0.7912165142609832, "qg_score": null}], "content": "The increased incidence of Crohn's in the industrialized world indicates an environmental component. Crohn's is associated with an increased intake of animal protein, milk protein and an increased ratio of omega-6 to omega-3 polyunsaturated fatty acids.Those who consume vegetable proteins appear to have a lower incidence of Crohn's disease. Consumption of fish protein has no association.Smoking increases the risk of the return of active disease (flares). The introduction of hormonal contraception in the United States in the 1960s is associated with a dramatic increase in incidence, and one hypothesis is that these drugs work on the digestive system in ways similar to smoking. Isotretinoin is associated with Crohn's. Although stress is sometimes claimed to exacerbate Crohn's disease, there is no concrete evidence to support such claim. Dietary microparticles, such as those found in toothpaste, have been studied as they produce effects on immunity, but they were not consumed in greater amounts in patients with Crohn's.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Cause", "sub_heading": "Environmental factors", "_id": "88--1--3---1", "title": "Crohn's Incidence and the Effects of Stress on Immunity"}
{"qas": [{"question": "How does Crohn's disease work?", "answer": ""}, {"question": "What is the difference between the ulcer and the tissue surrounding it?", "answer": "skip lesions", "ae_score": -0.8686383454015788, "qg_score": null}, {"question": "What is the difference between the ulcer and the tissue surrounding it?", "answer": "skip lesions", "ae_score": -0.8686383454015788, "qg_score": null}], "content": "During a colonoscopy, biopsies of the colon are often taken to confirm the diagnosis. Certain characteristic features of the pathology seen point toward Crohn's disease; it shows a transmural pattern of inflammation, meaning the inflammation may span the entire depth of the intestinal wall.<ref name=Baumgart2012/> Ulceration is an outcome seen in highly active disease. There is usually an abrupt transition between unaffected tissue and the ulcer\u2014a characteristic sign known as skip lesions. Under a microscope, biopsies of the affected colon may show mucosal inflammation, characterized by focal infiltration of neutrophils, a type of inflammatory cell, into the epithelium. This typically occurs in the area overlying lymphoid aggregates. These neutrophils, along with mononuclear cells, may infiltrate the crypts, leading to inflammation (crypititis) or abscess (crypt abscess). Granulomas, aggregates of macrophage derivatives known as giant cells, are found in 50% of cases and are most specific for Crohn's disease. The granulomas of Crohn's disease do not show \"caseation\", a cheese-like appearance on microscopic examination characteristic of granulomas associated with infections, such as tuberculosis. Biopsies may also show chronic mucosal damage, as evidenced by blunting of the intestinal villi, atypical branching of the crypts, and a change in the tissue type (metaplasia). One example of such metaplasia, ''Paneth cell metaplasia'', involves development of Paneth cells (typically found in the small intestine and a key regulator of intestinal microbiota) in other parts of the gastrointestinal system.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "88--2---1---1", "title": "Crohn's Disease \u2014 Colonoscopy"}
{"qas": [{"question": "Why is Crohn's disease classified as a disease?", "answer": ""}, {"question": "Where does crohn's disease usually occur in the body?", "answer": "gastrointestinal tract", "ae_score": -0.6635103993836667, "qg_score": null}, {"question": "Where does crohn's disease usually occur in the body?", "answer": "gastrointestinal tract", "ae_score": -0.6635103993836667, "qg_score": null}], "content": "Crohn's disease is one type of inflammatory bowel disease (IBD). It typically manifests in the gastrointestinal tract and can be categorized by the specific tract region affected. A disease of both the ileum (the last part of the small intestine that connects to the large intestine), and the large intestine, Ileocolic Crohn's accounts for fifty percent of cases. Crohn's ileitis, manifest in the ileum only, accounts for thirty percent of cases, while Crohn's colitis, of the large intestine, accounts for the remaining twenty percent of cases and may be particularly difficult to distinguish from ulcerative colitis. Gastroduodenal Crohn's disease causes inflammation in the stomach and first part of the small intestine, called the duodenum. Jejunoileitis causes spotty patches of inflammation in the top half of the small intestine, called the jejunum. The disease can attack any part of the digestive tract, from mouth to anus. However, individuals affected by the disease rarely fall outside these three classifications, with presentations in other areas.<ref name=Baumgart2012/>\nCrohn's disease may also be categorized by the behavior of disease as it progresses. These categorizations formalized in the Vienna classification of the disease. There are three categories of disease presentation in Crohn's disease: stricturing, penetrating, and inflammatory. Stricturing disease causes narrowing of the bowel that may lead to bowel obstruction or changes in the caliber of the feces. Penetrating disease creates abnormal passageways (fistulae) between the bowel and other structures, such as the skin. Inflammatory disease (or nonstricturing, nonpenetrating disease) causes inflammation without causing strictures or fistulae.<ref name=Vienna/>", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "88--3--0---1", "title": "The Vienna classification of Crohn's Disease"}
{"qas": [{"question": "How does a colonoscopy work?", "answer": ""}, {"question": "What is the best test for diagnosis of crohn's disease?", "answer": "colonoscopy", "ae_score": -0.3854276369226898, "qg_score": null}, {"question": "What is the best test for diagnosis of crohn's disease?", "answer": "colonoscopy", "ae_score": -0.3854276369226898, "qg_score": null}], "content": "A colonoscopy is the best test for making the diagnosis of Crohn's disease, as it allows direct visualization of the colon and the terminal ileum, identifying the pattern of disease involvement. On occasion, the colonoscope can travel past the terminal ileum, but it varies from person to person. During the procedure, the gastroenterologist can also perform a biopsy, taking small samples of tissue for laboratory analysis, which may help confirm a diagnosis. As 30% of Crohn's disease involves only the ileum,<ref name=Baumgart2012/> cannulation of the terminal ileum is required in making the diagnosis. Finding a patchy distribution of disease, with involvement of the colon or ileum, but not the rectum, is suggestive of Crohn's disease, as are other endoscopic stigmata.The utility of capsule endoscopy for this, however, is still uncertain. A \"cobblestone\"-like appearance is seen in approximately 40% of cases of Crohn's disease upon colonoscopy, representing areas of ulceration separated by narrow areas of healthy tissue.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Endoscopy", "_id": "88--3--1---1", "title": "Colonoscopy for Crohn's disease"}
{"qas": [{"question": "Why do doctors use barium sulfate suspension to test for Crohn's Disease?", "answer": ""}, {"question": "What is the name of the procedure in which barium is inserted into the rectum?", "answer": "Barium enemas", "ae_score": -1.0673055801574007, "qg_score": null}, {"question": "What is the name of the procedure in which barium is inserted into the rectum?", "answer": "Barium enemas", "ae_score": -1.0673055801574007, "qg_score": null}], "content": "A small bowel follow-through may suggest the diagnosis of Crohn's disease and is useful when the disease involves only the small intestine. Because colonoscopy and gastroscopy allow direct visualization of only the terminal ileum and beginning of the duodenum, they cannot be used to evaluate the remainder of the small intestine. As a result, a barium follow-through X-ray, wherein barium sulfate suspension is ingested and fluoroscopic images of the bowel are taken over time, is useful for looking for inflammation and narrowing of the small bowel. Barium enemas, in which barium is inserted into the rectum and fluoroscopy is used to image the bowel, are rarely used in the work-up of Crohn's disease due to the advent of colonoscopy. They remain useful for identifying anatomical abnormalities when strictures of the colon are too small for a colonoscope to pass through, or in the detection of colonic fistulae (in this case contrast should be performed with iodate substances).\nCT and MRI scans are useful for evaluating the small bowel with enteroclysis protocols. They are also useful for looking for intra-abdominal complications of Crohn's disease, such as abscesses, small bowel obstructions, or fistulae. Magnetic resonance imaging (MRI) is another option for imaging the small bowel as well as looking for complications, though it is more expensive and less readily available.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Radiologic tests", "_id": "88--3--2---1", "title": "Small bowel follow-through X-rays"}
{"qas": [{"question": "How do blood counts work for Crohn's disease?", "answer": ""}, {"question": "Low serum levels of vitamin d are associated with?", "answer": "Crohn's disease", "ae_score": -0.696302690915101, "qg_score": null}, {"question": "Low serum levels of vitamin d are associated with?", "answer": "Crohn's disease", "ae_score": -0.696302690915101, "qg_score": null}], "content": "A complete blood count may reveal anemia, which commonly is caused by blood loss leading to iron deficiency (a microcytic anemia) or by vitamin B deficiency (a macrocytic anemia), usually caused by ileal disease impairing vitamin B absorption. Rarely autoimmune hemolysis may occur. Ferritin levels help assess if iron deficiency is contributing to the anemia. Erythrocyte sedimentation rate (ESR) and C-reactive protein help assess the degree of inflammation, which is important as ferritin can also be raised in inflammation. Serum iron, total iron binding capacity and transferrin saturation may be more easily interpreted in inflammation. Anemia of chronic disease results in a normocytic anemia. Other causes of anemia include medication used in treatment of inflammatory bowel disease, like azathioprine, which can lead to cytopenia, and sulfasalazine, which can also result in folate deficiency. Testing for ''Saccharomyces cerevisiae'' antibodies (ASCA) and antineutrophil cytoplasmic antibodies (ANCA) has been evaluated to identify inflammatory diseases of the intestine and to differentiate Crohn's disease from ulcerative colitis. Furthermore, increasing amounts and levels of serological antibodies such as ASCA, antilaminaribioside [Glc(\u03b21,3)Glb(\u03b2); ALCA], antichitobioside [GlcNAc(\u03b21,4)GlcNAc(\u03b2); ACCA], antimannobioside [Man(\u03b11,3)Man(\u03b1)AMCA], antiLaminarin [(Glc(\u03b21,3))3n(Glc(\u03b21,6))n; anti-L] and antichitin [GlcNAc(\u03b21,4)n; anti-C] associate with disease behavior and surgery, and may aid in the prognosis of Crohn's disease.\nLow serum levels of vitamin D are associated with Crohn's disease. Further studies are required to determine the significance of this association.<ref name=IBD2015/>", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Blood tests", "_id": "88--3--3---1", "title": "Crohn's Disease \u2014 A Case Report"}
{"qas": [{"question": "Crohn's Disease?", "answer": ""}, {"question": "What is the most common type of crohn's disease?", "answer": "ulcerative colitis", "ae_score": -0.1690806863092876, "qg_score": null}, {"question": "What is the most common type of crohn's disease?", "answer": "ulcerative colitis", "ae_score": -0.1690806863092876, "qg_score": null}], "content": "The most common disease that mimics the symptoms of Crohn's disease is ulcerative colitis, as both are inflammatory bowel diseases that can affect the colon with similar symptoms. It is important to differentiate these diseases, since the course of the diseases and treatments may be different. In some cases, however, it may not be possible to tell the difference, in which case the disease is classified as indeterminate colitis.<ref name=Baumgart2012/><ref name=emed/><ref name=Podolsky/>", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Comparison with ulcerative colitis", "_id": "88--3--4---1", "title": "Crohn's Disease and Ulcerative Colitis"}
{"qas": [{"question": "Why is Crohn's disease excluded from the list of conditions?", "answer": ""}, {"question": "What are the different types of crohn's disease?", "answer": "Celiac disease", "ae_score": -1.1697169786746962, "qg_score": null}, {"question": "What are the different types of crohn's disease?", "answer": "Celiac disease", "ae_score": -1.1697169786746962, "qg_score": null}], "content": "Other conditions with similar symptoms as Crohn's disease includes intestinal tuberculosis, Beh\u00e7et\u2019s disease, ulcerative colitis, nonsteroidal anti-inflammatory drug enteropathy, irritable bowel syndrome and celiac disease. Irritable bowel syndrome is excluded when there are inflammatory changes. Celiac disease can't be excluded if specific antibodies (anti-transglutaminase antibodies) are negative, nor in absence of intestinal villi atrophy.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Diagnosis", "sub_heading": "Differential diagnosis", "_id": "88--3--5---1", "title": "Crohn\u2019s disease is not a Crohn\u2019s disease"}
{"qas": [{"question": "How does Crohn's disease work?", "answer": ""}, {"question": "What type of diary helps identify foods that trigger symptoms?", "answer": "food diary", "ae_score": -1.5385613119124077, "qg_score": null}, {"question": "What type of diary helps identify foods that trigger symptoms?", "answer": "food diary", "ae_score": -1.5385613119124077, "qg_score": null}], "content": "Certain lifestyle changes can reduce symptoms, including dietary adjustments, elemental diet, proper hydration, and smoking cessation. Diets that include higher levels of fiber and fruit are associated with reduced risk, while diets rich in total fats, polyunsaturated fatty acids, meat, and omega-6 fatty acids may increase the risk of Crohn's. Smoking may increase Crohn's disease; stopping is recommended. Eating small meals frequently instead of big meals may also help with a low appetite. To manage symptoms have a balanced diet with proper portion control. Fatigue can be helped with regular exercise, a healthy diet, and enough sleep. A food diary may help with identifying foods that trigger symptoms. Some people should follow a low dietary fiber diet to control symptoms especially if fibrous foods cause symptoms.<ref name = WebMD/> Some find relief in eliminating casein (protein found in cow's milk) and gluten (protein found in wheat, rye and barley) from their diets. They may have specific dietary intolerances (not allergies).", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Management", "sub_heading": "Management", "_id": "88--4--0---1", "title": "Crohn's Disease Symptoms & Treatment"}
{"qas": [{"question": "What is the difference between a monoclonal antibody and a biological antibody for Crohn's disease?", "answer": ""}, {"question": "What is the most common drug used to treat crohn's disease?", "answer": "Hydrocortisone", "ae_score": -0.6549829152279346, "qg_score": null}, {"question": "What is the most common drug used to treat crohn's disease?", "answer": "Hydrocortisone", "ae_score": -0.6549829152279346, "qg_score": null}], "content": "Acute treatment uses medications to treat any infection (normally antibiotics) and to reduce inflammation (normally aminosalicylate anti-inflammatory drugs and corticosteroids). When symptoms are in remission, treatment enters maintenance, with a goal of avoiding the recurrence of symptoms. Prolonged use of corticosteroids has significant side-effects; as a result, they are, in general, not used for long-term treatment. Alternatives include aminosalicylates alone, though only a minority are able to maintain the treatment, and many require immunosuppressive drugs. It has been also suggested that antibiotics change the enteric flora, and their continuous use may pose the risk of overgrowth with pathogens such as ''Clostridium difficile''.\nMedications used to treat the symptoms of Crohn's disease include 5-aminosalicylic acid (5-ASA) formulations, prednisone, immunomodulators such as azathioprine (given as the prodrug for 6-mercaptopurine), methotrexate, infliximab, adalimumab, certolizumab and natalizumab. Hydrocortisone should be used in severe attacks of Crohn's disease. Biological therapies (biopharmaceuticals) are medications used to avoid long-term steroid use, decrease inflammation, and treat people who have fistulas with abscesses. The monoclonal antibody ustekinumab appears to be a safe treatment option, and may help people with moderate to severe active crohn's disease. The long term safety and effectiveness of monoclonal antibody treatment is not known. The monoclonal antibody briakinumab is not effective for people with active crohn's disease.<ref name=Kha2015/>\nThe gradual loss of blood from the gastrointestinal tract, as well as chronic inflammation, often leads to anemia, and professional guidelines suggest routinely monitoring for this. Adequate disease control usually improves anemia of chronic disease, but iron deficiency may require treatment with iron supplements. Guidelines vary as to how iron should be administered. Besides other, problems include a limitation in possible daily resorption and an increased growth of intestinal bacteria. Some advise parenteral iron as first line as it works faster, has fewer gastrointestinal side effects, and is unaffected by inflammation reducing enteral absorption.\nOther guidelines advise oral iron as first line with parenteral iron reserved for those that fail to adequately respond as oral iron is considerably cheaper. All agree that severe anemia (hemoglobin under 10g/dL) should be treated with parenteral iron. Blood transfusion should be reserved for those who are cardiovascularly unstable, due to its relatively poor safety profile, lack of long term efficacy, and cost.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Management", "sub_heading": "Medication", "_id": "88--4--1---1", "title": "Crohn's Disease Symptoms & Treatment"}
{"qas": [{"question": "What is bile acid malabsorption and how does it work?", "answer": ""}, {"question": "What is the main symptom of crohn's disease?", "answer": "Diarrhea", "ae_score": -0.26262390173696554, "qg_score": null}, {"question": "What is the main symptom of crohn's disease?", "answer": "Diarrhea", "ae_score": -0.26262390173696554, "qg_score": null}], "content": "Crohn's cannot be cured by surgery, as the disease eventually recurs, though it is used in the case of partial or full blockage of the intestine. Surgery may also be required for complications such as obstructions, fistulas, or abscesses, or if the disease does not respond to drugs. After the first surgery, Crohn's usually comes back at the site where the diseased intestine was removed and the healthy ends were rejoined, however it can come back in other locations. After a resection, scar tissue builds up, which can cause strictures, which form when the intestines become too small to allow excrement to pass through easily, which can lead to a blockage. After the first resection, another resection may be necessary within five years. For patients with an obstruction due to a stricture, two options for treatment are strictureplasty and resection of that portion of bowel. There is no statistical significance between strictureplasty alone versus strictureplasty and resection in cases of duodenal involvement. In these cases, re-operation rates were 31% and 27%, respectively, indicating that strictureplasty is a safe and effective treatment for selected people with duodenal involvement.\nPostsurgical recurrence of Crohn's disease is relatively common. Crohn's lesions are nearly always found at the site of the resected bowel. The join (or anastomosis) after surgery may be inspected, usually during a colonoscopy, and disease activity graded. The \"Rutgeert's score\" is an endoscopic scoring system for post-operative disease recurrence in Crohn's disease. Mild postsurgical recurrences of Crohn's disease are graded i1 and i2, moderate to severe recurrences are graded i3 and i4. Fewer lesions result in a lower grade. Based on the score, treatment plans can be designed to give the patient the best chance of managing recurrence of the disease.\nShort bowel syndrome (SBS, also short gut syndrome or simply short gut) is caused by the surgical removal of part of the small intestine. It usually develops in those patients who have had half or more of their small intestines removed. Diarrhea is the main symptom, but others may include weight loss, cramping, bloating, and heartburn. Short bowel syndrome is treated with changes in diet, intravenous feeding, vitamin and mineral supplements, and treatment with medications. In some cases of SBS, intestinal transplant surgery may be considered; though the number of transplant centres offering this procedure is quite small and it comes with a high risk due to the chance of infection and rejection of the transplanted intestine.\nBile acid diarrhea is another complication following surgery for Crohn's disease in which the terminal ileum has been removed. This leads to the development of excessive watery diarrhea. It is usually thought to be due to an inability of the ileum to reabsorb bile acids after resection of the terminal ileum and was the first type of bile acid malabsorption recognized.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Management", "sub_heading": "Surgery", "_id": "88--4--2---1", "title": "Symptoms of Crohn's Disease: Symptoms, Treatment, and Treatment"}
{"qas": [{"question": "Why is Crohn's Disease so hard to cure?", "answer": ""}, {"question": "How many people have tried alternative treatments for crohn's disease?", "answer": "More than half", "ae_score": -0.38915974815175164, "qg_score": null}, {"question": "How many people have tried alternative treatments for crohn's disease?", "answer": "More than half", "ae_score": -0.38915974815175164, "qg_score": null}], "content": "More than half of people with Crohn's disease have tried complementary or alternative therapy. These include diets, probiotics, fish oil and other herbal and nutritional supplements. Some scientists have suggested more research into these is needed to discriminate between effective therapies and those that have not been found to be effective.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Management", "sub_heading": "Alternative medicine", "_id": "88--4--3---1", "title": "Alternative Therapies for Crohn\u2019s Disease"}
{"qas": [{"question": "Why is Crohn's Disease so common?", "answer": ""}, {"question": "What is the main risk factor for Crohn's disease?", "answer": "malnutrition", "ae_score": -0.41935377676783636, "qg_score": null}, {"question": "What is the main risk factor for Crohn's disease?", "answer": "malnutrition", "ae_score": -0.41935377676783636, "qg_score": null}], "content": "Crohn's disease is a chronic condition for which there is no cure. It is characterised by periods of improvement followed by episodes when symptoms flare up. With treatment, most people achieve a healthy weight, and the mortality rate for the disease is relatively low. It can vary from being benign to very severe and people with CD could experience just one episode or have continuous symptoms. It usually reoccurs, although some people can remain disease free for years or decades. Most people with Crohn's live a normal lifespan. However, Crohn's disease is associated with a small increase in risk of small bowel and colorectal carcinoma (bowel cancer).\nCrohn's disease can lead to several mechanical complications within the intestines, including obstruction, fistulae, and abscesses. Obstruction typically occurs from strictures or adhesions that narrow the lumen, blocking the passage of the intestinal contents. A fistula can develop between two loops of bowel, between the bowel and bladder, between the bowel and vagina, and between the bowel and skin. Abscesses are walled off concentrations of infection, which can occur in the abdomen or in the perianal area. Crohn's is responsible for 10% of vesicoenteric fistulae, and is the most common cause of ileovesical fistulae.\nCrohn's disease also increases the risk of cancer in the area of inflammation. For example, individuals with Crohn's disease involving the small bowel are at higher risk for small intestinal cancer. Similarly, people with Crohn's colitis have a relative risk of 5.6 for developing colon cancer. Screening for colon cancer with colonoscopy is recommended for anyone who has had Crohn's colitis for at least eight years. Some studies suggest there is a role for chemoprotection in the prevention of colorectal cancer in Crohn's involving the colon; two agents have been suggested, folate and mesalamine preparations. Also, immunomodulators and biologic agents used to treat this disease may promote developing extra-intestinal cancers.\nIndividuals with Crohn's disease are at risk of malnutrition for many reasons, including decreased food intake and malabsorption. The risk increases following resection of the small bowel. Such individuals may require oral supplements to increase their caloric intake, or in severe cases, total parenteral nutrition (TPN). Most people with moderate or severe Crohn's disease are referred to a dietitian for assistance in nutrition.\nThe major significant complications of Crohn's disease include bowel obstruction, abscesses, free perforation and hemorrhage, which in rare cases may be fatal.<ref> <BR>  <BR>  \nCrohn's disease can be problematic during pregnancy, and some medications can cause adverse outcomes for the fetus or mother. Consultation with an obstetrician and gastroenterologist about Crohn's disease and all medications facilitates preventative measures. In some cases, remission occurs during pregnancy. Certain medications can also lower sperm count or otherwise adversely affect a man's fertility.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Prognosis", "sub_heading": "Prognosis", "_id": "88--5---1---1", "title": "Crohn's Disease \u2014 Symptoms, Causes, and Treatment"}
{"qas": [{"question": "Why is Crohn's Disease so common in Europe but not in North America?", "answer": ""}, {"question": "What disease is increasing in the u.s.?", "answer": "Crohn's disease", "ae_score": -0.2185515751560773, "qg_score": null}, {"question": "What disease is increasing in the u.s.?", "answer": "Crohn's disease", "ae_score": -0.2185515751560773, "qg_score": null}], "content": "The percentage of people with Crohn's disease has been determined in Norway and the United States and is similar at 6 to 7.1:100,000. The Crohn's and Colitis Foundation of America cites this number as approx 149:100,000; NIH cites 28 to 199 per 100,000. Crohn's disease is more common in northern countries, and with higher rates still in the northern areas of these countries. The incidence of Crohn's disease is thought to be similar in Europe but lower in Asia and Africa.<ref name=Hiatt/> It also has a higher incidence in Ashkenazi Jews<ref name=Baumgart2012/> and smokers.\nCrohn's disease begins most commonly in people in their teens and 20s, and people in their 50s through to their 70s.<ref name=Baumgart2012/><ref name=emed/> It is rarely diagnosed in early childhood. It usually affects female children more severely than males. However, only slightly more women than men have Crohn's disease. Parents, siblings or children of people with Crohn's disease are 3 to 20 times more likely to develop the disease. Twin studies find that if one has the disease there is a 55% chance the other will too.\nThe incidence of Crohn's disease is increasing in Europe.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "88--6---1---1", "title": "Crohn's Disease in Europe"}
{"qas": [{"question": "How did they figure out how to treat bowel disease?", "answer": ""}, {"question": "Who discovered inflammatory bowel disease in 1913?", "answer": "T. Kennedy Dalziel", "ae_score": -0.12232891412345634, "qg_score": null}, {"question": "Who discovered inflammatory bowel disease in 1913?", "answer": "T. Kennedy Dalziel", "ae_score": -0.12232891412345634, "qg_score": null}], "content": "Inflammatory bowel diseases were described by Giovanni Battista Morgagni (1682\u20131771) and by Scottish physician T. Kennedy Dalziel in 1913.\n''Ileitis terminalis'' was first described by Polish surgeon Antoni Le\u015bniowski in 1904, although it was not conclusively distinguished from intestinal tuberculosis. In Poland, it is still called Le\u015bniowski-Crohn's disease (choroba Le\u015bniowskiego-Crohna). Burrill Bernard Crohn, an American gastroenterologist at New York City's Mount Sinai Hospital, described fourteen cases in 1932, and submitted them to the American Medical Association under the rubric of \"Terminal ileitis: A new clinical entity\". Later that year, he, along with colleagues Leon Ginzburg and Gordon Oppenheimer, published the case series as \"Regional ileitis: a pathologic and clinical entity\". However, due to the precedence of Crohn's name in the alphabet, it later became known in the worldwide literature as Crohn's disease.<ref name=CrohnBB/>", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "History", "sub_heading": "History", "_id": "88--7---1---1", "title": "''Ileitis terminalis'' (Crohn's disease)"}
{"qas": [{"question": "Why is it so hard to eradicate the bacterium that causes Crohn's disease?", "answer": ""}, {"question": "What is an example of an inflammatory bowel disease?", "answer": "Crohn's disease", "ae_score": -0.8290107712486283, "qg_score": null}, {"question": "What is an example of an inflammatory bowel disease?", "answer": "Crohn's disease", "ae_score": -0.8290107712486283, "qg_score": null}], "content": "Some evidence supports the hypothesis that the bacterium ''Mycobacterium avium'' subspecies ''paratuberculosis'' (MAP) is a cause of Crohn\u2019s disease (see also Johne's disease). As a result, researchers are looking at the eradication of MAP as a therapeutic option. Treating MAP using antibiotics has been examined and the results are unclear but tentatively beneficial. Vaccination against MAP is also being studied. An anti-MAP vaccine appears effective in mice and cattle with MAP with no apparent side effects. Trials in human are pending.\nCrohn's is common in parts of the world where helminthic colonisation is rare and uncommon in those areas where most people carry worms. Infections with helminths may alter the autoimmune response that causes the disease. Trials of extracts from the worm ''Trichuris suis'' showed promising results when used in people with IBD. However these trials (TRUST -I & TRUST -II)  failed in Phase 2 clinical trials and were then discontinued after consistent failure in both North America and Europe.\nNumerous preclinical studies demonstrate that activation of the CB1 and CB2 cannabinoid receptors exert biological functions on the gastrointestinal tract. Activation of CB1 and CB2 receptors in animals has shown a strong anti-inflammatory effect. Cannabinoids and/or modulation of the endocannabinoid system is a novel therapeutic means for the treatment of numerous GI disorders, including inflammatory bowel diseases like Crohn's disease. A few small trials have looked at medical cannabis but further evidence is required to determine its usefulness.\nThere is no good evidence that thalidomide or lenalidomide is useful to bring about or maintain remission.", "page_name": "Crohn's disease", "page_id": "Crohn's%20disease", "heading": "Research", "sub_heading": "Research", "_id": "88--8---1---1", "title": "Cannabinoids and endocannabinoids for the treatment of GI disorders"}
{"qas": [{"question": "Where did the term \"junk food\" come from?", "answer": ""}, {"question": "Who came up with the term junk food?", "answer": "Michael F. Jacobson", "ae_score": -0.7643139174107908, "qg_score": null}, {"question": "Who came up with the term junk food?", "answer": "Michael F. Jacobson", "ae_score": -0.7643139174107908, "qg_score": null}], "content": "The term ''junk food'' dates back at least to the early 1950s, although it has been reported that it was coined in 1972 by Michael F. Jacobson of the Center for Science in the Public Interest. In 1952, it appeared in a headline in the Lima, Ohio, ''News'', \"Candy, Cake, 'Junk Foods' Cause Serious Malnutrition\", for a reprint of a 1948 article from the Ogden, Utah, ''Standard-Examiner'', originally headlined, \"Dr. Brady\u2019s Health Column: More Junk Than Food\". In it, Dr. Brady writes, \"What Mrs. H calls 'junk' I call cheat food. That is anything made principally of (1) white flour and or (2) refined white sugar or syrup. For example, white bread, crackers, cake, candy, ice cream soda, chocolate malted, sundaes, sweetened carbonated beverages.\" The term ''cheat food'' can be traced back in newspaper mentions to at least 1916.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Origin of the term", "sub_heading": "Origin of the term", "_id": "89--0---1---1", "title": "''Candy, Cake, ''Junk Food'' Cause Ser"}
{"qas": [{"question": "What is the difference between junk food and healthy food?", "answer": ""}, {"question": "Who wrote the encyclopedia of junk food and fast food?", "answer": "Andrew F. Smith", "ae_score": -0.44336324289453827, "qg_score": null}, {"question": "Who wrote the encyclopedia of junk food and fast food?", "answer": "Andrew F. Smith", "ae_score": -0.44336324289453827, "qg_score": null}], "content": "Andrew F. Smith, in his book, ''Encyclopedia of Junk Food and Fast Food'' defines junk food as \"those commercial products, including candy, bakery goods, ice cream, salty snacks, and soft drinks, which have little or no nutritional value but do have plenty of calories, salt, and fats. While not all fast foods are junk foods, most are. Fast foods are ready-to-eat foods served promptly after ordering. Some fast foods are high in calories and low in nutritional value, while other fast foods, such as salads, may be low in calories and high in nutritional value.\"\nJunk foods have empty calories as the energetic content is not complemented with proteins and lipids required for nutritious alimentation. Fran\u00e7ois Magendie showed by experiment in 1816 that dogs died when fed only sugar. It has been noted that the metabolic cost of processing empty calories drains a body of resources and is debilitating.\nFoods commonly considered junk foods include salted snack foods, gum, candy, sweet desserts, fried fast food, and sugary carbonated beverages. Many foods such as hamburgers, pizza, and tacos can be considered either healthy or junk food depending on their ingredients and preparation methods. The more highly processed items usually fall under the junk food category, including breakfast cereals that are mostly sugar or high-fructose corn syrup and white flour or milled corn.\nEspecially in the case of ethnic foods, a classification as \"junk food\" could be perceived as rather offensive, given that such foods may have been prepared and consumed for centuries and may contain healthy ingredients. In the book, ''Panic Nation: Unpicking the Myths We're Told About Food and Health'', a complementary point is argued: food is food, and if there is no nutritional value, then it isn't a food of any type, \"junk\" or otherwise. Co-editor Vincent Marks explains, \"To label a food as 'junk' is just another way of saying, 'I disapprove of it.' There are bad diets - that is, bad mixtures and quantities of food - but there are no 'bad foods' except those that have become bad through contamination or deterioration.\"", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Definitions", "sub_heading": "Definitions", "_id": "89--1---1---1", "title": "''Junk Food'' Isn't Junk Food"}
{"qas": [{"question": "Why do the poor eat more junk food than the more affluent?", "answer": ""}, {"question": "How much money does fast food make in the us?", "answer": "$160 billion", "ae_score": -0.42961535975282406, "qg_score": null}, {"question": "How much money does fast food make in the us?", "answer": "$160 billion", "ae_score": -0.42961535975282406, "qg_score": null}], "content": "Junk food in its various forms is extremely popular, and an integral part of modern popular culture. In the US, annual fast food sales are in the area of $160 billion, compared to supermarket sales of $620 billion (a figure which also includes junk food in the form of convenience foods, snack foods, and candy). In 1976, \"Junk Food Junkie\", the tale of a junk food addict who pretends to follow a healthy diet by day, while at night he clandestinely gorges on Hostess Twinkies and Fritos corn chips, McDonalds and KFC, became a Top 10 pop hit in the US. Thirty-six years later, ''Time'' placed the Twinkie at #1 in its \"Top 10 Iconic Junk Foods\" special feature: \"Not only...a mainstay on our supermarket shelves and in our bellies, they've been a staple in our popular culture and, above all, in our hearts. Often criticized for its lack of any nutritional value whatsoever, the Twinkie has managed to persevere as a cultural and gastronomical icon.\"\nAmerica also celebrates an annual National Junk Food Day on July 21. Origins are unclear; it is one of around 175 US food and drink days, most created by \"people who want to sell more food\", at times aided by elected officials at the request of a trade association or commodity group. \"In honor of the day,\" ''Time'' in 2014 published, \"5 Crazy Junk Food Combinations\". Headlines from other national and local media coverage include: \"Celebrate National Junk Food Day With\u2026 Beer-Flavored Oreos?\" (MTV); \"National Junk Food Day: Pick your favorite unhealthy treats in this poll\" (Baltimore); \"Celebrities' favorite junk food\" (Los Angeles); \"A Nutritionist's Guide to National Junk Food Day\" with \"Rules for Splurging\" (''Huffington Post''); and \"It's National Junk Food Day: Got snacks?\" (Kansas City).\nThat the poor eat more junk food overall than the more affluent is quite well-established, but the reasons for this are not clear. Few studies have focused on variations in food perception according to socio-economic status (SES); some studies that have differentiated based on SES suggest that the economically challenged don't perceive healthy food much differently than any other segment of the population. Recent research into scarcity, combining behavioral science and economics, suggests that, faced with extreme economic uncertainty, where even the next meal may not be a sure thing, judgment is impaired and the drive is to the instant gratification of junk food, rather than to making the necessary investment in the longer-term benefits of a healthier diet.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Popularity and appeal", "sub_heading": "Popularity and appeal", "_id": "89--2---1---1", "title": "National Junk Food Day \u2014 A History of Junk Food in America"}
{"qas": [{"question": "Why is junk food bad for you?", "answer": ""}, {"question": "How long did it take for rats to stop eating junk food?", "answer": "two weeks", "ae_score": -0.5613357816550485, "qg_score": null}, {"question": "How long did it take for rats to stop eating junk food?", "answer": "two weeks", "ae_score": -0.5613357816550485, "qg_score": null}], "content": "When junk food is consumed very often, the excess fat, carbohydrates, and processed sugar found in junk food contributes to an increased risk of obesity, cardiovascular disease, diabetes, weight gain, and many other chronic health conditions. Also consumers tend to eat too much at one sitting and consumers who have satisfied their appetite with junk food are less likely to eat healthy foods like fruit, vegetables or dairy products. Studies reveal that as early as the age of 30, arteries could begin clogging and lay the groundwork for future heart attacks.\nTesting on rats has indicated negative effects of junk food that may manifest likewise in people. A Scripps Research Institute study in 2008 suggested that junk food consumption alters brain activity in a manner similar to addictive drugs like cocaine and heroin. After many weeks with unlimited access to junk food, the pleasure centers of rat brains became desensitized, requiring more food for pleasure; after the junk food was taken away and replaced with a healthy diet, the rats starved for two weeks instead of eating nutritious fare. A 2007 study in the ''British Journal of Nutrition'' found that female rats who eat junk food during pregnancy increased the likelihood of unhealthy eating habits in their offspring.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Health effects", "sub_heading": "Health effects", "_id": "89--3---1---1", "title": "Why Junk Food Is Bad for Your Health"}
{"qas": [{"question": "Why is junk food so expensive?", "answer": ""}, {"question": "Which country introduced the world's first fat-food tax in october 2011?", "answer": "Denmark", "ae_score": -0.7044928715873453, "qg_score": null}, {"question": "Which country introduced the world's first fat-food tax in october 2011?", "answer": "Denmark", "ae_score": -0.7044928715873453, "qg_score": null}], "content": "In an attempt to reduce junk food consumption through price control, forms of Pigovian taxation have been implemented. Targeting saturated fat consumption, Denmark introduced the world's first fat-food tax in October, 2011, by imposing a surcharge on all foods, including those made from natural ingredients, that contain more than 2.3 percent saturated fat, an unpopular measure that lasted a little over a year. Hungary has also imposed a tax on packaged foods that contain unhealthy concentrations, such as beverages containing more than 20 mg of caffeine per 100 ml. Norway taxes refined sugar, and Mexico has various excises on unhealthy food. On April 1, 2015, the first fat tax in the US, the Navajo Nation's Healthy Din\u00e9 Nation Act of 2014, mandating a 2% junk food tax, came into effect, covering the 27,000 sq. mi. of Navajo reservation; the Act targeted problems with obesity and diabetes among the Navajo population.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Anti-junk food measures", "sub_heading": "Anti-junk food measures", "_id": "89--4--0---1", "title": "Pigovian Taxation in the US"}
{"qas": [{"question": "Why is there so much controversy over junk food in cricket?", "answer": ""}, {"question": "What type of food is targeted at children?", "answer": "Junk food", "ae_score": -0.5193413711889464, "qg_score": null}, {"question": "What type of food is targeted at children?", "answer": "Junk food", "ae_score": -0.5193413711889464, "qg_score": null}], "content": "Junk food that is targeted at children is a contentious issue. In \"The Impact of Advertising on Childhood Obesity\", the American Psychological Association reports: \"Research has found strong associations between increases in advertising for non-nutritious foods and rates of childhood obesity.\" In the UK, efforts to increasingly limit or eliminate advertising of foods high in sugar, salt or fat at any time when children may be viewing are ongoing.\nControversy over junk food promotions during Australian cricket matches was reported in the news media in early 2015. A Wollongong University study showed that junk food sponsors were mentioned over 1,000 times in a single match broadcast, which included ads and branding worn on players' uniforms and on the scoreboard and pitch. A coalition of Australian obesity, cancer and diabetes organizations called on Cricket Australia, the sport's governing body, to \"phase out sponsorships with unhealthy brands\", emphasizing that cricket is a \"healthy, family-oriented sport\" with children in the audience.many countries have restricted advertising of junk food.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Anti-junk food measures", "sub_heading": "Advertising restriction", "_id": "89--4--1---1", "title": "The Impact of Advertising on Childhood Obesity is a Controversy"}
{"qas": [{"question": "Is junk food bad for you?", "answer": ""}, {"question": "At what age were 4000 children given the strengths and difficulties questionnaire?", "answer": "seven", "ae_score": -0.6899639126378709, "qg_score": null}, {"question": "At what age were 4000 children given the strengths and difficulties questionnaire?", "answer": "seven", "ae_score": -0.6899639126378709, "qg_score": null}], "content": "In a study by the European Journal of Clinical Nutrition, the frequency of consumption of 57 foods/drinks of 4000 children at the age of four and a half were collected by maternal report. At age seven the 4000 children were given the Strengths and Difficulties Questionnaire (SDQ). The test was divided into 5 sections: Hyperactivity, peer problems, emotional symptoms and pro-social behavior. A one standard deviation increase in junk food was then linked to excessive hyperactivity in 33% of the 4000 children. In conclusion, children with excess junk food at four and a half are more likely to be in the top third of the hyperactivity sub-scale; however, there is not enough correlation between junk food and the other sub-scales such as emotional symptoms and peer problems.", "page_name": "Junk food", "page_id": "Junk%20food", "heading": "Behavior problems", "sub_heading": "Behavior problems", "_id": "89--5---1---1", "title": "Emotional symptoms and pro-social behavior in children with excess junk food at four and "}
{"qas": [{"question": "Why do so many people work in the informal sector?", "answer": ""}, {"question": "What are the two most prevalent types of workers in the informal economy?", "answer": "street vendors", "ae_score": -0.33003546918156135, "qg_score": null}, {"question": "What are the two most prevalent types of workers in the informal economy?", "answer": "street vendors", "ae_score": -0.33003546918156135, "qg_score": null}], "content": "The informal sector is largely characterized by several qualities: easy entry, meaning anyone who wishes to join the sector can find some sort of work which will result in cash earnings, a lack of stable employer-employee relationships, a small scale of operations, and skills gained outside of a formal education. Workers who participate in the informal economy are typically classified as employed. The type of work that makes up the informal economy is diverse, particularly in terms of capital invested, technology used, and income generated. The spectrum ranges from self-employment or unpaid family labor to street vendors, shoe shiners, and junk collectors. On the higher end of the spectrum are upper-tier informal activities such as small-scale service or manufacturing businesses, which have more limited entry. The upper-tier informal activities have higher set-up costs, which might include complicated licensing regulations, and irregular hours of operation. However, most workers in the informal sector, even those are self-employed or wage workers, do not have access to secure work, benefits, welfare protection, or representation. These features differ from businesses and employees in the formal sector which have regular hours of operation, a regular location and other structured benefits.\nThe most prevalent types of work in the informal economy are home-based workers and street vendors. Home-based workers are more numerous while street vendors are more visible. Combined, the two fields make up about 10\u201315% of the non-agricultural workforce in developing countries and over 5% of the workforce in developed countries.\nWhile participation in the informal sector can be stigmatized, many workers engage in informal ventures by choice, for either economic or non-economic reasons. Economic motivations include the ability to evade taxes, the freedom to circumvent regulations and licensing requirements, and the capacity to maintain certain government benefits. A study of informal workers in Costa Rica illustrated other economic reasons for staying in the informal sector, as well as non-economic factors. First, they felt they would earn more money through their informal sector work than at a job in the formal economy. Second, even if workers made less money, working in the informal sector offered them more independence, the chance to select their own hours, the opportunity to work outside and near friends, etc. While jobs in the formal economy might bring more security and regularity, or even pay better, the combination of monetary and psychological rewards from working in the informal sector proves appealing for many workers.\nThe informal sector was historically recognized as an opposition to formal economy, meaning it included all income earning activities beyond legally regulated enterprises. However, this understanding is too inclusive and vague, and certain activities that could be included by that definition are not considered part of the informal economy. As the International Labour Organization defined the informal sector in 2002, the informal sector does not include the criminal economy. While production or employment arrangements in the informal economy may not be strictly legal, the sector produces and distributes legal goods and services. The criminal economy produces illegal goods and services.  The informal economy also does not include the reproductive or care economy, which is made up of unpaid domestic work and care activities. The informal economy is part of the market economy, meaning it produces goods and services for sale and profit. Unpaid domestic work and care activities do not contribute to that, and as a result, are not a part of the informal economy.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Definition", "sub_heading": "Definition", "_id": "90--0--0---1", "title": "What is the informal economy?"}
{"qas": [{"question": "What is an informal economy?", "answer": ""}, {"question": "Who wrote the book on the informal economy?", "answer": "Mario Vargas Llosa", "ae_score": -0.2943329144883922, "qg_score": null}, {"question": "Who wrote the book on the informal economy?", "answer": "Mario Vargas Llosa", "ae_score": -0.2943329144883922, "qg_score": null}], "content": "Governments have tried to regulate aspects of their economies for as long as surplus wealth has existed which is at least as early as Sumer. Yet no such regulation has ever been wholly enforceable. Archaeological and anthropological evidence strongly suggests that people of all societies regularly adjust their activity within economic systems in attempt to evade regulations. Therefore, if informal economic activity is that which goes unregulated in an otherwise regulated system then informal economies are as old as their formal counterparts, if not older. The term itself, however, is much more recent. The optimism of the modernization theory school of development had led most people in the 1950s and 1960s to believe that traditional forms of work and production would disappear as a result of economic progress in developing countries. As this optimism proved to be unfounded, scholars turned to study more closely what was then called the traditional sector. They found that the sector had not only persisted, but in fact expanded to encompass new developments. In accepting that these forms of productions were there to stay, scholars and some international organizations quickly took up the term informal sector (later known as the informal economy or just informality), which is credited to the British anthropologist Keith Hart in a 1971 study on Ghana published in 1973, and was coined by the International Labour Organization in a widely read study on Kenya in 1972.\nIn \u201cThe Underground Economies: Tax Evasion and Information Distortion\u201d Edgar L. Feige examined the economic implications of a shift of economic activity from the observed to the non-observed sector of the economy. Such a shift not only reduces the government\u2019s ability to collect revenues, it can also bias the nation\u2019s information systems and therefore lead to misguided policy decisions. The book examines alternative means of estimating the size of various unobserved economies and examines their consequences in both socialist and market oriented economies. Feige goes on to develop a taxonomic framework that clarifies the distinctions between informal, illegal, unreported and unrecorded economies, and identifies their conceptual and empirical linkages and the alternative means of measuring their size and trends. Since then the informal sector has become an increasingly popular subject of investigation, not just in economics, but also in sociology, anthropology and urban planning. With the turn towards so called post-fordist modes of production in the advanced developing countries, many workers were forced out of their formal sector work and into informal employment. In a seminal collection of articles, ''The Informal Economy. Studies in Advanced and Less Developed Countries'', Alejandro Portes and collaborators emphasized the existence of an informal economy in all countries by including case studies ranging from New York City and Madrid to Uruguay and Colombia.\nArguably one of the more influential books on the informal economy is Hernando de Soto's ''El otro sendero'' (1986), which was published in English in 1989 as ''The Other Path'' with a preface by Peruvian writer Mario Vargas Llosa.  De Soto and his team argue that excessive regulation in the Peruvian (and other Latin American) economies force a large part of the economy into informality and thus prevent economic development. While accusing the ruling class of 20th century mercantilism, de Soto admires the entrepreneurial spirit of the informal economy. In a widely cited experiment, his team tried to legally register a small garment factory in Lima. This took more than 100 administrative steps and almost a year of full-time work. Feige's review of the Other Path places the work in the context of the informal economy literature.  Whereas de Soto's work is popular with policymakers and champions of free market policies like ''The Economist'', some scholars of the informal economy have criticized it both for methodological flaws and normative bias.\nIn the second half of the 1990s many scholars have started to consciously use the term \"informal economy\" instead of \"informal sector\" to refer to a broader concept that includes enterprises as well as employment in developing, transition, and advanced industrialized economies.\nAmong the surveys about the size and development of the shadow economy (mostly expressed in percent of official GDP) are those by Feige (1989), and Schneider and Enste (2000). In these surveys an intensive discussion about the various estimation procedures of the size of the shadow economy as well as a critical evaluation of the size of the shadow economy and the consequences of the shadow economy on the official one can be found. The most recent survey paper on the subject reviews the meaning and measurement of unobserved economies and is particularly critical of estimates of the size of the so-called \u201cshadow economy\u201d that employ Multiple Indicator multiple cause methods which treat the shadow economy as a latent variable.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "History", "sub_heading": "History", "_id": "90--1---1---1", "title": "The Informal Economy"}
{"qas": [{"question": "How do people estimate the size and development of a shadow economy?", "answer": ""}, {"question": "Who is credited with the development of the shadow economy?", "answer": "Friedrich Schneider", "ae_score": -1.2894750178173762, "qg_score": null}, {"question": "Who is credited with the development of the shadow economy?", "answer": "Friedrich Schneider", "ae_score": -1.2894750178173762, "qg_score": null}], "content": "To estimate the size and development of any underground or shadow economy is quite a challenging task since participants in such economies attempt to hide their behaviors.  One must also be very careful to distinguish whether one is attempting to measure the unreported economy, normally associated with tax evasion,  or the unrecorded or non observed economy, associated with the amount of income that is readily excluded from national income and produce accounts due to the difficulty of measurement.There are numerous estimates of tax noncompliance as measured by tax gaps produced by audit methods or by \u201ctop down\u201d methods Friedrich Schneider and several co-authors claim to have estimated the size and trend of what they call the \u201cshadow economy\u201d worldwide by a currency demand /MIMIC model approach that treats the \u201cshadow economy\u201d as a latent variable.Trevor S. Breusch has critiqued this work warning the profession that\u201d The literature applying this model to the underground economyabounds with alarming Procrustean tendencies. Various kinds of sliding and scaling of the results are carried out in the name of \u201cbenchmarking\u201d, although these operations are not always clearlydocumented. The data are typically transformed in ways that are not only undeclared but have the unfortunate effect of making the results of the study sensitive to the units in which the variables are measured.The complexity of the estimation procedure, together with its deficient documentation, leave the reader unaware of how these results have been shorted to fit the bed of prior belief. There are manyother results in circulation for various countries, for which the data cannot be identified and which are given no more documentation than \u201cown calculations by the MIMIC method\u201d. Readers are advised toadjust their valuation of these estimates accordingly. Edgar L. Feige finds that Schneider\u2019s Shadow economy \u201cestimates suffer from conceptual flaws, apparent manipulation of results and insufficient documentation for replication, questioning their place in the academic, policy and popular literature.\u201d", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Statistics", "sub_heading": "Statistics", "_id": "90--2--0---1", "title": "The Shadow Economy"}
{"qas": [{"question": "How can a country have a shadow economy?", "answer": ""}, {"question": "What percentage of the gdp does the shadow economy produce?", "answer": "8%", "ae_score": -0.2553601048143577, "qg_score": null}, {"question": "What percentage of the gdp does the shadow economy produce?", "answer": "8%", "ae_score": -0.2553601048143577, "qg_score": null}], "content": "Since the establishment of the Single Market (Maastricht 1993) the total EU shadow economy has been growing systematically to approx. 1.9 trillions \u20ac in preparation of the EURO driven by the motor of the European shadow economy, Germany, which has been generating approx. 350 bn \u20ac per annum since then (see also diagram on the right). Hence, the EU financial economy has developed parallel an efficient tax haven bank system to protect and manage its growing shadow economy. As per the Financial Secrecy Index (FSI 2013) currently Germany and some neighbouring countries, range among the world's top tax haven countries.\nThe diagram below clearly shows that national informal economies per capita vary only moderately in most EU countries. It is because market sectors with high informal part (above 45%) like \"building and construction\" or \"agriculture\" are rather homogeneously distributed over the countries, whereas sectors with low informal part (below 30%)<ref name=FS/> like \"financial and business\" (in Switzerland, Luxembourg), \"public and personal services\" (in Scandinavian countries) as well as \"retail, wholesale and repair\" are dominant in countries with extremely high GDP per capita i.e. industrially highly developed countries. The diagram also shows that in absolute numbers the shadow economy per capita is related to the wealth of a society (GDP). Generally spoken, the higher GDP the higher shadow economy, albeit non-proportional.\nThere is a direct relation between high self-employment of a country to its above average shadow economy. In highly industrialized countries where shadow economy (per capita) is high and the huge private sector is shared by an extremely small elite of entrepreneurs a considerable part of tax evasion is practised by a much smaller number of (elite) people. As an example German shadow economy in 2013 was 4.400 \u20ac per capita, which was the 9th highest place in EU, whereas according to OECD only 11.2% of employed people were self-employed (place 18). On the other hand, Greece's shadow economy was only 3.900 \u20ac p.c (place 13) but self-employment was 36.9% (place 1)\nAn extreme example of shadow economy camouflaged by the financial market is Luxembourg where the relative annual shadow economy is only 8% of the GDP which is the second lowest percentage (2013) of all EU countries whereas its absolute size (6.800 \u20ac per capita) is the highest.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Statistics", "sub_heading": "Comparison of shadow economies in EU countries according to estimates by Friedrich Schneider", "_id": "90--2--1---1", "title": "EU shadow economy per capita vs GDP per capita"}
{"qas": [{"question": "Why are there so few women in the informal sector of the economy?", "answer": ""}, {"question": "What are the informal jobs in india?", "answer": "street vendors", "ae_score": -0.5620839509160481, "qg_score": null}, {"question": "What are the informal jobs in india?", "answer": "street vendors", "ae_score": -0.5620839509160481, "qg_score": null}], "content": "Women tend to make up the greatest portion of the informal sector, often ending up in the most erratic and corrupt segments of the sector. In developing countries,  most of the female non-agricultural labor force is in the informal sector. Major occupations in the informal sector include home-based workers (such as dependent subcontract workers, independent own account producers, and unpaid workers in family businesses) and street vendors, which both are classified in the informal sector. In India, women working in the informal sector often work as ragpickers, domestic workers, coolies, vendors, beauticians, construction laborers, and garment workers.\nFemale representation in the informal sector is attributed to a variety of factors. One such factor is the fact that employment in the informal sector is the source of employment that is most readily available to women. A 2011 study of poverty in Bangladesh noted that cultural norms, religious seclusion, and illiteracy among women in many developing countries, along with a greater commitment to family responsibilities, prevent women from entering the formal sector.\nAccording to a 2002 study commissioned by the ILO, the connection between employment in the informal economy and being poor is stronger for women than men. While men tend to be overrepresented in the top segment of the informal sector, women overpopulate the bottom segment. Men are more likely to have larger scale operations and deal in non-perishable items while few women are employers who hire others. Instead, women are more likely to be involved in smaller scale operations and trade food items. Women are under-represented in higher income employment positions in the informal economy and over-represented in lower income statuses. As a result, the gender gap in terms of wage is even higher in the informal sector than the formal sector. Labor markets, household decisions, and states all propagate this gender inequality.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Social and political implications and issues", "sub_heading": "Social and political implications and issues", "_id": "90--3--0---1", "title": "Women in the Non-Agricultural Sector"}
{"qas": [{"question": "Why is the informal economy such a bad thing?", "answer": ""}, {"question": "What do informal workers lack a significant voice in?", "answer": "government policy", "ae_score": -2.027232688435643, "qg_score": null}, {"question": "What do informal workers lack a significant voice in?", "answer": "government policy", "ae_score": -2.027232688435643, "qg_score": null}], "content": "Workers in the informal economy lack a significant voice in government policy. Not only is the political power of informal workers limited, but the existence of the informal economy creates challenges for other politically influential actors. For example, the informal workforce is not a part of any trade union, nor does there seem a push or inclination to change that status. Yet the informal economy negatively affects membership and investment in the trade unions. Laborers who might be formally employed and join a union for protection may choose to branch out on their own instead. As a result, trade unions are inclined to oppose the informal sector, highlighting the costs and disadvantages of the system. Producers in the formal sector can similarly feel threatened by the informal economy. The flexibility of production, low labor and production costs, and bureaucratic freedom of the informal economy can be seen as consequential competition for formal producers, leading them to challenge and object to that sector. Last, the nature of the informal economy is largely anti-regulation and free of standard taxes, which diminishes the material and political power of government agents.  Whatever the significance of these concerns are, the informal sector can shift political power and energies.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Social and political implications and issues", "sub_heading": "Political power of agents", "_id": "90--3--1---1", "title": "The Politics of the Informal Economy"}
{"qas": [{"question": "What is the relationship between the informal sector and poverty?", "answer": ""}, {"question": "Where is the informal sector of the economy located?", "answer": "Europe", "ae_score": null, "qg_score": null}, {"question": "Where is the informal sector of the economy located?", "answer": "Europe", "ae_score": null, "qg_score": null}], "content": "The relationship between the informal sectors and poverty certainly is not simple nor does a clear, causal relationship exist. An inverse relationship between an increased informal sector and slower economic growth has been observed though. Average incomes are substantially lower in the informal economy and there is a higher preponderance of impoverished employees working in the informal sector. In addition, workers in the informal economy are less likely to benefit from employment benefits and social protection programs. For instance, a survey in Europe shows that the respondents who have difficulties to pay their household bills have worked informally more often in the past year than those that do not (10% versus 3% of the respondents).", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Social and political implications and issues", "sub_heading": "Poverty", "_id": "90--3--2---1", "title": "The Inequality of Work in the Informal Sector"}
{"qas": [{"question": "Why do so many children work as domestic servants?", "answer": ""}, {"question": "Who considers child domestic work to be among the lowest status?", "answer": "UNICEF", "ae_score": -1.2898623617946388, "qg_score": null}, {"question": "Who considers child domestic work to be among the lowest status?", "answer": "UNICEF", "ae_score": -1.2898623617946388, "qg_score": null}], "content": "Children work in the informal economy in many parts of the world. They often work as scavengers (collecting recyclables from the streets and dump sites), day laborers, cleaners, construction workers, vendors, in seasonal activities, domestic workers, and in small workshops; and often work under hazardous and exploitative conditions. It is common for children to work as domestic servants across Latin America and parts of Asia. Such children are very vulnerable to exploitation: often they are not allowed to take breaks or are required to work long hours; many suffer from a lack of access to education, which can contribute to social isolation and a lack of future opportunity. UNICEF considers domestic work to be among the lowest status, and reports that most child domestic workers are live-in workers and are under the round-the-clock control of their employers. Some estimates suggest that among girls, domestic work is the most common form of employment.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Social and political implications and issues", "sub_heading": "Children and child labour", "_id": "90--3--3---1", "title": "Child Domestic Workers in Latin America and Asia"}
{"qas": [{"question": "Why is the unorganized sector of the economy so much more talked about in Marxian economics than the organised sector?", "answer": ""}, {"question": "When did the informal sector start to expand?", "answer": "1960s", "ae_score": -0.5419289716465786, "qg_score": null}, {"question": "When did the informal sector start to expand?", "answer": "1960s", "ae_score": -0.5419289716465786, "qg_score": null}], "content": "The division of the economy into formal and informal sectors has a long heritage. Arthur Lewis in his seminal work ''Economic Development with Unlimited Supply of Labour'', published in the 1950s, was the celebrated paradigm of development for the newly independent countries in the 1950s and 1960s. The model assumed that the unorganized sector with the surplus labour will gradually disappear as the surplus labour gets absorbed in the organised sector. The Lewis model is drawn from the experience of capitalist countries in which the share of agriculture and unorganized sector showed a spectacular decline, but it didn't prove to be true in many developing countries, including India. On the other hand, probabilistic migration models developed by Harris and Todaro in the 1970s envisaged the phenomenon of the informal sector as a transitional phase through which migrants move to the urban centers before shifting to formal sector employment. Hence it is not a surprise to see policy invisibility in the informal sector. Curiously, the informal sector does not find a permanent place in the Marxian theory since they anticipate the destruction of the pre-capitalist structure as a result of the aggressive growth of capitalism. To them, in the course of development, \u2018the small fish is being eaten by the big fish\u2019. Therefore, neither in the Marxian theory nor in the classical economic theory, the unorganized sector holds a permanent place in the economic literature.\nThe informal sector has been expanding as more economies have started to liberalize.This pattern of expansion began in the 1960s when a lot of developing countries didn't create enough formal jobs in their economic development plans, which led to the formation of an informal sector that didn't solely include marginal work and actually contained profitable opportunities. In the 1980s, the sector grew alongside formal industrial sectors. In the 1990s, an increase in global communication and competition led to a restructuring of production and distribution, often relying more heavily on the informal sector.\nOver the past decade, the informal economy is said to account for more than half of the newly created jobs in Latin America. In Africa it accounts for around eighty percent. Many explanations exist as to why the informal sector has been expanding in the developing world throughout the past few decades. It is possible that the kind of development that has been occurring has failed to support the increased labor force in a formal manner. Expansion can also be explained by the increased subcontracting due to globalization and economic liberalization. Finally, employers could be turning toward the informal sector to lower costs and cope with increased competition. \nSuch extreme competition between industrial countries occurred after the expansion of the EC to markets of the then new member countries Greece, Spain and Portugal, and particularly after the establishment of the Single European Market (1993, Treaty of Maastricht). Mainly for French and German corporations it led to systematic increase of their informal sectors under liberalized tax laws, thus fostering their mutual competitiveness and against small local competitors. The continuous systematic increase of the German informal sector was stopped only after the establishment of the EURO and the execution of the Summer Olympic Games 2004, which has been the first and (up to now) only in the Single Market. Since then the German informal sector stabilized on the achieved 350 bn \u20ac level which signifies an extremely high tax evasion for a country with 90% salary-employment.\nAccording to the Swedish International Development Cooperation Agency (SIDA), the key drivers for the growth of the informal economy in the twenty-first century include:\nHistorically, development theories have asserted that as economies mature and develop, economic activity will shift from the informal to the formal sphere. In fact, much of the economic development discourse is centered around the notion that formalization indicates how developed a country's economy is; for more on this discussion see the page on fiscal capacity.  However, evidence suggests that the progression from informal to formal sectors is not universally applicable. While the characteristics of a formalized economy \u2013 full employment and an extensive welfare system \u2013 have served as effective methods of organizing work and welfare for some nations, such a structure is not necessarily inevitable or ideal. Indeed, development appears to be heterogeneous in different localities, regions, and nations, as well as the type of work practiced. For example, at one end of the spectrum of the type of work practiced in the informal economy are small-scale businesses and manufacturing; on the other \"street vendors, shoe shiners, junk collectors and domestic servants.\" Regardless of how the informal economy develops, its continued growth that it cannot be considered a temporary phenomenon.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Expansion and growth", "sub_heading": "Expansion and growth", "_id": "90--4---1---1", "title": "The Unorganized Sector in the Twenty-first Century"}
{"qas": [{"question": "Why is the informal sector of the economy so stigmatized?", "answer": ""}, {"question": "When was the informal economy introduced in europe?", "answer": "2004", "ae_score": -0.4490568158828922, "qg_score": null}, {"question": "When was the informal economy introduced in europe?", "answer": "2004", "ae_score": -0.4490568158828922, "qg_score": null}], "content": "As it has been historically stigmatized, policy perspectives viewed the informal sector as disruptive to the national economy and a hindrance to development. The justifications for such criticisms include viewing the informal economy as a fraudulent activity that results in a loss of revenue from taxes, weakens unions, creates unfair competition, leads to a loss of regulatory control on the government's part, reduces observance of health and safety standards, and reduces the availability of employment benefits and rights. These characteristics have led to many nations pursuing a policy of deterrence with strict regulation and punitive procedures.\nIn a 2004 report, the Department for Infrastructure and Economic Cooperation under SIDA explained three perspectives on the role of government and policy in relation to the informal economy. \nAs informal economy has significant job creation and income generation potential, as well as the capacity to meet the needs of poor consumers by providing cheaper and more accessible goods and services, many stakeholders subscribe to the third perspective and support government intervention and accommodation.  Embedded in the third perspective is the significant expectation that governments will revise policies that have favored the formal sphere at the expense of the informal sector.\nTheories of how to accommodate the informal economy argue for government policies that, recognizing the value and importance of the informal sector, regulate and restrict when necessary but generally work to improve working conditions and increase efficiency and production.\nThe challenge for policy interventions is that so many different types of informal work exist; a solution would have to provide for a diverse range of circumstances. A possible strategy would be to provide better protections and benefits to informal sector players. However, such programs could lead to a disconnect between the labor market and protections, which would not actually improve informal employment conditions. In a 2014 report monitoring street vending, WIEGO suggested urban planners and local economic development strategists study the carrying capacity of areas regularly used by informal workers and deliver the urban infrastructure necessary to support the informal economy, including running water and toilets, street lights and regular electricity, and adequate shelter and storage facilities. That study also called for basic legal rights and protections for informal workers, such as appropriate licensing and permit practices.\nAn ongoing policy debate considers the value of government tax breaks for household services such cleaning, babysitting and home maintenance, with an aim to reduce the shadow economy's impact.  There are currently systems in place in Sweden and France which offer 50 percent tax breaks for home cleaning services. There has also been debate in the UK about introducing a similar scheme, with potentially large savings for middle-class families and greater incentive for women to return to work after having children. The European Union has used political measures to try and curb the shadow economy. Although no definitive solution has been established to date, the EU council has led dialogue on a platform that would combat undeclared work.", "page_name": "Informal sector", "page_id": "Informal%20sector", "heading": "Policy suggestions", "sub_heading": "Policy suggestions", "_id": "90--5---1---1", "title": "The Shadow Economy and the Politics of Government"}
{"qas": [{"question": "Why is it unsafe to charge all reagents and mix in a nuclear reactor?", "answer": ""}, {"question": "What is it called when a reactor has insufficient mixing?", "answer": "Thermal runaway", "ae_score": -0.3876267358776293, "qg_score": null}, {"question": "What is it called when a reactor has insufficient mixing?", "answer": "Thermal runaway", "ae_score": -0.3876267358776293, "qg_score": null}], "content": "In chemical engineering, thermal runaway is also called '''thermal explosion''', that is a process by which an exothermic reaction goes out of control, often resulting in an explosion.  It is also known as a '''runaway reaction''' in organic chemistry.\nThermal explosion occurs when the reaction rate increases due to an increase in temperature, causing a further increase in temperature and hence a further rapid increase in the reaction rate. It has contributed to industrial chemical accidents, most notably the 1947 Texas City disaster from overheated ammonium nitrate in a ship's hold, and the disastrous release of a large volume of methyl isocyanate gas from a Union Carbide plant in Bhopal, India in 1984.\nMost chemical reactions produce some heat, so many industrial-scale and oil refinery processes have some level of risk of thermal runaway. These include hydrocracking, hydrogenation, alkylation (S2), oxidation, metalation and nucleophilic aromatic substitution. For example, oxidation of cyclohexane into cyclohexanol and cyclohexanone and ortho-xylene into phthalic anhydride have led to catastrophic explosions when reaction control failed.\nThermal runaway may result from unwanted exothermic side reaction(s) that begin at higher temperatures, following an initial accidental overheating of the reaction mixture. This scenario was behind the Seveso disaster, where thermal runaway heated a reaction to temperatures such that in addition to the intended 2,4,5-trichlorophenol, poisonous 2,3,7,8-tetrachlorodibenzo-p-dioxin was also produced, and was vented into the environment after the reactor's rupture disk burst.\nThermal runaway is most often caused by failure of the reactor vessel's cooling system. Failure of the mixer can result in localized heating, which initiates thermal runaway. Similarly, in flow reactors, localized insufficient mixing causes hotspots to form, wherein thermal runaway conditions occur, which causes violent blowouts of reactor contents and catalysts. Incorrect equipment component installation is also a common cause. Many chemical production facilities are designed with high-volume emergency venting, a measure to limit the extent of injury and property damage when such accidents occur.\nAt large scale, it is unsafe to \"charge all reagents and mix\", as is done in laboratory scale. This is because the amount of reaction scales with the cube of the size of the vessel (V \u221d r\u00b3), but the heat transfer area scales with the square of the size (A \u221d r\u00b2), so that the heat production-to-area ratio scales with the size (V/A \u221d r). Consequently, reactions that easily cool fast enough in the laboratory can dangerously self-heat at ton scale. In 2007, this kind of erroneous procedure caused an explosion of a 2400 gal-reactor used to metalate methylcyclopentadiene with metallic sodium, causing the loss of four lives and parts of the reactor being flung 400 ft away. Thus, industrial scale reactions prone to thermal runaway are preferably controlled by the addition of one reagent at a rate corresponding to the available cooling capacity.\nSome laboratory reactions must be run under extreme cooling, because they are very prone to hazardous thermal runaway. For example, in Swern oxidation, the formation of  sulfonium chloride must be performed in a cooled system (\u201330 \u00b0C), because at room temperature the reaction undergoes explosive thermal runaway.\nThe UK Chemical Reaction Hazards Forum publishes analysis of previously-unreported chemical accidents to assist the education of the scientific and engineering community, with the aim of preventing similar occurrences elsewhere.  Almost 150 such reports are available to view as of January 2009.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Chemical engineering", "sub_heading": "Chemical engineering", "_id": "91--0---1---1", "title": "Thermal runaway in chemical reactions"}
{"qas": [{"question": "Why do some materials heat up faster in the microwave than others?", "answer": ""}, {"question": "What is it called when a material gets exposed to microwaves?", "answer": "thermal runaway materials", "ae_score": -0.485503286043175, "qg_score": null}, {"question": "What is it called when a material gets exposed to microwaves?", "answer": "thermal runaway materials", "ae_score": -0.485503286043175, "qg_score": null}], "content": "Microwaves are used for heating of various materials in cooking and various industrial processes. The rate of heating of the material depends on the energy absorption, which depends on the dielectric constant of the material. The dependence of dielectric constant on temperature varies for different materials; some materials display significant increase with increasing temperature. This behavior, when the material gets exposed to microwaves, leads to selective local overheating, as the warmer areas are better able to accept further energy than the colder areas\u2014potentially dangerous especially for thermal insulators, where the heat exchange between the hot spots and the rest of the material is slow. These materials are called ''thermal runaway materials''. This phenomenon occurs in some ceramics.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Microwave heating", "sub_heading": "Microwave heating", "_id": "91--1---1---1", "title": "Microwaves are used for heating of various materials in cooking and various industrial processes"}
{"qas": [{"question": "Why does silicon heat up?", "answer": ""}, {"question": "What is the temperature of silicon when it reaches its melting point?", "answer": "160 \u00b0C", "ae_score": -0.8700400264795848, "qg_score": null}, {"question": "What is the temperature of silicon when it reaches its melting point?", "answer": "160 \u00b0C", "ae_score": -0.8700400264795848, "qg_score": null}], "content": "Silicon shows a peculiar profile, in that its electrical resistance increases with temperature up to about 160 \u00b0C, then starts ''decreasing'', and drops further when the melting point is reached. This can lead to thermal runaway phenomena within internal regions of the semiconductor junction; the resistance decreases in the regions which become heated above this threshold, allowing more current to flow through the overheated regions, in turn causing yet more heating in comparison with the surrounding regions, which leads to further temperature increase and resistance decrease. This leads to the phenomenon of current crowding and formation of current filaments (similar to current hogging, but within a single device), and is one of the underlying causes of many semiconductor junction failures.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Electrical engineering", "_id": "91--2--0---1", "title": "Silicon is a conductive material with a high resistance to heat and current"}
{"qas": [{"question": "Why do transistors lose power at room temperature?", "answer": ""}, {"question": "What is it called when a transistor becomes hot?", "answer": "second breakdown", "ae_score": -0.19739200559166972, "qg_score": null}, {"question": "What is it called when a transistor becomes hot?", "answer": "second breakdown", "ae_score": -0.19739200559166972, "qg_score": null}], "content": "Leakage current increases significantly in bipolar transistors (especially germanium-based bipolar transistors) as they increase in temperature. Depending on the design of the circuit, this increase in leakage current can increase the current flowing through a transistor and thus the power dissipation, causing a further increase in collector-to-emitter leakage current. This is frequently seen in a push\u2013pull stage of a class AB amplifier. If the pull-up and pull-down transistors are biased to have minimal crossover distortion at room temperature, and the biasing is not temperature-compensated, then as the temperature rises both transistors will be increasingly biased on, causing current and power to further increase, and eventually destroying one or both devices.\nOne rule of thumb to avoid thermal runaway is to keep the operating point of a BJT so that V \u2264 1/2V\nAnother practice is to mount a thermal feedback sensing transistor or other device on the heat sink, to control the crossover bias voltage. As the output transistors heat up, so does the thermal feedback transistor.  This in turn causes the thermal feedback transistor  to turn on at a slightly lower voltage,  reducing the crossover bias voltage, and so reducing the heat dissipated by the output transistors.\nIf multiple BJT transistors are connected in parallel (which is typical in high current applications), a current hogging problem can occur.  Special measures must be taken to control this characteristic vulnerability of BJTs.\nIn power transistors (which effectively consist of many small transistors in parallel), current hogging can occur between different parts of the transistor itself, with one part of the transistor becoming more hot than the others. This is called second breakdown, and can result in destruction of the transistor even when the average junction temperature seems to be at a safe level.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Bipolar junction transistors (BJTs)", "_id": "91--2--1---1", "title": "How to Avoid Thermal Runaway in Bipolar Transistors"}
{"qas": [{"question": "How do power MOSFETs work?", "answer": ""}, {"question": "What is it called when a mosfet produces more heat than the heatsink can?", "answer": "thermal runaway", "ae_score": -0.8003548753939735, "qg_score": null}, {"question": "What is it called when a mosfet produces more heat than the heatsink can?", "answer": "thermal runaway", "ae_score": -0.8003548753939735, "qg_score": null}], "content": "Power MOSFETs typically increase their on-resistance with temperature. Under some circumstances, power dissipated in this resistance causes more heating of the junction, which further increases the junction temperature, in a positive feedback loop. As a consequence, power MOSFETs have stable and instable regions of operation. However, the increase of on-resistance with temperature helps balance current across multiple MOSFETs connected in parallel, so current hogging does not occur. If a MOSFET transistor produces more heat than the heatsink can dissipate, then thermal runaway can still destroy the transistors. This problem can be alleviated to a degree by lowering the thermal resistance between the transistor die and the heatsink. See also Thermal Design Power.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Power MOSFETs", "_id": "91--2--2---1", "title": "Power MOSFETs \u2014 Thermal Design"}
{"qas": [{"question": "How does fault current work?", "answer": ""}, {"question": "What is it called when a mov has lowered trigger voltage?", "answer": "thermal runaway", "ae_score": -1.9575730626450873, "qg_score": null}, {"question": "What is it called when a mov has lowered trigger voltage?", "answer": "thermal runaway", "ae_score": -1.9575730626450873, "qg_score": null}], "content": "Metal oxide varistors typically develop lower resistance as they heat up.  If connected directly across an AC or DC power bus (a common usage for protection against electrical transients), a MOV which has developed a lowered trigger voltage can slide into catastrophic thermal runaway, possibly culminating in a small explosion or fire.   To prevent this possibility, fault current is typically limited by a thermal fuse, circuit breaker, or other current limiting device.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Metal oxide varistors (MOVs)", "_id": "91--2--3---1", "title": "Metal Oxide Varistors"}
{"qas": [{"question": "Why are tantalum capacitors not used in high-power circuits?", "answer": ""}, {"question": "What is the danger of tantalum capacitors in high power circuits?", "answer": "thermal runaway failures", "ae_score": -0.31238095685685896, "qg_score": null}, {"question": "What is the danger of tantalum capacitors in high power circuits?", "answer": "thermal runaway failures", "ae_score": -0.31238095685685896, "qg_score": null}], "content": "Tantalum capacitors are under some conditions prone to self-destruction by thermal runaway. The capacitor typically consists of a sintered tantalum sponge acting as the anode, a manganese dioxide cathode, and a dielectric layer of tantalum pentoxide created on the tantalum sponge surface by anodizing.  It may happen that the tantalum oxide layer has weak spots that undergo dielectric breakdown during a voltage spike. The tantalum sponge then comes into direct contact with the manganese dioxide, and increased leakage current causes localized heating; usually, this drives an endothermic chemical reaction that produces manganese(III) oxide and regenerates (self-heals) the tantalum oxide dielectric layer.\nHowever, if the energy dissipated at the failure point is high enough, a self-sustaining exothermic reaction can start, similar to the thermite reaction, with metallic tantalum as fuel and manganese dioxide as oxidizer.  This undesirable reaction will destroy the capacitor, producing smoke and possibly flame.\nTherefore, tantalum capacitors can be freely deployed in small-signal circuits, but application in high-power circuits must be carefully designed to avoid thermal runaway failures.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Tantalum capacitors", "_id": "91--2--4---1", "title": "Tantalum Capacitors \u2014 Thermite Reactions"}
{"qas": [{"question": "Why do Athlon 64 heat sinks not work?", "answer": ""}, {"question": "How many times worse is the thermal resistivity of a stock athlon 64 heat sink?", "answer": "about 6", "ae_score": null, "qg_score": null}, {"question": "How many times worse is the thermal resistivity of a stock athlon 64 heat sink?", "answer": "about 6", "ae_score": null, "qg_score": null}], "content": "The leakage current of logic switching transistors increases with temperature. In rare instances, this may lead to thermal runaway in digital circuits. This is not a common problem, since leakage currents usually make up a small portion of overall power consumption, so the increase in power is fairly modest \u2014 for an Athlon 64, the power dissipation increases by about 10% for every 30 degrees Celsius. For a device with a TDP of 100 W, for thermal runaway to occur, the heat sink would have to have a thermal resistivity of over 3 K/W (kelvins per watt), which is about 6 times worse than a stock Athlon 64 heat sink. (A stock Athlon 64 heat sink is rated at 0.34 K/W, although the actual thermal resistance to the environment is somewhat higher, due to the thermal boundary between processor and heatsink, rising temperatures in the case, and other thermal resistances..) Regardless, an inadequate heat sink with a thermal resistance of over 0.5 to 1 K/W would result in the destruction of a 100 W device even without thermal runaway effects.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Digital logic", "_id": "91--2--5---1", "title": "Thermal Runaway in Digital Circuits"}
{"qas": [{"question": "Why do batteries explode on airplanes?", "answer": ""}, {"question": "When was the last time a lithium battery exploded?", "answer": "2006", "ae_score": null, "qg_score": null}, {"question": "When was the last time a lithium battery exploded?", "answer": "2006", "ae_score": null, "qg_score": null}], "content": "When handled improperly,  or if manufactured defectively, some rechargeable batteries can experience thermal runaway resulting in overheating. Sealed cells will sometimes explode violently if safety vents are overwhelmed or nonfunctional. Especially prone to thermal runaway are lithium-ion batteries, most markedly in the form of the lithium polymer battery. Reports of exploding cellphones occasionally appear in newspapers. In 2006,  batteries from Apple, HP, Toshiba, Lenovo, Dell and other notebook manufacturers were recalled because of fire and explosions.The Pipeline and Hazardous Materials Safety Administration (PHMSA) of the U.S. Department of Transportation has established regulations regarding the carrying of certain types of batteries on airplanes because of their instability in certain situations. This action was partially inspired by a cargo bay fire on a UPS airplane.One of the possible solutions is in using safer and less reactive anode (lithium titanates) and cathode (lithium iron phosphate) materials \u2014 avoiding the cobalt electrodes in many lithium rechargeable cells \u2014 together with non-flammable electrolytes based on ionic liquids.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Electrical engineering", "sub_heading": "Batteries", "_id": "91--2--6---1", "title": "Lithium rechargeable batteries are prone to thermal runaway and overheating"}
{"qas": [{"question": "What happens to the Helium in a star's core?", "answer": ""}, {"question": "What is the name of the runaway event in which helium fusion occurs in a star?", "answer": "helium flash", "ae_score": -0.6125835672365579, "qg_score": null}, {"question": "What is the name of the runaway event in which helium fusion occurs in a star?", "answer": "helium flash", "ae_score": -0.6125835672365579, "qg_score": null}], "content": "When stars in the 0.8-2.0 solar mass range exhaust the hydrogen in their cores and become red giants, the helium accumulating in their cores reaches degeneracy before it ignites. When the degenerate core reaches a critical mass of about 0.45 solar masses, helium fusion is ignited and takes off in a runaway fashion, called the helium flash, briefly increasing the star's energy production to a rate 100 billion times normal. About 6% of the core is quickly converted into carbon. While the release is sufficient to convert the core back into normal plasma after a few seconds, it does not disrupt the star, nor immediately change its luminosity. The star then contracts, leaving the red giant phase and continuing its evolution into a stable helium-burning phase.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "Astrophysics", "_id": "91--3--0---1", "title": "The Red Giant Phase of a Star"}
{"qas": [{"question": "What is a nova?", "answer": ""}, {"question": "What is the temperature at which hydrogen is heated in a white dwarf star?", "answer": "20 million K", "ae_score": -0.5581165107586461, "qg_score": null}, {"question": "What is the temperature at which hydrogen is heated in a white dwarf star?", "answer": "20 million K", "ae_score": -0.5581165107586461, "qg_score": null}], "content": "A nova results from runaway hydrogen fusion (via the CNO cycle) in the outer layer of a carbon-oxygen white dwarf star. If a white dwarf has a companion star from which it can accrete gas, the material will accumulate in a surface layer made degenerate by the dwarf's intense gravity. Under the right conditions, a sufficiently thick layer of hydrogen is eventually heated to a temperature of 20 million K, igniting runaway fusion. The surface layer is blasted off the white dwarf, increasing luminosity by a factor on the order of 50,000. The white dwarf and companion remain intact, however, so the process can repeat. A much rarer type of nova may occur when the outer layer that ignites is composed of helium.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "Novae", "_id": "91--3--1---1", "title": "A nova occurs when hydrogen fusion in the outer layer of a carbon-oxygen"}
{"qas": [{"question": "What is the process leading to neutron star novae?", "answer": ""}, {"question": "What accumulates on the surface of a neutron star during a thermal runaway?", "answer": "degenerate matter", "ae_score": -1.0029068094389209, "qg_score": null}, {"question": "What accumulates on the surface of a neutron star during a thermal runaway?", "answer": "degenerate matter", "ae_score": -1.0029068094389209, "qg_score": null}], "content": "Analogous to the process leading to novae, degenerate matter can also accumulate on the surface of a neutron star that is accreting gas from a close companion. If a sufficiently thick layer of hydrogen accumulates, ignition of runaway hydrogen fusion can then lead to an X-ray burst. As with novae, such bursts tend to repeat and may also be triggered by helium or even carbon fusion. It has been proposed that in the case of \"superbursts\", runaway breakup of accumulated heavy nuclei into iron group nuclei via photodissociation rather than nuclear fusion could contribute the majority of the energy of the burst.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "X-ray bursts", "_id": "91--3--2---1", "title": "X-ray Bursts \u2014 X-Ray Bursts"}
{"qas": [{"question": "How does a supernova work?", "answer": ""}, {"question": "How many white dwarfs can cause a thermal runaway?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many white dwarfs can cause a thermal runaway?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "A type Ia supernova results from runaway carbon fusion in the core of a carbon-oxygen white dwarf star. If a white dwarf, which is composed almost entirely of degenerate matter, can gain mass from a companion, the increasing temperature and density of material in its core will ignite carbon fusion if the star's mass approaches the Chandrasekhar limit. This leads to an explosion that completely disrupts the star. Luminosity increases by a factor of greater than 5 billion. One way to gain the additional mass would be by accreting gas from a giant star (or even main sequence) companion. A second and apparently more common mechanism to generate the same type of explosion is the merger of two white dwarfs.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "Type Ia supernovae", "_id": "91--3--3---1", "title": "A Type Ia Supernova"}
{"qas": [{"question": "What is a pair-instability supernova?", "answer": ""}, {"question": "What happens when the gamma rays in a supernova decay into electron-positron?", "answer": "pair production", "ae_score": -0.41341817416498455, "qg_score": null}, {"question": "What happens when the gamma rays in a supernova decay into electron-positron?", "answer": "pair production", "ae_score": -0.41341817416498455, "qg_score": null}], "content": "A pair-instability supernova is believed to result from runaway oxygen fusion in the core of a massive, 130-250 solar mass, low to moderate metallicity star. According to theory, in such a star, a large but relatively low density core of nonfusing oxygen builds up, with its weight supported by the pressure of gamma rays produced by the extreme temperature. As the core heats further, the gamma rays eventually begin to pass the energy threshold needed for collision-induced decay into electron-positron pairs, a process called pair production. This causes a drop in the pressure within the core, leading it to contract and heat further, causing more pair production, a further pressure drop, and so on. The core starts to undergo gravitational collapse. At some point this ignites runaway oxygen fusion, releasing enough energy to obliterate the star. These explosions are rare, perhaps about one per 100,000 supernovae.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "Pair-instability supernovae", "_id": "91--3--4---1", "title": "A pair-instability supernova"}
{"qas": [{"question": "Why are supernovae triggered by runaway nuclear fusion?", "answer": ""}, {"question": "What causes supernovae to collapse into neutron stars?", "answer": "runaway nuclear fusion", "ae_score": -0.529432579193398, "qg_score": null}, {"question": "What causes supernovae to collapse into neutron stars?", "answer": "runaway nuclear fusion", "ae_score": -0.529432579193398, "qg_score": null}], "content": "Not all supernovae are triggered by runaway nuclear fusion. Type Ib, Ic and type II supernovae also undergo core collapse, but because they have exhausted their supply of atomic nuclei capable of undergoing exothermic fusion reactions, they collapse all the way into neutron stars, or in the higher-mass cases, stellar black holes, powering explosions by the release of gravitational potential energy. It is the absence of runaway fusion reactions that allows such supernovae to leave behind compact stellar remnants.", "page_name": "Thermal runaway", "page_id": "Thermal%20runaway", "heading": "Astrophysics", "sub_heading": "Comparison to nonrunaway supernovae", "_id": "91--3--5---1", "title": "Supernovae Are Not All Supernovae, They Are All Supernovae"}
{"qas": [{"question": "What is the difference between a free market and a privilege free society?", "answer": ""}, {"question": "Who criticized the georgist school of political economy's claim that self-ownership?", "answer": "G. A. Cohen", "ae_score": -0.5155187085159768, "qg_score": null}, {"question": "Who criticized the georgist school of political economy's claim that self-ownership?", "answer": "G. A. Cohen", "ae_score": -0.5155187085159768, "qg_score": null}], "content": "Contemporary left-libertarian scholars such as Hillel Steiner, Peter Vallentyne, Philippe Van Parijs, Michael Otsuka, and David Ellerman root an economic egalitarianism in the classical liberal concepts of self-ownership and appropriation.  They hold that it is illegitimate for anyone to claim private ownership of natural resources to the detriment of others, a condition John Locke explicated in ''Two Treatises of Government''.  Locke argued that natural resources could be appropriated as long as doing so satisfies the proviso that there remains \"enough, and as good, left in common for others.\"  In this view, unappropriated natural resources are either unowned or owned in common, and private appropriation is only legitimate if everyone can appropriate an equal amount or the property is taxed to compensate those who are excluded.  This position is articulated in contrast to the position of other libertarians who argue for a characteristically labor-based right to appropriate unequal parts of the external world, such as land.  Most left-libertarians of this tradition support some form of economic rent redistribution on the grounds that each individual is entitled to an equal share of natural resources, and argue for the desirability of state social welfare programs.\nEconomists since Adam Smith have known that, unlike other forms of taxation, a land value tax would not cause economic inefficiency.  It would be a progressive tax \u2013 that is, a tax paid primarily by the wealthy \u2013 that increases wages, reduces economic inequality, removes incentives to misuse real estate, and reduces the vulnerability that economies face from credit and property bubbles.  Early proponents of this view include Thomas Paine, Herbert Spencer, and Hugo Grotius, but the concept was widely popularized by the political economist and social reformer Henry George.  George believed that people ought to own the fruits of their labor and the value of the improvements they make.  Thus, he was opposed to tariffs, income taxes, sales taxes, poll taxes, property taxes (on improvements), and to any tax on production, consumption, or capital wealth.  George was among the staunchest defenders of free markets, and his book ''Protection or Free Trade'' was read into the U.S. Congressional Record.  Yet he did support direct management of natural monopolies as a last resort, such as right-of-way monopolies necessary for railroad construction.  George advocated the elimination of intellectual property arrangements, regarding them as an especially damaging form of protectionism, and instead favored government-sponsored prizes for inventors.\nEarly followers of George's philosophy called themselves \"Single Taxers\" because they believed the only economically and morally legitimate, broad-based tax is on land rent.  The term ''Georgism'' was coined later, though some modern proponents prefer the less eponymous term ''geoism'' instead, leaving the meaning of ''geo''- (from the Greek ''ge'', meaning \"earth\") deliberately ambiguous.  The terms ''Earth Sharing'',  ''geonomics'', and ''geolibertarianism'' are used by some Georgists to represent a difference of emphasis or divergent ideas about how the land value tax revenue should be spent or redistributed to residents, but all agree that economic rent must be recovered from private landholders.\nOxford University Marxist philosopher G. A. Cohen extensively criticized the claim, characteristic of the Georgist school of political economy, that self-ownership and a privilege-free society can be realized simultaneously.  In ''Self-Ownership, Freedom, and Equality'', Cohen argued that any system purporting to take equality and its enforcement seriously is not consistent with the full emphasis on self-ownership and negative freedom that defines market libertarian thought.<ref>Tom G. Palmer has responded to Cohen's critique:", "page_name": "Left-libertarianism", "page_id": "Left-libertarianism", "heading": "Classical liberal radicalism", "sub_heading": "Classical liberal radicalism", "_id": "92--1---1---1", "title": "Economic Egalitarianism and the Politics of Self-Ownership"}
{"qas": [{"question": "How did Pi i Margall become so influential in Spanish politics?", "answer": ""}, {"question": "Who was the principal translator of Proudhon's works into spanish?", "answer": "Francesc Pi i Margall", "ae_score": -0.18199970755513875, "qg_score": null}, {"question": "Who was the principal translator of Proudhon's works into spanish?", "answer": "Francesc Pi i Margall", "ae_score": -0.18199970755513875, "qg_score": null}], "content": "Anarchism is a political philosophy that advocates stateless societies characterized by self-governed, non-hierarchical, voluntary institutions.  It developed in the 19th century from the secular or religious thought of the Enlightenment, particularly Jean-Jacques Rousseau's arguments for the moral centrality of freedom.\nAs part of the political turmoil of the 1790s, in the wake of the French Revolution, William Godwin developed the first expression of modern anarchist thought.  According to anarchist Peter Kropotkin, Godwin was \"the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work\";  Godwin instead attached his ideas to an early Edmund Burke. Godwin is generally regarded as the founder of philosophical anarchism.  He argued in ''Political Justice'' that government has an inherently malevolent influence on society, and that it perpetuates dependency and ignorance.  He thought the proliferation of reason would eventually cause government to wither away as an unnecessary force.  Although he did not accord the state with moral legitimacy, he was against the use of revolutionary tactics for removing the government from power.  Rather, he advocated for its replacement through a process of peaceful evolution.  His aversion to the imposition of a rules-based society led him to denounce, as a manifestation of the people's \"mental enslavement,\" the foundations of law, property rights and even the institution of marriage.  He considered the basic foundations of society as constraining the natural development of individuals to use their powers of reasoning to arrive at a mutually beneficial method of social organization.  In each case, government and its institutions are shown to constrain the development of our capacity to live wholly in accordance with the full and free exercise of private judgment.\nIn France, revolutionaries began using the term ''anarchiste'' in a positive light as early as September 1793.  Pierre-Joseph Proudhon was the first self-proclaimed anarchist, a label he adopted in his treatise ''What is Property?,'' and is often described as the founder of modern anarchist theory.  He developed the theory of spontaneous order in society, in which organisation emerges without a central coordinator imposing its own idea of order against the wills of individuals acting in their own interests \u2013 \"Liberty is the mother, not the daughter, of order.\"  Proudhon answers his own question in ''What is Property?'' with the famous statement, \"Property is theft.\"  He opposed the institution of decreed property (\"proprietorship\") in which owners have complete rights to \"use and abuse\" their property as they wish, and contrasted this with usufruct (\"possession\"), or limited ownership of resources only while in more or less continuous use.  Later, Proudhon added that \"Property is Liberty,\" and argued that it was a bulwark against state power.  His opposition to the state, organized religion, and certain capitalist practices inspired subsequent anarchists, and made him one of the leading social thinkers of his time.\nIn a scathing letter written in 1857, French anarchist Joseph D\u00e9jacque castigated Proudhon for his sexist economic and political views.  He argued that \"it is not the product of his or her labour that the worker has a right to, but to the satisfaction of his or her needs, whatever may be their nature.\"  D\u00e9jacque later named his anarchist publication ''The Libertarian: Journal of the Social Movement'', which was printed from 9 June 1858 to 4 February 1861.  In the mid-1890s, S\u00e9bastien Faure began publishing a new ''Le Libertaire'' while France's Third Republic enacted the \"villainous laws\" (''lois sc\u00e9l\u00e9rates''), which banned anarchist publications in France; ''libertarianism'' has frequently been used as a synonym for ''anarchism'' since this time, especially in continental Europe.  In the 1950s, classical liberals in the United States began identifying as libertarians in order to distance themselves from the social liberals of the New Left.  Since this time, it has become useful to distinguish this modern American libertarianism, which promotes laissez-faire capitalism and, generally, a night-watchman state, from traditional, left-wing anarchism.  Accordingly, the former is often described as right-wing libertarianism or simply right-libertarianism, while synonyms for the latter include ''left-libertarianism'', ''libertarian socialism'', ''socialist anarchism'', and ''left-anarchism''.\nJosiah Warren is widely regarded as the first US anarchist, and the four-page weekly paper he edited during 1833, ''The Peaceful Revolutionist'', was the first anarchist periodical published, an enterprise for which he built his own printing press, cast his own type, and made his own printing plates.  Warren was a follower of Robert Owen and joined Owen's community at New Harmony, Indiana.  Josiah Warren termed the phrase \"Cost the limit of price,\" with \"cost\" referring not to monetary price paid but the labor one exerted to produce an item.  Therefore, \"[h]e proposed a system to pay people with certificates indicating how many hours of work they did.  They could exchange the notes at local time stores for goods that took the same amount of time to produce.\"<ref name=Slate/>  He put his theories to the test by establishing an experimental \"labor for labor store\" called the Cincinnati Time Store where trade was facilitated by notes backed by a promise to perform labor.  The store proved successful and operated for three years after which it was closed so that Warren could pursue establishing colonies based on mutualism.  These included Utopia and Modern Times.  Warren said that Stephen Pearl Andrews' ''The Science of Society'', published in 1852, was the most lucid and complete exposition of Warren's own theories. American individualist anarchist Benjamin Tucker argued that the elimination of what he called \"the four monopolies\" \u2013 the land monopoly, the money and banking monopoly, the monopoly powers conferred by patents, and the quasi-monopolistic effects of tariffs \u2013 would undermine the power of the wealthy and big business, making possible widespread property ownership and higher incomes for ordinary people, while minimizing the power of would-be bosses and achieving socialist goals without state action.  Tucker influenced and interacted with anarchist contemporaries \u2013 including Lysander Spooner, Voltairine de Cleyre, Dyer D. Lum, and William B. Greene \u2013 who have in various ways influenced later left-libertarian thinking.\nThe catalan politician Francesc Pi i Margall became the principal translator of Proudhon's works into Spanish and later briefly became president of Spain in 1873 while being the leader of the Democratic Republican Federal Party. For prominent anarcho-syndicalist Rudolf Rocker: \"The first movement of the Spanish workers was strongly influenced by the ideas of Pi y Margall, leader of the Spanish Federalists and disciple of Proudhon. Pi y Margall was one of the outstanding theorists of his time and had a powerful influence on the development of libertarian ideas in Spain. His political ideas had much in common with those of Richard Price, Joseph Priestly (sic), Thomas Paine, Jefferson, and other representatives of the Anglo-American liberalism of the first period. He wanted to limit the power of the state to a minimum and gradually replace it by a Socialist economic order.\" Pi i Margall was a dedicated theorist in his own right, especially through book-length works such as ''La reacci\u00f3n y la revoluci\u00f3n'' (en:\"Reaction and revolution\" from 1855), ''Las nacionalidades'' (en:\"Nationalities\" from 1877), and ''La Federaci\u00f3n'' from 1880.", "page_name": "Left-libertarianism", "page_id": "Left-libertarianism", "heading": "Anarchism", "sub_heading": "Anarchism", "_id": "92--2---1---1", "title": "Anarchism and the New Left"}
{"qas": [{"question": "Libertarian Socialism?", "answer": ""}, {"question": "What type of political philosophy is alexandria?", "answer": "libertarian socialist", "ae_score": -0.5014646221381536, "qg_score": null}, {"question": "What type of political philosophy is alexandria?", "answer": "libertarian socialist", "ae_score": -0.5014646221381536, "qg_score": null}], "content": "Libertarian socialism (sometimes called social anarchism, left-libertarianism and socialist libertarianism) is a group of anti-authoritarian political philosophies inside the socialist movement that rejects socialism as centralized state ownership and control of the economy, as well as the state itself. It criticizes wage labour relationships within the workplace, instead emphasizing workers' self-management of the workplace and decentralized structures of political organization, asserting that a society based on freedom and justice can be achieved through abolishing authoritarian institutions that control certain means of production and subordinate the majority to an owning class or political and economic elite. Libertarian socialists advocate for decentralized structures based on direct democracy and federal or confederal associations such as libertarian municipalism, citizens' assemblies, trade unions, and workers' councils. All of this is generally done within a general call for libertarian and voluntary human relationships through the identification, criticism, and practical dismantling of illegitimate authority in all aspects of human life.\nPast and present political philosophies and movements commonly described as libertarian socialist include anarchism (especially anarchist communism, anarchist collectivism, anarcho-syndicalism, and mutualism) as well as autonomism, communalism, participism, guild socialism, revolutionary syndicalism, and libertarian Marxist philosophies such as council communism and Luxemburgism; as well as some versions of \"utopian socialism\" and individualist anarchism.", "page_name": "Left-libertarianism", "page_id": "Left-libertarianism", "heading": "Libertarian socialism", "sub_heading": "Libertarian socialism", "_id": "92--3---1---1", "title": "Libertarian Socialism (also known as Libertarian Socialism)"}
{"qas": [{"question": "What is the difference between left-wing and right-wing economists?", "answer": ""}, {"question": "Samuel edward konkin iii founded what tendency?", "answer": "Agorism", "ae_score": -0.5651613949870947, "qg_score": null}, {"question": "Samuel edward konkin iii founded what tendency?", "answer": "Agorism", "ae_score": -0.5651613949870947, "qg_score": null}], "content": "While, with notable exceptions, US market-oriented libertarians after Benjamin Tucker tended to ally with the political right, relationships between such libertarians and the New Left thrived in the 1960s, laying the groundwork for modern left-wing market anarchism.  Austrian School economist Murray Rothbard was initially an enthusiastic partisan of the Old Right, particularly because of its general opposition to war and imperialism, but long embraced a reading of American history that emphasized the role of elite privilege in shaping legal and political institutions \u2013 one that was thus naturally agreeable to many on the left.  In the 1960s, he came increasingly to seek alliances on the left, especially with members of the New Left, in light of the Vietnam War, the military draft, and the emergence of the black power movement.  Working with other radicals like Ronald Radosh and Karl Hess, Rothbard argued that the consensus view of American economic history, according to which a beneficent government has used its power to counter corporate predation, is fundamentally flawed.  Rather, government intervention in the economy has largely benefited established players at the expense of marginalized groups, to the detriment of both liberty and equality.  Moreover, the \"Robber Baron\" period, hailed by the right and despised by the left as a heyday of laissez-faire, was not characterized by laissez-faire at all, but was a time of massive state privilege accorded to capital.  In tandem with his emphasis on the intimate connection between state and corporate power, he defended the seizure of corporations dependent on state ''largesse'' by workers and others. Rothbard himself ultimately broke with the left, allying himself instead with the burgeoning paleoconservative movement.  He criticized the tendency of left-libertarians to appeal to \"'free spirits,' to people who don't want to push other people around, and who don't want to be pushed around themselves\" in contrast to \"the bulk of Americans,\" who \"might well be tight-assed conformists, who want to stamp out drugs in their vicinity, kick out people with strange dress habits, etc.\"\nSome thinkers associated with market-oriented American libertarianism, drawing on the work of Rothbard during his alliance with the left and on the thought of Karl Hess, came increasingly to identify with the left on a range of issues, including opposition to war, to corporate oligopolies and state-corporate partnerships, and an affinity for cultural liberalism.  This left-libertarianism is associated with scholars such as Kevin Carson, Roderick T. Long, Samuel Edward Konkin III, Sheldon Richman, Chris Matthew Sciabarra, and Gary Chartier who stress the value of radically free markets, termed ''freed markets'' to distinguish them from the common conception which these libertarians believe to be riddled with statist and capitalist privileges.  Referred to as left-wing market anarchists or market-oriented left-libertarians, proponents of this approach strongly affirm the classical liberal ideas of self-ownership and free markets, while maintaining that, taken to their logical conclusions, these ideas support strongly anti-corporatist, anti-hierarchical, pro-labor positions in economics; anti-imperialism in foreign policy; and thoroughly liberal or radical views regarding such cultural issues as gender, sexuality, and race.  While adopting familiar libertarian views, including opposition to drug prohibition, gun control, civil liberties violations, and war, left-libertarians are more likely to take more distinctively leftist stances on issues as diverse as feminism, gender and sexuality, class, immigration, and environmentalism.  Members of this school typically urge the abolition of the state, arguing that vast disparities in wealth and social influence result from the use of force \u2013 especially state power \u2013 to steal and engross land and acquire and maintain special privileges.  They judge that, in a stateless society, the kinds of privileges secured by the state will be absent, and injustices perpetrated or tolerated by the state can be rectified.  Thus, they conclude that, with state interference eliminated, it will be possible to achieve \"socialist ends by market means.\"  According to libertarian scholar Sheldon Richman:\nAgorism is an anarchist tendency founded by Samuel Edward Konkin III which advocates counter-economics, working in untaxable black or grey markets and boycotting as much as possible the unfree, taxed market with the intended result that private voluntary institutions emerge and outcompete statist ones.", "page_name": "Left-libertarianism", "page_id": "Left-libertarianism", "heading": "Left-wing market anarchism", "sub_heading": "Left-wing market anarchism", "_id": "92--4---1---1", "title": "Left-Wing Market Anarchism and the New Left"}
{"qas": [{"question": "Why is it so difficult for countries to effectively manage their own resources?", "answer": ""}, {"question": "The study of water use in the ecosystem is based on?", "answer": "integrated water resource management", "ae_score": -0.3307976237064412, "qg_score": null}, {"question": "The study of water use in the ecosystem is based on?", "answer": "integrated water resource management", "ae_score": -0.3307976237064412, "qg_score": null}], "content": "Water is an essential resource for all life on the planet. Of the water resources on Earth only three percent of it is fresh and two-thirds of the freshwater is locked up in ice caps and glaciers. Of the remaining one percent, a fifth is in remote, inaccessible areas and much seasonal rainfall in monsoonal deluges and floods cannot easily be used. As time advances, water is becoming scarcer and having access to clean, safe, drinking water is limited among countries. At present only about 0.08 percent of all the world\u2019s fresh water  is exploited by mankind  in ever increasing demand  for sanitation, drinking, manufacturing, leisure and agriculture. Due to the small percentage of water remaining, optimizing the fresh water we have left from natural resources has been a continuous difficulty in several locations worldwide.\nMuch effort in water resource management is directed at optimizing the use of water and in minimizing the environmental impact of water use on the natural environment. The observation of water as an integral part of the ecosystem is based on integrated water resource management, where the quantity and quality of the ecosystem help to determine the nature of the natural resources.\nSuccessful management of any resources requires accurate knowledge of the resource available, the uses to which it may be put, the competing demands for the resource, measures to and processes to evaluate the significance and worth of competing demands and mechanisms to translate  policy decisions into actions on the ground.\nFor water as a resource, this is particularly difficult since sources of water can cross many national boundaries and the uses of water include many that are difficult to assign financial value to and may also be difficult to manage in conventional terms. Examples include rare species or ecosystems or the very long term value of ancient groundwater reserves.", "page_name": "Water resource management", "page_id": "Water%20resource%20management", "heading": "Overview", "sub_heading": "Overview", "_id": "93--0---1---1", "title": "Water as an integral part of the ecosystem."}
{"qas": [{"question": "Why is there so much water scarcity in the world?", "answer": ""}, {"question": "What percentage of earth's freshwater is used for agriculture?", "answer": "70 percent", "ae_score": -0.49441329850003624, "qg_score": null}, {"question": "What percentage of earth's freshwater is used for agriculture?", "answer": "70 percent", "ae_score": -0.49441329850003624, "qg_score": null}], "content": "Agriculture is the largest user of the world's freshwater resources, consuming 70 percent. As the world population rises it consumes more food (currently exceeding 6%, it is expected to reach 9% by 2050), the industries and urban developments expand, and the emerging biofuel crops trade also demands a share of freshwater resources, water scarcity is becoming an important issue. An assessment of water resource management in agriculture was conducted in 2007 by the International Water Management Institute in Sri Lanka to see if the world had sufficient water to provide food for its growing population or not . It assessed the current availability of water for agriculture on a global scale and mapped out locations suffering from water scarcity. It found that a fifth of the world's people, more than 1.2 billion, live in areas of physical water scarcity, where there is not enough water to meet all their demands. A further 1.6 billion people live in areas experiencing economic water scarcity, where the lack of investment in water or insufficient human capacity make it impossible for authorities to satisfy the demand for water.\nThe report found that it would be possible to produce the food required in future, but that continuation of today's food production and environmental trends would lead to crises in many parts of the world. Regarding food production, the World Bank targets agricultural food production and water resource management as an increasingly global issue that is fostering an important and growing debate. The authors of the book ''Out of Water: From abundance to Scarcity and How to Solve the World's Water Problems'', which laid down a six-point plan for solving the world's water problems. These are: 1) Improve data related to water; 2) Treasure the environment; 3) Reform water governance; 4) Revitalize agricultural water use; 5) Manage urban and industrial demand; and 6) Empower the poor and women in water resource management. To avoid a global water crisis, farmers will have to strive to increase productivity to meet growing demands for food, while industry and cities find ways to use water more efficiently.", "page_name": "Water resource management", "page_id": "Water%20resource%20management", "heading": "Agriculture", "sub_heading": "Agriculture", "_id": "93--1---1---1", "title": "Water scarcity in agriculture"}
{"qas": [{"question": "Why is it so important for developing world countries to clean their water?", "answer": ""}, {"question": "What is the second most common cause of infant deaths?", "answer": "diarrhoea", "ae_score": -0.24425493320170363, "qg_score": null}, {"question": "What is the second most common cause of infant deaths?", "answer": "diarrhoea", "ae_score": -0.24425493320170363, "qg_score": null}], "content": "As the carrying capacity of the Earth increases greatly due to technological advances, urbanization in modern times occurs because of economic opportunity. This rapid urbanization happens worldwide but mostly in new rising economies and developing countries. Cities in Africa and Asia are growing fastest with 28 out of 39 megacities (a city or urban area with more than 10 million inhabitants) worldwide in these developing nations.  The number of megacities will continue to rise reaching approximately 50 in 2025. With developing economies water scarcity is a very common and very prevalent issue. Global freshwater resources dwindle in the eastern hemisphere either than at the poles, and with the majority of urban development millions live with insufficient fresh water. This is caused by polluted freshwater resources, overexploited groundwater resources, insufficient harvesting capacities in the surrounding rural areas, poorly constructed and maintained water supply systems, high amount of informal water use and insufficient technical and water management capacities.\nIn the areas surrounding urban centres, agriculture must compete with industry and municipal users for safe water supplies, while traditional water sources are becoming polluted with urban runoff. As cities offer the best opportunities for selling produce, farmers often have no alternative to using polluted water to irrigate their crops. Depending on how developed a city\u2019s wastewater treatment is, there can be significant health hazards related to the use of this water. Wastewater from cities can contain a mixture of pollutants. There is usually wastewater from kitchens and toilets along with rainwater runoff. This means that the water usually contains excessive levels of nutrients and salts, as well as a wide range of pathogens. Heavy metals may also be present, along with traces of antibiotics and endocrine disruptors, such as oestrogens.\nDeveloping world countries tend to have the lowest levels of wastewater treatment. Often, the water that farmers use for irrigating crops is contaminated with pathogens from sewage. The pathogens of most concern are bacteria, viruses and parasitic worms, which directly affect farmers\u2019 health and indirectly affect consumers if they eat the contaminated crops. Common illnesses include diarrhoea, which kills 1.1 million people annually and is the second most common cause of infant deaths. Many cholera outbreaks are also related to the reuse of poorly treated wastewater. Actions that reduce or remove contamination, therefore, have the potential to save a large number of lives and improve livelihoods. Scientists have been working to find ways to reduce contamination of food using a method called the 'multiple-barrier approach'.\nThis involves analysing the food production process from growing crops to selling them in markets and eating them, then considering where it might be possible to create a barrier against contamination. Barriers include: introducing safer irrigation practices; promoting on-farm wastewater treatment; taking actions that cause pathogens to die off; and effectively washing crops after harvest in markets and restaurants.", "page_name": "Water resource management", "page_id": "Water%20resource%20management", "heading": "Managing water in urban settings", "sub_heading": "Managing water in urban settings", "_id": "93--2---1---1", "title": "The Multi-Barrier Approach to Food Contamination"}
{"qas": [{"question": "Why do we care so much about water?", "answer": ""}, {"question": "Which country has tried to create a sustainable freshwater system?", "answer": "Australia", "ae_score": -0.5097567382238707, "qg_score": null}, {"question": "Which country has tried to create a sustainable freshwater system?", "answer": "Australia", "ae_score": -0.5097567382238707, "qg_score": null}], "content": "One of the biggest concerns for our water-based resources in the future is the sustainability of the current and even future water resource allocation. As water becomes more scarce, the importance of how it is managed grows vastly. Finding a balance between what is needed by humans and what is needed in the environment is an important step in the sustainability of water resources. Attempts to create sustainable freshwater systems have been seen on a national level in countries such as Australia, and such commitment to the environment could set a model for the rest of the world.\nThe field of water resources management will have to continue to adapt to the current and future issues facing the allocation of water. With the growing uncertainties of global climate change and the long term impacts of management actions,the decision-making will be even more difficult. It is likely that ongoing climate change will lead to situations that have not been encountered. As a result, alternative management strategies are sought for in order to avoid setbacks in the allocation of water resources.", "page_name": "Water resource management", "page_id": "Water%20resource%20management", "heading": "Future of water resources", "sub_heading": "Future of water resources", "_id": "93--3---1---1", "title": "Sustainability of Water Resources Management in the Future"}
{"qas": [{"question": "How is the world's natural oil supply fixed?", "answer": ""}, {"question": "What are the products of oil depletion?", "answer": "petroleum compounds", "ae_score": -0.732023142717967, "qg_score": null}, {"question": "What are the products of oil depletion?", "answer": "petroleum compounds", "ae_score": -0.732023142717967, "qg_score": null}], "content": "The World's natural oil supply is fixed because petroleum is naturally formed far too slowly to be replaced at the rate at which it is being extracted.  Over many millions of years, plankton, bacteria, and other plant and animal matter became buried in sediments on the ocean floor.  When conditions were right \u2013 a lack of oxygen for decomposition, and sufficient depth and temperature of burial \u2013 these organic remains were converted into petroleum compounds, while the sediment accompanying them was converted into sandstone, siltstone, and other porous sedimentary rock.  When capped by impermeable rocks such as shale, salt, or igneous intrusions, they formed the petroleum reservoirs which are exploited today.", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Resource availability", "sub_heading": "Resource availability", "_id": "94--0---1---1", "title": "The World's Natural Oil Supply Is Fixed Because The World's Natural Oil Supply is"}
{"qas": [{"question": "Why does the price of oil fluctuate so much?", "answer": ""}, {"question": "Where does the decline in oil come from?", "answer": "the reservoir drive mechanism", "ae_score": -1.8431722119191238, "qg_score": null}, {"question": "Where does the decline in oil come from?", "answer": "the reservoir drive mechanism", "ae_score": -1.8431722119191238, "qg_score": null}], "content": "An individual oil well usually produces at its maximum rate at the start of its life; the production rate eventually declines to a point at which it no longer produces profitable amounts. The shape of the decline curve depends on the oil reservoir and the reservoir drive mechanism. Wells in water-drive and gas-cap drive reservoirs often produce at a near constant rate until the encroaching water or expanding gas cap reaches the well, causing a sudden decline in oil production. Wells in gas solution drive and oil expansion drive reservoirs have exponential or hyperbolic declines: rapid declines at first, then leveling off.\nThe shape of production curve of an oil well can also be affected by a number of nongeologic factors:", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Production decline models", "sub_heading": "Production decline models", "_id": "94--1--0---1", "title": "The Oil Well Production Curve"}
{"qas": [{"question": "How do oil fields stay in production for so long?", "answer": ""}, {"question": "How long have oil fields been producing for?", "answer": "over 100 years", "ae_score": -0.8814456551965701, "qg_score": null}, {"question": "How long have oil fields been producing for?", "answer": "over 100 years", "ae_score": -0.8814456551965701, "qg_score": null}], "content": "Individual oil wells are typically within multi-well oil fields. As with individual wells, the production curves for oil fields vary depending on geology and how they are developed and produced. Some fields have symmetric bell-shaped production profiles, but it is more common that the period of inclining production is briefer and steeper than the subsequent decline. More than half the production usually occurs after a field has reached a peak or plateau. Production profiles of many fields show distinct peaks, but for giant oil fields, it is more common for production to reach and maintain a plateau before declining. Once a field declines, it usually follows an exponential decline. As this decline levels off, production can continue at relatively low rates. A number of oil fields in the U.S. have been producing for over 100 years.\nOil field production curves can be modified by a number of factors:", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Production decline models", "sub_heading": "Oil field production decline", "_id": "94--1--1---1", "title": "Oil Field Production Curves"}
{"qas": [{"question": "Hubbert peak theory?", "answer": ""}, {"question": "Which theory states that oil production starts off slowly, rises faster and faster, then slows?", "answer": "Hubbert peak theory", "ae_score": -0.754149680821705, "qg_score": null}, {"question": "Which theory states that oil production starts off slowly, rises faster and faster, then slows?", "answer": "Hubbert peak theory", "ae_score": -0.754149680821705, "qg_score": null}], "content": "Most oil is found in a small number of very large oil fields. According to Hubbert peak theory, production starts off slowly, rises faster and faster, then slows down and flattens until it reaches a peak, after which production declines. In the late stage, production often enters a period of exponential decline in which the decline becomes less and less steep. Oil production may never actually reach zero, but eventually becomes very low.Factors which can modify this curve include:", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Production decline models", "sub_heading": "Multi-field production decline", "_id": "94--1--2---1", "title": "The Hubbert Peak Theory"}
{"qas": [{"question": "Why does the US have such a low oil production compared to other countries?", "answer": ""}, {"question": "When did the us oil production peak?", "answer": "1970", "ae_score": -0.4800491022063998, "qg_score": null}, {"question": "When did the us oil production peak?", "answer": "1970", "ae_score": -0.4800491022063998, "qg_score": null}], "content": "Oil production in the United States, provided one excludes Alaska, began by following the theoretical Hubbert curve for a few decades but is now deviating strongly from it. U.S. oil production reached a peak in 1970 and by the mid-2000s it had fallen to 1940s levels. In 1950, the United States produced over half the world's oil, but by 2005 that proportion had dropped to about 8%. In 2005, U.S. crude oil imports peaked at a rate twice as high as domestic production; since then, U.S. oil production has increased, and imports have fallen 41%.\nThe production peak in 1970 was predicted by one of the two projections put forward in 1956 by Hubbert. By 1972 all import quotas and controls on U.S. domestic production had been removed. Despite this, and despite the quadrupling of prices during the 1973 oil crisis, the production decline was not reversed in the lower 48 states until 2009. Crude oil production has since risen sharply from 2009 through 2014, so that the rate of US oil production in October 2014 was 81% higher than the average rate in 2008.\nThe actual U.S. production curve deviates from Hubbert's 1956 curve in significant ways:", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Production decline models", "sub_heading": "United States production", "_id": "94--1--3---1", "title": "U.S. Oil Production Deviates From Hubbert's 1956 Curve"}
{"qas": [{"question": "What would happen if all of the cities in the world were built on the same ground?", "answer": ""}, {"question": "What is the name of the movement to deal with oil depletion?", "answer": "New Urbanism", "ae_score": -0.2981719919276461, "qg_score": null}, {"question": "What is the name of the movement to deal with oil depletion?", "answer": "New Urbanism", "ae_score": -0.2981719919276461, "qg_score": null}], "content": "The use of fossil fuels allows humans to participate in takedown, which is the consumption of energy at a greater rate than it is being replaced. The industrial economy is currently heavily dependent on oil as a fuel and chemical feedstock.  For example, over 90% of transportation in the United States relies on oil.\nSince the 1940s, agriculture has dramatically increased its productivity, due largely to the use of chemical pesticides, fertilizers, and increased mechanisation. This process has been called the Green Revolution. The increase in food production has allowed world population to grow dramatically over the last 50 years. Pesticides rely upon oil as a critical ingredient, and fertilizers require natural gas.  Farm machinery also requires oil.\nMost or all of the uses of fossil fuels in agriculture can be replaced with alternatives.  For example, by far the biggest fossil fuel input to agriculture is the use of natural gas as a hydrogen source for the Haber-Bosch fertilizer-creation process.  Natural gas is used simply because it is the cheapest currently available source of hydrogen; were that to change, other sources, such as electrolysis powered by solar energy, could be used to provide the hydrogen for creating fertilizer without relying on fossil fuels.\nOil shortages may force a move to lower input \"organic agriculture\" methods, which may be more labor-intensive and require a population shift from urban to rural areas, reversing the trend towards urbanisation which has predominated in industrial societies; however, some organic farmers using modern organic-farming methods have reported yields as high as those available from conventional farming, but without the use of fossil-fuel-intensive artificial fertilizers or pesticides.\nAnother possible effect would derive from modern transportation and housing infrastructure. A large proportion of the developed world's population live in suburbs, a type of low-density settlement designed with the automobile in mind.  A movement to deal with this problem early, called \"New Urbanism,\" seeks to develop the suburbs into higher density neighborhoods and use high density, mixed-use forms for new building projects.", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Implications of a world peak", "sub_heading": "Implications of a world peak", "_id": "94--2--0---1", "title": "Urbanism and Urbanism"}
{"qas": [{"question": "What would happen if all the oil in the world suddenly stopped being used?", "answer": ""}, {"question": "What is the term for an economic crisis caused by oil depletion?", "answer": "Energy crisis", "ae_score": -1.181189400671355, "qg_score": null}, {"question": "What is the term for an economic crisis caused by oil depletion?", "answer": "Energy crisis", "ae_score": -1.181189400671355, "qg_score": null}], "content": "A more modest scenario, assuming a slower rate of depletion or a smoother transition to alternative energy sources, could still cause substantial economic hardship such as a recession or depression due to higher energy prices.  Inflation has also been linked to oil price spikes.  However, economists disagree on the strength and causes of this association. See Energy crisis.", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Implications of a world peak", "sub_heading": "Recession", "_id": "94--2--1---1", "title": "Inflation and the Energy Crisis."}
{"qas": [{"question": "Why are food prices rising?", "answer": ""}, {"question": "Which law predicts that if fewer farmers are producing food the price of food will rise?", "answer": "The law of supply and demand", "ae_score": -0.8749012634979406, "qg_score": null}, {"question": "Which law predicts that if fewer farmers are producing food the price of food will rise?", "answer": "The law of supply and demand", "ae_score": -0.8749012634979406, "qg_score": null}], "content": "Rising oil prices cause rising food prices in three ways. First, increased equipment fuel costs drive higher prices. Second, transportation costs increase retail prices. Third, higher oil prices are causing farmers to switch from producing food crops to producing biofuel crops.  The law of supply and demand predicts that if fewer farmers are producing food the price of food will rise.", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Implications of a world peak", "sub_heading": "Rising food prices", "_id": "94--2--2---1", "title": "Rising oil prices cause rising food prices in three ways."}
{"qas": [{"question": "Why is it so hard to harness solar energy?", "answer": ""}, {"question": "What is the name of the alternative fuel to oil?", "answer": "biogas", "ae_score": -0.18652528613609864, "qg_score": null}, {"question": "What is the name of the alternative fuel to oil?", "answer": "biogas", "ae_score": -0.18652528613609864, "qg_score": null}], "content": "An alternative considered likely by some is that oil will be replaced with renewable energy during the first half of the 21st century. The replacement fuel would likely be hydrogen. A hydrogen economy would then replace the current oil-based economy. Another possible replacement fuel is biogas, which is composed of methane. Methane has boiling point of \u2212161 \u00b0C, rather than hydrogen's -252.87 \u00b0C, making methane a much easier fuel to condense.\nOther people consider that the whole idea of \"the hydrogen economy\" is flawed. Compressed hydrogen has an energy density of only 5.6 megajoules per liter.  Robert Zubrin looks at the practical problems of using hydrogen as an energy storage medium in ''Energy Victory: Winning the War on Terror by Breaking Free of Oil''. He considers that hydrogen is a very poor form of storage, and that batteries, methanol or dimethyl ether would be better.  This point is reiterated in ''Beyond Oil and Gas: The Methanol Economy'' and in David MacKay's book described below.\nGeothermal power is one source of sustainable energy that can produce hydrogen.  Note that David MacKay has shown in his book ''Sustainable Energy: Without the Hot Air'' that geothermal can only provide a tiny fraction of the world's needs sustainably.  In some areas located over geological hotspots (such as Iceland), geothermal makes more sense.\nSolar energy is a source of inexhaustible energy. There is more solar energy that reaches the surface of the Earth each hour than the amount of energy consumed by the world in a year. The challenges of using the sun's energy \u2013 energy which can be obtained either from wind power or from solar power \u2013 is that the energy needs to either be (1) stored in physical form of fuel for when it can be used in the future, or (2) transported directly as electricity, through transmission lines. Neither is dispatchable, as there is no control over when the sun will shine or when the wind will blow. There are, however, concentrated solar power plants using thermal storage that can store energy efficiently for up to 24 hours.", "page_name": "Oil depletion", "page_id": "Oil%20depletion", "heading": "Replacement", "sub_heading": "Replacement", "_id": "94--3---1---1", "title": "The Future of Energy \u2014 The Future of Energy"}
{"qas": [{"question": "Why is child labor illegal?", "answer": ""}, {"question": "Who defines child labor in cocoa production?", "answer": "The International Labour Organization", "ae_score": -0.9645455374753138, "qg_score": null}, {"question": "Who defines child labor in cocoa production?", "answer": "The International Labour Organization", "ae_score": -0.9645455374753138, "qg_score": null}], "content": "The International Labour Organization (ILO) defines child labor as work that \"is mentally, physically, socially or morally dangerous and harmful to children; and interferes with their schooling by depriving them of the opportunity to attend school; by obliging them to leave school prematurely; or by requiring them to attempt to combine school attendance with excessively long and heavy work.\" Not all work that children do is child labor. Work done that is not detrimental to children\u2019s health, development or schooling is beneficial because it allows children to develop skills, gain experience and prepare them for future positions; these are not considered child labor.\nThe worst forms of child labor, related to cocoa production, are using children as slaves or in debt bondage, trafficking them, and forcing them to do hazardous work, which includes using dangerous machinery or tools, manually transporting heavy loads, working with hazardous agents or working long hours.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Child labor definition", "sub_heading": "Child labor definition", "_id": "95--0---1---1", "title": "Child labor in cocoa production is not considered child labor."}
{"qas": [{"question": "Why is the cocoa industry so much more successful in C\u00f4te d'Ivoire than in Ghana?", "answer": ""}, {"question": "When did ghana become the largest cocoa producer in the world?", "answer": "1910", "ae_score": -0.24894979758212424, "qg_score": null}, {"question": "When did ghana become the largest cocoa producer in the world?", "answer": "1910", "ae_score": -0.24894979758212424, "qg_score": null}], "content": "In Ghana, the cocoa industry began in the late 19th century and in C\u00f4te d'Ivoire it began in the early 20th century. Ghana became the largest cocoa producer in the world in 1910. By 1980 C\u00f4te d'Ivoire overtook Ghana as the biggest producer. In both countries, the majority of farms are small and family-owned. Family members, including children, are often expected to work on the farms.\nIn the 2008\u20132009 growing year (which runs October through September), 3.54 million tonnes of cocoa beans were produced. African nations produced 2.45 million tonnes (69%), Asia and Oceania 0.61 million tonnes (17%) and the Americas 0.48 million tonnes (14%). Two African nations, C\u00f4te d'Ivoire and Ghana, produce more than half of the world's cocoa, with 1.23 and 0.73 million tonnes respectively (35% and 21%, respectively).\nDifferent metrics are used for chocolate consumption. The Netherlands has the highest monetary amount of cocoa bean imports (US$2.1 billion); it is also one of the main ports into Europe. The United States has highest amount of cocoa powder imports ($220 million); the US has a large amount of cocoa complementary products.  The United Kingdom has the highest amount of retail chocolate ($1.3 billion) and is one of the biggest chocolate consumption per capita markets.\nCocoa plantations in Ghana, the Ivory Coast and Malaysia provide 80% of the world with chocolate, according to CorpWatch.[3] Chocolate producers around the world have been pressured to \"verify that their chocolate is not the product of child labor or slavery.\"[4]", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Production and consumption statistics", "sub_heading": "Production and consumption statistics", "_id": "95--1---1---1", "title": "Chocolate Consumption in the World"}
{"qas": [{"question": "Why is it so dangerous for children to eat raw beans?", "answer": ""}, {"question": "How many children worked in hazardous conditions in west africa in 2002?", "answer": "284,000", "ae_score": -0.35635870700416544, "qg_score": null}, {"question": "How many children worked in hazardous conditions in west africa in 2002?", "answer": "284,000", "ae_score": -0.35635870700416544, "qg_score": null}], "content": "Cocoa trees are treated with pesticides and fungicides. Cocoa harvest is not restricted to one period per year and occurs over a period of several months to the whole year. Pods are harvested at multiple times during the harvest season because they do not all ripen at once. Pod ripening is judged by pod color, and ripe pods are harvested from the trunk and branches of the cocoa tree with a curved knife on a long pole. The pods are opened and wet beans are removed. Wet beans are transported to a facility so they can be fermented and dried.\nMany of these tasks could be hazardous when performed by children, according to the ILO. Mixing and applying chemicals can be hazardous due to pesticide contamination, especially because no protective clothing is worn during application. Clearing vegetation and harvesting pods can be hazardous because these tasks are often done using machetes, which can cause incision. This skill is part of normal development in children 15 to 17 years old, but is a higher risk in younger children. Many have wounds on their legs where they have cut themselves. Transport of the wet beans can also be hazardous due to long transport distances and heavy loads; hernias and physical injuries can occur. The director of the Save the Children Fund described \"young children carrying 6 kg of cocoa sacks so heavy that they have wounds all over their shoulders.\"\nIn 2002, the International Institute of Tropical Agriculture investigated the prevalence of child labor in the cocoa industry. They found 284,000 children working in hazardous conditions in West Africa. Of these, 153,000 were children who applied pesticides without protective equipment, others picked pods and opened them to get the beans; 64% of the children were younger than 14 and 40% of the children were girls. Children often began working at 6am, worked 12-hour days and were beaten regularly.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Children in cocoa harvest and processing", "sub_heading": "Children in cocoa harvest and processing", "_id": "95--2---1---1", "title": "Child Labor in Cocoa"}
{"qas": [{"question": "Why are child laborers more likely to attend school?", "answer": ""}, {"question": "Who are the children that work on cocoa farms?", "answer": "Child laborers", "ae_score": -0.9335719702507824, "qg_score": null}, {"question": "Who are the children that work on cocoa farms?", "answer": "Child laborers", "ae_score": -0.9335719702507824, "qg_score": null}], "content": "Child laborers are less likely to attend school. They are kept out of school because families need their help on the farms, and 12-hour workdays make it difficult to attend school. In C\u00f4te d'Ivoire, 34 percent of children on cocoa farms attended school compared to 64 percent of children who did not work on farms. Only 33 percent of children from immigrant cocoa workers attended school, while 71 percent of the local children attended school.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Education of child laborers", "sub_heading": "Education of child laborers", "_id": "95--3---1---1", "title": "Child laborers are less likely to attend school in C\u00f4te d'Ivoire"}
{"qas": [{"question": "Why are there so many child slaves in Ivory Coast?", "answer": ""}, {"question": "According to the us state department, how many child slaves were there in cocoa, cotton?", "answer": "15,000", "ae_score": -0.3957434579062248, "qg_score": null}, {"question": "According to the us state department, how many child slaves were there in cocoa, cotton?", "answer": "15,000", "ae_score": -0.3957434579062248, "qg_score": null}], "content": "In 1998, UNICEF reported that Ivorian farmers were using enslaved children \u2014 many from surrounding countries. A 2000 BBC documentary described child slavery on commercial cocoa farms in C\u00f4te d'Ivoire. In 2001, the US State Department estimated there were 15,000 child slaves in cocoa, cotton, and coffee farms in C\u00f4te d'Ivoire, and the Chocolate Manufacturers Association acknowledged that child slavery is used in the cocoa harvest.\nMalian migrants have long worked on cocoa farms in C\u00f4te d'Ivoire, but in 2000 cocoa prices had dropped to a 10-year low and some farmers stopped paying their employees. The Malian counsel had to rescue boys who had not been paid for five years and who were beaten if they tried to run away. Malian officials believed that 15,000 children, some as young as 11 years old, were working in C\u00f4te d'Ivoire in 2001. These children were often from poor families or the slums and were sold for \"just a few dollars\" to work in other countries. Parents were told the children would find work and send money home, but once the children left home, they often worked in conditions resembling slavery. In other cases, children begging for food were lured from bus stations and sold as slaves.\nIn 2002, C\u00f4te d'Ivoire had 12,000 children with no relatives nearby, which suggested they were trafficked, likely from neighboring Mali, Burkina Faso and Togo. According to a 2009 snowball sampling study, the majority of those with childhood cocoa labor experience were trafficked (75% from Burkina Faso and 63% from Mali). The majority of those who were trafficked had no interaction with police, and only 0.5% had any contact from institutions that provided social services. Western African nations of Cameroon, C\u00f4te d'Ivoire, Ghana and Mali are on the 2009 US State Department's Tier 2 Watch List for human trafficking in part due to the trafficking of children in cocoa production. Burkina Faso and Togo  are rated at Tier 2 in part due to trafficking for cocoa production.\nThe blame for the slavery in cocoa production has been passed from one group to the next. Those who sell the children to the farmers claimed they did not see the slavery. The Ivorian government accused foreigners of using and selling slaves and blamed multinational chocolate companies for keeping cocoa prices low and farmers in poverty; it claimed the low prices forced some farmers to use slave labor. The Ivorian prime minister, Pascal Affi N'Guessan, said the price would need to increase 10 times to ensure a good quality of life for the farmers and their families. Farmers who bought slaves blamed the worldwide cost of cocoa. Cocoa suppliers claimed they cannot manage what happens on the farms. Chocolate companies stated that the suppliers needed to provide cocoa that was not produced by slaves. Consumers did not know that their chocolate was produced using slave labor.\nIn 2001, due to pressure applied by the US Congress and potential US and UK boycotts, the chocolate manufacturers promised to start eliminating forced child labor.In 2012, Ferrero and Mars promised that they will end cocoa slavery by 2020.\nIn December 2014, the U.S. Department of Labor issued a report on labor conditions around the world in which a ''List of Goods Produced by Child Labor or Forced Labor'' mentioned 6 countries (among a total of 74) where the cocoa industry employed underage children and indentured laborers. Instances of child labor were reported in 4 of the listed countries namely Cameroon, Ghana, Guniea and Sierra Leone. The others (C\u00f4te d'Ivoire and Nigeria) resorted to both child labor and forced labor.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Child slavery and trafficking", "sub_heading": "Child slavery and trafficking", "_id": "95--4---1---1", "title": "Child Slavery in Cocoa Production"}
{"qas": [{"question": "Why is the cocoa industry not required to register as a \"slave free\" industry?", "answer": ""}, {"question": "Who criticized the 2012 european union resolution on child labor?", "answer": "International Labor Rights Forum", "ae_score": -0.6956822928887166, "qg_score": null}, {"question": "Who criticized the 2012 european union resolution on child labor?", "answer": "International Labor Rights Forum", "ae_score": -0.6956822928887166, "qg_score": null}], "content": "To combat child slavery in cocoa production, US Representative Eliot Engel introduced a legislative amendment to fund the development of a \"no child slavery\" label for chocolate products sold in the United States. Senator Tom Harkin proposed an addition to an agriculture bill to label qualified chocolate and cocoa products as \"slave free\". It was approved in the House of Representatives by a vote of 291\u2013115, but before it went to the Senate the chocolate makers hired former senators George Mitchell and Bob Dole to lobby against it, and it did not go to a vote. Instead, the chocolate manufacturers reached agreement with the Congressmen to create the Harkin-Engel Protocol to remove child slavery from the industry by July 2005. The voluntary agreement was a commitment by industry groups to develop and implement voluntary standards to certify cocoa produced without the \"worst forms of child labor,\" and was signed by the heads of major chocolate companies, Congressmen, the Ambassador of C\u00f4te d'Ivoire, and others concerned with child labor.\nThe chocolate makers were to create programs in West Africa to make Africans aware of the consequences of child labor, keeping their children from an education, and child trafficking. The primary incentive for the companies' voluntary participation would be the addition of a \"slave free\" label. The 2005 deadline was not met, and all parties agreed to a three-year extension of the Protocol. This extension allowed the cocoa industry more time to implement the Protocol including creating a certification system to address the worst forms of child labor for half of the growing areas in C\u00f4te d'Ivoire and Ghana. By 2008, the industry had collected data forn over half of the areas, as required, but they did not have proper independent verification. In June 2008, the Protocol was extended until the end of 2010. At that time, the industry was required to have full certifications with independent verifications.\nThe European Union passed a resolution in 2012 to fully implement the Harkin-Engel Protocol and fight child labor in cocoa production. The resolution was criticized by the International Labor Rights Forum for having no legally binding measures and two major chocolate manufacturers claimed they were addressing the problem.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Harkin-Engel Protocol", "sub_heading": "Harkin-Engel Protocol", "_id": "95--5---1---1", "title": "The Harkin-Engel Protocol and the Chocolate Industry"}
{"qas": [{"question": "Why is it illegal to import cacao from other countries?", "answer": ""}, {"question": "When did femke halsema file a motion to abolish european imports of?", "answer": "September 2005", "ae_score": -0.8021993861613856, "qg_score": null}, {"question": "When did femke halsema file a motion to abolish european imports of?", "answer": "September 2005", "ae_score": -0.8021993861613856, "qg_score": null}], "content": "In September 2005, Dutch member of parliament Femke Halsema filed a motion to abolish European imports of slave-processed cacao. Statements have been issued by Anti-Slavery International, the Anti-Slavery Society, Fred E. Foldvary, the Organic Consumers Association and StoptheTraffick UK.", "page_name": "Children in cocoa production", "page_id": "Children%20in%20cocoa%20production", "heading": "Position statements and legislation", "sub_heading": "Position statements and legislation", "_id": "95--6---1---1", "title": "Anti-Slavery International, Anti-Slavery International, Fred E. Foldvar"}
{"qas": [{"question": "What does the Greenhouse Ecological Foundation do?", "answer": ""}, {"question": "When was the first sustainable forestry certification program established?", "answer": "1989", "ae_score": -0.32608297086918364, "qg_score": null}, {"question": "When was the first sustainable forestry certification program established?", "answer": "1989", "ae_score": -0.32608297086918364, "qg_score": null}], "content": "The Rainforest Alliance launched the world\u2019s first sustainable forestry certification program in 1989 to encourage market-driven and environmentally and socially responsible management of forests, tree farms, and forest resources. The organization helped to found the Forest Stewardship Council (FSC), the non-profit international body that manages the standard, in 1993. Through its certification arm, RA-Cert, the Rainforest Alliance is accredited to certify forestry operations that meet the FSC's strict environmental, social, and economic standards. Operations that earn certification can use a seal on wood products so consumers know that the wood they are buying comes from forestlands that are managed in a way that conserves biodiversity and ensures the rights of workers and local people. The Rainforest Alliance has certified more than 113 million acres (45.9 million hectares) of forest worldwide, as of 2016, making it the largest FSC certifier of forestlands in the world. The Rainforest Alliance's forest certification program was ranked \"top of the class\" according to \"Wood Products Legality Verification Systems: An Assessment,\" an independent report compiled by Greenpeace, a global environmental organization.\nThe organization also connects certified forestry enterprises to buyers of forest products and provides marketing support for community forestry enterprises. By promoting green building and helping companies that purchase forest products to incorporate sustainability into their sourcing policies, they are also working to increase the demand for certified products.\nThe Rainforest Alliance also provides training and technical assistance to small forestry operations on how to implement sustainable land-management practices (sometimes with the end goal of earning certification) and educates consumer forest products businesses about conservation and certification.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Rainforest Alliance programs", "sub_heading": "Rainforest Alliance programs", "_id": "96--0--0---1", "title": "The Rainforest Alliance is the world\u2019s largest sustainable forest certification program"}
{"qas": [{"question": "What is the Rainforest Alliance?", "answer": ""}, {"question": "Who verifies carbon offset projects in the us?", "answer": "Rainforest Alliance", "ae_score": null, "qg_score": null}, {"question": "Who verifies carbon offset projects in the us?", "answer": "Rainforest Alliance", "ae_score": null, "qg_score": null}], "content": "The organization verifies carbon offset projects to standards that address greenhouse gas sequestration,  biodiversity conservation and sustainable livelihoods.  The Rainforest Alliance verifies projects to the American Carbon Registry Standard, the Carbon Fix Standard, the Climate Action Reserve Standard, the CDM Gold Standard, the Verified Carbon Standard, the standards of the Climate, Community & Biodiversity Alliance, the Chicago Climate Exchange and Plan Vivo.  As of 2015, 10,756,000 acres (4,352,800 hectares) have been protected by forest carbon projects that have been verified or validated by the Rainforest Alliance\u2014removing or avoiding greenhouse gas emissions equivalent to those produced by 7.13 million cars in one year.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Rainforest Alliance programs", "sub_heading": "Carbon offset verification", "_id": "96--0--1---1", "title": "Rainforest Alliance Verifies Forest Carbon Projects to Standards"}
{"qas": [{"question": "What criteria do farmers need to meet in order to become certified as a conservationist?", "answer": ""}, {"question": "What percentage of criteria must be met in order to be certified by the rainforest alliance?", "answer": "50%", "ae_score": -0.3071837501308482, "qg_score": null}, {"question": "What percentage of criteria must be met in order to be certified by the rainforest alliance?", "answer": "50%", "ae_score": -0.3071837501308482, "qg_score": null}], "content": "The Rainforest Alliance's sustainable agriculture program includes training programs for farmers and the certification of small, medium and large farms that produce more than 100 different crops, including avocado, cattle, cinnamon, coffee, palm oil, and potatoes, as well as tea, cocoa, and bananas. In recent years, the Rainforest Alliance has greatly expanded its work with smallholders, who now account for 75% of the farms (more than 783,000 farmers in all) certified by the organization. To obtain certification, farms must meet the Sustainable Agriculture Network (SAN) standard, which is designed to conserve ecosystems, protect biodiversity and waterways, conserve forests, reduce agrochemical use, and safeguard the well-being of workers and local communities. The Rainforest Alliance certified the first banana plantation in 1993, the independent banana farm Platanera Rio Sixaola in Bribri, Costa Rica, owned by Volker Ribniger. By 2000, all Chiquita-owned banana farms in Latin America had earned Rainforest Alliance certification. Daniel Esty, professor of environmental science and policy at Yale University, and Andrew Winston, director of the corporate environmental strategy project at Yale University, reports that Chiquita spent $20 million over ten years to bring its farms up to Rainforest Alliance standards. Esty and Winston call the Chiquita - Rainforest Alliance partnership \"one of the most strategic and effective in the world.\"[6]Unilever, the world's largest tea company, committed to have all of its Lipton tea plantations Rainforest Alliance Certified by 2015.[7] The Rainforest Alliance is a member of the Sustainable Agriculture Network (SAN), an international group works to promote and increase the use of sustainable agricultural practices and manage the certification program. The Rainforest Alliance encourages businesses and consumers to support sustainable agriculture by source or choose products grown on certified farms. More than 1.2 million farms and cooperatives across more than 42 countries\u2014covering nearly 8.6 million acres (3.5 million hectares) of land\u2014are being managed sustainably under Rainforest Alliance certification, as of 2015.\nThe organization requires that 50% of criteria under a certain principle (group of criteria) be achieved, and 80% overall. Several of these criteria are \"critical\" and must be complied with for a farm to earn certification. They include an ecosystem conservation program, protection of wild animals and waterways, the prohibition of discrimination in work and hiring practices, the prohibition of contracting children under the age of 15, the use of protective gear for workers, guidelines about agrochemical use and the prohibition of transgenic crops.\nThe Rainforest Alliance Certified Seal appears only on products that meet the crop standards and criteria detailed above. According to ''Consumer Reports'', \"The Rainforest Alliance Certified label is clear and meaningful in support of sustainable agriculture, social responsibility and integrated pest management. The label is consistent in meaning among all certified. The label does not consist of farmers and none of the members are certified by the Rainforest Alliance. In this sense, the organizations behind these labels are independent from the products they certify.\" In February 2008, ''Ethical Corporation'' called Rainforest Alliance certification a \"rigorous, independently verified scheme\". As of 2015, more than 4,300 companies buy or sell products from Rainforest Alliance Certified farms, and the Rainforest Alliance Certified seal can be seen in more than 120 countries. As of June 2015, 13.6 percent of the world\u2019s cocoa, 5.4 percent of coffee and 15.1 percent of tea comes from Rainforest Alliance Certified farms.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Rainforest Alliance programs", "sub_heading": "Sustainable agriculture certification", "_id": "96--0--2---1", "title": "The Rainforest Alliance Certified Farms"}
{"qas": [{"question": "What does the Tourism Council of the Americas do?", "answer": ""}, {"question": "When did the rainforest alliance start their sustainable tourism program?", "answer": "2000", "ae_score": -0.32777316959592573, "qg_score": null}, {"question": "When did the rainforest alliance start their sustainable tourism program?", "answer": "2000", "ae_score": -0.32777316959592573, "qg_score": null}], "content": "The organization launched a sustainable tourism program in 2000 and provides small- and medium-sized tourism businesses in Latin America with training and tools to minimize their impacts on the environment and local communities. In addition to awarding the Rainforest Alliance Certified seal to those tourism businesses that meet the organization\u2019s standards, the Rainforest Alliance also provides training, technical assistance and marketing support to certified businesses and businesses in the process of becoming certified. More than 10,000 employees of tourism businesses in Mexico and Costa Rica have participated in the organization\u2019s sustainability training. In addition, they work internationally to create partnerships with tour operators (hotels,lodges, travel agents, etc...) to green all elements of the tourism supply chain. In March 2008, the Discovery Channel noted that \"the Rainforest Alliance has been a leader in developing a sort of meta-analysis of the various programs operating in the Americas - possibly leading to a world-wide standard for what ecotourism ought to achieve.\"\nThe organization also works to integrate sustainable tourism certification programs in the Americas, through a coalition known as Sustainable Tourism Certification Network of the Americas. The mission of the Network is to promote sustainable tourism in the region through strengthening tourism initiatives based on mutual respect and recognition, joint efforts, harmonizing systems, and sharing information and experience.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Rainforest Alliance programs", "sub_heading": "Sustainable tourism", "_id": "96--0--3---1", "title": "Sustainable Tourism Certification Network of the Americas (STNA)"}
{"qas": [{"question": "What is the purpose of the World Wildlife Fund?", "answer": ""}, {"question": "How many teachers are in the rainforest alliance?", "answer": "5,700", "ae_score": -0.27583138892408776, "qg_score": null}, {"question": "How many teachers are in the rainforest alliance?", "answer": "5,700", "ae_score": -0.27583138892408776, "qg_score": null}], "content": "The organization works to help people of all ages understand the role that every person plays in biodiversity conservation. They do this through their education site\u2014developed in conjunction with education experts\u2014and their Adopt-a-Rainforest program. They also work with schools in the US and around the world, to help teachers implement the lesson plans. As of June 2015, 5,700 teachers have been trained in the environmental curricula, and more than 84,000 students have studied it.\nThe organization developed free, on-line curricula that offer complete lesson plans, stories (in English, Spanish and Portuguese), presentations, posters and articles about societies and flora and fauna in Latin America, plus on-the-ground conservation projects for kindergarten through eighth grade. As of June 2015, the Learning Site has received more than 2.66 million visitors.\nThrough the Rainforest Alliance's Adopt-A-Rainforest program, individuals and school groups can donate money to support the programs described in the lesson plans. These donations can be made on the Rainforest Alliance website which describes exactly where the money goes and offers fundraising ideas.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Rainforest Alliance programs", "sub_heading": "Education program", "_id": "96--0--4---1", "title": "Rainforest Alliance \u2014 Adopt-a-Rainforest"}
{"qas": [{"question": "What is the Rainforest Alliance?", "answer": ""}, {"question": "What is the name of the agreement signed by the rainforest alliance?", "answer": "New York Declaration on Forests", "ae_score": -0.5468734395175393, "qg_score": null}, {"question": "What is the name of the agreement signed by the rainforest alliance?", "answer": "New York Declaration on Forests", "ae_score": -0.5468734395175393, "qg_score": null}], "content": "The Rainforest Alliance is also a signatory of the New York Declaration on Forests, a UN-sponsored voluntary agreement to cut deforestation from business, government, and organization supply chains. The Declaration also recognizes the ecosystem services provided by forests, and the role forests play in mitigating climate change.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "New York Declaration on Forests", "sub_heading": "New York Declaration on Forests", "_id": "96--2---1---1", "title": "Rainforest Alliance is a signatory of the New York Declaration on Forests"}
{"qas": [{"question": "How did the world become the first place to start a sustainable farming industry?", "answer": ""}, {"question": "Who is the president of the rainforest alliance?", "answer": "Nigel Sizer", "ae_score": -0.058412763334749415, "qg_score": null}, {"question": "Who is the president of the rainforest alliance?", "answer": "Nigel Sizer", "ae_score": -0.058412763334749415, "qg_score": null}], "content": "'''1987- 1988'''\u2022 Rainforest Alliance is incorporated. First large-scale conference on rainforest destruction is held.\n'''1989'''\u2022 Rainforest Alliance\u2019s SmartWood program is founded.\n'''1990'''\u2022 SmartWood certifies its first forest in Indonesia.\u2022 Banana standards are introduced and sustainable agriculture program, initially called ECO-O.K is launched.\n'''1991'''\u2022 Forests in Honduras, Mexico and Belize are certified.\n'''1992 - 1993'''\u2022 Adopt-A-Rainforest is launched to channel donations to grassroots conservation projects in Latin America.\u2022 First Rainforest Alliance agriculture certification goes to two banana farms in Costa Rica and Hawaii.\u2022 Forest Stewardship Council, an international sustainable forestry management accreditation body, is established.\n'''1994'''\u2022 SmartWood expands to temperate and boreal forests in the US and Canada.\u2022 The first two Chiquita-owned banana farms are certified.\n'''1995'''\u2022 First coffee farms are certified in Guatemala.\u2022 The Rainforest Alliance receives the Peter F. Drucker Award for Non-profit Innovation.\n'''1996'''\u2022 SmartWood Rediscovered for reuse of old wood is launched.\u2022 SmartWood certifies forestlands owned by indigenous peoples in Mexico and Wisconsin.\u2022 Work with Gibson USA results in the world\u2019s first certified guitars.\n'''1997'''\u2022 All Chiquita-owned farms in Costa Rica become Rainforest Alliance Certified. Chiquita commits to certifying all its farms throughout Latin America.\u2022 Cocoa program is launched in partnership with Conservaci\u00f3n y Desarrollo.\u2022 First Rainforest Alliance certification of citrus groves goes to Del Oro in Northwestern Costa Rica.\n'''1998'''\u2022 The Conservation Agriculture Network, later renamed the Sustainable Agriculture Network, is formed to develop guidelines for sustainable farming.\u2022 First shade-grown cocoa certification awarded to El Progreso cooperative in Ecuador.\n'''1999'''\u2022 SmartWood certifies its first non-timber forest products operation.\u2022 The Coffee and Biodiversity Project is launched to address environmental degradation in El Salvador by using shade-grown coffee farms to buffer ecologically sensitive land.\u2022 Rainforest Alliance receives the American Society of Association Executives (ASAE) Gold Circle Award for excellence in nonprofit communications.\n'''2000'''\u2022 Daniel Katz steps down as executive director and becomes board chairman. Tensie Whelan becomes executive director of the organization.\u2022 SmartWood certifies all of New York State\u2019s multiple-use public forestlands. In Guatemala\u2019s Maya Biosphere Reserve, five community forestry operations are certified.\u2022 Fifteen percent of bananas in trade are grown on Rainforest Alliance Certified farms.\u2022 SmartVoyager tourism certification is launched in partnership with Conservaci\u00f3n y Desarrollo.\n'''2001'''\u2022 SmartWood certifications expand to include municipal forests, state parks, maple syrup, pencils and snowboards.\u2022 100 percent certification of Chiquita's company-owned farms earn certification.\u2022 Fern and flower certification program is launched in Colombia, Ecuador and Costa Rica.\u2022 Training Research Extension Education Systems (TREES) program is established to give small, community and indigenous forestry operations access to certification.\n'''2002'''\u2022 Twelve hundred companies and cooperatives have adopted Rainforest Alliance sustainable practices.\u2022 SmartWood expands certification to Estonia, Latvia and Lithuania.\u2022 First two banana farms in South-east Asia.\u2022 The first nine fern farms are certified in Costa Rica.\n'''2003'''\u2022 Total area of certified forestland reaches 25 million acres (100,000 km\u00b2).SmartWood certifies its first US company, the first North America boreal forest, the first certification in Russia and the largest certified forest in Japan.\u2022 Sustainable Tourism Certification Network of the Americas is established to accredit tourism certification programs.\u2022 Rainforest Alliance Learning Site is launched.\n'''2004'''\u2022 Total area of forests certified reaches 33 million acres (130,000 km\u00b2).\u2022 Total combined area of certified coffee farms roughly doubles over 2003 levels\u2014from 46,000 to 93,000 acres (190 to 380 km\u00b2).\u2022 Procter & Gamble's introduction of Millstone Rainforest Reserve coffee in the US and Kraft's launch of Kenco Rainforest Alliance Certified coffee in the UK. Gloria Jean's entire line of flavored coffees is certified. Certified coffee becomes available in Belgium, Japan and Canada.\u2022 \"Cupping for Quality\" is the first formal coffee competition where the emerging field of \"certified-sustainable\" coffee receives gourmet evaluation by leading coffee experts.\u2022 Certified Sustainable Products Alliance is launched with the aim of bringing to market increased quantities of sustainable bananas, coffee and timber.\n'''2005'''\u2022 JP Morgan, Citigroup, Johnson & Johnson, McDonald's, Nike, the HSBC Bank and others print their annual and corporate social responsibility reports on certified paper.\u2022 Certified coffee production doubles over 2004 levels.\u2022 Rainforest Alliance Certified coffee wins first place in the World Barista Championship and the second \"Cupping for Quality\" event.\u2022 Chiquita sells 50 million bananas bearing the Rainforest Alliance Certified seal each week in nine European countries.\n'''2006'''\u2022 The area of Forest Stewardship Council/Rainforest Alliance Certified forestland reaches 100 million acres (400,000 km\u00b2).\u2022 Certified coffee volumes double again for the third year in a row.\u2022 First African coffee farms are certified in Ethiopia.\u2022 Launch of African cocoa program in C\u00f4te d'Ivoire.\u2022 Launch of Migratory Species Pathway.\u2022 Pineapple certification criteria are established.\n'''2007'''\u2022 Launch of standards for tea \u2014 Unilever announces that it is converting all the tea used in its Lipton and PG Tips brands to Rainforest Alliance certified sources. Certification will start in Kenya.\n'''2008'''\u2022 McDonald's New Zealand and Australia switches all McCafe restaurants to Rainforest Alliance Certified coffee beans.\u2022 Develops Global Sustainable Tourism Criteria, partnering with the UN Environment Programme, the UN Foundation and the UN World Tourism Organization to lead a coalition of more than 50 organizations around the world. \u2022 Costa Coffee becomes the first large coffee chain to source all of its beans from certified farms.\n'''2009''' \u2022 Mars, Inc. commits to using only cocoa from certified sustainable farms by 2020. \u2022 Nestl\u00e9 Nespresso commits to bringing 80 percent of the farmers that grow its coffee into the company's AAA program, which includes Rainforest Alliance certification standards. \u2022 Rainforest Alliance becomes the first FSC-certifier to be fully accredited under the Voluntary Carbon Standard (VCS), allowing it to carry out VCS validations and verifications of carbon projects.\n'''2010''' \u2022 Launches SustainableTrip.org, a trilingual database of sustainable hotels and tour operators in Latin America and the Caribbean.\u2022 Tata Global Beverages commits to sourcing all of its Tetley brand tea from Rainforest Alliance Certified farms.\u2022 Validates its first carbon project in Africa.\u2022 Launches a standard for sustainable cattle farms.All of the coffee served on American Airlines flights is from Rainforest Alliance Certified farms.\n'''2011''' \u2022 El Platanillo in Guatemala becomes the world\u2019s first Rainforest Alliance Certified coffee farm to comply with climate-friendly criteria. \u2022 Launches Tour Operators Promoting Sustainability (TOPS), a global network of eco-conscious tour operators.\n'''2012'''\u2022 Caribou Coffee becomes the first major coffeehouse to use only Rainforest Alliance certified coffee beans.\u2022 Begins certifying the sustainable production of spices.\u2022 Launches \u201cShop the Frog\u201d an online directory of Rainforest Alliance Certified products and brands available around the world.\n'''2013'''\u2022 Launches Climate, Nature and Communities in Guatemala (CNCG), a national initiative to provide training to communities, small- and medium-sized forest enterprises, and government institutions to help them adapt to the effects of climate change.\u2022 Italian fashion giant Gucci creates the world's first handbags made with leather from Rainforest Alliance Certified\u2122 cattle ranches.\u2022 Rainforest Alliance Certified\u2122 cocoa reaches 10 percent of global market share.\u2022 The organization\u2019s new headquarters in New York City earn Forest Stewardship Council\u2122 Partial Project certification, making it the first building in the region to achieve this distinction.\u2022 Launches the Sustainable Finance Initiative to increase access to credit by smallholder farmers.\n'''2014'''\u2022 The number of Rainforest Alliance Certified\u2122 coffee farms in Central America that have achieved climate-smart verification reaches 200 in just two years\n\u2022 Collaborates with GRAMMY Award-winning artists Caetano Veloso, Lenine and others on I\u2019m Alive, a music and film project narrated by Brazilian supermodel and Rainforest Alliance Board Member Gisele B\u00fcndchen\n\u2022 Fundo Teresita in Peru becomes first pomegranate producer in Latin America to achieve Rainforest Alliance certification\u2022 Collaborated with the Ecuadorian government to protect nature reserves throughout the country, and this work is being replicated across the Andean Amazon region of South America\n'''2015'''\u2022 Announces the Appalachian Woodlands Alliance\u2014funded by a $1.35 million combined investment from Avery Dennison, Columbia Forest Products, Domtar and Staples, Inc.\u2014focused on promoting sustainable forestry in the southeastern United States\n'''2016'''\u2022 Nigel Sizer hired as President", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Timeline", "sub_heading": "Timeline", "_id": "96--3---1---1", "title": "'''1920''' \u2014 Rainforest Alliance"}
{"qas": [{"question": "What is the difference between a $1.00 minimum wage and a $0.01 minimum wage?", "answer": ""}, {"question": "What is the name of the program that allows farmers to receive no less than a predetermined?", "answer": "Minimum price programs", "ae_score": -0.2692904378898921, "qg_score": null}, {"question": "What is the name of the program that allows farmers to receive no less than a predetermined?", "answer": "Minimum price programs", "ae_score": -0.2692904378898921, "qg_score": null}], "content": "Rainforest Alliance sustainable agriculture certification, like the certification schemes UTZ Certified and organic,  does not offer producers minimum or guaranteed price, therefore leaving them vulnerable to market price variations: as an example, in the 1980s, a pound of standard-grade coffee sold for around US $1.20. In 2003, a pound sold for about $0.50, which was not enough to cover the costs of production in much of the world. The price of coffee has since rebounded somewhat, with prices for arabica reaching $1.18/pound by the end of 2007.  (It should be noted, however, that Fair Trade\u2019s minimum pricing requirements have come under criticism as well, notably for lack of evidence that Fair Trade farmers actually receive higher prices.)\nThe Rainforest Alliance counters that a system that focuses primarily on pricing misses out on a number of other critical elements that influence whether or not a farmer can transcend poverty and sustain future generations on the land. For example, price-based systems depend on the willingness of customers to pay premiums for certified products. But this approach is of little use to farmers who cannot reach such buyers. Others, including UTZ, another certification system, have argued that price minimums distort the market, which is an important force in scaling up good practices. Maximizing yields and protecting the long-term health of the land are critical to the economic sustainability of any certification system.\nAlthough many Rainforest Alliance Certified farms do in fact achieve price premiums for high-quality product, Rainforest Alliance focuses on improving the entire spectrum of farming practices. Third-party studies have shown the organization\u2019s approach to be effective in raising both income and net revenue for farmers.\nMichigan State University professor of sociology Daniel Jaffee has criticized Rainforest Alliance certification, claiming that its standards are \"arguably far lower than fair trade's\" and saying \"they establish minimum housing and sanitary conditions but do not stipulate a minimum price for coffee. Critically, they require plantation owners only to pay laborers the national minimum wage, a notoriously inadequate standard.\"\n''The Economist'' favors the Rainforest Alliance's method and notes that \"guaranteeing a minimum price [as Fairtrade does] means there is no incentive to improve quality.\" They also note that coffee drinkers say \"the quality of Fairtrade brews varies widely. The Rainforest Alliance does things differently. It does not guarantee a minimum price or offer a premium but provides training advice. That consumers are often willing to pay more for a product with the [Rainforest Alliance] logo on it is an added bonus, not the result of a formal subsidy scheme; such products must still fend for themselves in the marketplace.\"\nMinimum price programs, which ensure that farmers receive no less than a given, predetermined amount, regardless of the commodity price, have been criticized by some economists as artificially manipulating markets and counter-intuitively limiting the impact of minimum price goods, by making them too expensive for some consumers to afford.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Criticism and response", "sub_heading": "Criticism and response", "_id": "96--4--0---1", "title": "Rainforest Alliance and Fair Trade \u2014 What\u2019s the Rainforest Alliance\u2019s"}
{"qas": [{"question": "What is the purpose of the \"Certificate of Agribusiness\" on food products?", "answer": ""}, {"question": "Who owns the rights to the rainforest alliance?", "answer": "World Wildlife Fund", "ae_score": -0.23580668461708548, "qg_score": null}, {"question": "Who owns the rights to the rainforest alliance?", "answer": "World Wildlife Fund", "ae_score": -0.23580668461708548, "qg_score": null}], "content": "The organization certification has been criticized for allowing the use of the seal on products containing a minimum of 30% of certified content. According to Michael Conroy, former chairman of the board for Fair Trade USA,  this use of the seal is the \"most damaging dimension\" of [Rainforest Alliance's] agricultural certification program and \"a serious blow to the integrity of certification\".\nConsumer Reports counters Conroy's implication that the Rainforest Alliance Certified seal is misleading. Consumer Reports classifies the Rainforest Alliance Certified seal on agricultural products as \"somewhat meaningful,\" and the Rainforest Alliance Certified seal is endorsed by the World Wildlife Fund.\nThe Rainforest Alliance responds that a greater positive impact on the ground can be made by engaging with companies of all sizes and offering 30% as an entry point. A large company that agrees to source at 30% can have a greater scale of impact due to higher product volume (e.g. 30% of 1,000 tons is substantially more than 100% of 100 tons). The entry point is also intended to address limited availability of certain products, since in some cases, years of work are required to train and certify enough farms to meet a large company's commodity needs.\nThe organization requires companies to increase quantities of certified ingredients to 100% certified content over time, and maintains a database detailing these commitments. The organization also requires companies to clearly disclose the percentage of Rainforest Alliance Certified content if it is less than 90%.", "page_name": "Rainforest Alliance", "page_id": "Rainforest%20Alliance", "heading": "Criticism and response", "sub_heading": "Use of seal", "_id": "96--4--1---1", "title": "The Rainforest Alliance Certified Seal is Misleading"}
{"qas": [{"question": "Why are Toll House cookies called Toll House Cookies?", "answer": ""}, {"question": "Who invented the first chocolate chip cookie in 1937?", "answer": "Ruth Graves Wakefield", "ae_score": -0.21241474647171293, "qg_score": null}, {"question": "Who invented the first chocolate chip cookie in 1937?", "answer": "Ruth Graves Wakefield", "ae_score": -0.21241474647171293, "qg_score": null}], "content": "Chocolate chips are a required ingredient in chocolate chip cookies, which were invented in 1937 when Ruth Graves Wakefield of the Toll House Inn in the town of Whitman, Massachusetts added cut-up chunks of a semi-sweet Nestl\u00e9 chocolate bar to a cookie recipe. The cookies were a huge success, and Wakefield reached an agreement in 1939 with Nestl\u00e9 to add her recipe to the chocolate bar's packaging in exchange for a lifetime supply of chocolate. Initially, Nestl\u00e9 included a small chopping tool with the chocolate bars. In 1941 Nestl\u00e9 and one or more of its competitors started selling the chocolate in chip (or \"morsel\") form. The Nestl\u00e9 brand Toll House cookies is named for the inn.", "page_name": "Chocolate chip", "page_id": "Chocolate%20chip", "heading": "Origin", "sub_heading": "Origin", "_id": "97--0---1---1", "title": "Chocolate Chip Cookies"}
{"qas": [{"question": "Why are chocolate chips called chocolate chips?", "answer": ""}, {"question": "What are chocolate chips made out of?", "answer": "semi-sweet chocolate", "ae_score": -0.5965153412345053, "qg_score": null}, {"question": "What are chocolate chips made out of?", "answer": "semi-sweet chocolate", "ae_score": -0.5965153412345053, "qg_score": null}], "content": "Originally, chocolate chips were made of semi-sweet chocolate, but today there are many flavors. These include bittersweet chocolate chips, peanut butter chips, butterscotch chips, mint chocolate chips, white chocolate chips, dark chocolate chips, milk chocolate chips, and white and dark swirled chocolate chips.", "page_name": "Chocolate chip", "page_id": "Chocolate%20chip", "heading": "Types", "sub_heading": "Types", "_id": "97--1---1---1", "title": "Chocolate Chips \u2014 Chocolate Chips"}
{"qas": [{"question": "What are chocolate chips and how do they work?", "answer": ""}, {"question": "What is the name of the chip in pancakes?", "answer": "Chocolate chips", "ae_score": -0.2122422049518838, "qg_score": null}, {"question": "What is the name of the chip in pancakes?", "answer": "Chocolate chips", "ae_score": -0.2122422049518838, "qg_score": null}], "content": "Chocolate chips can be used in cookies, pancakes, waffles, cakes, pudding, muffins, cr\u00eapes, pies, hot chocolate, and various types of pastry. They are also found in many other retail food products such as granola bars, ice cream, and trail mix.\nChocolate chips can also be melted and used in sauces and other recipes. The chips melt best at temperatures between 104 and. The melting process starts at around 90 \u00b0F when the cocoa butter in the chips starts to heat. The cooking temperature must never exceed 115 \u00b0F (for milk and white) or 120 \u00b0F (for dark) or the chocolate will burn. Although convenient, melted chocolate chips are not always recommended as a substitute for melted baking chocolate. Because most chocolate chips are designed to retain their shape when baking, they contain less cocoa butter than baking chocolate. This can make them more difficult to work with in melted form. ", "page_name": "Chocolate chip", "page_id": "Chocolate%20chip", "heading": "Uses", "sub_heading": "Uses", "_id": "97--2---1---1", "title": "Chocolate Chips \u2014 The Best Chocolate Chips"}
{"qas": [{"question": "Why are chocolate chips so popular in the US?", "answer": ""}, {"question": "What is the name of the chocolate chip company?", "answer": "Hershey Company", "ae_score": -0.4866798096024731, "qg_score": null}, {"question": "What is the name of the chocolate chip company?", "answer": "Hershey Company", "ae_score": -0.4866798096024731, "qg_score": null}], "content": "In the 2010s, chocolate chips are popular as a baking ingredient in the United States and the chocolate chip cookie is regarded as a quintessential American dessert. Chocolate chips are also widely available in Australia and Canada, and (less commonly) in Europe, and other parts of the world. Nestl\u00e9 and The Hershey Company are among the top producers of chocolate chips.", "page_name": "Chocolate chip", "page_id": "Chocolate%20chip", "heading": "Availability", "sub_heading": "Availability", "_id": "97--3---1---1", "title": "Chocolate Chips \u2014 The World\u2019s Most Popular Dessert Ingredient"}
{"qas": [{"question": "What is the difference between carbohydrate and carbohydrate?", "answer": ""}, {"question": "What is the name for simple carbohydrates with a general formula (CHO) where n is?", "answer": "monosaccharides", "ae_score": -0.34975973675452005, "qg_score": null}, {"question": "What is the name for simple carbohydrates with a general formula (CHO) where n is?", "answer": "monosaccharides", "ae_score": -0.34975973675452005, "qg_score": null}], "content": "Formerly the name \"carbohydrate\" was used in chemistry for any compound with the formula C (HO). Following this definition, some chemists considered formaldehyde (CHO) to be the simplest carbohydrate,<ref name=\"coulter\">\nNatural saccharides are generally built of simple carbohydrates called monosaccharides with general formula (CHO) where ''n'' is three or more. A typical monosaccharide has the structure H\u2013(CHOH)(C=O)\u2013(CHOH)\u2013H, that is, an aldehyde or ketone with many hydroxyl groups added, usually one on each carbon atom that is not part of the aldehyde or ketone functional group. Examples of monosaccharides are glucose, fructose, and glyceraldehydes. However, some biological substances commonly called \"monosaccharides\" do not conform to this formula (e.g. uronic acids and deoxy-sugars such as fucose) and there are many chemicals that do conform to this formula but are not considered to be monosaccharides (e.g. formaldehyde CHO and inositol (CHO)).<ref>\nThe open-chain form of a monosaccharide often coexists with a closed ring form where the aldehyde/ketone carbonyl group carbon (C=O) and hydroxyl group (\u2013OH) react forming a hemiacetal with a new C\u2013O\u2013C bridge.\nMonosaccharides can be linked together into what are called polysaccharides (or oligosaccharides) in a large variety of ways. Many carbohydrates contain one or more modified monosaccharide units that have had one or more groups replaced or removed. For example, deoxyribose, a component of DNA, is a modified version of ribose; chitin is composed of repeating units of N-acetyl glucosamine, a nitrogen-containing form of glucose.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Structure", "sub_heading": "Structure", "_id": "98--0---1---1", "title": "Monosaccharides and Polysaccharides in Chemistry"}
{"qas": [{"question": "What is the difference betweenDP and DPM?", "answer": ""}, {"question": "How many principal groups are carbohydrates typically divided into?", "answer": "three", "ae_score": null, "qg_score": null}, {"question": "How many principal groups are carbohydrates typically divided into?", "answer": "three", "ae_score": null, "qg_score": null}], "content": "Carbohydrates are polyhydroxy aldehydes, ketones, alcohols, acids, their simple derivatives and their polymers having linkages of the acetal type. They may be classified according to their degree of polymerization and may be divided initially into three principal groups, namely sugars, oligosaccharides and polysaccharides\nDP * = Degree of polymerization", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Division", "sub_heading": "Division", "_id": "98--1---1---1", "title": "Carbohydrates are carbohydrates, sugars, oligosaccharides,"}
{"qas": [{"question": "How do monosaccharide formulas work?", "answer": ""}, {"question": "What are monosaccharides with 3 carbon atoms called?", "answer": "trioses", "ae_score": -0.9893198275446595, "qg_score": null}, {"question": "What are monosaccharides with 3 carbon atoms called?", "answer": "trioses", "ae_score": -0.9893198275446595, "qg_score": null}], "content": "Monosaccharides are classified according to three different characteristics: the placement of its carbonyl group, the number of carbon atoms it contains, and its chiral handedness. If the carbonyl group is an aldehyde, the monosaccharide is an aldose; if the carbonyl group is a ketone, the monosaccharide is a ketose. Monosaccharides with three carbon atoms are called trioses, those with four are called tetroses, five are called pentoses, six are hexoses, and so on. These two systems of classification are often combined. For example, glucose is an aldohexose (a six-carbon aldehyde), ribose is an aldopentose (a five-carbon aldehyde), and fructose is a ketohexose (a six-carbon ketone).\nEach carbon atom bearing a hydroxyl group (-OH), with the exception of the first and last carbons, are asymmetric, making them stereo centers with two possible configurations each (R or S). Because of this asymmetry, a number of isomers may exist for any given monosaccharide formula. Using Le Bel-van't Hoff rule, the aldohexose D-glucose, for example, has the formula (C\u00b7HO), of which four of its six carbons atoms are stereogenic, making D-glucose one of 2=16 possible stereoisomers. In the case of glyceraldehydes, an aldotriose, there is one pair of possible stereoisomers, which are enantiomers and epimers. 1, 3-dihydroxyacetone, the ketose corresponding to the aldose glyceraldehydes, is a symmetric molecule with no stereo centers. The assignment of D or L is made according to the orientation of the asymmetric carbon furthest from the carbonyl group: in a standard Fischer projection if the hydroxyl group is on the right the molecule is a D sugar, otherwise it is an L sugar. The \"D-\" and \"L-\" prefixes should not be confused with \"d-\" or \"l-\", which indicate the direction that the sugar  rotates plane polarized light. This usage of \"d-\" and \"l-\" is no longer followed in carbohydrate chemistry.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Monosaccharides", "sub_heading": "Monosaccharides", "_id": "98--2--0---1", "title": "Monosaccharides \u2014 Molecular Structures"}
{"qas": [{"question": "How does monosaccharide work?", "answer": ""}, {"question": "What are the possible pair of stereoisomers called?", "answer": "anomers", "ae_score": -0.5208474429585784, "qg_score": null}, {"question": "What are the possible pair of stereoisomers called?", "answer": "anomers", "ae_score": -0.5208474429585784, "qg_score": null}], "content": "The aldehyde or ketone group of a straight-chain monosaccharide will react reversibly with a hydroxyl group on a different carbon atom to form a hemiacetal or hemiketal, forming a heterocyclic ring with an oxygen bridge between two carbon atoms. Rings with five and six atoms are called furanose and pyranose forms, respectively, and exist in equilibrium with the straight-chain form.\nDuring the conversion from straight-chain form to the cyclic form, the carbon atom containing the carbonyl oxygen, called the anomeric carbon, becomes a stereogenic center with two possible configurations: The oxygen atom may take a position either above or below the plane of the ring. The resulting possible pair of stereoisomers is called anomers. In the ''\u03b1 anomer'', the -OH substituent on the anomeric carbon rests on the opposite side (trans) of the ring from the CHOH side branch. The alternative form, in which the CHOH substituent and the anomeric hydroxyl are on the same side (cis) of the plane of the ring, is called the ''\u03b2 anomer''.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Monosaccharides", "sub_heading": "Ring-straight chain isomerism", "_id": "98--2--1---1", "title": "'' anomer'' is a heterocyclic ring with an"}
{"qas": [{"question": "What is the difference between monosaccharides and carbohydrates?", "answer": ""}, {"question": "What is the major source of fuel for metabolism?", "answer": "Monosaccharides", "ae_score": -0.45494822958403797, "qg_score": null}, {"question": "What is the major source of fuel for metabolism?", "answer": "Monosaccharides", "ae_score": -0.45494822958403797, "qg_score": null}], "content": "Monosaccharides      are the major source of fuel for metabolism, being used both as an energy source (glucose being the most important in nature) and in biosynthesis. When monosaccharides are not immediately needed by many cells they are often converted to more space-efficient forms, often polysaccharides. In many animals, including humans, this storage form is glycogen, especially in liver and muscle cells. In plants, starch is used for the same purpose. The most abundant carbohydrate, cellulose, is a structural component of the cell wall of plants and many forms of algae. Ribose is a component of RNA. Deoxyribose is a component of DNA. Lyxose is a component of lyxoflavin found in the human heart. Ribulose and xylulose occur in the pentose phosphate pathway. Galactose, a component of milk sugar lactose, is found in galactolipids in plant cell membranes and in glycoproteins in many tissues. Mannose occurs in human metabolism, especially in the glycosylation of certain proteins. Fructose, or fruit sugar, is found in many plants and in humans, it is metabolized in the liver, absorbed directly into the intestines during digestion, and found in semen. Trehalose, a major sugar of insects, is rapidly hydrolyzed into two glucose molecules to support continuous flight.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Monosaccharides", "sub_heading": "Use in living organisms", "_id": "98--2--2---1", "title": "Monosaccharides in the Human Body"}
{"qas": [{"question": "What is the difference between sucrose and fructose?", "answer": ""}, {"question": "What is the most abundant disaccharide in plants?", "answer": "Sucrose", "ae_score": -0.08271256082306246, "qg_score": null}, {"question": "What is the most abundant disaccharide in plants?", "answer": "Sucrose", "ae_score": -0.08271256082306246, "qg_score": null}], "content": "Two joined monosaccharides are called a disaccharide and these are the simplest polysaccharides. Examples include sucrose and lactose. They are composed of two monosaccharide units bound together by a covalent bond known as a glycosidic linkage formed via a dehydration reaction, resulting in the loss of a hydrogen atom from one monosaccharide and a hydroxyl group from the other. The formula of unmodified disaccharides is CHO. Although there are numerous kinds of disaccharides, a handful of disaccharides are particularly notable.\nSucrose, pictured to the right, is the most abundant disaccharide, and the main form in which carbohydrates are transported in plants. It is composed of one D-glucose molecule and one D-fructose molecule. The systematic name for sucrose, ''O''-\u03b1-D-glucopyranosyl-(1\u21922)-D-fructofuranoside, indicates four things:\nLactose, a disaccharide composed of one D-galactose molecule and one D-glucose molecule, occurs naturally in mammalian milk. The systematic name for lactose is ''O''-\u03b2-D-galactopyranosyl-(1\u21924)-D-glucopyranose. Other notable disaccharides include maltose (two D-glucoses linked \u03b1-1,4) and cellulobiose (two D-glucoses linked \u03b2-1,4). Disaccharides can be classified into two types: reducing and non-reducing disaccharides. If the functional group is present in bonding with another sugar unit, it is called a reducing disaccharide or biose.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Disaccharides", "sub_heading": "Disaccharides", "_id": "98--3---1---1", "title": "Disaccharides: The most abundant polysaccharides"}
{"qas": [{"question": "What is the difference between a carbohydrate and a complex carbohydrate?", "answer": ""}, {"question": "What is a measure of how quickly food glucose is absorbed?", "answer": "glycemic index", "ae_score": -0.7611836465018988, "qg_score": null}, {"question": "What is a measure of how quickly food glucose is absorbed?", "answer": "glycemic index", "ae_score": -0.7611836465018988, "qg_score": null}], "content": "Nutritionists often refer to carbohydrates as either simple or complex. However, the exact distinction between these groups can be ambiguous. The term ''complex carbohydrate'' was first used in the U.S. Senate Select Committee on Nutrition and Human Needs publication ''Dietary Goals for the United States'' (1977) where it was intended to distinguish sugars from other carbohydrates (which were perceived to be nutritionally superior). However, the report put \"fruit, vegetables and whole-grains\" in the complex carbohydrate column, despite the fact that these may contain sugars as well as polysaccharides. This confusion persists as today some nutritionists use the term complex carbohydrate to refer to any sort of digestible saccharide present in a whole food, where fiber, vitamins and minerals are also found (as opposed to processed carbohydrates, which provide energy but few other nutrients). The standard usage, however, is to classify carbohydrates chemically: simple if they are sugars (monosaccharides and disaccharides) and complex if they are polysaccharides (or oligosaccharides).\nIn any case, the simple vs. complex chemical distinction has little value for determining the nutritional quality of carbohydrates. Some simple carbohydrates (e.g. fructose) raise blood glucose slowly, while some complex carbohydrates (starches), especially if processed, raise blood sugar rapidly. The speed of digestion is determined by a variety of factors including which other nutrients are consumed with the carbohydrate, how the food is prepared, individual differences in metabolism, and the chemistry of the carbohydrate.\nThe USDA's ''Dietary Guidelines for Americans 2010'' call for moderate- to high-carbohydrate consumption from a balanced diet that includes six one-ounce servings of grain foods each day, at least half from whole grain sources and the rest from enriched.\nThe glycemic index (GI) and glycemic load concepts have been developed to characterize food behavior during human digestion. They rank carbohydrate-rich foods based on the rapidity and magnitude of their effect on blood glucose levels. Glycemic index is a measure of how quickly food glucose is absorbed, while glycemic load is a measure of the total absorbable glucose in foods. The insulin index is a similar, more recent classification method that ranks foods based on their effects on blood insulin levels, which are caused by glucose (or starch) and some amino acids in food.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Nutrition", "sub_heading": "Nutrition", "_id": "98--4--0---1", "title": "The Difference Between Simple and Complex Carbohydrates"}
{"qas": [{"question": "What is the most important carbohydrate?", "answer": ""}, {"question": "In what process are oligo/polysaccharides cleaved to smaller monos?", "answer": "glycolysis", "ae_score": -0.515323829158117, "qg_score": null}, {"question": "In what process are oligo/polysaccharides cleaved to smaller monos?", "answer": "glycolysis", "ae_score": -0.515323829158117, "qg_score": null}], "content": "'''Carbohydrate metabolism''' denotes the various biochemical processes responsible for the formation, breakdown and interconversion of carbohydrates in living organisms.\nThe most important carbohydrate is glucose, a simple sugar (monosaccharide) that is metabolized by nearly all known organisms. Glucose and other carbohydrates are part of a wide variety of metabolic pathways across species: plants synthesize carbohydrates from carbon dioxide and water by photosynthesis, storing the absorbed energy internally, often in the form of starch or lipids. Plant components are consumed by animals and fungi, and used as fuel for cellular respiration. Oxidation of one gram of carbohydrate yields approximately 4 kcal of energy, while the oxidation of one gram of lipids yields about 9 kcal. Energy obtained from metabolism (e.g., oxidation of glucose) is usually stored temporarily within cells in the form of ATP. Organisms capable of aerobic respiration metabolize glucose and oxygen to release energy with carbon dioxide and water as byproducts.\nCatabolism is the metabolic reaction which cells undergo to extract energy. There are two major metabolic pathways of monosaccharide catabolism: glycolysis and the citric acid cycle.\nIn glycolysis, oligo/polysaccharides are cleaved first to smaller monosaccharides by enzymes called glycoside hydrolases. The monosaccharide units can then enter into monosaccharide catabolism. In some cases, as with humans, not all carbohydrate types are usable as the digestive and metabolic enzymes necessary are not present.", "page_name": "Carbohydrate", "page_id": "Carbohydrate", "heading": "Metabolism", "sub_heading": "Metabolism", "_id": "98--5---1---1", "title": "Carbohydrate | Metabolism"}
{"qas": [{"question": "Where did the word \"chocolate\" come from?", "answer": ""}, {"question": "When did the word chocolate come into english?", "answer": "about 1600", "ae_score": -0.9758840354827302, "qg_score": null}, {"question": "When did the word chocolate come into english?", "answer": "about 1600", "ae_score": -0.9758840354827302, "qg_score": null}], "content": "The word \"chocolate\" entered the English language from Spanish in about 1600. How the word came into Spanish is less certain, and there are competing explanations. Perhaps the most cited explanation is that \"chocolate\" comes from Nahuatl, the language of the Aztecs, from the word ''chocol\u0101tl'', which many sources say derived from ''xocol\u0101tl'' , combining ''xococ'', sour or bitter, and ''\u0101tl'', water or drink.<ref name=heritagedictionary/> The word \"chocolatl\" does not occur in central Mexican colonial sources, making this an unlikely derivation.  Another derivation comes from the Yucatec Mayan word ''chokol'' meaning hot, and the Nahuatl ''atl'' meaning water. The Nahuatl term, ''chicolatl'', meaning \"beaten drink\", may derive from the word for the frothing stick, ''chicoli''. The term \"chocolate chip\" was first used in 1940. The term \"chocolatier\", for a chocolate confection maker, is attested from 1888.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Etymology", "sub_heading": "Etymology", "_id": "99--0---1---1", "title": "The origins of the word \"chocolate\""}
{"qas": [{"question": "How did the Aztecs make money from cacao?", "answer": ""}, {"question": "Who did the aztecs associate with chocolate?", "answer": "Quetzalcoatl", "ae_score": -0.3802849129684819, "qg_score": null}, {"question": "Who did the aztecs associate with chocolate?", "answer": "Quetzalcoatl", "ae_score": -0.3802849129684819, "qg_score": null}], "content": "Chocolate has been prepared as a drink for nearly all of its history. For example, one vessel found at an Olmec archaeological site on the Gulf Coast of Veracruz, Mexico, dates chocolate's preparation by pre-Olmec peoples as early as 1750 BCE. On the Pacific coast of Chiapas, Mexico, a Mokaya archaeological site provides evidence of cacao beverages dating even earlier, to 1900 BCE. The residues and the kind of vessel in which they were found indicate the initial use of cacao was not simply as a beverage, but the white pulp around the cacao beans was likely used as a source of fermentable sugars for an alcoholic drink.\nAn early Classic-period (460\u2013480 AD) Mayan tomb from the site in Rio Azul had vessels with the Maya glyph for cacao on them with residue of a chocolate drink, suggests the Maya were drinking chocolate around 400 AD. Documents in Maya hieroglyphs stated chocolate was used for ceremonial purposes, in addition to everyday life. The Maya grew cacao trees in their backyards, and used the cacao seeds the trees produced to make a frothy, bitter drink.\nBy the 15th century, the Aztecs gained control of a large part of Mesoamerica and adopted cacao into their culture. They associated chocolate with Quetzalcoatl, who, according to one legend, was cast away by the other gods for sharing chocolate with humans, and identified its extrication from the pod with the removal of the human heart in sacrifice. In contrast to the Maya, who liked their chocolate warm, the Aztecs drank it cold, seasoning it with a broad variety of additives, including the petals of the ''Cymbopetalum penduliflorum'' tree, chile pepper, allspice, vanilla, and honey.\nThe Aztecs were not able to grow cacao themselves, as their home in the Mexican highlands was unsuitable for it, so chocolate was a luxury imported into the empire. Those who lived in areas ruled by the Aztecs were required to offer cacao seeds in payment of the tax they deemed \"tribute\". Cocoa beans were often used as currency. For example, the Aztecs used a system in which one turkey cost 100 cacao beans and one fresh avocado was worth three beans.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "History", "sub_heading": "History", "_id": "99--1--0---1", "title": "Chocolate and the Aztecs"}
{"qas": [{"question": "Why is coffee so popular in the Americas?", "answer": ""}, {"question": "In what year did the bishop of rome declare that religious fasts were not broken?", "answer": "1662", "ae_score": -0.4128326173825149, "qg_score": null}, {"question": "In what year did the bishop of rome declare that religious fasts were not broken?", "answer": "1662", "ae_score": -0.4128326173825149, "qg_score": null}], "content": "Until the 16th century, no European had ever heard of the popular drink from the Central and South American peoples. Christopher Columbus and his son Ferdinand encountered the cacao bean on Columbus's fourth mission to the Americas on 15 August 1502, when he and his crew seized a large native canoe that proved to contain cacao beans among other goods for trade. Spanish conquistador Hern\u00e1n Cort\u00e9s may have been the first European to encounter it, as the frothy drink was part of the after-dinner routine of Montezuma. Jose de Acosta, a Spanish Jesuit missionary who lived in Peru and then Mexico in the later 16th century, wrote of its growing influence on the Spaniards:\nWhile Columbus had taken cacao beans with him back to Spain,<ref name=Exploratorium/> chocolate made no impact until Spanish friars introduced it to the Spanish court. After the Spanish conquest of the Aztecs, chocolate was imported to Europe. There, it quickly became a court favorite. It was still served as a beverage, but the Spanish added sugar, as well as honey, to counteract the natural bitterness. Vanilla was also a popular additive, with pepper and other spices sometimes used to give the illusion of a more potent vanilla flavor. Unfortunately, these spices had the tendency to unsettle the European constitution; the ''Encyclop\u00e9die'' states, \"The pleasant scent and sublime taste it imparts to chocolate have made it highly recommended; but a long experience having shown that it could potentially upset one's stomach,\" which is why chocolate without vanilla was sometimes referred to as \"healthy chocolate.\" <ref>Diderot, Denis. \"Chocolate.\" The Encyclopedia of Diderot & d'Alembert Collaborative Translation Project. Translated by Colleen Oberc, Samantha Schaeffer, and Courtney Wilder. Ann Arbor: Michigan Publishing, University of Michigan Library, 2015. Web. 1 April 2015. \n By 1602, chocolate had made its way from Spain to Austria. By 1662, the bishop of Rome had declared that religious fasts were not broken by consuming chocolate drinks. Within about a hundred years, chocolate established a foothold throughout Europe.\nThe new craze for chocolate brought with it a thriving slave market, as between the early 1600s and late 1800s, the laborious and slow processing of the cacao bean was manual. Cacao plantations spread, as the English, Dutch, and French colonized and planted. With the depletion of Mesoamerican workers, largely to disease, cacao production was often the work of poor wage laborers and African slaves. Wind-powered and horse-drawn mills were used to speed production, augmenting human labor. Heating the working areas of the table-mill, an innovation that emerged in France in 1732, also assisted in extraction.\nNew processes that sped the production of chocolate emerged early in the Industrial Revolution. In 1815, Dutch chemist Coenraad van Houten introduced alkaline salts to chocolate, which reduced its bitterness. A few years thereafter, in 1828, he created a press to remove about half the natural fat (cocoa butter or cacao butter) from chocolate liquor, which made chocolate both cheaper to produce and more consistent in quality. This innovation introduced the modern era of chocolate.<ref name=Exploratorium/> Known as \"Dutch cocoa\", this machine-pressed chocolate was instrumental in the transformation of chocolate to its solid form when, in 1847, Joseph Fry learned to make chocolate moldable by adding back melted cacao butter.<ref name=Smithsonian/> Milk had sometimes been used as an addition to chocolate beverages since the mid-17th century, but in 1875 Daniel Peter invented milk chocolate by mixing a powdered milk developed by Henri Nestl\u00e9 with the liquor. Next, the chocolate is cooled to about 27 C, which will allow crystal types IV and V to form. At this temperature, the chocolate is agitated to create many small crystal \"seeds\" which will serve as nuclei to create small crystals in the chocolate. The chocolate is then heated to about 31 C to eliminate any type IV crystals, leaving just type V. After this point, any excessive heating of the chocolate will destroy the temper and this process will have to be repeated. However, other methods of chocolate tempering are used. The most common variant is introducing already tempered, solid \"seed\" chocolate. The temper of chocolate can be measured with a chocolate temper meter to ensure accuracy and consistency. A sample cup is filled with the chocolate and placed in the unit which then displays or prints the results.\nTwo classic ways of manually tempering chocolate are:\nChocolate tempering machines (or temperers) with computer controls can be used for producing consistently tempered chocolate, particularly for large volume applications.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "History", "sub_heading": "European adaptation", "_id": "99--1--1---1", "title": "Chocolate and the Industrial Revolution: A History of Chocolate"}
{"qas": [{"question": "Why does chocolate taste so much better than other foods?", "answer": ""}, {"question": "What is the ideal storage temperature for chocolate?", "answer": "between 15 and", "ae_score": null, "qg_score": null}, {"question": "What is the ideal storage temperature for chocolate?", "answer": "between 15 and", "ae_score": null, "qg_score": null}], "content": "Chocolate is very sensitive to temperature and humidity. Ideal storage temperatures are between 15 and, with a relative humidity of less than 50%. Various types of \"blooming\" effects can occur if chocolate is stored or served improperly. Fat bloom is caused by storage temperature fluctuating or exceeding 24 C, while sugar bloom is caused by temperature below 15 C or excess humidity. To distinguish between different types of bloom, one can rub the surface of the chocolate lightly, and if the bloom disappears, it is fat bloom. One can get rid of bloom by retempering the chocolate or using it for any use that requires melting the chocolate.\nChocolate is generally stored away from other foods, as it can absorb different aromas. Ideally, chocolates are packed or wrapped, and placed in proper storage with the correct humidity and temperature. Additionally, chocolate is frequently stored in a dark place or protected from light by wrapping paper.\nIf refrigerated or frozen without containment, chocolate can absorb enough moisture to cause a whitish discoloration, the result of fat or sugar crystals rising to the surface. Moving chocolate from one temperature extreme to another, such as from a refrigerator on a hot day, can result in an oily texture. Although visually unappealing, chocolate suffering from bloom is perfectly safe for consumption.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "History", "sub_heading": "Storage", "_id": "99--1--2---1", "title": "Chocolate Blooming Effects"}
{"qas": [{"question": "Why does milk chocolate have so many calories?", "answer": ""}, {"question": "A few studies have documented allergic reactions from what in children?", "answer": "chocolate", "ae_score": -0.3226897354444549, "qg_score": null}, {"question": "A few studies have documented allergic reactions from what in children?", "answer": "chocolate", "ae_score": -0.3226897354444549, "qg_score": null}], "content": "A 100 gram serving of milk chocolate supplies 540 calories. It is 59% carbohydrates (52% as sugar and 3% as dietary fiber), 30% fat and 8% protein (table). Approximately 65% of the fat in milk chocolate is saturated, composed mainly of palmitic acid and stearic acid, while the predominant unsaturated fat is oleic acid (table, see USDA reference for full report).\nIn 100 gram amounts, milk chocolate is an excellent source (> 19% of the Daily Value, DV) of riboflavin, vitamin B12 and the dietary minerals, manganese, phosphorus and zinc (table). Chocolate is a good source (10-19% DV) of calcium, magnesium and iron (table).\nChocolate and cocoa are under preliminary research to determine if consumption affects the risk of certain cardiovascular diseases or cognitive abilities.\nChocolate may be a factor for heartburn in some people because one of its constituents, theobromine, may affect the oesophageal sphincter muscle, hence permitting stomach acidic contents to enter into the oesophagus.  Theobromine is also toxic to some animals unable to metabolize it (see theobromine poisoning).\nExcessive consumption of large quantities of any energy-rich food, such as chocolate, without a corresponding increase in activity to expend the associated calories, can increase the risk of weight gain and possibly obesity. Raw chocolate is high in cocoa butter, a fat which is removed during chocolate refining, then added back in varying proportions during the manufacturing process. Manufacturers may add other fats, sugars, and milk as well, all of which increase the caloric content of chocolate.\nChocolate and cocoa contain moderate to high amounts of oxalate, which may increase risk for kidney stones. During cultivation and production, chocolate may absorb lead from the environment, but the total amounts typically eaten are less than the tolerable daily limit for lead consumption, according to a World Health Organization report from 2010. However, reports from 2014 indicate that \"chocolate might be a significant source\" of lead ingestion for children if consumption is high and \"one 10 g cube of dark chocolate may contain as much as 20% of the daily lead oral limit.\"<ref name=Yanus/>\nA few studies have documented allergic reactions from chocolate in children.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Nutrition and research", "sub_heading": "Nutrition and research", "_id": "99--2---1---1", "title": "Chocolate and the Risk of Heartburn and Obesity (Table)"}
{"qas": [{"question": "Why do some chocolate bars have a percentage of cocoa in them?", "answer": ""}, {"question": "Organic or fair trade certified carry labels on what?", "answer": "Chocolates", "ae_score": -0.264686249241482, "qg_score": null}, {"question": "Organic or fair trade certified carry labels on what?", "answer": "Chocolates", "ae_score": -0.264686249241482, "qg_score": null}], "content": "Some manufacturers provide the percentage of chocolate in a finished chocolate confection as a label quoting percentage of \"cocoa\" or \"cacao\". It should be noted that this refers to the combined percentage of both cocoa solids and cocoa butter in the bar, not just the percentage of cocoa solids.  The Belgian AMBAO certification mark indicates that no non-cocoa vegetable fats have been used in making the chocolate.\nChocolates that are organic or fair trade certified carry labels accordingly.\nIn the United States, some large chocolate manufacturers lobbied the federal government to permit confections containing cheaper hydrogenated vegetable oil in place of cocoa butter to be sold as \"chocolate\". In June 2007, as a response to consumer concern after the proposed change, the FDA reiterated \"Cacao fat, as one of the signature characteristics of the product, will remain a principal component of standardized chocolate.\"", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Labeling", "sub_heading": "Labeling", "_id": "99--3---1---1", "title": "Cocoa Butter in Chocolate Condiments"}
{"qas": [{"question": "How do companies like Cadbury and Hershey make chocolate?", "answer": ""}, {"question": "What is the world's largest confectionery manufacturer?", "answer": "Cadbury", "ae_score": -0.2797826882604088, "qg_score": null}, {"question": "What is the world's largest confectionery manufacturer?", "answer": "Cadbury", "ae_score": -0.2797826882604088, "qg_score": null}], "content": "Chocolate manufacturers produce a range of products from chocolate bars to fudge. Large manufacturers of chocolate products include Cadbury (the world's largest confectionery manufacturer), Guylian, The Hershey Company, Lindt & Spr\u00fcngli, Mars, Incorporated, Milka, Neuhaus and Suchard.\nGuylian is best known for its chocolate sea shells; Cadbury for its Dairy Milk and Creme Egg. The Hershey Company, the largest chocolate manufacturer in North America, produces the Hershey Bar and Hershey's Kisses. Mars Incorporated, a large privately owned U.S. corporation, produces Mars Bar, Milky Way, M&M's, Twix, and Snickers. Lindt is known for its truffle balls and gold foil-wrapped Easter bunnies.\nFood conglomerates Nestl\u00e9 SA and Kraft Foods both have chocolate brands. Nestl\u00e9 acquired Rowntree's in 1988 and now markets chocolates under their own brand, including Smarties (a chocolate candy) and Kit Kat (a candy bar); Kraft Foods through its 1990 acquisition of Jacobs Suchard, now owns Milka and Suchard. In February 2010, Kraft also acquired British-based Cadbury.; Fry's, Trebor Basset and the fair trade brand Green & Black's also belongs to the group.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Industry", "sub_heading": "Industry", "_id": "99--4--0---1", "title": "Chocolate Manufacturers: Cadbury, Guylian, Lindt & Spr\u00fcngli,"}
{"qas": [{"question": "Why is the use of children in cocoa production controversial?", "answer": ""}, {"question": "How many children were trafficked in the ivory coast of africa in 2009?", "answer": "12,000", "ae_score": -0.5780523486131321, "qg_score": null}, {"question": "How many children were trafficked in the ivory coast of africa in 2009?", "answer": "12,000", "ae_score": -0.5780523486131321, "qg_score": null}], "content": "The widespread use of children in cocoa production is controversial, not only for the concerns about child labor and exploitation, but also because up to 12,000 of the 200,000 children working in C\u00f4te d'Ivoire, the world's biggest producer of cocoa, may be victims of trafficking or slavery. Most attention on this subject has focused on West Africa, which collectively supplies 69 percent of the world's cocoa, and C\u00f4te d'Ivoire in particular, which supplies 35 percent of the world's cocoa. Thirty percent of children under age 15 in sub-Saharan Africa are child laborers, mostly in agricultural activities including cocoa farming. It is estimated that more than 1.8 million children in West Africa are involved in growing cocoa. Major chocolate producers, such as  Nestl\u00e9, buy cocoa at commodities exchanges where Ivorian cocoa is mixed with other cocoa.\nIn 2009, Salvation Army International Development (SAID) UK stated that 12,000 children have been trafficked on cocoa farms in the Ivory Coast of Africa, where half of the world's chocolate is made. SAID UK states that it is these child slaves who are likely to be working in \"harsh and abusive\" conditions for the production of chocolate, and an increasing number of health-food and anti-slavery organisations are now highlighting and campaigning against the use of trafficking in the chocolate industry.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Industry", "sub_heading": "Human trafficking of child labourers", "_id": "99--4--1---1", "title": "Child Trafficking in the Chocolate Industry"}
{"qas": [{"question": "Fair Trade?", "answer": ""}, {"question": "What country traditionally received low prices for cocoa?", "answer": "Africa", "ae_score": null, "qg_score": null}, {"question": "What country traditionally received low prices for cocoa?", "answer": "Africa", "ae_score": null, "qg_score": null}], "content": "In the 2000s, some chocolate producers began to engage in fair trade initiatives, to address concerns about the marginalization of cocoa laborers in developing countries. Traditionally, Africa and other developing countries received low prices for their exported commodities such as cocoa, which caused poverty to abound. Fair trade seeks to establish a system of direct trade from developing countries to counteract this unfair system.  One solution for fair labor practices is for farmers to become part of an Agricultural cooperative. Cooperatives pay farmers a fair price for their cocoa so farmers have enough money for food, clothes, and school fees. One of the main tenets of fair trade is that farmers receive a fair price, but this does not mean that the larger amount of money paid for fair trade cocoa goes directly to the farmers. The effectiveness of fair trade has been questioned. In a 2014 article, ''The Economist'' stated that workers on fair trade farms have a lower standard of living than on similar farms outside the fair trade system.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Industry", "sub_heading": "Fair trade", "_id": "99--4--2---1", "title": "Fair Trade \u2014 What is Fair Trade and Why?"}
{"qas": [{"question": "What is the difference between chocolate and chocolate?", "answer": ""}, {"question": "What type of chocolate is used in chocolate bars?", "answer": "dark chocolate", "ae_score": -1.8164915178287524, "qg_score": null}, {"question": "What type of chocolate is used in chocolate bars?", "answer": "dark chocolate", "ae_score": -1.8164915178287524, "qg_score": null}], "content": "Chocolate is sold in chocolate bars, which come in dark chocolate, milk chocolate and white chocolate varieties. Some bars that are mostly chocolate have other ingredients blended into the chocolate, such as nuts, raisins or crisped rice. Chocolate is used as an ingredient in a huge variety of candy bars, which typically contain various confectionary ingredients (e.g., nougat, wafers, caramel, nuts, etc.) which are coated in chocolate. Chocolate is used as a flavouring product in many desserts, such as chocolate cakes, chocolate brownies, chocolate mousse and chocolate chip cookies. Numerous types of candy and snacks contain chocolate, either as a filling (e.g., M&M's) or as a coating (e.g., chocolate-coated raisins or chocolate-coated peanuts). Some non-alcoholic beverages contain chocolate, such as chocolate milk, hot chocolate and chocolate milkshakes. Some alcoholic liqueurs are flavoured with chocolate, such as chocolate liqueur and creme de cacao. Chocolate is a popular flavour of ice cream and pudding, and chocolate sauce is a commonly added as a topping on ice cream sundaes.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Usage and consumption", "sub_heading": "Usage and consumption", "_id": "99--5---1---1", "title": "Chocolate \u2014 What is Chocolate?"}
{"qas": [{"question": "Why are chocolate hearts and chocolate coins associated with Christmas?", "answer": ""}, {"question": "Who wrote charlie and the chocolate factory?", "answer": "Roald Dahl", "ae_score": -0.3028228388912978, "qg_score": null}, {"question": "Who wrote charlie and the chocolate factory?", "answer": "Roald Dahl", "ae_score": -0.3028228388912978, "qg_score": null}], "content": "Chocolate is associated with festivals such as Easter, when moulded chocolate rabbits and eggs are traditionally given in Christian communities, and Hanukkah, when chocolate coins are given in Jewish communities. Chocolate hearts and chocolate in heart-shaped boxes are popular on Valentine's Day and are often presented along with flowers and a greeting card. Chocolate is an acceptable gift on other holidays and on occasions such as birthdays.\nMany confectioners make holiday-specific chocolate candies. Chocolate Easter eggs or rabbits and Santa Claus figures are two examples. Such confections can be solid, hollow, or filled with sweets or fondant.\nChocolate has been the center of several successful book and film adaptations. In 1964, Roald Dahl published a children's novel titled ''Charlie and the Chocolate Factory''. The novel centers on a poor boy named Charlie Bucket who takes a tour through the greatest chocolate factory in the world, owned by Willy Wonka. Two film adaptations of the novel were produced. The first was ''Willy Wonka & the Chocolate Factory'', a 1971 film which later became a cult classic, and spawned the real world Willy Wonka Candy Company, which produces chocolate products to this day. Thirty-four years later, a second film adaptation was produced, titled ''Charlie and the Chocolate Factory''. The 2005 film was very well received by critics and was one of the highest-grossing films that year, earning over US$470,000,000 worldwide. ''Charlie and the Chocolate Factory'' was also recognized at the 78th Academy Awards, where it was nominated for Best Costume Design for Gabriella Pesucci.\n''Like Water for Chocolate'' (''Como agua para chocolate''), a 1989 love story by novelist Laura Esquivel, was adapted to film in 1992. The plot incorporates magical realism with Mexican cuisine, and the title is a double entendre in its native language, referring both to a recipe for hot chocolate and to an idiom that is a metaphor for sexual arousal. The film earned 11 Ariel Awards from the Academia Mexicana de Artes y Ciencias Cinematogr\u00e1ficas, including Best Picture.\n''Chocolat'', a 1999 novel by Joanne Harris, tells the story of Vianne Rocher, a young mother, whose confections change the lives of the townspeople. The 2000 film adaptation, ''Chocolat'', also proved successful, grossing over US$150,000,000 worldwide, and receiving Academy Award and Golden Globe nominations for Best Picture, Best Actress, and Best Original Score.", "page_name": "Chocolate", "page_id": "Chocolate", "heading": "Popular culture", "sub_heading": "Popular culture", "_id": "99--6---1---1", "title": "''Charlie and the Chocolate Factory''"}
{"qas": [{"question": "Why do some people get fevers and others don't?", "answer": ""}, {"question": "What are the main symptoms of cholera?", "answer": "profuse diarrhea", "ae_score": -0.684266981757382, "qg_score": null}, {"question": "What are the main symptoms of cholera?", "answer": "profuse diarrhea", "ae_score": -0.684266981757382, "qg_score": null}], "content": "The primary symptoms of cholera are profuse diarrhea and vomiting of clear fluid. These symptoms usually start suddenly, half a day to five days after ingestion of the bacteria. The diarrhea is frequently described as \"rice water\" in nature and may have a fishy odor.<ref name=Lancet2004/> An untreated person with cholera may produce 10 to of diarrhea a day.<ref name=Lancet2004/> Severe cholera, without treatment, kills about half of affected individuals.<ref name=Lancet2004/> If the severe diarrhea is not treated, it can result in life-threatening dehydration and electrolyte imbalances.<ref name=Lancet2004/> Estimates of the ratio of asymptomatic to symptomatic infections have ranged from 3 to 100. Cholera has been nicknamed the \"blue death\" because a person's skin may turn bluish-gray from extreme loss of fluids.\nFever is rare and should raise suspicion for secondary infection. Patients can be lethargic, and might have sunken eyes, dry mouth, cold clammy skin, decreased skin turgor, or wrinkled hands and feet. Kussmaul breathing, a deep and labored breathing pattern, can occur because of acidosis from stool bicarbonate losses and lactic acidosis associated with poor perfusion. Blood pressure drops due to dehydration, peripheral pulse is rapid and thready, and urine output decreases with time. Muscle cramping and weakness, altered consciousness, seizures, or even coma due to electrolyte losses and ion shifts are common, especially in children.<ref name=Lancet2004/>", "page_name": "Cholera", "page_id": "Cholera", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "100--0---1---1", "title": "Cholera | Signs and symptoms"}
{"qas": [{"question": "Why do we have cholera in our bodies but not in other animals?", "answer": ""}, {"question": "What does cholera do to a person infected with it?", "answer": "diarrhea", "ae_score": -0.34174677576393986, "qg_score": null}, {"question": "What does cholera do to a person infected with it?", "answer": "diarrhea", "ae_score": -0.34174677576393986, "qg_score": null}], "content": "Cholera has been found in two animal populations: shellfish and plankton.\nTransmission is usually through the fecal-oral route of contaminated food or water caused by poor sanitation. Most cholera cases in developed countries are a result of transmission by food, while in the developing world it is more often water. Food transmission can occur when people harvest seafood such as oysters in waters infected with sewage, as ''Vibrio cholerae'' accumulates in planktonic crustaceans and the oysters eat the zooplankton.\nPeople infected with cholera often have diarrhea, and disease transmission may occur if this highly liquid stool, colloquially referred to as \"rice-water\", contaminates water used by others. The source of the contamination is typically other cholera sufferers when their untreated diarrheal discharge is allowed to get into waterways, groundwater or drinking water supplies. Drinking any infected water and eating any foods washed in the water, as well as shellfish living in the affected waterway, can cause a person to contract an infection. Cholera is rarely spread directly from person to person.\nBoth toxic and non-toxic strains exist. Non-toxic strains can acquire toxicity through a temperate bacteriophage.\nAbout 100 million bacteria must typically be ingested to cause cholera in a normal healthy adult.<ref name=Lancet2004/> This dose, however, is less in those with lowered gastric acidity (for instance those using proton pump inhibitors).<ref name=Lancet2004/> Children are also more susceptible, with two- to four-year-olds having the highest rates of infection.<ref name=Lancet2004/> Individuals' susceptibility to cholera is also affected by their blood type, with those with type O blood being the most susceptible.<ref name=Lancet2004/> Persons with lowered immunity, such as persons with AIDS or children who are malnourished, are more likely to experience a severe case if they become infected. Any individual, even a healthy adult in middle age, can experience a severe case, and each person's case should be measured by the loss of fluids, preferably in consultation with a professional health care provider.\nThe cystic fibrosis genetic mutation known as delta-F508 in humans has been said to maintain a selective heterozygous advantage: heterozygous carriers of the mutation (who are thus not affected by cystic fibrosis) are more resistant to ''V. cholerae'' infections. In this model, the genetic deficiency in the cystic fibrosis transmembrane conductance regulator channel proteins interferes with bacteria binding to the gastrointestinal epithelium, thus reducing the effects of an infection.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Cause", "sub_heading": "Cause", "_id": "100--1---1---1", "title": "CHOLERA \u2014 Symptoms, Causes, and Treatment"}
{"qas": [{"question": "Why are there so many different strains of the flu?", "answer": ""}, {"question": "When does cluster i contain the most strains?", "answer": "1960s and 1970s", "ae_score": -0.9432454082193996, "qg_score": null}, {"question": "When does cluster i contain the most strains?", "answer": "1960s and 1970s", "ae_score": -0.9432454082193996, "qg_score": null}], "content": "Amplified fragment length polymorphism fingerprinting of the pandemic isolates of ''V. cholerae'' has revealed variation in the genetic structure. Two clusters have been identified: Cluster I and Cluster II. For the most part, Cluster I consists of strains from the 1960s and 1970s, while Cluster II largely contains strains from the 1980s and 1990s, based on the change in the clone structure. This grouping of strains is best seen in the strains from the African continent.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Mechanism", "sub_heading": "Mechanism", "_id": "100--2--0---1", "title": "''V. cholerae'' Genetic Analysis"}
{"qas": [{"question": "Why is antibiotic resistance increasing?", "answer": ""}, {"question": "Where are most cases of cholera found?", "answer": "Bangladesh", "ae_score": -0.4057351695462664, "qg_score": null}, {"question": "Where are most cases of cholera found?", "answer": "Bangladesh", "ae_score": -0.4057351695462664, "qg_score": null}], "content": "In many areas of the world, antibiotic resistance is increasing. In Bangladesh, for example, most cases are resistant to tetracycline, trimethoprim-sulfamethoxazole, and erythromycin. Rapid diagnostic assay methods are available for the identification of multiple drug-resistant cases. New generation antimicrobials have been discovered which are effective against in ''in vitro'' studies.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Mechanism", "sub_heading": "Antibiotic resistance", "_id": "100--2--1---1", "title": "New Generation Antimicrobials are Effective against Multiple Drug-Resistant Cases"}
{"qas": [{"question": "How do doctors determine whether a disease is a bacterial or viral infection?", "answer": ""}, {"question": "What test can be used to determine the presence of v. cholerae?", "answer": "rapid dipstick test", "ae_score": -0.6581435364377822, "qg_score": null}, {"question": "What test can be used to determine the presence of v. cholerae?", "answer": "rapid dipstick test", "ae_score": -0.6581435364377822, "qg_score": null}], "content": "A rapid dipstick test is available to determine the presence of ''V. cholerae''. In those samples that test positive, further testing should be done to determine antibiotic resistance. In epidemic situations, a clinical diagnosis may be made by taking a patient history and doing a brief examination. Treatment is usually started without or before confirmation by laboratory analysis.\nStool and swab samples collected in the acute stage of the disease, before antibiotics have been administered, are the most useful specimens for laboratory diagnosis. If an epidemic of cholera is suspected, the most common causative agent is ''V. cholerae'' O1. If ''V. cholerae'' serogroup O1 is not isolated, the laboratory should test for ''V. cholerae'' O139. However, if neither of these organisms is isolated, it is necessary to send stool specimens to a reference laboratory.\nInfection with ''V. cholerae'' O139 should be reported and handled in the same manner as that caused by ''V. cholerae'' O1. The associated diarrheal illness should be referred to as cholera and must be reported in the United States.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "100--3---1---1", "title": "''V. cholerae'' O139: A Case Report"}
{"qas": [{"question": "Why is it recommended to wash your hands before you use the toilet?", "answer": ""}, {"question": "When was the last major cholera outbreak in the united states?", "answer": "1910\u20131911", "ae_score": -0.19649544306838193, "qg_score": null}, {"question": "When was the last major cholera outbreak in the united states?", "answer": "1910\u20131911", "ae_score": -0.19649544306838193, "qg_score": null}], "content": "The World Health Organization (WHO) recommends focusing on prevention, preparedness, and response to combat the spread of cholera. They also stress the importance of an effective surveillance system. Governments can play a role in all of these areas, and in preventing cholera or indirectly facilitating its spread.\nAlthough cholera may be life-threatening, prevention of the disease is normally straightforward if proper sanitation practices are followed. In developed countries, due to nearly universal advanced water treatment and sanitation practices, cholera is no longer a major health threat. The last major outbreak of cholera in the United States occurred in 1910\u20131911. Effective sanitation practices, if instituted and adhered to in time, are usually sufficient to stop an epidemic. There are several points along the cholera transmission path at which its spread may be halted:\nHandwashing with soap and/or ash after visiting toilets and before handling food or eating is also recommended for cholera prevention by WHO Africa.\nSurveillance and prompt reporting allow for containing cholera epidemics rapidly. Cholera exists as a seasonal disease in many endemic countries, occurring annually mostly during rainy seasons. Surveillance systems can provide early alerts to outbreaks, therefore leading to coordinated response and assist in preparation of preparedness plans. Efficient surveillance systems can also improve the risk assessment for potential cholera outbreaks. Understanding the seasonality and location of outbreaks provides guidance for improving cholera control activities for the most vulnerable. For prevention to be effective, it is important that cases be reported to national health authorities.<ref name=Lancet2004/>\nA number of safe and effective oral vaccines for cholera are available. Dukoral, an orally administered, inactivated whole cell vaccine, has an overall efficacy of about 52% during the first year after being given and 62% in the second year, with minimal side effects. It is available in over 60 countries. However, it is not currently recommended by the Centers for Disease Control and Prevention (CDC) for most people traveling from the United States to endemic countries. One injectable vaccine was found to be effective for two to three years. The protective efficacy was 28% lower in children less than 5 years old. However, as of 2010, it has limited availability.<ref name=WHO2010/> Work is under way to investigate the role of mass vaccination. The World Health Organization (WHO) recommends immunization of high-risk groups, such as children and people with HIV, in countries where this disease is endemic.<ref name=WHO2010/> If people are immunized broadly, herd immunity results, with a decrease in the amount of contamination in the environment.<ref name=NEJM2006/>\nAn effective and relatively cheap method to prevent the transmission of cholera is the use of a folded ''sari'' (a long cloth garment) to filter drinking water. In Bangladesh this practice was found to decrease rates of cholera by nearly half. It involves folding a ''sari'' four to eight times.<ref name=Ram2010/> Between uses the cloth should be rinsed in clean water and dried in the sun to kill any bacteria on it. A nylon cloth appears to work as well.<ref name=Merr2010/>", "page_name": "Cholera", "page_id": "Cholera", "heading": "Prevention", "sub_heading": "Prevention", "_id": "100--4---1---1", "title": "Cholera Prevention and Prevention"}
{"qas": [{"question": "Why can't we just eat bananas and drink water to rehydrate them?", "answer": ""}, {"question": "What is the most common treatment for cholera?", "answer": "oral rehydration therapy", "ae_score": -0.4808219896531446, "qg_score": null}, {"question": "What is the most common treatment for cholera?", "answer": "oral rehydration therapy", "ae_score": -0.4808219896531446, "qg_score": null}], "content": "The most common error in caring for patients with cholera is to underestimate the speedand volume of fluids required. In most cases, cholera can be successfully treated with oral rehydration therapy, which is highly effective, safe, and simple to administer.<ref name=NEJM2006/> Rice-based solutions are preferred to glucose-based ones due to greater efficiency.<ref name=NEJM2006/> In severe cases with significant dehydration, intravenous rehydration may be necessary. Ringer's lactate is the preferred solution, often with added potassium.<ref name=Lancet2004/> Large volumes and continued replacement until diarrhea has subsided may be needed.<ref name=Lancet2004/> Ten percent of a person's body weight in fluid may need to be given in the first two to four hours.<ref name=Lancet2004/> This method was first tried on a mass scale during the Bangladesh Liberation War, and was found to have much success.  Despite widespread beliefs, fruit juices and commercial fizzy drinks like cola, are not ideal for rehydration of people with serious infections of the intestines, and the too high sugar content may even harm water uptake.\nIf commercially produced oral rehydration solutions are too expensive or difficult to obtain, solutions can be made. One such recipe calls for 1 liter of boiled water, 1/2 teaspoon of salt, 6 teaspoons of sugar, and added mashed banana for potassium and to improve taste.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Treatment", "sub_heading": "Treatment", "_id": "100--5--0---1", "title": "How to Treat Cholera with Oral Rehydration Therapy"}
{"qas": [{"question": "What happens to your body when you're dehydrated?", "answer": ""}, {"question": "What is the initial stage of cholera?", "answer": "acidosis", "ae_score": -0.6593022607770653, "qg_score": null}, {"question": "What is the initial stage of cholera?", "answer": "acidosis", "ae_score": -0.6593022607770653, "qg_score": null}], "content": "As there frequently is initially acidosis, the potassium level may be normal, even though large losses have occurred.<ref name=Lancet2004/> As the dehydration is corrected, potassium levels may decrease rapidly, and thus need to be replaced.<ref name=Lancet2004/>  This may be done by eating foods high in potassium like bananas or green coconut water.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Treatment", "sub_heading": "Electrolytes", "_id": "100--5--1---1", "title": "Cholera | Treatment | Electrolytes"}
{"qas": [{"question": "How do antibiotics work?", "answer": ""}, {"question": "What is used first line for cholera?", "answer": "Doxycycline", "ae_score": -0.1450685633615027, "qg_score": null}, {"question": "What is used first line for cholera?", "answer": "Doxycycline", "ae_score": -0.1450685633615027, "qg_score": null}], "content": "Antibiotic treatments for one to three days shorten the course of the disease and reduce the severity of the symptoms.<ref name=Lancet2004/> Use of antibiotics also reduces fluid requirements. People will recover without them, however, if sufficient hydration is maintained.<ref name=NEJM2006/> The World Health Organization only recommends antibiotics in those with severe dehydration.\nDoxycycline is typically used first line, although some strains of ''V. cholerae'' have shown resistance.<ref name=Lancet2004/> Testing for resistance during an outbreak can help determine appropriate future choices.<ref name=Lancet2004/> Other antibiotics proven to be effective include cotrimoxazole, erythromycin, tetracycline, chloramphenicol, and furazolidone. Fluoroquinolones, such as ciprofloxacin, also may be used, but resistance has been reported.\nAntibiotics improve outcomes in those who are both severely and not severely dehydrated. Azithromycin and tetracycline may work better than doxycycline or ciprofloxacin.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Treatment", "sub_heading": "Antibiotics", "_id": "100--5--2---1", "title": "Cholera | Treatment | Antibiotics"}
{"qas": [{"question": "How do zinc supplements help prevent diarrhea?", "answer": ""}, {"question": "How long did zinc supplementation reduce the length of cholera?", "answer": "eight hours", "ae_score": -0.6429326848330476, "qg_score": null}, {"question": "How long did zinc supplementation reduce the length of cholera?", "answer": "eight hours", "ae_score": -0.6429326848330476, "qg_score": null}], "content": "In Bangladesh zinc supplementation reduced the duration and severity of diarrhea in children with cholera when given with antibiotics and rehydration therapy as needed. It reduced the length of disease by eight hours and the amount of diarrhea stool by 10%. Supplementation appears to be also effective in both treating and preventing infectious diarrhea due to other causes among children in the developing world.<ref name=CDC2013/>", "page_name": "Cholera", "page_id": "Cholera", "heading": "Treatment", "sub_heading": "Zinc supplementation", "_id": "100--5--3---1", "title": "Zinc Supplementation Reduced Diarrhea in Children with Cholera in Bangladesh"}
{"qas": [{"question": "Why is the mortality rate for cholera so high?", "answer": ""}, {"question": "What is the mortality rate for untreated cholera?", "answer": "50\u201360%", "ae_score": -0.34995563283411046, "qg_score": null}, {"question": "What is the mortality rate for untreated cholera?", "answer": "50\u201360%", "ae_score": -0.34995563283411046, "qg_score": null}], "content": "If people with cholera are treated quickly and properly, the mortality rate is less than 1%; however, with untreated cholera, the mortality rate rises to 50\u201360%. For certain genetic strains of cholera, such as the one present during the 2010 epidemic in Haiti and the 2004 outbreak in India, death can occur within two hours of becoming ill.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Prognosis", "sub_heading": "Prognosis", "_id": "100--6---1---1", "title": "Cholera is a deadly disease that can cause death within two hours of being ill"}
{"qas": [{"question": "How did the spread of cholera in the Americas start?", "answer": ""}, {"question": "How many deaths does cholera cause each year?", "answer": "58,000\u2013130,000", "ae_score": -0.43457184062924104, "qg_score": null}, {"question": "How many deaths does cholera cause each year?", "answer": "58,000\u2013130,000", "ae_score": -0.43457184062924104, "qg_score": null}], "content": "Cholera affects an estimated 3\u20135 million people worldwide, and causes 58,000\u2013130,000 deaths a year as of 2010.<ref name=WHO2010/><ref name=Loz2012/> This occurs mainly in the developing world. In the early 1980s, death rates are believed to have been greater than 3 million a year.<ref name=Lancet2004/> It is difficult to calculate exact numbers of cases, as many go unreported due to concerns that an outbreak may have a negative impact on the tourism of a country. Cholera remains both epidemic and endemic in many areas of the world.<ref name=Lancet2004/>\nAlthough much is known about the mechanisms behind the spread of cholera, this has not led to a full understanding of what makes cholera outbreaks happen in some places and not others. Lack of treatment of human feces and lack of treatment of drinking water greatly facilitate its spread, but bodies of water can serve as a reservoir, and seafood shipped long distances can spread the disease. Cholera was not known in the Americas for most of the 20th century, but it reappeared towards the end of that century.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Epidemiology", "sub_heading": "Epidemiology", "_id": "100--7---1---1", "title": "Cholera \u2014 A Global Epidemic and Enemy"}
{"qas": [{"question": "How did people in developed nations deal with diseases like cholera before modern sanitation?", "answer": ""}, {"question": "When was cholera first discovered in the uk?", "answer": "1854", "ae_score": -0.13194294135075585, "qg_score": null}, {"question": "When was cholera first discovered in the uk?", "answer": "1854", "ae_score": -0.13194294135075585, "qg_score": null}], "content": "The bacterium was isolated in 1854 by Italian anatomist Filippo Pacini,<ref>See:\nSpanish physician Jaume Ferran i Clua developed a cholera inoculation in 1885, the first to immunize humans against a bacterial disease.\nRussian-Jewish bacteriologist Waldemar Haffkine developed the first cholera vaccine in July 1892.\nOne of the major contributions to fighting cholera was made by the physician and pioneer medical scientist John Snow (1813\u20131858), who in 1854 found a link between cholera and contaminated drinking water. Dr. Snow proposed a microbial origin for epidemic cholera in 1849. In his major \"state of the art\" review of 1855, he proposed a substantially complete and correct model for the etiology of the disease. In two pioneering epidemiological field studies, he was able to demonstrate human sewage contamination was the most probable disease vector in two major epidemics in London in 1854. His model was not immediately accepted, but it was seen to be the more plausible, as medical microbiology developed over the next 30 years or so.\nCities in developed nations made massive investment in clean water supply and well-separated sewage treatment infrastructures between the mid-1850s and the 1900s. This eliminated the threat of cholera epidemics from the major developed cities in the world. In 1883, Robert Koch identified ''V. cholerae'' with a microscope as the bacillus causing the disease.\nRobert Allan Phillips, working at the US Naval Medical Research Unit Two in Southeast Asia, evaluated the pathophysiology of the disease using modern laboratory chemistry techniques and developed a protocol for rehydration. His research led the Lasker Foundation to award him its prize in 1967.\nMore recently, in 2002, Alam, ''et al.'', studied stool samples from patients at the International Centre for Diarrhoeal Disease in Dhaka, Bangladesh. From the various experiments they conducted, the researchers found a correlation between the passage of ''V. cholerae'' through the human digestive system and an increased infectivity state. Furthermore, the researchers found the bacterium creates a hyperinfected state where genes that control biosynthesis of amino acids, iron uptake systems, and formation of periplasmic nitrate reductase complexes were induced just before defecation. These induced characteristics allow the cholera vibrios to survive in the \"rice water\" stools, an environment of limited oxygen and iron, of patients with a cholera infection.", "page_name": "Cholera", "page_id": "Cholera", "heading": "History", "sub_heading": "History", "_id": "100--8--0---1", "title": "''V. cholerae'': The Bacterial Cause of"}
{"qas": [{"question": "Why is the cholera outbreak in India so much worse than in South Africa?", "answer": ""}, {"question": "In what year was the kottayam district declared cholera-affected?", "answer": "2000", "ae_score": -0.6865725505890967, "qg_score": null}, {"question": "In what year was the kottayam district declared cholera-affected?", "answer": "2000", "ae_score": -0.6865725505890967, "qg_score": null}], "content": "In many developing countries, cholera still reaches its victims through contaminated water sources, and countries without proper sanitation techniques have greater incidence of the disease. Governments can play a role in this. In 2008, for example, the Zimbabwean cholera outbreak was due partly to the government's role, according to a report from the James Baker Institute. The Haitian government\u2019s inability to provide safe drinking water after the 2010 earthquake led to an increase in cholera cases as well.\nSimilarly, South Africa\u2019s cholera outbreak was exacerbated by the government\u2019s policy of privatizing water programs. The wealthy elite of the country were able to afford safe water while others had to use water from cholera-infected rivers.\nAccording to Rita R. Colwell of the James Baker Institute, if cholera does begin to spread, government preparedness is crucial. A government's ability to contain the disease before it extends to other areas can prevent a high death toll and the development of an epidemic or even pandemic. Effective disease surveillance can ensure that cholera outbreaks are recognized as soon as possible and dealt with appropriately. Oftentimes, this will allow public health programs to determine and control the cause of the cases, whether it is unsanitary water or seafood that have accumulated a lot of ''Vibrio cholerae'' specimens. Having an effective surveillance program contributes to a government\u2019s ability to prevent cholera from spreading. In the year 2000 in the state of Kerala in India, the Kottayam district was determined to be \"Cholera-affected\"; this pronouncement led to task forces that concentrated on educating citizens with 13,670 information sessions about human health. These task forces promoted the boiling of water to obtain safe water, and provided chlorine and oral rehydration salts. Ultimately, this helped to control the spread of the disease to other areas and minimize deaths. On the other hand, researchers have shown that most of the citizens infected during the 1991 cholera outbreak in Bangladesh lived in rural areas, and were not recognized by the government's surveillance program. This inhibited physicians' abilities to detect cholera cases early.\nAccording to Colwell, the quality and inclusiveness of a country's health care system affects the control of cholera, as it did in the Zimbabwean cholera outbreak. While sanitation practices are important, when governments respond quickly and have readily available vaccines, the country will have a lower cholera death toll. Affordability of vaccines can be a problem; if the governments do not provide vaccinations, only the wealthy may be able to afford them and there will be a greater toll on the country's poor. The speed with which government leaders respond to cholera outbreaks is important.\nBesides contributing to an effective or declining public health care system and water sanitation treatments, government can have indirect effects on cholera control and the effectiveness of a response to cholera. A country's government can impact its ability to prevent disease and control its spread. A speedy government response backed by a fully functioning health care system and financial resources can prevent cholera's spread. This limits cholera's ability to cause death, or at the very least a decline in education, as children are kept out of school to minimize the risk of infection.", "page_name": "Cholera", "page_id": "Cholera", "heading": "Society and culture", "sub_heading": "Society and culture", "_id": "100--9--0---1", "title": "How Governments Can Influence Cholera Control and Control"}
{"qas": [{"question": "What is the difference between ethics and morals?", "answer": ""}, {"question": "What is the greek word for character, disposition?", "answer": "\u00eathos", "ae_score": -0.4896536108678402, "qg_score": null}, {"question": "What is the greek word for character, disposition?", "answer": "\u00eathos", "ae_score": -0.4896536108678402, "qg_score": null}], "content": "Rushworth Kidder states that \"standard definitions of ''ethics'' have typically included such phrases as 'the science of the ideal human character' or 'the science of moral duty'. Richard William Paul and Linda Elder define ethics as \"a set of concepts and principles that guide us in determining what behavior helps or harms sentient creatures\". The ''Cambridge Dictionary of Philosophy'' states that the word ethics is \"commonly used interchangeably with 'morality' ... and sometimes it is used more narrowly to mean the moral principles of a particular tradition, group or individual.\" Paul and Elder state that most people confuse ethics with behaving in accordance with social conventions, religious beliefs and the law and don't treat ethics as a stand-alone concept.\nThe word \"ethics\" in English refers to several things. It can refer to philosophical ethics or moral philosophy\u2014a project that attempts to use reason in order to answer various kinds of ethical questions. As the English philosopher Bernard Williams writes, attempting to explain moral philosophy: \"What makes an inquiry a philosophical one is reflective generality and a style of argument that claims to be rationally persuasive.\" And Williams describes the content of this area of inquiry as addressing the very broad question, \"how one should live\" Ethics can also refer to a common human ability to think about ethical problems that is not particular to philosophy. As bioethicist Larry Churchill has written: \"Ethics, understood as the capacity to think critically about moral values and direct our actions in terms of such values, is a generic human capacity.\" Ethics can also be used to describe a particular person's own idiosyncratic principles or habits. For example: \"Joe has strange ethics.\"\nThe English word ethics is derived from an Ancient Greek word ''\u00eathikos'', which means \"relating to one's character\". The Ancient Greek adjective ''\u00eathikos'' is itself derived from another Greek word, the noun ''\u00eathos'' meaning \"character, disposition\".", "page_name": "Ethics", "page_id": "Ethics", "heading": "Defining ethics", "sub_heading": "Defining ethics", "_id": "101--0---1---1", "title": "Ethics and Moral Philosophy"}
{"qas": [{"question": "What is the difference between non-descriptivists and non-cognitivists?", "answer": ""}, {"question": "What asks how we understand, know about, and what we mean when we talk about?", "answer": "Meta-ethics", "ae_score": -0.322307899939716, "qg_score": null}, {"question": "In what spheres of inquiry is meta-ethics important?", "answer": "ethics spheres", "ae_score": null, "qg_score": null}], "content": "Meta-ethics asks how we understand, know about, and what we mean when we talk about what is right and what is wrong. An ethical question fixed on some particular practical question\u2014such as, \"Should I eat this particular piece of chocolate cake?\"\u2014cannot be a meta-ethical question. A meta-ethical question is abstract and relates to a wide range of more specific practical questions. For example, \"Is it ever possible to have secure knowledge of what is right and wrong?\" would be a meta-ethical question.\nMeta-ethics has always accompanied philosophical ethics. For example, Aristotle implies that less precise knowledge is possible in ethics than in other spheres of inquiry, and he regards ethical knowledge as depending upon habit and acculturation in a way that makes it distinctive from other kinds of knowledge. Meta-ethics is also important in G.E. Moore's ''Principia Ethica'' from 1903. In it he first wrote about what he called ''the naturalistic fallacy''. Moore was seen to reject naturalism in ethics, in his Open Question Argument. This made thinkers look again at second order questions about ethics. Earlier, the Scottish philosopher David Hume had put forward a similar view on the difference between facts and values.\nStudies of how we know in ethics divide into cognitivism and non-cognitivism; this is similar to the contrast between descriptivists and non-descriptivists. Non-cognitivism is the claim that when we judge something as right or wrong, this is neither true nor false. We may for example be only expressing our emotional feelings about these things. Cognitivism can then be seen as the claim that when we talk about right and wrong, we are talking about matters of fact.\nThe ontology of ethics is about value-bearing things or properties, i.e. the kind of things or stuff referred to by ethical propositions. Non-descriptivists and non-cognitivists believe that ethics does not need a specific ontology, since ethical propositions do not refer. This is known as an anti-realist position. Realists on the other hand must explain what kind of entities, properties or states are relevant for ethics, how they have value, and why they guide and motivate our actions.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Meta-ethics", "sub_heading": "Meta-ethics", "_id": "101--1---1---1", "title": "Meta-ethics and the Philosophy of Ethics"}
{"qas": [{"question": "What is virtue ethics?", "answer": ""}, {"question": "What is the term for the ethical system that aristotle posited?", "answer": "self-realizationism", "ae_score": -0.37433872501421583, "qg_score": null}, {"question": "What term is used to describe the character of a moral agent as a driving force for?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Virtue ethics describes the character of a moral agent as a driving force for ethical behavior, and is used to describe the ethics of Socrates, Aristotle, and other early Greek philosophers. Socrates (469\u2013399 BC) was one of the first Greek philosophers to encourage both scholars and the common citizen to turn their attention from the outside world to the condition of humankind. In this view, knowledge bearing on human life was placed highest, while all other knowledge were secondary. Self-knowledge was considered necessary for success and inherently an essential good. A self-aware person will act completely within his capabilities to his pinnacle, while an ignorant person will flounder and encounter difficulty. To Socrates, a person must become aware of every fact (and its context) relevant to his existence, if he wishes to attain self-knowledge. He posited that people will naturally do what is good, if they know what is right. Evil or bad actions are the result of ignorance. If a criminal was truly aware of the intellectual and spiritual consequences of his actions, he would neither commit nor even consider committing those actions. Any person who knows what is truly right will automatically do it, according to Socrates. While he correlated knowledge with virtue, he similarly equated virtue with joy. The truly wise man will know what is right, do what is good, and therefore be happy.\nAristotle (384\u2013323 BC) posited an ethical system that may be termed \"self-realizationism\". In Aristotle's view, when a person acts in accordance with his nature and realizes his full potential, he will do good and be content. At birth, a baby is not a person, but a potential person. To become a \"real\" person, the child's inherent potential must be realized. Unhappiness and frustration are caused by the unrealized potential of a person, leading to failed goals and a poor life. Aristotle said, \"Nature does nothing in vain.\" Therefore, it is imperative for people to act in accordance with their nature and develop their latent talents in order to be content and complete. Happiness was held to be the ultimate goal. All other things, such as civic life or wealth, are merely means to the end. Self-realization, the awareness of one's nature and the development of one's talents, is the surest path to happiness.\nAristotle asserted that man had three natures: vegetable (physical/metabolism), animal (emotional/appetite) and rational (mental/conceptual). Physical nature can be assuaged through exercise and care, emotional nature through indulgence of instinct and urges, and mental through human reason and developed potential. Rational development was considered the most important, as essential to philosophical self-awareness and as uniquely human. Moderation was encouraged, with the extremes seen as degraded and immoral. For example, courage is the moderate virtue between the extremes of cowardice and recklessness. Man should not simply live, but live well with conduct governed by moderate virtue. This is regarded as difficult, as virtue denotes doing the right thing, to the right person, at the right time, to the proper extent, in the correct fashion, for the right reason.\nThe Stoic philosopher Epictetus posited that the greatest good was contentment and serenity. Peace of mind, or Apatheia, was of the highest value; self-mastery over one's desires and emotions leads to spiritual peace. The \"unconquerable will\" is central to this philosophy. The individual's will should be independent and inviolate. Allowing a person to disturb the mental equilibrium is in essence offering yourself in slavery. If a person is free to anger you at will, you have no control over your internal world, and therefore no freedom. Freedom from material attachments is also necessary. If a thing breaks, the person should not be upset, but realize it was a thing that could break. Similarly, if someone should die, those close to them should hold to their serenity because the loved one was made of flesh and blood destined to death. Stoic philosophy says to accept things that cannot be changed, resigning oneself to existence and enduring in a rational fashion. Death is not feared. People do not \"lose\" their life, but instead \"return\", for they are returning to God (who initially gave what the person is as a person). Epictetus said difficult problems in life should not be avoided, but rather embraced. They are spiritual exercises needed for the health of the spirit, just as physical exercise is required for the health of the body. He also stated that sex and sexual desire are to be avoided as the greatest threat to the integrity and equilibrium of a man's mind. Abstinence is highly desirable. Epictetus said remaining abstinent in the face of temptation was a victory for which a man could be proud.\nModern virtue ethics was popularized during the late 20th century in large part as a response to G. E. M. Anscombe's \"Modern Moral Philosophy\". Anscombe argues that consequentialist and deontological ethics are only feasible as universal theories if the two schools ground themselves in divine law. As a deeply devoted Christian herself, Anscombe proposed that either those who do not give ethical credence to notions of divine law take up virtue ethics, which does not necessitate universal laws as agents themselves are investigated for virtue or vice and held up to \"universal standards\", or that those who wish to be utilitarian or consequentialist ground their theories in religious conviction. Alasdair MacIntyre, who wrote the book ''After Virtue'', was a key contributor and proponent of modern virtue ethics, although MacIntyre supports a relativistic account of virtue based on cultural norms, not objective standards. Martha Nussbaum, a contemporary virtue ethicist, objects to MacIntyre's relativism, among that of others, and responds to relativist objections to form an objective account in her work \"Non-Relative Virtues: An Aristotelian Approach\".''Complete Conduct Principles for the 21st Century'' blended the Eastern virtue ethics and the Western virtue ethics, with some modifications to suit the 21st Century, and formed a part of contemporary virtue ethics.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Normative ethics", "_id": "101--2--0---1", "title": "Virtue Ethics in the 20th Century"}
{"qas": [{"question": "What is Hedonism?", "answer": ""}, {"question": "What philosophy encouraged the pursuit of enjoyment and indulgence without hesitation?", "answer": "Cyrenaic hedonism", "ae_score": -0.7901655031398701, "qg_score": null}, {"question": "What type of ethics did Epicurus believe should be based on reason and reason?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Hedonism posits that the principal ethic is maximizing pleasure and minimizing pain. There are several schools of Hedonist thought ranging from those advocating the indulgence of even momentary desires to those teaching a pursuit of spiritual bliss. In their consideration of consequences, they range from those advocating self-gratification regardless of the pain and expense to others, to those stating that the most ethical pursuit maximizes pleasure and happiness for the most people.\nFounded by Aristippus of Cyrene, Cyrenaics supported immediate gratification or pleasure. \"Eat, drink and be merry, for tomorrow we die.\" Even fleeting desires should be indulged, for fear the opportunity should be forever lost. There was little to no concern with the future, the present dominating in the pursuit for immediate pleasure. Cyrenaic hedonism encouraged the pursuit of enjoyment and indulgence without hesitation, believing pleasure to be the only good.\nEpicurean ethics is a hedonist form of virtue ethics. Epicurus \"presented a sustained argument that pleasure, correctly understood, will coincide with virtue\". He rejected the extremism of the Cyrenaics, believing some pleasures and indulgences to be detrimental to human beings. Epicureans observed that indiscriminate indulgence sometimes resulted in negative consequences. Some experiences were therefore rejected out of hand, and some unpleasant experiences endured in the present to ensure a better life in the future. To Epicurus the ''summum bonum'', or greatest good, was prudence, exercised through moderation and caution. Excessive indulgence can be destructive to pleasure and can even lead to pain. For example, eating one food too often will cause a person to lose taste for it. Eating too much food at once will lead to discomfort and ill-health. Pain and fear were to be avoided. Living was essentially good, barring pain and illness. Death was not to be feared. Fear was considered the source of most unhappiness. Conquering the fear of death would naturally lead to a happier life. Epicurus reasoned if there was an afterlife and immortality, the fear of death was irrational. If there was no life after death, then the person would not be alive to suffer, fear or worry; he would be non-existent in death. It is irrational to fret over circumstances that do not exist, such as one's state in death in the absence of an afterlife.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Hedonism", "_id": "101--2--1---1", "title": "Hedonism and Virtue Ethics"}
{"qas": [{"question": "What is the difference between Mohism and State consequentialism?", "answer": ""}, {"question": "What is another name for state consequentialism?", "answer": "Mohist consequentialism", "ae_score": -0.3047944524285538, "qg_score": null}, {"question": "What is an ethical theory that evaluates the moral worth of an action based on how much?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "State consequentialism, also known as Mohist consequentialism, is an ethical theory that evaluates the moral worth of an action based on how much it contributes to the basic goods of a state.<ref name=readings/> The ''Stanford Encyclopedia of Philosophy'' describes Mohist consequentialism, dating back to the 5th century BC, as \"a remarkably sophisticated version based on a plurality of intrinsic goods taken as constitutive of human welfare\". Unlike utilitarianism, which views pleasure as a moral good, \"the basic goods in Mohist consequentialist thinking are ... order, material wealth, and increase in population\". During Mozi's era, war and famines were common, and population growth was seen as a moral necessity for a harmonious society. The \"material wealth\" of Mohist consequentialism refers to basic needs like shelter and clothing, and the \"order\" of Mohist consequentialism refers to Mozi's stance against warfare and violence, which he viewed as pointless and a threat to social stability.\nStanford sinologist David Shepherd Nivison, in ''The Cambridge History of Ancient China'', writes that the moral goods of Mohism \"are interrelated: more basic wealth, then more reproduction; more people, then more production and wealth ... if people have plenty, they would be good, filial, kind, and so on unproblematically.\" The Mohists believed that morality is based on \"promoting the benefit of all under heaven and eliminating harm to all under heaven\". In contrast to Bentham's views, state consequentialism is not utilitarian because it is not hedonistic or individualistic. The importance of outcomes that are good for the community outweigh the importance of individual pleasure and pain.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "State consequentialism", "_id": "101--2--2---1", "title": "Ethics | Normative ethics | State consequentialism"}
{"qas": [{"question": "What is the difference between utilitarianism and consequentialism?", "answer": ""}, {"question": "What term refers to moral theories that hold that the consequences of a particular action form the?", "answer": "Consequentialism", "ae_score": -0.2186656676522853, "qg_score": null}, {"question": "What is the term for moral theories that hold that the consequences of a particular action form?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "Consequentialism refers to moral theories that hold that the consequences of a particular action form the basis for any valid moral judgment about that action (or create a structure for judgment, see rule consequentialism). Thus, from a consequentialist standpoint, a morally right action is one that produces a good outcome, or consequence. This view is often expressed as the aphorism ''\"The ends justify the means\"''.\nThe term \"consequentialism\" was coined by G. E. M. Anscombe in her essay \"Modern Moral Philosophy\" in 1958, to describe what she saw as the central error of certain moral theories, such as those propounded by Mill and Sidgwick. Since then, the term has become common in English-language ethical theory.\nThe defining feature of consequentialist moral theories is the weight given to the consequences in evaluating the rightness and wrongness of actions. In consequentialist theories, the consequences of an action or rule generally outweigh other considerations. Apart from this basic outline, there is little else that can be unequivocally said about consequentialism as such. However, there are some questions that many consequentialist theories address:\nOne way to divide various consequentialisms is by the types of consequences that are taken to matter most, that is, which consequences count as good states of affairs. According to utilitarianism, a good action is one that results in an increase in a positive effect, and the best action is one that results in that effect for the greatest number. Closely related is eudaimonic consequentialism, according to which a full, flourishing life, which may or may not be the same as enjoying a great deal of pleasure, is the ultimate aim. Similarly, one might adopt an aesthetic consequentialism, in which the ultimate aim is to produce beauty. However, one might fix on non-psychological goods as the relevant effect. Thus, one might pursue an increase in material equality or political liberty instead of something like the more ephemeral \"pleasure\". Other theories adopt a package of several goods, all to be promoted equally.  Whether a particular consequentialist theory focuses on a single good or many, conflicts and tensions between different good states of affairs are to be expected and must be adjudicated.\nUtilitarianism is an ethical theory that argues the proper course of action is one that maximizes a positive effect, such as \"happiness\", \"welfare\", or the ability to live according to personal preferences. Jeremy Bentham and John Stuart Mill are influential proponents of this school of thought.  In ''A Fragment on Government'' Bentham says 'it is the greatest happiness of the greatest number that is the measure of right and wrong' and describes this as a fundamental axiom. In ''An Introduction to the Principles of Morals and Legislation'' he talks of 'the principle of utility' but later prefers \"the greatest happiness principle\".\nUtilitarianism is the paradigmatic example of a consequentialist moral theory. This form of utilitarianism holds that what matters is the aggregate positive effect of everyone and not only of any one person. John Stuart Mill, in his exposition of utilitarianism, proposed a hierarchy of pleasures, meaning that the pursuit of certain kinds of pleasure is more highly valued than the pursuit of other pleasures. Other noteworthy proponents of utilitarianism are neuroscientist Sam Harris, author of The Moral Landscape, and moral philosopher Peter Singer, author of, amongst other works, Practical Ethics.\nThere are two types of utilitarianism, act utilitarianism and rule utilitarianism. In act utilitarianism the principle of utility is applied directly to each alternative act in a situation of choice. The right act is then defined as the one which brings about the best results (or the least amount of bad results). In rule utilitarianism the principle of utility is used to determine the validity of rules of conduct (moral principles). A rule like promise-keeping is established by looking at the consequences of a world in which people broke promises at will and a world in which promises were binding. Right and wrong are then defined as following or breaking those rules.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Consequentialism/Teleology", "_id": "101--2--3---1", "title": "What is consequentialism?"}
{"qas": [{"question": "What is deontological ethics?", "answer": ""}, {"question": "Who argued that the highest good must be both good in itself and good without qualification?", "answer": "Kant", "ae_score": null, "qg_score": null}, {"question": "What type of ethics is based on the consequences of an act?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Deontological ethics or deontology (from Greek \u03b4\u03ad\u03bf\u03bd, ''deon'', \"obligation, duty\"; and -\u03bb\u03bf\u03b3\u03af\u03b1, ''-logia'') is an approach to ethics that determines goodness or rightness from examining acts, or the rules and duties that the person doing the act strove to fulfill.  This is in contrast to consequentialism, in which rightness is based on the consequences of an act, and not the act by itself. In deontology, an act may be considered right even if the act produces a bad consequence, if it follows the ''rule'' that \"one should do unto others as they would have done unto them\", and even if the person who does the act lacks virtue and had a bad intention in doing the act.  According to deontology, people have a ''duty'' to act in a way that does those things that are inherently good as acts (\"truth-telling\" for example), or follow an objectively obligatory rule (as in rule utilitarianism).  For deontologists, the ends or consequences of people's actions are not important in and of themselves, and people's intentions are not important in and of themselves.\nImmanuel Kant's theory of ethics is considered deontological for several different reasons. First, Kant argues that to act in the morally right way, people must act from duty (''deon''). Second, Kant argued that it was not the consequences of actions that make them right or wrong but the motives (maxime) of the person who carries out the action. Kant's argument that to act in the morally right way, one must act from duty, begins with an argument that the highest good must be both good in itself, and good without qualification. Something is 'good in itself' when it is intrinsically good, and 'good without qualification' when the addition of that thing never makes a situation ethically worse. Kant then argues that those things that are usually thought to be good, such as intelligence, perseverance and pleasure, fail to be either intrinsically good or good without qualification. Pleasure, for example, appears to not be good without qualification, because when people take pleasure in watching someone suffer, they make the situation ethically worse. He concludes that there is only one thing that is truly good:", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Deontology", "_id": "101--2--4---1", "title": "Deontological Ethics \u2014 Kant, Kant, Kant, Kant, and"}
{"qas": [{"question": "What is pragmatic ethics?", "answer": ""}, {"question": "What holds that moral correctness evolves similarly to scientific knowledge socially over the course of many lif?", "answer": "pragmatic ethics", "ae_score": -0.6956614832311188, "qg_score": null}, {"question": "What type of ethics holds that moral correctness evolves similarly to scientific knowledge socially over the course?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Associated with the pragmatists, Charles Sanders Peirce, William James, and especially John Dewey, pragmatic ethics holds that moral correctness evolves similarly to scientific knowledge: socially over the course of many lifetimes. Thus, we should prioritize social reform over attempts to account for consequences, individual virtue or duty (although these may be worthwhile attempts, provided social reform is provided for).", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Pragmatic ethics", "_id": "101--2--5---1", "title": "Pragmatist Ethics \u2014 Social Reform"}
{"qas": [{"question": "What is role ethics?", "answer": ""}, {"question": "What is an ethical theory based on family roles?", "answer": "Role ethics", "ae_score": -0.7652279012278467, "qg_score": null}, {"question": "What is an ethical theory based on family roles?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Role ethics is an ethical theory based on family roles. Unlike virtue ethics, role ethics is not individualistic. Morality is derived from a person's relationship with their community. Confucian ethics is an example of role ethics. Confucian roles center around the concept of filial piety or ''xiao'', a respect for family members. According to Roger Ames and Henry Rosemont, \"Confucian normativity is defined by living one's family roles to maximum effect.\" Morality is determined through a person's fulfillment of a role, such as that of a parent or a child. Confucian roles are not rational, and originate through the ''xin'', or human emotions.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Role ethics", "_id": "101--2--6---1", "title": "Confucian Role Ethics"}
{"qas": [{"question": "Anarchist Ethics?", "answer": ""}, {"question": "Which russian zoologist, geographer, economist, and political activist is credited with?", "answer": "Peter Kropotkin", "ae_score": -0.46777161042224735, "qg_score": null}, {"question": "What type of ethics is based on the studies of anarchists?", "answer": "anarchist ethics", "ae_score": null, "qg_score": null}], "content": "Anarchist ethics is an ethical theory based on the studies of anarchist thinkers. The biggest contributor to the anarchist ethics is the Russian zoologist, geographer, economist and political activist Peter Kropotkin. The anarchist ethics is a big and vague field which can depend upon different historical situations and different anarchist thinkers, but as Peter Kropotkin explains, \"any \u201cbourgeois\u201d or \u201cproletarian\u201d ethics rests, after all, on the common basis, on the common ethnological foundation, which at times exerts a very strong in\ufb02uence on the principles of the class or group morality.\" Still, most of the anarchist ethics schools are based on three fundamental ideas, which are: \"solidarity, equality and justice\". Kropotkin argues that Ethics is evolutionary and is inherited as a sort of a social instinct through History, and by so, he rejects any religious and transcendental explanation of ethics. Kropotkin suggests that the principle of equality which lies at the basis of anarchism is the same as the Golden rule: ", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Anarchist ethics", "_id": "101--2--7---1", "title": "Anarchist Ethics \u2014 Peter Kropotkin. Anarchist ethics is an ethical theory"}
{"qas": [{"question": "Why is it so hard to find a good answer to a simple question?", "answer": ""}, {"question": "Who concluded that all humans are born with the same set of genes?", "answer": "Hoy", "ae_score": -0.08565096974837734, "qg_score": null}, {"question": "What causes will remain in the ethical realm until legislation or the state apparatus addresses?", "answer": "ethical resistance", "ae_score": null, "qg_score": null}], "content": "The 20th century saw a remarkable expansion and evolution of critical theory, following on earlier Marxist Theory efforts to locate individuals within larger structural frameworks of ideology and action.\nAntihumanists such as Louis Althusser and Michel Foucault and structuralists such as Roland Barthes challenged the possibilities of individual agency and the coherence of the notion of the 'individual' itself. As critical theory developed in the later 20th century, post-structuralism sought to problematize human relationships to knowledge and 'objective' reality. Jacques Derrida argued that access to meaning and the 'real' was always deferred, and sought to demonstrate via recourse to the linguistic realm that \"there is nothing outside context\" (\"''il n'y a pas de hors-texte''\" is often mistranslated as \"there is nothing outside the text\"); at the same time, Jean Baudrillard theorised that signs and symbols or simulacra mask reality (and eventually the absence of reality itself), particularly in the consumer world.\nPost-structuralism and postmodernism argue that ethics must study the complex and relational conditions of actions.  A simple alignment of ideas of right and particular acts is not possible.  There will always be an ethical remainder that cannot be taken into account or often even recognized.  Such theorists find narrative (or, following Nietzsche and Foucault, genealogy) to be a helpful tool for understanding ethics because narrative is always about particular lived experiences in all their complexity rather than the assignment of an idea or norm to separate and individuated actions.\nZygmunt Bauman says Postmodernity is best described as Modernity without illusion, the illusion being the belief that humanity can be repaired by some ethic principle.  Postmodernity can be seen in this light as accepting the messy nature of humanity as unchangeable.\nDavid Couzens Hoy states that Emmanuel Levinas's writings on the face of the Other and Derrida's meditations on the relevance of death to ethics are signs of the \"ethical turn\" in Continental philosophy that occurred in the 1980s and 1990s. Hoy describes post-critique ethics as the \"obligations that present themselves as necessarily to be fulfilled but are neither forced on one or are enforceable\" (2004, p. 103).\nHoy's post-critique model uses the term ''ethical resistance''. Examples of this would be an individual's resistance to consumerism in a retreat to a simpler but perhaps harder lifestyle, or an individual's resistance to a terminal illness. Hoy describes Levinas's account as \"not the attempt to use power against itself, or to mobilize sectors of the population to exert their political power; the ethical resistance is instead the resistance of the powerless\"(2004, p. 8).\nHoy concludes that\nIn present-day terms the powerless may include the unborn, the terminally sick, the aged, the insane, and non-human animals. It is in these areas that ethical action in Hoy's sense will apply. Until legislation or the state apparatus enforces a moral order that addresses the causes of resistance these issues will remain in the ethical realm. For example, should animal experimentation become illegal in a society, it will no longer be an ethical issue on Hoy's definition. Likewise one hundred and fifty years ago, not having a black slave in America would have been an ethical choice. This later issue has been absorbed into the fabric of an enforceable social order and is therefore no longer an ethical issue in Hoy's sense.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Normative ethics", "sub_heading": "Postmodern ethics", "_id": "101--2--8---1", "title": "The Ethics of Post-Critical Ethics"}
{"qas": [{"question": "Why is it not ethical to ask the same questions as asking the same question in court?", "answer": ""}, {"question": "What do not all questions studied in applied ethics concern?", "answer": "public policy", "ae_score": -0.5430146775254918, "qg_score": null}, {"question": "What do not all questions studied in applied ethics concern?", "answer": "public policy", "ae_score": -0.5430146775254918, "qg_score": null}], "content": "Applied ethics is used in some aspects of determining public policy, as well as by individuals facing difficult decisions. The sort of questions addressed by applied ethics include: \"Is getting an abortion immoral?\" \"Is euthanasia immoral?\" \"Is affirmative action right or wrong?\" \"What are human rights, and how do we determine them?\" \"Do animals have rights as well?\" and \"Do individuals have the right of self determination?\"<ref name=bbc/>\nA more specific question could be: \"If someone else can make better out of his/her life than I can, is it then moral to sacrifice myself for them if needed?\" Without these questions there is no clear fulcrum on which to balance law, politics, and the practice of arbitration\u2014in fact, no common assumptions of all participants\u2014so the ability to formulate the questions are prior to rights balancing. But not all questions studied in applied ethics concern public policy. For example, making ethical judgments regarding questions such as, \"Is lying always wrong?\" and, \"If not, when is it permissible?\" is prior to any etiquette.\nPeople in-general are more comfortable with dichotomies (two opposites).  However, in ethics the issues are most often multifaceted and the best proposed actions address many different areas concurrently. In ethical decisions the answer is almost never a \"yes or no\", \"right or wrong\" statement. Many buttons are pushed so that the overall condition is improved and not to the benefit of any particular faction.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Applied ethics", "sub_heading": "Applied ethics", "_id": "101--3--0---1", "title": "Applied Ethics \u2014 Part 1"}
{"qas": [{"question": "What is the difference between military ethics and war theory?", "answer": ""}, {"question": "What is the set of principles that govern the writing and publishing process for professional publications?", "answer": "Publication ethics", "ae_score": -0.17470086609256494, "qg_score": null}, {"question": "What type of ethics are used in qualitative research?", "answer": "relational ethics", "ae_score": null, "qg_score": null}], "content": "Bioethics is the study of controversial ethics brought about by advances in biology and medicine. Bioethicists are concerned with the ethical questions that arise in the relationships among life sciences, biotechnology, medicine, politics, law, and philosophy. It also includes the study of the more commonplace questions of values (\"the ethics of the ordinary\") that arise in primary care and other branches of medicine.\nBioethics also needs to address emerging biotechnologies that affect basic biology and future humans. These developments include cloning, gene therapy, human genetic engineering, astroethics and life in space, and manipulation of basic biology through altered DNA, RNA and proteins,e.g.- \"three parent baby,where baby is born from genetically modified embryos, would have DNA from a mother, a father and from a female donor. Correspondingly, new bioethics also need to address life at its core. For example, biotic ethics value organic gene/protein life itself and seek to propagate it. With such life-centered principles, ethics may secure a cosmological future for life.\nBusiness ethics (also corporate ethics) is a form of applied ethics or professional ethics that examines ethical principles and moral or ethical problems that arise in a business environment, including fields like Medical ethics. It applies to all aspects of business conduct and is relevant to the conduct of individuals and entire organizations.\nBusiness ethics has both normative and descriptive dimensions. As a corporate practice and a career specialization, the field is primarily normative. Academics attempting to understand business behavior employ descriptive methods. The range and quantity of business ethical issues reflects the interaction of profit-maximizing behavior with non-economic concerns. Interest in business ethics accelerated dramatically during the 1980s and 1990s, both within major corporations and within academia. For example, today most major corporations promote their commitment to non-economic values under headings such as ethics codes and social responsibility charters. Adam Smith said, \"People of the same trade seldom meet together, even for merriment and diversion, but the conversation ends in a conspiracy against the public, or in some contrivance to raise prices.\" Governments use laws and regulations to point business behavior in what they perceive to be beneficial directions. Ethics implicitly regulates areas and details of behavior that lie beyond governmental control. The emergence of large corporations with limited relationships and sensitivity to the communities in which they operate accelerated the development of formal ethics regimes.\nIn ''Moral Machines: Teaching Robots Right from Wrong'', Wendell Wallach and Colin Allen conclude that issues in machine ethics will likely drive advancement in understanding of human ethics by forcing us to address gaps in modern normative theory and by providing a platform for experimental investigation. The effort to actually program a machine or artificial agent to behave as though instilled with a sense of ethics requires new specificity in our normative theories, especially regarding aspects customarily considered common-sense. For example, machines, unlike humans, can support a wide selection of learning algorithms, and controversy has arisen over the relative ethical merits of these options. This may reopen classic debates of normative ethics framed in new (highly technical) terms.\nMilitary ethics are concerned with questions regarding the application of force and the ethos of the soldier and are often understood as applied professional ethics. Just war theory is generally seen to set the background terms of military ethics. However individual countries and traditions have different fields of attention.\nMilitary ethics involves multiple subareas, including the following among others:\nPolitical ethics (also known as political morality or public ethics) is the practice of making moral judgements about political action and political agents.\nPublic sector ethics is a set of principles that guide public officials in their service to their constituents, including their decision-making on behalf of their constituents.  Fundamental to the concept of public sector ethics is the notion that decisions and actions are based on what best serves the public's interests, as opposed to the official's personal interests (including financial interests) or self-serving political interests.\nPublication ethics is the set of principles that guide the writing and publishing process for all professional publications. In order to follow the set of principles, authors should verify that the publication does not contain plagiarism or publication bias. As a way to avoid misconduct in research these principles can also be applied to experiments which are referenced or analyzed in publications by ensuring the data is recorded, honestly and accurately.\nPlagiarism is the failure to give credit to another author\u2019s work or ideas, when it is used in the publication. It is the obligation of the editor of the journal to ensure the article does not contain any plagiarism before it is published. If a publication which has already been published is proven to contain plagiarism, then the editor of the journal can proceed to have the article retracted.\nPublication bias occurs when the publication is one-sided or \"prejudiced against results\". In best practice, an author should try to include information from all parties involved, or affected by the topic. If an author is prejudiced against certain results, than it can \"lead to erroneous conclusions being drawn.\u201d\nMisconduct in research can occur when information from an experiment is falsely recorded or altered. Falsely recorded information occurs when the researcher \"fakes\" information or data, which was not used when conducting the actual experiment. By faking the data, the researcher can alter the results from the experiment to better fit the hypothesis they originally predicted. When conducting medical research, it is important to honor the healthcare rights of a patient by protecting their anonymity in the publication.\nRelational ethics are related to an ethics of care. They are used in qualitative research, especially ethnography and autoethnography. Researchers who employ relational ethics value and respect the connection between themselves and the people they study, and \"between researchers and the communities in which they live and work\" (Ellis, 2007, p. 4). Relational ethics also help researchers understand difficult issues such as conducting research on intimate others that have died and developing friendships with their participants. Relational ethics in close personal relationships form a central concept of contextual therapy.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Applied ethics", "sub_heading": "Particular fields of application", "_id": "101--3--1---1", "title": "The Evolution of Moral Ethics in the 21st Century"}
{"qas": [{"question": "What is \"moral psychology\"?", "answer": ""}, {"question": "What concerns approaches to ethics based on the role of evolution in shaping human psychology and behavior?", "answer": "Evolutionary ethics", "ae_score": -0.4353276705336003, "qg_score": null}, {"question": "What concerns approaches to ethics based on the role of evolution in shaping human psychology and behavior?", "answer": "Evolutionary ethics", "ae_score": -0.4353276705336003, "qg_score": null}], "content": "'''Moral psychology''' is a field of study that began as an issue in philosophy and that is now properly considered part of the discipline of psychology.  Some use the term \"moral psychology\" relatively narrowly to refer to the study of moral development. However, others tend to use the term more broadly to include any topics at the intersection of ethics and psychology (and philosophy of mind). Such topics are ones that involve the mind and are relevant to moral issues. Some of the main topics of the field are moral responsibility, moral development, moral character (especially as related to virtue ethics), altruism, psychological egoism, moral luck, and moral disagreement.\nEvolutionary ethics concerns approaches to ethics (morality) based on the role of evolution in shaping human psychology and behavior. Such approaches may be based in scientific fields such as evolutionary psychology or sociobiology, with a focus on understanding and explaining observed ethical preferences and choices.", "page_name": "Ethics", "page_id": "Ethics", "heading": "Moral psychology", "sub_heading": "Moral psychology", "_id": "101--4---1---1", "title": "Moral Psychology (Moral Psychology)"}
{"qas": [{"question": "Descriptive Ethics?", "answer": ""}, {"question": "What type of ethics is descriptive ethics?", "answer": "a social science", "ae_score": -1.875751874556018, "qg_score": null}, {"question": "What type of ethics seeks to gather information about how people live?", "answer": "descriptive ethics", "ae_score": null, "qg_score": null}], "content": "Descriptive ethics is on the less philosophical end of the spectrum, since it seeks to gather particular information about how people live and draw general conclusions based on observed patterns. Abstract and theoretical questions that are more clearly philosophical\u2014such as, \"Is ethical knowledge possible?\"\u2014are not central to descriptive ethics. Descriptive ethics offers a value-free approach to ethics, which defines it as a social science rather than a humanity.  Its examination of ethics doesn't start with a preconceived theory, but rather investigates observations of actual choices made by moral agents in practice. Some philosophers rely on descriptive ethics and choices made and unchallenged by a society or culture to derive categories, which typically vary by context. This can lead to situational ethics and situated ethics. These philosophers often view aesthetics, etiquette, and arbitration as more fundamental, percolating \"bottom up\" to imply the existence of, rather than explicitly prescribe, theories of value or of conduct. The study of descriptive ethics may include examinations of the following:", "page_name": "Ethics", "page_id": "Ethics", "heading": "Descriptive ethics", "sub_heading": "Descriptive ethics", "_id": "101--5---1---1", "title": "Descriptive Ethics: A Social Science Approach"}
{"qas": [{"question": "Why do some foods taste better when they're sour?", "answer": ""}, {"question": "What compounds can be considered flavorants that enhance salty and sweet tastes?", "answer": "salt and sugar", "ae_score": -0.6651935210825091, "qg_score": null}, {"question": "What compounds can be considered flavorants that enhance salty and sweet tastes?", "answer": "salt and sugar", "ae_score": -0.6651935210825091, "qg_score": null}], "content": "While salt and sugar can technically be considered flavorants that enhance salty and sweet tastes, usually only compounds that enhance umami, as well as other secondary flavors are considered and referred to as ''taste flavorants''. Artificial sweeteners are also technically flavorants.\nUmami or \"savory\" flavorants, more commonly called taste or flavor enhancers, are largely based on amino acids and nucleotides. These are typically used as sodium or calcium salts. Umami flavorants recognized and approved by the European Union include:\nCertain organic and inorganic acids can be used to enhance sour tastes, but like salt and sugar these are usually not considered and regulated as flavorants under law. Each acid imparts a slightly different sour or tart taste that alters the flavor of a food.", "page_name": "Flavor", "page_id": "Flavor", "heading": "Flavorants or flavorings", "sub_heading": "Flavorants or flavorings", "_id": "102--0--0---1", "title": "Umami flavorants (Sour and Tart)"}
{"qas": [{"question": "Why do some drinks taste better when they're darker?", "answer": ""}, {"question": "How many studies have shown that adding more red color to a drink increases the perceived sweetness?", "answer": "one", "ae_score": null, "qg_score": null}, {"question": "How many studies have shown that adding more red color to a drink increases the perceived sweetness?", "answer": "one", "ae_score": null, "qg_score": null}], "content": "The color of food can affect one's expectations of the flavor significantly.In one study, adding more red color to a drink increased the perceived sweetness with  darker colored solutions being rated 2\u201310% better than lighter ones, even though it had 1% less sucrose concentration.", "page_name": "Flavor", "page_id": "Flavor", "heading": "Flavorants or flavorings", "sub_heading": "Color", "_id": "102--0--1---1", "title": "The Color of Food Can Influence Your Expectation of the Taste"}
{"qas": [{"question": "Why is it that people with known sensitivities to food products are advised to avoid foods that contain generic \"natural flavors\"?", "answer": ""}, {"question": "What does uk food law define as?", "answer": "a natural flavor", "ae_score": -0.23947276097119263, "qg_score": null}, {"question": "What does uk food law define as?", "answer": "a natural flavor", "ae_score": -0.23947276097119263, "qg_score": null}], "content": "UK Food Law defines a natural flavor as:\nThe U.S. Code of Federal Regulations describes a \"natural flavorant\" as:\nThe European Union's guidelines for natural flavorants are slightly different. Certain artificial flavorants are given an E number, which may be included on food labels.\nFood manufacturers are sometimes reluctant to inform consumers about the source and identity of flavor ingredients and whether they have been produced with the incorporation of substances such as animal by-products.  Some flavor ingredients, such as gelatin, are produced from animal products.  Some, such as glycerin can be derived from either animal or vegetable sources.  And some extracts, such as vanilla, may contain alcohol.   Many Jews, Jains, Hindus, and Muslims adhere to religious dietary laws, and vegans to personal convictions, which restrict the use of animal by-products and/or alcohol in foods unless subject to oversight and inspection by their respective religious authority or moral beliefs.  In many Western countries some consumers rely on a Jewish Kosher Pareve certification mark to indicate that natural flavorings used in a food product are free of meat and dairy (although they can still contain fish). The Vegan Society's Sunflower symbol (which is currently used by over 260 companies worldwide) can also be used to see which products do not use any animal ingredients (including flavorings and colorings).\nSimilarly, persons with known sensitivities or allergies to food products are advised to avoid foods that contain generic \"natural flavors\" or to first determine the source of the flavoring before consuming the food.  Such flavors may be derived from a variety of source products that are themselves common allergens, such as dairy, soy, sesame, eggs, and nuts.", "page_name": "Flavor", "page_id": "Flavor", "heading": "Restrictions and regulations", "sub_heading": "Restrictions and regulations", "_id": "102--1---1---1", "title": "Natural Flavorings \u2014 A Guide for Vegans and Non-Vegetarian"}
{"qas": [{"question": "How do food companies ensure that the flavor of their food doesn't go out of date?", "answer": ""}, {"question": "Who is the person that creates the flavor?", "answer": "flavorist", "ae_score": -0.6282585397632032, "qg_score": null}, {"question": "Who is the person that creates the flavor?", "answer": "flavorist", "ae_score": -0.6282585397632032, "qg_score": null}], "content": "Food and beverage companies may require flavors for new products, product line extensions (e.g., low fat versions of existing products) or changes in formula or processing for existing products. In 2011, about US$10.6 billion were generated with the sale of flavors; the majority of the flavors used are consumed in processed and packaged food.\nMost flavors represent a mixture of aroma compounds, the raw material that is produced by flavor companies. In rare cases, a single synthetic compound is used in pure form. Artificial vanilla flavors vanillin and ethylvanillin are a notable exception, as well as the artificial strawberry flavor (ethyl methylphenylglycidate). The ubiquitous \"green apple\" aroma is based on hexyl acetate.\nThe flavor creation is done by a specially trained scientist called a \"flavorist\". The flavorist's job combines scientific knowledge of the chemical palette with creativity to develop new and distinctive flavors. The flavor creation begins when the flavorist receives a brief from the client. In the brief the client will attempt to communicate exactly what type of flavor they seek, in what application it will be used, and any special requirements (e.g., must be all natural). The communication barrier can be quite difficult to overcome since most people aren't experienced at describing flavors. The flavorist will use his or her knowledge of the available chemical ingredients to create a formula and compound it on an electronic balance. The flavor will then be submitted to the client for testing. Several iterations, with feedback from the client, may be needed before the right flavor is found.\nAdditional work may also be done by the flavor company. For example, the flavor company may conduct sensory taste tests to test consumer acceptance of a flavor before it is sent to the client or to further investigate the \"sensory space.\" The flavor company may also employ application specialists who work to ensure the flavor will work in the application for which it is intended. This may require special flavor delivery technologies that are used to protect the flavor during processing or cooking so that the flavor is only released when eaten by the end consumer.", "page_name": "Flavor", "page_id": "Flavor", "heading": "Flavor creation", "sub_heading": "Flavor creation", "_id": "102--2---1---1", "title": "The Art of Flavor Creation"}
{"qas": [{"question": "How do they figure out what flavors are in food?", "answer": ""}, {"question": "What is another name for solid phase extraction?", "answer": "SPE", "ae_score": null, "qg_score": null}, {"question": "What is another name for solid phase extraction?", "answer": "SPE", "ae_score": null, "qg_score": null}], "content": "Few standards are available or being prepared for sensory analysis of flavors. In chemical analysis of flavors, solid phase extraction (SPE), solid phase microextraction (SPME), and headspace gas chromatography are applied to extract and separate the flavor compounds in the sample. The determination is typically done by various mass spectrometric techniques.", "page_name": "Flavor", "page_id": "Flavor", "heading": "Determination", "sub_heading": "Determination", "_id": "102--3---1---1", "title": "Sensory Analysis of Flavors"}
{"qas": [{"question": "Why do we get goosebumps when we're scared?", "answer": ""}, {"question": "What is the physiological response to fear called?", "answer": "fight-or-flight response", "ae_score": -1.01299043166699, "qg_score": null}, {"question": "What is the physiological response to fear called?", "answer": "fight-or-flight response", "ae_score": -1.01299043166699, "qg_score": null}], "content": "Many physiological changes in the body are associated with fear, summarized as the fight-or-flight response. An inborn response for coping with danger, it works by accelerating the breathing rate (hyperventilation), heart rate, constriction of the peripheral blood vessels leading to blushing and vasodilation of the central vessels (pooling),  increasing muscle tension including the muscles attached to each hair follicle to contract and causing \"goose bumps\", or more clinically, piloerection (making a cold person warmer or a frightened animal look more impressive), sweating, increased blood glucose (hyperglycemia), increased serum calcium, increase in white blood cells called neutrophilic leukocytes, alertness leading to sleep disturbance and \"butterflies in the stomach\" (dyspepsia). This primitive mechanism may help an organism survive by either running away or fighting the danger. With the series of physiological changes, the consciousness realizes an emotion of fear.", "page_name": "Fear", "page_id": "Fear", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "103--0---1---1", "title": "Fear and the fight-or-flight reaction"}
{"qas": [{"question": "What are some of the worst things that could happen to the human race?", "answer": ""}, {"question": "Who came up with the fear of flying?", "answer": "Bill Tancer", "ae_score": -0.283559945773461, "qg_score": null}, {"question": "Who came up with the fear of flying?", "answer": "Bill Tancer", "ae_score": -0.283559945773461, "qg_score": null}], "content": "In a 2005 Gallup poll (U.S.), a national sample of adolescents between the ages of 13 and 17 were asked what they feared the most. The question was open-ended and participants were able to say whatever they wanted. The top ten fears were, in order: terrorist attacks, spiders, death, being a failure, war, criminal or gang violence, being alone, the future, and nuclear war.\nIn an estimate of what people fear the most, book author Bill Tancer analyzed the most frequent online queries that involved the phrase, \"fear of...\" following the assumption that people tend to seek information on the issues that concern them the most. His top ten list of fears published 2008 consisted of flying, heights, clowns, intimacy, death, rejection, people, snakes, failure, and driving.", "page_name": "Fear", "page_id": "Fear", "heading": "Causes", "sub_heading": "Causes", "_id": "103--1--0---1", "title": "Top Ten Fears"}
{"qas": [{"question": "Why do so many people have a fear of heights?", "answer": ""}, {"question": "What are some of the most common fears?", "answer": "demons and ghosts", "ae_score": -0.33010474036627996, "qg_score": null}, {"question": "What are some of the most common fears?", "answer": "demons and ghosts", "ae_score": -0.33010474036627996, "qg_score": null}], "content": "According to surveys, some of the most common fears are of demons and ghosts, the existence of evil powers, cockroaches, spiders, snakes, heights, water, enclosed spaces, tunnels, bridges, needles, social rejection, failure, examinations and public speaking.", "page_name": "Fear", "page_id": "Fear", "heading": "Causes", "sub_heading": "Common phobias", "_id": "103--1--1---1", "title": "The most common fears are of demons and ghosts, the existence of evil powers,"}
{"qas": [{"question": "Why do some people have a higher fear of dying than others?", "answer": ""}, {"question": "Who is the author of the book fear of death?", "answer": "Shelly Kagan", "ae_score": -0.28697816583247404, "qg_score": null}, {"question": "Who is the author of the book fear of death?", "answer": "Shelly Kagan", "ae_score": -0.28697816583247404, "qg_score": null}], "content": "Death anxiety is multidimensional; it covers \"fears related to one's own death, the death of others, fear of the unknown after death, fear of obliteration, and fear of the dying process, which includes fear of a slow death and a painful death\".\nThe Yale philosopher Shelly Kagan examined fear of death in a 2007 Yale open course by examining the following questions: Is fear of death a reasonable appropriate response? What conditions are required and what are appropriate conditions for feeling fear of death? What is meant by fear, and how much fear is appropriate? According to Kagan for fear in general to make sense, three conditions should be met: the object of fear needs to be \"something bad\", there needs to be a non-negligible chance that the bad state of affairs will happen, and there needs to be some uncertainty about the bad state of affairs. The amount of fear should be appropriate to the size of \"the bad\". If the 3 conditions aren't met, fear is an inappropriate emotion. He argues, that death does not meet the first two criteria, even if death is a \"deprivation of good things\" and even if one believes in a painful afterlife. Because death is certain, it also does not meet the third criterion, but he grants that the unpredictability of when one dies ''may'' be cause to a sense of fear.\nIn a 2003 study of 167 women and 121 men, aged 65\u201387, low self-efficacy predicted fear of the unknown after death and fear of dying for women and men better than demographics, social support, and physical health. Fear of death was measured by a \"Multidimensional Fear of Death Scale\" which included the 8 subscales Fear of Dying, Fear of the Dead, Fear of Being Destroyed, Fear for Significant Others, Fear of the Unknown, Fear of Conscious Death, Fear for the Body After Death, and Fear of Premature Death. In hierarchical multiple regression analysis the most potent predictors of death fears were low \"spiritual health efficacy\", defined as beliefs relating to one's perceived ability to generate spiritually based faith and inner strength, and low \"instrumental efficacy\", defined as beliefs relating to one's perceived ability to manage activities of daily living.\nPsychologists have tested the hypothesis that fear of death motivates religious commitment, and assurances about an afterlife alleviate the fear and empirical research on this topic has been equivocal. Religiosity can be related to fear of death when the afterlife is portrayed as time of punishment. \"Intrinsic religiosity\", as opposed to mere \"formal religious involvement\" has been found to be negatively correlated with death anxiety. In a 1976 study people of various Christian denominations those most firm in their faith, attending religious services weekly were the least afraid of dying. The survey found a negative correlation between fear of death and \"religious concern\".\nIn a 2006 study of white, Christian men and women the hypothesis was tested that traditional, church-centered religiousness and de-institutionalized spiritual seeking are ways of approaching fear of death in old age. Both religiousness and spirituality were related to positive psychosocial functioning, but only church-centered religiousness protected subjects against the fear of death.", "page_name": "Fear", "page_id": "Fear", "heading": "Causes", "sub_heading": "Fear of death", "_id": "103--1--2---1", "title": "How much fear is appropriate?"}
{"qas": [{"question": "Why do people have irrational fears?", "answer": ""}, {"question": "What is the scientific name for irrational fear?", "answer": "Fear of the unknown", "ae_score": -1.2315176248601152, "qg_score": null}, {"question": "What is the scientific name for irrational fear?", "answer": "Fear of the unknown", "ae_score": -1.2315176248601152, "qg_score": null}], "content": "Fear of the unknown or '''irrational fear''' is caused by negative thinking (worry) which arises from anxiety. Many people are scared of the \"unknown\". The irrational fear can branch out to many areas such as the hereafter, the next ten years, or even tomorrow. In these cases specialists use '''F'''alse '''E'''vidence '''A'''ppearing '''R'''eal as a definition. Being scared makes people to anticipate and aggravate of what may lie ahead rather than plan and evaluate. E.g. Continuation of scholarly education, most educators perceive this as a risk that may cause them fear and stress and they would rather teach things they've been taught than go and do research. This can lead to habits such as laziness and procrastination. The ambiguity of a situations that tend to be uncertain and unpredictable can cause anxiety, other psychological and physical problems in some populations; especially those who engage it constantly. E.g. War-ridden or Conflict places, Terrorism, Abuse ...etc. Poor parenting that instills fear can also debilitate children's psyche development or personality. E.g. Parents tell their children not to talk to strangers in order to protect them. In school they would be motivated to not show fear in talking with strangers, but to be assertive and also aware of the risks and the environment that it takes place. Ambiguous and mixed messages like this can affect their self-esteem and self-confidence. Researcher's say talking to strangers isn't something to be thwarted but allowed in a parent's presence if required. Developing  a sense of equanimity to handle various situations is often advocated as an antidote to irrational fear and essential skill by a number of ancient philosophies.", "page_name": "Fear", "page_id": "Fear", "heading": "Causes", "sub_heading": "Fear of the unknown", "_id": "103--1--3---1", "title": "Fear | Causes | Fear of the unknown"}
{"qas": [{"question": "Why do some people have a higher chance of getting pheromone poisoning than others?", "answer": ""}, {"question": "When was the link between alarm chemosignals and mice found?", "answer": "1993", "ae_score": -0.21078470750238995, "qg_score": null}, {"question": "When was the link between alarm chemosignals and mice found?", "answer": "1993", "ae_score": -0.21078470750238995, "qg_score": null}], "content": "In threatening situations insects, aquatic organisms, birds, reptiles, and mammals emit odorant substances, initially called alarm substances, which are chemical signals now called alarm pheromones (\"Schreckstoff\" in German). This is to defend themselves and at the same time to inform members of the same species of danger and leads to observable behavior change like freezing, defensive behavior, or dispersion depending on circumstances and species. For example, stressed rats release odorant cues that cause other rats to move away from the source of the signal. Pheromones are synthesized, emitted and perceived by all living organisms studied to date, with the exception of viruses and prions: i.e. in bacteria, prokaryotes, plants, plankton, parasites, insects, invertebrates and vertebrates (aquatic organisms, birds, reptiles, and mammals).\nAfter the discovery of pheromones in 1959, alarm pheromones were first described in 1968 in ants and earthworms, and 4 years later also found in mammals, both mice and rats. Over the next two decades identification and characterization of these pheromones proceeded in all manner of insects and sea animals, including fish, but it was not until 1990 that more insight into mammalian alarm pheromones was gleaned.\nEarly on, in 1985, a link between odors released by stressed rats and pain perception was discovered: unstressed rats exposed to these odors developed opioid-mediated analgesia. In 1997, researchers found bees became less responsive to pain after they had been stimulated with isoamyl acetate, a chemical smelling of banana, and a component of bee alarm pheromone. The experiment also showed that the bees' fear-induced pain tolerance was mediated by an endorphine.\nBy using the forced swimming test in rats as a model of fear-induction, the first mammalian \"alarm substance\" was found.\nIn 1991, this \"alarm substance\" was shown to fulfill criteria for pheromones: well-defined behavioral effect, species specificity, minimal influence of experience and control for nonspecific arousal. Rat activity testing with alarm pheromone and their preference/avoidance for odors from cylinders containing the pheromone showed, that the pheromone had very low volatility.\nIn 1993 a connection between alarm chemosignals in mice and their immune response was found.\nPheromone production in mice was found to be associated with or mediated by the pituitary gland in 1994.\nIt was not until 2011 that a link between severe pain, neuroinflammation and alarm pheromones release in rats was found: real time RT-PCR analysis of rat brain tissues indicated that shocking the footpad of a rat increased its production of proinflammatory cytokines in deep brain structures, namely of IL-1\u03b2, heteronuclear Corticotropin-releasing hormone and c-fos mRNA expressions in both the paraventricular nucleus and the bed nucleus of the stria terminalis, and it increased stress hormone levels in plasma (corticosterone).\nIn 2004, it was demonstrated that rats\u2019 alarm pheromones had different effects on the \u201crecipient\u201c rat (the rat perceiving the pheromone) depending which body region they were released from: Pheromone production from the face modified behavior in the recipient rat, e.g. caused sniffing or movement, whereas pheromone secreted from the rat's anal area induced autonomic nervous system stress responses, like an increase in core body temperature. Further experiments showed that when a rat perceived alarm pheromones, it increased its defensive and risk assessment behavior. and its acoustic startle reflex was enhanced.\nThe neurocircuit for how rats perceive alarm pheromones was shown to be related to hypothalamus, brainstem, and amygdala, all of which are evolutionary ancient structures deep inside or in the case of the brainstem underneath the brain away from the cortex, and involved in the fight-or-flight response, as is the case in humans.\nAlarm pheromone-induced anxiety in rats has been used to evaluate the degree to which anxiolytics can alleviate anxiety in humans. For this the change in the acoustic startle reflex of rats with alarm pheromone-induced anxiety (i.e. reduction of defensiveness) has been measured. Pretreatment of rats with one of five anxiolytics used in clinical medicine was able to reduce their anxiety: namely midazolam, phenelzine (a nonselective monoamine oxidase (MAO) inhibitor), propranolol, a nonselective beta blocker, clonidine, an alpha 2 adrenergic agonist or CP-154,526, a corticotropin-releasing hormone antagonist.\nFaulty development of odor discrimination impairs the perception of pheromones and pheromone-related behavior, like aggressive behavior and mating in male rats: The enzyme Mitogen-activated protein kinase 7 (MAPK7) has been implicated in regulating the development of the olfactory bulb and odor discrimination and it is highly expressed in developing rat brains, but absent in most regions of adult rat brains. conditional deletion of the MAPK7gene in mouse neural stem cells impairs several pheromone-mediated behaviors, including aggression and mating in male mice. These behavior impairments were not caused by a reduction in the level of testosterone, by physical immobility, by heightened fear or anxiety or by depression. Using mouse urine as a natural pheromone-containing solution, it has been shown that the impairment was associated with defective detection of related pheromones, and with changes in their inborn preference for pheromones related to sexual and reproductive activities.\nLastly, alleviation of an acute fear response because a friendly peer (or in biological language: an affiliative conspecific) tends and befriends is called \"social buffering\". The term is in analogy to the 1985 \"buffering\" hypothesis in psychology, where social support has been proven to mitigate the negative health effects of alarm pheromone mediated distress. The role of a \"social pheromone\" is suggested by the recent discovery that olfactory signals are responsible in mediating the \"social buffering\" in male rats. \"Social buffering\" was also observed to mitigate the conditioned fear responses of honeybees.  A bee colony exposed to an environment of high threat of predation did not show increased aggression and aggressive-like gene expression patterns in individual bees, but decreased aggression. That the bees did not simply habituate to threats is suggested by the fact that the disturbed colonies also decreased their foraging.\nBiologists have proposed in 2012 that fear pheromones evolved as molecules of \"keystone significance\", a term coined in analogy to keystone species. Pheromones may determine species compositions, and affect rates of energy and material exchange in an ecological community. Thus pheromones generate structure in a trophic web and play critical roles in maintaining natural systems.", "page_name": "Fear", "page_id": "Fear", "heading": "Mechanism", "sub_heading": "Mechanism", "_id": "103--2--0--0", "title": "How alarm pheromones affect human behavior?"}
{"qas": [{"question": "Why do we startle when we hear a loud noise?", "answer": ""}, {"question": "What is the induction of empathy by?", "answer": "smelling anxiety", "ae_score": -0.3886630696494448, "qg_score": null}, {"question": "What is the induction of empathy by?", "answer": "smelling anxiety", "ae_score": -0.3886630696494448, "qg_score": null}], "content": "Evidence of chemosensory alarm signals in humans has emerged slowly: Although alarm pheromones have not been physically isolated and their chemical structure has not been identified in man so far, there is evidence for their presence. Androstadienone, for example, a steroidal, endogenous odorant, is a pheromone candidate found in human sweat, axillary hair and plasma. The closely related compound androstenone is involved in communicating dominance, aggression or competition;   sex hormone influences on androstenone perception in humans showed high testosterone level related to heightened androstenone sensitivity in men, a high testosterone level related to unhappiness in response to androstenone in men, and a high estradiol level related to disliking of androstenone in women.\nA German study from 2006 showed when anxiety-induced versus exercise-induced human sweat from a dozen people was pooled and offered to seven study participants, of five able to olfactorily distinguish exercise-induced sweat from room air, three could also distinguish exercise-induced sweat from anxiety induced sweat. The acoustic startle reflex response to a sound when sensing anxiety sweat was larger than when sensing exercise-induced sweat, as measured by electromyograph analysis of the orbital muscle, which is responsible for the eyeblink component. This showed for the first time that fear chemosignals can modulate the startle reflex in humans without emotional mediation; fear chemosignals primed the recipient's \"defensive behavior\" prior to the subjects' conscious attention on the acoustic startle reflex level.\nIn analogy to the social buffering of rats and honeybees in response to chemosignals, induction of empathy by \"smelling anxiety\" of another person has been found in humans.\nA study from 2013 provided brain imaging evidence that human responses to fear chemosignals may be gender-specific. Researchers collected alarm-induced sweat and exercise-induced sweat from donors extracted it, pooled it and presented it to 16 unrelated people undergoing functional brain MRI. While stress-induced sweat from males produced a comparably strong emotional response in both females and males, stress-induced sweat from females produced a markedly stronger arousal in women than in men. Statistical tests pinpointed this gender-specificity to the right amygdala and strongest in the superficial nuclei. Since no significant differences were found in the olfactory bulb, the response to female fear-induced signals is likely based on processing the meaning, i.e. on the emotional level, rather than the strength of chemosensory cues from each gender, i.e. the perceptual level.\nAn approach-avoidance task was set up where volunteers seeing either an angry or a happy cartoon face on a computer screen pushed away or pulled toward them a joystick as fast as possible. Volunteers smelling anandrostadienone, masked with clove oil scent responded faster, especially to angry faces, than those smelling clove oil only, which was interpreted as anandrostadienone-related activation of the fear system. A potential mechanism of action is, that androstadienone alters the \"emotional face processing\". Androstadienone is known to influence activity of the fusiform gyrus which is relevant for face recognition.", "page_name": "Fear", "page_id": "Fear", "heading": "Mechanism", "sub_heading": "Fear pheromones in humans", "_id": "103--2--0--1", "title": "Fear chemosignals in humans"}
{"qas": [{"question": "How does fear conditioning work?", "answer": ""}, {"question": "What is used to treat fear in the amygdala?", "answer": "glucocorticoids", "ae_score": -0.41927042374000667, "qg_score": null}, {"question": "What is used to treat fear in the amygdala?", "answer": "glucocorticoids", "ae_score": -0.41927042374000667, "qg_score": null}], "content": "A drug treatment for fear conditioning and phobias via the amygdala is the use of glucocorticoids. In one study, glucocorticoid receptors in the central nucleus of the amygdala were disrupted in order to better understand the mechanisms of fear and fear conditioning. The glucocorticoid receptors were inhibited using lentiviral vectors containing Cre-recombinase injected into mice. Results showed that disruption of the glucocorticoid receptors prevented conditioned fear behavior. The mice were subjected to auditory cues which caused them to freeze normally. However, a reduction of freezing was observed in the mice that had inhibited glucocorticoid receptors.\nCognitive behavioral therapy has been successful in helping people overcome fear. Because fear is more complex than just forgetting or deleting memories, an active and successful approach involves people repeatedly confronting their fears. By confronting their fears in a safe manner a person can suppress the fear-triggering memory or stimulus.  Known as \u2018exposure therapy\u2019, this practice can help cure up to 90% of people, with specific phobias.", "page_name": "Fear", "page_id": "Fear", "heading": "Management", "sub_heading": "Management", "_id": "103--3---1---1", "title": "Fear Conditioning and Phobias Using Glucocorticoids"}
{"qas": [{"question": "Why do some religions believe that death is a big influence on morals?", "answer": ""}, {"question": "What is the euphoria of fear based on?", "answer": "patriotism", "ae_score": -0.774674036334931, "qg_score": null}, {"question": "What is the euphoria of fear based on?", "answer": "patriotism", "ae_score": -0.774674036334931, "qg_score": null}], "content": "The fear of the end and its existence is in other words the fear of death. The fear of death ritualized the lives of our ancestors. These rituals were designed to reduce that fear; they helped collect the cultural ideas that we now have in the present. These rituals also helped preserve the cultural ideas. The results and methods of human existence had been changing at the same time that social formation was changing. One can say that the formation of communities happened because people lived in fear. The result of this fear forced people to unite to fight dangers together rather than fight alone.\nReligions are filled with different fears that humans have had throughout many centuries. The fears aren't just metaphysical (including the problems of life and death) but are also moral. Death is seen as a boundary to another world. That world would always be different depending on how each individual lived their lives. The origins of this intangible fear are not found in the present world. In a sense we can assume that fear was a big influence on things such as morality. This assumption, however, flies in the face of concepts such as Moral Absolutism and Moral Universalism \u2013 which would hold that our morals are rooted in either the divine or natural laws of the universe, and would not be generated by any human feeling, thought or emotion.\nFear may be politically and culturally manipulated to persuade citizenry of ideas which would otherwise be widely rejected or dissuade citizenry from ideas which would otherwise be wildly supported. In contexts of disasters, nation-states manage the fear not only to provide their citizens with an explanation about the event or blaming some minorities, but also to adjust their previous beliefs. The manipulation of fear is done by means of symbolic instruments as terror movies and the administration ideologies that lead to nationalism. After a disaster, the fear is re-channeled in a climate of euphoria based on patriotism. The fear and evilness are inextricably intertwined.\nFear is found in mythology and folklore, and portrayed in books and movies. The Story of the Youth Who Went Forth to Learn What Fear Was is a German fairy tale dealing with the topic of not knowing fear.For example, many stories include characters who fear the antagonist of the plot. One of the important characteristics of historical and mythical heroes across cultures is to be fearless in the face of big and often lethal enemies.", "page_name": "Fear", "page_id": "Fear", "heading": "Society and culture", "sub_heading": "Society and culture", "_id": "103--4---1---1", "title": "The Fear of Death"}
{"qas": [{"question": "Why is fear so debilitating?", "answer": ""}, {"question": "What do people with damage to the amygdala lack?", "answer": "fear", "ae_score": -0.44553520400261426, "qg_score": null}, {"question": "What do people with damage to the amygdala lack?", "answer": "fear", "ae_score": -0.44553520400261426, "qg_score": null}], "content": "People who have damage to the amygdala, such as from Urbach\u2013Wiethe disease, are unable to experience fear.  This is not debilitating, but a lack of fear can allow someone to get into a dangerous situation they otherwise would have avoided.", "page_name": "Fear", "page_id": "Fear", "heading": "Inability to experience", "sub_heading": "Inability to experience", "_id": "103--5---1---1", "title": "Fear is a symptom of the amygdala"}
{"qas": [{"question": "How does genetic engineering work?", "answer": ""}, {"question": "What is it called when genes are transferred from one species to another?", "answer": "Genetic modification", "ae_score": -0.6406195800839736, "qg_score": null}, {"question": "What is it called when genes are transferred from one species to another?", "answer": "Genetic modification", "ae_score": -0.6406195800839736, "qg_score": null}], "content": "Genetic modification involves the mutation, insertion, or deletion of genes. Inserted genes usually come from a different species in a form of horizontal gene-transfer. In nature this can occur when exogenous DNA penetrates the cell membrane for any reason. This can be accomplished artificially by:\nOther methods exploit natural forms of gene transfer, such as the ability of ''Agrobacterium'' to transfer genetic material to plants,or the ability of lentiviruses to transfer genes to animal cells.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Production", "sub_heading": "Production", "_id": "104--0---1---1", "title": "Genetic modification is a form of gene-transfer."}
{"qas": [{"question": "How did the first genetically modified organism come into existence?", "answer": ""}, {"question": "What was the name of the first synthetic bacterial genome?", "answer": "Synthia", "ae_score": -0.04353467700711086, "qg_score": null}, {"question": "The first genetically modified organism ( gmo ) was able to survive in the presence of?", "answer": "kanamycin", "ae_score": null, "qg_score": null}], "content": "Humans have domesticated plants and animals since around 12,000 BCE, using selective breeding or artificial selection (as contrasted with natural selection). The process of selective breeding, in which organisms with desired traits (and thus with the desired genes) are used to breed the next generation and organisms lacking the trait are not bred, is a precursor to the modern concept of genetic modification. Various advancements in genetics allowed humans to directly alter the DNA and therefore genes of organisms. In 1972  Paul Berg created the first recombinant DNA molecule when he combined DNA from a monkey virus with that of the lambda virus.\nHerbert Boyer and Stanley Cohen made the first genetically modified organism (GMO) in 1973. They took a gene from a bacterium that provided resistance to the antibiotic kanamycin, inserted it into a plasmid and then induced another bacteria to uptake the plasmid. The bacteria was then able to survive in the presence of kanamycin. Boyer and Cohen expressed other genes in bacteria. This included genes from the toad Xenopus laevis in 1974, creating the first GMO expressing a gene from an organism from different kingdom.\nIn 1974 Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world\u2019s first transgenic animal. However it took another eight years before transgenic mice were developed that passed the transgene to their offspring. Genetically modified mice were created in 1984 that carried cloned oncogenes, predisposed them to developing cancer. Mice with genes knocked out (knockout mouse) were created in 1989. The first transgenic livestock were produced in 1985 and the first animal to synthesise transgenic proteins in their milk were mice, engineered to produce human tissue plasminogen activator in 1987.\nIn 1983 the first genetically engineered plant was developed by Michael W. Bevan, Richard B. Flavell and Mary-Dell Chilton. They infected tobacco with ''Agrobacterium'' transformed with an antibiotic resistance gene and through tissue culture techniques were able to grow a new plant containing the resistance gene. The gene gun was invented in 1987, allowing transformation of plants not susceptible to ''Agrobacterium'' infection. In 2000, Vitamin A-enriched golden rice, was the first plant developed with increased nutrient value.\nIn 1976 Genentech, the first genetic engineering company was founded by Herbert Boyer and Robert Swanson; a year later, the company produced a human protein (somatostatin) in ''E.coli''. Genentech announced the production of genetically engineered human insulin in 1978. The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982. In 1988 the first human antibodies were produced in plants. In 1987, the ice-minus strain of ''P. syringae'' became the first genetically modified organism to be released into the environment when a strawberry field and a potato field in California were sprayed with it.\nThe first genetically modified crop, an antibiotic-resistant tobacco plant, was produced in 1982. China was the first country to commercialize transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, the first genetically modified food. Also in 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialized in Europe. An insect resistant Potato was approved for release in the USA in 1995, and by 1996 approval had been granted to commercially grow 8 transgenic crops and one flower crop (carnation) in 6 countries plus the EU.\nIn 2010, scientists at the J. Craig Venter Institute, announced that they had created the first synthetic bacterial genome. They  named it Synthia and it was the world's first synthetic life form.\nThe first genetically modified animal to be commercialised was the GloFish, a Zebra fish with a fluorescent gene added that allows it to glow in the dark under ultraviolet light. The first genetically modified animal to be approved for food use was AquAdvantage salmon in 2015. The salmon were transformed with a growth hormone-regulating gene from a Pacific Chinook salmon and a promoter from an ocean pout enabling it to grow year-round instead of only during spring and summer.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "History", "sub_heading": "History", "_id": "104--1---1---1", "title": "The Evolution of Genetic Modification"}
{"qas": [{"question": "Why are bacteria the first organisms to be modified in the laboratory?", "answer": ""}, {"question": "Which organism was the first to be genetically modified?", "answer": "Bacteria", "ae_score": -0.339813941235532, "qg_score": null}, {"question": "What are the components of a genetically modified organism?", "answer": "genomes", "ae_score": null, "qg_score": null}], "content": "Bacteria were the first organisms to be modified in the laboratory, due to the relative ease of modifying their genetics.\nThey continue to be important model organisms for experiments in genetic engineering.  In the field of synthetic biology, they have been used to test various synthetic approaches, from synthesizing genomes to creating novel nucleotides.\nThese organisms are now used for several purposes, and are particularly important in producing large amounts of pure human proteins for use in medicine.\nGenetically modified bacteria are used to produce the protein insulin to treat diabetes. Similar bacteria have been used to produce biofuels, clotting factors to treat haemophilia, and human growth hormone to treat various forms of dwarfism.\nIn addition, various genetically engineered micro-organisms are routinely used as sources of enzymes for the manufacture of a variety of processed foods. These include alpha-amylase from bacteria, which converts starch to simple sugars, chymosin from bacteria or fungi, which clots milk protein for cheese making, and pectinesterase from fungi, which improves fruit juice clarity.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Uses", "_id": "104--2--0---1", "title": "Genetically Modified Bacteria Are Used to Produce Proteins"}
{"qas": [{"question": "How is it possible to make medicine from plants and plant cells?", "answer": ""}, {"question": "What percentage of the world's croplands were planted with gm crops in?", "answer": "10%", "ae_score": -0.5187506759910776, "qg_score": null}, {"question": "What type of cells can be genetically modified?", "answer": "transgenic", "ae_score": null, "qg_score": null}], "content": "Transgenic plants have been engineered for scientific research, to create new colours in plants, and to create different crops.\nIn research, plants are engineered to help discover the functions of certain genes. One way to do this is to knock out the gene of interest and see what phenotype develops. Another strategy is to attach the gene to a strong promoter and see what happens when it is over expressed. A common technique used to find out where the gene is expressed is to attach it to GUS or a similar reporter gene that allows visualisation of the location.'\nAfter thirteen years of collaborative research, an Australian company \u2013 Florigene, and a Japanese company \u2013 Suntory, created a blue rose (actually lavender or mauve) in 2004. The genetic engineering involved three alterations \u2013 adding two genes, and interfering with another. One of the added genes was for the blue plant pigment delphinidin cloned from the pansy. The researchers then used RNA interference (RNAi) technology to depress all color production by endogenous genes by blocking a crucial protein in color production, called dihydroflavonol 4-reductase) (DFR), and adding a variant of that protein that would not be blocked by the RNAi but that would allow the delphinidin to work.<ref name=physorg/> The roses are sold in Japan, the United States, and Canada. Florigene has also created and sells lavender-colored carnations that are genetically engineered in a similar way.\nSimple plants and plant cells have been genetically engineered for production of biopharmaceuticals in bioreactors as opposed to cultivating plants in open fields. Work has been done with duckweed ''Lemna minor'', the algae ''Chlamydomonas reinhardtii'' and the moss ''Physcomitrella patens''.An Israeli company, Protalix, has developed a method to produce therapeutics in cultured transgenic carrot and tobacco cells. Protalix and its partner, Pfizer, received FDA approval to market its drug Elelyso, a treatment for Gaucher's disease, in 2012.\n'''Genetically modified crops''' ('''GMCs''', '''GM crops''', or '''biotech crops''') are plants used in agriculture, the DNA of which has been modified using genetic engineering techniques.  In most cases, the aim is to introduce a new trait to the plant which does not occur naturally in the species.  Examples in food crops include resistance to certain pests, diseases, or environmental conditions, reduction of spoilage, or resistance to chemical treatments (e.g. resistance to a herbicide), or improving the nutrient profile of the crop.  Examples in non-food crops include production of pharmaceutical agents, biofuels, and other industrially useful goods, as well as for bioremediation.\nFarmers have widely adopted GM technology. Between 1996 and 2013, the total surface area of land cultivated with GM crops increased by a factor of 100, from 17000 km2 to 1,750,000 km (432 million acres). 10% of the world's croplands were planted with GM crops in 2010.  In the US, by 2014, 94% of the planted area of soybeans, 96% of cotton and 93% of corn were genetically modified varieties.  In recent years GM crops expanded rapidly in developing countries. In 2013 approximately 18 million farmers grew 54% of worldwide GM crops in developing countries.\nFor discussions of issues about GM crops and GM food, see the Controversies section below and the article on genetically modified food controversies.\nCisgenesis, sometimes also called intragenesis, is a product designation for a category of genetically engineered plants. A variety of classification schemes have been proposed that order genetically modified organisms based on the nature of introduced genotypical changes rather than the process of genetic engineering.\nWhile some genetically modified plants are developed by the introduction of a gene originating from distant, sexually incompatible species into the host genome, cisgenic plants contain genes that have been isolated either directly from the host species or from sexually compatible species. The new genes are introduced using recombinant DNA methods and gene transfer. Some scientists hope that the approval process of cisgenic plants might be simpler than that of proper transgenics, but it remains to be seen.\nGenetically modified organisms have been proposed to aid conservation of plant species threatened by extinction. Many trees face the treat of invasive plants and diseases, such as the emerald ash borer in North American and the fungal disease, Ceratocystis platani, in European plane trees. A suggested solution to increase the resilience of threatened tree species is to genetically modify individuals by transferring resistant genes. Papaya trees are an example of a species that was successfully conserved using genetic modification. The papaya ringspot virus (PRSV) devastated papaya trees in Hawaii in the twentieth century until transgenic papaya plants were given pathogen-derived resistance.\nHowever, genetic modification for conservation in plants remains mainly speculative and further experimentation is needed before the technique can be widely implemented. A main concern with using genetic modification for conservation purposes is that a transgenic species may no longer bear enough resemblance to the original species to truly claim that the original species is being conserved. Instead, the transgenic species may be genetically different enough to be considered a new species, thus diminishing the conservation worth of genetic modification.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Plants", "_id": "104--2--1---1", "title": "Genetically Modified Crops"}
{"qas": [{"question": "What are genetically modified animals and why are they so important?", "answer": ""}, {"question": "What disease was the first target of a genetically modified primate?", "answer": "Parkinson's disease", "ae_score": -0.2214965947908848, "qg_score": null}, {"question": "What is the name of the genetically modified virus that was genetically modified to protect rabbits from?", "answer": "myxoma", "ae_score": null, "qg_score": null}], "content": "Genetically modified mammals are an important category of genetically modified organisms. Ralph L. Brinster and Richard Palmiter developed the techniques responsible for transgenic mice, rats, rabbits, sheep, and pigs in the early 1980s, and established many of the first transgenic models of human disease, including the first carcinoma caused by a transgene. The process of genetically engineering animals is a slow, tedious, and expensive process. However, new technologies are making genetic modifications easier and more precise.\nThe first transgenic (genetically modified) animal was produced by injecting DNA into mouse embryos then implanting the embryos in female mice.\nGenetically modified animals currently being developed can be placed into six different broad classes based on the intended purpose of the genetic modification:\nTransgenic animals are used as experimental models to perform phenotypic and for testing in biomedical research.\nGenetically modified (genetically engineered) animals are becoming more vital to the discovery and development of cures and treatments for many serious diseases. By altering the DNA or transferring DNA to an animal, we can develop certain proteins that may be used in medical treatment. Stable expressions of human proteins have been developed in many animals, including sheep, pigs, and rats. Human-alpha-1-antitrypsin, which has been tested in sheep and is used in treating humans with this deficiency and transgenic pigs with human-histo-compatibility have been studied in the hopes that the organs will be suitable for transplant with less chances of rejection.\nScientists have genetically engineered several organisms, including some mammals, to include green fluorescent protein (GFP), first observed in the jellyfish, ''Aequorea victoria'' in 1962, for medical research purposes (Chalfie, Shimoura, and Tsien were awarded the Nobel prize in Chemistry in 2008 for the discovery and development of GFP ). For example, fluorescent pigs have been bred to study human organ transplants (xenotransplantation), regenerating ocular photoreceptor cells, and other topics. In 2011 a Japanese-American team created green-fluorescent cats to find therapies for HIV/AIDS and other diseases as feline immunodeficiency virus (FIV) is related to HIV.\nIn 2009, scientists in Japan announced that they had successfully transferred a gene into a primate species (marmosets) and produced a stable line of breeding transgenic primates for the first time. Their first research target for these marmosets was Parkinson's disease, but they were also considering amyotrophic lateral sclerosis and Huntington's disease.\nWithin the field known as pharming, intensive research has been conducted to develop transgenic animals that produce biotherapeutics. On 6 February 2009, the U.S. Food and Drug Administration approved the first human biological drug produced from such an animal, a goat. The drug, ATryn, is an anticoagulant which reduces the probability of blood clots during surgery or childbirth. It is extracted from the goat's milk.\nIn 2006, a pig was engineered to produce omega-3 fatty acids through the expression of a roundworm gene.\nEnviropig was a genetically enhanced line of Yorkshire pigs in Canada created with the capability of digesting plant phosphorus more efficiently than conventional Yorkshire pigs. The project ended in 2012. These pigs produced the enzyme phytase, which breaks down the indigestible phosphorus, in their saliva. The enzyme was introduced into the pig chromosome by pronuclear microinjection. With this enzyme, the animal is able to digest cereal grain phosphorus. The use of these pigs would reduce the potential of water pollution since they excrete from 30 to 70.7% less phosphorus in manure depending upon the age and diet. The lower concentrations of phosphorus in surface runoff reduces algal growth, because phosphorus is the limiting nutrient for algae. Because algae consume large amounts of oxygen, it can result in dead zones for fish.\nIn 2011, Chinese scientists generated dairy cows genetically engineered with genes from human beings to produce milk that would be the same as human breast milk. This could potentially benefit mothers who cannot produce breast milk but want their children to have breast milk rather than formula. Aside from milk production, the researchers claim these transgenic cows to be identical to regular cows. Two months later scientists from Argentina presented Rosita, a transgenic cow incorporating two human genes, to produce milk with similar properties as human breast milk. In 2012, researchers from New Zealand also developed a genetically engineered cow that produced allergy-free milk.\nGoats have been genetically engineered to produce milk with strong spiderweb-like silk proteins in their milk.\nGene therapy, uses genetically modified viruses to deliver genes that can cure disease in humans. Although gene therapy is still relatively new, it has had some successes. It has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis. Treatments are also being developed for a range of other currently incurable diseases, such as cystic fibrosis, sickle cell anemia, Parkinson's disease, cancer, diabetes, heart disease and muscular dystrophy.\nGenetically modified organisms have been used to conserve European wild rabbits in the Iberian peninsula and Australia. In both cases, the genetically modified organism used was a myxoma virus, but for opposite purposes: to protect the endangered population in Europe with immunizations and to regulate the overabundant population in Australia with contraceptives.\nIn the Iberian peninsula, the European wild rabbit population has experienced a sharp decline from viral diseases and overhunting. To protect the species from viral diseases, the myxoma virus was genetically modified to immunize the rabbits. The European wild rabbit population in Australia faces the opposite problem: lack of natural predators has made the introduced species invasive. The same myxoma virus was genetically modified to lower fertility in the Australian rabbit population.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Mammals", "_id": "104--2--2---1", "title": "How Genetically Modified Animals Can Cure Disease"}
{"qas": [{"question": "What is Glo Fish and why is it so controversial?", "answer": ""}, {"question": "Where is the first genetically modified organism lab located?", "answer": "University of Cincinnati", "ae_score": -0.17254012763487206, "qg_score": null}, {"question": "What type of dna is in a genetically modified organism?", "answer": "transgenic", "ae_score": null, "qg_score": null}], "content": "Genetically modified fish are used for scientific research and as pets, and are being considered for use as food and as aquatic pollution sensors.\nGM fish are widely used in basic research in genetics and development. Two species of fish, zebrafish and medaka, are most commonly modified because they have optically clear chorions (membranes in the egg), rapidly develop, and the 1-cell embryo is easy to see and microinject with transgenic DNA.\nThe GloFish is a patented brand of genetically modified (GM) fluorescent zebrafish with bright red, green, and orange fluorescent color. Although not originally developed for the ornamental fish trade, it became the first genetically modified animal to become publicly available as a pet when it was introduced for sale in 2003. They were quickly banned for sale in California.\nGM fish have been developed with promoters driving an over-production of \"all fish\" growth hormone for use in the aquaculture industry to increase the speed of development and potentially reduce fishing pressure on wild stocks. This has resulted in dramatic growth enhancement in several species, including salmon, trout and tilapia. AquaBounty Technologies, a biotechnology company working on bringing a GM salmon to market, claims that their GM AquAdvantage salmon can mature in half the time as wild salmon. AquaBounty applied for regulatory approval to market their GM salmon in the US, and was approved in November 2015. On 25 November 2013 Canada approved commercial scale production and export of GM Salmon eggs but they are not approved for human consumption in Canada.\nSeveral academic groups have been developing GM zebrafish to detect aquatic pollution. The lab that originated the GloFish discussed above originally developed them to change color in the presence of pollutants, to be used as environmental sensors. A lab at University of Cincinnati has been developing GM zebrafish for the same purpose, as has a lab at Tulane University.\nRecent research on pain in fish has resulted in concerns being raised that genetic-modifications induced for scientific research may have detrimental effects on the welfare of fish.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Fish", "_id": "104--2--3---1", "title": "Genetically Modified Zebrafish are being considered for use as food and as aquatic pollution sensors"}
{"qas": [{"question": "What is the purpose of genetically modified frogs?", "answer": ""}, {"question": "How many species of frog have been genetically modified?", "answer": "Two", "ae_score": null, "qg_score": null}, {"question": "How many species of frog have been genetically modified?", "answer": "Two", "ae_score": null, "qg_score": null}], "content": "Genetically modified frogs are used for scientific research and are widely used in basic research including genetics and early development. Two species of frog, ''Xenopus laevis'' and ''Xenopus tropicalis'', are most commonly used.\nGM frogs are also being used as pollution sensors, especially for endocrine disrupting chemicals.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Frogs", "_id": "104--2--4---1", "title": "Genetically modified frogs are widely used for scientific research and are widely used in basic"}
{"qas": [{"question": "What is the significance of the discovery of the first living organism?", "answer": ""}, {"question": "How long has it taken for pectinophora gossypiella to?", "answer": "over three years", "ae_score": -0.4517453239288927, "qg_score": null}, {"question": "Hydras and sea anemones are examples of what type of organism?", "answer": "transgenic", "ae_score": null, "qg_score": null}], "content": "In biological research, transgenic fruit flies (''Drosophila melanogaster'') are model organisms used to study the effects of genetic changes on development. Fruit flies are often preferred over other animals due to their short life cycle, low maintenance requirements, and relatively simple genome compared to many vertebrates.\nIn 2010, scientists created \"malaria-resistant mosquitoes\" in the laboratory. The World Health Organization estimated that malaria killed almost one million people in 2008. Genetically modified male mosquitoes containing a lethal gene have been developed to combat the spread of dengue fever and the Zika virus. ''Aedes aegypti'' mosquitoes, the single most important carrier of dengue fever and the Zika virus, were reduced by 80% in a 2010 trial of these GM mosquitoes in the Cayman Islands and by 90% in a 2015 trial in Bahia, Brazil. In comparison, the Florida Keys Mosquito Control District has achieved only 30%-60% population reduction with traps and pesticide spraying. In 2016 FDA approved a genetically modified mosquito intervention for Key West, Florida. UK firm Oxitec proposed the release of millions of modified male (non-biting) mosquitoes to compete with wild males for mates. The males are engineered so that their offspring die before maturing, helping to eradicate mosquito-borne disease. Final approval was to be based on a local referendum to be held in November. Andrea Crisanti, a molecular biologist at Imperial College in London is working on ways to stop the A. gambiae mosquito from transmitting disease.\nA strain of ''Pectinophora gossypiella'' (Pink bollworm) has been genetically engineered to express a red fluorescent protein. This allows researchers to monitor bollworms that have been sterilized by radiation and released to reduce bollworm infestation.  The strain has been field tested for over three years and has been approved for release.\nCnidaria such as ''Hydra'' and the sea anemone ''Nematostella vectensis'' are attractive model organisms to study the evolution of immunity and certain developmental processes. An important technical breakthrough was the development of procedures for generation of stable transgenic hydras and sea anemones by embryo microinjection.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Uses", "sub_heading": "Invertebrates", "_id": "104--2--5---1", "title": "Genetically Modified Male Mosquitoes"}
{"qas": [{"question": "What is genetically engineering and why is it controversial?", "answer": ""}, {"question": "What is another name for genetically modified organisms?", "answer": "GMO", "ae_score": null, "qg_score": null}, {"question": "What is another name for genetically modified organisms?", "answer": "GMO", "ae_score": null, "qg_score": null}], "content": " The regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the use of genetic engineering technology and the development and release of genetically modified organisms (GMO), including genetically modified crops and genetically modified fish. There are differences in the regulation of GMOs between countries, with some of the most marked differences occurring between the USA and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. The European Union differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing. The cultivation of GMOs has triggered a debate about coexistence of GM and nonGM crops. Depending on the coexistence regulations, incentives for cultivation of GM crops differ.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Regulation", "sub_heading": "Regulation", "_id": "104--3---1---1", "title": "Regulation of GMOs"}
{"qas": [{"question": "Why is it so hard to find a good place to put your finger on something?", "answer": ""}, {"question": "What percentage of widely eaten crops are gm crops?", "answer": "19%", "ae_score": -0.4198787804628616, "qg_score": null}, {"question": "What percentage of widely eaten crops are gm crops?", "answer": "19%", "ae_score": -0.4198787804628616, "qg_score": null}], "content": "There is controversy over GMOs, especially with regard to their use in producing food. The dispute involves buyers, biotechnology companies, governmental regulators, nongovernmental organizations, and scientists. The key areas of controversy related to GMO food are whether GM food should be labeled, the role of government regulators, the effect of GM crops on health and the environment, the effect on pesticide resistance, the impact of GM crops for farmers, and the role of GM crops in feeding the world population. In 2014, sales of products that had been labeled as non-GMO grew 30 percent to $1.1 billion.\nThere is a scientific consensus<ref>{{Cite journal|url=http://www.agrobio.org/bfiles/fckimg/Nicolia%202013.pdf|title=An overview of the last 10 years of genetically engineered crop safety research|first1=Alessandro|last1=Nicolia|first2=Alberto|last2=Manzo|first3=Fabio|last3=Veronesi|first4=Daniele|last4=Rosellini|journal=Critical Reviews in Biotechnology|date=2013|pages=1\u201312|doi=10.3109/07388551.2013.823595|quote=\"We have reviewed the scientific literature on GE crop safety for the last 10 years that catches the scientific consensus matured since GE plants became widely cultivated worldwide, and we can conclude that the scientific research conducted so far has not detected any significant hazard directly connected with the use of GM crops.\n<ref>But see also:<p><p><p>And contrast:<p><p>and<p>{{Cite journal|url=http://www.ncbi.nlm.nih.gov/pubmed/?term=Governing+GMOs+in+the+USA%3A+Science%2C+law+and+public+health|title=Governing GMOs in the USA: science, law and public health|first1=Y.T.|last1=Yang|first2=B.|last2=Chen|journal=Journal of the Science of Food and Agriculture|volume=96|pages=1851\u20131855|date=2016|doi=10.1002/jsfa.7523|quote=\"It is therefore not surprising that efforts to require labeling and to ban GMOs have been a growing political issue in the USA ''(citing Domingo and Bordonaba, 2011)''.<p>Overall, a broad scientific consensus holds that currently marketed GM food poses no greater risk than conventional food... Major national and international science and medical associations have stated that no adverse human health effects related to GMO food have been reported or substantiated in peer-reviewed literature to date.\n that currently available food derived from GM crops poses no greater risk to human health than conventional food,<ref>\n<ref>\n but that each GM food needs to be tested on a case-by-case basis before introduction.<ref>{{Cite web|url=http://www.who.int/foodsafety/areas_work/food-technology/faq-genetically-modified-food/en/|title=Frequently asked questions on genetically modified foods|publisher=World Health Organization|accessdate=February 8, 2016|quote=\"Different GM organisms include different genes inserted in different ways. This means that individual GM foods and their safety should be assessed on a case-by-case basis and that it is not possible to make general statements on the safety of all GM foods.\n but that each GM food needs to be tested on a case-by-case basis before introduction.<ref>Some medical organizations, including the British Medical Association, advocate further caution based upon the precautionary principle:<p>{{Cite web|url=http://www.argenbio.org/adc/uploads/pdf/bma.pdf|title=Genetically modified foods and health: a second interim statement|publisher=British Medical Association|date=March 2004|accessdate=March 21, 2016|quote=\"In our view, the potential for GM foods to cause harmful health effects is very small and many of the concerns expressed apply with equal vigour to conventionally derived foods. However, safety concerns cannot, as yet, be dismissed completely on the basis of information currently available.<p>When seeking to optimise the balance between benefits and risks, it is prudent to err on the side of caution and, above all, learn from accumulating knowledge and experience. Any new technology such as genetic modification must be examined for possible benefits and risks to human health and the environment. As with all novel foods, safety assessments in relation to GM foods must be made on a case-by-case basis.<p>Members of the GM jury project were briefed on various aspects of genetic modification by a diverse group of acknowledged experts in the relevant subjects. The GM jury reached the conclusion that the sale of GM foods currently available should be halted and the moratorium on commercial growth of GM crops should be continued. These conclusions were based on the precautionary principle and lack of evidence of any benefit. The Jury expressed concern over the impact of GM crops on farming, the environment, food safety and other potential health effects.\n Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.\nNo reports of ill effects have been proven in the human population from ingesting GM food. Although labeling of GMO products in the marketplace is required in many countries, it is not required in the United States and no distinction between marketed GMO and non-GMO foods is recognized by the US FDA. In a May 2014 article in The Economist it was argued that, while GM foods could potentially help feed 842 million malnourished people globally, laws such as those being considered by Vermont's governor, Peter Shumlin, to require labeling of foods containing genetically modified ingredients, could have the unintended consequence of interrupting the process of spreading GM technologies to impoverished countries that suffer with food security problems.\nA 2014 critical review of histopathology studies on rats (eating approved widely eaten GM crops) found significant flaws, inadequacies, and a lack of transparency in methodology and results. Published studies could be found for only 19% of these widely eaten crops. Most of reviewed studies were performed after the approval of crop. More research is needed, including long-term animal feeding studies and thorough histopathological investigations.\nThe Organic Consumers Association, and the Union of Concerned Scientists, and Greenpeace stated that risks have not been adequately identified and managed, and they have questioned the objectivity of regulatory authorities. Some health groups say there are unanswered questions regarding the potential long-term impact on human health from food derived from GMOs, and propose mandatory labeling or a moratorium on such products. Concerns include contamination of the non-genetically modified food supply, effects of GMOs on the environment and nature,<ref name=CAPE/><ref name=VDC/> the rigor of the regulatory process,<ref name=IDEA/> and consolidation of control of the food supply in companies that make and sell GMOs,<ref name=CAPE/> or concerns over the use of herbicides with glyphosate.", "page_name": "Genetically modified organism", "page_id": "Genetically%20modified%20organism", "heading": "Controversy", "sub_heading": "Controversy", "_id": "104--4---1---1", "title": "Genetically modified organism | Controversy"}
{"qas": [{"question": "How did the idea of human rights come about?", "answer": ""}, {"question": "Which 17th century english philosopher argued that natural rights could not be surrendered in the social?", "answer": "John Locke", "ae_score": -0.4575412281207341, "qg_score": null}, {"question": "Which 17th century english philosopher argued that natural rights could not be surrendered in the social?", "answer": "John Locke", "ae_score": -0.4575412281207341, "qg_score": null}], "content": "The earliest conceptualization of human rights is credited to ideas about natural rights emanating from natural law. In particular, the issue of universal rights was introduced by the examination of extending rights to indigenous peoples by Spanish clerics, such as Francisco de Vitoria and  Bartolom\u00e9 de Las Casas. In the Valladolid debate, Juan Gin\u00e9s de Sep\u00falveda, who maintained an Aristotelian view of humanity as divided into classes of different worth, argued with Las Casas, who argued in favour of equal rights to freedom from slavery for all humans regardless of race or religion.\n17th-century English philosopher John Locke discussed natural rights in his work, identifying them as being \"life, liberty, and estate (property)\", and argued that such fundamental rights could not be surrendered in the social contract. In Britain in 1689, the English Bill of Rights and the Scottish Claim of Right each made illegal a range of oppressive governmental actions. Two major revolutions occurred during the 18th century, in the United States (1776) and in France (1789), leading to the United States Declaration of Independence and the French Declaration of the Rights of Man and of the Citizen respectively, both of which articulated certain human rights. Additionally, the Virginia Declaration of Rights of 1776 encoded into law a number of fundamental civil rights and civil freedoms.\nThese were followed by developments in philosophy of human rights by philosophers such as Thomas Paine, John Stuart Mill and G.W.F. Hegel during the 18th and 19th centuries. The term ''human rights'' probably came into use some time between Paine's ''The Rights of Man'' and William Lloyd Garrison's 1831 writings in ''The Liberator'', in which he stated that he was trying to enlist his readers in \"the great cause of human rights\".  Although the term had been used by at least one author as early as 1742.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "History of the concept", "sub_heading": "History of the concept", "_id": "105--0--0---1", "title": "Human Rights in the 18th and 19th Century"}
{"qas": [{"question": "Why are there so many women's rights movements in the world?", "answer": ""}, {"question": "Who was the leader of the indian human rights movement?", "answer": "Mahatma Gandhi", "ae_score": -0.25818400813907727, "qg_score": null}, {"question": "Who was the leader of the indian human rights movement?", "answer": "Mahatma Gandhi", "ae_score": -0.25818400813907727, "qg_score": null}], "content": "In the 19th century, human rights became a central concern over the issue of slavery.<ref name=twsGaryJBass/> A number of reformers, notably British Member of Parliament William Wilberforce, worked towards the abolition of the Atlantic slave trade and abolition of slavery. This was achieved across the British Empire by the Slave Trade Act 1807, which was enforced internationally by the Royal Navy under treaties Britain negotiated with other nations, and the Slavery Abolition Act 1833. In the United States, all the northern states had abolished the institution of slavery between 1777 and 1804, although southern states clung tightly to the \"peculiar institution\". Conflict and debates over the expansion of slavery to new territories constituted one of the reasons for the southern states' secession and the American Civil War. During the reconstruction period immediately following the war, several amendments to the United States Constitution were made. These included the 13th amendment, banning slavery, the 14th amendment, assuring full citizenship and civil rights to all people born in the United States, and the 15th amendment, guaranteeing African Americans the right to vote. In Russia, the reformer Tsar Alexander II ended serfdom in 1861,<ref name=twsGaryJBass/> although the freed serfs often faced restrictions of their mobility within the nation.\nMany groups and movements have achieved profound social changes over the course of the 20th century in the name of human rights. In Europe and North America, labour unions brought about laws granting workers the right to strike, establishing minimum work conditions and forbidding or regulating child labour. The women's rights movement succeeded in gaining for many women the right to vote. National liberation movements in many countries succeeded in driving out colonial powers. One of the most influential was Mahatma Gandhi's movement to free his native India from British rule. Movements by long-oppressed racial and religious minorities succeeded in many parts of the world, among them the African American Civil Rights Movement, and more recent diverse identity politics movements, on behalf of women and minorities in the United States.\nThe establishment of the International Committee of the Red Cross, the 1864 Lieber Code and the first of the Geneva Conventions in 1864 laid the foundations of International humanitarian law, to be further developed following the two World Wars.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "History of the concept", "sub_heading": "19th century", "_id": "105--0--1---1", "title": "Human Rights in the 20th Century"}
{"qas": [{"question": "How did the Human Rights League come to be?", "answer": ""}, {"question": "When was the league of nations formed?", "answer": "1919", "ae_score": -0.16510926907653628, "qg_score": null}, {"question": "When was the league of nations formed?", "answer": "1919", "ae_score": -0.16510926907653628, "qg_score": null}], "content": "The World Wars, and the huge losses of life and gross abuses of human rights that took place during them, were a driving force behind the development of modern human rights instruments. The League of Nations was established in 1919 at the negotiations over the Treaty of Versailles following the end of World War I. The League's goals included disarmament, preventing war through collective security, settling disputes between countries through negotiation and diplomacy, and improving global welfare. Enshrined in its charter was a mandate to promote many of the rights later included in the Universal Declaration of Human Rights.\nAt the 1945 Yalta Conference, the Allied Powers agreed to create a new body to supplant the League's role; this was to be the United Nations. The United Nations has played an important role in international human-rights law since its creation. Following the World Wars, the United Nations and its members developed much of the discourse and the bodies of law that now make up international humanitarian law and international human rights law. Analyst Belinda Cooper argued that human rights organizations flourished in the 1990s, possibly as a result of the dissolution of the western and eastern Cold War blocs. Ludwig Hoffmann argues that human rights became more widely emphasized in the latter half of the twentieth century because it \"provided a language for political claim making and counter-claims, liberal-democratic, but also socialist and post colonialist.  \nThe CDHR was signed by member states of the OIC in 1990 at the 19th Conference of Foreign Ministers held in Cairo, Egypt. It was seen as the answer to the UDHR. In fact, the CDHR was \"patterned after the UN-sponsored UDHR of 1948\". The object of the CDHR was to \"serve as a guide for member states on human rights issues.\" CDHR translated the Qur'anic teachings as follows: \"All men are equal in terms of basic human dignity and basic obligations and responsibilities, without any discrimination on the basis of race, colour, language, belief, sex, religion, political affiliation, social status or other considerations. True religion is the guarantee for enhancing such dignity along the path to human integrity.\" On top of references to the Qur'an, the CDHR also referenced prophetic teachings and Islamic legal tradition.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "History of the concept", "sub_heading": "20th century", "_id": "105--0--2---1", "title": "The Development of Human Rights Law"}
{"qas": [{"question": "Why is the concept of human rights so controversial?", "answer": ""}, {"question": "What does the philosophy of human rights critically look at?", "answer": "content and justification", "ae_score": -0.4370985754351933, "qg_score": null}, {"question": "What does the philosophy of human rights critically look at?", "answer": "content and justification", "ae_score": -0.4370985754351933, "qg_score": null}], "content": "The philosophy of human rights attempts to examine the underlying basis of the concept of human rights and critically looks at its content and justification. Several theoretical approaches have been advanced to explain how and why human rights have become a part of social expectations.\nOne of the oldest Western philosophies of human rights is that they are a product of a natural law, stemming from different philosophical or religious grounds. Other theories hold that human rights codify moral behaviour which is a human social product developed by a process of biological and social evolution (associated with Hume). Human rights are also described as a sociological pattern of rule setting (as in the sociological theory of law and the work of Weber). These approaches include the notion that individuals in a society accept rules from legitimate authority in exchange for security and economic advantage (as in Rawls) \u2013 a social contract. The two theories that dominate contemporary human rights discussion are the interest theory and the will theory. Interest theory argues that the principal function of human rights is to protect and promote certain essential human interests, while will theory attempts to establish the validity of human rights based on the unique human capacity for freedom. Other positions attempt to categorize rights into basic types, rather than make claims about the function or derivation of particular rights.\nThe claims made by human rights to universality have led to criticism. Philosophers who have criticized the concept of human rights include Jeremy Bentham, Edmund Burke, Friedrich Nietzsche and Karl Marx. Political philosophy professor Charles Blattberg argues that discussion of human rights, being abstract, demotivates people from upholding the values that rights are meant to affirm. The Internet Encyclopedia of Philosophy gives particular attention to two types of criticisms: the one questioning universality of human rights and the one denying them objective ground. Alain Pellet, an international law scholar, criticizes \"human rightism\" approach as denying the principle of sovereignty and claiming a special place for human rights among the branches of international law; Alain de Benoist questions human rights premises of human equality. David Kennedy had listed pragmatic worries and polemical charges concerning human rights in 2002 in ''Harvard Human Rights Journal''.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Philosophy", "sub_heading": "Philosophy", "_id": "105--1---1---1", "title": "The Philosophy of Human Rights"}
{"qas": [{"question": "What is the purpose of the phrase, \"I'm not a robot, I'm a robot.\"?", "answer": ""}, {"question": "Where was the 2005 world summit held?", "answer": "New York", "ae_score": -0.32885886658083374, "qg_score": null}, {"question": "Where was the 2005 world summit held?", "answer": "New York", "ae_score": -0.32885886658083374, "qg_score": null}], "content": "The UDHR included both economic, social and cultural rights and civil and political rights because it was based on the principle that the different rights could only successfully exist in combination:\nThis is held to be true because without civil and political rights the public cannot assert their economic, social and cultural rights. Similarly, without livelihoods and a working society, the public cannot assert or make use of civil or political rights (known as the ''full belly thesis'').\nThe indivisibility and interdependence of all human rights has been confirmed by the 1993 Vienna Declaration and Programme of Action:\nThis statement was again endorsed at the 2005 World Summit in New York (paragraph 121).\nAlthough accepted by the signatories to the UDHR, most do not in practice give equal weight to the different types of rights. Some Western cultures have often given priority to civil and political rights, sometimes at the expense of economic and social rights such as the right to work, to education, health and housing. Similarly the ex Soviet bloc countries and Asian countries have tended to give priority to economic, social and cultural rights, but have often failed to provide civil and political rights.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Classification", "sub_heading": "Classification", "_id": "105--2--0---1", "title": "Economic, Social and Cultural Rights vs Civil and Political Rights"}
{"qas": [{"question": "What is the difference between a civil right and a social right?", "answer": ""}, {"question": "Who argued that the social right to housing is a real legal right?", "answer": "Olivia Ball", "ae_score": null, "qg_score": null}, {"question": "Who argued that the social right to housing is a real legal right?", "answer": "Olivia Ball", "ae_score": null, "qg_score": null}], "content": "Opponents of the indivisibility of human rights argue that economic, social and cultural rights are fundamentally different from civil and political rights and require completely different approaches. Economic, social and cultural rights are argued to be:\nSimilarly civil and political rights are categorized as:\nOlivia Ball and Paul Gready argue that for both civil and political rights and economic, social and cultural rights, it is easy to find examples which do not fit into the above categorization. Among several others, they highlight the fact that maintaining a judicial system, a fundamental requirement of the civil right to due process before the law and other rights relating to judicial process, is positive, resource-intensive, progressive and vague, while the social right to housing is precise, justiciable and can be a real 'legal' right.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Classification", "sub_heading": "Categorization", "_id": "105--2--1---1", "title": "Economic, Social and Cultural Rights"}
{"qas": [{"question": "Why is the president of the United States so concerned about the NSA spying on him?", "answer": ""}, {"question": "What do he and others urge caution with?", "answer": "prioritization of rights", "ae_score": -0.1573571756328354, "qg_score": null}, {"question": "What do he and others urge caution with?", "answer": "prioritization of rights", "ae_score": -0.1573571756328354, "qg_score": null}], "content": "Another categorization, offered by Karel Vasak, is that there are ''three generations of human rights'': first-generation civil and political rights (right to life and political participation), second-generation economic, social and cultural rights (right to subsistence) and third-generation solidarity rights (right to peace, right to clean environment). Out of these generations, the third generation is the most debated and lacks both legal and political recognition. This categorization is at odds with the indivisibility of rights, as it implicitly states that some rights can exist without others. Prioritization of rights for pragmatic reasons is however a widely accepted necessity. Human rights expert Philip Alston argues:\nHe, and others, urge caution with prioritization of rights:\nSome human rights are said to be \"inalienable rights\". The term inalienable rights (or unalienable rights) refers to \"a set of human rights that are fundamental, are not awarded by human power, and cannot be surrendered.\"", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Classification", "sub_heading": "Three generations", "_id": "105--2--2---1", "title": "Prioritization of Rights"}
{"qas": [{"question": "Why is the United Nations Charter so important?", "answer": ""}, {"question": "Which article of the un charter states that all members pledge themselves to take joint and separate?", "answer": "Article 56", "ae_score": -0.6577588611172545, "qg_score": null}, {"question": "Which article of the un charter states that all members pledge themselves to take joint and separate?", "answer": "Article 56", "ae_score": -0.6577588611172545, "qg_score": null}], "content": "The provisions of the United Nations Charter provided a basis for the development of international human rights protection in the opinion of Brownlie. The preamble of the charter provides that the members \"reaffirm faith in fundamental human rights, in the equal rights of men and women\" and Article 1(3) of the United Nations charter states that one of the purposes of the UN is: \"to achieve international cooperation in solving international problems of an economic, social, cultural, or humanitarian character, and in promoting and encouraging respect for human rights and for fundamental freedoms for all without distinction as to race, sex, language, or religion\". Article 55 provides that:Of particular importance is Article 56 of the charter: \"All Members pledge themselves to take joint and separate action in co-operation with the Organization for the achievement of the purposes set forth in Article 55.\" This is a binding treaty provision applicable to both the Organization and its members and has been taken to constitute a legal obligation for the members of the United Nations. Overall, the references to human rights in the Charter are general and vague. The Charter does not contain specific legal rights, nor does it mandate any enforcement procedures to protect these rights.Despite this, the significance of the espousal of human rights within the UN charter must not be understated. The importance of human rights on the global stage can be traced to the importance of human rights within the United Nations framework and the UN Charter can be seen as the starting point for the development of a broad array of declarations, treaties, implementation and enforcement mechanisms, UN organs, committees and reports on the protection of human rights. The rights espoused in the UN charter would be codified and defined in an non-binding context within the International Bill of Human Rights, composing the Universal Declaration of Human Rights, the International Covenant on Civil and Political Rights and the International Covenant on Economic, Social and Cultural Rights.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "International protection and promotion", "_id": "105--3--0---1", "title": "The importance of human rights in the United Nations Charter"}
{"qas": [{"question": "How did the UN Human Rights Council come up with the Declaration of Human Rights?", "answer": ""}, {"question": "When was the universal declaration of human rights adopted?", "answer": "1948", "ae_score": -0.23145349349587752, "qg_score": null}, {"question": "When was the universal declaration of human rights adopted?", "answer": "1948", "ae_score": -0.23145349349587752, "qg_score": null}], "content": "The '''Universal Declaration of Human Rights (UDHR)''' was adopted by the United Nations General Assembly in 1948, partly in response to the atrocities of World War II. It is generally viewed as the preeminent statement of international rights and has been identified as being a culmination of centuries of thinking along both secular and religious lines. Although the UDHR is a non-binding resolution, it is now considered by some to have acquired the force of international customary law which may be invoked in appropriate circumstances by national and other tribunals.  The UDHR urges member nations to promote a number of human, civil, economic and social rights, asserting these rights as part of the \"foundation of freedom, justice and peace in the world.\" The declaration was the first international legal effort to limit the behaviour of states and press upon them duties to their citizens.\nThe UDHR was framed by members of the Human Rights Commission, with former First Lady Eleanor Roosevelt as Chair, who began to discuss an ''International Bill of Rights'' in 1947. The members of the Commission did not immediately agree on the form of such a bill of rights, and whether, or how, it should be enforced. The Commission proceeded to frame the UDHR and accompanying treaties, but the UDHR quickly became the priority.Canadian law professor John Humphrey and French lawyer Ren\u00e9 Cassin were responsible for much of the cross-national research and the structure of the document respectively, where the articles of the declaration were interpretative of the general principle of the preamble. The document was structured by Cassin to include the basic principles of dignity, liberty, equality and brotherhood in the first two articles, followed successively by rights pertaining to individuals; rights of individuals in relation to each other and to groups; spiritual, public and political rights; and economic, social and cultural rights. According to Cassin, the final three articles place rights in the context of limits, duties and the social and political order in which they are to be realized.<ref name=Glendon/>Humphrey and Cassin intended the rights in the UDHR to be legally enforceable through some means, as is reflected in the third clause of the preamble:<ref name=Glendon/>\nSome of the UDHR was researched and written by a committee of international experts on human rights, including representatives from all continents and all major religions, and drawing on consultation with leaders such as Mahatma Gandhi.The inclusion of civil, political, economic, social and cultural rights<ref name=Glendon/> was predicated on the assumption that all human rights are indivisible and that the different types of rights listed are inextricably linked. This principle was not then opposed by any member states (the declaration was adopted unanimously, Byelorussian SSR, Czechoslovakia, Poland, Saudi Arabia, Ukrainian SSR, Union of South Africa, USSR, Yugoslavia.); however, this principle was later subject to significant challenges.\nThe Universal Declaration was bifurcated into treaties, a Covenant on Civil and Political Rights and another on social, economic, and cultural rights, due to questions about the relevance and propriety of economic and social provisions in covenants on human rights. Both covenants begin with the right of people to self-determination and to sovereignty over their natural resources. This debate over whether human rights are more fundamental than economic rights has continued to the present day. The United States declared after the World Food Summit that a right to be free from hunger does not give rise to any international obligations which has been interpreted as a negative duty.\nThe drafters of the Covenants initially intended only one instrument. The original drafts included only political and civil rights, but economic and social rights were also proposed. The disagreement over which rights were basic human rights resulted in there being two covenants. The debate was whether economic and social rights are aspirational, as contrasted with basic human rights which all people possess purely by being human, because economic and social rights depend on wealth and the availability of resources. In addition, which social and economic rights should be recognized depends on ideology or economic theories, in contrast to basic human rights, which are defined purely by the nature (mental and physical abilities) of human beings. It was debated whether economic rights were appropriate subjects for binding obligations and whether the lack of consensus over such rights would dilute the strength of political-civil rights. There was wide agreement and clear recognition that the means required to enforce or induce compliance with socio-economic undertakings were different from the means required for civil-political rights.\nThis debate and the desire for the greatest number of signatories to human-rights law led to the two covenants. The Soviet bloc and a number of developing countries had argued for the inclusion of all rights in a so-called ''Unity Resolution''. Both covenants allowed states to derogate some rights. Those in favour of a single treaty could not gain sufficient consensus.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "Universal Declaration of Human Rights", "_id": "105--3--1---1", "title": "The Universal Declaration of Human Rights (UDHR) \u2014 Part I"}
{"qas": [{"question": "How did the first human rights law come into existence?", "answer": ""}, {"question": "Who adopted the international covenant on civil and political rights in 1966?", "answer": "the United Nations", "ae_score": -0.30981000497776273, "qg_score": null}, {"question": "Who adopted the international covenant on civil and political rights in 1966?", "answer": "the United Nations", "ae_score": -0.30981000497776273, "qg_score": null}], "content": "In 1966, the International Covenant on Civil and Political Rights ('''ICCPR''') and the International Covenant on Economic, Social and Cultural Rights ('''ICESCR''') were adopted by the United Nations, between them making the rights contained in the UDHR binding on all states that have signed this treaty, creating human-rights law.\nSince then numerous other treaties (pieces of legislation) have been offered at the international level. They are generally known as ''human rights instruments''. Some of the most significant, referred to (with ICCPR and ICESCR) as \"the seven core treaties\", are:", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "International treaties", "_id": "105--3--2---1", "title": "''The Seven Core Treaties'''"}
{"qas": [{"question": "Geneva Conventions?", "answer": ""}, {"question": "Who was the founder of the international committee of the red cross?", "answer": "Henry Dunant", "ae_score": -0.33773523038754805, "qg_score": null}, {"question": "Who was the founder of the international committee of the red cross?", "answer": "Henry Dunant", "ae_score": -0.33773523038754805, "qg_score": null}], "content": "The '''Geneva Conventions''' came into being between 1864 and 1949 as a result of efforts by Henry Dunant, the founder of the International Committee of the Red Cross. The conventions safeguard the human rights of individuals involved in armed conflict, and build on the Hague Conventions of 1899 and 1907, the international community's first attempt to formalize the laws of war and war crimes in the nascent body of secular international law. The conventions were revised as a result of World War II and readopted by the international community in 1949.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "International humanitarian law", "_id": "105--3--4---1", "title": "The Geneva Conventions of 1949"}
{"qas": [{"question": "What happens if the UN Human Rights Council is found guilty of human rights violations?", "answer": ""}, {"question": "When was the universal declaration of human rights passed?", "answer": "1948", "ae_score": -0.3581716337638446, "qg_score": null}, {"question": "When was the universal declaration of human rights passed?", "answer": "1948", "ae_score": -0.3581716337638446, "qg_score": null}], "content": "Under the mandate of the UN charter, and the multilateral UN human rights treaties, the United Nations (UN) as an intergovernmental body seeks to apply international jurisdiction for universal human-rights legislation. Within the UN machinery, human-rights issues are primarily the concern of the United Nations Security Council and the United Nations Human Rights Council, and there are numerous committees within the UN with responsibilities for safeguarding different human-rights treaties. The most senior body of the UN in the sphere of human rights is the Office of the High Commissioner for Human Rights. The United Nations has an international mandate to:\nThe '''United Nations Security Council''' has the primary responsibility for maintaining international peace and security and is the only body of the UN that can authorize the use of force. It has been criticized for failing to take action to prevent human rights abuses, including the Darfur crisis, the Srebrenica massacre and the Rwandan Genocide. For example, critics blamed the presence of non-democracies on the Security Council for its failure regarding.\nOn April 28, 2006 the Security Council adopted resolution 1674 that reaffirmed the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity\" and committed the Security Council to action to protect civilians in armed conflict.\nThe '''United Nations General Assembly''', under Article 13 of the UN Charter, has the power to initiate studies and make recommendations on human rights issues.Under this provision, the general assembly passed the Universal Declaration of Human Rights in 1948, and since then a wide variety of other human rights instruments. The assembly has several subsidiary organs that deal with specific human rights issues, such as the Special Committee on Decolonization and the Special Commission against Apartheid (no longer operational). In addition the general assembly has set up a number of subsidiary organs that consider human rights issues in a number of high-profile contexts: such as the UN Council on Namibia, the Special Committee to Investigate Israeli Practises in the Occupied territories and the Committee on the Exercise of the Inalienable rights of the Palestine People.\nThe '''United Nations Human Rights Council''', created at the 2005 World Summit to replace the United Nations Commission on Human Rights, has a mandate to investigate violations of human rights.The Human Rights Council is a subsidiary body of the General Assembly and reports directly to it. It ranks below the Security Council, which is the final authority for the interpretation of the United Nations Charter. Forty-seven of the one hundred ninety-one member states sit on the council, elected by simple majority in a secret ballot of the United Nations General Assembly. Members serve a maximum of six years and may have their membership suspended for gross human rights abuses. The Council is based in Geneva, and meets three times a year; with additional meetings to respond to urgent situations.\nIndependent experts (''rapporteurs'') are retained by the Council to investigate alleged human rights abuses and to provide the Council with reports.\nThe Human Rights Council may request that the Security Council take action when human rights violations occur. This action may be direct actions, may involve sanctions, and the Security Council may also refer cases to the International Criminal Court (ICC) even if the issue being referred is outside the normal jurisdiction of the ICC.\nIn addition to the political bodies whose mandate flows from the UN charter, the UN has set up a number of ''treaty-based'' bodies, comprising committees of independent experts who monitor compliance with human rights standards and norms flowing from the core international human rights treaties. They are supported by and are created by the treaty that they monitor, With the exception of the CESCR, which was established under a resolution of the Economic and Social Council to carry out the monitoring functions originally assigned to that body under the Covenant, they are technically autonomous bodies, established by the treaties that they monitor and accountable to the state parties of those treaties - rather than subsidiary to the United Nations. Though in practice they are closely intertwined with the United Nations system and are supported by the UN High Commissioner for Human Rights (UNHCHR) and the UN Centre for Human Rights.\nEach treaty body receives secretariat support from the Human Rights Council and Treaties Division of Office of the High Commissioner on Human Rights (OHCHR) in Geneva except CEDAW, which is supported by the Division for the Advancement of Women (DAW). CEDAW formerly held all its sessions at United Nations headquarters in New York but now frequently meets at the United Nations Office in Geneva; the other treaty bodies meet in Geneva. The Human Rights Committee usually holds its March session in New York City.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "United Nations system", "_id": "105--3--5---1", "title": "Human Rights in the United Nations: A Guide to the UN"}
{"qas": [{"question": "Why is the European Court of Human Rights in Strasbourg?", "answer": ""}, {"question": "How many member states of the council of europe have signed the convention?", "answer": "47", "ae_score": -0.512952175726386, "qg_score": null}, {"question": "How many member states of the council of europe have signed the convention?", "answer": "47", "ae_score": -0.512952175726386, "qg_score": null}], "content": "International human rights regimes are in several cases \"nested\" within more comprehensive and overlapping regional agreements. These regional regimes can be seen as relatively independently coherent human rights sub-regimes. Three principal regional human rights instruments can be identified; the African Charter on Human and Peoples' Rights, the American Convention on Human Rights (the Americas) and the European Convention on Human Rights. The European Convention on Human Rights has since 1950 defined and guaranteed human rights and fundamental freedoms in Europe.All 47 member states of the Council of Europe have signed the Convention and are therefore under the jurisdiction of the European Court of Human Rights in Strasbourg.<ref name=EUCourt/>", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "International protection and promotion", "sub_heading": "Regional human rights regimes", "_id": "105--3--6---1", "title": "Human rights | International protection and promotion | Regional human rights regimes"}
{"qas": [{"question": "What is the difference between human rights organizations and non-governmental organizations?", "answer": ""}, {"question": "Who was the special Rapporteur of the un commission on human rights in 2003?", "answer": "Jean Ziegler", "ae_score": -0.3661616475927559, "qg_score": null}, {"question": "Who was the special Rapporteur of the un commission on human rights in 2003?", "answer": "Jean Ziegler", "ae_score": -0.3661616475927559, "qg_score": null}], "content": "International '''non-governmental human rights organizations''' such as Amnesty International, Human Rights Watch, International Service for Human Rights and FIDH monitor what they see as human rights issues around the world and promote their views on the subject. Human rights organizations have been said to \"\"translate complex international issues into activities to be undertaken by concerned citizens in their own community\".Human rights organizations frequently engage in lobbying and advocacy in an effort to convince the United Nations, supranational bodies and national governments to adopt their policies on human rights. Many human-rights organizations have observer status at the various UN bodies tasked with protecting human rights. A new (in 2009) non-governmental human-rights conference is the Oslo Freedom Forum, a gathering described by The Economist as \"on its way to becoming a human-rights equivalent of the Davos economic forum.\" The same article noted that human-rights advocates are more and more divided amongst themselves over how violations of human rights are to be defined, notably as regards the Middle East.\nThere is criticism of human-rights organizations who use their status but allegedly move away from their stated goals. For example, Gerald M. Steinberg, an Israel-based academic, maintains that NGOs take advantage of a \"halo effect\" and are \"given the status of impartial moral watchdogs\" by governments and the media.Such critics claim that this may be seen at various governmental levels, including when human-rights groups testify before investigation committees.\nA human rights defender is someone who, individually or with others, acts to promote or protect human rights. Human rights defenders are those men and women who act peacefully for the promotion and protection of those rights, and most of this activity happens within a nation as opposed to internationally.<ref name=twsGaryJBass/>\nMultinational companies play an increasingly large role in the world, and have been responsible for numerous human rights abuses.Although the legal and moral environment surrounding the actions of governments is reasonably well developed, that surrounding multinational companies is both controversial and ill-defined. Multinational companies' primary responsibility is to their shareholders, not to those affected by their actions. Such companies may be larger than the economies of some of the states within which they operate, and can wield significant economic and political power. No international treaties exist to specifically cover the behaviour of companies with regard to human rights, and national legislation is very variable. Jean Ziegler, Special Rapporteur of the UN Commission on Human Rights on the right to food stated in a report in 2003:\nIn August 2003 the Human Rights Commission's Sub-Commission on the Promotion and Protection of Human Rights produced draft ''Norms on the responsibilities of transnational corporations and other business enterprises with regard to human rights''.These were considered by the Human Rights Commission in 2004, but have no binding status on corporations and are not monitored.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Non-governmental actors", "sub_heading": "Non-governmental actors", "_id": "105--4---1---1", "title": "Human Rights Defenders and Non-Governmental Organizations"}
{"qas": [{"question": "What is the difference between human rights violations and violations of human rights?", "answer": ""}, {"question": "Wars of aggression, war crimes and crimes against humanity are breaches of what?", "answer": "International humanitarian law", "ae_score": -0.44342715639660135, "qg_score": null}, {"question": "Wars of aggression, war crimes and crimes against humanity are breaches of what?", "answer": "International humanitarian law", "ae_score": -0.44342715639660135, "qg_score": null}], "content": "'''Human rights violations''' occur when actions by state (or non-state) actors abuse, ignore, or deny basic human rights (including civil, political, cultural, social, and economic rights). Furthermore, violations of human rights can occur when any state or non-state actor breaches any part of the UDHR treaty or other international human rights or humanitarian law. In regard to human rights violations of United Nations laws, Article 39 of the United Nations Charter designates the UN Security Council (or an appointed authority) as the only tribunal that may determine UN human rights violations.\nHuman rights abuses are monitored by United Nations committees, national institutions and governments and by many independent non-governmental organizations, such as Amnesty International, International Federation of Human Rights, Human Rights Watch, World Organisation Against Torture, Freedom House, International Freedom of Expression Exchange and Anti-Slavery International. These organizations collect evidence and documentation of alleged human rights abuses and apply pressure to enforce human rights laws.\nWars of aggression, war crimes and crimes against humanity, including genocide, are breaches of International humanitarian law and represent the most serious of human rights violations.\nIn efforts to eliminate violations of human rights, building awareness and protesting inhumane treatment has often led to calls for action and sometimes improved conditions. The UN Security Council has interceded with peace keeping forces, and other states and treaties (NATO) have intervened in situations to protect human rights.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Violations", "sub_heading": "Violations", "_id": "105--5---1---1", "title": "'''Human Rights Violations'''"}
{"qas": [{"question": "What is the right to life?", "answer": ""}, {"question": "What is an essential right of a human being?", "answer": "The right to life", "ae_score": -0.38274634476601477, "qg_score": null}, {"question": "What is an essential right of a human being?", "answer": "The right to life", "ae_score": -0.38274634476601477, "qg_score": null}], "content": "The right to life is the essential right that a human being has the right not to be killed by another human being. The concept of a right to life is central to debates on the issues of abortion, capital punishment, euthanasia, self defence and war. According to many human rights activists, the death penalty violates this right.The United Nations has called on states retaining the death penalty to establish a moratorium on capital punishment with a view to its abolition. States which do not do so face considerable moral and political pressure.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Substantive rights", "_id": "105--6--0---1", "title": "The right to life is fundamental to debates on abortion, capital punishment, euthan"}
{"qas": [{"question": "Why is torture illegal in most countries?", "answer": ""}, {"question": "How many countries ratified the united nations convention against torture?", "answer": "157", "ae_score": -0.5143344105770488, "qg_score": null}, {"question": "How many countries ratified the united nations convention against torture?", "answer": "157", "ae_score": -0.5143344105770488, "qg_score": null}], "content": "Throughout history, torture has been used as a method of political re-education, interrogation, punishment, and coercion. In addition to state-sponsored torture, individuals or groups may be motivated to inflict torture on others for similar reasons to those of a state; however, the motive for torture can also be for the sadistic gratification of the torturer, as in the Moors murders.\nSince the mid-20th century, torture is prohibited under international law and the domestic laws of most countries. It is considered to be a violation of human rights, and is declared to be unacceptable by Article 5 of the UN Universal Declaration of Human Rights. Signatories of the Geneva Conventions of 1949 and the Additional Protocols I and II of June 8, 1977 officially agree not to torture captured persons in armed conflicts, whether international or internal. Torture is also prohibited by the United Nations Convention Against Torture, which has been ratified by 157 countries.\nNational and international legal prohibitions on torture derive from a consensus that torture and similar ill-treatment are immoral, as well as impractical.Despite these international conventions, organizations that monitor abuses of human rights (e.g., Amnesty International, the International Rehabilitation Council for Torture Victims) report widespread use condoned by states in many regions of the world.Amnesty International estimates that at least 81 world governments currently practise torture, some of them openly.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Freedom from torture", "_id": "105--6--1---1", "title": "Torture and the Moors"}
{"qas": [{"question": "Why is freedom from slavery not recognized as a human right?", "answer": ""}, {"question": "What is internationally recognized as a human right?", "answer": "Freedom from slavery", "ae_score": -0.48879081225748566, "qg_score": null}, {"question": "What is internationally recognized as a human right?", "answer": "Freedom from slavery", "ae_score": -0.48879081225748566, "qg_score": null}], "content": "Freedom from slavery is internationally recognized as a human right. Article 4 of the Universal Declaration of Human Rights states:\nDespite this, the number of slaves today is higher than at any point in history, remaining as high as 12 million to 27 million,Most are debt slaves, largely in South Asia, who are under debt bondage incurred by lenders, sometimes even for generations.Human trafficking is primarily for prostituting women and children into sex industries.\nGroups such as the American Anti-Slavery Group, Anti-Slavery International, Free the Slaves, the Anti-Slavery Society, and the Norwegian Anti-Slavery Society continue to campaign to rid the world of slavery.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Freedom from slavery", "_id": "105--6--2---1", "title": "Free the Slaves"}
{"qas": [{"question": "What is the right to a fair trial?", "answer": ""}, {"question": "What is one of the most litigated human rights?", "answer": "The right to a fair trial", "ae_score": -0.692697861247071, "qg_score": null}, {"question": "What is one of the most litigated human rights?", "answer": "The right to a fair trial", "ae_score": -0.692697861247071, "qg_score": null}], "content": "The right to a fair trial has been defined in numerous regional and international human rights instruments. It is one of the most extensive human rights and all international human rights instruments enshrine it in more than one article.The right to a fair trial is one of the most litigated human rights and substantial case law has been established on the interpretation of this human right.Despite variations in wording and placement of the various fair trial rights, international human rights instrument define the right to a fair trial in broadly the same terms.The aim of the right is to ensure the proper administration of justice. As a minimum the right to fair trial includes the following fair trial rights in civil and criminal proceedings:", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Right to a fair trial", "_id": "105--6--3---1", "title": "The right to a fair trial"}
{"qas": [{"question": "What is freedom of speech?", "answer": ""}, {"question": "What is the right to speak freely without censorship?", "answer": "Freedom of speech", "ae_score": -0.6420937183077221, "qg_score": null}, {"question": "What is the right to speak freely without censorship?", "answer": "Freedom of speech", "ae_score": -0.6420937183077221, "qg_score": null}], "content": "Freedom of speech is the freedom to speak freely without censorship. The term freedom of expression is sometimes used synonymously, but includes any act of seeking, receiving and imparting information or ideas, regardless of the medium used. In practice, the right to freedom of speech is not absolute in any country and the right is commonly subject to limitations, such as on libel, slander, obscenity, incitement to commit a crime, etc.The right to freedom of expression is recognized as a human right under Article 19 of the Universal Declaration of Human Rights and recognized in international human rights law in the International Covenant on Civil and Political Rights (ICCPR). Article 19 of the ICCPR states that \"[e]veryone shall have the right to hold opinions without interference\" and \"everyone shall have the right to freedom of expression; this right shall include freedom to seek, receive and impart information and ideas of all kinds, regardless of frontiers, either orally, in writing or in print, in the form of art, or through any other media of his choice\".", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Freedom of speech", "_id": "105--6--4---1", "title": "Freedom of speech is the right to speak freely without censorship"}
{"qas": [{"question": "Freedom of thought, conscience and religion?", "answer": ""}, {"question": "The freedom to leave or discontinue membership in a religion is called what?", "answer": "apostasy", "ae_score": -0.35963245018566875, "qg_score": null}, {"question": "The freedom to leave or discontinue membership in a religion is called what?", "answer": "apostasy", "ae_score": -0.35963245018566875, "qg_score": null}], "content": "Freedom of thought, conscience and religion are closely related rights that protect the freedom of an individual or community, in public or private, to think and freely hold conscientious beliefs and to manifest religion or belief in teaching, practice, worship, and observance; the concept is generally recognized also to include the freedom to change religion or not to follow any religion. The freedom to ''leave'' or discontinue membership in a religion or religious group\u2014in religious terms called \"apostasy\"\u2014is also a fundamental part of religious freedom, covered by Article 18 of the Universal Declaration of Human Rights.\nHuman rights groups such as Amnesty International organizes campaigns to protect those arrested and or incarcerated as a prisoner of conscience because of their conscientious beliefs, particularly concerning intellectual, political and artistic freedom of expression and association. In legislation, a conscience clause is a provision in a statute that excuses a health professional from complying with the law (for example legalizing surgical or pharmaceutical abortion) if it is incompatible with religious or conscientious beliefs.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Freedom of thought, conscience and religion", "_id": "105--6--5---1", "title": "Freedom of Thought, Conscience, and Religion"}
{"qas": [{"question": "Freedom of movement?", "answer": ""}, {"question": "What asserts that a citizen of a state in which that citizen is present has the liberty?", "answer": "Freedom of movement", "ae_score": -0.4481020056732406, "qg_score": null}, {"question": "What asserts that a citizen of a state in which that citizen is present has the liberty?", "answer": "Freedom of movement", "ae_score": -0.4481020056732406, "qg_score": null}], "content": "Freedom of movement asserts that a citizen of a state in which that citizen is present has the liberty to travel, reside in, and/or work in any part of the state where one pleases within the limits of respect for the liberty and rights of others,[1] and to leave that state and return at any time.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Freedom of movement", "_id": "105--6--6---1", "title": "Freedom of movement asserts that a citizen of a state has the freedom to travel,"}
{"qas": [{"question": "How did the right to bear arms come to be?", "answer": ""}, {"question": "Who wrote about the right to keep and bear arms?", "answer": "Cicero", "ae_score": null, "qg_score": null}, {"question": "Who wrote about the right to keep and bear arms?", "answer": "Cicero", "ae_score": null, "qg_score": null}], "content": "The right to keep and bear arms for defence is described in the philosophical and political writings of Aristotle, Cicero, John Locke, Machiavelli, the English Whigs and others. In countries with an English common law tradition, a long-standing common law right to keep and bear arms has long been recognized, as pre-existing in common law, prior even to the existence of national constitutions.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Rights debates", "_id": "105--6--7--0", "title": "The right to keep and bear arms for defence"}
{"qas": [{"question": "What is the preamble of the Kyoto Protocol?", "answer": ""}, {"question": "When did unesco adopt the declaration on the responsibilities of the present generation towards the?", "answer": "1997", "ae_score": -0.2562717261891026, "qg_score": null}, {"question": "When did unesco adopt the declaration on the responsibilities of the present generation towards the?", "answer": "1997", "ae_score": -0.2562717261891026, "qg_score": null}], "content": "In 1997, UNESCO adopted the ''Declaration on the Responsibilities of the Present Generation Towards the Future Generation''. The Declaration opens with the words:\nArticle 1 of the declaration states \"the present generations have the responsibility of ensuring that the needs and interests of present and future generations are fully safeguarded.\" The preamble to the declaration states that \"at this point in history, the very existence of humankind and its environment are threatened\" and the declaration covers a variety of issues including protection of the environment, the human genome, biodiversity, cultural heritage, peace, development, and education. The preamble recalls that the responsibilities of the present generations towards future generations has been referred to in various international instruments, including the Convention for the Protection of the World Cultural and Natural Heritage (UNESCO 1972), the United Nations Framework Convention on Climate Change and the Convention on Biological Diversity (Rio de Janeiro, 1992), the Rio Declaration on Environment and Development (UN Conference on Environment and Development, 1992), the Vienna Declaration and Programme of Action (World Conference on Human Rights, 1993) and a number of UN General Assembly resolutions relating to the protection of the global climate for present and future generations adopted since 1990.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Future generations", "_id": "105--6--7--1", "title": "The Responsibilities of the Present Generation Towards the Future Generation (UNESCO"}
{"qas": [{"question": "What is the global charter for sexual orientation and gender identity rights?", "answer": ""}, {"question": "Homosexual behavior is illegal in how many countries?", "answer": "76", "ae_score": -0.18618709083351778, "qg_score": null}, {"question": "Homosexual behavior is illegal in how many countries?", "answer": "76", "ae_score": -0.18618709083351778, "qg_score": null}], "content": "Sexual orientation and gender identity rights relate to the expression of sexual orientation and gender identity based on the right to respect for private life and the right not to be discriminated against on the ground of \"other status\" as defined in various human rights conventions, such as article 17 and 26 in the United Nations International Covenant on Civil and Political Rights and article 8 and article 14 in the European Convention on Human Rights.\nAs of 2011, homosexual behaviour is illegal in 76 countries and punishable by execution in seven countries.The criminalization of private, consensual, adult sexual relations, especially in countries where corporal or capital punishment is involved, is one of the primary concerns of LGBT human rights advocates.\nOther issues include: government recognition of same-sex relationships, LGBT adoption, sexual orientation and military service, immigration equality, anti-discrimination laws, hate crime laws regarding violence against LGBT people, sodomy laws, anti-lesbianism laws, and equal age of consent for same-sex activity.\nA global charter for sexual orientation and gender identity rights has been proposed in the form of the 'Yogyakarta Principles', a set of 29 principles whose authors say they apply International Human Rights Law statutes and precedent to situations relevant to LGBT people's experience.The principles were presented at a United Nations event in New York on November 7, 2007, co-sponsored by Argentina, Brazil and Uruguay.\nThe principles have been acknowledged with influencing the French proposed UN declaration on sexual orientation and gender identity, which focuses on ending violence, criminalization and capital punishment and does not include dialogue about same-sex marriage or right to start a family.The proposal was supported by 67 of the then 192 member countries of the United Nations, including all EU member states and the United States. An alternative statement opposing the proposal was initiated by Syria and signed by 57 member nations, including all 27 nations of the Arab League as well as Iran and North Korea.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Sexual orientation and gender identity", "_id": "105--6--7--2", "title": "The 'Yogyakarta Principles' on Sexual Orientation and G"}
{"qas": [{"question": "Why is the right to trade not a human right?", "answer": ""}, {"question": "Both the universal declaration of human rights and the international covenant on economic, social and cultural?", "answer": "a right to work", "ae_score": -0.6397112894442959, "qg_score": null}, {"question": "Both the universal declaration of human rights and the international covenant on economic, social and cultural?", "answer": "a right to work", "ae_score": -0.6397112894442959, "qg_score": null}], "content": "Although both the Universal Declaration of Human Rights and the International Covenant on Economic, Social and Cultural Rights emphasize the importance of a right to work, neither of these documents explicitly mention free trade as a mechanism for ensuring this fundamental right. And yet trade plays a key role in providing jobs.\nSome experts argue that trade is inherent to human nature and that when governments inhibit international trade they directly inhibit the right to work and the other indirect benefits, like the right to education, that increased work and investment help accrue.Others have argued that the ability to trade does not affect everyone equally\u2014often groups like the rural poor, indigenous groups and women are less likely to access the benefits of increased trade.\nOn the other hand, others think that it is no longer primarily individuals but companies that trade, and therefore it cannot be guaranteed as a human right. Additionally, trying to fit too many concepts under the umbrella of what qualifies as a human right has the potential to dilute their importance. Finally, it is difficult to define a right to trade as either \"fair\" or \"just\" in that the current trade regime produces winners and losers but its reform is likely to produce (different) winners and losers.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Trade", "_id": "105--6--7--3", "title": "Trade is a Human Right"}
{"qas": [{"question": "How is water and sanitation recognized as human rights?", "answer": ""}, {"question": "When was water and sanitation recognized as human rights?", "answer": "July 28, 2010", "ae_score": -0.3965811584500583, "qg_score": null}, {"question": "When was water and sanitation recognized as human rights?", "answer": "July 28, 2010", "ae_score": -0.3965811584500583, "qg_score": null}], "content": "The right to water has been recognized in a wide range of international documents, including treaties, declarations and other standards. For instance, the 1979 Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW) requires State parties to ensure to women the right to \u201cenjoy adequate living conditions, particularly in relation to [\u2026]  water supply\u201d. The 1989 Convention on the Rights of the Child (CRC) requires States parties to combat disease and malnutrition \u201cthrough the provision of adequate nutritious foods and clean drinking-water\u201d.\nThe most clear definition of the Human right to water has been issued by the UN Committee on Economic, Social and Cultural Rights. This treaty body interpreting legal obligations of State parties to the International Covenant on Economic, Social and Cultural Rights (ICESCR) issued in 2002 a non-binding interpretation affirming that access to water was a condition for the enjoyment of the right to an adequate standard of living and inextricably related to the right to the highest attainable standard of health (see ICESCR Art.11 & 12) and therefore a human right:\nOn July 28, 2010, the United Nations General Assembly declared water and sanitation as human rights. Today all States have at least ratified one human rights convention which explicitly or implicitly recognizes the right, and they all have signed at least one political declaration recognizing this right.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Water", "_id": "105--6--7--4", "title": "The Human Right to Water"}
{"qas": [{"question": "What is the difference between human rights and sexual and reproductive rights?", "answer": ""}, {"question": "Where was the conference on human rights held in 1994?", "answer": "Cairo", "ae_score": -0.29210553051908295, "qg_score": null}, {"question": "Where was the conference on human rights held in 1994?", "answer": "Cairo", "ae_score": -0.29210553051908295, "qg_score": null}], "content": "Human rights include women\u2019s rights and sexual and reproductive rights. Sexual and reproductive rights are part of a continuum of human rights, which includes the rights to life, health and education, the rights to equality and non-discrimination, and the right to decide the timing, number and spacing of one\u2019s children.\nReproductive and sexual rights as part of human rights was affirmed internationally at the Programme of Action of the International Conference on Population and Development (ICPD) in Cairo in 1994. It was the first among international development frameworks to address issues related to sexuality, sexual and reproductive health, and reproductive rights.\nThe ICPD Programme of Action in paragraph 7.2 \u201cdefines an individual\u2019s sexual and reproductive health as complete well-being related to sexual activity and reproduction. Sexual and reproductive health and rights (SRHR) encompass both entitlements and freedoms. This includes the definition of reproductive rights in paragraph 7.3 of the ICPD PoA, which clarifies that these are not a new set of rights but human rights in existing human rights instruments related to sexual and reproductive autonomy and the attainment of sexual and reproductive health. Additionally, the 1995 Beijing Platform for Action (PfA) expands this definition to cover both sexuality and reproduction by affirming in paragraph 96 the right to exercise control over and make decisions about one\u2019s sexuality, including sexual and reproductive health, free of coercion, discrimination and violence.\u201d ", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Sexual and reproductive rights", "_id": "105--6--7--5", "title": "Reproductive and sexual rights as part of human rights"}
{"qas": [{"question": "How did the concept ofroductive rights come to be?", "answer": ""}, {"question": "When did reproductive rights become a part of human rights?", "answer": "1968", "ae_score": -0.6467491702963424, "qg_score": null}, {"question": "When did reproductive rights become a part of human rights?", "answer": "1968", "ae_score": -0.6467491702963424, "qg_score": null}], "content": "Reproductive rights were first established as a subset of human rights at the United Nations 1968 International Conference on Human Rights. The sixteenth article of the resulting Proclamation of Teheran states, \"Parents have a basic human right to determine freely and responsibly the number and the spacing of their children.\"\nReproductive rights may include some or all of the following rights: the right to legal or safe abortion, the right to control one's reproductive functions, the right to quality reproductive healthcare, and the right to education and access in order to make reproductive choices free from coercion, discrimination, and violence.\nReproductive rights may also be understood to include education about contraception and sexually transmitted infections, and freedom from coerced sterilization and contraception, protection from gender-based practices such as female genital cutting (FGC) and male genital mutilation (MGM).", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "World Health Organization", "_id": "105--6--7--6", "title": "Reproductive Rights (Reproductive Rights)"}
{"qas": [{"question": "Why do people think access to the internet is a fundamental right?", "answer": ""}, {"question": "What percentage of adults said that access to the internet should be a fundamental right of all?", "answer": "79%", "ae_score": -0.3284271772074532, "qg_score": null}, {"question": "What percentage of adults said that access to the internet should be a fundamental right of all?", "answer": "79%", "ae_score": -0.3284271772074532, "qg_score": null}], "content": "In October 2009, Finland's Ministry of Transport and Communications announced that every person in Finland would have the legal right to Internet access.Since July 2010, the government has legally obligated telecommunications companies to offer broadband Internet access to every permanent residence and office. The connection must be \"reasonably priced\" and have a downstream rate of at least 1 Mbit/s.\nIn March 2010, the BBC, having commissioned an opinion poll, reported that \"almost four in five people around the world believe that access to the internet is a fundamental right.\"The poll, conducted by the polling company GlobeScan for the BBC World Service, collated the answers of 27,973 adult citizens across 26 countries to find that 79% of adults either strongly agreed or somewhat agreed with the statement: \"access to the internet should be a fundamental right of all people\".", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Information and communication technologies", "_id": "105--6--7--7", "title": "Access to the Internet Should Be a Fundamental Right of All People"}
{"qas": [{"question": "What is non-refoulement?", "answer": ""}, {"question": "What is the foundation for international refugee law?", "answer": "Non-refoulement", "ae_score": -0.31344592014560824, "qg_score": null}, {"question": "What is the foundation for international refugee law?", "answer": "Non-refoulement", "ae_score": -0.31344592014560824, "qg_score": null}], "content": "Non-refoulement is the right not to be returned to a place of persecution and is the foundation for international refugee law, as outlined in the 1951 Convention Relating to the Status of Refugees. Both the right to non-refoulement and the right to asylum have taken centre stage in recent debates over the treatment of refugees. A central worry about the right to asylum is that it can limit a states power to handle a mass influx of refugees. Processing asylum applications can take a considerable amount of time, and this amount rises with the amount of refugees applying. This creates an incentive for more refugees to apply, since they are allowed to stay in the country during the application process. One potential solution to the problem of mass influx is proposed by political philosopher Andy Lamey. Lamey proposes a portable procedural model that focuses on the right to non-refoulement. Crucially, the procedural rights defended by this model can be applied outside national borders, within any rights respecting country; this allows the burden of mass influx to be shared by a plurality of countries without violating the procedural rights of the refugee.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Substantive rights", "sub_heading": "Right to Non-refoulement vs. Right to Asylum", "_id": "105--6--7--8", "title": "The Right to Non-Refoulement and the Right to Asyl"}
{"qas": [{"question": "Why are there so many conflicts between human rights and environmental rights?", "answer": ""}, {"question": "How many basic conceptions of environmental human rights are there?", "answer": "two", "ae_score": -0.5852827905014334, "qg_score": null}, {"question": "How many basic conceptions of environmental human rights are there?", "answer": "two", "ae_score": -0.5852827905014334, "qg_score": null}], "content": "There are two basic conceptions of environmental human rights in the current human rights system. The first is that the right to a healthy or adequate environment is itself a human right (as seen in both Article 24 of the African Charter on Human and Peoples' Rights, and Article 11 of the San Salvador Protocol to the American Convention on Human Rights).The second conception is the idea that environmental human rights can be derived from other human rights, usually \u2013 the right to life, the right to health, the right to private family life and the right to property (among many others). This second theory enjoys much more widespread use in human rights courts around the world, as those rights are contained in many human rights documents.\nThe onset of various environmental issues, especially climate change, has created potential conflicts between different human rights. Human rights ultimately require a working ecosystem and healthy environment, but the granting of certain rights to individuals may damage these. Such as the conflict between right to decide number of offspring and the common need for a healthy environment, as noted in the tragedy of the commons.In the area of environmental rights, the responsibilities of multinational corporations, so far relatively unaddressed by human rights legislation, is of paramount consideration.\nEnvironmental rights revolve largely around the idea of a right to a livable environment both for the present and the future generations.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Relationship with other topics", "sub_heading": "Relationship with other topics", "_id": "105--7--0---1", "title": "Environmental Human Rights in the United States"}
{"qas": [{"question": "What is the difference between human rights and the right to bear arms?", "answer": ""}, {"question": "What are rights that cannot be derogated for reasons of national security known as?", "answer": "peremptory norms", "ae_score": -0.32622460193333686, "qg_score": null}, {"question": "What are rights that cannot be derogated for reasons of national security known as?", "answer": "peremptory norms", "ae_score": -0.32622460193333686, "qg_score": null}], "content": "With the exception of non-derogable human rights (international conventions class the right to life, the right to be free from slavery, the right to be free from torture and the right to be free from retroactive application of penal laws as non-derogable), the UN recognizes that human rights can be limited or even pushed aside during times of national emergency \u2013 although\nRights that cannot be derogated for reasons of national security in any circumstances are known as peremptory norms or ''jus cogens''. Such United Nations Charter obligations are binding on all states and cannot be modified by treaty.\nExamples of national security being used to justify human rights violations include the Japanese American internment during World War II,Stalin's Great Purge, and the modern-day abuses of terror suspects rights by some countries, often in the name of the War on Terror.", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Relationship with other topics", "sub_heading": "National security", "_id": "105--7--1---1", "title": "Human Rights in Times of National Security"}
{"qas": [{"question": "Why is it racist to say that Asians want human rights?", "answer": ""}, {"question": "What is an example of a practice that is not mandated by any religion?", "answer": "female genital mutilation", "ae_score": -0.19011408902938928, "qg_score": null}, {"question": "What is an example of a practice that is not mandated by any religion?", "answer": "female genital mutilation", "ae_score": -0.19011408902938928, "qg_score": null}], "content": "The UDHR enshrines universal rights that apply to all humans equally, whichever geographical location, state, race or culture they belong to. However, in academia there is a dispute between scholars that advocate moral relativism and scholars that advocate moral universalism. Relativists do not argue against human rights, but concede that human rights are social constructed and are shaped by cultural and environmental contexts. Universalists argue that human rights have always existed, and apply to all people regardless of culture, race, sex, or religion.\nMore specifically, proponents of cultural relativism argue for acceptance of different cultures, which may have practices conflicting with human rights. Relativists caution that universalism could be used as a form of cultural, economic or political imperialism. The White Man's Burden is used as an example of imperialism and the destruction of local cultures justified by the desire to spread Eurocentric values.In particular, the concept of human rights is often claimed to be fundamentally rooted in a politically liberal outlook which, although generally accepted in Europe, Japan or North America, is not necessarily taken as standard elsewhere.\nOpponents of relativism argue that some practices exist that violate the norms of all human cultures. A common example is female genital mutilation, which occurs in different cultures in Africa, Asia and South America . It is not mandated by any religion, but has become a tradition in many cultures. It is considered a violation of women's and girl's rights by much of the international community, and is outlawed in some countries.\nThe former Prime Ministers of Singapore, Lee Kuan Yew, and of Malaysia, Mahathir bin Mohamad both claimed in the 1990s that ''Asian values'' were significantly different from Western values and included a sense of loyalty and foregoing personal freedoms for the sake of social stability and prosperity, and therefore authoritarian government is more appropriate in Asia than democracy. Lee Kuan Yew argued that:\nIn response, critics have pointed out that cultural relativism could be used as a justification for authoritarianism. An example is in 1981, when the Iranian representative to the United Nations, Said Rajaie-Khorassani, articulated the position of his country regarding the Universal Declaration of Human Rights by saying that the UDHR was \"a secular understanding of the Judeo-Christian tradition\", which could not be implemented by Muslims without trespassing the Islamic law.The Asian Values argument was criticized by Mahathir's former deputy:\nand by Singapore's opposition leader Chee Soon Juan, who states that it is racist to assert that Asians do not want human rights.\nDefenders of moral universalism argue that relativistic arguments neglect the fact that modern human rights are new to all cultures, dating back no further than the UDHR in 1948. They argue that the UDHR was drafted by people from many different cultures and traditions, including a US Roman Catholic, a Chinese Confucian philosopher, a French zionist and a representative from the Arab League, amongst others, and drew upon advice from thinkers such as Mahatma Gandhi. Michael Ignatieff has argued that cultural relativism is almost exclusively an argument used by those who wield power in cultures which commit human rights abuses, and that those whose human rights are compromised are the powerless.This reflects the fact that the difficulty in judging universalism versus relativism lies in who is claiming to represent a particular culture.\nAlthough the argument between universalism and relativism is far from complete, it is an academic discussion in that all international human rights instruments adhere to the principle that human rights are universally applicable. The 2005 World Summit reaffirmed the international community's adherence to this principle:", "page_name": "Human rights", "page_id": "Human%20rights", "heading": "Relationship with other topics", "sub_heading": "Relativism and universalism", "_id": "105--7--2---1", "title": "Moral Relativism vs Moral Universalism"}
{"qas": [{"question": "Why is heavy water used in nuclear power?", "answer": ""}, {"question": "When was heavy water first used in nuclear reactors?", "answer": "1932", "ae_score": -0.2961660006386378, "qg_score": null}, {"question": "When was heavy water first used in nuclear reactors?", "answer": "1932", "ae_score": -0.2961660006386378, "qg_score": null}], "content": "Deuterium is an isotope of hydrogen whose nucleus comprises both a neutron and a proton; the nucleus of a protium (normal hydrogen) atom consists of just a proton. The additional neutron makes a deuterium atom roughly twice as heavy as a protium atom.\nA molecule of heavy water has two deuterium atoms in place of the two protium atoms of ordinary \"light\" water. The weight of a heavy water molecule, however, is not substantially different from that of a normal water molecule, because about 89% of the molecular weight of water comes from the single oxygen atom rather than the two hydrogen atoms. The colloquial term ''heavy water'' refers to a highly enriched water mixture that contains mostly deuterium oxide , but also some hydrogen-deuterium oxide (HDO) and a smaller number of ordinary hydrogen oxide  molecules. For instance, the heavy water used in CANDU reactors is 99.75% enriched by hydrogen atom-fraction\u2014meaning that 99.75% of the hydrogen atoms are of the heavy type. For comparison, ordinary water (the \"ordinary water\" used for a deuterium standard) contains only about 156 deuterium atoms per million hydrogen atoms, meaning that 0.0156% of the hydrogen atoms are of the heavy type.\nHeavy water is not radioactive. In its pure form, it has a density about 11% greater than water, but is otherwise physically and chemically similar. Nevertheless, the various differences in deuterium-containing water (especially affecting the biological properties) are larger than in any other commonly occurring isotope-substituted compound because deuterium is unique among heavy stable isotopes in being twice as heavy as the lightest isotope. This difference increases the strength of water's hydrogen-oxygen bonds, and this in turn is enough to cause differences that are important to some biochemical reactions. The human body naturally contains deuterium equivalent to about five grams of heavy water, which is harmless. When a large fraction of water (> 50%) in higher organisms is replaced by heavy water, the result is cell dysfunction and death.\nHeavy water was first produced in 1932, a few months after the discovery of deuterium. With the discovery of nuclear fission in late 1938, and the need for a neutron moderator that captured few neutrons, heavy water became a component of early nuclear energy research. Since then, heavy water has been an essential component in some types of reactors, both those that generate power and those designed to produce isotopes for nuclear weapons. These heavy water reactors have the advantage of being able to run on natural uranium without using graphite moderators that pose radiological and dust explosion hazards in the decommissioning phase. Most modern reactors use enriched uranium with ordinary water as the moderator.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Explanation", "sub_heading": "Explanation", "_id": "106--0---1---1", "title": "Heavy Water \u2014 A Chemical Comparison of Deuterium and Normal Water"}
{"qas": [{"question": "What is heavy water and why is it so expensive?", "answer": ""}, {"question": "Which type of water is denser than normal water?", "answer": "heavy water", "ae_score": -0.91553782105357, "qg_score": null}, {"question": "Which type of water is denser than normal water?", "answer": "heavy water", "ae_score": -0.91553782105357, "qg_score": null}], "content": "'''Semiheavy water''', HDO, exists whenever there is water with light hydrogen (protium, ) and deuterium (D or ) in the mix. This is because hydrogen atoms (hydrogen-1 and deuterium) are rapidly exchanged between water molecules. Water containing 50% H and 50% D in its hydrogen actually contains about 50% HDO and 25% each of  and , in dynamic equilibrium.In normal water, about 1 molecule in 3,200 is HDO (one hydrogen in 6,400 is in the form of D), and heavy water molecules () only occur in a proportion of about 1 molecule in 41 million (i.e. one in 6,400). Thus semiheavy water molecules are far more common than \"pure\" (homoisotopic) heavy water molecules.\nWater enriched in the heavier oxygen isotopes  and  is also commercially available, e.g., for use as a non-radioactive isotopic tracer. It is \"heavy water\" as it is denser than normal water ( is approximately as dense as ,  is about halfway between  and )\u2014but is rarely called heavy water, since it does not contain the deuterium that gives DO its unusual nuclear and biological properties. It is more expensive than DO due to the more difficult separation of O and O.\nTritiated water contains tritium (H) in place of protium (H) or deuterium (H), and therefore is radioactive.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Other heavy forms of water", "sub_heading": "Other heavy forms of water", "_id": "106--1---1---1", "title": "'''Semiheavy Water''', HDO, is"}
{"qas": [{"question": "How can we tell the difference between normal water and heavy water?", "answer": ""}, {"question": "What is the melting temperature of heavy water?", "answer": "3.7 \u00b0C", "ae_score": -0.35290639506411187, "qg_score": null}, {"question": "What is the melting temperature of heavy water?", "answer": "3.7 \u00b0C", "ae_score": -0.35290639506411187, "qg_score": null}], "content": "The physical properties of water and heavy water differ in several respects. Heavy water is 10.6% denser than ordinary water, and heavy water's physically different properties can be seen without equipment if a frozen sample is dropped into normal water, as it will sink. If the water is ice-cold the higher melting temperature of heavy ice can also be observed: it melts at 3.7 \u00b0C, and thus does not melt in ice-cold normal water.\nAn early experiment reported not the \"slightest difference\" in taste between ordinary and heavy water. However, rats given a choice between distilled normal water and heavy water were able to avoid the heavy water based on smell, and it may have a different taste.\nNo physical properties are listed for \"pure\" semi-heavy water, because it is unstable as a bulk liquid. In the liquid state, a few water molecules are always in an ionised state, which means the hydrogen atoms can exchange among different oxygen atoms. Semi-heavy water could, in theory, be created via a chemical method, but it would rapidly transform into a dynamic mixture of 25% light water, 25% heavy water, and 50% semi-heavy water.  However, if it were made in the gas phase and directly deposited into a solid, semi heavy water in the form of ice could be stable.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Physical properties", "sub_heading": "Physical properties", "_id": "106--2---1---1", "title": "Semi-Heavy Water: Physical Properties"}
{"qas": [{"question": "How did scientists figure out how much water to make?", "answer": ""}, {"question": "Who discovered the isotope deuterium in 1931?", "answer": "Harold Urey", "ae_score": -0.5201530819495008, "qg_score": null}, {"question": "Who discovered the isotope deuterium in 1931?", "answer": "Harold Urey", "ae_score": -0.5201530819495008, "qg_score": null}], "content": "Harold Urey discovered the isotope deuterium in 1931 and was later able to concentrate it in water. Urey's mentor Gilbert Newton Lewis isolated the first sample of pure heavy water by electrolysis in 1933. George de Hevesy and Erich Hofer used heavy water in 1934 in one of the first biological tracer experiments, to estimate the rate of turnover of water in the human body. The history of large-quantity production and use of heavy water in early nuclear experiments is given below.Emilian Bratu and Otto Redlich studied the autodissociation of heavy water in 1934.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "History", "sub_heading": "History", "_id": "106--3---1---1", "title": "The History of Heavy Water in Early Nuclear Explorations"}
{"qas": [{"question": "Why can't we replace the heavy atom with hydrogen?", "answer": ""}, {"question": "What type of oxide is used in heavy water?", "answer": "Deuterium oxide", "ae_score": -0.3420886492481676, "qg_score": null}, {"question": "What type of oxide is used in heavy water?", "answer": "Deuterium oxide", "ae_score": -0.3420886492481676, "qg_score": null}], "content": "Experiments in mice, rats, and dogs have shown that a degree of 25% deuteration causes (sometimes irreversible) sterility, because neither gametes nor zygotes can develop. High concentrations of heavy water (90%) rapidly kill fish, tadpoles, flatworms, and ''Drosophila''. Mammals (for example, rats) given heavy water to drink die after a week, at a time when their body water approaches about 50% deuteration. The mode of death appears to be the same as that in cytotoxic poisoning (such as chemotherapy) or in acute radiation syndrome (though deuterium is not radioactive), and is due to deuterium's action in generally inhibiting cell division. It is more toxic to malignant cells than normal cells but the concentrations needed are too high for regular use. As in chemotherapy, deuterium-poisoned mammals die of a failure of bone marrow (bleeding and infection) and intestinal-barrier functions (diarrhea and fluid loss).\nDespite the problems of plants and animals in living with too much deuterium, prokaryotic organisms such as bacteria, which do not have the mitotic problems induced by deuterium, may be grown and propagated in fully deuterated conditions, resulting in replacement of all hydrogen atoms in the bacterial proteins and DNA with the deuterium isotope.\nFull replacement with heavy atom isotopes can be accomplished in higher organisms with other non-radioactive heavy isotopes (such as carbon-13, nitrogen-15, and oxygen-18), but this cannot be done for the stable heavy isotope of hydrogen.\nDeuterium oxide is used to enhance boron neutron capture therapy, but this effect does not rely on the biological effects of deuterium per se, but instead on deuterium's ability to moderate (slow) neutrons without capturing them.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Effect on biological systems", "sub_heading": "Effect on biological systems", "_id": "106--4--0---1", "title": "Deuterium Oxide and the Effects of Nitrogen Neutron Capture Therapy"}
{"qas": [{"question": "How do we know how much water is in our body?", "answer": ""}, {"question": "What is the cause of the dizziness in heavy water?", "answer": "altered vestibular function", "ae_score": -0.7508668594337159, "qg_score": null}, {"question": "What is the cause of the dizziness in heavy water?", "answer": "altered vestibular function", "ae_score": -0.7508668594337159, "qg_score": null}], "content": "Because it would take a very large amount of heavy water to replace 25% to 50% of a human being's body water (water being in turn 50\u201375% of body weight) with heavy water, accidental or intentional poisoning with heavy water is unlikely to the point of practical disregard. Poisoning would require that the victim ingest large amounts of heavy water without significant normal water intake for many days to produce any noticeable toxic effects.\nOral doses of heavy water in the range of several grams, as well as heavy oxygen O, are routinely used in human metabolic experiments. See doubly labeled water testing. Since one in about every 6,400 hydrogen atoms is deuterium, a 50 kg human containing 32 kg of body water would normally contain enough deuterium (about 1.1 g) to make 5.5 g of pure heavy water, so roughly this dose is required to double the amount of deuterium in the body.\nThe American patent  is for the use of heavy water to treat hypertension (high blood pressure). A loss of blood pressure may partially explain the reported incidence of dizziness upon ingestion of heavy water. However, it is more likely that this symptom can be attributed to altered vestibular function.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Effect on biological systems", "sub_heading": "Toxicity in humans", "_id": "106--4--1---1", "title": "Heavy Water Poisoning"}
{"qas": [{"question": "How does heavy water poisoning work?", "answer": ""}, {"question": "How many employees drank some of the contaminated water?", "answer": "Eight", "ae_score": -0.6661964922192406, "qg_score": null}, {"question": "How many employees drank some of the contaminated water?", "answer": "Eight", "ae_score": -0.6661964922192406, "qg_score": null}], "content": "Although many people associate heavy water primarily with its use in nuclear reactors, pure heavy water is not radioactive. Commercial-grade heavy water is slightly radioactive due to the presence of minute traces of natural tritium, but the same is true of ordinary water. Heavy water that has been used as a coolant in nuclear power plants contains substantially more tritium as a result of neutron bombardment of the deuterium in the heavy water (tritium is a health risk when ingested in large quantities).\nIn 1990, a disgruntled employee at the Point Lepreau Nuclear Generating Station in Canada obtained a sample (estimated as about a \"half cup\") of heavy water from the primary heat transport loop of the nuclear reactor, and loaded it into a cafeteria drink dispenser. Eight employees drank some of the contaminated water. The incident was discovered when employees began leaving bioassay urine samples with elevated tritium levels. The quantity of heavy water involved was far below levels that could induce heavy water toxicity, but several employees received elevated radiation doses from tritium and neutron-activated chemicals in the water. This was not an incident of heavy water poisoning, but rather radiation poisoning from other isotopes in the heavy water. Some news services were not careful to distinguish these points, and some of the public were left with the impression that heavy water is normally radioactive and more severely toxic than it is. Even if pure heavy water had been used in the water cooler indefinitely, it is not likely the incident would have been detected or caused harm, since no employee would be expected to get much more than 25% of their daily drinking water from such a source.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Effect on biological systems", "sub_heading": "Heavy water radiation contamination confusion", "_id": "106--4--2---1", "title": "Heavy Water is Not Radioactive"}
{"qas": [{"question": "Why does Argentina produce so much heavy water?", "answer": ""}, {"question": "How much heavy water does argentina produce per year?", "answer": "200 tons", "ae_score": -0.6889909980838118, "qg_score": null}, {"question": "How much heavy water does argentina produce per year?", "answer": "200 tons", "ae_score": -0.6889909980838118, "qg_score": null}], "content": "Argentina is the main producer of heavy water, using an ammonia/hydrogen exchange based plant supplied by Switzerland's Sulzer company. It is also a major exporter to countries such as Canada, US, and Germany as well as others. The heavy water production facility located at Arroyito (Neuqu\u00e9n Province) is the world's largest heavy water production facility. Argentina produces 200 tons of heavy water per year.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Production", "_id": "106--5--0---1", "title": "Argentina is the world's largest producer of heavy water"}
{"qas": [{"question": "How did the Soviet Union come up with the idea for a nuclear power plant?", "answer": ""}, {"question": "Who took over the heavy water project after world war ii?", "answer": "NKVD", "ae_score": -0.7060375777838734, "qg_score": null}, {"question": "Who took over the heavy water project after world war ii?", "answer": "NKVD", "ae_score": -0.7060375777838734, "qg_score": null}], "content": "In October 1939, Soviet physicists Yakov Borisovich Zel'dovich and  Yulii Borisovich Khariton concluded that heavy water and carbon were the only feasible moderators for a natural uranium reactor, and in August, 1940, along with Georgy Flyorov, submitted a plan to the Russian Academy of Sciences calculating that 15 tons of heavy water were needed for a reactor.  With the Soviet Union having no uranium mines at the time, young Academy workers were sent to Leningrad photographic shops to buy uranium nitrate, but the entire heavy water project was halted in 1941 when German forces invaded during Operation Barbarossa.\nBy 1943, Soviet scientists had discovered that all scientific literature relating to heavy water had disappeared from the West, which Flyorov in a letter warned Soviet leader Joseph Stalin about, and at which time there was only 2\u20133 kg of heavy water in the entire country.  In late 1943, the Soviet purchasing commission in the U.S. obtained 1 kg of heavy water and a further 100 kg in February 1945, and upon World War II ending, the NKVD took over the project.\nIn October 1946, as part of the Russian Alsos, the NKVD deported to the Soviet Union from Germany the German scientists who had worked on heavy water production during the war, including the inventor of the Girdler sulfide process Karl-Hermann Geib.  These German scientists worked under the supervison of German physical chemist  Max Volmer at the Institute of Physical Chemistry in Moscow with the plant they constructed producing large quantities of heavy water by 1948.<ref name=HW/>", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Soviet Union", "_id": "106--5--1---1", "title": "Heavy Water and Uranium Reactors in the Soviet Union"}
{"qas": [{"question": "How was heavy water produced in the US before the Manhattan Project?", "answer": ""}, {"question": "When was the last heavy water reactor shut down?", "answer": "1996", "ae_score": -0.31447074007122544, "qg_score": null}, {"question": "When was the last heavy water reactor shut down?", "answer": "1996", "ae_score": -0.31447074007122544, "qg_score": null}], "content": "During the Manhattan Project the United States constructed three heavy water production plants as part of the P-9 Project at Morgantown Ordnance Works, near Morgantown, West Virginia; at the Wabash River Ordnance Works, near Dana and Newport, Indiana; and at the Alabama Ordnance Works, near Childersburg and Sylacauga, Alabama. Heavy water was also acquired from the Cominco plant in Trail, British Columbia (Canada). The Chicago Pile-3 experimental reactor used heavy water as a moderator and went critical in 1944. The three domestic production plants were shut down in 1945 after producing around 20 metric tons of product (around 20,000 litres). The Wabash plant was reopened and began resumption of heavy water production in 1952.\nIn 1953, the United States began using heavy water in plutonium production reactors at the Savannah River Site. The first of the five heavy water reactors came online in 1953, and the last was placed in cold shutdown in 1996. The SRS reactors were heavy water reactors so that they could produce both plutonium and tritium for the US nuclear weapons program.\nThe U.S. developed the Girdler sulfide chemical exchange production process\u2014which was first demonstrated on a large scale at the Dana, Indiana plant in 1945 and at the Savannah River Plant, South Carolina in 1952. DuPont operated the SRP for the USDOE until 1 April 1989, when Westinghouse took it over.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "United States", "_id": "106--5--2---1", "title": "Heavy Water Production in the United States"}
{"qas": [{"question": "How did India become the world's largest water producer?", "answer": ""}, {"question": "Which country is the leading producer of heavy water in the world?", "answer": "India", "ae_score": -0.3150760453313103, "qg_score": null}, {"question": "Which country is the leading producer of heavy water in the world?", "answer": "India", "ae_score": -0.3150760453313103, "qg_score": null}], "content": "India is one of the world's largest producers of heavy water through its Heavy Water Board and also exports to countries like Republic of Korea and the US. Development of heavy water process in India happened in three phases: The first phase (late 1950s to mid-1980s) was a period of technology development, the second phase was of deployment of technology and process stabilisation (mid-1980s to early 1990s) and third phase saw consolidation and a shift towards improvement in production and energy conservation.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "India", "_id": "106--5--3---1", "title": "Heavy Water Process Development in India"}
{"qas": [{"question": "How did North Korea get their water?", "answer": ""}, {"question": "What type of water was produced by the japanese pilot plant?", "answer": "heavy water", "ae_score": -0.8218138905512087, "qg_score": null}, {"question": "What type of water was produced by the japanese pilot plant?", "answer": "heavy water", "ae_score": -0.8218138905512087, "qg_score": null}], "content": "In the 1930s, it was suspected by the United States and Soviet Union that Austrian chemist Fritz Johann Hansgirg built a pilot plant for the Empire of Japan in Japanese ruled northern Korea to produce heavy water by using a new process he had invented.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Empire of Japan", "_id": "106--5--4---1", "title": "In the 1930s, it was suspected that Austrian chemist Fritz Johann Hansgirg"}
{"qas": [{"question": "Why didn't the Germans use Hydrogen to make nuclear weapons?", "answer": ""}, {"question": "When did israel start using norwegian heavy water?", "answer": "1959", "ae_score": -0.24796717132645874, "qg_score": null}, {"question": "When did israel start using norwegian heavy water?", "answer": "1959", "ae_score": -0.24796717132645874, "qg_score": null}], "content": "In 1934, Norsk Hydro built the first commercial heavy water plant at Vemork, Tinn, with a capacity of 12 tonnes per year. From 1940 and throughout World War II, the plant was under German control and the Allies decided to destroy the plant and its heavy water to inhibit German development of nuclear weapons. In late 1942, a planned raid by British airborne troops failed, both gliders crashing. The raiders were killed in the crash or subsequently executed by the Germans. On the night of 27 February 1943 Operation Gunnerside succeeded. Norwegian commandos and local resistance managed to demolish small, but key parts of the electrolytic cells, dumping the accumulated heavy water down the factory drains.\nOn 16 November 1943, the Allied air forces dropped more than 400 bombs on the site. The Allied air raid prompted the Nazi government to move all available heavy water to Germany for safekeeping. On 20 February 1944, a Norwegian partisan sank the ferry M/F ''Hydro'' carrying heavy water across Lake Tinn, at the cost of 14 Norwegian civilian lives, and most of the heavy water was presumably lost. A few of the barrels were only half full, and therefore could float, and may have been salvaged and transported to Germany.\nRecent investigation of production records at Norsk Hydro and analysis of an intact barrel that was salvaged in 2004 revealed that although the barrels in this shipment contained water of pH 14\u2014indicative of the alkaline electrolytic refinement process\u2014they did not contain high concentrations of DO. Despite the apparent size of the shipment, the total quantity of pure heavy water was quite small, most barrels only containing 0.5\u20131% pure heavy water. The Germans would have needed a total of about 5 tons of heavy water to get a nuclear reactor running. The manifest clearly indicated that there was only half a ton of heavy water being transported to Germany. ''Hydro'' was carrying far too little heavy water for one reactor, let alone the 10 or more tons needed to make enough plutonium for a nuclear weapon.\nIsrael admitted running the Dimona reactor with Norwegian heavy water sold to it in 1959. Through re-export using Romania and Germany, India probably also used Norwegian heavy water.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Norway", "_id": "106--5--5---1", "title": "Heavy Water from Norsk Hydro"}
{"qas": [{"question": "Why is Bruce a bad place to build a nuclear power plant?", "answer": ""}, {"question": "When was the first heavy water plant built?", "answer": "1943", "ae_score": -0.36838937116076065, "qg_score": null}, {"question": "When was the first heavy water plant built?", "answer": "1943", "ae_score": -0.36838937116076065, "qg_score": null}], "content": "As part of its contribution to the Manhattan Project, Canada built and operated a 6-tonnes-per-year electrolytic heavy water plant at Trail, British Columbia, which started operation in 1943.\nThe Atomic Energy of Canada Limited (AECL) design of power reactor requires large quantities of heavy water to act as a neutron moderator and coolant. AECL ordered two heavy water plants, which were built and operated in Atlantic Canada at Glace Bay, Nova Scotia (by Deuterium of Canada Limited) and Port Hawkesbury, Nova Scotia (by General Electric Canada). These plants proved to have significant design, construction and production problems and so AECL built the Bruce Heavy Water Plant (), which it later sold to Ontario Hydro, to ensure a reliable supply of heavy water for future power plants. The two Nova Scotia plants were shut down in 1985 when their production proved unnecessary.\nThe Bruce Heavy Water Plant in Ontario was the world's largest heavy water production plant with a capacity of 700 tonnes per year. It used the Girdler sulfide process to produce heavy water, and required 340,000 tonnes of feed water to produce one tonne of heavy water. It was part of a complex that included eight CANDU reactors, which provided heat and power for the heavy water plant. The site was located at Douglas Point near Tiverton, Ontario on Lake Huron where it had access to the waters of the Great Lakes.\nThe Bruce plant was commissioned in 1979 to provide heavy water for a large increase in Ontario's nuclear power generation. The plants were significantly more efficient than planned and only three of the planned four units were eventually commissioned. In addition, the nuclear power programme was slowed down and effectively stopped due to a perceived oversupply of electricity, later shown to be temporary, in 1993. Improved efficiency in the use and recycling of heavy water plus the over-production at Bruce left Canada with enough heavy water for its anticipated future needs. Also, the Girdler process involves large amounts of hydrogen sulfide, raising environmental concerns if there should be a release. The Bruce heavy water plant was shut down in 1997, after which the plant was gradually dismantled and the site cleared.\nAtomic Energy of Canada Limited (AECL) is currently researching other more efficient and environmentally benign processes for creating heavy water. This is essential for the future of the CANDU reactors since heavy water represents about 20% of the capital cost of each reactor.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Canada", "_id": "106--5--6---1", "title": "Canada's contribution to the Manhattan Project"}
{"qas": [{"question": "Why is Iran allowed to store so much heavy water?", "answer": ""}, {"question": "When was the ir-40 supposed to be re-designed?", "answer": "July 2015", "ae_score": -0.21321531093902862, "qg_score": null}, {"question": "When was the ir-40 supposed to be re-designed?", "answer": "July 2015", "ae_score": -0.21321531093902862, "qg_score": null}], "content": "Since 1996 a plant for production of heavy water was being constructed at Khondab near Arak. On 26 August 2006, Iranian President Ahmadinejad inaugurated the expansion of the country's heavy-water plant. Iran has indicated that the heavy-water production facility will operate in tandem with a 40 MW research reactor that had a scheduled completion date in 2009.\nIran produced deuterated solvents in early 2011 for the first time.\nThe core of the IR-40 is supposed to be re-designed based on the nuclear agreement in July 2015.\nIran is currently allowed to store only 130 Tons of heavy-water.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Iran", "_id": "106--5--7---1", "title": "Heavy-water production in Iran"}
{"qas": [{"question": "Why is Pakistan building nuclear weapons?", "answer": ""}, {"question": "How many MWt heavy water research reactor in pakistan?", "answer": "50", "ae_score": null, "qg_score": null}, {"question": "How many MWt heavy water research reactor in pakistan?", "answer": "50", "ae_score": null, "qg_score": null}], "content": "The 50 MWt heavy water and natural uranium research reactor at Khushab, in Punjab province, is a central element of Pakistan's program for production of plutonium, deuterium and tritium for advanced compact warheads (i.e. thermonuclear weapons). Pakistan succeeded in acquiring a tritium purification and storage plant and deuterium and tritium precursor materials from two German firms.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Pakistan", "_id": "106--5--8---1", "title": "Pakistan Acquires Heavy Water and Natural Uranium Research Reactor in Punjab Province"}
{"qas": [{"question": "Why did France not have a nuclear reactor in the 1950s?", "answer": ""}, {"question": "Where was the first heavy water plant built?", "answer": "France", "ae_score": -0.3733884476956955, "qg_score": null}, {"question": "Where was the first heavy water plant built?", "answer": "France", "ae_score": -0.3733884476956955, "qg_score": null}], "content": "Romania produces heavy water at the Drobeta Girdler sulfide plant for domestic and export purposes.\nFrance operated a small plant during the 1950s and 1960s.\nHeavy water exists in elevated concentration in Lake Tanganyika in East Africa.  It is likely that similar elevated concentrations exist in lakes with similar limnology.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Production", "sub_heading": "Other countries", "_id": "106--5--9---1", "title": "Heavy Water in Lake Tanganyika"}
{"qas": [{"question": "Why is deuterium oxide used in nuclear magnetic resonance spectroscopy?", "answer": ""}, {"question": "What is used in nuclear magnetic resonance spectroscopy?", "answer": "Deuterium oxide", "ae_score": -0.5773278245763009, "qg_score": null}, {"question": "What is used in nuclear magnetic resonance spectroscopy?", "answer": "Deuterium oxide", "ae_score": -0.5773278245763009, "qg_score": null}], "content": "Deuterium oxide is used in nuclear magnetic resonance spectroscopy when using water as solvent if the nuclide of interest is hydrogen. This is because the signal from light-water (HO) solvent molecules interfere with observing the signal from the molecule of interest dissolved in it. Deuterium has a different magnetic moment and therefore does not contribute to the H-NMR signal at the hydrogen-1 resonance frequency.\nFor some experiments, it may be desirable to identify the labile hydrogens on a compound, that is hydrogens that can easily exchange away as H ions on some positions in a molecule.  With addition of DO, sometimes referred to as a ''DO shake'', labile hydrogens exchange away and are substituted by deuterium (H) atoms. These positions in the molecule then do not appear in the H-NMR spectrum.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Applications", "_id": "106--6--0---1", "title": "Deuterium oxide in nuclear magnetic resonance spectroscopy"}
{"qas": [{"question": "What is deuterium oxide and tritium?", "answer": ""}, {"question": "Where does deuterium come from in heavy water?", "answer": "Deuterium oxide", "ae_score": -0.2547757275024861, "qg_score": null}, {"question": "Where does deuterium come from in heavy water?", "answer": "Deuterium oxide", "ae_score": -0.2547757275024861, "qg_score": null}], "content": "Deuterium oxide is often used as the source of deuterium for preparing specifically labelled isotopologues of organic compounds. For example, C-H bonds adjacent to ketonic carbonyl groups can be replaced by C-D bonds, using acid or base catalysis. Trimethylsulfoxonium iodide, made from dimethyl sulfoxide and methyl iodide can be recrystallized from deuterium oxide, and then dissociated to regenerate methyl iodide and dimethyl sulfoxide, both deuterium labelled. In cases where specific double labelling by deuterium and tritium is contemplated, the researcher must be aware that deuterium oxide, depending upon age and origin, can contain some tritium.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Organic chemistry", "_id": "106--6--1---1", "title": "Deuterium Oxide and Tritium"}
{"qas": [{"question": "How does Deuterium Oxide work?", "answer": ""}, {"question": "What is used instead of water to collect fir spectra?", "answer": "Deuterium oxide", "ae_score": -0.28828796214181807, "qg_score": null}, {"question": "What is used instead of water to collect fir spectra?", "answer": "Deuterium oxide", "ae_score": -0.28828796214181807, "qg_score": null}], "content": "Deuterium oxide is often used instead of water when collecting FTIR spectra of proteins in solution. HO creates a strong band that overlaps with the amide I region of proteins. The band from DO is shifted away from the amide I region.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Fourier transform spectroscopy", "_id": "106--6--2---1", "title": "FTIR spectra of proteins in solution"}
{"qas": [{"question": "Why is heavy water used in nuclear power plants?", "answer": ""}, {"question": "When was the first heavy water reactor built?", "answer": "1942", "ae_score": -0.31697730656495704, "qg_score": null}, {"question": "When was the first heavy water reactor built?", "answer": "1942", "ae_score": -0.31697730656495704, "qg_score": null}], "content": "Heavy water is used in certain types of nuclear reactors, where it acts as a neutron moderator to slow down neutrons so that they are more likely to react with the fissile uranium-235 than with uranium-238, which captures neutrons without fissioning.The CANDU reactor uses this design. Light water also acts as a moderator,  but because light water absorbs more neutrons than heavy water, reactors using light water for a reactor moderator must use enriched uranium rather than natural uranium, otherwise criticality is impossible. A significant fraction of outdated power reactors, such as the RBMK reactors in the USSR, were constructed using normal water for cooling but graphite as a moderator. However, the danger of graphite in power reactors (graphite fires in part led to the Chernobyl disaster) has led to the discontinuation of graphite in standard reactor designs.\nBecause they do not require uranium enrichment, heavy water reactors are more of a concern in regards to nuclear proliferation. The breeding and extraction of plutonium can be a relatively rapid and cheap route to building a nuclear weapon, as chemical separation of plutonium from fuel is easier than isotopic separation of U-235 from natural uranium.Among current and past nuclear weapons states, Israel, India, and North Korea first used plutonium from heavy water moderated reactors burning natural uranium, while China, South Africa and Pakistan first built weapons using highly enriched uranium.\nIn the U.S., however, the first experimental atomic reactor (1942), as well as the Manhattan Project Hanford production reactors that produced the plutonium for the Trinity test and Fat Man bombs, all used pure carbon (graphite) neutron moderators combined with normal water cooling pipes. They functioned with neither enriched uranium nor heavy water. Russian and British plutonium production also used graphite-moderated reactors.\nThere is no evidence that civilian heavy water power reactors\u2014such as the CANDU or Atucha designs\u2014have been used to produce military fissile materials. In nations that do not already possess nuclear weapons, nuclear material at these facilities is under IAEA safeguards to discourage any diversion.\nDue to its potential for use in nuclear weapons programs, the possession or import/export of large industrial quantities of heavy water are subject to government control in several countries. Suppliers of heavy water and heavy water production technology typically apply IAEA (International Atomic Energy Agency) administered safeguards and material accounting to heavy water. (In Australia, the ''Nuclear Non-Proliferation (Safeguards) Act 1987''.) In the U.S. and Canada, non-industrial quantities of heavy water (i.e., in the gram to kg range) are routinely available without special license through chemical supply dealers and commercial companies such as the world's former major producer Ontario Hydro.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Neutron moderator", "_id": "106--6--3---1", "title": "Heavy Water Reactors"}
{"qas": [{"question": "How does the Sudbury Neutrino Observatory work?", "answer": ""}, {"question": "How much heavy water is used to detect cherenkov radiation?", "answer": "1,000 tonnes", "ae_score": null, "qg_score": null}, {"question": "How much heavy water is used to detect cherenkov radiation?", "answer": "1,000 tonnes", "ae_score": null, "qg_score": null}], "content": "The Sudbury Neutrino Observatory (SNO) in Sudbury, Ontario used 1,000 tonnes of heavy water on loan from Atomic Energy of Canada Limited. The neutrino detector is 6800 ft underground in a mine, to shield it from muons produced by cosmic rays. SNO was built to answer the question of whether or not electron-type neutrinos produced by fusion in the Sun (the only type the Sun should be producing directly, according to theory) might be able to turn into other types of neutrinos on the way to Earth. SNO detects the Cherenkov radiation in the water from high-energy electrons produced from electron-type neutrinos as they undergo charged current (CC) interactions with neutrons in deuterium, turning them into protons and electrons (however, only the electrons are fast enough to produce Cherenkov radiation for detection). SNO also detects neutrino\u2194electron scattering (ES) events, where the neutrino transfers energy to the electron, which then proceeds to generate Cherenkov radiation distinguishable from that produced by CC events. The first of these two reactions is produced only by electron-type neutrinos, while the second can be caused by all of the neutrino flavors. The use of deuterium is critical to the SNO function, because all three \"flavours\" (types) of neutrinos may be detected in a third type of reaction as well, neutrino-disintegration, in which a neutrino of any type (electron, muon, or tau) scatters from a deuterium nucleus (deuteron), transferring enough energy to break up the loosely bound deuteron into a free neutron and proton via a neutral current (NC) interaction. This event is detected when the free neutron is absorbed by Cl present from NaCl deliberately dissolved in the heavy water, causing emission of characteristic capture gamma rays. Thus, in this experiment, heavy water not only provides the transparent medium necessary to produce and visualize Cherenkov radiation, but it also provides deuterium to detect exotic mu type (\u03bc) and tau (\u03c4) neutrinos, as well as a non-absorbent moderator medium to preserve free neutrons from this reaction, until they can be absorbed by an easily detected neutron-activated isotope.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Neutrino detector", "_id": "106--6--4---1", "title": "The Sudbury Neutrino Observatory (SNO)"}
{"qas": [{"question": "Why is heavy water used to measure metabolic rate?", "answer": ""}, {"question": "What is the metabolic test in heavy water?", "answer": "doubly labeled water test", "ae_score": -0.22528604194442192, "qg_score": null}, {"question": "What is the metabolic test in heavy water?", "answer": "doubly labeled water test", "ae_score": -0.22528604194442192, "qg_score": null}], "content": "Heavy water is employed as part of a mixture with HO for a common and safe test of mean metabolic rate in humans and animals undergoing their normal activities. This metabolic test is usually called the doubly labeled water test.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Metabolic rate testing in physiology/biology", "_id": "106--6--5---1", "title": "Heavy water | Applications | Metabolic rate testing in physiology/biology"}
{"qas": [{"question": "Why does deuterium have a higher concentration of neutrons than oxygen?", "answer": ""}, {"question": "What is the active substance in heavy water moderated reactors?", "answer": "Tritium", "ae_score": -0.38561966932829644, "qg_score": null}, {"question": "What is the active substance in heavy water moderated reactors?", "answer": "Tritium", "ae_score": -0.38561966932829644, "qg_score": null}], "content": "Tritium is the active substance in self-powered lighting and controlled nuclear fusion, its other uses including autoradiography and radioactive labeling. It is also used in nuclear weapon design for boosted fission weapons and initiators. Some tritium is created in heavy water moderated reactors when deuterium captures a neutron. This reaction has a small cross-section (probability of a single neutron-capture event) and produces only small amounts of tritium, although enough to justify cleaning tritium from the moderator every few years to reduce the environmental risk of tritium escape.\nProducing a lot of tritium in this way would require reactors with very high neutron fluxes, or with a very high proportion of heavy water to nuclear fuel and very low neutron absorption by other reactor material. The tritium would then have to be recovered by isotope separation from a much larger quantity of deuterium, unlike production from lithium-6 (the present method), where only chemical separation is needed.\nDeuterium's absorption cross section for thermal neutrons is 0.52 millibarns (barn=10 m, milli=1/1000), while oxygen-16's is 0.19 millibarns and oxygen-17's is 0.24 barns. O makes up 0.038% of natural oxygen, making the overall cross section 0.28 millibarns. Therefore, in DO with natural oxygen, 21% of neutron captures are on oxygen, rising higher as O builds up from neutron capture on O. Also, O may emit an alpha particle on neutron capture, producing radioactive carbon-14.", "page_name": "Heavy water", "page_id": "Heavy%20water", "heading": "Applications", "sub_heading": "Tritium production", "_id": "106--6--6---1", "title": "Tritium in Nuclear Weapon Design"}
{"qas": [{"question": "Why is the immune system so much more advanced than it was 20 years ago?", "answer": ""}, {"question": "When was the earliest known mention of immunity?", "answer": "430 BCE", "ae_score": -0.536106338403931, "qg_score": null}, {"question": "When was the earliest known mention of immunity?", "answer": "430 BCE", "ae_score": -0.536106338403931, "qg_score": null}], "content": "Classical immunology ties in with the fields of epidemiology and medicine. It studies the relationship between the body systems, pathogens, and immunity. The earliest written mention of immunity can be traced back to the plague of Athens in 430 BCE. Thucydides noted that people who had recovered from a previous bout of the disease could nurse the sick without contracting the illness a second time. Many other ancient societies have references to this phenomenon, but it was not until the 19th and 20th centuries before the concept developed into scientific theory.\nThe study of the molecular and cellular components that comprise the immune system, including their function and interaction, is the central science of immunology. The immune system has been divided into a more primitive innate immune system and, in vertebrates, an acquired or adaptive immune system. The latter is further divided into humoral (or antibody) and cell-mediated components.\nThe humoral (antibody) response is defined as the interaction between antibodies and antigens. Antibodies are specific proteins released from a certain class of immune cells known as B lymphocytes, while antigens are defined as anything that elicits the generation of antibodies (\"anti\"body \"gen\"erators). Immunology rests on an understanding of the properties of these two biological entities and the cellular response to both.\nImmunological research continues to become more specialized, pursuing non-classical models of immunity and functions of cells, organs and systems not previously associated with the immune system (Yemeserach 2010).", "page_name": "Immunology", "page_id": "Immunology", "heading": "Classical immunology", "sub_heading": "Classical immunology", "_id": "107--0---1---1", "title": "Immunology \u2014 The Evolution of Immunology"}
{"qas": [{"question": "Why are there so many diseases caused by the immune system?", "answer": ""}, {"question": "What is the most well-known disease affecting the immune system?", "answer": "AIDS", "ae_score": -0.15967760521889812, "qg_score": null}, {"question": "What is the most well-known disease affecting the immune system?", "answer": "AIDS", "ae_score": -0.15967760521889812, "qg_score": null}], "content": "Clinical immunology is the study of diseases caused by disorders of the immune system (failure, aberrant action, and malignant growth of the cellular elements of the system). It also involves diseases of other systems, where immune reactions play a part in the pathology and clinical features.\nThe diseases caused by disorders of the immune system fall into two broad categories:\nOther immune system disorders include various hypersensitivities (such as in asthma and other allergies) that respond inappropriately to otherwise harmless compounds.\nThe most well-known disease that affects the immune system itself is AIDS, an immunodeficiency characterized by the suppression of CD4+ (\"helper\") T cells, dendritic cells and macrophages by the Human Immunodeficiency Virus (HIV).\nClinical immunologists also study ways to prevent the immune system's attempts to destroy allografts (transplant rejection).", "page_name": "Immunology", "page_id": "Immunology", "heading": "Clinical immunology", "sub_heading": "Clinical immunology", "_id": "107--1---1---1", "title": "Clinical Immunology: The study of diseases caused by disorders of the immune system (fail"}
{"qas": [{"question": "Why is it that when a child is exposed to a vaccine, they are not immune to it until a few months later?", "answer": ""}, {"question": "Physical changes during puberty are known as what?", "answer": "thymic involution", "ae_score": -0.298281426801014, "qg_score": null}, {"question": "Physical changes during puberty are known as what?", "answer": "thymic involution", "ae_score": -0.298281426801014, "qg_score": null}], "content": "The body\u2019s capability to react to antigen depends on a person's age, antigen type, maternal factors and the area where the antigen is presented. Neonates are said to be in a state of physiological immunodeficiency, because both their innate and adaptive immunological responses are greatly suppressed.  Once born, a child\u2019s immune system responds favorably to protein antigens while not as well to glycoproteins and polysaccharides. In fact, many of the infections acquired by neonates are caused by low virulence organisms like ''Staphylococcus'' and ''Pseudomonas''.  In neonates, opsonic activity and the ability to activate the complement cascade is very limited.  For example, the mean level of C3 in a newborn is approximately 65% of that found in the adult. Phagocytic activity is also greatly impaired in newborns. This is due to lower opsonic activity, as well as diminished up-regulation of integrin and selectin receptors, which limit the ability of neutrophils to interact with adhesion molecules in the endothelium. Their monocytes are slow and have a reduced ATP production, which also limits the newborn's phagocytic activity.  Although, the number of total lymphocytes is significantly higher than in adults, the cellular and humoral immunity is also impaired. Antigen-presenting cells in newborns have a reduced capability to activate T cells.  Also, T cells of a newborn proliferate poorly and produce very small amounts of cytokines like IL-2, IL-4, IL-5, IL-12, and IFN-g which limits their capacity to activate the humoral response as well as the phagocitic activity of macrophage.  B cells develop early during gestation but are not fully active.\nMaternal factors also play a role in the body\u2019s immune response.  At birth, most of the immunoglobulin present is maternal IgG. Because IgM, IgD, IgE and IgA don\u2019t cross the placenta, they are almost undetectable at birth. Some IgA is provided by breast milk. These passively-acquired antibodies can protect the newborn for up to 18 months, but their response is usually short-lived and of low affinity.  These antibodies can also produce a negative response.  If a child is exposed to the antibody for a particular antigen before being exposed to the antigen itself then the child will produce a dampened response. Passively acquired maternal antibodies can suppress the antibody response to active immunization. Similarly the response of T-cells to vaccination differs in children compared to adults, and vaccines that induce Th1 responses in adults do not readily elicit these same responses in neonates. Between six and nine months after birth, a child\u2019s immune system begins to respond more strongly to glycoproteins, but there is usually no marked improvement in their response to polysaccharides until they are at least one year old. This can be the reason for distinct time frames found in vaccination schedules.\nDuring adolescence, the human body undergoes various physical, physiological and immunological changes triggered and mediated by hormones, of which the most significant in females is 17-\u03b2-oestradiol (an oestrogen) and, in males, is testosterone. Oestradiol usually begins to act around the age of 10 and testosterone some months later. There is evidence that these steroids act directly not only on the primary and secondary sexual characteristics but also have an effect on the development and regulation of the immune system, including an increased risk in developing pubescent and post-pubescent autoimmunity. There is also some evidence that cell surface receptors on B cells and macrophages may detect sex hormones in the system.\nThe female sex hormone 17-\u03b2-oestradiol has been shown to regulate the level of immunological response, while some male androgens such as testosterone seem to suppress the stress response to infection. Other androgens, however, such as DHEA, increase immune response. As in females, the male sex hormones seem to have more control of the immune system during puberty and post-puberty than during the rest of a male's adult life.\nPhysical changes during puberty such as thymic involution also affect immunological response.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Developmental immunology", "sub_heading": "Developmental immunology", "_id": "107--2---1---1", "title": "The Immune Response of Neonates"}
{"qas": [{"question": "How does the immune system work?", "answer": ""}, {"question": "What is the medical term for the treatment of a disease or disorder?", "answer": "immunotherapy", "ae_score": -0.27250505619762605, "qg_score": null}, {"question": "What is the medical term for the treatment of a disease or disorder?", "answer": "immunotherapy", "ae_score": -0.27250505619762605, "qg_score": null}], "content": "The use of immune system components to treat a disease or disorder is known as immunotherapy. Immunotherapy is most commonly used in the context of the treatment of cancers together with chemotherapy (drugs) and radiotherapy (radiation). However, immunotherapy is also often used in the immunosuppressed (such as HIV patients) and people suffering from other immune deficiencies or autoimmune diseases.This includes regulating factors such as IL-2, IL-10, GM-CSF B, IFN-\u03b1.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Immunotherapy", "sub_heading": "Immunotherapy", "_id": "107--3---1---1", "title": "Immunotherapy \u2014 The Immunotherapy of the Immune System"}
{"qas": [{"question": "Antibodies and Antigens?", "answer": ""}, {"question": "What can the similarity between some antigens lead to?", "answer": "false positives", "ae_score": -1.382246619611342, "qg_score": null}, {"question": "What can the similarity between some antigens lead to?", "answer": "false positives", "ae_score": -1.382246619611342, "qg_score": null}], "content": "The specificity of the bond between antibody and antigen has made the antibody an excellent tool for the detection of substances by a variety of diagnostic techniques. Antibodies specific for a desired antigen can be conjugated with an isotopic (radio) or fluorescent label or with a color-forming enzyme in order to detect it. However, the similarity between some antigens can lead to false positives and other errors in such tests by antibodies cross-reacting with antigens that aren't exact matches.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Diagnostic immunology", "sub_heading": "Diagnostic immunology", "_id": "107--4---1---1", "title": "Antibodies and Antigens \u2014 An Introduction"}
{"qas": [{"question": "What is the purpose of the term \"in vitro fertilization\"?", "answer": ""}, {"question": "What is an example of a dangerous complication of pregnancy?", "answer": "pre-eclampsia", "ae_score": -0.6009282345584402, "qg_score": null}, {"question": "What is an example of a dangerous complication of pregnancy?", "answer": "pre-eclampsia", "ae_score": -0.6009282345584402, "qg_score": null}], "content": "This area of the immunology is devoted to the study of immunological aspects of the reproductive process including fetus acceptance. The term has also been used by fertility clinics to address fertility problems, recurrent miscarriages, premature deliveries and dangerous complications such as pre-eclampsia.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Reproductive immunology", "sub_heading": "Reproductive immunology", "_id": "107--6---1---1", "title": "Immunology \u2014 The Immunology of the Reproductive Process"}
{"qas": [{"question": "What is the difference between a \"cognitive immune system\" and a \"autopoietic immune system\"?", "answer": ""}, {"question": "Who represented the cellular theory of immunity?", "answer": "Elie Metchnikoff", "ae_score": -0.5352506657031179, "qg_score": null}, {"question": "Who represented the cellular theory of immunity?", "answer": "Elie Metchnikoff", "ae_score": -0.5352506657031179, "qg_score": null}], "content": "Immunology is strongly experimental in everyday practice but is also characterized by an ongoing theoretical attitude. Many theories have been suggested in immunology from the end of the nineteenth century up to the present time. The end of the 19th century and the beginning of the 20th century saw a battle between \"cellular\" and \"humoral\" theories of immunity. According to the cellular theory of immunity, represented in particular by Elie Metchnikoff, it was cells \u2013 more precisely, phagocytes \u2013 that were responsible for immune responses. In contrast, the humoral theory of immunity, held, among others, by Robert Koch and Emil von Behring, stated that the active immune agents were soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells.\nIn the mid-1950s, Frank Burnet, inspired by a suggestion made by Niels Jerne, formulated the clonal selection theory (CST) of immunity. On the basis of CST, Burnet developed a theory of how an immune response is triggered according to the self/nonself distinction: \"self\" constituents (constituents of the body) do not trigger destructive immune responses, while \"nonself\" entities (e.g., pathogens, an allograft) trigger a destructive immune response. The theory was later modified to reflect new discoveries regarding histocompatibility or the complex \"two-signal\" activation of T cells. The self/nonself theory of immunity and the self/nonself vocabulary have been criticized, but remain very influential.\nMore recently, several theoretical frameworks have been suggested in immunology, including \"autopoietic\" views, \"cognitive immune\" views, the \"danger model\" (or \"danger theory\",  and the \"discontinuity\" theory. The danger model, suggested by Polly Matzinger and colleagues, has been very influential, arousing many comments and discussions.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Theoretical immunology", "sub_heading": "Theoretical immunology", "_id": "107--7---1---1", "title": "Immunology | Theoretical immunology"}
{"qas": [{"question": "What is the difference between an introductory course and an advanced course?", "answer": ""}, {"question": "What is the name of the major in which undergraduate students interested in general well-being?", "answer": "Bioscience", "ae_score": -0.3127151129824246, "qg_score": null}, {"question": "What is the name of the major in which undergraduate students interested in general well-being?", "answer": "Bioscience", "ae_score": -0.3127151129824246, "qg_score": null}], "content": "According to the American Academy of Allergy, Asthma, and Immunology (AAAAI), \"an immunologist is a research scientist who investigates the immune system of vertebrates (including the human immune system). Immunologists include research scientists (PhDs) who work in laboratories. Immunologists also include physicians who, for example, treat patients with immune system disorders. Some immunologists are physician-scientists who combine laboratory research with patient care.\"\nBioscience is the overall major in which undergraduate students who are interested in general well-being take in college. Immunology is a branch of bioscience for undergraduate programs but the major gets specified as students move on for graduate program in immunology. The aim of immunology is to study the health of humans and animals through effective yet consistent research, (AAAAI, 2013). The most important thing about being immunologists is the research because it is the biggest portion of their jobs.\nMost graduate immunology schools follow the AAI courses immunology which are offered throughout numerous schools in the United States. For example, in New York State, there are several universities that offer the AAI courses immunology: Albany Medical College, Cornell University, Icahn School of Medicine at Mount Sinai, New York University Langone Medical Center, University at Albany (SUNY), University at Buffalo (SUNY), University of Rochester Medical Center and Upstate Medical University (SUNY). The AAI immunology courses include an Introductory Course and an Advance Course. The Introductory Course is a course that gives students an overview of the basics of immunology.\nIn addition, this Introductory Course gives students more information to complement general biology or science training. It also has two different parts: Part I is an introduction to the basic principles of immunology and Part II is a clinically-oriented lecture series. On the other hand, the Advanced Course is another course for those who are willing to expand or update their understanding of immunology. It is advised for students who want to attend the Advanced Course to have a background of the principles of immunology. Most schools require students to take electives in other to complete their degrees. A Master\u2019s degree requires two years of study following the attainment of a bachelor's degree. For a doctoral programme it is required to take two additional years of study.\nThe expectation of occupational growth in immunology is an increase of 36 percent from 2010 to 2020. The median annual wage was $76,700 in May 2010. However, the lowest 10 percent of immunologists earned less than $41,560, and the top 10 percent earned more than $142,800, (Bureau of Labor Statistics, 2013). The practice of immunology itself is not specified by the U.S. Department of Labor but it belongs to the practice of life science in general.", "page_name": "Immunology", "page_id": "Immunology", "heading": "Immunologist", "sub_heading": "Immunologist", "_id": "107--8---1---1", "title": "AAI Courses Immunology"}
{"qas": [{"question": "What is the difference between living things and living things?", "answer": ""}, {"question": "What are the complex processes that sustain life called?", "answer": "physiological functions", "ae_score": -0.18389440909244173, "qg_score": null}, {"question": "What are the complex processes that sustain life called?", "answer": "physiological functions", "ae_score": -0.18389440909244173, "qg_score": null}], "content": "Since there is no unequivocal definition of life, most current definitions in biology are descriptive. Life is considered a characteristic of something that exhibits all or most of the following traits:<ref name=McKay/>\nThese complex processes, called physiological functions, have underlying physical and chemical bases, as well as signaling and control mechanisms that are essential to maintaining life.\nFrom a physics perspective, living beings are thermodynamic systems with an organized molecular structure that can reproduce itself and evolve as survival dictates. Thermodynamically, life has been described as an open system which makes use of gradients in its surroundings to create imperfect copies of itself. Hence, life is a self-sustained chemical system capable of undergoing Darwinian evolution. A major strength of this definition is that it distinguishes life by the evolutionary process rather than its chemical composition.\nOthers take a systemic viewpoint that does not necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an autonomous agent or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.\nWhether or not viruses should be considered as alive is controversial. They are most often considered as just replicators rather than forms of life. They have been described as \"organisms at the edge of life\" because they possess genes, evolve by natural selection, and replicate by creating multiple copies of themselves through self-assembly. However, viruses do not metabolize and they require a host cell to make new products. Virus self-assembly within host cells has implications for the study of the origin of life, as it may support the hypothesis that life could have started as self-assembling organic molecules.", "page_name": "Life", "page_id": "Life", "heading": "Definitions", "sub_heading": "Definitions", "_id": "108--0--0---1", "title": "The Origins of Life"}
{"qas": [{"question": "What is life?", "answer": ""}, {"question": "What do physicists believe living things function on?", "answer": "negative entropy", "ae_score": -0.6858941186640694, "qg_score": null}, {"question": "What do physicists believe living things function on?", "answer": "negative entropy", "ae_score": -0.6858941186640694, "qg_score": null}], "content": "To reflect the minimum phenomena required, other biological definitions of life have been proposed, with many of these being based upon chemical systems. Biophysicists have commented that living things function on negative entropy. In other words, living processes can be viewed as a delay of the spontaneous diffusion or dispersion of the internal energy of biological molecules towards more potential microstates. In more detail, according to physicists such as John Bernal, Erwin Schr\u00f6dinger, Eugene Wigner, and John Avery, life is a member of the class of phenomena that are open or continuous systems able to decrease their internal entropy at the expense of substances or free energy taken in from the environment and subsequently rejected in a degraded form.", "page_name": "Life", "page_id": "Life", "heading": "Definitions", "sub_heading": "Biophysics", "_id": "108--0--1---1", "title": "Life: A Biophysical Definition of Life"}
{"qas": [{"question": "Where did the idea that the Earth is alive come from?", "answer": ""}, {"question": "What is the name of the fundamental principle that describes the evolution of order in living systems?", "answer": "Darwinian dynamic", "ae_score": -0.2675215154537538, "qg_score": null}, {"question": "What is the name of the fundamental principle that describes the evolution of order in living systems?", "answer": "Darwinian dynamic", "ae_score": -0.2675215154537538, "qg_score": null}], "content": "Living systems are open self-organizing living things that interact with their environment. These systems are maintained by flows of information, energy, and matter.\nSome scientists have proposed in the last few decades that a general living systems theory is required to explain the nature of life. Such a general theory would arise out of the ecological and biological sciences and attempt to map general principles for how all living systems work. Instead of examining phenomena by attempting to break things down into components, a general living systems theory explores phenomena in terms of dynamic patterns of the relationships of organisms with their environment.\nThe idea that the Earth is alive is found in philosophy and religion, but the first scientific discussion of it was by the Scottish scientist James Hutton. In 1785, he stated that the Earth was a superorganism and that its proper study should be physiology. Hutton is considered the father of geology, but his idea of a living Earth was forgotten in the intense reductionism of the 19th century. The Gaia hypothesis, proposed in the 1960s by scientist James Lovelock, suggests that life on Earth functions as a single organism that defines and maintains environmental conditions necessary for its survival. This hypothesis served as one of the foundations of the modern Earth system science.\nThe first attempt at a general living systems theory for explaining the nature of life was in 1978, by American biologist James Grier Miller. Robert Rosen (1991) built on this by defining a system component as \"a unit of organization; a part with a function, i.e., a definite relation between part and whole.\" From this and other starting concepts, he developed a \"relational theory of systems\" that attempts to explain the special properties of life. Specifically, he identified the \"nonfractionability of components in an organism\" as the fundamental difference between living systems and \"biological machines.\"\nA systems view of life treats environmental fluxes and biological fluxes together as a \"reciprocity of influence,\" and a reciprocal relation with environment is arguably as important for understanding life as it is for understanding ecosystems. As Harold J. Morowitz (1992) explains it, life is a property of an ecological system rather than a single organism or species. He argues that an ecosystemic definition of life is preferable to a strictly biochemical or physical one. Robert Ulanowicz (2009) highlights mutualism as the key to understand the systemic, order-generating behavior of life and ecosystems.\nComplex systems biology (CSB) is a field of science that studies the emergence of complexity in functional organisms from the viewpoint of dynamic systems theory. The latter is also often called systems biology and aims to understand the most fundamental aspects of life. A closely related approach to CSB and systems biology called relational biology is concerned mainly with understanding life processes in terms of the most important relations, and categories of such relations among the essential functional components of organisms; for multicellular organisms, this has been defined as \"categorical biology\", or a model representation of organisms as a category theory of biological relations, as well as an algebraic topology of the functional organization of living organisms in terms of their dynamic, complex networks of metabolic, genetic, and epigenetic processes and signaling pathways. Alternative but closely related approaches focus on the interdependance of constraints, where constraints can be either molecular, such as enzymes, or macroscopic, such as the geometry of a bone or of the vascular system.\nIt has also been argued that the evolution of order in living systems and certain physical systems obeys a common fundamental principle termed the Darwinian dynamic. The Darwinian dynamic was formulated by first considering how macroscopic order is generated in a simple non-biological system far from thermodynamic equilibrium, and then extending consideration to short, replicating RNA molecules. The underlying order-generating process was concluded to be basically similar for both types of systems.\nAnother systemic definition called the operator theory proposes that \"life is a general term for the presence of the typical closures found in organisms; the typical closures are a membrane and an autocatalytic set in the cell\" and that an organism is any system with an organisation that complies with an operator type that is at least as complex as the cell. Life can also be modeled as a network of inferior negative feedbacks of regulatory mechanisms subordinated to a superior positive feedback formed by the potential of expansion and reproduction.", "page_name": "Life", "page_id": "Life", "heading": "Definitions", "sub_heading": "Living systems theories", "_id": "108--0--2---1", "title": "The Evolution of Life: A General Living Systems Theory"}
{"qas": [{"question": "What is the origin of life?", "answer": ""}, {"question": "Who revived the mechanistic materialism that originated in ancient greece?", "answer": "Ren\u00e9 Descartes", "ae_score": -0.3199020225116059, "qg_score": null}, {"question": "Who revived the mechanistic materialism that originated in ancient greece?", "answer": "Ren\u00e9 Descartes", "ae_score": -0.3199020225116059, "qg_score": null}], "content": "Some of the earliest theories of life were materialist, holding that all that exists is matter, and that life is merely a complex form or arrangement of matter. Empedocles (430 BC) argued that everything in the universe is made up of a combination of four eternal \"elements\" or \"roots of all\": earth, water, air, and fire. All change is explained by the arrangement and rearrangement of these four elements. The various forms of life are caused by an appropriate mixture of elements.\nDemocritus (460 BC) thought that the essential characteristic of life is having a soul (''psyche''). Like other ancient writers, he was attempting to explain what makes something a ''living'' thing. His explanation was that fiery atoms make a soul in exactly the same way atoms and void account for any other thing. He elaborates on fire because of the apparent connection between life and heat, and because fire moves.\nThe mechanistic materialism that originated in ancient Greece was revived and revised by the French philosopher Ren\u00e9 Descartes, who held that animals and humans were assemblages of parts that together functioned as a machine. In the 19th century, the advances in cell theory in biological science encouraged this view. The evolutionary theory of Charles Darwin (1859) is a mechanistic explanation for the origin of species by means of natural selection.", "page_name": "Life", "page_id": "Life", "heading": "History of study", "sub_heading": "History of study", "_id": "108--1--0---1", "title": "The Evolution of Life"}
{"qas": [{"question": "Why is the polar bear's coat white?", "answer": ""}, {"question": "Who believed that all living things are made of matter and form?", "answer": "Aristotle", "ae_score": -0.3453507186450454, "qg_score": null}, {"question": "Who believed that all living things are made of matter and form?", "answer": "Aristotle", "ae_score": -0.3453507186450454, "qg_score": null}], "content": "Hylomorphism is a theory first expressed by the Greek philosopher Aristotle (322 BC). The application of hylomorphism to biology was important to Aristotle, and biology is extensively covered in his extant writings. In this view, everything in the material universe has both matter and form, and the form of a living thing is its soul (Greek ''psyche'', Latin ''anima''). There are three kinds of souls: the ''vegetative soul'' of plants, which causes them to grow and decay and nourish themselves, but does not cause motion and sensation; the ''animal soul'', which causes animals to move and feel; and the ''rational soul'', which is the source of consciousness and reasoning, which (Aristotle believed) is found only in man. Each higher soul has all of the attributes of the lower ones. Aristotle believed that while matter can exist without form, form cannot exist without matter, and that therefore the soul cannot exist without the body.\nThis account is consistent with teleological explanations of life, which account for phenomena in terms of purpose or goal-directedness. Thus, the whiteness of the polar bear's coat is explained by its purpose of camouflage. The direction of causality (from the future to the past) is in contradiction with the scientific evidence for natural selection, which explains the consequence in terms of a prior cause. Biological features are explained not by looking at future optimal results, but by looking at the past evolutionary history of a species, which led to the natural selection of the features in question.", "page_name": "Life", "page_id": "Life", "heading": "History of study", "sub_heading": "Hylomorphism", "_id": "108--1--1---1", "title": "Aristotle's Hylomorphism and the Evolution of Life"}
{"qas": [{"question": "What is spontaneous generation?", "answer": ""}, {"question": "Who proposed the theory of spontaneous generation?", "answer": "Aristotle", "ae_score": -0.2245103343530237, "qg_score": null}, {"question": "Who proposed the theory of spontaneous generation?", "answer": "Aristotle", "ae_score": -0.2245103343530237, "qg_score": null}], "content": "Spontaneous generation was the belief on the ordinary formation of living organisms without descent from similar organisms. Typically, the idea was that certain forms such as fleas could arise from inanimate matter such as dust or the supposed seasonal generation of mice and insects from mud or garbage.\nThe theory of spontaneous generation was proposed by Aristotle, who compiled and expanded the work of prior natural philosophers and the various ancient explanations of the appearance of organisms; it held sway for two millennia. It was decisively dispelled by the experiments of Louis Pasteur in 1859, who expanded upon the investigations of predecessors such as Francesco Redi. Disproof of the traditional ideas of spontaneous generation is no longer controversial among biologists.", "page_name": "Life", "page_id": "Life", "heading": "History of study", "sub_heading": "Spontaneous generation", "_id": "108--1--2---1", "title": "The Theory of Spontaneous Generation"}
{"qas": [{"question": "What is Vitalism?", "answer": ""}, {"question": "What is the belief that the life principle is non-material?", "answer": "Vitalism", "ae_score": -0.505387269057587, "qg_score": null}, {"question": "What is the belief that the life principle is non-material?", "answer": "Vitalism", "ae_score": -0.505387269057587, "qg_score": null}], "content": "Vitalism is the belief that the life-principle is non-material. This originated with Georg Ernst Stahl (17th century), and remained popular until the middle of the 19th century. It appealed to philosophers such as Henri Bergson, Friedrich Nietzsche, and Wilhelm Dilthey, anatomists like Marie Fran\u00e7ois Xavier Bichat, and chemists like Justus von Liebig. Vitalism included the idea that there was a fundamental difference between organic and inorganic material, and the belief that organic material can only be derived from living things. This was disproved in 1828, when Friedrich W\u00f6hler prepared urea from inorganic materials. This W\u00f6hler synthesis is considered the starting point of modern organic chemistry. It is of historical significance because for the first time an organic compound was produced in inorganic reactions.<ref name=Wilkinson/>\nDuring the 1850s, Hermann von Helmholtz, anticipated by Julius Robert von Mayer, demonstrated that no energy is lost in muscle movement, suggesting that there were no \"vital forces\" necessary to move a muscle. These results led to the abandonment of scientific interest in vitalistic theories, although the belief lingered on in pseudoscientific theories such as homeopathy, which interprets diseases and sickness as caused by disturbances in a hypothetical vital force or life force.", "page_name": "Life", "page_id": "Life", "heading": "History of study", "sub_heading": "Vitalism", "_id": "108--1--3---1", "title": "Vitalism \u2014 A History of Life-Principles"}
{"qas": [{"question": "How do we know that genes and proteins came from the same egg?", "answer": ""}, {"question": "Who performed the experiment that demonstrated darwinian evolution?", "answer": "Gerald Joyce", "ae_score": -0.16243980937912858, "qg_score": null}, {"question": "Who performed the experiment that demonstrated darwinian evolution?", "answer": "Gerald Joyce", "ae_score": -0.16243980937912858, "qg_score": null}], "content": "The age of the Earth is about 4.54 billion years. Evidence suggests that life on Earth has existed for at least 3.5 billion years, with the oldest physical traces of life dating back 3.7 billion years; however, some theories, such as the Late Heavy Bombardment theory, suggest that life on Earth may have started even earlier, as early as 4.1\u20134.4 billion years ago, and the chemistry leading to life may have begun shortly after the Big Bang, 13.8 billion years ago, during an epoch when the universe was only 10\u201317 million years old. All known life forms share fundamental molecular mechanisms, reflecting their common descent; based on these observations, hypotheses on the origin of life attempt to find a mechanism explaining the formation of a universal common ancestor, from simple organic molecules via pre-cellular life to protocells and metabolism. Models have been divided into \"genes-first\" and \"metabolism-first\" categories, but a recent trend is the emergence of hybrid models that combine both categories.\nThere is no current scientific consensus as to how life originated. However, most accepted scientific models build on the Miller\u2013Urey experiment and the work of Sidney Fox, which show that conditions on the primitive Earth favored chemical reactions that synthesize amino acids and other organic compounds from inorganic precursors, and phospholipids spontaneously form lipid bilayers, the basic structure of a cell membrane.\nLiving organisms synthesize proteins, which are polymers of amino acids using instructions encoded by deoxyribonucleic acid (DNA). Protein synthesis entails intermediary ribonucleic acid (RNA) polymers. One possibility for how life began is that genes originated first, followed by proteins; the alternative being that proteins came first and then genes.\nHowever, because genes and proteins are both required to produce the other, the problem of considering which came first is like that of the chicken or the egg. Most scientists have adopted the hypothesis that because of this, it is unlikely that genes and proteins arose independently.\nTherefore, a possibility, first suggested by Francis Crick, is that the first life was based on RNA, which has the DNA-like properties of information storage and the catalytic properties of some proteins. This is called the RNA world hypothesis, and it is supported by the observation that many of the most critical components of cells (those that evolve the slowest) are composed mostly or entirely of RNA. Also, many critical cofactors (ATP, Acetyl-CoA, NADH, etc.) are either nucleotides or substances clearly related to them. The catalytic properties of RNA had not yet been demonstrated when the hypothesis was first proposed, but they were confirmed by Thomas Cech in 1986.\nOne issue with the RNA world hypothesis is that synthesis of RNA from simple inorganic precursors is more difficult than for other organic molecules. One reason for this is that RNA precursors are very stable and react with each other very slowly under ambient conditions, and it has also been proposed that living organisms consisted of other molecules before RNA. However, the successful synthesis of certain RNA molecules under the conditions that existed prior to life on Earth has been achieved by adding alternative precursors in a specified order with the precursor phosphate present throughout the reaction. This study makes the RNA world hypothesis more plausible.\nGeological findings in 2013 showed that reactive phosphorus species (like phosphite) were in abundance in the ocean before 3.5 Ga, and that Schreibersite easily reacts with aqueous glycerol to generate phosphite and glycerol 3-phosphate. It is hypothesized that Schreibersite-containing meteorites from the Late Heavy Bombardment could have provided early reduced phosphorus, which could react with prebiotic organic molecules to form phosphorylated biomolecules, like RNA.<ref name=Pasek/>\nIn 2009, experiments demonstrated Darwinian evolution of a two-component system of RNA enzymes (ribozymes) ''in vitro''. The work was performed in the laboratory of Gerald Joyce, who stated \"This is the first example, outside of biology, of evolutionary adaptation in a molecular genetic system.\"\nPrebiotic compounds may have originated extraterrestrially. NASA findings in 2011, based on studies with meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules) may be formed in outer space.\nIn March 2015, NASA scientists reported that, for the first time, complex DNA and RNA organic compounds of life, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the Universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.\nAccording to the panspermia hypothesis, microscopic life\u2014distributed by meteoroids, asteroids and other small Solar System bodies\u2014may exist throughout the universe.", "page_name": "Life", "page_id": "Life", "heading": "Origin", "sub_heading": "Origin", "_id": "108--2---1---1", "title": "The Origins of Life"}
{"qas": [{"question": "What is the biosphere?", "answer": ""}, {"question": "What is the name of the global sum of all ecosystems?", "answer": "The biosphere", "ae_score": -0.6358401757960148, "qg_score": null}, {"question": "What is the name of the global sum of all ecosystems?", "answer": "The biosphere", "ae_score": -0.6358401757960148, "qg_score": null}], "content": "The biosphere is the global sum of all ecosystems. It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior of the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere. The biosphere is postulated to have evolved, beginning with a process of biopoesis (life created naturally from non-living matter, such as simple organic compounds) or biogenesis (life created from living matter), at least some 3.5 billion years ago. The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, \"remains of biotic life\" were found in 4.1 billion-year-old rocks in Western Australia. According to one of the researchers, \"If life arose relatively quickly on Earth ... then it could be common in the universe.\"\nIn a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.", "page_name": "Life", "page_id": "Life", "heading": "Environmental conditions", "sub_heading": "Environmental conditions", "_id": "108--3--0---1", "title": "The Biosphere: The Zone of Life on Earth"}
{"qas": [{"question": "Why are there so many different types of organisms in the same ecosystem?", "answer": ""}, {"question": "What is the term for the range of conditions organisms can survive in an ecosystem?", "answer": "range of tolerance", "ae_score": -0.6794922866526603, "qg_score": null}, {"question": "What is the term for the range of conditions organisms can survive in an ecosystem?", "answer": "range of tolerance", "ae_score": -0.6794922866526603, "qg_score": null}], "content": "The inert components of an ecosystem are the physical and chemical factors necessary for life \u2014 energy (sunlight or chemical energy), water, temperature, atmosphere, gravity, nutrients, and ultraviolet solar radiation protection. In most ecosystems, the conditions vary during the day and from one season to the next. To live in most ecosystems, then, organisms must be able to survive a range of conditions, called the \"range of tolerance.\" Outside that are the \"zones of physiological stress,\" where the survival and reproduction are possible but not optimal. Beyond these zones are the \"zones of intolerance,\" where survival and reproduction of that organism is unlikely or impossible. Organisms that have a wide range of tolerance are more widely distributed than organisms with a narrow range of tolerance.<ref name=tolerance/>", "page_name": "Life", "page_id": "Life", "heading": "Environmental conditions", "sub_heading": "Range of tolerance", "_id": "108--3--1---1", "title": "Life | Environmental conditions | Range of tolerance"}
{"qas": [{"question": "Why is it so important for scientists to find extraterrestrial life?", "answer": ""}, {"question": "How long could lichen survive in a simulated martian environment?", "answer": "a month", "ae_score": -0.5945769876603484, "qg_score": null}, {"question": "How long could lichen survive in a simulated martian environment?", "answer": "a month", "ae_score": -0.5945769876603484, "qg_score": null}], "content": "To survive, selected microorganisms can assume forms that enable them to withstand freezing, complete desiccation, starvation, high levels of radiation exposure, and other physical or chemical challenges. These microorganisms may survive exposure to such conditions for weeks, months, years, or even centuries.<ref name= astrobiology/> Extremophiles are microbial life forms that thrive outside the ranges where life is commonly found. They excel at exploiting uncommon sources of energy. While all organisms are composed of nearly identical molecules, evolution has enabled such microbes to cope with this wide range of physical and chemical conditions. Characterization of the structure and metabolic diversity of microbial communities in such extreme environments is ongoing.\nMicrobial life forms thrive even in the Mariana Trench, the deepest spot on the Earth. Microbes also thrive inside rocks up to 1900 feet below the sea floor under 8500 feet of ocean.\nInvestigation of the tenacity and versatility of life on Earth, as well as an understanding of the molecular systems that some organisms utilize to survive such extremes, is important for the search for life beyond Earth.<ref name=astrobiology/> For example, lichen could survive for a month in a simulated Martian environment.", "page_name": "Life", "page_id": "Life", "heading": "Environmental conditions", "sub_heading": "Extremophiles", "_id": "108--3--2---1", "title": "Extremophiles \u2014 Life beyond Earth"}
{"qas": [{"question": "What is the most biologically abundant element in life?", "answer": ""}, {"question": "Which molecule carries most of the genetic instructions used in the growth, development, functioning and?", "answer": "Deoxyribonucleic acid", "ae_score": -0.22353460024184268, "qg_score": null}, {"question": "Which molecule carries most of the genetic instructions used in the growth, development, functioning and?", "answer": "Deoxyribonucleic acid", "ae_score": -0.22353460024184268, "qg_score": null}], "content": "All life forms require certain core chemical elements needed for biochemical functioning. These include carbon, hydrogen, nitrogen, oxygen, phosphorus, and sulfur\u2014the elemental macronutrients for all organisms\u2014often represented by the acronym CHNOPS. Together these make up nucleic acids, proteins and lipids, the bulk of living matter. Five of these six elements comprise the chemical components of DNA, the exception being sulfur. The latter is a component of the amino acids cysteine and methionine. The most biologically abundant of these elements is carbon, which has the desirable attribute of forming multiple, stable covalent bonds. This allows carbon-based (organic) molecules to form an immense variety of chemical arrangements. Alternative hypothetical types of biochemistry have been proposed that eliminate one or more of these elements, swap out an element for one not on the list, or change required chiralities or other chemical properties.\nDeoxyribonucleic acid is a molecule that carries most of the genetic instructions used in the growth, development, functioning and reproduction of all known living organisms and many viruses. DNA and RNA are nucleic acid\ns; alongside proteins and complex carbohydrates, they are one of the three major types of macromolecule that are essential for all known forms of life. Most DNA molecules consist of two biopolymer strands coiled around each other to form a double helix. The two DNA strands are known as polynucleotides since they are composed of simpler units called nucleotides. Each nucleotide is composed of a nitrogen-containing nucleobase\u2014either cytosine (C), guanine (G), adenine (A), or thymine (T)\u2014as well as a sugar called deoxyribose and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. According to base pairing rules (A with T, and C with G), hydrogen bonds bind the nitrogenous bases of the two separate polynucleotide strands to make double-stranded DNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 10, and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).\nDNA stores biological information. The DNA backbone is resistant to cleavage, and both strands of the double-stranded structure store the same biological information. Biological information is replicated as the two strands are separated. A significant portion of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences.\nThe two strands of DNA run in opposite directions to each other and are therefore anti-parallel. Attached to each sugar is one of four types of nucleobases (informally, ''bases''). It is the sequence of these four nucleobases along the backbone that encodes biological information. Under the genetic code, RNA strands are translated to specify the sequence of amino acids within proteins. These RNA strands are initially created using DNA strands as a template in a process called transcription.\nWithin eukaryotic cells, DNA is organized into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the eukaryotic chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.\nDNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was identified by James Watson and Francis Crick in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Rosalind Franklin.", "page_name": "Life", "page_id": "Life", "heading": "Environmental conditions", "sub_heading": "Chemical elements", "_id": "108--3--3---1", "title": "Molecular Biology of the Human Genome"}
{"qas": [{"question": "What is the difference between a single cell organism and a multicellular organism?", "answer": ""}, {"question": "What regulates the basic functions of all living things?", "answer": "Cell signaling", "ae_score": -0.19379577810894372, "qg_score": null}, {"question": "What regulates the basic functions of all living things?", "answer": "Cell signaling", "ae_score": -0.19379577810894372, "qg_score": null}], "content": "Cells are the basic unit of structure in every living thing, and all cells arise from pre-existing cells by division. Cell theory was formulated by Henri Dutrochet, Theodor Schwann, Rudolf Virchow and others during the early nineteenth century, and subsequently became widely accepted. The activity of an organism depends on the total activity of its cells, with energy flow occurring within and between them. Cells contain hereditary information that is carried forward as a genetic code during cell division.\nThere are two primary types of cells. Prokaryotes lack a nucleus and other membrane-bound organelles, although they have circular DNA and ribosomes. Bacteria and Archaea are two domains of prokaryotes. The other primary type of cells are the eukaryotes, which have distinct nuclei bound by a nuclear membrane and membrane-bound organelles, including mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, and vacuoles. In addition, they possess organized chromosomes that store genetic material. All species of large complex organisms are eukaryotes, including animals, plants and fungi, though most species of eukaryote are protist microorganisms. The conventional model is that eukaryotes evolved from prokaryotes, with the main organelles of the eukaryotes forming through endosymbiosis between bacteria and the progenitor eukaryotic cell.\nThe molecular mechanisms of cell biology are based on proteins. Most of these are synthesized by the ribosomes through an enzyme-catalyzed process called protein biosynthesis. A sequence of amino acids is assembled and joined together based upon gene expression of the cell's nucleic acid. In eukaryotic cells, these proteins may then be transported and processed through the Golgi apparatus in preparation for dispatch to their destination.\nCells reproduce through a process of cell division in which the parent cell divides into two or more daughter cells. For prokaryotes, cell division occurs through a process of fission in which the DNA is replicated, then the two copies are attached to parts of the cell membrane. In eukaryotes, a more complex process of mitosis is followed. However, the end result is the same; the resulting cell copies are identical to each other and to the original cell (except for mutations), and both are capable of further division following an interphase period.\nMulticellular organisms may have first evolved through the formation of colonies like cells. These cells can form group organisms through cell adhesion. The individual members of a colony are capable of surviving on their own, whereas the members of a true multi-cellular organism have developed specializations, making them dependent on the remainder of the organism for survival. Such organisms are formed clonally or from a single germ cell that is capable of forming the various specialized cells that form the adult organism. This specialization allows multicellular organisms to exploit resources more efficiently than single cells. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule, called GK-PID, may have allowed organisms to go from a single cell organism to one of many cells.\nCells have evolved methods to perceive and respond to their microenvironment, thereby enhancing their adaptability. Cell signaling coordinates cellular activities, and hence governs the basic functions of multicellular organisms. Signaling between cells can occur through direct cell contact using juxtacrine signalling, or indirectly through the exchange of agents as in the endocrine system. In more complex organisms, coordination of activities can occur through a dedicated nervous system.", "page_name": "Life", "page_id": "Life", "heading": "Cells", "sub_heading": "Cells", "_id": "108--5---1---1", "title": "The Evolution of Multicellular Organisms"}
{"qas": [{"question": "The Drake Equation?", "answer": ""}, {"question": "What is the name of the region around another star that could support life in our solar?", "answer": "habitable zone", "ae_score": -0.6408291394586099, "qg_score": null}, {"question": "What is the name of the region around another star that could support life in our solar?", "answer": "habitable zone", "ae_score": -0.6408291394586099, "qg_score": null}], "content": "Though life is confirmed only on Earth, many think that extraterrestrial life is not only plausible, but probable or inevitable. Other planets and moons in the Solar System and other planetary systems are being examined for evidence of having once supported simple life, and projects such as SETI are trying to detect radio transmissions from possible alien civilizations. Other locations within the Solar System that may host microbial life include the subsurface of Mars, the upper atmosphere of Venus, and subsurface oceans on some of the moons of the giant planets.Beyond the Solar System, the region around another main-sequence star that could support Earth-like life on an Earth-like planet is known as the habitable zone. The inner and outer radii of this zone vary with the luminosity of the star, as does the time interval during which the zone survives. Stars more massive than the Sun have a larger habitable zone, but remain on the main sequence for a shorter time interval. Small red dwarfs have the opposite problem, with a smaller habitable zone that is subject to higher levels of magnetic activity and the effects of tidal locking from close orbits. Hence, stars in the intermediate mass range such as the Sun may have a greater likelihood for Earth-like life to develop. The location of the star within a galaxy may also affect the likelihood of life forming. Stars in regions with a greater abundance of heavier elements that can form planets, in combination with a low rate of potentially habitat-damaging supernova events, are predicted to have a higher probability of hosting planets with complex life. The variables of the Drake equation are used to discuss the conditions in planetary systems where civilization is most likely to exist. Use of the equation to predict the amount of extraterrestrial life, however, is difficult; because many of the variables are unknown, the equation functions as more of a mirror to what its user already thinks. As a result, the number of civilizations in the galaxy can be estimated as low as 9.1 x 10^-11 or as high as 156 million; for the calculations, see Drake equation.", "page_name": "Life", "page_id": "Life", "heading": "Extraterrestrial", "sub_heading": "Extraterrestrial", "_id": "108--6---1---1", "title": "The Drake Equation for Planetary Systems"}
{"qas": [{"question": "What is artificial life?", "answer": ""}, {"question": "What is the name of the new field of biotechnology that combines science and biological engineering?", "answer": "Synthetic biology", "ae_score": -0.423867754786994, "qg_score": null}, {"question": "What is the name of the new field of biotechnology that combines science and biological engineering?", "answer": "Synthetic biology", "ae_score": -0.423867754786994, "qg_score": null}], "content": "Artificial life is the simulation of any aspect of life, as through computers, robotics, or biochemistry. The study of artificial life imitates traditional biology by recreating some aspects of biological phenomena. Scientists study the logic of living systems by creating artificial environments\u2014seeking to understand the complex information processing that defines such systems. While life is, by definition, alive, artificial life is generally referred to as data confined to a digital environment and existence.\nSynthetic biology is a new area of biotechnology that combines science and biological engineering. The common goal is the design and construction of new biological functions and systems not found in nature. Synthetic biology includes the broad redefinition and expansion of biotechnology, with the ultimate goals of being able to design and build engineered biological systems that process information, manipulate chemicals, fabricate materials and structures, produce energy, provide food, and maintain and enhance human health and the environment.", "page_name": "Life", "page_id": "Life", "heading": "Artificial", "sub_heading": "Artificial", "_id": "108--7---1---1", "title": "Synthetic Biology \u2014 Synthetic Biology"}
{"qas": [{"question": "What is the difference between extinction and mass extinctions?", "answer": ""}, {"question": "What percentage of all the species that have ever lived are extinct?", "answer": "over 99%", "ae_score": -0.5200340359633526, "qg_score": null}, {"question": "What percentage of all the species that have ever lived are extinct?", "answer": "over 99%", "ae_score": -0.5200340359633526, "qg_score": null}], "content": "Death is the permanent termination of all vital functions or life processes in an organism or cell. It can occur as a result of an accident, medical conditions, biological interaction, malnutrition, poisoning, senescence, or suicide. After death, the remains of an organism re-enter the biogeochemical cycle. Organisms may be consumed by a predator or a scavenger and leftover organic material may then be further decomposed by detritivores, organisms that recycle detritus, returning it to the environment for reuse in the food chain.\nOne of the challenges in defining death is in distinguishing it from life. Death would seem to refer to either the moment life ends, or when the state that follows life begins.<ref name=define_death/> However, determining when death has occurred requires drawing precise conceptual boundaries between life and death. This is problematic, however, because there is little consensus over how to define life. The nature of death has for millennia been a central concern of the world's religious traditions and of philosophical inquiry. Many religions maintain faith in either a kind of afterlife or reincarnation for the soul, or resurrection of the body at a later date.\nExtinction is the process by which a group of taxa or species dies out, reducing biodiversity. The moment of extinction is generally considered the death of the last individual of that species. Because a species' potential range may be very large, determining this moment is difficult, and is usually done retrospectively after a period of apparent absence. Species become extinct when they are no longer able to survive in changing habitat or against superior competition. In Earth's history, over 99% of all the species that have ever lived are extinct; however, mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.\nFossils are the preserved remains or traces of animals, plants, and other organisms from the remote past. The totality of fossils, both discovered and undiscovered, and their placement in fossil-containing rock formations and sedimentary layers (strata) is known as the ''fossil record''. A preserved specimen is called a fossil if it is older than the arbitrary date of 10,000 years ago. Hence, fossils range in age from the youngest at the start of the Holocene Epoch to the oldest from the Archaean Eon, up to 3.4 billion years old.", "page_name": "Life", "page_id": "Life", "heading": "Death", "sub_heading": "Death", "_id": "108--8---1---1", "title": "The Nature of Death"}
{"qas": [{"question": "How do we know that fire doesn't escape through pores in a candle?", "answer": ""}, {"question": "What substance is thought to have increased the weight of nitroaereus when heated?", "answer": "antimony", "ae_score": -0.4221423332212951, "qg_score": null}, {"question": "What substance is thought to have increased the weight of nitroaereus when heated?", "answer": "antimony", "ae_score": -0.4221423332212951, "qg_score": null}], "content": "One of the first known experiments on the relationship between combustion and air was conducted by the 2nd century BCE Greek writer on mechanics, Philo of Byzantium. In his work ''Pneumatica'', Philo observed that inverting a vessel over a burning candle and surrounding the vessel's neck with water resulted in some water rising into the neck. Philo incorrectly surmised that parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass. Many centuries later Leonardo da Vinci built on Philo's work by observing that a portion of air is consumed during combustion and respiration.\nOxygen was discovered by the Polish alchemist Sendivogius, who considered it the philosopher's stone.\nIn the late 17th century, Robert Boyle proved that air is necessary for combustion. English chemist John Mayow (1641\u20131679) refined this work by showing that fire requires only a part of air that he called ''spiritus nitroaereus''. In one experiment, he found that placing either a mouse or a lit candle in a closed container over water caused the water to rise and replace one-fourteenth of the air's volume before extinguishing the subjects. From this he surmised that nitroaereus is consumed in both respiration and combustion.\nMayow observed that antimony increased in weight when heated, and inferred that the nitroaereus must have combined with it. He also thought that the lungs separate nitroaereus from air and pass it into the blood and that animal heat and muscle movement result from the reaction of nitroaereus with certain substances in the body. Accounts of these and other experiments and ideas were published in 1668 in his work ''Tractatus duo'' in the tract \"De respiratione\".", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "History", "sub_heading": "History", "_id": "109--0--0---1", "title": "Air and Combustion \u2014 Part 1"}
{"qas": [{"question": "How did we discover that wood is lighter than other combustible materials?", "answer": ""}, {"question": "What theory was the favored explanation of combustion and corrosion?", "answer": "phlogiston theory", "ae_score": -0.3186112380893032, "qg_score": null}, {"question": "What theory was the favored explanation of combustion and corrosion?", "answer": "phlogiston theory", "ae_score": -0.3186112380893032, "qg_score": null}], "content": "Robert Hooke, Ole Borch, Mikhail Lomonosov, and  all produced oxygen in experiments in the 17th and the 18th century but none of them recognized it as a chemical element. This may have been in part due to the prevalence of the philosophy of combustion and corrosion called the phlogiston theory, which was then the favored explanation of those processes.\nEstablished in 1667 by the German alchemist J. J. Becher, and modified by the chemist Georg Ernst Stahl by 1731, phlogiston theory stated that all combustible materials were made of two parts. One part, called phlogiston, was given off when the substance containing it was burned, while the dephlogisticated part was thought to be its true form, or calx.\nHighly combustible materials that leave little residue, such as wood or coal, were thought to be made mostly of phlogiston; non-combustible substances that corrode, such as iron, contained very little. Air did not play a role in phlogiston theory, nor were any initial quantitative experiments conducted to test the idea; instead, it was based on observations of what happens when something burns, that most common objects appear to become lighter and seem to lose something in the process. The fact that a substance like wood gains overall weight in burning was hidden by the buoyancy of the gaseous combustion products.\nThis theory, while it was on the right track, was unfortunately set up backwards. Rather than combustion or corrosion occurring as a result of the decomposition of phlogiston compounds into their base elements with the phlogiston being lost to the air, it is in fact the result of oxygen from the air combining with the base elements to produce oxides. Indeed, one of the first clues that the phlogiston theory was incorrect was that metals gain weight in rusting (when they were supposedly losing phlogiston).", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "History", "sub_heading": "Phlogiston theory", "_id": "109--0--1---1", "title": "The Phlogiston Theory of Combustion and Corrosion"}
{"qas": [{"question": "How did Charles Priestley discover a new gas?", "answer": ""}, {"question": "Who discovered the gas oxygen in 1771?", "answer": "Carl Wilhelm Scheele", "ae_score": -0.1873413252726606, "qg_score": null}, {"question": "Who discovered the gas oxygen in 1771?", "answer": "Carl Wilhelm Scheele", "ae_score": -0.1873413252726606, "qg_score": null}], "content": "Oxygen was first discovered by Swedish pharmacist Carl Wilhelm Scheele. He had produced oxygen gas by heating mercuric oxide and various nitrates in 1771\u20132. Scheele called the gas \"fire air\" because it was the only known supporter of combustion, and wrote an account of this discovery in a manuscript he titled ''Treatise on Air and Fire'', which he sent to his publisher in 1775. That document was published in 1777.\nIn the meantime, on August 1, 1774, an experiment conducted by the British clergyman Joseph Priestley focused sunlight on mercuric oxide (HgO) inside a glass tube, which liberated a gas he named \"dephlogisticated air\". He noted that candles burned brighter in the gas and that a mouse was more active and lived longer while breathing it. After breathing the gas himself, he wrote: \"The feeling of it to my lungs was not sensibly different from that of common air, but I fancied that my breast felt peculiarly light and easy for some time afterwards.\" Priestley published his findings in 1775 in a paper titled \"An Account of Further Discoveries in Air\" which was included in the second volume of his book titled ''Experiments and Observations on Different Kinds of Air''. Because he published his findings first, Priestley is usually given priority in the discovery.\nThe French chemist Antoine Laurent Lavoisier later claimed to have discovered the new substance independently. Priestley visited Lavoisier in October 1774 and told him about his experiment and how he liberated the new gas. Scheele also posted a letter to Lavoisier on September 30, 1774 that described his discovery of the previously unknown substance, but Lavoisier never acknowledged receiving it (a copy of the letter was found in Scheele's belongings after his death).", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "History", "sub_heading": "Discovery", "_id": "109--0--2---1", "title": "Oxygen: The First Gas Discovered in Europe"}
{"qas": [{"question": "Why does tin weigh less when heated in a closed container?", "answer": ""}, {"question": "When was the first chemical reaction of oxygen discovered?", "answer": "1774", "ae_score": -0.31234261061301594, "qg_score": null}, {"question": "When was the first chemical reaction of oxygen discovered?", "answer": "1774", "ae_score": -0.31234261061301594, "qg_score": null}], "content": "What Lavoisier did (although this was disputed at the time) was to conduct the first adequate quantitative experiments on oxidation and give the first correct explanation of how combustion works. He used these and similar experiments, all started in 1774, to discredit the phlogiston theory and to prove that the substance discovered by Priestley and Scheele was a chemical element.\nIn one experiment, Lavoisier observed that there was no overall increase in weight when tin and air were heated in a closed container. He noted that air rushed in when he opened the container, which indicated that part of the trapped air had been consumed. He also noted that the tin had increased in weight and that increase was the same as the weight of the air that rushed back in. This and other experiments on combustion were documented in his book ''Sur la combustion en g\u00e9n\u00e9ral'', which was published in 1777. In that work, he proved that air is a mixture of two gases; 'vital air', which is essential to combustion and respiration, and ''azote'' (Gk. ''\u1f04\u03b6\u03c9\u03c4\u03bf\u03bd'' \"lifeless\"), which did not support either. ''Azote'' later became ''nitrogen'' in English, although it has kept the name in French and several other European languages.\nLavoisier renamed 'vital air' to ''oxyg\u00e8ne'' in 1777 from the Greek roots ''\u1f40\u03be\u03cd\u03c2 (oxys)'' (acid, literally \"sharp\", from the taste of acids) and ''-\u03b3\u03b5\u03bd\u03ae\u03c2 (-gen\u0113s)'' (producer, literally begetter), because he mistakenly believed that oxygen was a constituent of all acids. Chemists (such as Sir Humphry Davy in 1812) eventually determined that Lavoisier was wrong in this regard (hydrogen forms the basis for acid chemistry), but by then the name was too well established.\n''Oxygen'' entered the English language despite opposition by English scientists and the fact that the Englishman Priestley had first isolated the gas and written about it. This is partly due to a poem praising the gas titled \"Oxygen\" in the popular book ''The Botanic Garden'' (1791) by Erasmus Darwin, grandfather of Charles Darwin.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "History", "sub_heading": "Lavoisier's contribution", "_id": "109--0--3---1", "title": "''Oxygen'' \u2014 Lavoisier"}
{"qas": [{"question": "Why is the global temperature dropping so rapidly?", "answer": ""}, {"question": "Who was the first chemist to produce liquid oxygen?", "answer": "James Dewar", "ae_score": -0.3064359040833462, "qg_score": null}, {"question": "Who was the first chemist to produce liquid oxygen?", "answer": "James Dewar", "ae_score": -0.3064359040833462, "qg_score": null}], "content": "John Dalton's original atomic hypothesis presumed that all elements were monatomic and that the atoms in compounds would normally have the simplest atomic ratios with respect to one another. For example, Dalton assumed that water's formula was HO, giving the atomic mass of oxygen was 8 times that of hydrogen, instead of the modern value of about 16. In 1805, Joseph Louis Gay-Lussac and Alexander von Humboldt showed that water is formed of two volumes of hydrogen and one volume of oxygen; and by 1811 Amedeo Avogadro had arrived at the correct interpretation of water's composition, based on what is now called Avogadro's law and the diatomic elemental molecules in those gases.\nBy the late 19th century scientists realized that air could be liquefied and its components isolated by compressing and cooling it. Using a cascade method, Swiss chemist and physicist Raoul Pierre Pictet evaporated liquid sulfur dioxide in order to liquefy carbon dioxide, which in turn was evaporated to cool oxygen gas enough to liquefy it. He sent a telegram on December 22, 1877 to the French Academy of Sciences in Paris announcing his discovery of liquid oxygen.  Just two days later, French physicist Louis Paul Cailletet announced his own method of liquefying molecular oxygen. Only a few drops of the liquid were produced in each case and no meaningful analysis could be conducted. Oxygen was liquified in a stable state for the first time on March 29, 1883 by Polish scientists from Jagiellonian University, Zygmunt Wr\u00f3blewski and Karol Olszewski.\nIn 1891 Scottish chemist James Dewar was able to produce enough liquid oxygen for study. The first commercially viable process for producing liquid oxygen was independently developed in 1895 by German engineer Carl von Linde and British engineer William Hampson. Both men lowered the temperature of air until it liquefied and then distilled the component gases by boiling them off one at a time and capturing them. Later, in 1901, oxyacetylene welding was demonstrated for the first time by burning a mixture of acetylene and compressed . This method of welding and cutting metal later became common.\nIn 1923, the American scientist Robert H. Goddard became the first person to develop a rocket engine that burned liquid fuel; the engine used gasoline for fuel and liquid oxygen as the oxidizer. Goddard successfully flew a small liquid-fueled rocket 56 m at 97 km/h on March 16, 1926 in Auburn, Massachusetts, US.\nOxygen levels in the atmosphere are trending slightly downward globally, possibly because of fossil-fuel burning.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "History", "sub_heading": "Later history", "_id": "109--0--4---1", "title": "The Origins of Oxygen in the 20th Century"}
{"qas": [{"question": "What is the difference between oxygen and oxygen?", "answer": ""}, {"question": "What is the molecular formula for oxygen?", "answer": "dioxygen", "ae_score": -0.10792734288252279, "qg_score": null}, {"question": "What is the molecular formula for oxygen?", "answer": "dioxygen", "ae_score": -0.10792734288252279, "qg_score": null}], "content": "At standard temperature and pressure, oxygen is a colorless, odorless, and tasteless gas with the molecular formula , referred to as dioxygen.\nAs ''dioxygen'', two oxygen atoms are chemically bound to each other. The bond can be variously described based on level of theory, but is reasonably and simply described as a covalent double bond that results from the filling of molecular orbitals formed from the atomic orbitals of the individual oxygen atoms, the filling of which results in a bond order of two. More specifically, the double bond is the result of sequential, low-to-high energy, or Aufbau, filling of orbitals, and the resulting cancellation of contributions from the 2s electrons, after sequential filling of the low \u03c3 and \u03c3 orbitals; \u03c3 overlap of the two atomic 2p orbitals that lie along the O-O molecular axis and  overlap of two pairs of atomic 2p orbitals perpendicular to the O-O molecular axis, and then cancellation of contributions from the remaining two of the six 2p electrons after their partial filling of the lowest  and  orbitals.\nThis combination of cancellations and \u03c3 and  overlaps results in dioxygen's double bond character and reactivity, and a triplet electronic ground state. An electron configuration with two unpaired electrons, as is found in dioxygen orbitals (see the filled * orbitals in the diagram) that are of equal energy\u2014i.e., degenerate\u2014is a configuration termed a spin triplet state. Hence, the ground state of the  molecule is referred to as triplet oxygen. The highest energy, partially filled orbitals are antibonding, and so their filling weakens the bond order from three to two. Because of its unpaired electrons, triplet oxygen reacts only slowly with most organic molecules, which have paired electron spins; this prevents spontaneous combustion.\nIn the triplet form,  molecules are paramagnetic. That is, they impart magnetic character to oxygen when it is in the presence of a magnetic field, because of the spin magnetic moments of the unpaired electrons in the molecule, and the negative exchange energy between neighboring  molecules. Liquid oxygen is so magnetic that, in laboratory demonstrations, a bridge of liquid oxygen may be supported against its own weight between the poles of a powerful magnet.\nSinglet oxygen is a name given to several higher-energy species of molecular  in which all the electron spins are paired. It is much more reactive with common organic molecules than is molecular oxygen per se. In nature, singlet oxygen is commonly formed from water during photosynthesis, using the energy of sunlight. It is also produced in the troposphere by the photolysis of ozone by light of short wavelength, and by the immune system as a source of active oxygen. Carotenoids in photosynthetic organisms (and possibly animals) play a major role in absorbing energy from singlet oxygen and converting it to the unexcited ground state before it can cause harm to tissues.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Characteristics", "_id": "109--1--0---1", "title": "Singlet Oxygen \u2014 The Double Bond"}
{"qas": [{"question": "What is a rhombohedral cluster?", "answer": ""}, {"question": "What is the common allotrope of oxygen on earth called?", "answer": "dioxygen", "ae_score": -0.1516801468586633, "qg_score": null}, {"question": "What is the common allotrope of oxygen on earth called?", "answer": "dioxygen", "ae_score": -0.1516801468586633, "qg_score": null}], "content": "The common allotrope of elemental oxygen on Earth is called dioxygen, , the major part of the Earth's atmospheric oxygen (see Occurrence). O has a bond length of 121 pm and a bond energy of 498 kJ\u00b7mol, which is smaller than the energy of other double bonds or pairs of single bonds in the biosphere and responsible for the exothermic reaction of O with any organic molecule. Due to its energy content, O is used by complex forms of life, such as animals, in cellular respiration (see Biological role). Other aspects of  are covered in the remainder of this article.\nTrioxygen () is usually known as ozone and is a very reactive allotrope of oxygen that is damaging to lung tissue. Ozone is produced in the upper atmosphere when  combines with atomic oxygen made by the splitting of  by ultraviolet (UV) radiation. Since ozone absorbs strongly in the UV region of the spectrum, the ozone layer of the upper atmosphere functions as a protective radiation shield for the planet. Near the Earth's surface, it is a pollutant formed as a by-product of automobile exhaust. The metastable molecule tetraoxygen () was discovered in 2001,<ref name=\"o4\">{{cite journal|last=Cacace|first=Fulvio|last2=de Petris|first2=Giulia|last3=Troiani|first3=Anna |date=2001|title=Experimental Detection of Tetraoxygen|journal=Angewandte Chemie International Edition|volume=40|issue=21|pages=4062\u201365|doi = 10.1002/1521-3773(20011105)40:21\n and was assumed to exist in one of the six phases of solid oxygen. It was proven in 2006 that this phase, created by pressurizing  to 20 GPa, is in fact a rhombohedral  cluster. This cluster has the potential to be a much more powerful oxidizer than either  or  and may therefore be used in rocket fuel. A metallic phase was discovered in 1990 when solid oxygen is subjected to a pressure of above 96 GPa and it was shown in 1998 that at very low temperatures, this phase becomes superconducting.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Allotropes", "_id": "109--1--1---1", "title": "Exploratory Detection of Tetraoxygen"}
{"qas": [{"question": "Why does oxygen dissolves more easily in water than in air?", "answer": ""}, {"question": "What highly reactive substance must be segregated from combustible materials?", "answer": "Oxygen", "ae_score": -0.2875960988825769, "qg_score": null}, {"question": "What highly reactive substance must be segregated from combustible materials?", "answer": "Oxygen", "ae_score": -0.2875960988825769, "qg_score": null}], "content": "Oxygen dissolves more readily in water than nitrogen, and in freshwater more readily than seawater. Water in equilibrium with air contains approximately 1 molecule of dissolved  for every 2 molecules of  (1:2), compared with an atmospheric ratio of approximately 1:4. The solubility of oxygen in water is temperature-dependent, and about twice as much (14.6 mg\u00b7L) dissolves at 0 \u00b0C than at 20 \u00b0C (7.6 mg\u00b7L). At 25 \u00b0C and 1 atm of air, freshwater contains about 6.04 milliliters (mL) of oxygen per liter, and seawater contains about 4.95 mL per liter. At 5 \u00b0C the solubility increases to 9.0 mL (50% more than at 25 \u00b0C) per liter for water and 7.2 mL (45% more) per liter for sea water.\nOxygen condenses at 90.20 K (\u2212182.95 \u00b0C, \u2212297.31 \u00b0F), and freezes at 54.36 K (\u2212218.79 \u00b0C, \u2212361.82 \u00b0F). Both liquid and solid  are clear substances with a light sky-blue color caused by absorption in the red (in contrast with the blue color of the sky, which is due to Rayleigh scattering of blue light). High-purity liquid  is usually obtained by the fractional distillation of liquefied air. Liquid oxygen may also be condensed from air using liquid nitrogen as a coolant.\nOxygen is a highly reactive substance and must be segregated from combustible materials.\nThe spectroscopy of molecular oxygen is associated with the atmospheric processes of aurora, airglow and nightglow. The absorption in the Herzberg continuum and Schumann\u2013Runge bands in the ultraviolet produces atomic oxygen that is important in the chemistry of the middle atmosphere. Excited state singlet molecular oxygen is responsible for red chemiluminescence in solution.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Physical properties", "_id": "109--1--2---1", "title": "Spectroscopy of Oxygen in Water"}
{"qas": [{"question": "What is the difference between naturally occurring and naturally occurring oxygen?", "answer": ""}, {"question": "How many radioisotopes are there in oxygen?", "answer": "Fourteen", "ae_score": -0.3816562614059229, "qg_score": null}, {"question": "How many radioisotopes are there in oxygen?", "answer": "Fourteen", "ae_score": -0.3816562614059229, "qg_score": null}], "content": "Naturally occurring oxygen is composed of three stable isotopes, O, O, and O, with O being the most abundant (99.762% natural abundance).\nMost O is synthesized at the end of the helium fusion process in massive stars but some is made in the neon burning process. O is primarily made by the burning of hydrogen into helium during the CNO cycle, making it a common isotope in the hydrogen burning zones of stars. Most O is produced when N (made abundant from CNO burning) captures a He nucleus, making O common in the helium-rich zones of evolved, massive stars.\nFourteen radioisotopes have been characterized. The most stable are O with a half-life of 122.24 seconds and O with a half-life of 70.606 seconds. All of the remaining radioactive isotopes have half-lives that are less than 27 s and the majority of these have half-lives that are less than 83 milliseconds. The most common decay mode of the isotopes lighter than O is \u03b2 decay to yield nitrogen, and the most common mode for the isotopes heavier than O is beta decay to yield fluorine.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Isotopes and stellar origin", "_id": "109--1--3---1", "title": "O, O, and O \u2014 Radioactive Isotopes"}
{"qas": [{"question": "Why is there such a high concentration of oxygen gas on Earth?", "answer": ""}, {"question": "Where does most of the oxygen in the atmosphere come from?", "answer": "photosynthesis", "ae_score": -0.1137876777311176, "qg_score": null}, {"question": "Where does most of the oxygen in the atmosphere come from?", "answer": "photosynthesis", "ae_score": -0.1137876777311176, "qg_score": null}], "content": "Oxygen is the most abundant chemical element by mass in the Earth's biosphere, air, sea and land. Oxygen is the third most abundant chemical element in the universe, after hydrogen and helium. About 0.9% of the Sun's mass is oxygen. Oxygen constitutes 49.2% of the Earth's crust by mass as part of oxide compounds such as silicon dioxide and is the most abundant element by mass in the Earth's crust. It is also the major component of the world's oceans (88.8% by mass). Oxygen gas is the second most common component of the Earth's atmosphere, taking up 20.8% of its volume and 23.1% of its mass (some 10 tonnes). Earth is unusual among the planets of the Solar System in having such a high concentration of oxygen gas in its atmosphere: Mars (with 0.1%  by volume) and Venus have much less. The  surrounding those planets is produced solely by ultraviolet radiation on oxygen-containing molecules such as carbon dioxide.\nThe unusually high concentration of oxygen gas on Earth is the result of the oxygen cycle. This biogeochemical cycle describes the movement of oxygen within and between its three main reservoirs on Earth: the atmosphere, the biosphere, and the lithosphere. The main driving factor of the oxygen cycle is photosynthesis, which is responsible for modern Earth's atmosphere. Photosynthesis releases oxygen into the atmosphere, while respiration, decay, and combustion remove it from the atmosphere. In the present equilibrium, production and consumption occur at the same rate of roughly 1/2000th of the entire atmospheric oxygen per year.\nFree oxygen also occurs in solution in the world's water bodies. The increased solubility of  at lower temperatures (see Physical properties) has important implications for ocean life, as polar oceans support a much higher density of life due to their higher oxygen content. Water polluted with plant nutrients such as nitrates or phosphates may stimulate growth of algae by a process called eutrophication and the decay of these organisms and other biomaterials may reduce the  content in eutrophic water bodies. Scientists assess this aspect of water quality by measuring the water's biochemical oxygen demand, or the amount of  needed to restore it to a normal concentration.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Occurrence", "_id": "109--1--4---1", "title": "The Biogeochemical Cycle on Earth"}
{"qas": [{"question": "How do we know the amount of oxygen in the sun?", "answer": ""}, {"question": "Who studies the oxygen isotope ratio of marine organisms?", "answer": "Paleoclimatologists", "ae_score": null, "qg_score": null}, {"question": "Who studies the oxygen isotope ratio of marine organisms?", "answer": "Paleoclimatologists", "ae_score": null, "qg_score": null}], "content": "Paleoclimatologists measure the ratio of oxygen-18 and oxygen-16 in the shells and skeletons of marine organisms to determine the climate millions of years ago (see oxygen isotope ratio cycle). Seawater molecules that contain the lighter isotope, oxygen-16, evaporate at a slightly faster rate than water molecules containing the 12% heavier oxygen-18, and this disparity increases at lower temperatures. During periods of lower global temperatures, snow and rain from that evaporated water tends to be higher in oxygen-16, and the seawater left behind tends to be higher in oxygen-18. Marine organisms then incorporate more oxygen-18 into their skeletons and shells than they would in a warmer climate. Paleoclimatologists also directly measure this ratio in the water molecules of ice core samples as old as hundreds of thousands of years.\nPlanetary geologists have measured the relative quantities of oxygen isotopes in samples from the Earth, the Moon, Mars, and meteorites, but were long unable to obtain reference values for the isotope ratios in the Sun, believed to be the same as those of the primordial solar nebula. Analysis of a silicon wafer exposed to the solar wind in space and returned by the crashed Genesis spacecraft has shown that the Sun has a higher proportion of oxygen-16 than does the Earth. The measurement implies that an unknown process depleted oxygen-16 from the Sun's disk of protoplanetary material prior to the coalescence of dust grains that formed the Earth.\nOxygen presents two spectrophotometric absorption bands peaking at the wavelengths 687 and 760 nm. Some remote sensing scientists have proposed using the measurement of the radiance coming from vegetation canopies in those bands to characterize plant health status from a satellite platform. This approach exploits the fact that in those bands it is possible to discriminate the vegetation's reflectance from its fluorescence, which is much weaker. The measurement is technically difficult owing to the low signal-to-noise ratio and the physical structure of vegetation; but it has been proposed as a possible method of monitoring the carbon cycle from satellites on a global scale.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Characteristics", "sub_heading": "Analysis", "_id": "109--1--5---1", "title": "Measurement of the Carbon Cycle from Satellites"}
{"qas": [{"question": "What is the purpose of the phrase \"I'm not a robot, I'm a robot\"?", "answer": ""}, {"question": "What was thought to be a requirement for all complex life?", "answer": "oxygen", "ae_score": -0.17827856440742748, "qg_score": null}, {"question": "What was thought to be a requirement for all complex life?", "answer": "oxygen", "ae_score": -0.17827856440742748, "qg_score": null}], "content": "In nature, free oxygen is produced by the light-driven splitting of water during oxygenic photosynthesis. According to some estimates, green algae and cyanobacteria in marine environments provide about 70% of the free oxygen produced on Earth, and the rest is produced by terrestrial plants. Other estimates of the oceanic contribution to atmospheric oxygen are higher, while some estimates are lower, suggesting oceans produce ~45% of Earth's atmospheric oxygen each year.\nA simplified overall formula for photosynthesis is:\nor simply\nPhotolytic oxygen evolution occurs in the thylakoid membranes of photosynthetic organisms and requires the energy of four photons. Many steps are involved, but the result is the formation of a proton gradient across the thylakoid membrane, which is used to synthesize adenosine triphosphate (ATP) via photophosphorylation. The  remaining (after production of the water molecule) is released into the atmosphere.\nOxygen is used in mitochondria to generate ATP during oxidative phosphorylation. The reaction for aerobic respiration is essentially the reverse of photosynthesis and is simplified as:\nIn vertebrates,  diffuses through membranes in the lungs and into red blood cells. Hemoglobin binds , changing color from bluish red to bright red ( is released from another part of hemoglobin through the Bohr effect). Other animals use hemocyanin (molluscs and some arthropods) or hemerythrin (spiders and lobsters). A liter of blood can dissolve 200 cm of .\nUntil the discovery of anaerobic metazoa, oxygen was thought to be a requirement for all complex life.\nReactive oxygen species, such as superoxide ion () and hydrogen peroxide (), are reactive by-products of oxygen use in organisms. Parts of the immune system of higher organisms create peroxide, superoxide, and singlet oxygen to destroy invading microbes. Reactive oxygen species also play an important role in the hypersensitive response of plants against pathogen attack. Oxygen is damaging to obligately anaerobic organisms, which were the dominant form of early life on Earth until  began to accumulate in the atmosphere about 2.5 billion years ago during the Great Oxygenation Event, about a billion years after the first appearance of these organisms.\nAn adult human at rest inhales 1.8 to 2.4 grams of oxygen per minute. This amounts to more than 6 billion tonnes of oxygen inhaled by humanity per year.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Biological role of O", "sub_heading": "Biological role of O", "_id": "109--2--0---1", "title": "Oxygen & Biochemicals"}
{"qas": [{"question": "What is partial pressure?", "answer": ""}, {"question": "The amount of free oxygen in the body is called?", "answer": "Partial pressure", "ae_score": -0.6712767777852271, "qg_score": null}, {"question": "The amount of free oxygen in the body is called?", "answer": "Partial pressure", "ae_score": -0.6712767777852271, "qg_score": null}], "content": "The free oxygen partial pressure in the body of a living vertebrate organism is highest in the respiratory system, and decreases along any arterial system, peripheral tissues, and venous system, respectively. Partial pressure is the pressure that oxygen would have if it alone occupied the volume.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Biological role of O", "sub_heading": "Living organisms", "_id": "109--2--1---1", "title": "Free O2 Partially Pressure in the Body of a Living Vertebrate"}
{"qas": [{"question": "Why is it colder in the winter than it is in the summer?", "answer": ""}, {"question": "At the end of the carboniferous period, atmospheric levels reached what percentage by volume?", "answer": "35%", "ae_score": -0.2650411942234055, "qg_score": null}, {"question": "At the end of the carboniferous period, atmospheric levels reached what percentage by volume?", "answer": "35%", "ae_score": -0.2650411942234055, "qg_score": null}], "content": "Free oxygen gas was almost nonexistent in Earth's atmosphere before photosynthetic archaea and bacteria evolved, probably about 3.5 billion years ago. Free oxygen first appeared in significant quantities during the Paleoproterozoic eon (between 3.0 and 2.3 billion years ago). For the first billion years, any free oxygen produced by these organisms combined with dissolved iron in the oceans to form banded iron formations. When such oxygen sinks became saturated, free oxygen began to outgas from the oceans 3\u20132.7 billion years ago, reaching 10% of its present level around 1.7 billion years ago.\nThe presence of large amounts of dissolved and free oxygen in the oceans and atmosphere may have driven most of the extant anaerobic organisms to extinction during the Great Oxygenation Event (''oxygen catastrophe'') about 2.4 billion years ago. Cellular respiration using  enables aerobic organisms to produce much more ATP than anaerobic organisms. Cellular respiration of  occurs in all eukaryotes, including all complex multicellular organisms such as plants and animals.\nSince the beginning of the Cambrian period 540 million years ago, atmospheric  levels have fluctuated between 15% and 30% by volume. Towards the end of the Carboniferous period (about 300 million years ago) atmospheric  levels reached a maximum of 35% by volume, which may have contributed to the large size of insects and amphibians at this time.\nVariations of oxygen shaped the climates of the past. When oxygen declined, atmospheric density dropped and this in turn increased surface evaporation, and led to precipitation increases and warmer temperatures.\nAt the current rate of photosynthesis it would take about 2,000 years to regenerate the entire  in the present atmosphere.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Biological role of O", "sub_heading": "Build-up in the atmosphere", "_id": "109--2--2---1", "title": "Free Oxygen Gas in the Earth's Atmosphere"}
{"qas": [{"question": "How is air extracted from the air?", "answer": ""}, {"question": "What is it called when a continuous supply of gaseous oxygen is pumped through a?", "answer": "pressure swing adsorption", "ae_score": -0.6662859105690792, "qg_score": null}, {"question": "What is it called when a continuous supply of gaseous oxygen is pumped through a?", "answer": "pressure swing adsorption", "ae_score": -0.6662859105690792, "qg_score": null}], "content": "One hundred million tonnes of  are extracted from air for industrial uses annually by two primary methods. The most common method is fractional distillation of liquefied air, with  distilling as a vapor while  is left as a liquid.\nThe other primary method of producing  is passing a stream of clean, dry air through one bed of a pair of identical zeolite molecular sieves, which absorbs the nitrogen and delivers a gas stream that is 90% to 93% . Simultaneously, nitrogen gas is released from the other nitrogen-saturated zeolite bed, by reducing the chamber operating pressure and diverting part of the oxygen gas from the producer bed through it, in the reverse direction of flow. After a set cycle time the operation of the two beds is interchanged, thereby allowing for a continuous supply of gaseous oxygen to be pumped through a pipeline. This is known as pressure swing adsorption. Oxygen gas is increasingly obtained by these non-cryogenic technologies (see also the related vacuum swing adsorption).\nOxygen gas can also be produced through electrolysis of water into molecular oxygen and hydrogen. DC electricity must be used: if AC is used, the gases in each limb consist of hydrogen and oxygen in the explosive ratio 2:1. Contrary to popular belief, the 2:1 ratio observed in the DC electrolysis of acidified water does not prove that the empirical formula of water is HO unless certain assumptions are made about the molecular formulae of hydrogen and oxygen themselves. A similar method is the electrocatalytic  evolution from oxides and oxoacids. Chemical catalysts can be used as well, such as in chemical oxygen generators or oxygen candles that are used as part of the life-support equipment on submarines, and are still part of standard equipment on commercial airliners in case of depressurization emergencies. Another air separation method is forcing air to dissolve through ceramic membranes based on zirconium dioxide by either high pressure or an electric current, to produce nearly pure  gas.\nIn large quantities, the price of liquid oxygen in 2001 was approximately $0.21/kg. Since the primary cost of production is the energy cost of liquefying the air, the production cost will change as energy cost varies.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Industrial production", "sub_heading": "Industrial production", "_id": "109--3---1---1", "title": "Oxygen Production Costs"}
{"qas": [{"question": "How do hospitals store oxygen?", "answer": ""}, {"question": "Where does liquid oxygen go in a hospital?", "answer": "heat exchangers", "ae_score": -0.8860028782982743, "qg_score": null}, {"question": "Where does liquid oxygen go in a hospital?", "answer": "heat exchangers", "ae_score": -0.8860028782982743, "qg_score": null}], "content": "Oxygen storage methods include high pressure oxygen tanks, cryogenics and chemical compounds. For reasons of economy, oxygen is often transported in bulk as a liquid in specially insulated tankers, since one liter of liquefied oxygen is equivalent to 840 liters of gaseous oxygen at atmospheric pressure and 20 C. Such tankers are used to refill bulk liquid oxygen storage containers, which stand outside hospitals and other institutions that need large volumes of pure oxygen gas. Liquid oxygen is passed through heat exchangers, which convert the cryogenic liquid into gas before it enters the building. Oxygen is also stored and shipped in smaller cylinders containing the compressed gas; a form that is useful in certain portable medical applications and oxy-fuel welding and cutting.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Storage", "sub_heading": "Storage", "_id": "109--4---1---1", "title": "Oxygen Storage Methods"}
{"qas": [{"question": "Why is oxygen used medically for patients who require mechanical ventilation?", "answer": ""}, {"question": "What is the concentration of oxygen in ambient air?", "answer": "21%", "ae_score": -0.30491498936829836, "qg_score": null}, {"question": "What is the concentration of oxygen in ambient air?", "answer": "21%", "ae_score": -0.30491498936829836, "qg_score": null}], "content": "Uptake of  from the air is the essential purpose of respiration, so oxygen supplementation is used in medicine. Treatment not only increases oxygen levels in the patient's blood, but has the secondary effect of decreasing resistance to blood flow in many types of diseased lungs, easing work load on the heart. Oxygen therapy is used to treat emphysema, pneumonia, some heart disorders (congestive heart failure), some disorders that cause increased pulmonary artery pressure, and any disease that impairs the body's ability to take up and use gaseous oxygen.\nTreatments are flexible enough to be used in hospitals, the patient's home, or increasingly by portable devices. Oxygen tents were once commonly used in oxygen supplementation, but have since been replaced mostly by the use of oxygen masks or nasal cannulas.\nHyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of  around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the 'bends') are sometimes addressed with this therapy. Increased  concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in the blood. Increasing the pressure of  as soon as possible helps to redissolve the bubbles back into the blood so that these excess gasses can be exhaled naturally through the lungs.\nOxygen is also used medically for patients who require mechanical ventilation, often at concentrations above the 21% found in ambient air.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Applications", "sub_heading": "Applications", "_id": "109--5--0---1", "title": "Oxygen Therapy in Medicine"}
{"qas": [{"question": "How does breathing gas work in space?", "answer": ""}, {"question": "What gases are used in deep sea diving?", "answer": "nitrogen or helium", "ae_score": -0.7399535218650238, "qg_score": null}, {"question": "What gases are used in deep sea diving?", "answer": "nitrogen or helium", "ae_score": -0.7399535218650238, "qg_score": null}], "content": "An application of  as a low-pressure breathing gas is in modern space suits, which surround their occupant's body with pressurized air. These devices use nearly pure oxygen at about one third normal pressure, resulting in a normal blood partial pressure of . This trade-off of higher oxygen concentration for lower pressure is needed to maintain suit flexibility.\nScuba divers and submariners also rely on artificially delivered , but most often use normal pressure, and/or mixtures of oxygen and air. Pure or nearly pure  use in diving at higher-than-sea-level pressures is usually limited to rebreather, decompression, or emergency treatment use at relatively shallow depths (~6 meters depth, or less). Deeper diving requires significant dilution of  with other gases, such as nitrogen or helium, to prevent oxygen toxicity.\nPeople who climb mountains or fly in non-pressurized fixed-wing aircraft sometimes have supplemental  supplies. Pressurized commercial airplanes have an emergency supply of  automatically supplied to the passengers in case of cabin depressurization. Sudden cabin pressure loss activates chemical oxygen generators above each seat, causing oxygen masks to drop. Pulling on the masks \"to start the flow of oxygen\" as cabin safety instructions dictate, forces iron filings into the sodium chlorate inside the canister. A steady stream of oxygen gas is then produced by the exothermic reaction.\nOxygen, as a supposed mild euphoric, has a history of recreational use in oxygen bars and in sports. Oxygen bars are establishments found in Japan, California, and Las Vegas, Nevada since the late 1990s that offer higher than normal  exposure for a fee. Professional athletes, especially in American football, sometimes go off-field between plays to don oxygen masks to boost performance. The pharmacological effect is doubted; a placebo effect is a more likely explanation. Available studies support a performance boost from enriched  mixtures only if it is breathed ''during'' aerobic exercise.\nOther recreational uses that do not involve breathing include pyrotechnic applications, such as George Goble's five-second ignition of barbecue grills.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Applications", "sub_heading": "Life support and recreational use", "_id": "109--5--1---1", "title": "Oxygen is a low-pressure breathing gas"}
{"qas": [{"question": "Why does steel have a temperature of 1,700\u00b0C?", "answer": ""}, {"question": "What percentage of commercially produced oxygen is used by the chemical industry?", "answer": "25%", "ae_score": -0.3606349713811092, "qg_score": null}, {"question": "What percentage of commercially produced oxygen is used by the chemical industry?", "answer": "25%", "ae_score": -0.3606349713811092, "qg_score": null}], "content": "Smelting of iron ore into steel consumes 55% of commercially produced oxygen. In this process,  is injected through a high-pressure lance into molten iron, which removes sulfur impurities and excess carbon as the respective oxides,  and . The reactions are exothermic, so the temperature increases to 1,700 \u00b0C.\nAnother 25% of commercially produced oxygen is used by the chemical industry. Ethylene is reacted with  to create ethylene oxide, which, in turn, is converted into ethylene glycol; the primary feeder material used to manufacture a host of products, including antifreeze and polyester polymers (the precursors of many plastics and fabrics).\nMost of the remaining 20% of commercially produced oxygen is used in medical applications, metal cutting and welding, as an oxidizer in rocket fuel, and in water treatment. Oxygen is used in oxyacetylene welding burning acetylene with  to produce a very hot flame. In this process, metal up to 60 cm thick is first heated with a small oxy-acetylene flame and then quickly cut by a large stream of .", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Applications", "sub_heading": "Industrial", "_id": "109--5--2---1", "title": "Oxygen is used in a wide variety of industries"}
{"qas": [{"question": "What are water-soluble silicates and how do they work?", "answer": ""}, {"question": "What is the purpose of water soluble silicates?", "answer": "detergents and adhesives", "ae_score": -0.19786382128150035, "qg_score": null}, {"question": "What is the purpose of water soluble silicates?", "answer": "detergents and adhesives", "ae_score": -0.19786382128150035, "qg_score": null}], "content": "Water () is an oxide of hydrogen and the most familiar oxygen compound. Hydrogen atoms are covalently bonded to oxygen in a water molecule but also have an additional attraction (about 23.3 kJ\u00b7mol per hydrogen atom) to an adjacent oxygen atom in a separate molecule. These hydrogen bonds between water molecules hold them approximately 15% closer than what would be expected in a simple liquid with just van der Waals forces.\nDue to its electronegativity, oxygen forms chemical bonds with almost all other elements to give corresponding oxides. The surface of most metals, such as aluminium and titanium, are oxidized in the presence of air and become coated with a thin film of oxide that passivates the metal and slows further corrosion. Many oxides of the transition metals are non-stoichiometric compounds, with slightly less metal than the chemical formula would show. For example, the mineral FeO (w\u00fcstite) is written as , where ''x'' is usually around 0.05.\nOxygen is present in the atmosphere in trace quantities in the form of carbon dioxide (). The Earth's crustal rock is composed in large part of oxides of silicon (silica , as found in granite and quartz), aluminium (aluminium oxide , in bauxite and corundum), iron (iron(III) oxide , in hematite and rust), and calcium carbonate (in limestone). The rest of the Earth's crust is also made of oxygen compounds, in particular various complex silicates (in silicate minerals). The Earth's mantle, of much larger mass than the crust, is largely composed of silicates of magnesium and iron.\nWater-soluble silicates in the form of , , and  are used as detergents and adhesives.\nOxygen also acts as a ligand for transition metals, forming transition metal dioxygen complexes, which feature metal\u2013.  This class of compounds includes the heme proteins hemoglobin and myoglobin. An exotic and unusual reaction occurs with , which oxidizes oxygen to give OPtF.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Compounds", "sub_heading": "Compounds", "_id": "109--6--0---1", "title": "Oxygen and Oxygen Compounds in the Earth\u2019s Crust"}
{"qas": [{"question": "Why is oxygen the most important element in life?", "answer": ""}, {"question": "Oxygen reacts spontaneously with many organic compounds at or below room temperature in what process?", "answer": "autoxidation", "ae_score": -0.21268576229682307, "qg_score": null}, {"question": "Oxygen reacts spontaneously with many organic compounds at or below room temperature in what process?", "answer": "autoxidation", "ae_score": -0.21268576229682307, "qg_score": null}], "content": "Among the most important classes of organic compounds that contain oxygen are (where \"R\" is an organic group): alcohols (R-OH); ethers (R-O-R); ketones (R-CO-R); aldehydes (R-CO-H); carboxylic acids (R-COOH); esters (R-COO-R); acid anhydrides (R-CO-O-CO-R); and amides (). There are many important organic solvents that contain oxygen, including: acetone, methanol, ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid. Acetone () and phenol () are used as feeder materials in the synthesis of many different substances. Other important organic compounds that contain oxygen are: glycerol, formaldehyde, glutaraldehyde, citric acid, acetic anhydride, and acetamide. Epoxides are ethers in which the oxygen atom is part of a ring of three atoms.\nOxygen reacts spontaneously with many organic compounds at or below room temperature in a process called autoxidation. Most of the organic compounds that contain oxygen are not made by direct action of . Organic compounds important in industry and commerce that are made by direct oxidation of a precursor include ethylene oxide and peracetic acid.\nThe element is found in almost all biomolecules that are important to (or generated by) life. Only a few common complex biomolecules, such as squalene and the carotenes, contain no oxygen. Of the organic compounds with biological relevance, carbohydrates contain the largest proportion by mass of oxygen. All fats, fatty acids, amino acids, and proteins contain oxygen (due to the presence of carbonyl groups in these acids and their ester residues). Oxygen also occurs in phosphate () groups in the biologically important energy-carrying molecules ATP and ADP, in the backbone and the purines (except adenine) and pyrimidines of RNA and DNA, and in bones as calcium phosphate and hydroxylapatite.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Compounds", "sub_heading": "Organic compounds and biomolecules", "_id": "109--6--1---1", "title": "Oxygen in Organic Compounds \u2014 A Brief Overview"}
{"qas": [{"question": "How do deep scuba divers die from inhaling too much oxygen?", "answer": ""}, {"question": "What is the most feared effect of oxygen toxicity?", "answer": "seizures", "ae_score": -0.73879287036834, "qg_score": null}, {"question": "What is the most feared effect of oxygen toxicity?", "answer": "seizures", "ae_score": -0.73879287036834, "qg_score": null}], "content": "Oxygen gas () can be toxic at elevated partial pressures, leading to convulsions and other health problems. Oxygen toxicity usually begins to occur at partial pressures more than 50 kilopascals (kPa), equal to about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level  partial pressure of about 21 kPa. This is not a problem except for patients on mechanical ventilators, since gas supplied through oxygen masks in medical applications is typically composed of only 30%\u201350%  by volume (about 30 kPa at standard pressure). (although this figure also is subject to wide variation, depending on type of mask).\nAt one time, premature babies were placed in incubators containing -rich air, but this practice was discontinued after some babies were blinded by the oxygen content being too high.\nBreathing pure  in space applications, such as in some modern space suits, or in early spacecraft such as Apollo, causes no damage due to the low total pressures used. In the case of spacesuits, the  partial pressure in the breathing gas is, in general, about 30 kPa (1.4 times normal), and the resulting  partial pressure in the astronaut's arterial blood is only marginally more than normal sea-level  partial pressure (for more information on this, see space suit and arterial blood gas).\nOxygen toxicity to the lungs and central nervous system can also occur in deep scuba diving and surface supplied diving. Prolonged breathing of an air mixture with an  partial pressure more than 60 kPa can eventually lead to permanent pulmonary fibrosis. Exposure to a  partial pressures greater than 160 kPa (about 1.6 atm) may lead to convulsions (normally fatal for divers). Acute oxygen toxicity (causing seizures, its most feared effect for divers) can occur by breathing an air mixture with 21%  at 66 m or more of depth; the same thing can occur by breathing 100%  at only 6 m.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Safety and precautions", "sub_heading": "Safety and precautions", "_id": "109--7--0---1", "title": "Oxygen Toxicity in Spacesuits and Spacesuits"}
{"qas": [{"question": "Why do people get frostbite on their eyes when they inhale oxygen?", "answer": ""}, {"question": "What can oxygen cause to the skin and eyes?", "answer": "frostbites", "ae_score": -0.3128836663519629, "qg_score": null}, {"question": "What can oxygen cause to the skin and eyes?", "answer": "frostbites", "ae_score": -0.3128836663519629, "qg_score": null}], "content": "Highly concentrated sources of oxygen promote rapid combustion. Fire and explosion hazards exist when concentrated oxidants and fuels are brought into close proximity; an ignition event, such as heat or a spark, is needed to trigger combustion. Oxygen is the oxidant, not the fuel, but nevertheless the source of most of the chemical energy released in combustion. Combustion hazards also apply to compounds of oxygen with a high oxidative potential, such as peroxides, chlorates, nitrates, perchlorates, and dichromates because they can donate oxygen to a fire.\nConcentrated  will allow combustion to proceed rapidly and energetically. Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel; and therefore the design and manufacture of  systems requires special training to ensure that ignition sources are minimized. The fire that killed the Apollo 1 crew in a launch pad test spread so rapidly because the capsule was pressurized with pure  but at slightly more than atmospheric pressure, instead of the  normal pressure that would be used in a mission.\nLiquid oxygen spills, if allowed to soak into organic matter, such as wood, petrochemicals, and asphalt can cause these materials to detonate unpredictably on subsequent mechanical impact. As with other cryogenic liquids, on contact with the human body it can cause frostbites to the skin and the eyes.", "page_name": "Oxygen", "page_id": "Oxygen", "heading": "Safety and precautions", "sub_heading": "Combustion and other hazards", "_id": "109--7--1---1", "title": "Combustion Hazards and Fires"}
{"qas": [{"question": "Why do most organisms use visible light for photosynthesis?", "answer": ""}, {"question": "Who came up with the general equation for photosynthesis?", "answer": "Cornelius van Niel", "ae_score": -0.059072777547267086, "qg_score": null}, {"question": "Who came up with the general equation for photosynthesis?", "answer": "Cornelius van Niel", "ae_score": -0.059072777547267086, "qg_score": null}], "content": "Photosynthetic organisms are photoautotrophs, which means that they are able to synthesize food directly from carbon dioxide and water using energy from light. However, not all organisms that use light as a source of energy carry out photosynthesis; photoheterotrophs use organic compounds, rather than carbon dioxide, as a source of carbon.<ref name=bryantfrigaard/> In plants, algae, and cyanobacteria, photosynthesis releases oxygen. This is called ''oxygenic photosynthesis'' and is by far the most common type of photosynthesis used by living organisms. Although there are some differences between oxygenic photosynthesis in plants, algae, and cyanobacteria, the overall process is quite similar in these organisms. There are also many varieties of anoxygenic photosynthesis, used mostly by certain types of bacteria, which consume carbon dioxide but do not release oxygen.\nCarbon dioxide is converted into sugars in a process called carbon fixation. Carbon fixation is an endothermic redox reaction, so photosynthesis needs to supply both a source of energy to drive this process, and the electrons needed to convert carbon dioxide into a carbohydrate via a reduction reaction. The addition of electrons to a chemical species is called reduction. In general outline and in effect, photosynthesis is the opposite of cellular respiration, in which glucose and other compounds are oxidized to produce carbon dioxide and water, and to release chemical energy (an exothermic reaction) to drive the organism's metabolism. The two processes, reduction of carbon dioxide to carbohydrate and then later oxidation of the carbohydrate, are distinct: photosynthesis and cellular respiration take place through a different sequence of chemical reactions and in different cellular compartments.\nThe general equation for photosynthesis as first proposed by Cornelius van Niel is therefore:\nSince water is used as the electron donor in oxygenic photosynthesis, the equation for this process is:\nThis equation emphasizes that water is both a reactant in the light-dependent reaction and a product of the light-independent reaction, but canceling ''n'' water molecules from each side gives the net equation:\nOther processes substitute other compounds (such as arsenite) for water in the electron-supply role; for example some microbes use sunlight to oxidize arsenite to arsenate: The equation for this reaction is:\nPhotosynthesis occurs in two stages. In the first stage, ''light-dependent reactions'' or ''light reactions'' capture the energy of light and use it to make the energy-storage molecules ATP and NADPH. During the second stage, the ''light-independent reactions'' use these products to capture and reduce carbon dioxide.\nMost organisms that utilize oxygenic photosynthesis use visible light for the light-dependent reactions, although at least three use shortwave infrared or, more specifically, far-red radiation.\nSome organisms employ even more radical variants of photosynthesis. Some archea use a simpler method that employs a pigment similar to those used for vision in animals. The bacteriorhodopsin changes its configuration in response to sunlight, acting as a proton pump. This produces a proton gradient more directly, which is then converted to chemical energy. The process does not involve carbon dioxide fixation and does not release oxygen, and seems to have evolved separately from the more common types of photosynthesis.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Overview", "sub_heading": "Overview", "_id": "110--0---1---1", "title": "Photosynthesis: The opposite of cellular respiration"}
{"qas": [{"question": "How do plants and algae produce light?", "answer": ""}, {"question": "Where does photosynthesis take place in plants?", "answer": "antenna proteins", "ae_score": -0.14216335339885677, "qg_score": null}, {"question": "Where does photosynthesis take place in plants?", "answer": "antenna proteins", "ae_score": -0.14216335339885677, "qg_score": null}], "content": "In photosynthetic bacteria, the proteins that gather light for photosynthesis are embedded in cell membranes. In its simplest form, this involves the membrane surrounding the cell itself. However, the membrane may be tightly folded into cylindrical sheets called thylakoids,<ref name=Mullineaux1999/> or bunched up into round vesicles called ''intracytoplasmic membranes''. These structures can fill most of the interior of a cell, giving the membrane a very large surface area and therefore increasing the amount of light that the bacteria can absorb.\nIn plants and algae, photosynthesis takes place in organelles called chloroplasts. A typical plant cell contains about 10 to 100 chloroplasts. The chloroplast is enclosed by a membrane. This membrane is composed of a phospholipid inner membrane, a phospholipid outer membrane, and an intermembrane space. Enclosed by the membrane is an aqueous fluid called the stroma. Embedded within the stroma are stacks of thylakoids (grana), which are the site of photosynthesis. The thylakoids appear as flattened disks. The thylakoid itself is enclosed by the thylakoid membrane, and within the enclosed volume is a lumen or thylakoid space. Embedded in the thylakoid membrane are integral and peripheral membrane protein complexes of the photosynthetic system.\nPlants absorb light primarily using the pigment chlorophyll. The green part of the light spectrum is not absorbed but is reflected which is the reason that most plants have a green color. Besides chlorophyll, plants also use pigments such as carotenes and xanthophylls. Algae also use chlorophyll, but various other pigments are present, such as phycocyanin, carotenes, and xanthophylls in green algae, phycoerythrin in red algae (rhodophytes) and fucoxanthin in brown algae and diatoms resulting in a wide variety of colors.\nThese pigments are embedded in plants and algae in complexes called antenna proteins. In such proteins, the pigments are arranged to work together. Such a combination of proteins is also called a light-harvesting complex.\nAlthough all cells in the green parts of a plant have chloroplasts, the majority of those are found in specially adapted structures called leaves. Certain species adapted to conditions of strong sunlight and aridity, such as many Euphorbia and cactus species, have their main photosynthetic organs in their stems. The cells in the interior tissues of a leaf, called the mesophyll, can contain between 450,000 and 800,000 chloroplasts for every square millimeter of leaf. The surface of the leaf is coated with a water-resistant waxy cuticle that protects the leaf from excessive evaporation of water and decreases the absorption of ultraviolet or blue light to reduce heating. The transparent epidermis layer allows light to pass through to the palisade mesophyll cells where most of the photosynthesis takes place.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Photosynthetic membranes and organelles", "sub_heading": "Photosynthetic membranes and organelles", "_id": "110--1---1---1", "title": "Photosynthesis in Plants & Algae"}
{"qas": [{"question": "What is the difference between light-dependent and non-cyclic reactions?", "answer": ""}, {"question": "Where does the cyclic reaction take place in photosynthesis?", "answer": "photosystem I", "ae_score": -0.4725980370377437, "qg_score": null}, {"question": "Where does the cyclic reaction take place in photosynthesis?", "answer": "photosystem I", "ae_score": -0.4725980370377437, "qg_score": null}], "content": "In plants, light-dependent reactions occur in the thylakoid membranes of the chloroplasts where they drive the synthesis of ATP and NADPH. The light-dependent reactions are of two forms: cyclic and non-cyclic.\nIn the non-cyclic reaction, the photons are captured in the light-harvesting antenna complexes of photosystem II by chlorophyll and other accessory pigments (see diagram at right). The absorption of a photon by the antenna complex frees an electron by a process called photoinduced charge separation. The antenna system is at the core of the chlorophyll molecule of the photosystem II reaction center. That freed electron is transferred to the primary electron-acceptor molecule, pheophytin. As the electrons are shuttled through an electron transport chain (the so-called '''''Z-scheme''''' shown in the diagram), it initially functions to generate a chemiosmotic potential by pumping proton cations (H) across the membrane and into the thylakoid space. An ATP synthase enzyme uses that chemiosmotic potential to make ATP during photophosphorylation, whereas NADPH is a product of the terminal redox reaction in the ''Z-scheme''. The electron enters a chlorophyll molecule in Photosystem I. There it is further excited by the light absorbed by that photosystem. The electron is then passed along a chain of electron acceptors to which it transfers some of its energy. The energy delivered to the electron acceptors is used to move hydrogen ions across the thylakoid membrane into the lumen. The electron is eventually used to reduce the co-enzyme NADP with a H to NADPH (which has functions in the light-independent reaction); at that point, the path of that electron ends.\nThe cyclic reaction is similar to that of the non-cyclic, but differs in that it generates only ATP, and no reduced NADP (NADPH) is created. The cyclic reaction takes place only at photosystem I. Once the electron is displaced from the photosystem, the electron is passed down the electron acceptor molecules and returns to photosystem I, from where it was emitted, hence the name ''cyclic reaction''.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Light-dependent reactions", "sub_heading": "Light-dependent reactions", "_id": "110--2--0---1", "title": "Photosynthesis | Light-dependent reactions"}
{"qas": [{"question": "How does photosynthesis work?", "answer": ""}, {"question": "What is the main reducing agent produced by chloroplasts?", "answer": "The NADPH", "ae_score": -0.5931359295411117, "qg_score": null}, {"question": "What is the main reducing agent produced by chloroplasts?", "answer": "The NADPH", "ae_score": -0.5931359295411117, "qg_score": null}], "content": "The NADPH is the main reducing agent produced by chloroplasts, which then goes on to provide a source of energetic electrons in other cellular reactions. Its production leaves chlorophyll in photosystem I with a deficit of electrons (chlorophyll has been oxidized), which must be balanced by some other reducing agent that will supply the missing electron. The excited electrons lost from chlorophyll from photosystem I are supplied from the electron transport chain by plastocyanin. However, since photosystem II is the first step of the ''Z-scheme'', an external source of electrons is required to reduce its oxidized '''chlorophyll ''a''''' molecules. The source of electrons in green-plant and cyanobacterial photosynthesis is water. Two water molecules are oxidized by four successive charge-separation reactions by photosystem II to yield a molecule of diatomic oxygen and four hydrogen ions; the electrons yielded are transferred to a redox-active tyrosine residue that then reduces the oxidized chlorophyll ''a'' (called P680) that serves as the primary light-driven electron donor in the photosystem II reaction center. That photo receptor is in effect reset and is then able to repeat the absorption of another photon and the release of another photo-dissociated electron. The oxidation of water is catalyzed in photosystem II by a redox-active structure that contains four manganese ions and a calcium ion; this oxygen-evolving complex binds two water molecules and contains the four oxidizing equivalents that are used to drive the water-oxidizing reaction. Photosystem II is the only known biological enzyme that carries out this oxidation of water. The hydrogen ions released contribute to the transmembrane chemiosmotic potential that leads to ATP synthesis. Oxygen is a waste product of light-dependent reactions, but the majority of organisms on Earth use oxygen for cellular respiration, including photosynthetic organisms.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Light-dependent reactions", "sub_heading": "Water photolysis", "_id": "110--2--1---1", "title": "Photosystem II and the Z-scheme"}
{"qas": [{"question": "How do green plants work?", "answer": ""}, {"question": "What is the name of the 3-carbon compound that carbon dioxide combines with ribul?", "answer": "glycerate 3-phosphate", "ae_score": -0.49895164819494975, "qg_score": null}, {"question": "What is the name of the 3-carbon compound that carbon dioxide combines with ribul?", "answer": "glycerate 3-phosphate", "ae_score": -0.49895164819494975, "qg_score": null}], "content": "In the light-independent (or \"dark\") reactions, the enzyme RuBisCO captures CO from the atmosphere and, in a process called the Calvin-Benson cycle, it uses the newly formed NADPH and releases three-carbon sugars, which are later combined to form sucrose and starch. The overall equation for the light-independent reactions in green plants is\nCarbon fixation produces the intermediate three-carbon sugar product, which is then converted to the final carbohydrate products. The simple carbon sugars produced by photosynthesis are then used in the forming of other organic compounds, such as the building material cellulose, the precursors for lipid and amino acid biosynthesis, or as a fuel in cellular respiration. The latter occurs not only in plants but also in animals when the energy from plants is passed through a food chain.\nThe fixation or reduction of carbon dioxide is a process in which carbon dioxide combines with a five-carbon sugar, ribulose 1,5-bisphosphate, to yield two molecules of a three-carbon compound, glycerate 3-phosphate, also known as 3-phosphoglycerate. Glycerate 3-phosphate, in the presence of ATP and NADPH produced during the light-dependent stages, is reduced to glyceraldehyde 3-phosphate. This product is also referred to as 3-phosphoglyceraldehyde (PGAL) or, more generically, as triose phosphate. Most (5 out of 6 molecules) of the glyceraldehyde 3-phosphate produced is used to regenerate ribulose 1,5-bisphosphate so the process can continue. The triose phosphates not thus \"recycled\" often condense to form hexose phosphates, which ultimately yield sucrose, starch and cellulose. The sugars produced during carbon metabolism yield carbon skeletons that can be used for other metabolic reactions like the production of amino acids and lipids.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Light-independent reactions", "sub_heading": "Light-independent reactions", "_id": "110--3--0---1", "title": "Carbon Fixation in Green Plants \u2014 Part 1"}
{"qas": [{"question": "Why do leaves turn brown in hot weather?", "answer": ""}, {"question": "What is the four-carbon organic acid produced by photosynthesis?", "answer": "oxaloacetic acid", "ae_score": -0.9371119041478672, "qg_score": null}, {"question": "What is the four-carbon organic acid produced by photosynthesis?", "answer": "oxaloacetic acid", "ae_score": -0.9371119041478672, "qg_score": null}], "content": "In hot and dry conditions, plants close their stomata to prevent water loss. Under these conditions,  will decrease and oxygen gas, produced by the light reactions of photosynthesis, will increase, causing an increase of photorespiration by the oxygenase activity of ribulose-1,5-bisphosphate carboxylase/oxygenase and decrease in carbon fixation. Some plants have evolved mechanisms to increase the  concentration in the leaves under these conditions.\nPlants that use the C carbon fixation process chemically fix carbon dioxide in the cells of the mesophyll by adding it to the three-carbon molecule phosphoenolpyruvate (PEP), a reaction catalyzed by an enzyme called PEP carboxylase, creating the four-carbon organic acid oxaloacetic acid. Oxaloacetic acid or malate synthesized by this process is then translocated to specialized bundle sheath cells where the enzyme RuBisCO and other Calvin cycle enzymes are located, and where  released by decarboxylation of the four-carbon acids is then fixed by RuBisCO activity to the three-carbon 3-phosphoglyceric acids. The physical separation of RuBisCO from the oxygen-generating light reactions reduces photorespiration and increases  fixation and, thus, the photosynthetic capacity of the leaf.  plants can produce more sugar than  plants in conditions of high light and temperature. Many important crop plants are  plants, including maize, sorghum, sugarcane, and millet. Plants that do not use PEP-carboxylase in carbon fixation are called C plants because the primary carboxylation reaction, catalyzed by RuBisCO, produces the three-carbon 3-phosphoglyceric acids directly in the Calvin-Benson cycle. Over 90% of plants use  carbon fixation, compared to 3% that use  carbon fixation; however, the evolution of  in over 60 plant lineages makes it a striking example of convergent evolution.\nXerophytes, such as cacti and most succulents, also use PEP carboxylase to capture carbon dioxide in a process called Crassulacean acid metabolism (CAM). In contrast to  metabolism, which ''spatially'' separates the  fixation to PEP from the Calvin cycle, CAM ''temporally'' separates these two processes. CAM plants have a different leaf anatomy from  plants, and fix the  at night, when their stomata are open. CAM plants store the  mostly in the form of malic acid via carboxylation of phosphoenolpyruvate to oxaloacetate, which is then reduced to malate. Decarboxylation of malate during the day releases  inside the leaves, thus allowing carbon fixation to 3-phosphoglycerate by RuBisCO. Sixteen thousand species of plants use CAM.\nCyanobacteria possess carboxysomes, which increase the concentration of  around RuBisCO to increase the rate of photosynthesis. An enzyme, carbonic anhydrase, located within the carboxysome releases CO from the dissolved hydrocarbonate ions (HCO). Before the CO diffuses out it is quickly sponged up by RuBisCO, which is concentrated within the carboxysomes. HCO ions are made from CO outside the cell by another carbonic anhydrase and are actively pumped into the cell by a membrane protein. They cannot cross the membrane as they are charged, and within the cytosol they turn back into CO very slowly without the help of carbonic anhydrase. This causes the HCO ions to accumulate within the cell from where they diffuse into the carboxysomes. Pyrenoids in algae and hornworts also act to concentrate  around rubisco.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Light-independent reactions", "sub_heading": "Carbon concentrating mechanisms", "_id": "110--3--1---1", "title": "The Evolution of Carbon Fixation in Plants"}
{"qas": [{"question": "How do we know how much light is absorbed by a leaf?", "answer": ""}, {"question": "What is the phenomenon that increases the efficiency of the energy transport of light?", "answer": "quantum walk", "ae_score": -0.4160324421440527, "qg_score": null}, {"question": "What is the phenomenon that increases the efficiency of the energy transport of light?", "answer": "quantum walk", "ae_score": -0.4160324421440527, "qg_score": null}], "content": "Plants usually convert light into chemical energy with a photosynthetic efficiency of 3\u20136%.Absorbed light that is unconverted is dissipated primarily as heat, with a small fraction (1\u20132%) re-emitted as chlorophyll fluorescence at longer (redder) wavelengths. A fact that allows measurement of the light reaction of photosynthesis by using chlorophyll fluorometers.\nActual plants' photosynthetic efficiency varies with the frequency of the light being converted, light intensity, temperature and proportion of carbon dioxide in the atmosphere, and can vary from 0.1% to 8%. By comparison, solar panels convert light into electric energy at an efficiency of approximately 6\u201320% for mass-produced panels, and above 40% in laboratory devices.\nThe efficiency of both light and dark reactions can be measured but the relationship between the two can be complex. For example, the ATP and NADPH energy molecules, created by the light reaction, can be used for carbon fixation or for photorespiration in C plants. Electrons may also flow to other electron sinks. For this reason, it is not uncommon for authors to differentiate between work done under non-photorespiratory conditions and under photorespiratory conditions.\nChlorophyll fluorescence of photosystem II can measure the light reaction, and Infrared gas analyzers can  measure the dark reaction. It is also possible to investigate both at the same time using an integrated chlorophyll fluorometer and gas exchange system, or by using two separate systems together. Infrared gas analyzers and some  moisture sensors are sensitive enough to measure the photosynthetic assimilation of CO, and of \u0394HO using reliable methods CO is commonly measured in \u03bcmols/m/s, parts per million or volume per million and H0 is commonly measured in mmol/m/s or in mbars.<ref name=long2003/> By measuring CO assimilation, \u0394HO, leaf temperature, barometric pressure, leaf area, and photosynthetically active radiation or PAR, it becomes possible to estimate, \u201cA\u201d or carbon assimilation, \u201cE\u201d or transpiration, \u201cgs\u201d or stomatal conductance, and Ci or intracellular CO.<ref name=long2003/> However, it is more common to used chlorophyll fluorescence for plant stress measurement, where appropriate, because the most commonly used measuring parameters FV/FM and Y(II) or F/FM\u2019 can be made in a few seconds, allowing the measurement of larger plant populations.\nGas exchange systems that offer control of CO levels, above and below ambient, allow the common practice of measurement of A/Ci curves, at different CO levels, to characterize a plant\u2019s photosynthetic response.<ref name=long2003/>\nIntegrated chlorophyll fluorometer \u2013 gas exchange systems allow a more precise measure of photosynthetic response and mechanisms. While standard gas exchange photosynthesis systems can measure Ci, or substomatal CO levels, the addition of integrated chlorophyll fluorescence measurements allows a more precise measurement of C to replace Ci. The estimation of CO at the site of carboxylation in the chloroplast, or C, becomes possible with the measurement of mesophyll conductance or g using an integrated system.\nPhotosynthesis measurement systems are not designed to directly measure the amount of light absorbed by the leaf. But analysis of chlorophyll-fluorescence, P700- and P515-absorbance and gas exchange measurements reveal detailed information about e.g. the photosystems, quantum efficiency and the CO assimilation rates. With some instruments even wavelength-dependency of the photosynthetic efficiency can be analyzed.\nA phenomenon known as quantum walk increases the efficiency of the energy transport of light significantly. In the photosynthetic cell of an algae, bacterium, or plant, there are light-sensitive molecules called chromophores arranged in an antenna-shaped structure named a photocomplex. When a photon is absorbed by a chromophore, it is converted into a quasiparticle referred to as an exciton, which jumps from chromophore to chromophore towards the reaction center of the photocomplex, a collection of molecules that traps its energy in a chemical form that makes it accessible for the cell's metabolism. The exciton's wave properties enable it to cover a wider area and try out several possible paths simultaneously, allowing it to instantaneously \"choose\" the most efficient route, where it will have the highest probability of arriving at its destination in the minimum possible time. Because that quantum walking takes place at temperatures far higher than quantum phenomena usually occur, it is only possible over very short distances, due to obstacles in the form of destructive interference that come into play. These obstacles cause the particle to lose its wave properties for an instant before it regains them once again after it is freed from its locked position through a classic \"hop\". The movement of the electron towards the photo center is therefore covered in a series of conventional hops and quantum walks.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Efficiency", "sub_heading": "Efficiency", "_id": "110--5---1---1", "title": "Quantum Walks and Photosynthesis"}
{"qas": [{"question": "How are slugs able to survive so long without photosynthesis?", "answer": ""}, {"question": "What process allows marine mollusks to survive solely by chloroplasts?", "answer": "photosynthesis", "ae_score": -0.9973054375098652, "qg_score": null}, {"question": "What process allows marine mollusks to survive solely by chloroplasts?", "answer": "photosynthesis", "ae_score": -0.9973054375098652, "qg_score": null}], "content": "Several groups of animals have formed symbiotic relationships with photosynthetic algae. These are most common in corals, sponges and sea anemones. It is presumed that this is due to the particularly simple body plans and large surface areas of these animals compared to their volumes. In addition, a few marine mollusks ''Elysia viridis'' and ''Elysia chlorotica'' also maintain a symbiotic relationship with chloroplasts they capture from the algae in their diet and then store in their bodies. This allows the mollusks to survive solely by photosynthesis for several months at a time. Some of the genes from the plant cell nucleus have even been transferred to the slugs, so that the chloroplasts can be supplied with proteins that they need to survive.\nAn even closer form of symbiosis may explain the origin of chloroplasts. Chloroplasts have many similarities with photosynthetic bacteria, including a circular chromosome, prokaryotic-type ribosome, and similar proteins in the photosynthetic reaction center. The endosymbiotic theory suggests that photosynthetic bacteria were acquired (by endocytosis) by early eukaryotic cells to form the first plant cells. Therefore, chloroplasts may be photosynthetic bacteria that adapted to life inside plant cells. Like mitochondria, chloroplasts possess their own DNA, separate from the nuclear DNA of their plant host cells and the genes in this chloroplast DNA resemble those found in cyanobacteria. DNA in chloroplasts codes for redox proteins such as those found in the photosynthetic reaction centers. The CoRR Hypothesis proposes that this '''Co'''-location is required for '''R'''edox '''R'''egulation.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Evolution", "sub_heading": "Evolution", "_id": "110--6--0---1", "title": "The Origin of Chloroplasts in Plant Cells"}
{"qas": [{"question": "How did cyanobacteria become the primary source of oxygen?", "answer": ""}, {"question": "When did the first photosynthetic cyanobacteria appear on the earth?", "answer": "Proterozoic", "ae_score": null, "qg_score": null, "filter_answer": "at least 2450\u20132320 million years"}, {"question": "When did the first photosynthetic cyanobacteria appear on the earth?", "answer": "Proterozoic", "ae_score": null, "qg_score": null, "filter_answer": "at least 2450\u20132320 million years"}], "content": "The biochemical capacity to use water as the source for electrons in photosynthesis evolved once, in a common ancestor of extant cyanobacteria. The geological record indicates that this transforming event took place early in Earth's history, at least 2450\u20132320 million years ago (Ma), and, it is speculated, much earlier. Because the Earth's atmosphere contained almost no oxygen during the estimated development of photosynthesis, it is believed that the first photosynthetic cyanobacteria did not generate oxygen. Available evidence from geobiological studies of Archean (>2500 Ma) sedimentary rocks indicates that life existed 3500 Ma, but the question of when oxygenic photosynthesis evolved is still unanswered. A clear paleontological window on cyanobacterial evolution opened about 2000 Ma, revealing an already-diverse biota of blue-green algae. Cyanobacteria remained the principal primary producers of oxygen throughout the Proterozoic Eon (2500\u2013543 Ma), in part because the redox structure of the oceans favored photoautotrophs capable of nitrogen fixation. Green algae joined blue-green algae as the major primary producers of oxygen on continental shelves near the end of the Proterozoic, but it was only with the Mesozoic (251\u201365 Ma) radiations of dinoflagellates, coccolithophorids, and diatoms did the primary production of oxygen in marine shelf waters take modern form. Cyanobacteria remain critical to marine ecosystems as primary producers of oxygen in oceanic gyres, as agents of biological nitrogen fixation, and, in modified form, as the plastids of marine algae.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Evolution", "sub_heading": "Cyanobacteria and the evolution of photosynthesis", "_id": "110--6--1---1", "title": "Cyanobacteria and the Origin of Photosynthesis"}
{"qas": [{"question": "Why are photosynthesis and photophosphorylation the same thing?", "answer": ""}, {"question": "Who came up with the name photosyntax and photosynthesis?", "answer": "Charles Reid Barnes", "ae_score": -0.20371565878993095, "qg_score": null}, {"question": "Who came up with the name photosyntax and photosynthesis?", "answer": "Charles Reid Barnes", "ae_score": -0.20371565878993095, "qg_score": null}], "content": "In 1893, Charles Reid Barnes proposed two terms, ''photosyntax'' and ''photosynthesis'', for the biological process of ''synthesis of complex carbon compounds out of carbonic acid, in the presence of chlorophyll, under the influence of light''. Over time, the term ''photosynthesis'' came into common usage as the term of choice. Later discovery of anoxygenic photosynthetic bacteria and photophosphorylation necessitated redefinition of the term.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Discovery", "sub_heading": "Discovery", "_id": "110--7--0---1", "title": "''Photosyntax'' & ''Photosynthesis''"}
{"qas": [{"question": "How do we know how much CO2 plants produce?", "answer": ""}, {"question": "What does pg stand for in plants?", "answer": "phosphoglyceric acid", "ae_score": -0.6097336658160003, "qg_score": null}, {"question": "What does pg stand for in plants?", "answer": "phosphoglyceric acid", "ae_score": -0.6097336658160003, "qg_score": null}], "content": "After   WWII at late 1940   at the University of California, Berkeley, the details of photosynthetic carbon metabolism were sorted out by the chemists Melvin Calvin, Andrew Benson, James Bassham and a score of students and researchers utilizing the carbon-14 isotope and paper chromatography techniques. The pathway of CO2 fixation by the algae ''Chlorella'' in a fraction of a second in light resulted in a 3 carbon molecule called phosphoglyceric acid (PGA). For that original and ground-breaking work, a Nobel Prize in Chemistry was awarded to Melvin Calvin 1961. In parallel, plant physiologists studied leaf gas exchanges using the new method of infrared gas analysis and a leaf chamber where the net photosynthetic rates ranged from 10 to 13 u mole CO2/square metere.sec., with the conclusion that all terrestrial plants having the same photosynthetic capacities that were light saturated at less than 50% of sunlight. These rates were determined in potted plants grown indoors under low light intensity.\nLater in 1958-1963 at Cornell University, field grown maize was reported to have much greater leaf photosynthetic rates of 40 u mol CO2/square meter.sec and was not saturated at near full sunlight. This higher rate in maize was almost double those observed in other species such as wheat and  soybean, indicating that large differences in photosynthesis exist among higher plants. At the University of Arizona, detailed gas exchange research on more than 15 species of monocot and dicot uncovered for the first time that differences in leaf anatomy are  crucial factors in differentiating photosynthetic capacities among species. In tropical grasses, including maize, sorghum, sugarcane, Bermuda grass and in the dicot amaranthus, leaf photosynthetic rates were around 38\u221240 u mol CO2/square meter.sec., and the leaves have two types of green cells, i. e. outer layer of mesophyll cells surrounding a tightly packed cholorophyllous vascular bundle sheath cells. This type of anatomy was termed Kranz anatomy in the 19th century by the botanist Gottlieb Haberlandt while studying leaf anatomy of sugarcane. Plant species with the greatest photosynthetic rates and Kranz anatomy showed no apparent photorespiration, very low CO2 compensation point, high optimum temperature, high stomatal resistances and lower mesophyll resistances for gas diffusion and rates never saturated at full sun light. The research at Arizona was designated Citation Classic by the ISI 1986. These species was later termed C4 plants as the first stable compound of CO2 fixation in light has 4 carbon as malate and aspartate. Other species that lack Kranz anatomy were termed C3 type such as cotton and sunflower, as the first stable carbon compound is the 3-carbon PGA acid. At 1000 ppm CO2 in measuring air, both the C3 and C4 plants had similar leaf photosynthetic rates around 60 u mole CO2/square meter.sec. indicating the suppression of phototorespiration in C3 plants.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Discovery", "sub_heading": "C3 : C4 photosynthesis research", "_id": "110--7--1---1", "title": "Photosynthesis in Plants"}
{"qas": [{"question": "Why is radiation so much more intense in space than it is in the sun?", "answer": ""}, {"question": "Where does the salvaging of photosynthesis take place?", "answer": "photorespiration", "ae_score": -0.11800795988385313, "qg_score": null}, {"question": "Where does the salvaging of photosynthesis take place?", "answer": "photorespiration", "ae_score": -0.11800795988385313, "qg_score": null}], "content": "There are three main factors affecting photosynthesis and several corollary factors. The three main are:\nThe process of photosynthesis provides the main input of free energy into the biosphere, and is one of four main ways in which radiation is important for plant life.\nThe radiation climate within plant communities is extremely variable, with both time and space.\nIn the early 20th century, Frederick Blackman and Gabrielle Matthaei investigated the effects of light intensity (irradiance) and temperature on the rate of carbon assimilation.\nThese two experiments illustrate several important points: First, it is known that, in general, photochemical reactions are not affected by temperature. However, these experiments clearly show that temperature affects the rate of carbon assimilation, so there must be two sets of reactions in the full process of carbon assimilation. These are, of course, the light-dependent 'photochemical' temperature-independent stage, and the light-independent, temperature-dependent stage. Second, Blackman's experiments illustrate the concept of limiting factors. Another limiting factor is the wavelength of light. Cyanobacteria, which reside several meters underwater, cannot receive the correct wavelengths required to cause photoinduced charge separation in conventional photosynthetic pigments. To combat this problem, a series of proteins with different pigments surround the reaction center. This unit is called a phycobilisome.\nAs carbon dioxide concentrations rise, the rate at which sugars are made by the light-independent reactions increases until limited by other factors. RuBisCO, the enzyme that captures carbon dioxide in the light-independent reactions, has a binding affinity for both carbon dioxide and oxygen. When the concentration of carbon dioxide is high, RuBisCO will fix carbon dioxide. However, if the carbon dioxide concentration is low, RuBisCO will bind oxygen instead of carbon dioxide. This process, called photorespiration, uses energy, but does not produce sugars.\nRuBisCO oxygenase activity is disadvantageous to plants for several reasons:\nThe salvaging pathway for the products of RuBisCO oxygenase activity is more commonly known as photorespiration, since it is characterized by light-dependent oxygen consumption and the release of carbon dioxide.", "page_name": "Photosynthesis", "page_id": "Photosynthesis", "heading": "Factors", "sub_heading": "Factors", "_id": "110--8---1---1", "title": "Photosynthesis and the Phycobilisome"}
{"qas": [{"question": "How did ancient civilizations deal with air pollution?", "answer": ""}, {"question": "What appears to be a key turning point in the creation of significant air pollution levels outside?", "answer": "Metal forging", "ae_score": -0.540842611260038, "qg_score": null}, {"question": "What appears to be a key turning point in the creation of significant air pollution levels outside?", "answer": "Metal forging", "ae_score": -0.540842611260038, "qg_score": null}], "content": "Air pollution has always accompanied civilizations. Pollution started from prehistoric times when man created the first fires. According to a 1983 article in the journal ''Science,'' \"soot found on ceilings of prehistoric caves provides ample evidence of the high levels of pollution that was associated with inadequate ventilation of open fires.\" Metal forging appears to be a key turning point in the creation of significant air pollution levels outside the home. Core samples of glaciers in Greenland indicate increases in pollution associated with Greek, Roman and Chinese metal production, but at that time the pollution was comparatively small and could be handled by nature.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Ancient cultures", "sub_heading": "Ancient cultures", "_id": "111--0---1---1", "title": "Air Pollution During Prehistoric Times"}
{"qas": [{"question": "Why is Lake Karachay considered the most polluted place on earth?", "answer": ""}, {"question": "In what year did king edward i ban the burning of sea-coal?", "answer": "1272", "ae_score": -0.28454829160878153, "qg_score": null}, {"question": "In what year did king edward i ban the burning of sea-coal?", "answer": "1272", "ae_score": -0.28454829160878153, "qg_score": null}], "content": "The burning of coal and wood, and the presence of many horses in concentrated areas made the cities the cesspools of pollution. The Industrial Revolution brought an infusion of untreated chemicals and wastes into local streams that served as the water supply.  King Edward I of England banned the burning of sea-coal by proclamation in London in 1272, after its smoke became a problem. But the fuel was so common in England that this earliest of names for it was acquired because it could be carted away from some shores by the wheelbarrow.\nIt was the industrial revolution that gave birth to environmental pollution as we know it today. London also recorded one of the earlier extreme cases of water quality problems with the Great Stink on the Thames of 1858, which led to construction of the London sewerage system soon afterward. Pollution issues escalated as population growth far exceeded view ability of neighborhoods to handle their waste problem. Reformers began to demand sewer systems, and clean water.\nIn 1870, the sanitary conditions in Berlin were among the worst in Europe.  August Bebel recalled conditions before a modern sewer system was built in the late 1870s:\nThe primitive conditions were intolerable for a world national capital, and the Imperial German  government brought in its scientists, engineers and urban planners to not only solve the deficiencies but to forge Berlin as the world's model city.  A British expert in 1906 concluded that Berlin represented \"the most complete application of science, order and method of public life,\" adding \"it is a marvel of civic administration, the most modern and most perfectly organized city that there is.\"\nThe emergence of great factories and consumption of immense quantities of coal gave rise to unprecedented air pollution and the large volume of industrial chemical discharges added to the growing load of untreated human waste. Chicago and Cincinnati were the first two American cities to enact laws ensuring cleaner air in 1881. Pollution became a major issue in the United States in the early twentieth century, as progressive reformers took issue with air pollution caused by coal burning, water pollution caused by bad sanitation, and street pollution caused by the 3 million horses who worked in American cities in 1900, generating large quantities of urine and manure.  As historian Martin Melosi notes, The generation that first saw automobiles replacing the horses saw cars as \"miracles of cleanliness.\".  By the 1940s, however, automobile-caused smog was a major issue in Los Angeles.\nOther cities followed around the country until early in the 20th century, when the short lived Office of Air Pollution was created under the Department of the Interior. Extreme smog events were experienced by the cities of Los Angeles and Donora, Pennsylvania in the late 1940s, serving as another public reminder.Air pollution would continue to be a problem in England, especially later during the industrial revolution, and extending into the recent past with the Great Smog of 1952.\nAwareness of atmospheric  pollution spread widely after World War II, with fears triggered by reports of radioactive fallout from atomic warfare and testing. Then a non-nuclear event, The Great Smog of 1952 in London, killed at least 4000 people. This prompted some of the first major modern environmental legislation, The Clean Air Act of 1956.\nPollution began to draw major public attention in the United States between the mid-1950s and early 1970s, when Congress passed the Noise Control Act, the Clean Air Act, the Clean Water Act and the National Environmental Policy Act.\nSevere incidents of pollution helped increase consciousness. PCB dumping in the Hudson River resulted in a ban by the EPA on consumption of its fish in 1974. Long-term dioxin contamination at Love Canal starting in 1947 became a national news story in 1978 and led to the Superfund legislation of 1980.  The pollution of industrial land gave rise to the name brownfield, a term now common in city planning.\nThe development of nuclear science introduced radioactive contamination, which can remain lethally radioactive for hundreds of thousands of years. Lake Karachay, named by the Worldwatch Institute as the \"most polluted spot\" on earth, served as a disposal site for the Soviet Union throughout the 1950s and 1960s. Second place may go to the area of Chelyabinsk Russian as the \"Most polluted place on the planet\".\nNuclear weapons continued to be tested in the Cold War, especially in the earlier stages of their development. The toll on the worst-affected populations and the growth since then in understanding about the critical threat to human health posed by radioactivity has also been a prohibitive complication associated with nuclear power. Though extreme care is practiced in that industry, the potential for disaster suggested by incidents such as those at Three Mile Island and Chernobyl pose a lingering specter of public mistrust. Worldwide publicity has been intense on those disasters. Widespread support for test ban treaties has ended almost all nuclear testing in the atmosphere.\nInternational catastrophes such as the wreck of the Amoco Cadiz oil tanker off the coast of Brittany in 1978 and the Bhopal disaster in 1984 have demonstrated the universality of such events and the scale on which efforts to address them needed to engage. The borderless nature of atmosphere and oceans inevitably resulted in the implication of pollution on a planetary level with the issue of global warming. Most recently the term persistent organic pollutant (POP) has come to describe a group of chemicals such as PBDEs and PFCs among others. Though their effects remain somewhat less well understood owing to a lack of experimental data, they have been detected in various ecological habitats far removed from industrial activity such as the Arctic, demonstrating diffusion and bioaccumulation after only a relatively brief period of widespread use.\nA much more recently discovered problem is the Great Pacific Garbage Patch, a huge concentration of plastics, chemical sludge and other debris which has been collected into a large area of the Pacific Ocean by the North Pacific Gyre. This is a less well known pollution problem than the others described above, but nonetheless has multiple and serious consequences such as increasing wildlife mortality, the spread of invasive species and human ingestion of toxic chemicals. Organizations such as 5 Gyres have researched the pollution and, along with artists like Marina DeBris, are working toward publicizing the issue.\nPollution introduced by light at night is becoming a global problem, more severe in urban centres, but nonetheless contaminating also large territories, far away from towns.\nGrowing evidence of local and global pollution and an increasingly informed public over time have given rise to environmentalism and the environmental movement, which generally seek to limit human impact on the environment.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Urban pollution", "sub_heading": "Urban pollution", "_id": "111--1---1---1", "title": "Environmental Pollution and the Global Warming"}
{"qas": [{"question": "Why is it that pollution is bad for the environment, but pollution is good for society?", "answer": ""}, {"question": "What type of activities impose health and clean-up costs on the whole society?", "answer": "Manufacturing", "ae_score": -1.6643163292998107, "qg_score": null}, {"question": "What type of activities impose health and clean-up costs on the whole society?", "answer": "Manufacturing", "ae_score": -1.6643163292998107, "qg_score": null}], "content": "Pollution has cost. Manufacturing activities that cause air pollution impose health and clean-up costs on the whole society, whereas the neighbors of an individual who chooses to fire-proof his home may benefit from a reduced risk of a fire spreading to their own houses. If external costs exist, such as pollution, the producer may choose to produce more of the product than would be produced if the producer were required to pay all associated environmental costs. Because responsibility or consequence for self-directed action lies partly outside the self, an element of externalization is involved. If there are external benefits, such as in public safety, less of the good may be produced than would be the case if the producer were to receive payment for the external benefits to others.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Cost of pollution", "sub_heading": "Cost of pollution", "_id": "111--4---1---1", "title": "Pollution has cost."}
{"qas": [{"question": "If humans are the primary cause of global warming, why is it so hard to stop it?", "answer": ""}, {"question": "What is the dominant source of noise pollution worldwide?", "answer": "motor vehicle", "ae_score": -0.3977455801368443, "qg_score": null}, {"question": "What is the dominant source of noise pollution worldwide?", "answer": "motor vehicle", "ae_score": -0.3977455801368443, "qg_score": null}], "content": "Air pollution comes from both natural and human-made (anthropogenic) sources. However, globally human-made pollutants from combustion, construction, mining, agriculture and warfare are increasingly significant in the air pollution equation.\nMotor vehicle emissions are one of the leading causes of air pollution. China, United States, Russia, India Mexico, and Japan are the world leaders in air pollution emissions. Principal stationary pollution sources include chemical plants, coal-fired power plants, oil refineries,<ref name=Aqueous/> petrochemical plants, nuclear waste disposal activity, incinerators, large livestock farms (dairy cows, pigs, poultry, etc.), PVC factories, metals production factories, plastics factories, and other heavy industry. Agricultural air pollution comes from contemporary practices which include clear felling and burning of natural vegetation as well as spraying of pesticides and herbicides\nAbout 400 million metric tons of hazardous wastes are generated each year. The United States alone produces about 250 million metric tons. Americans constitute less than 5% of the world's population, but produce roughly 25% of the world\u2019s , and generate approximately 30% of world\u2019s waste. In 2007, China has overtaken the United States as the world's biggest producer of , while still far behind based on per capita pollution - ranked 78th among the world's nations.\nIn February 2007, a report by the Intergovernmental Panel on Climate Change (IPCC), representing the work of 2,500 scientists, economists, and policymakers from more than 120 countries, said that humans have been the primary cause of global warming since 1950. Humans have ways to cut greenhouse gas emissions and avoid the consequences of global warming, a major climate report concluded. But to change the climate, the transition from fossil fuels like coal and oil needs to occur within decades, according to the final report this year from the UN's Intergovernmental Panel on Climate Change (IPCC).\nSome of the more common soil contaminants are chlorinated hydrocarbons (CFH), heavy metals (such as chromium, cadmium\u2013found in rechargeable batteries, and lead\u2013found in lead paint, aviation fuel and still in some countries, gasoline), MTBE, zinc, arsenic and benzene. In 2001 a series of press reports culminating in a book called ''Fateful Harvest'' unveiled a widespread practice of recycling industrial byproducts into fertilizer, resulting in the contamination of the soil with various metals. Ordinary municipal landfills are the source of many chemical substances entering the soil environment (and often groundwater), emanating from the wide variety of refuse accepted, especially substances illegally discarded there, or from pre-1970 landfills that may have been subject to little control in the U.S. or EU. There have also been some unusual releases of polychlorinated dibenzodioxins, commonly called ''dioxins'' for simplicity, such as TCDD.\nPollution can also be the consequence of a natural disaster. For example, hurricanes often involve water contamination from sewage, and petrochemical spills from ruptured boats or automobiles. Larger scale and environmental damage is not uncommon when coastal oil rigs or refineries are involved. Some sources of pollution, such as nuclear power plants or oil tankers, can produce widespread and potentially hazardous releases when accidents occur.\nIn the case of noise pollution the dominant source class is the motor vehicle, producing about ninety percent of all unwanted noise worldwide.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Sources and causes", "sub_heading": "Sources and causes", "_id": "111--5---1---1", "title": "Air Pollution in the United States, Russia, India, Mexico, and Japan"}
{"qas": [{"question": "Why is it bad for the environment to have air conditioning?", "answer": ""}, {"question": "What has been found to be widely in the environment?", "answer": "Pollution", "ae_score": -0.3742318307719659, "qg_score": null}, {"question": "What has been found to be widely in the environment?", "answer": "Pollution", "ae_score": -0.3742318307719659, "qg_score": null}], "content": "Adverse air quality can kill many organisms including humans. Ozone pollution can cause respiratory disease, cardiovascular disease, throat inflammation, chest pain, and congestion. Water pollution causes approximately 14,000 deaths per day, mostly due to contamination of drinking water by untreated sewage in developing countries. An estimated 500 million Indians have no access to a proper toilet, Over ten million people in India fell ill with waterborne illnesses in 2013, and 1,535 people died, most of them children. Nearly 500 million Chinese lack access to safe drinking water. A 2010 analysis estimated that 1.2 million people died prematurely each year in China because of air pollution. The WHO estimated in 2007 that air pollution causes half a million deaths per year in India. Studies have estimated that the number of people killed annually in the United States could be over 50,000.\nOil spills can cause skin irritations and rashes. Noise pollution induces hearing loss, high blood pressure, stress, and sleep disturbance. Mercury has been linked to developmental deficits in children and neurologic symptoms. Older people are majorly exposed to diseases induced by air pollution. Those with heart or lung disorders are at additional risk. Children and infants are also at serious risk. Lead and other heavy metals have been shown to cause neurological problems. Chemical and radioactive substances can cause cancer and as well as birth defects.\nPollution has been found to be present widely in the environment. There are a number of effects of this:\nThe Toxicology and Environmental Health Information Program (TEHIP) at the United States National Library of Medicine (NLM) maintains a comprehensive toxicology and environmental health web site that includes access to resources produced by TEHIP and by other government agencies and organizations. This web site includes links to databases, bibliographies, tutorials, and other scientific and consumer-oriented resources. TEHIP also is responsible for the Toxicology Data Network (TOXNET) an integrated system of toxicology and environmental health databases that are available free of charge on the web.\nTOXMAP is a Geographic Information System (GIS) that is part of TOXNET. TOXMAP uses maps of the United States to help users visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs.\nA number of studies show that pollution has an adverse effect on the productivity of both indoor and outdoor workers.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Effects", "sub_heading": "Effects", "_id": "111--6---1---1", "title": "Toxicology and Environmental Health Information Network"}
{"qas": [{"question": "What is pollution control?", "answer": ""}, {"question": "What means the control of emissions and effluents into air, water or soil?", "answer": "Pollution control", "ae_score": -0.39001433252107565, "qg_score": null}, {"question": "What means the control of emissions and effluents into air, water or soil?", "answer": "Pollution control", "ae_score": -0.39001433252107565, "qg_score": null}], "content": "Pollution control is a term used in environmental management. It means the control of emissions and effluents into air, water or soil. Without pollution control, the waste products from overconsumption, heating, agriculture, mining, manufacturing, transportation and other human activities, whether they accumulate or disperse, will degrade the environment. In the hierarchy of controls, pollution prevention and waste minimization are more desirable than pollution control. In the field of land development, low impact development is a similar technique for the prevention of urban runoff.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Pollution control", "sub_heading": "Pollution control", "_id": "111--8---1---1", "title": "Pollution control is a term used in environmental management."}
{"qas": [{"question": "Why is it so important for us to know how much toxic chemicals are in our environment?", "answer": ""}, {"question": "The attendant consequences on viability and population levels fell within the sphere of what?", "answer": "natural selection", "ae_score": -0.7625250431300078, "qg_score": null}, {"question": "The attendant consequences on viability and population levels fell within the sphere of what?", "answer": "natural selection", "ae_score": -0.7625250431300078, "qg_score": null}], "content": "The earliest precursor of pollution generated by life forms would have been a natural function of their existence. The attendant consequences on viability and population levels fell within the sphere of natural selection. These would have included the demise of a population locally or ultimately, species extinction. Processes that were untenable would have resulted in a new balance brought about by changes and adaptations. At the extremes, for any form of life, consideration of pollution is superseded by that of survival.\nFor humankind, the factor of technology is a distinguishing and critical consideration, both as an enabler and an additional source of byproducts. Short of survival, human concerns include the range from quality of life to health hazards. Since science holds experimental demonstration to be definitive, modern treatment of toxicity or environmental harm involves defining a level at which an effect is observable. Common examples of fields where practical measurement is crucial include automobile emissions control, industrial exposure (e.g. Occupational Safety and Health Administration (OSHA) PELs), toxicology (e.g. ), and medicine (e.g. medication and radiation doses).\n\"The solution to pollution is dilution\", is a dictum which summarizes a traditional approach to pollution management whereby sufficiently diluted pollution is not harmful. It is well-suited to some other modern, locally scoped applications such as laboratory safety procedure and hazardous material release emergency management. But it assumes that the dilutant is in virtually unlimited supply for the application or that resulting dilutions are acceptable in all cases.\nSuch simple treatment for environmental pollution on a wider scale might have had greater merit in earlier centuries when physical survival was often the highest imperative, human population and densities were lower, technologies were simpler and their byproducts more benign. But these are often no longer the case. Furthermore, advances have enabled measurement of concentrations not possible before. The use of statistical methods in evaluating outcomes has given currency to the principle of probable harm in cases where assessment is warranted but resorting to deterministic models is impractical or infeasible. In addition, consideration of the environment beyond direct impact on human beings has gained prominence.\nYet in the absence of a superseding principle, this older approach predominates practices throughout the world. It is the basis by which to gauge concentrations of effluent for legal release, exceeding which penalties are assessed or restrictions applied.  One such superseding principle is contained in modern hazardous waste laws in developed countries, as the process of diluting hazardous waste to make it non-hazardous is usually a regulated treatment process.  Migration from pollution dilution to elimination in many cases can be confronted by challenging economical and technological barriers.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Perspectives", "sub_heading": "Perspectives", "_id": "111--9---1---1", "title": "The Solution to Pollution is Dilution"}
{"qas": [{"question": "Why is carbon dioxide bad for the environment?", "answer": ""}, {"question": "What is carbon dioxide sometimes referred to as?", "answer": "pollution", "ae_score": -0.5070212929557961, "qg_score": null}, {"question": "What is carbon dioxide sometimes referred to as?", "answer": "pollution", "ae_score": -0.5070212929557961, "qg_score": null}], "content": "Carbon dioxide, while vital for photosynthesis, is sometimes referred to as pollution, because raised levels of the gas in the atmosphere are affecting the Earth's climate. Disruption of the environment can also highlight the connection between areas of pollution that would normally be classified separately, such as those of water and air. Recent studies have investigated the potential for long-term rising levels of atmospheric carbon dioxide to cause slight but critical increases in the acidity of ocean waters, and the possible effects of this on marine ecosystems.", "page_name": "Pollution", "page_id": "Pollution", "heading": "Greenhouse gases and global warming", "sub_heading": "Greenhouse gases and global warming", "_id": "111--10---1---1", "title": "The Impact of Carbon Dioxide on the Environment"}
{"qas": [{"question": "Why is white flour so rich in Vitamin B?", "answer": ""}, {"question": "Which vitamin is added to breakfast cereals, pastas and vitamin-enriched meal?", "answer": "Riboflavin", "ae_score": -0.5657059631616806, "qg_score": null}, {"question": "Which vitamin is added to breakfast cereals, pastas and vitamin-enriched meal?", "answer": "Riboflavin", "ae_score": -0.5657059631616806, "qg_score": null}], "content": "Food and beverages that provide riboflavin without fortification are milk, cheese, eggs, leaf vegetables, liver, kidneys, legumes, mushrooms, and almonds.\nThe milling of cereals results in considerable loss (up to 60%) of vitamin B, so white flour is enriched in some countries such as US by addition of the vitamin. The enrichment of bread and ready-to-eat breakfast cereals contributes significantly to the dietary supply of vitamin B. Polished rice is not usually enriched, because the vitamin\u2019s yellow color would make the rice visually unacceptable to the major rice-consumption populations. However, most of the flavin content of whole brown rice is retained if the rice is steamed (parboiled) prior to milling. This process drives the flavins in the germ and aleurone layers into the endosperm. Free riboflavin is naturally present in foods along with protein-bound FMN and FAD. Bovine milk contains mainly free riboflavin, with a minor contribution from FMN and FAD. In whole milk, 14% of the flavins are bound noncovalently to specific proteins. Egg white and egg yolk contain specialized riboflavin-binding proteins, which are required for storage of free riboflavin in the egg for use by the developing embryo.\nRiboflavin is added to baby foods, breakfast cereals, pastas and vitamin-enriched meal replacement products. It is difficult to incorporate riboflavin into liquid products because it has poor solubility in water, hence the requirement for riboflavin-5'-phosphate (E101a), a more soluble form of riboflavin. Riboflavin is also used as a food coloring  and as such is designated in Europe as the E number E101.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Function", "sub_heading": "Function", "_id": "112--0--0---1", "title": "Riboflavin and Vitamin B"}
{"qas": [{"question": "How do nutrition labels determine the amount of calories in a serving?", "answer": ""}, {"question": "What is the daily value of riboflavin?", "answer": "1.3 mg", "ae_score": -0.4854880642295866, "qg_score": null}, {"question": "What is the daily value of riboflavin?", "answer": "1.3 mg", "ae_score": -0.4854880642295866, "qg_score": null}], "content": "The Food and Nutrition Board of the U.S. Institute of Medicine updated Estimated Average Requirements (EARs) and Recommended Dietary Allowances (RDAs) in 1998. The current EARs for riboflavin for women and men ages 14 and up are 0.9 mg/day and 1.1 mg/day, respectively; the RDAs are 1.1 and 1.3 mg/day. RDAs are higher than EARs so as to identify amounts that will cover people with higher than average requirements. RDA for pregnancy equals 1.4 mg/day. RDA for lactation equals 1.6 mg/day. For infants up to 12 months the Adequate Intake (AI) is 0.3-0.4 mg/day and for children ages 1\u201313 years the RDA increases with age from 0.5 to 0.9 mg/day. Collectively the EARs, RDAs and ULs (see Toxicity) are referred to as Dietary Reference Intakes. \nFor U.S. food and dietary supplement labeling purposes the amount in a serving is expressed as a percent of Daily Value (%DV). For riboflavin labeling purposes 100% of the Daily Value was 1.7 mg, but as of May 2016 it has been revised to 1.3 mg. A table of the pre-change adult Daily Values is provided at Reference Daily Intake. Food and supplement companies have until July 2018 to comply with the change.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Function", "sub_heading": "Dietary reference intake", "_id": "112--0--1---1", "title": "The Food and Nutrition Board of the U.S. Institute of Medicine Updated Adult Daily Value"}
{"qas": [{"question": "Why do so many people in third world countries require multivitamins?", "answer": ""}, {"question": "Which amino acid has been shown to help prevent malaria?", "answer": "Riboflavin", "ae_score": -0.230558906287647, "qg_score": null}, {"question": "Which amino acid has been shown to help prevent malaria?", "answer": "Riboflavin", "ae_score": -0.230558906287647, "qg_score": null}], "content": "Mild deficiencies can exceed 50% of the population in third world countries and in refugee situations. Deficiency is uncommon in the United States and in other countries that have wheat flour, bread, pasta, corn meal or rice enrichment regulations. In the U.S., starting in the 1940s, flour, corn meal and rice have been fortified with B vitamins as a means of restoring some of what is lost in milling, bleaching and other processing. For adults 20 and older, average intake from food and beverages is 1.8 mg/day for women and 2.5 mg/day for men. An estimated 23% consume a riboflavin-containing dietary supplement that provides on average 10 mg. The U.S. Department of Health and Human Services conducts National Health and Nutrition Examination Survey every two years and reports food results in a series of reports referred to as \"What We Eat In America.\" From NHANES 2011\u20132012, the latest for which data has been reported, estimates are that 8% of women and 3% of men consume less than the RDA. When compared to the lower Estimated Average Requirements, fewer than 3% do not achieve the EAR level. However, anyone choosing a gluten-free or low gluten diet should as a precaution take a multi-vitamin/mineral dietary supplement which provides 100% DV for riboflavin and other B vitamins.\nRiboflavin deficiency (also called ariboflavinosis) results in stomatitis including painful red tongue with sore throat, chapped and fissured lips (cheilosis), and inflammation of the corners of the mouth (angular stomatitis).  There can be oily scaly skin rashes on the scrotum, vulva, philtrum of the lip, or the nasolabial folds.  The eyes can become itchy, watery, bloodshot and sensitive to light.  Due to interference with iron absorption, even mild to moderate riboflavin deficiency results in an anemia with normal cell size and normal hemoglobin content (i.e. normochromic normocytic anemia).  This is distinct from anemia caused by deficiency of folic acid (B) or cyanocobalamin (B), which causes anemia with large blood cells (megaloblastic anemia). Deficiency of riboflavin during pregnancy can result in birth defects including congenital heart defects and limb deformities.\nThe stomatitis symptoms are similar to those seen in pellagra, which is caused by niacin (B) deficiency.  Therefore, riboflavin deficiency is sometimes called \"pellagra sine pellagra\" (pellagra without pellagra), because it causes stomatitis but not widespread peripheral skin lesions characteristic of niacin deficiency.\nRiboflavin has been noted to prolong recovery from malaria, despite preventing growth of plasmodium (the malaria parasite).\nIn other animals, riboflavin deficiency results in lack of growth, failure to thrive, and eventual death. Experimental riboflavin deficiency in dogs results in growth failure, weakness, ataxia, and inability to stand. The animals collapse, become comatose, and die. During the deficiency state, dermatitis develops together with hair loss. Other signs include corneal opacity, lenticular cataracts, hemorrhagic adrenals, fatty degeneration of the kidney and liver, and inflammation of the mucous membrane of the gastrointestinal tract. Post-mortem studies in rhesus monkeys fed a riboflavin-deficient diet revealed about one-third the normal amount of riboflavin was present in the liver, which is the main storage organ for riboflavin in mammals.  Riboflavin deficiency in birds results in low egg hatch rates.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Deficiency", "sub_heading": "Deficiency", "_id": "112--1--0---1", "title": "Riboflavin Deficiency in the United States"}
{"qas": [{"question": "What causes riboflavin deficiency?", "answer": ""}, {"question": "Which vitamin is excreted in the urine of healthy people?", "answer": "Riboflavin", "ae_score": -0.9274263216310425, "qg_score": null}, {"question": "Which vitamin is excreted in the urine of healthy people?", "answer": "Riboflavin", "ae_score": -0.9274263216310425, "qg_score": null}], "content": "Riboflavin is continuously excreted in the urine of healthy individuals, making deficiency relatively common when dietary intake is insufficient. Riboflavin deficiency is usually found together with other nutrient deficiencies, particularly of other water-soluble vitamins.A deficiency of riboflavin can be primary - poor vitamin sources in one's daily diet - or secondary, which may be a result of conditions that affect absorption in the intestine, the body not being able to use the vitamin, or an increase in the excretion of the vitamin from the body.Subclinical deficiency has also been observed in women taking oral contraceptives, in the elderly, in people with eating disorders, chronic alcoholism and in diseases such as HIV, inflammatory bowel disease, diabetes and chronic heart disease. The Celiac Disease Foundation points out that a gluten-free diet may be low in riboflavin (and other nutrients) as enriched wheat flour and wheat foods (bread, pasta, cereals, etc.) is a major dietary contribution to total riboflavin intake.Phototherapy to treat jaundice in infants can cause increased degradation of riboflavin, leading to deficiency if not monitored closely.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Deficiency", "sub_heading": "Causes", "_id": "112--1--2---1", "title": "Riboflavin Deficiency \u2014 A Case Study"}
{"qas": [{"question": "How do multivitamins work?", "answer": ""}, {"question": "What is the daily value of riboflavin?", "answer": "5882%", "ae_score": -0.6813432822733886, "qg_score": null}, {"question": "What is the daily value of riboflavin?", "answer": "5882%", "ae_score": -0.6813432822733886, "qg_score": null}], "content": "Treatment involves a diet which includes an adequate amount of riboflavin containing foods. Multi-vitamin and mineral dietary supplements often contain 100% of the Daily Value for riboflavin, and can be used by persons concerned about an inadequate diet. Over-the-counter dietary supplements are available in the United States with doses as high as 100 mg (5882% of Daily Value), but there is no evidence that these high doses have any additional benefit for healthy people.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Deficiency", "sub_heading": "Treatment", "_id": "112--1--3---1", "title": "Riboflavin Supplements \u2014 Riboflavin Treatment"}
{"qas": [{"question": "What is riboflavin and how does it work?", "answer": ""}, {"question": "Keratoconus is the medical term for which condition?", "answer": "Corneal ectasia", "ae_score": -0.5774704988883218, "qg_score": null}, {"question": "Keratoconus is the medical term for which condition?", "answer": "Corneal ectasia", "ae_score": -0.5774704988883218, "qg_score": null}], "content": "Riboflavin has been used in several clinical and therapeutic situations. For over 30 years, riboflavin supplements have been used as part of the phototherapy treatment of neonatal jaundice. The light used to irradiate the infants breaks down not only bilirubin, the toxin causing the jaundice, but also the naturally occurring riboflavin within the infant's blood, so extra supplementation is necessary.\nOne clinical trial found that high-dose riboflavin appears to be useful alone or along with beta-blockers in the prevention of migraine. A dose of 400 mg daily has been used effectively in the prophylaxis of migraines, especially in combination with a daily supplement of magnesium citrate 500 mg and, in some cases, a supplement of coenzyme Q10. However, two other clinical studies have failed to find any significant results for the effectiveness of B2 as a treatment for migraine.\nRiboflavin in combination with UV light has been shown to be effective in reducing the ability of harmful pathogens found in blood products to cause disease. When UV light is applied to blood products containing riboflavin, the nucleic acids in pathogens are damaged, rendering them unable to replicate and cause disease. Riboflavin and UV light treatment has been shown to be effective for inactivating pathogens in platelets and plasma, and is under development for application to whole blood. Because platelets and red blood cells do not contain a nucleus (i.e. they have no DNA to be damaged) the technique is well-suited for destroying nucleic acid containing pathogens (including viruses, bacteria, parasites, and white blood cells) in blood products.<ref>{{cite journal | vauthors = Hardwick CC, Herivel TR, Hernandez SC, Ruane PH, Goodrich RP | title = Separation, identification and quantification of riboflavin and its photoproducts in blood products using high-performance liquid chromatography with fluorescence detection: a method to support pathogen reduction technology | journal = Photochemistry and Photobiology | volume = 80 | issue = 3 | pages = 609\u2013615 | year = 2004 | pmid = 15382964 | doi = 10.1562/0031-8655(2004)080\nCorneal ectasia is a progressive thinning of the cornea; the most common form of this condition is keratoconus. Collagen cross-linking is a non-surgical treatment intended to slow progression of corneal ectasia by strengthening corneal tissue. The standard protocol calls for application directly to the eye of a 0.1% riboflavin solution for 30 minutes followed by 30 minutes of ultraviolet-A irradiation with a wavelength of 370 nm and power of 3 mW/cm.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Medical uses", "sub_heading": "Medical uses", "_id": "112--2---1---1", "title": "Riboflavin and Collagen Cross-Linking"}
{"qas": [{"question": "Why do we use riboflavin in tanks?", "answer": ""}, {"question": "What is fluorescent under the uv light?", "answer": "riboflavin", "ae_score": -0.7415502010015093, "qg_score": null}, {"question": "What is fluorescent under the uv light?", "answer": "riboflavin", "ae_score": -0.7415502010015093, "qg_score": null}], "content": "Because riboflavin is fluorescent under UV light, dilute solutions (0.015-0.025% w/w) are often used to detect leaks or to demonstrate coverage in an industrial system such a chemical blend tank or bioreactor. (See the ASME BPE section on Testing and Inspection for additional details.)", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Industrial uses", "sub_heading": "Industrial uses", "_id": "112--3---1---1", "title": "Riboflavin Detection in Industrial Systems"}
{"qas": [{"question": "Why is riboflavin so bad for you?", "answer": ""}, {"question": "What does the u.s. institute of medicine call ULs?", "answer": "Tolerable Upper Intake Levels", "ae_score": -0.40681293198834584, "qg_score": null}, {"question": "What does the u.s. institute of medicine call ULs?", "answer": "Tolerable Upper Intake Levels", "ae_score": -0.40681293198834584, "qg_score": null}], "content": "In humans, there is no evidence for riboflavin toxicity produced by excessive intakes, in part because it has lower water solubility than other B vitamins, because absorption becomes less efficient as doses increase, and because what excess is absorbed is excreted via the kidneys into urine. Even when 400 mg of riboflavin per day was given orally to subjects in one study for three months to investigate the efficacy of riboflavin in the prevention of migraine headache, no short-term side effects were reported. Although toxic doses can be administered by injection, any excess at nutritionally relevant doses is excreted in the urine, imparting a bright yellow color when in large quantities.\nThe Food and Nutrition Board of the U.S. Institute of Medicine sets Tolerable Upper Intake Levels (known as ULs) for vitamins and minerals when evidence is sufficient. In the case of riboflavin there is no UL, as there is no human data for adverse effects from high doses. The European Food Safety Authority reviewed the same safety question and also reached the conclusion that there was not sufficient evidence to set a UL for riboflavin.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Toxicity", "sub_heading": "Toxicity", "_id": "112--4---1---1", "title": "Riboflavin Toxicity in Humans"}
{"qas": [{"question": "Why is riboflavin yellow?", "answer": ""}, {"question": "Where does riboflavin come from in plants?", "answer": "filamentous fungi", "ae_score": -2.0292042176705576, "qg_score": null}, {"question": "Where does riboflavin come from in plants?", "answer": "filamentous fungi", "ae_score": -2.0292042176705576, "qg_score": null}], "content": "Various biotechnological processes have been developed for industrial scale riboflavin biosynthesis using different microorganisms, including filamentous fungi such as ''Ashbya gossypii'', ''Candida famata'' and ''Candida flaveri'',  as well as the bacteria ''Corynebacterium ammoniagenes'' and ''Bacillus subtilis''. The latter organism has been genetically modified to both increase the bacteria's production of riboflavin and to introduce an antibiotic (ampicillin) resistance marker, and is now successfully employed at a commercial scale to produce riboflavin for feed and food fortification purposes. The chemical company BASF has installed a plant in South Korea, which is specialized on riboflavin production using ''Ashbya gossypii''. The concentrations of riboflavin in their modified strain are so high, that the mycelium has a reddish/brownish color and accumulates riboflavin crystals in the vacuoles, which will eventually burst the mycelium. Riboflavin is sometimes overproduced, possibly as a protective mechanism, by certain bacteria in the presence of high concentrations of hydrocarbons or aromatic compounds.  One such organism is ''Micrococcus luteus'' (American Type Culture Collection strain number ATCC 49442), which develops a yellow color due to production of riboflavin while growing on pyridine, but not when grown on other substrates, such as succinic acid.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "Industrial synthesis", "sub_heading": "Industrial synthesis", "_id": "112--5---1---1", "title": "''Ashbya gossypii'' \u2014"}
{"qas": [{"question": "How did scientists figure out how to get vitamin B?", "answer": ""}, {"question": "Which vitamin was isolated from egg white in 1933?", "answer": "Ovoflavin", "ae_score": -0.4733610859624999, "qg_score": null}, {"question": "Which vitamin was isolated from egg white in 1933?", "answer": "Ovoflavin", "ae_score": -0.4733610859624999, "qg_score": null}], "content": "Vitamin B was originally considered to have two components, a heat-labile vitamin B and a heat-stable vitamin B. In the 1920s, vitamin B was thought to be the factor necessary for preventing pellagra. In 1923, Paul Gyorgy in Heidelberg was investigating egg-white injury in rats; the curative factor for this condition was called vitamin H (which is now called biotin or vitamin B7). Since both pellagra and vitamin H deficiency were associated with dermatitis, Gyorgy decided to test the effect of vitamin B on vitamin H deficiency in rats. He enlisted the service of Wagner-Jauregg in Kuhn\u2019s laboratory. In 1933, Kuhn, Gyorgy, and Wagner found that thiamin-free extracts of yeast, liver, or rice bran prevented the growth failure of rats fed a thiamin-supplemented diet.\nFurther, the researchers noted that a yellow-green fluorescence in each extract promoted rat growth, and that the intensity of fluorescence was proportional to the effect on growth. This observation enabled them to develop a rapid chemical and bioassay to isolate the factor from egg white in 1933, they called it Ovoflavin. The same group then isolated the same preparation (a growth-promoting compound with yellow-green fluorescence) from whey using the same procedure (lactoflavin). In 1934 Kuhn\u2019s group identified the structure of so-called flavin and synthesized vitamin B.", "page_name": "Riboflavin", "page_id": "Riboflavin", "heading": "History", "sub_heading": "History", "_id": "112--6---1---1", "title": "Vitamin B \u2014 The Cure for pellagra"}
{"qas": [{"question": "Where did the word \"sugar\" come from?", "answer": ""}, {"question": "What is the english word for sugar?", "answer": "sugar", "ae_score": -1.1030653286144443, "qg_score": null}, {"question": "What is the english word for sugar?", "answer": "sugar", "ae_score": -1.1030653286144443, "qg_score": null}], "content": "The etymology reflects the spread of the commodity. The English word \"sugar\" originates from the Sanskrit \u0936\u0930\u094d\u0915\u0930\u093e ''\u015barkar\u0101'', via Persian \u0634\u06a9\u0631 ''shakkar''.  It most probably came to England by way of Italian merchants. The contemporary Italian word is ''zucchero'', whereas the Spanish and Portuguese words, ''az\u00facar'' and ''a\u00e7\u00facar'' respectively, have kept a trace of the Arabic definite article. The Old French word is ''zuchre'' \u2013 contemporary French ''sucre''. The earliest Greek word attested is \u03c3\u03ac\u03ba\u03c7\u03b1\u03c1\u03b9\u03c2 (''s\u00e1kk\u02b0aris''). A satisfactory ''pedigree'' explaining the spread of the word has yet to be done. The English word ''jaggery'', a coarse brown sugar made from date palm sap or sugarcane juice, has a similar etymological origin; Portuguese ''xagara'' or ''jagara'', from the Sanskrit ''\u015barkar\u0101''.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Etymology", "sub_heading": "Etymology", "_id": "113--0---1---1", "title": "Sugar | Etymology"}
{"qas": [{"question": "Why is sugar such a big deal in India?", "answer": ""}, {"question": "What is the most popular sweetener in the world?", "answer": "honey", "ae_score": -0.4825186206281202, "qg_score": null}, {"question": "What is the most popular sweetener in the world?", "answer": "honey", "ae_score": -0.4825186206281202, "qg_score": null}], "content": "Sugar has been produced in the Indian subcontinent since ancient times. It was not plentiful or cheap in early times and honey was more often used for sweetening in most parts of the world. Originally, people chewed raw sugarcane to extract its sweetness. Sugarcane was a native of tropical South Asia and Southeast Asia.<ref name=Kiple/> Different species seem to have originated from different locations with ''Saccharum barberi'' originating in India and ''S. edule'' and ''S. officinarum'' coming from New Guinea. One of the earliest historical references to sugarcane is in Chinese manuscripts dating back to 8th century BC that state that the use of sugarcane originated in India.\nSugar was found in Europe by the 1st century AD, but only as an imported medicine, and not as a food. The Greek physician Dioscorides in the 1st century (AD) described sugar in his medical treatise De Materia Medica, and Pliny the Elder, a 1st century (AD) Roman, described sugar in his Natural History: \"Sugar is made in Arabia as well, but Indian sugar is better. It is a kind of honey found in cane, white as gum, and it crunches between the teeth. It comes in lumps the size of a hazelnut. Sugar is used only for medical purposes.\"<ref name=faas/>\nSugar remained relatively unimportant until the Indians discovered methods of turning sugarcane juice into granulated crystals that were easier to store and to transport. Crystallized sugar was discovered by the time of the Imperial Guptas, around the 5th century AD.<ref name=Adas/> In the local Indian language, these crystals were called ''khanda'' (Devanagari:\u0916\u0923\u094d\u0921,), which is the source of the word ''candy''.\nIndian sailors, who carried clarified butter and sugar as supplies, introduced knowledge of sugar on the various trade routes they travelled.<ref name=Adas/> Buddhist monks, as they travelled around, brought sugar crystallization methods to China. During the reign of Harsha (r. 606\u2013647) in North India, Indian envoys in Tang China taught methods of cultivating sugarcane after Emperor Taizong of Tang (r. 626\u2013649) made known his interest in sugar. China then established its first sugarcane plantations in the seventh century. Chinese documents confirm at least two missions to India, initiated in 647 AD, to obtain technology for sugar refining. In South Asia, the Middle East and China, sugar became a staple of cooking and desserts.\nCrusaders brought sugar home with them to Europe after their campaigns in the Holy Land, where they encountered caravans carrying \"sweet salt\". Early in the 12th century, Venice acquired some villages near Tyre and set up estates to produce sugar for export to Europe, where it supplemented honey, which had previously been the only available sweetener.Crusade chronicler William of Tyre, writing in the late 12th century, described sugar as \"very necessary for the use and health of mankind\". In the 15th century, Venice was the chief sugar refining and distribution centre in Europe.<ref name=gr1/>", "page_name": "Sugar", "page_id": "Sugar", "heading": "History", "sub_heading": "History", "_id": "113--1--0---1", "title": "The History of Sugar"}
{"qas": [{"question": "How did the United Kingdom become the world's largest producer of sugar?", "answer": ""}, {"question": "What is the name of the cutting tool used to cut sugar?", "answer": "sugar nips", "ae_score": -0.22301417043943333, "qg_score": null}, {"question": "What is the name of the cutting tool used to cut sugar?", "answer": "sugar nips", "ae_score": -0.22301417043943333, "qg_score": null}], "content": "In August 1492, Christopher Columbus stopped at La Gomera in the Canary Islands, for wine and water, intending to stay only four days. He became romantically involved with the governor of the island, Beatriz de Bobadilla y Ossorio, and stayed a month. When he finally sailed, she gave him cuttings of sugarcane, which became the first to reach the New World.\nThe first sugar cane harvest was conducted in Hispaniola in 1501, and many sugar mills had been constructed in Cuba and Jamaica by the 1520s. The Portuguese took sugar cane to Brazil. By 1540, there were 800 cane sugar mills in Santa Catarina Island and another 2,000 on the north coast of Brazil, Demarara, and Surinam.\nSugar was a luxury in Europe until the 18th century, when it became more widely available. It then became popular and by the 19th century, sugar came to be considered a necessity. This evolution of taste and demand for sugar as an essential food ingredient unleashed major economic and social changes. It drove, in part, colonization of tropical islands and nations where labor-intensive sugarcane plantations and sugar manufacturing could thrive. The demand for cheap labor to perform the hard work involved in its cultivation and processing increased the demand for the slave trade from Africa (in particular West Africa). After slavery was abolished, there was high demand for indentured laborers from South Asia (in particular India). Millions of slave and indentured laborers were brought into the Caribbean and the Americas, Indian Ocean colonies, southeast Asia, Pacific Islands, and East Africa and Natal. The modern ethnic mix of many nations that have been settled in the last two centuries has been influenced by the demand for sugar.\nSugar also led to some industrialization of areas where sugar cane was grown. For example, Lieutenant J. Paterson, of the Bengal establishment, persuaded the British Government that sugar cane could be cultivated in British India with many advantages and at less expense than in the West Indies; as a result, sugar factories were established in Bihar in eastern India.\nDuring the Napoleonic Wars, sugar beet production increased in continental Europe because of the difficulty of importing sugar when shipping was subject to blockade. By 1880, the sugar beet was the main source of sugar in Europe. It was cultivated in Lincolnshire and other parts of England, although the United Kingdom continued to import the main part of its sugar from its colonies.\nUntil the late nineteenth century, sugar was purchased in loaves, which had to be cut using implements called sugar nips. In later years, granulated sugar was more usually sold in bags.\nSugar cubes were produced in the nineteenth century. The first inventor of a process to make sugar in cube form was the Moravian Jakub Kry\u0161tof Rad, director of a sugar company in Da\u010dice. He began sugar cube production after being granted a five-year patent for the process on January 23, 1843. Henry Tate of Tate & Lyle was another early manufacturer of sugar cubes at his refineries in Liverpool and London. Tate purchased a patent for sugar cube manufacture from German Eugen Langen, who in 1872 had invented a different method of processing of sugar cubes.", "page_name": "Sugar", "page_id": "Sugar", "heading": "History", "sub_heading": "Modern history", "_id": "113--1--1---1", "title": "The History of Sugar Cane"}
{"qas": [{"question": "What is the difference between sugars and carbohydrates?", "answer": ""}, {"question": "How many people died in the 2008 georgia sugar refinery explosion?", "answer": "14", "ae_score": -0.47069672815822844, "qg_score": null}, {"question": "How many people died in the 2008 georgia sugar refinery explosion?", "answer": "14", "ae_score": -0.47069672815822844, "qg_score": null}], "content": "Scientifically, ''sugar'' loosely refers to a number of carbohydrates, such as monosaccharides, disaccharides, or oligosaccharides. Monosaccharides are also called \"simple sugars,\" the most important being glucose. Almost all sugars have the formula  (n is between 3 and 7). Glucose has the molecular formula . The names of typical sugars end with -''ose'', as in \"glucose\" and \"fructose\". Sometimes such words may also refer to any types of carbohydrates soluble in water. The acyclic mono- and disaccharides contain either aldehyde groups or ketone groups. These carbon-oxygen double bonds (C=O) are the reactive centers. All saccharides with more than one ring in their structure result from two or more monosaccharides joined by glycosidic bonds with the resultant loss of a molecule of water () per bond.\nMonosaccharides in a closed-chain form can form glycosidic bonds with other monosaccharides, creating disaccharides (such as sucrose) and polysaccharides (such as starch). Enzymes must hydrolyze or otherwise break these glycosidic bonds before such compounds become metabolized. After digestion and absorption the principal monosaccharides present in the blood and internal tissues include glucose, fructose, and galactose. Many pentoses and hexoses can form ring structures. In these closed-chain forms, the aldehyde or ketone group remains non-free, so many of the reactions typical of these groups cannot occur. Glucose in solution exists mostly in the ring form at equilibrium, with less than 0.1% of the molecules in the open-chain form.<ref name=Pigman/>\nBiopolymers of sugars are common in nature. Through photosynthesis, plants produce glyceraldehyde-3-phosphate (G3P), a phosphated 3-carbon sugar that is used by the cell to make monosaccharides such as glucose () or (as in cane and beet) sucrose (). Monosaccharides may be further converted into structural polysaccharides such as cellulose and pectin for cell wall construction or into energy reserves in the form of storage polysaccharides such as starch or inulin. Starch, consisting of two different polymers of glucose, is a readily degradable form of chemical energy stored by cells, and can be converted to other types of energy.<ref name=Pigman/> Another polymer of glucose is cellulose, which is a linear chain composed of several hundred or thousand glucose units. It is used by plants as a structural component in their cell walls. Humans can digest cellulose only to a very limited extent, though ruminants can do so with the help of symbiotic bacteria in their gut. DNA and RNA are built up of the monosaccharides deoxyribose and  ribose, respectively. Deoxyribose has the formula  and ribose the formula .\nBecause sugars burn easily when exposed to flame, the handling of sugars risks dust explosion. The 2008 Georgia sugar refinery explosion, which killed 14 persons and injured 40, and destroyed most of the refinery, was caused by the ignition of sugar dust.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Chemistry", "sub_heading": "Chemistry", "_id": "113--2---1---1", "title": "Sugar | Chemistry"}
{"qas": [{"question": "What is the difference between lactose, maltose, sucrose and sucrose?", "answer": ""}, {"question": "What is the general formula for sucrose?", "answer": "CHO", "ae_score": -0.3341188912785546, "qg_score": null}, {"question": "What is the general formula for sucrose?", "answer": "CHO", "ae_score": -0.3341188912785546, "qg_score": null}], "content": "Fructose, galactose, and glucose are all simple sugars, monosaccharides, with the general formula CHO. They have five hydroxyl groups (\u2212OH) and a carbonyl group (C=O) and are cyclic when dissolved in water. They each exist as several isomers with dextro- and laevo-rotatory forms that cause polarized light to diverge to the right or the left.\nLactose, maltose, and sucrose are all compound sugars, disaccharides, with the general formula CHO. They are formed by the combination of two monosaccharide molecules with the exclusion of a molecule of water.<ref name=Manual/>", "page_name": "Sugar", "page_id": "Sugar", "heading": "Types of sugar", "sub_heading": "Types of sugar", "_id": "113--3---1---1", "title": "Sugar | Types of sugar"}
{"qas": [{"question": "How are sugar beets made?", "answer": ""}, {"question": "Which vegetable has the latin name beta vulgaris?", "answer": "Sugar beet", "ae_score": -0.8166732273679582, "qg_score": null}, {"question": "Which vegetable has the latin name beta vulgaris?", "answer": "Sugar beet", "ae_score": -0.8166732273679582, "qg_score": null}], "content": "Sugar beet (''Beta vulgaris'') is a biennial plant in the Family Amaranthaceae, the tuberous root of which contains a high proportion of sucrose. It is cultivated in temperate regions with adequate rainfall and requires a fertile soil. The crop is harvested mechanically in the autumn and the crown of leaves and excess soil removed. The roots do not deteriorate rapidly and may be left in a clamp in the field for some weeks before being transported to the processing plant. Here the crop is washed and sliced and the sugar extracted by diffusion. Milk of lime is added to the raw juice  and carbonatated in a number of stages in order to purify it. Water is evaporated by boiling the syrup under a vacuum. The syrup is then cooled and seeded with sugar crystals. The white sugar that crystallizes out can be separated in a centrifuge and dried. It requires no further refining.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Production", "sub_heading": "Production", "_id": "113--4--0---1", "title": "Sugar beet (''Beta vulgaris'')"}
{"qas": [{"question": "How is sugar made?", "answer": ""}, {"question": "Sugar cane belongs to which family of plants?", "answer": "Poaceae", "ae_score": -0.7204644710791954, "qg_score": null}, {"question": "Sugar cane belongs to which family of plants?", "answer": "Poaceae", "ae_score": -0.7204644710791954, "qg_score": null}], "content": "Sugarcane (''Saccharum spp.'') is a perennial grass in the family Poaceae. It is cultivated in tropical and sub-tropical regions for the sucrose that is found in its stems. It requires a frost-free climate with sufficient rainfall during the growing season to make full use of the plant's great growth potential. The crop is harvested mechanically or by hand, chopped into lengths and conveyed rapidly to the processing plant. Here, it is either milled and the juice extracted with water or extracted by diffusion. The juice is then clarified with lime and heated to destroy enzymes. The resulting thin syrup is concentrated in a series of evaporators, after which further water is removed by evaporation in vacuum containers. The resulting supersaturated solution is seeded with sugar crystals and the sugar crystallizes out and is separated from the fluid and dried. Molasses is a by-product of the process and the fiber from the stems, known as bagasse, is burned to provide energy for the sugar extraction process. The crystals of raw sugar have a sticky brown coating and either can be used as they are or can be bleached by sulfur dioxide or can be treated in a carbonatation process to produce a whiter product.  About 2500 l of irrigation water is needed for every one kilogram of sugar produced.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Production", "sub_heading": "Sugarcane", "_id": "113--4--1---1", "title": "Sugarcane (''Saccharum spp.'')"}
{"qas": [{"question": "What is the difference between refined sugar and raw sugar?", "answer": ""}, {"question": "What is the first stage of the sugar refining process called?", "answer": "affination", "ae_score": -0.4556237496780628, "qg_score": null}, {"question": "What is the first stage of the sugar refining process called?", "answer": "affination", "ae_score": -0.4556237496780628, "qg_score": null}], "content": "Refined sugar is made from raw sugar that has undergone a refining process to remove the molasses. Raw sugar is a sucrose which is synthesized from sugarcane or sugar beet and cannot immediately be consumed before going through the refining process to produce refined sugar or white sugar.\nThe sugar may be transported in bulk to the country where it will be used and the refining process often takes place there. The first stage is known as affination and involves immersing the sugar crystals in a concentrated syrup that softens and removes the sticky brown coating without dissolving them. The crystals are then separated from the liquor and dissolved in water. The resulting syrup is treated either by a carbonatation or by a phosphatation process. Both involve the precipitation of a fine solid in the syrup and when this is filtered out, many of the impurities are removed at the same time. Removal of colour is achieved by using either a granular activated carbon or an ion-exchange resin. The sugar syrup is concentrated by boiling and then cooled and seeded with sugar crystals, causing the sugar to crystallize out. The liquor is spun off in a centrifuge and the white crystals are dried in hot air and ready to be packaged or used. The surplus liquor is made into refiners' molasses.The International Commission for Uniform Methods of Sugar Analysis sets standards for the measurement of the purity of refined sugar, known as ICUMSA numbers; lower numbers indicate a higher level of purity in the refined sugar.\nRefined sugar is widely used for industrial needs for higher quality. Refined sugar is purer (ICUMSA below 300) than raw sugar (ICUMSA over 1,500). The level of purity associated with the colors of sugar, expressed by standard number ICUMSA (International Commission for Uniform Methods of sugar Analysis), the smaller ICUMSA numbers indicate that higher purity of sugar.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Production", "sub_heading": "Refining", "_id": "113--4--2---1", "title": "Refined Sugar (Refined Sugar) \u2014 ICUMSA"}
{"qas": [{"question": "Why is Brazil the largest exporter of sugar in the world?", "answer": ""}, {"question": "Which country has the highest per capita consumption of sugar?", "answer": "Brazil", "ae_score": -0.2548649693098211, "qg_score": null}, {"question": "Which country has the highest per capita consumption of sugar?", "answer": "Brazil", "ae_score": -0.2548649693098211, "qg_score": null}], "content": "The five largest producers of sugar in 2011 were Brazil, India, the European Union, China and Thailand. In the same year, the largest exporter of sugar was Brazil, distantly followed by Thailand, Australia and India. The largest importers were the European Union, United States and Indonesia. At present, Brazil has the highest per capita consumption of sugar, followed by Australia, Thailand, and the European Union.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Production", "sub_heading": "Producing countries", "_id": "113--4--3---1", "title": "Sugar | Production | Producing countries"}
{"qas": [{"question": "Why is the sugar content of food so low in the US?", "answer": ""}, {"question": "What is an important part of the human diet?", "answer": "sugar", "ae_score": -0.35938211453057306, "qg_score": null}, {"question": "What is an important part of the human diet?", "answer": "sugar", "ae_score": -0.35938211453057306, "qg_score": null}], "content": "In most parts of the world, sugar is an important part of the human diet, making food more palatable and providing food energy. After cereals and vegetable oils, sugar derived from sugarcane and beet provided more kilocalories per capita per day on average than other food groups. According to the FAO, an average of 24 kg of sugar, equivalent to over 260 food calories per day, was consumed annually per person of all ages in the world in 1999. Even with rising human populations, sugar consumption is expected to increase to 25.1 kg per person per year by 2015.\nData collected in multiple nationwide surveys between 1999 and 2008 show that the intake of added sugars has declined by 24 percent with declines occurring in all age, ethnic and income groups.\nThe per capita consumption of refined sugar in the United States has varied between 27 and in the last 40 years. In 2008, American per capita total consumption of sugar and sweeteners, exclusive of artificial sweeteners, equalled 61.9 kg per year. This consisted of 29.65 kg pounds of refined sugar and 31 kg pounds of corn-derived sweeteners per person.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Consumption", "sub_heading": "Consumption", "_id": "113--5---1---1", "title": "Sugar Consumption in the United States"}
{"qas": [{"question": "What is a sugar addiction?", "answer": ""}, {"question": "What is the term for the relationship between sugar and addiction?", "answer": "Sugar addiction", "ae_score": -0.16692218590370003, "qg_score": null}, {"question": "What is the term for the relationship between sugar and addiction?", "answer": "Sugar addiction", "ae_score": -0.16692218590370003, "qg_score": null}], "content": "Sugar addiction is the term for the relationship between sugar and the various aspects of food addiction including \"bingeing, withdrawal, craving and cross-sensitization\".  Some scientists assert that consumption of sweets or sugar could have a heroin addiction-like effect.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Health effects", "_id": "113--6--0---1", "title": "Sugar Addiction \u2014 What is Sugar Addiction?"}
{"qas": [{"question": "How do they determine the amount of carbohydrates in a food?", "answer": ""}, {"question": "What is a method used by diabetics for planning their meals?", "answer": "carbohydrate counting", "ae_score": -0.6579837700396511, "qg_score": null}, {"question": "What is a method used by diabetics for planning their meals?", "answer": "carbohydrate counting", "ae_score": -0.6579837700396511, "qg_score": null}], "content": "Carbohydrates are classified according to their glycemic index, a system for measuring how quickly a food that is eaten raises blood sugar levels, and glycemic load, which takes into account both the glycemic index and the amount of carbohydrate in the food. This has led to carbohydrate counting, a method used by diabetics for planning their meals.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Blood glucose levels", "_id": "113--6--2---1", "title": "Carbohydrates are classified according to their glycemic index, g"}
{"qas": [{"question": "Why is sugar bad for you?", "answer": ""}, {"question": "What type of performance has been shown to be impaired by switching from a carbohydrate diet to?", "answer": "Cardiac", "ae_score": null, "qg_score": null}, {"question": "What type of performance has been shown to be impaired by switching from a carbohydrate diet to?", "answer": "Cardiac", "ae_score": null, "qg_score": null}], "content": "Studies in animals have suggested that chronic consumption of refined sugars can contribute to metabolic and cardiovascular dysfunction.  Some experts have suggested that refined fructose is more damaging than refined glucose in terms of cardiovascular risk.  Cardiac performance has been shown to be impaired by switching from a carbohydrate diet including fiber to a high-carbohydrate diet.Switching from saturated fatty acids to carbohydrates with high glycemic index values shows a statistically-significant increase in the risk of myocardial infarction. Other studies have shown that the risk of developing coronary heart disease is decreased by adopting a diet high in polyunsaturated fatty acids but low in sugar, whereas a low-fat, high-carbohydrate diet brings no reduction. This suggests that consuming a diet with a high glycemic load typical of the \"junk food\" diet is strongly associated with an increased risk of developing coronary heart disease.\nThe consumption of added sugars has been positively associated with multiple measures known to increase cardiovascular disease risk amongst adolescents as well as adults.Studies are suggesting that the impact of refined carbohydrates or high glycemic load carbohydrates are more significant than the impact of saturated fatty acids on cardiovascular disease.A high dietary intake of sugar (in this case, sucrose or disaccharide) can substantially increase the risk of heart and vascular diseases. According to a Swedish study of 4301 people undertaken by Lund University and Malm\u00f6 University College, sugar was associated with higher levels of bad blood lipids, causing a high level of small and medium low-density lipoprotein (LDL) and reduced high-density lipoprotein (HDL). In contrast, the amount of fat eaten did not affect the level of blood fats. Incidentally quantities of alcohol and protein were linked to an increase in the good HDL blood fat.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Cardiovascular disease", "_id": "113--6--3---1", "title": "The Impact of Sugar on Cardiovascular Disease"}
{"qas": [{"question": "Why is sugar bad for you?", "answer": ""}, {"question": "Sugar can lead to what in children?", "answer": "hyperactivity", "ae_score": -0.6721513721513153, "qg_score": null}, {"question": "Sugar can lead to what in children?", "answer": "hyperactivity", "ae_score": -0.6721513721513153, "qg_score": null}], "content": "There is a common notion that sugar leads to hyperactivity, in particular in children, but studies and meta-studies question or address this issue. Some articles and studies do refer to the increasing evidence supporting the links between refined sugar and hyperactivity. The WHO FAO meta-study suggests that such inconclusive results are to be expected when some studies do not effectively segregate or control for free sugars as opposed to sugars still in their natural form (entirely unrefined) while others do. One study followed thirty-five 5-to-7-year-old boys who were reported by their mothers to be behaviorally \"sugar-sensitive.\" They were randomly assigned to experimental and control groups. In the experimental group, mothers were told that their children were fed sugar, and, in the control group, mothers were told that their children received a placebo. In fact, all children received the placebo, but mothers in the sugar expectancy condition rated their children as significantly more hyperactive. This result suggests that the real effect of sugar is that it increases worrying among parents with preconceived notions.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Hyperactivity", "_id": "113--6--4---1", "title": "Sugar-Sensitivity and Hyperactivity"}
{"qas": [{"question": "Is it true that sugar is bad for you?", "answer": ""}, {"question": "In what year did a meta-analysis of eleven studies involving 310,819 participants?", "answer": "2010", "ae_score": null, "qg_score": null}, {"question": "In what year did a meta-analysis of eleven studies involving 310,819 participants?", "answer": "2010", "ae_score": null, "qg_score": null}], "content": "Controlled trials have now shown unequivocally that consumption of sugar-sweetened beverages increases body weight and body fat, and that replacement of sugar by artificial sweeteners reduces weight.Studies on the link between sugars and diabetes are inconclusive, with some suggesting that eating excessive amounts of sugar does not increase the risk of diabetes, although the extra calories from consuming large amounts of sugar can lead to obesity, which may itself increase the risk of developing this metabolic disease. Other studies show correlation between refined sugar (free sugar) consumption and the onset of diabetes, and negative correlation with the consumption of fiber. These included a 2010 meta-analysis of eleven studies involving 310,819 participants and 15,043 cases of type 2 diabetes. This found that \"SSBs (sugar-sweetened beverages) may increase the risk of metabolic syndrome and type 2 diabetes not only through obesity but also by increasing dietary glycemic load, leading to insulin resistance, \u03b2-cell dysfunction, and inflammation\". As an overview to consumption related to chronic disease and obesity, the World Health Organization's independent meta-studies specifically distinguish free sugars (\"all monosaccharides and disaccharides added to foods by the manufacturer, cook or consumer, plus sugars naturally present in honey, syrups and fruit juices\") from sugars occurring naturally in food. The reports prior to 2000 set the limits for free sugars at a maximum of 10% of carbohydrate intake, measured by energy, rather than mass, and since 2002 have aimed for a level across the entire population of less than 10%. The consultation committee recognized that this goal is \"controversial. However, the Consultation considered that the studies showing no effect of free sugars on excess weight have limitations\". A 2015 ''New York Times'' report noted that \"a review of beverage studies, published in the journal ''PLOS Medicine'', found that those funded by Coca-Cola, PepsiCo, the American Beverage Association and the sugar industry were five times more likely to find no link between sugary drinks and weight gain than studies whose authors reported no financial conflicts.\"<ref name=NYT01/>", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Obesity and diabetes", "_id": "113--6--5---1", "title": "Sugar and Obesity"}
{"qas": [{"question": "What is the role of free sugars in tooth decay?", "answer": ""}, {"question": "Along with starchy foods and starch, what food has been shown to have a negative?", "answer": "fresh fruit", "ae_score": -0.9193604278478373, "qg_score": null}, {"question": "Along with starchy foods and starch, what food has been shown to have a negative?", "answer": "fresh fruit", "ae_score": -0.9193604278478373, "qg_score": null}], "content": "In regard to contributions to tooth decay, the role of free sugars is also recommended to be below an absolute maximum of 10% of energy intake, with a minimum of zero.  There is \"convincing evidence from human intervention studies, epidemiological studies, animal studies and experimental studies, for an association between the amount and frequency of free sugars intake and dental caries\" while other sugars (complex carbohydrate) consumption is normally associated with a lower rate of dental caries. Lower rates of tooth decay have been seen in individuals with hereditary fructose intolerance.\nAlso, studies have shown that the consumption of sugar and starch have different impacts on oral health with the ingestion of starchy foods and fresh fruit being associated with low levels of dental caries.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Health effects", "sub_heading": "Tooth decay", "_id": "113--6--6---1", "title": "The role of free sugars in tooth decay"}
{"qas": [{"question": "Why is it recommended that adults and children eat the same amount of sugar?", "answer": ""}, {"question": "Monosaccharides and disaccharide are examples of what?", "answer": "Free sugars", "ae_score": -0.5212182883738194, "qg_score": null}, {"question": "Monosaccharides and disaccharide are examples of what?", "answer": "Free sugars", "ae_score": -0.5212182883738194, "qg_score": null}], "content": "The World Health Organization (WHO) recommends that both adults and children reduce the intake of free sugars to less than 10% of total energy intake. A reduction to below 5% of total energy intake brings additional health benefits, especially in what regards dental caries. These recommendations were based on the totality of available evidence reviewed regarding the relationship between free sugars intake and body weight and dental caries.\nFree sugars include monosaccharides and disaccharides added to foods and beverages by the manufacturer, cook or consumer, and sugars naturally present in honey, syrups, fruit juices and fruit juice concentrates.", "page_name": "Sugar", "page_id": "Sugar", "heading": "Recommended dietary intake", "sub_heading": "Recommended dietary intake", "_id": "113--7---1---1", "title": "The World Health Organization (WHO) recommends that both adults and children reduce the intake of"}
{"qas": [{"question": "Why do different types of sugar have different densities?", "answer": ""}, {"question": "What is the most popular sugar in the united states?", "answer": "Domino Sugar", "ae_score": -0.20908376032994289, "qg_score": null}, {"question": "What is the most popular sugar in the united states?", "answer": "Domino Sugar", "ae_score": -0.20908376032994289, "qg_score": null}], "content": "Various culinary sugars have different densities due to differences in particle size and inclusion of moisture.\nDomino Sugar gives the following weight to volume conversions (in United States customary units):\nThe \"Engineering Resources \u2013 Bulk Density Chart\" published in ''Powder and Bulk'' gives different values for the bulk densities:", "page_name": "Sugar", "page_id": "Sugar", "heading": "Measurements", "sub_heading": "Measurements", "_id": "113--8---1---1", "title": "Domino Sugar Bulk Density Chart (in United States Customary Units)"}
{"qas": [{"question": "How do we know that salt is a solution to Faraday's equations?", "answer": ""}, {"question": "Who came up with the term ion?", "answer": "Michael Faraday", "ae_score": -0.1354762675045285, "qg_score": null}, {"question": "Who came up with the term ion?", "answer": "Michael Faraday", "ae_score": -0.1354762675045285, "qg_score": null}], "content": "The word ''ion'' comes from the Greek word \u1f30\u03cc\u03bd, ''ion'', \"going\", the present participle of \u1f30\u03ad\u03bd\u03b1\u03b9, ''ienai'', \"to go\". This term was introduced by English physicist and chemist Michael Faraday in 1834 for the then-unknown species that ''goes'' from one electrode to the other through an aqueous medium. Faraday did not know the nature of these species, but he knew that since metals dissolved into and entered a solution at one electrode, and new metal came forth from a solution at the other electrode, that some kind of substance moved through the solution in a current, conveying matter from one place to the other.\nFaraday also introduced the words ''anion'' for a negatively charged ion, and ''cation'' for a positively charged one. In Faraday's nomenclature, cations were named because they were attracted to the cathode in a galvanic device and anions were named due to their attraction to the anode.\nSvante Arrhenius put forth, in his 1884 dissertation, his explanation of the fact that solid crystalline salts disassociate into paired charged particles when dissolved, for which he would win the 1903 Nobel Prize in Chemistry. Arrhenius' explanation was that in forming a solution, the salt dissociates into Faraday's ions. Arrhenius proposed that ions formed even in the absence of an electric current.", "page_name": "Ion", "page_id": "Ion", "heading": "History of discovery", "sub_heading": "History of discovery", "_id": "114--0---1---1", "title": "''Ions'' and ''Cations''"}
{"qas": [{"question": "How do scientists know how many cations are in a crystal?", "answer": ""}, {"question": "An ion with a +2 charge is known as what?", "answer": "dication", "ae_score": -0.1724049679128118, "qg_score": null}, {"question": "An ion with a +2 charge is known as what?", "answer": "dication", "ae_score": -0.1724049679128118, "qg_score": null}], "content": "Since the electric charge on a proton is equal in magnitude to the charge on an electron, the net electric charge on an ion is equal to the number of protons in the ion minus the number of electrons.\nAn ''anion'' (\u2212) ( ), from the Greek word \u1f04\u03bd\u03c9 (''\u00e1n\u014d''), meaning \"up\", is an ion with more electrons than protons, giving it a net negative charge (since electrons are negatively charged and protons are positively charged).\nA ''cation'' (+) ( ), from the Greek word \u03ba\u03b1\u03c4\u03ac (''kat\u00e1''), meaning \"down\", is an ion with fewer electrons than protons, giving it a positive charge.\nThere are additional names used for ions with multiple charges.  For example, an ion with a \u22122 charge is known as a dianion and an ion with a +2 charge is known as a dication.  A zwitterion is a neutral molecule with positive and negative charges at different locations within that molecule.\nCations and ions are measured by their ionic radius and they differ in relative size: \"Cations are small, most of them less than 10 cm in radius. But most anions are large, as is the most common Earth anion, oxygen. From this fact it is apparent that most of the space of a crystal is occupied by the anion and that the cations fit into the spaces between them.\"\nIn terms of an angstrom \u00c5, a cation has radius less than .8 \u00c5 while an anion has radius greater than 1.3 \u00c5.", "page_name": "Ion", "page_id": "Ion", "heading": "Characteristics", "sub_heading": "Characteristics", "_id": "114--1--0---1", "title": "Ion | Characteristics"}
{"qas": [{"question": "What are ionic gemstones?", "answer": ""}, {"question": "What type of ion is responsible for the luminescence of the sun and the existence?", "answer": "Ions", "ae_score": -0.9118518757459038, "qg_score": null}, {"question": "What type of ion is responsible for the luminescence of the sun and the existence?", "answer": "Ions", "ae_score": -0.9118518757459038, "qg_score": null}], "content": "Ions are ubiquitous in nature and are responsible for diverse phenomena from the luminescence of the Sun to the existence of the Earth's ionosphere. Atoms in their ionic state may have a different colour from neutral atoms, and thus light absorption by metal ions gives the colour of gemstones. In both inorganic and organic chemistry (including biochemistry), the interaction of water and ions is extremely important; an example is the energy that drives breakdown of adenosine triphosphate (ATP). The following sections describe contexts in which ions feature prominently; these are arranged in decreasing physical length-scale, from the astronomical to the microscopic.\nA collection of non-aqueous gas-like ions, or even a gas containing a proportion of charged particles, is called a plasma.  Greater than 99.9% of visible matter in the Universe may be in the form of plasmas.  These include our Sun and other stars and the space between planets, as well as the space in between stars.  Plasmas are often called the ''fourth state of matter'' because their properties are substantially different from those of solids, liquids, and gases. Astrophysical plasmas predominantly contain a mixture of electrons and protons (ionized hydrogen).", "page_name": "Ion", "page_id": "Ion", "heading": "Characteristics", "sub_heading": "Natural occurrences", "_id": "114--1--1---1", "title": "Ions in the Universe"}
{"qas": [{"question": "What are reactive charged particles and what are they used for?", "answer": ""}, {"question": "What is an example of a household item that uses ion as a charge?", "answer": "smoke detectors", "ae_score": -0.3104009163997744, "qg_score": null}, {"question": "What is an example of a household item that uses ion as a charge?", "answer": "smoke detectors", "ae_score": -0.3104009163997744, "qg_score": null}], "content": "Ions can be non-chemically prepared using various ion sources, usually involving high voltage or temperature.  These are used in a multitude of devices such as mass spectrometers, optical emission spectrometers, particle accelerators, ion implanters, and ion engines.\nAs reactive charged particles, they are also used in air purification by disrupting microbes, and in household items such as smoke detectors.\nAs signalling and metabolism in organisms are controlled by a precise ionic gradient across membranes, the disruption of this gradient contributes to cell death.  This is a common mechanism exploited by natural and artificial biocides, including the ion channels gramicidin and amphotericin (a fungicide).\nInorganic dissolved ions are a component of total dissolved solids, an indicator of water quality in the world.\nThe ionizing effect of radiation on a gas is extensively used for the detection of radiation such as alpha, beta, gamma and X-rays. The original ionization event in these instruments results in the formation of an \"ion pair\"; a positive ion and a free electron, by ion impact by the radiation on the gas molecules. The ionization chamber is the simplest of these detectors, and collects all the charges created by ''direct ionization'' within the gas through the application of an electric field.\nThe Geiger\u2013M\u00fcller tube and the proportional counter both use a phenomenon known as a Townsend avalanche to multiply the effect of the original ionizing event by means of a cascade effect whereby the free electrons are given sufficient energy by the electric field to release further electrons by ion impact.", "page_name": "Ion", "page_id": "Ion", "heading": "Related technology", "sub_heading": "Related technology", "_id": "114--2---1---1", "title": "The Ionization Effect of Radiation on Gases"}
{"qas": [{"question": "Why is it that when you draw a molecule/atom with multiple charges, it looks like it's the same thing?", "answer": ""}, {"question": "How many representations of ion are there?", "answer": "three", "ae_score": null, "qg_score": null}, {"question": "How many representations of ion are there?", "answer": "three", "ae_score": null, "qg_score": null}], "content": "When writing the chemical formula for an ion, its net charge is written in superscript immediately after the chemical structure for the molecule/atom.  The net charge is written with the magnitude ''before'' the sign; that is, a doubly charged cation is indicated as '''2+''' instead of '''+2'''.   However, the magnitude of the charge is omitted for singly charged molecules/atoms; for example, the sodium cation is indicated as Na and ''not'' Na.\nAn alternative (and acceptable) way of showing a molecule/atom with multiple charges is by drawing out the signs multiple times; this is often seen with transition metals.  Chemists sometimes circle the sign; this is merely ornamental and does not alter the chemical meaning.  All three representations of  shown in the figure are, thus, equivalent.\nMonatomic ions are sometimes also denoted with Roman numerals; for example, the  example seen above is occasionally referred to as Fe(II) or Fe.  The Roman numeral designates the ''formal oxidation state'' of an element, whereas the superscripted numerals denote the net charge.  The two notations are, therefore, exchangeable for monatomic ions, but the Roman numerals ''cannot'' be applied to polyatomic ions.  However, it is possible to mix the notations for the individual metal centre with a polyatomic complex, as shown by the uranyl ion example.\nIf an ion contains unpaired electrons, it is called a ''radical'' ion. Just like uncharged radicals, radical ions are very reactive.  Polyatomic ions containing oxygen, such as carbonate and sulfate, are called ''oxyanions''.   Molecular ions that contain at least one carbon to hydrogen bond are called ''organic ions''.  If the charge in an organic ion is formally centred on a carbon, it is termed a ''carbocation'' (if positively charged) or ''carbanion'' (if negatively charged).", "page_name": "Ion", "page_id": "Ion", "heading": "Chemistry", "sub_heading": "Chemistry", "_id": "114--3--0---1", "title": "The Chemical Formula of Monatomic Ions"}
{"qas": [{"question": "Why is the ionization energy of metals so much higher than that of nonmetals?", "answer": ""}, {"question": "How many electrons does cl have in its valence shell?", "answer": "7", "ae_score": -0.37341526781554, "qg_score": null}, {"question": "How many electrons does cl have in its valence shell?", "answer": "7", "ae_score": -0.37341526781554, "qg_score": null}], "content": "Monatomic ions are formed by the gain or loss of electrons to the valence shell (the outer-most electron shell) in an atom. The inner shells of an atom are filled with electrons that are tightly bound to the positively charged atomic nucleus, and so do not participate in this kind of chemical interaction. The process of gaining or losing electrons from a neutral atom or molecule is called ''ionization''.\nAtoms can be ionized by bombardment with radiation, but the more usual process of ionization encountered in chemistry is the transfer of electrons between atoms or molecules. This transfer is usually driven by the attaining of stable (\"closed shell\") electronic configurations. Atoms will gain or lose electrons depending on which action takes the least energy.\nFor example, a sodium atom, Na, has a single electron in its valence shell, surrounding 2 stable, filled inner shells of 2 and 8 electrons. Since these filled shells are very stable, a sodium atom tends to lose its extra electron and attain this stable configuration, becoming a sodium cation in the process\nOn the other hand, a chlorine atom, Cl, has 7 electrons in its valence shell, which is one short of the stable, filled shell with 8 electrons. Thus, a chlorine atom tends to ''gain'' an extra electron and attain a stable 8-electron configuration, becoming a chloride anion in the process:\nThis driving force is what causes sodium and chlorine to undergo a chemical reaction, wherein the \"extra\" electron is transferred from sodium to chlorine, forming sodium cations and chloride anions. Being oppositely charged, these cations and anions form ionic bonds and combine to form sodium chloride, NaCl, more commonly known as table salt.\nPolyatomic and molecular ions are often formed by the gaining or losing of elemental ions such as a proton, H, in neutral molecules. For example, when ammonia, NH, accepts a proton, H\u2014a process called protonation\u2014it forms the ammonium ion, NH. Ammonia and ammonium have the same number of electrons in essentially the same electronic configuration, but ammonium has an extra proton that gives it a net positive charge.\nAmmonia can also lose an electron to gain a positive charge, forming the ion . However, this ion is unstable, because it has an incomplete valence shell around the nitrogen atom, making it a very reactive radical ion.\nDue to the instability of radical ions, polyatomic and molecular ions are usually formed by gaining or losing elemental ions such as , rather than gaining or losing electrons. This allows the molecule to preserve its stable electronic configuration while acquiring an electrical charge.\nThe energy required to detach an electron in its lowest energy state from an atom or molecule of a gas with less net electric charge is called the ''ionization potential'', or ''ionization energy''. The ''n''th ionization energy of an atom is the energy required to detach its ''n''th electron after the first ''n \u2212 1'' electrons have already been detached.\nEach successive ionization energy is markedly greater than the last. Particularly great increases occur after any given block of atomic orbitals is exhausted of electrons. For this reason, ions tend to form in ways that leave them with full orbital blocks. For example, sodium has one ''valence electron'' in its outermost shell, so in ionized form it is commonly found with one lost electron, as . On the other side of the periodic table, chlorine has seven valence electrons, so in ionized form it is commonly found with one gained electron, as . Caesium has the lowest measured ionization energy of all the elements and helium has the greatest. In general, the ionization energy of metals is much lower than the ionization energy of nonmetals, which is why, in general, metals will lose electrons to form positively charged ions and nonmetals will gain electrons to form negatively charged ions.", "page_name": "Ion", "page_id": "Ion", "heading": "Chemistry", "sub_heading": "Formation", "_id": "114--3--1---1", "title": "ionization energy of metals"}
{"qas": [{"question": "How does ionic bonding work?", "answer": ""}, {"question": "What is the tendency of non-metals to gain more electrons?", "answer": "electronegativity", "ae_score": -0.5905783965414683, "qg_score": null}, {"question": "What is the tendency of non-metals to gain more electrons?", "answer": "electronegativity", "ae_score": -0.5905783965414683, "qg_score": null}], "content": "''Ionic bonding'' is a kind of chemical bonding that arises from the mutual attraction of oppositely charged ions. Ions of like charge repel each other, and ions of opposite charge attract each other. Therefore, ions do not usually exist on their own, but will bind with ions of opposite charge to form a crystal lattice. The resulting compound is called an ''ionic compound'', and is said to be held together by ''ionic bonding''. In ionic compounds there arise characteristic distances between ion neighbours from which the spatial extension and the ionic radius of individual ions may be derived.\nThe most common type of ionic bonding is seen in compounds of metals and nonmetals (except noble gases, which rarely form chemical compounds). Metals are characterized by having a small number of electrons in excess of a stable, closed-shell electronic configuration. As such, they have the tendency to lose these extra electrons in order to attain a stable configuration. This property is known as ''electropositivity''. Non-metals, on the other hand, are characterized by having an electron configuration just a few electrons short of a stable configuration. As such, they have the tendency to gain more electrons in order to achieve a stable configuration. This tendency is known as ''electronegativity''. When a highly electropositive metal is combined with a highly electronegative nonmetal, the extra electrons from the metal atoms are transferred to the electron-deficient nonmetal atoms. This reaction produces metal cations and nonmetal anions, which are attracted to each other to form a ''salt''.", "page_name": "Ion", "page_id": "Ion", "heading": "Chemistry", "sub_heading": "Ionic bonding", "_id": "114--3--2---1", "title": "''Ionic Bonding'' is a kind of chemical bonding that arise"}
{"qas": [{"question": "What happens to the inside of an animal's mouth when they die?", "answer": ""}, {"question": "What are the chambers of the gastrovascular cavity called?", "answer": "mesenteries", "ae_score": -0.5533260392277558, "qg_score": null}, {"question": "What are the chambers of the gastrovascular cavity called?", "answer": "mesenteries", "ae_score": -0.5533260392277558, "qg_score": null}], "content": "A gastrovascular cavity functions as a stomach and possesses a single opening to the outside, which operates as both a mouth and anus. Waste and undigested matter is excreted through this opening, which can be described as an incomplete gut. The mouth is typically slit-like in shape, and bears a groove at one or both ends. The groove, termed a ''siphonophore'', is ciliated, and helps to circulate water through the gastrovascular cavity. Some anemones feed on small particles, which are caught with the aid of a mucus secretion and moving currents that are set up by the tentacles. Most sea anemones are predacious, immobilizing their prey with the aid of their nematocysts.\nThe mouth opens into a flattened pharynx. This consists of an in-folding of the body wall, and is therefore lined by the animal's epidermis. The pharynx typically runs for about one third the length of the body before opening into the gastrovascular cavity that fills the remainder of the body.\nThe gastrovascular cavity itself is divided into a number of chambers by mesenteries radiating inwards from the body wall. Some of the mesenteries form complete partitions with a free edge at the base of the pharynx, where they connect, but others reach only partway across. The mesenteries are usually found in multiples of twelve, and are symmetrically arranged around the central pharynx. They have stomach lining on both sides, separated by a thin layer of mesoglea, and includes filaments of tissue specialised for secreting digestive enzymes. In some species, these filaments extend below the lower margin of the mesentery, hanging free in the gastrovascular cavity as acontial filaments.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Anatomy", "sub_heading": "Anatomy", "_id": "115--0--0---1", "title": "Anemones \u2014 The Gastrovascular Cavity"}
{"qas": [{"question": "What is a nervous system?", "answer": ""}, {"question": "What type of system controls the sea anemone?", "answer": "A primitive nervous system", "ae_score": -0.5494967600238368, "qg_score": null}, {"question": "What type of system controls the sea anemone?", "answer": "A primitive nervous system", "ae_score": -0.5494967600238368, "qg_score": null}], "content": "A primitive nervous system, without centralization, coordinates the processes involved in maintaining homeostasis, as well as biochemical and physical responses to various stimuli. No specialized sense organs are present.\nThe muscles and nerves are much simpler than those of most other animals, although more specialised than in other cnidarians, such as corals. Cells in the outer layer (epidermis) and the inner layer (gastrodermis) have microfilaments that group into contractile fibers. These fibers are not true muscles because they are not freely suspended in the body cavity as they are in more developed animals. Longitudinal fibres are found in the tentacles and oral disc, and also within the mesenteries, where they can contract the whole length of the body. Circular fibers are found in the body wall and, in some species, around the oral disc, allowing the animal to retract its tentacles into a protective sphincter.<ref name=IZ/>\nSince the anemone lacks a skeleton, the contractile cells pull against the gastrovascular cavity, which acts as a hydrostatic skeleton. The anemone stabilizes itself by shutting its mouth, which keeps the gastrovascular cavity at a constant volume, making it more rigid. Although generally sessile, sea anemones are capable of slow movements using their pedal disc, or of swimming, using either their tentacles or by flexing their bodies.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Anatomy", "sub_heading": "Nerve system", "_id": "115--0--1---1", "title": "Sea anemone | Anatomy | Nerve system"}
{"qas": [{"question": "What is the difference between a brooding anemone and a hermaphrodite?", "answer": ""}, {"question": "What do sea anemones produce during the free swimming stage?", "answer": "eggs and sperm", "ae_score": -0.4007668464464552, "qg_score": null}, {"question": "What do sea anemones produce during the free swimming stage?", "answer": "eggs and sperm", "ae_score": -0.4007668464464552, "qg_score": null}], "content": "Unlike other cnidarians, anemones (and other anthozoans) entirely lack the free-swimming medusal stage of their lifecycle; the polyp produces eggs and sperm, and the fertilized egg develops into a planula that develops directly into another polyp.\nAnemones tend to stay in the same spot until conditions become unsuitable (prolonged dryness, for example), or a predator attacks them. In that case, anemones can release themselves from the substrate and use flexing motions to swim to a new location. Most sea anemones attach temporarily to submerged objects; a few thrust themselves into the sand or live in burrows; a few are parasitic on other marine organisms, and some have symbiotic relationships with hermit crabs.\nThe sexes in sea anemones are separate in some species, while other species are protandric hermaphrodites.  The brooding anemone (''Epiactis prolifera'') is gynodioecious, starting life as a female and later becoming hermaphroditic, so that populations consist of females and hermaphrodites, and all females are fertilized by hermaphrodites. The gonads are strips of tissue within the mesenteries. Both sexual and asexual reproduction can occur. In sexual reproduction, males release sperm to stimulate females to release eggs, and fertilization occurs. Anemones eject eggs and sperm through the mouth. The fertilized egg develops into a planula, which settles and grows into a single polyp.\nAnemones can also reproduce asexually, by budding or in some cases by binary fission, when the polyp separates into two halves. Some species can also reproduce by pedal laceration. In this process, a ring of material breaks off from the pedal disc at the base of the column which then fragments, the pieces regenerating into new individuals.  The sea anemone ''Aiptasia diaphana'' displays sexual plasticity. Thus asexually produced clones derived form a single founder individual can contain both male and female individuals (ramets).  When eggs and sperm (gametes) are formed, they can produce zygotes derived from \u201cselfing\u201d (within the founding clone) or out-crossing, that then develop into swimming planula larvae.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Lifecycle", "sub_heading": "Lifecycle", "_id": "115--1---1---1", "title": "Anemones and the Sea Anemone"}
{"qas": [{"question": "How do fish and invertebrates interact with sea life?", "answer": ""}, {"question": "What part of the anemone is used to capture prey?", "answer": "oral disk", "ae_score": -0.3313957016686938, "qg_score": null}, {"question": "What part of the anemone is used to capture prey?", "answer": "oral disk", "ae_score": -0.3313957016686938, "qg_score": null}], "content": "The sea anemone has an oral disk, which the organism uses to capture prey. The anemone attaches to the substrate using the basal disk at its posterior end. Others also burrow into weaker objects. Some species attach to kelp while others are free-swimming.\nAlthough not plants and therefore incapable of photosynthesis themselves, many sea anemones form an important facultative symbiotic relationship with certain single-celled algae species that reside in the animals' gastrodermal cells. These algae may be either zooxanthellae, zoochlorellae or both. The sea anemone benefits from the products of the algae's photosynthesis, namely oxygen and food in the form of glycerol, glucose and alanine; the algae in turn are assured a reliable exposure to sunlight and protection from micro-feeders, which the sea anemones actively maintain. The algae also benefit by being protected by the sea anemone's stinging cells, nematocysts, reducing the likelihood of being eaten by herbivores.\nSeveral species of fish and invertebrates live in symbiotic or commensal relationships with sea anemones, most famously the clownfish, but also certain cardinalfish (such as Banggai cardinalfish), juvenile threespot dascyllus,  Bucchich's (or anemone) goby, juvenile painted greenling, various crabs (such as ''Inachus phalangium'', ''Mithraculus cinctimanus'' and ''Neopetrolisthes''), shrimp (such as certain ''Alpheus'', ''Lebbeus'', ''Periclimenes'' and ''Thor''), opossum shrimp (such as ''Heteromysis'' and ''Leptomysis''), and various marine snails.\nTwo of the more unusual relationships are those between certain anemones (such as ''Adamsia'', ''Calliactis'' and ''Neoaiptasia'') and hermit crabs or snails, and ''Bundeopsis'' or ''Triactis'' anemones and ''Lybia'' boxing crabs. In the former, the anemones live on the shell of the hermit crab or snail.<ref name=Crustacea/><ref name=Mercier/><ref name=Goodwill/><ref name=Ates/> In the latter, the small anemones are carried in the claws of the boxing crab.<ref name=Crustacea/>\nMost species inhabit tropical reefs, although there are species adapted to relatively cold waters, intertidal reefs, and sand/kelp environments.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Ecology", "sub_heading": "Ecology", "_id": "115--2---1---1", "title": "Sea Anemones \u2014 Species of Fish and Invertebrates"}
{"qas": [{"question": "Why are there so many species of fish in the ocean?", "answer": ""}, {"question": "What percentage of marine ornamentals are imported by the united states?", "answer": "80%", "ae_score": -0.21456367393525944, "qg_score": null}, {"question": "What percentage of marine ornamentals are imported by the united states?", "answer": "80%", "ae_score": -0.21456367393525944, "qg_score": null}], "content": "The global trade of marine ornamentals has been a rapidly expanding industry involving numerous countries worldwide. In the early 1980s, the estimated value of imported marine fish and invertebrates was US$24\u201340 million annually. Current estimates place that value at US$200\u2013330 million, with the United States accounting for 80% of the industry imports. Despite advances and the expansion of aquaculture, postlarval capture and rearing, the majority of marine ornamentals are collected in the wild as adults or juveniles.\nAnemones are susceptible to overexploitation due to their long lifespans, slower relative growth rates, and lower reproductive rates than their resident fish, which are also affected because they settle exclusively and are restricted to specific host sea anemones. The demand for these organisms is reflected in fishermen's catch records, which document the value they are paid per catch, and on average sea anemones were valued at five times the average value of anemonefish, and 10 times the value of the most abundant anemonefish, and in fact only made up 4.1% of the total value of the catch.\nAquarium fishing activities significantly impact the populations of anemones and anemonefish by drastically reducing the densities of each in exploited areas, and could also negatively impact anemone shrimp, and any organisms obligately associated with sea anemones. Anemonefish can survive alone in captivity, as has been shown by multiple research efforts.\nIn southern Italy and southwestern Spain, the anemone ''Anemonia sulcata'' is consumed as a delicacy. The whole animal is marinated in vinegar, then coated in a tempura-like batter and deep-fried in olive oil. They are similar in appearance and texture to croquettes, but have an intense seafood taste.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Exploitation", "sub_heading": "Exploitation", "_id": "115--3---1---1", "title": "Anemones and Anemonefish in the Aquarium Industry"}
{"qas": [{"question": "Are Actiniaria fossils?", "answer": ""}, {"question": "What is the oldest known fossil of anemone?", "answer": "Mackenzia", "ae_score": -0.8092317516957755, "qg_score": null}, {"question": "What is the oldest known fossil of anemone?", "answer": "Mackenzia", "ae_score": -0.8092317516957755, "qg_score": null}], "content": "Most Actiniaria do not form hard parts that can be recognized as fossils, but a few do exist; ''Mackenzia'', from the Middle Cambrian Burgess Shale of Canada, is the oldest fossil identified as a sea anemone.", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Fossil record", "sub_heading": "Fossil record", "_id": "115--4---1---1", "title": "''Mackenzia'', from the Middle Cambrian Burges"}
{"qas": [{"question": "What is the difference between Actiniaria and Actinaria?", "answer": ""}, {"question": "What is the scientific name for a sea anemone?", "answer": "Actiniaria", "ae_score": -0.08670563837221647, "qg_score": null}, {"question": "What is the scientific name for a sea anemone?", "answer": "Actiniaria", "ae_score": -0.08670563837221647, "qg_score": null}], "content": "Rodriguez et al proposed a new classification for the Actiniaria based on extensive DNA results.\nSuborders and Superfamilies included in Actiniaria are: \nThe relationships of higher-level taxa in Carlgren\u2019s classification are re-interpreted as follows:", "page_name": "Sea anemone", "page_id": "Sea%20anemone", "heading": "Taxonomy", "sub_heading": "Taxonomy", "_id": "115--5---1---1", "title": "Carlgren Classification of Actiniaria"}
{"qas": [{"question": "Why does the Amazon have such a high rate of deforestation?", "answer": ""}, {"question": "What percentage of the amazon rainforest is controlled by small farmers?", "answer": "30 percent", "ae_score": -0.43407610633056026, "qg_score": null}, {"question": "What percentage of the amazon rainforest is controlled by small farmers?", "answer": "30 percent", "ae_score": -0.43407610633056026, "qg_score": null}], "content": "In the pre-Colombian era, parts of the Amazon Rainforest were a densely populated open agricultural landscape. After the European invasion in the 16th century, with the hunt for gold, Western diseases, slavery and later and the rubber boom, the Amazon Rainforest was depopulated and the forest grew larger.\nPrior to the 1970s, access to the forest's largely roadless interior was difficult, and aside from partial clearing along rivers the forest remained intact. Deforestation accelerated greatly following the opening of highways deep into the forest, such as the Trans-Amazonian highway in 1972.\nParts of the Amazon the poor soil had made plantation-based agriculture unprofitable. The key turning point in deforestation of the Brazilian Amazon was when colonists began to establish farms within the forest during the 1960s. Their farming system was based on crop cultivation and the slash-and-burn method. However, the colonists were unable to successfully manage their fields and the crops due to the loss of soil fertility and weed invasion due to this method.\nIn indigenous areas of the Peruvian Amazon, such as the Urarina's Chambira River Basin, the soils are productive for only relatively short periods of time, therefore causing indigenous horticulturalists like the Urarina to move to new areas and clear more and more land.Amazonian colonization was ruled by cattle raising because ranching required little labor, generated decent profits, and awarded social status in the community. Additionally, grass is able to grow in the poor Amazon soil. However, the abundance of cattle ranching led to extensive deforestation, causing extensive environmental damage.\nAn estimated 30 percent of the deforestation is due to the actions of small farmers. Although small farmers possess smaller total land area than medium and large ranchers, who possess 89% of the Legal Amazon's private land, the intensity of deforestation within the areas that they inhabit is greater than that within the areas occupied by the larger ranchers.  This emphasizes the importance of using previously cleared land for agricultural use, rather the typically easier political path of distributing still-forested areas. In the Brazilian Amazon, the proportion of small farmers to large landholders changes frequently with economic and demographic pressures.\nIn 2009, Peruvian President Alan Garc\u00eda pushed through by executive decree Law 840 (also known as \"Ley de la Selva,\" \"the Law of the Jungle\" or simply the \"Forest Law\"), which allowed the sale of uncultivated Amazon land under state ownership to private companies, without term limits on the property rights. While the law was promoted as a \"reforestation\" measure, critics claimed the privatization measure would in fact encourage further deforestation of the Amazon, while surrendering the nation's rights over natural resources to foreign investors and leaving uncertain the fate of Peru's indigenous people, who do not typically hold formal title to the forestlands on which they subsist. Law 840 met widespread resistance and was eventually repealed by Peru's legislature for being unconstitutional.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "History", "sub_heading": "History", "_id": "116--0---1---1", "title": "Deforestation of the Brazilian Amazon"}
{"qas": [{"question": "Why is the US dumping oil in the Amazon a bad thing?", "answer": ""}, {"question": "What percentage of the amazon rainforest is used for livestock?", "answer": "70%", "ae_score": -0.38566624484944256, "qg_score": null}, {"question": "What percentage of the amazon rainforest is used for livestock?", "answer": "70%", "ae_score": -0.38566624484944256, "qg_score": null}], "content": "Deforestation of the Amazon rainforest can be attributed to many different factors at local, national, and international levels. The rainforest is seen as a resource for cattle pasture, valuable hardwoods, housing space, farming space (especially for soybeans), road works (such as highways and smaller roads) and medicines.\nA 2009 Greenpeace report found that the cattle sector in the Brazilian Amazon, supported by the international beef and leather trades, was responsible for about 80% of all deforestation in the region, or about 14% of the world's total annual deforestation, making it the largest single driver of deforestation in the world. According to a 2006 report by the Food and Agriculture Organization of the United Nations, 70% of formerly forested land in the Amazon, and 91% of land deforested since 1970, is used for livestock pasture.\nAdditional deforestation in the Amazon has resulted from farmers clearing land for small-scale subsistence agriculture or for mechanized cropland. Scientists using NASA satellite data found in 2006 that clearing for mechanized cropland had become a significant force in Brazilian Amazon deforestation. This change in land use may alter the region's climate. Researchers found that in 2003, a peak year of deforestation, more than 20 percent of the Mato Grosso state's forests were converted to cropland. In 2005, soybean prices fell by more than 25 percent and some areas of Mato Grosso showed a decrease in large deforestation events, suggesting that the rise and fall of prices for other crops, beef and timber may also have a significant impact on future land use in the region.\nUntil 2006, a major driver of forest loss in the Amazon was the cultivation of soy, mainly for export and production of biodiesel and animal feed; as soybean prices have risen, soy farmers pushed northwards into forested areas of the Amazon. However, a private sector agreement referred to as the Soy Moratorium has helped drastically reduce the deforestation linked to soy production in the region. In 2006, a number of major commodity trading companies such as Cargill agreed to not purchase soybeans produced in the Brazilian Amazon on recently deforested areas. Before the moratorium, 30 percent of soy field expansion had occurred through deforestation, contributing to record deforestation rates. After eight years of the moratorium, a 2015 study found that although soy production area had expanded another 1.3 million hectares, only about 1 percent of the new soy expansion had come at the expense of forest. In response to the moratorium, farmers were choosing to plant on already cleared land.\nThe needs of soy farmers have been used to validate some controversial transportation projects that have developed in the Amazon. The first two highways, the Bel\u00e9m-Bras\u00edlia (1958) and the Cuiaba-Porto Velho (1968), were the only federal highways in the Legal Amazon to be paved and passable year-round before the late 1990s. These two highways are said to be \"at the heart of the 'arc of deforestation'\", which at present is the focal point area of deforestation in the Brazilian Amazon. The Bel\u00e9m-Bras\u00edlia highway attracted nearly two million settlers in the first twenty years. The success of the Bel\u00e9m-Bras\u00edlia highway in opening up the forest was reenacted as paved roads continued to be developed, unleashing the irrepressible spread of settlement. The completions of the roads were followed by a wave of resettlement; these settlers had a significant effect on the forest as well.\nResearch conducted by Leydimere Oliveira et al. has shown that the more rainforest is logged in the Amazon, the less precipitation reaches the area and so the lower the yield per hectare becomes. Thus for Brazil as a whole, there is no economic gain to be made by logging and selling trees and using the logged land for pastoral purposes.\nA September 2016 Amazon Watch report concludes that imports of crude oil by the US are driving rainforest destruction in the Amazon and releasing significant greenhouse gases.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "Causes of deforestation", "sub_heading": "Causes of deforestation", "_id": "116--1---1---1", "title": "Deforestation in the Brazilian Amazon"}
{"qas": [{"question": "How does a tribe survive a wildfire?", "answer": ""}, {"question": "How long does it take to reforest the amazon rainforest?", "answer": "a few years", "ae_score": null, "qg_score": null}, {"question": "How long does it take to reforest the amazon rainforest?", "answer": "a few years", "ae_score": null, "qg_score": null}], "content": "A small area of land is cleared and the vegetation burned, providing a source of nutrients from the ash.For a few years the soil remains sufficiently fertile for the tribe to grow crops.When the soil's fertility is exhausted, the tribe                     moves on and clears another small area of forest.The original area is regenerated, as it receives nutrients and seeds from surrounding vegetation.As no lasting damage occurs, this method of agriculture is sustainable.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "Slash and Burn", "sub_heading": "Slash and Burn", "_id": "116--2---1---1", "title": "A Native American Way of Agriculture"}
{"qas": [{"question": "How do we know how much deforestation is in the Amazon rainforest?", "answer": ""}, {"question": "What is the name of the satellite used to study the amazon rainforest?", "answer": "Landsat satellite", "ae_score": -0.7477192225795528, "qg_score": null}, {"question": "What is the name of the satellite used to study the amazon rainforest?", "answer": "Landsat satellite", "ae_score": -0.7477192225795528, "qg_score": null}], "content": "The annual rate of deforestation in the Amazon region dramatically increased from 1991 to 2003. In the nine years from 1991 to 2000, the total area of Amazon rainforest cleared since 1970 rose from 419010 to, comparable to the land area of Spain, Madagascar or Manitoba. Most of this lost forest was replaced by pasture for cattle.\nDeforestation of the Amazon rainforest continued to accelerate in the early 2000s, reaching an annual rate of 27,423 km\u00b2 of forest loss in the year 2004. Today the remaining forest cover continues to dwindle, though the annual rate of forest loss has generally been slowing since 2004. However, rates of deforestation jumped again in 2008, 2013 and 2015.\nIn Brazil, the Instituto Nacional de Pesquisas Espaciais (INPE, or National Institute of Space Research) produces deforestation figures annually. Their deforestation estimates are derived from 100 to 220 images taken during the dry season in the Amazon by the Landsat satellite, also may only consider the loss of the Amazon rainforest biome \u2013 not the loss of natural fields or savannah within the rainforest.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "Rates of forest loss", "sub_heading": "Rates of forest loss", "_id": "116--3---1---1", "title": "Deforestation in the Amazon region"}
{"qas": [{"question": "Why is the Amazon considered a genocide?", "answer": ""}, {"question": "Who has destroyed most of the amazon rainforest?", "answer": "Loggers", "ae_score": -0.24390342553859615, "qg_score": null}, {"question": "Who has destroyed most of the amazon rainforest?", "answer": "Loggers", "ae_score": -0.24390342553859615, "qg_score": null}], "content": "The native tribes of the Amazon have often been abused during the Amazon's deforestation. Loggers have killed natives, and encroached on to their land. Many uncontacted peoples have come out of the jungles to mingle with mainstream society after threats from outsiders. Uncontacted peoples making first contact with outsiders are susceptible to diseases to which they have little immunity. Tribes can easily be decimated, the deaths resulting have been compared to a genocide.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "Impact on Indigenous peoples", "sub_heading": "Impact on Indigenous peoples", "_id": "116--4---1---1", "title": "Native Tribes in the Amazon"}
{"qas": [{"question": "How does Norway benefit from the Amazon rainforest?", "answer": ""}, {"question": "How much did brazil reduce the amazon rainforest?", "answer": "82 percent", "ae_score": -0.2146167871913422, "qg_score": null}, {"question": "How much did brazil reduce the amazon rainforest?", "answer": "82 percent", "ae_score": -0.2146167871913422, "qg_score": null}], "content": "Using the 2005 deforestation rates, it was estimated that the Amazon rainforest would be reduced by 40% in two decades. The rate of deforestation is now slowing; rates of forest loss in 2012 were the slowest on record. However, the forest is still shrinking.\nNorwegian prime minister Jens Stoltenberg announced on September 16, 2008, that Norway's government would donate US $1 billion to the newly established Amazon fund. The money from this fund would go to projects aimed at slowing down the deforestation of the Amazon rainforest.\nIn September 2015, Brazilian president Dilma Rousseff told the United Nations that Brazil had effectively reduced the rate of deforestation in the Amazon by 82 percent. She also announced that over the next 15 years, Brazil aimed to eliminate illegal deforestation, restore and reforest 120,000 sqkm, and recover 150,000 sqkm of degraded pastures.", "page_name": "Deforestation of the Amazon rainforest", "page_id": "Deforestation%20of%20the%20Amazon%20rainforest", "heading": "Future of the Amazon rainforest", "sub_heading": "Future of the Amazon rainforest", "_id": "116--5---1---1", "title": "The Deforestation of the Amazon Rainforest"}
{"qas": [{"question": "What is the difference between a liquid and a battery?", "answer": ""}, {"question": "What is the negative electrode in sodium sulphur battery?", "answer": "liquid sodium", "ae_score": -0.8330496014035669, "qg_score": null}, {"question": "What are the 3 components of sodium sulphur battery?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "Typical batteries have a solid electrolyte membrane between the anode and cathode, compared with liquid-metal batteries where the anode, the cathode and the membrane are liquids.\nThe cell is usually made in a cylindrical configuration. The entire cell is enclosed by a steel casing that is protected, usually by chromium and molybdenum, from corrosion on the inside. This outside container serves as the positive electrode, while the liquid sodium serves as the negative electrode. The container is sealed at the top with an airtight alumina lid. An essential part of the cell is the presence of a BASE (beta-alumina solid electrolyte) membrane, which selectively conducts Na. In commercial applications the cells are arranged in blocks for better heat conservation and are encased in a vacuum-insulated box.", "page_name": "Sodium\u2013sulfur battery", "page_id": "Sodium%E2%80%93sulfur%20battery", "heading": "Construction", "sub_heading": "Construction", "_id": "1000001222--0---1---1", "title": "Battery Cells \u2014 A Brief Introduction"}
{"qas": [{"question": "How do you treat a major depressive episode?", "answer": ""}, {"question": "What is the name of the atypical antidepressant used to treat depression?", "answer": "mirtazapine", "ae_score": -0.47774676341468236, "qg_score": null}, {"question": "What is the most common treatment for major depressive episodes?", "answer": "severe combined immunodeficiency", "ae_score": null, "qg_score": null}], "content": "Depression is a treatable illness. Treatments for a major depressive episode may be obtained in one or more of the following settings: mental health specialists (i.e. psychologist, psychiatrists, social workers, counselors, etc.), mental health centers or organizations, hospitals, outpatient clinics, social service agencies, private clinics, peer support groups, clergy, and employee assistance programs. The treatment plan could include psychotherapy alone, antidepressant medications alone, or a combination of medication and psychotherapy.\nFor major depressive episodes of severe intensity (multiple symptoms, minimal mood reactivity, severe functional impairment), combined psychotherapy and antidepressant medications are more effective than psychotherapy alone. Patients with severe symptoms may require outpatient treatment or hospitalization.\nPsychotherapy, also known as talk therapy, counseling, or psychosocial therapy, is characterized by a patient talking about their condition and mental health issues with a trained therapist. Different types of psychotherapy can be effective for depression. These include cognitive behavioral therapy, interpersonal therapy, dialectical behavior therapy, acceptance and commitment therapy, and mindfulness techniques.\nMedications used to treat depression include selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs), norepinephrine-dopamine reuptake inhibitors (NDRIs), tricyclic antidepressants, monoamine oxidase inhibitors (MAOIs), and atypical antidepressants such as mirtazapine, which do not fit neatly into any of the other categories. Different antidepressants work better for different individuals. It is often necessary to try several before finding one that works best for a specific patient. Some people may find it necessary to combine medications, which could mean two antidepressants or an antipsychotic medication in addition to an antidepressant. If a person's close relative has responded well to a certain medication, that treatment will likely work well for him or her.\nSometimes, people stop taking antidepressant medications due to side effects, although side effects often become less severe over time. Suddenly stopping treatment or missing several doses may cause withdrawal-like symptoms. Some studies have shown that antidepressants may increase short-term suicidal thoughts or actions, especially in children, adolescents, and young adults. However, antidepressants are more likely to reduce a person's risk of suicide in the long run.\nIf left untreated, a typical major depressive episode may last for about six months. About 20% of these episodes can last two years or more. About half of depressive episodes end spontaneously. However, even after the major depressive episode is over, 20% to 30% of patients have residual symptoms, which can be distressing and associated with disability.", "page_name": "Major depressive episode", "page_id": "Major%20depressive%20episode", "heading": "Treatment", "sub_heading": "Treatment", "_id": "1000002351--2---1---1", "title": "Psychotherapy for Depression"}
{"qas": [{"question": "Why does your gut flora change when you're in a stressful situation?", "answer": ""}, {"question": "When was the theory of the gut-brain axis discovered?", "answer": "2004", "ae_score": -0.4026392873111693, "qg_score": null}, {"question": "Which part of the brain is affected by gut flora?", "answer": "Gut-brain axis", "ae_score": null, "qg_score": null}], "content": "The gut\u2013brain axis, a bidirectional neurohumoral communication system, is important for maintaining homeostasis and is regulated through the central and enteric nervous systems and the neural, endocrine, immune, and metabolic pathways, and especially including the hypothalamic\u2013pituitary\u2013adrenal axis (HPA axis).  That term has been expanded to include the role of the gut flora as part of the \"microbiome-gut-brain axis\", a linkage of functions including the gut flora.\nInterest in the field was sparked by a 2004 study showing that germ-free mice (genetically homogeneous laboratory mice, birthed and raised in an antiseptic environment) showed an exaggerated HPA axis response to stress compared to non-GF laboratory mice.\nThe gut flora can produce a range of neuroactive molecules, such as acetylcholine, catecholamines, \u03b3-aminobutyric acid, histamine, melatonin, and serotonin, which is essential for regulating peristalsis and sensation in the gut.  Changes in the composition of the gut flora due to diet, drugs, or disease correlate with changes in levels of circulating cytokines, some of which can affect brain function.  The gut flora also release molecules that can directly activate the vagus nerve which transmits information about the state of the intestines to the brain.\nLikewise, chronic or acutely stressful situations activate the hypothalamic\u2013pituitary\u2013adrenal axis, causing changes in the gut flora and intestinal epithelium, and possibly having systemic effects.  Additionally, the cholinergic anti-inflammatory pathway, signaling through the vagus nerve, affects the gut epithelium and flora. Hunger and satiety are integrated in the brain, and the presence or absence of food in the gut and types of food present, also affect the composition and activity of gut flora.\nThat said, most of the work that has been done on the role of gut flora in the gut-brain axis has been conducted in animals, including the highly artificial germ-free mice.   As of 2016 studies with humans measuring changes to gut flora in response to stress, or measuring effects of various probiotics, have generally been small and cannot be generalized; whether changes to gut flora are a result of disease, a cause of disease, or both in any number of possible feedback loops in the gut-brain axis, remains unclear.", "page_name": "Gut\u2013brain axis", "page_id": "Gut%E2%80%93brain%20axis", "heading": "Gut-brain integration", "sub_heading": "Gut-brain integration", "_id": "1000008529--2---1---1", "title": "Gut flora in the gut-brain axis"}
{"qas": [{"question": "Who is Anita Sarkeesian and why is she so important?", "answer": ""}, {"question": "Helen tager flusberg is a leading researcher in?", "answer": "autism", "ae_score": -0.48204603862298057, "qg_score": null}, {"question": "Helen tager flusberg is a leading researcher in?", "answer": "autism", "ae_score": -0.48204603862298057, "qg_score": null}], "content": "Her research interests are in autism, Williams syndrome,<ref name=LabDirector/> Down syndrome, and specific language impairment, which she has researched since the late 70s.<ref name=MIND/>\nTager-Flusberg was President of the International Society for Autism Research (2011-2013), and served on the National Deafness and Communication Disorders Advisory Council from 2012-2016.\nShe is on the editorial boards of ''Autism'' and ''Autism Research''; and an Associate Editor of the ''British Journal of Psychology''<ref name=AutismSpeaks/> and is Associate Editor for the ''Journal of Neurodevelopmental Disorders''.<ref name=MIND/>", "page_name": "Helen Tager-Flusberg", "page_id": "Helen%20Tager-Flusberg", "heading": "Career", "sub_heading": "Career", "_id": "1000008812--1---1---1", "title": "Tager-Flusberg is an Associate Editor for the ''British"}
{"qas": [{"question": "What is the difference between a single cell and a multipotent stem cell?", "answer": ""}, {"question": "What is an organism consisting of tissues or parts of diverse genetic constitution?", "answer": "chimera", "ae_score": -0.4545377848468042, "qg_score": null}, {"question": "What type of integration occurs at the corresponding sites in the genome?", "answer": "plasmid", "ae_score": null, "qg_score": null}], "content": "The Desired gene construct is injected in the pronucleus of a reproductive cell using a glass needle around 0.5 to 5 micrometers in diameter. The manipulated cell is cultured in vitro to develop to a specific embryonic phase, is then transferred to a recipient female. DNA microinjection does not have a high success rate (roughly 2% of all injected subjects), even if the new DNA is incorporated in the genome, if it is not accepted by the germ-line the new traits will not appear in their offspring. If DNA is injected in multiple sites the chances of over-expression increase.\nA retrovirus is a virus that carries its genetic material in the form of RNA rather than DNA. Retroviruses are used as vectors to transfer genetic material into the host cell. The result is a chimera, an organism consisting of tissues or parts of diverse genetic constitution. Chimeras are inbred for as many as 20 generations until homozygous genetic offspring are born.\n'''Restriction enzyme mediated integration''' (abbreviated as '''REMI''') is a technique for integrating DNA (linearised plasmid) into the genome sites that have been generated by the same restriction enzyme used for the DNA linearisation. The plasmid integration occurs at the corresponding sites in the genome, often by regenerating the recognition sites by same the restriction enzyme used for plasmid linearisation.\nMultipotent stem cells can only differentiate into a limited number of therapeutically useful cell types, nevertheless their safety and relative lack of complexity to us have resulted in the vast majority of current personalized cellular therapeutics involving multipotent stem cells (typically mesenchymal stem cells from adipose tissue).\nTransgenic vectors can be delivered randomly, or targeted to a specific genomic location, such as a safe harbor . Scientists have performed research and technology development to provide the tools necessary to permit safe and effective pluripotent stem cell (PSC) transgenesis.\nThe manipulated gene construct is inserted into totipotent stem cells, cells which can develop into any specialized cell. Cells containing the desired DNA are incorporated into the host\u2019s embryo, resulting in a chimeric animal. Unlike the other two methods of injection which require live transgenic offspring for testing, embryonic cell transfer can be tested at the cell stage.", "page_name": "Transgenesis", "page_id": "Transgenesis", "heading": "Gene transfer technology", "sub_heading": "Gene transfer technology", "_id": "1000010079--1---1---1", "title": "Embryonic Cell Transgenes"}
{"qas": [{"question": "Aminoglycoside resistance genes?", "answer": ""}, {"question": "Which antibiotics are used to selectively destroy cells that did not take up the plasmid?", "answer": "kanamycin or neomycin", "ae_score": -1.6219636038910057, "qg_score": null, "filter_answer": "neomycin"}, {"question": "What is an example of an antibiotic that selectively destroys cells that did not take up the?", "answer": "kanamycin", "ae_score": null, "qg_score": null}], "content": "Aminoglycoside resistance genes are commonly used in the realm of genetic engineering in order to select for correctly transformed bacterial organisms. When constructing a vector plasmid, including antibiotic resistance in the vector is crucial to effectively expressing the gene of interest. Antibiotics, such as the aminoglycosides kanamycin or neomycin, are added to the cultures during growth phases in order to selectively destroy the cells that did not effectively take up the plasmid.", "page_name": "Kanamycin kinase", "page_id": "Kanamycin%20kinase", "heading": "Use in Research", "sub_heading": "Use in Research", "_id": "1000010407--3---1---1", "title": "Aminoglycoside Resistance Genes"}
{"qas": [{"question": "Why do car batteries smell bad after they are fully charged?", "answer": ""}, {"question": "What gases are emitted by electric vehicle batteries?", "answer": "hydrogen, oxygen and sulfur", "ae_score": -0.6342874771392856, "qg_score": null}, {"question": "What is the difference between lead acid batteries and petroleum fuels?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Flooded lead-acid batteries are the cheapest and in past most common traction batteries available. There are two main types of lead-acid batteries: automobile engine starter batteries, and deep cycle batteries. Automobile alternators are designed to provide starter batteries high charge rates for fast charges, while deep cycle batteries used for electric vehicles like forklifts or golf carts, and as the auxiliary house batteries in RV's, require different multi-stage charging. No lead acid battery should be discharged below 50% of its capacity, as it shortens the battery's life. Flooded batteries require inspection of electrolyte level and occasional replacement of water which gases away during the normal charging cycle.\nTraditionally, most electric vehicles have used lead-acid batteries due to their mature technology, high availability, and low cost  (exception: some early EVs, such as the Detroit Electric, used a nickel\u2013iron battery.)  Like all batteries, these have an environmental impact through their construction, use, disposal or recycling. On the upside, vehicle battery recycling rates top 95% in the United States. Deep-cycle lead batteries are expensive and have a shorter life than the vehicle itself, typically needing replacement every 3 years.\nLead-acid batteries in EV applications end up being a significant (25\u201350%) portion of the final vehicle mass. Like all batteries, they have significantly lower energy density than petroleum fuels\u2014in this case, 30\u201340 Wh/kg. While the difference isn't as extreme as it first appears due to the lighter drive-train in an EV, even the best batteries tend to lead to higher masses when applied to vehicles with a normal range. The efficiency (70\u201375%) and storage capacity of the current generation of common deep cycle lead acid batteries decreases with lower temperatures, and diverting power to run a heating coil reduces efficiency and range by up to 40%. Recent advances in battery efficiency, capacity, materials, safety, toxicity and durability are likely to allow these superior characteristics to be applied in car-sized EVs.\nCharging and operation of batteries typically results in the emission of hydrogen, oxygen and sulfur, which are naturally occurring and normally harmless if properly vented. Early Citicar owners discovered that, if not vented properly, unpleasant sulfur smells would leak into the cabin immediately after charging.\nLead-acid batteries powered such early-modern EVs as the original versions of the EV1 and the RAV4 EV.", "page_name": "Electric vehicle battery", "page_id": "Electric%20vehicle%20battery", "heading": "Battery types", "sub_heading": "Battery types", "_id": "1000010982--0--0---1", "title": "Why Lead Acid Batteries Are Important for EVs"}
{"qas": [{"question": "What is the difference between Cobasys and GM Ovonic batteries?", "answer": ""}, {"question": "Who makes the NiMH battery for the electric vehicle?", "answer": "GM Ovonic", "ae_score": -0.5948683073320528, "qg_score": null}, {"question": "What is the difference between lead acid and nickel-metal hydride batteries?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Nickel-metal hydride batteries are now considered a relatively mature technology. While less efficient (60\u201370%) in charging and discharging than even lead-acid, they boast an energy density of 30\u201380 Wh/kg, far higher than lead-acid. When used properly, nickel-metal hydride batteries can have exceptionally long lives, as has been demonstrated in their use in hybrid cars and surviving NiMH RAV4 EVs that still operate well after 100000 mi and over a decade of service. Downsides include the poor efficiency, high self-discharge, very finicky charge cycles, and poor performance in cold weather.\nGM Ovonic produced the NiMH battery used in the second generation EV-1, and Cobasys makes a nearly identical battery (ten 1.2 V 85 Ah NiMH cells in series in contrast with eleven cells for Ovonic battery). This worked very well in the EV-1. Patent encumbrance has limited the use of these batteries in recent years.", "page_name": "Electric vehicle battery", "page_id": "Electric%20vehicle%20battery", "heading": "Battery types", "sub_heading": "Nickel metal hydride", "_id": "1000010982--0--1---1", "title": "Nickel-Metal Hydride Batteries: The Future of Battery Technology"}
{"qas": [{"question": "Why don't we useebra batteries in cars?", "answer": ""}, {"question": "When did the zebra battery come out?", "answer": "2006", "ae_score": -0.17019085896373642, "qg_score": null}, {"question": "What is the main component of a zebra battery?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "The sodium or \"zebra\" battery uses a molten chloroaluminate sodium (NaAlCl4) as the electrolyte. This chemistry is also occasionally referred to as \"hot salt\". A relatively mature technology, the Zebra battery boasts an energy density of 120Wh/kg and reasonable series resistance. Since the battery must be heated for use, cold weather doesn't strongly affect its operation except for in increasing heating costs. They have been used in several EVs. Zebras can last for a few thousand charge cycles and are nontoxic. The downsides to the Zebra battery include poor power density (<300 W/kg) and the requirement of having to heat the electrolyte to about 270 C, which wastes some energy and presents difficulties in long-term storage of charge.\nZebra batteries have been used in the Modec commercial vehicle since it entered production in 2006.", "page_name": "Electric vehicle battery", "page_id": "Electric%20vehicle%20battery", "heading": "Battery types", "sub_heading": "Zebra", "_id": "1000010982--0--2---1", "title": "Zebra Batteries \u2014 EVs, EVs, EVs, "}
{"qas": [{"question": "Why do electric cars have such a long battery life compared to other electric vehicles?", "answer": ""}, {"question": "What type of battery is being developed in the lab?", "answer": "lithium ion batteries", "ae_score": -0.5978515546219518, "qg_score": null}, {"question": "What nanowires promise several times the energy density in the anode?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "Lithium-ion (and similar lithium polymer) batteries, widely known via their use in laptops and consumer electronics, dominate the most recent group of EVs in development. The traditional lithium-ion chemistry involves a lithium cobalt oxide cathode and a graphite anode. This yields cells with an impressive 200+ Wh/kg energy density and good power density, and 80 to 90% charge/discharge efficiency. The downsides of traditional lithium-ion batteries include short cycle lives (hundreds to a few thousand charge cycles) and significant degradation with age. The cathode is also somewhat toxic. Also, traditional lithium-ion batteries can pose a fire safety risk if punctured or charged improperly. These laptop cells don't accept or supply charge when cold, and so heaters can be necessary in some climates to warm them. The maturity of this technology is moderate. The Tesla Roadster uses \"blades\" of traditional lithium-ion \"laptop battery\" cells that can be replaced individually as needed.\nMost other EVs are utilizing new variations on lithium-ion chemistry that sacrifice energy and power density to provide fire resistance, environmental friendliness, very rapid charges (as low as a few minutes), and very long lifespans. These variants (phosphates, titanates, spinels, etc.) have been shown to have a much longer lifetime, with A123 expecting their lithium iron phosphate batteries to last for at least 10+ years and 7000+ charge cycles, and LG Chem expecting their lithium-manganese spinel batteries to last up to 40 years.\nMuch work is being done on lithium ion batteries in the lab.  Lithium vanadium oxide has already made its way into the Subaru prototype G4e, doubling energy density. Silicon nanowires, silicon nanoparticles, and tin nanoparticles promise several times the energy density in the anode, while composite and superlattice cathodes also promise significant density improvements.", "page_name": "Electric vehicle battery", "page_id": "Electric%20vehicle%20battery", "heading": "Battery types", "sub_heading": "Lithium ion", "_id": "1000010982--0--3---1", "title": "Lithium-ion Batteries: The Future of Electric Vehicles"}
{"qas": [{"question": "How did Ranieri and Salomon go from Salomon to Bank United?", "answer": ""}, {"question": "Lewis ranieri founded which investment firm in 1988?", "answer": "Hyperion Partners", "ae_score": -0.19926045201286716, "qg_score": null}, {"question": "What did lewis ranieri say was the cause of the financial crisis?", "answer": "housing bubble", "ae_score": null, "qg_score": null}], "content": "In 1968, Ranieri took a part-time job in the mail room of Salomon Brothers. He worked his way from the mail room to the position of Vice Chairman of Salomon Brothers, the full story of which is captured in Michael Lewis's bestseller Liar's Poker.<ref name=BW/> In the late 1970s, Ranieri joined the new mortgage-trading desk of Salomon Brothers where he contributed to creating the innovative practice of ''securitization'', a word he is said to have coined.<ref name=BW/> ''BusinessWeek'' said that in 1977, with the creation of mortgage-backed securities (MBS), \"Ranieri's job was to sell those bonds\u2014at a time when only 15 states recognized MBS as legal investments. With a trader's nerve and a salesman's persuasiveness, he did much more, creating the market to trade MBS and winning Washington lobbying battles to remove legal and tax barriers.\"<ref name=BW/> Ranieri also declared that \"mortgages are math,\" hiring PhDs who developed the collateralized mortgage obligation, repackaging mortgages into more attractive bonds.<ref name=BW/>\nAfter leaving Salomon in 1987, Ranieri formed Hyperion Partners, a successful investment firm, in 1988. In 2000, Ranieri and his partners at Hyperion sold Bank United, a firm they acquired in the late 1980s.\nAs mortgage-backed securities came under scrutiny for their role in the subprime mortgage crisis, the United States housing bubble and the financial crisis of 2007\u20132010, critics took aim at Ranieri. In March 2007, at a time when it was unknown whether or not the over-extension of leverage inherent in subprime mortgages could lead to a financial crisis, Ranieri commented \"I think [the risk] is containable. I don't think this is going to be a cataclysm.\"\nRanieri commented on the situation in a 2009 interview. \"It wasn't the concept of securitization that created the problem\", argued Ranieri. Rather, he blamed Wall Street for misusing securitization to create mortgage products that homeowners were unable to afford over the long term, such as those with low 'teaser' rates that became unaffordable when they reset. In the same interview, Ranieri also explained his firm's ongoing efforts to rehabilitate the US housing market by purchasing delinquent mortgages, working with the original homeowners to establish consistent payments, and then selling the newly stabilized loans.", "page_name": "Lewis Ranieri", "page_id": "Lewis%20Ranieri", "heading": "Career", "sub_heading": "Career", "_id": "1000012013--1---1---1", "title": "Ranieri's Mortgage-Backed Securities"}
{"qas": [{"question": "What causes bruxism?", "answer": ""}, {"question": "Bruxism is most common in which age group?", "answer": "50", "ae_score": null, "qg_score": null}, {"question": "Bruxism is most common in which age group?", "answer": "50", "ae_score": null, "qg_score": null}], "content": "Many studies have reported significant psychosocial risk factors for bruxism, particularly a stressful lifestyle, and this evidence is growing, but still not conclusive. Some consider emotional stress to be the main triggering factor. It has been reported that persons with bruxism respond differently to depression, hostility and stress compared to people without bruxism. Stress has a stronger relationship to awake bruxism, but the role of stress in sleep bruxism is less clear, with some stating that there is no evidence for a relationship with sleep bruxism. However, children with sleep bruxism have been shown to have greater levels of anxiety than other children. People aged 50 with bruxism are more likely to be single and have a high level of education. Work-related stress and irregular work shifts may also be involved. Personality traits are also commonly discussed in publications concerning the causes of bruxism, e.g. aggressive, competitive or hyperactive personality types. Some suggest that suppressed anger or frustration can contribute to bruxism. Stressful periods such as examinations, family bereavement, marriage or relocation have been suggested to intensify bruxism. Awake bruxism often occurs during periods of concentration such as while working at a computer, driving or reading. Animal studies have also suggested a link between bruxism and psychosocial factors. Rosales et al. electrocuted lab rats, and then observed high levels of bruxism-like muscular activity in rats that were allowed to watch this treatment compared to rats that did not see it. They proposed that the rats who witnessed the electrocution of other rats were under emotional stress which may have caused the bruxism-like behavior.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Causes", "sub_heading": "Causes", "_id": "1000015271--1--0---1", "title": "Bruxism and Psychosocial Factors"}
{"qas": [{"question": "Why are some people more prone to sleep bruxism than others?", "answer": ""}, {"question": "What percentage of people have a direct family member with sleep bruxism?", "answer": "21\u201350%", "ae_score": -0.8590310789650065, "qg_score": null}, {"question": "What percentage of people have a direct family member with sleep bruxism?", "answer": "21\u201350%", "ae_score": -0.8590310789650065, "qg_score": null}], "content": "Some research suggests that there may be a degree of inherited susceptibility to develop sleep bruxism. 21\u201350% of people with sleep bruxism have a direct family member who had sleep bruxism during childhood, suggesting that there are genetic factors involved, although no genetic markers have yet been identified. Offspring of people who have sleep bruxism are more likely to also have sleep bruxism than children of people who do not have bruxism, or people with awake bruxism rather than sleep bruxism.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Causes", "sub_heading": "Genetic factors", "_id": "1000015271--1--1---1", "title": "Sleep Bruxism: A genetic susceptibility to sleep bruxism"}
{"qas": [{"question": "What causes bruxism?", "answer": ""}, {"question": "Which drug is used to treat parkinson's disease?", "answer": "levodopa", "ae_score": -0.6796049329024085, "qg_score": null}, {"question": "Bruxism is caused by which type of drug?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Certain drugs, including both prescribed and recreational drugs are thought by some to cause the development of bruxism, however others argue that there is insufficient evidence to draw such a conclusion. Examples may include dopamine agonists, dopamine antagonists, tricyclic antidepressants, selective serotonin reuptake inhibitors, alcohol, cocaine, and amphetamines (including those taken for medical reasons). In some reported cases where bruxism is thought to have been initiated by selective serotonin reuptake inhibitors, decreasing the dose resolved the side effect. Other sources state that reports of selective serotonin reuptake inhibitors causing bruxism are rare, and it only happens with long-term use.\nSpecific examples include levodopa (when used in the long term, as in Parkinson's disease), fluoxetine, metoclopramide, lithium, cocaine, venlafaxine, citalopram, fluvoxamine, methylenedioxyamphetamine (MDA), methylphenidate (used in attention deficit hyperactive disorder), and gamma-hydroxybutyric acid (GHB) and similar gamma-aminobutyric acid-inducing analogues such as phenibut. Bruxism can also be exacerbated by excessive consumption of caffeine, as in coffee, tea or chocolate. Bruxism has also been reported to occur commonly comorbid with drug addiction. Methylenedioxymethamphetamine (MDMA, ecstasy) has been reported to be associated with bruxism, which occurs immediately after taking the drug and for several days afterwards. Tooth wear in people who take ecstasy is also frequently much more severe than in people with bruxism not associated with ecstasy.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Causes", "sub_heading": "Medications", "_id": "1000015271--1--2---1", "title": "Bruxism \u2014 Symptoms, Causes, and Treatment"}
{"qas": [{"question": "What is occlusion and Malocclusion?", "answer": ""}, {"question": "What medical term refers to the meeting of teeth during biting and chewing?", "answer": "Occlusion", "ae_score": -0.621397582137746, "qg_score": null}, {"question": "What medical term refers to the meeting of teeth during biting and chewing?", "answer": "Occlusion", "ae_score": -0.621397582137746, "qg_score": null}], "content": "Occlusion is defined most simply as \"contacts between teeth\", and refers to the meeting of teeth during biting and chewing. The term does not imply any disease. Malocclusion is a medical term referring to less than ideal positioning of the upper teeth relative to the lower teeth, which can occur both when the upper jaw is ideally proportioned to the lower jaw, or where there is a discrepancy between the size of the upper jaw relative to the lower jaw. Malocclusion of some sort is so common that the concept of an \"ideal occlusion\" is called into question, and it can be considered \"normal to be abnormal\". An occlusal interference may refer to a problem which interferes with the normal path of the bite, and is usually used to describe a localized problem with the position or shape of a single tooth or group of teeth. A premature contact is a term that refers to one part of the bite meeting sooner than other parts, meaning that the rest of the teeth meet later or are held open, e.g., a new dental restoration on a tooth (e.g., a crown) which has a slightly different shape or position to the original tooth may contact too soon in the bite. A deflective interference refers to an interference with the bite that changes the normal path of the bite. A common example of a deflective is an over-erupted upper wisdom tooth, often because the lower wisdom tooth has been removed or is impacted. In this example, when the jaws are brought together, the lower back teeth contact the prominent wisdom tooth before the other teeth, and the lower jaw has to move forward to get the rest of the teeth to meet. The difference between a premature contact and a deflective interference is that the latter implies a dynamic abnormality in the bite.\nHistorically, many believed that problems with the bite were the sole cause for bruxism. It was often claimed that a person would grind at the interfering area in a subconscious, instinctive attempt to wear this down and \"self equiliberate\" their occlusion. However, occlusal interferences are extremely common and usually do not cause any problems. It is unclear whether people with bruxism tend to notice problems with the bite because of their clenching and grinding habit, or whether these act as a causative factor in the development of the condition. In sleep bruxism especially, there is no evidence that removal of occlusal interferences has any impact on the condition. People with no teeth at all who wear dentures can still suffer from bruxism, although dentures also often change the original bite. Most modern sources state that there is no relationship, or at most a minimal relationship, between bruxism and occlusal factors. The findings of one study, which used self-reported tooth grinding rather than clinical examination to detect bruxism, suggested that there may be more of a relationship between occlusal factors and bruxism in children. However, the role of occlusal factors in bruxism cannot be completely discounted due to insufficient evidence and problems with the design of studies. A minority of researchers continue to claim that various adjustments to the mechanics of the bite are capable of curing bruxism (see Occlusal adjustment/reorganization).", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Causes", "sub_heading": "Occlusal factors", "_id": "1000015271--1--3---1", "title": "Bruxism & Occlusal Interferences"}
{"qas": [{"question": "Why is bruxism so common in dentists?", "answer": ""}, {"question": "What condition can cause significant tooth wear if it is severe?", "answer": "Bruxism", "ae_score": -0.5463524704506693, "qg_score": null}, {"question": "What condition can cause significant tooth wear if it is severe?", "answer": "Bruxism", "ae_score": -0.5463524704506693, "qg_score": null}], "content": "Bruxism can cause significant tooth wear if it is severe, and sometimes dental restorations (crowns, fillings etc.) are damaged or lost, sometimes repeatedly. Most dentists therefore prefer to keep dental treatment in people with bruxism very simple and only carry it out when essential, since any dental work is likely to fail in the long term. Dental implants and complex bridgework for example are relatively contraindicated in bruxists. In the case of crowns, the strength of the restoration becomes more important, sometimes at the cost of esthetic considerations. E.g. a full coverage gold crown, which has a degree of flexibility and also involves less removal (and therefore less weakening) of the underlying natural tooth may be more appropriate than other types of crown which are primarily designed for esthetics rather than durability. Porcelain veneers on the incisors are particularly vulnerable to damage, and sometimes a crown can be perforated by occlusal wear.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Management", "_id": "1000015271--3--0---1", "title": "Bruxism \u2014 Bruxism \u2014 Bruxism"}
{"qas": [{"question": "What are occlusal splints and how do they work?", "answer": ""}, {"question": "What are splints usually made out of?", "answer": "plastic", "ae_score": -0.517492825640883, "qg_score": null}, {"question": "What are splints usually made out of?", "answer": "plastic", "ae_score": -0.517492825640883, "qg_score": null}], "content": "Occlusal splints (also termed dental guards) are commonly prescribed, mainly by dentists and dental specialists, as a treatment for bruxism. Proponents of their use claim many benefits, however when the evidence is critically examined in systematic reviews of the topic, it is reported that there is insufficient evidence to show that occlusal splints are effective for sleep bruxism. Furthermore, occlusal splints are probably ineffective for awake bruxism, since they tend to be worn only during sleep. However, occlusal splints may be of some benefit in reducing the tooth wear that may accompany bruxism, but by mechanically protecting the teeth rather than reducing the bruxing activity itself. In a minority of cases, sleep bruxism may be made worse by an occlusal splint. Some patients will periodically return with splints with holes worn through them, either because the bruxism is aggravated, or unaffected by the presence of the splint. When tooth-to-tooth contact is possible through the holes in a splint, it is offering no protection against tooth wear and needs to be replaced.\nOcclusal splints are divided into partial or full-coverage splints according to whether they fit over some or all of the teeth. They are typically made of plastic (e.g. acrylic) and can be hard or soft. A lower appliance can be worn alone, or in combination with an upper appliance. Usually lower splints are better tolerated in people with a sensitive gag reflex. Another problem with wearing a splint can be stimulation of salivary flow, and for this reason some advise to start wearing the splint about 30 mins before going to bed so this does not lead to difficulty falling asleep. As an added measure for hypersensitive teeth in bruxism, desensitizing toothpastes (e.g. containing strontium chloride) can be applied initially inside the splint so the material is in contact with the teeth all night. This can be continued until there is only a normal level of sensitivity from the teeth, although it should be remembered that sensitivity to thermal stimuli is also a symptom of pulpitis, and may indicate the presence of tooth decay rather than merely hypersensitive teeth.\nSplints may also reduce muscle strain by allowing the upper and lower jaw to move easily with respect to each other. Treatment goals include: constraining the bruxing pattern to avoid damage to the temporomandibular joints; stabilizing the occlusion by minimizing gradual changes to the positions of the teeth, preventing tooth damage and revealing the extent and patterns of bruxism through examination of the markings on the splint's surface. A dental guard is typically worn during every night's sleep on a long-term basis. However, a meta-analysis of occlusal splints (dental guards) used for this purpose concluded \"There is not enough evidence to state that the occlusal splint is effective for treating sleep bruxism.\"\nA ''repositioning splint'' is designed to change the patient's occlusion, or bite. The efficacy of such devices is debated. Some writers propose that irreversible complications can result from the long-term use of mouthguards and repositioning splints. Random controlled trials with these type devices generally show no benefit over other therapies.Another partial splint is the nociceptive trigeminal inhibition tension suppression system (NTI-TSS) dental guard. This splint snaps onto the upper front teeth only. It is theorized to prevent tissue damages primarily by reducing the bite force from attempts to close the jaw normally into a forward twisting of the lower front teeth. The intent is for the brain to interpret the nerve sensations as undesirable, automatically and subconsciously reducing clenching force. However, there may be potential for the NTI-TSS device to act as a Dahl appliance, holding the posterior teeth out of occlusion and leading to their over-eruption, deranging the occlusion (i.e.  it may cause the teeth to move position). Hence, ongoing follow-ups are recommended.\nA mandibular advancement device (normally used for treatment of obstructive sleep apnea) may reduce sleep bruxism, although its use may be associated with discomfort.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Dental guards and occlusal splints", "_id": "1000015271--3--1---1", "title": "Occlusal splints for Sleep Bruxism"}
{"qas": [{"question": "Why is it so important to treat bruxism?", "answer": ""}, {"question": "What is the most common treatment for bruxism?", "answer": "Cognitive behavioral therapy", "ae_score": -0.6306102529076218, "qg_score": null}, {"question": "What is the most common treatment for bruxism?", "answer": "Cognitive behavioral therapy", "ae_score": -0.6306102529076218, "qg_score": null}], "content": "Given the strong association between awake bruxism and psychosocial factors (the relationship between sleep bruxism and psychosocial factors being unclear), the role of psychosocial interventions could be argued to be central to the management. The most simple form of treatment is therefore reassurance that the condition does not represent a serious disease, which may act to alleviate contributing stress. Other interventions include relaxation techniques, stress management, behavioural modification, habit reversal and hypnosis (self hypnosis or with a hypnotherapist). Cognitive behavioral therapy has been recommended by some for treatment of bruxism.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Psychosocial interventions", "_id": "1000015271--3--2---1", "title": "Bruxism and Psychosocial Interventions"}
{"qas": [{"question": "Why are there so many different medications for bruxism?", "answer": ""}, {"question": "What is the name of the drug used to treat bruxism?", "answer": "buspirone", "ae_score": -0.3810318501569122, "qg_score": null}, {"question": "What type of medication is used to treat bruxism?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Many different medications have been used to treat bruxism, including benzodiazepines, anticonvulsants, beta blockers, dopamine agents, antidepressants, muscle relaxants, and others. However, there is little, if any, evidence for their respective and comparative efficacies with each other and when compared to a placebo.  A systematic review is underway to investigate the evidence for drug treatments in sleep bruxism.\nSpecific drugs that have been studied in sleep bruxism are clonazepam, levodopa,<ref name=Machado2011/> amitriptyline,<ref name=Machado2011/>  bromocriptine,<ref name=Machado2011/>   pergolide, clonidine, propranolol, and l-tryptophan, with some showing no effect and others appear to have promising initial results; however, it has been suggested that further safety testing is required before any evidence-based clinical recommendations can be made. When bruxism is related to the use of selective serotonin reuptake inhibitors in depression, adding buspirone has been reported to resolve the side effect. Tricyclic antidepressants have also been suggested to be preferable to selective serotonin reuptake inhibitors in people with bruxism, and may help with the pain.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Medication", "_id": "1000015271--3--3---1", "title": "Sleep Bruxism: A Review"}
{"qas": [{"question": "How does Botox work?", "answer": ""}, {"question": "How many people were studied for bruxism?", "answer": "thirty", "ae_score": -0.4967343192650804, "qg_score": null}, {"question": "How many people were studied for bruxism?", "answer": "thirty", "ae_score": -0.4967343192650804, "qg_score": null}], "content": "Botulinum toxin (Botox) is used as a treatment for bruxism, however there is only one randomized control trial which has reported that Botox reduces the myofascial pain symptoms. This scientific study was based on thirty people with bruxism who received Botox injections into the muscles of mastication and a control group of people with bruxism who received placebo injections. Normally multiple trials with larger cohorts are required to make any firm statement about the efficacy of a treatment. In 2013, a further randomized control trial investigating Botox in bruxism started. There is also little information available about the safety and long term followup of this treatment for bruxism.\nBotulinum toxin causes muscle paralysis/atrophy by inhibition of acetylcholine release at neuromuscular junctions. Botox injections are used in bruxism on the theory that a dilute solution of the toxin will partially paralyze the muscles and lessen their ability to forcefully clench and grind the jaw, while aiming to retain enough muscular function to enable normal activities such as talking and eating. This treatment typically involves five or six injections into the masseter and temporalis muscles, and less often into the lateral pterygoids (given the possible risk of decreasing the ability to swallow) taking a few minutes per side. The effects may be noticeable by the next day, and they may last for about three months. Occasionally, adverse effects may occur, such as bruising, but this is quite rare. The dose of toxin used depends upon the person, and a higher dose may be needed in people with stronger muscles of mastication. With the temporary and partial muscle paralysis, atrophy of disuse may occur, meaning that the future required dose may be smaller or the length of time the effects last may be increased.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Botox", "_id": "1000015271--3--4---1", "title": "Botox in Bruxism: A Randomized Control Trial"}
{"qas": [{"question": "What is biofeedback?", "answer": ""}, {"question": "What is the term for a process that allows an individual to become aware of and alter?", "answer": "Biofeedback", "ae_score": -0.29114415699587226, "qg_score": null}, {"question": "What is the term for a process that allows an individual to become aware of and alter?", "answer": "Biofeedback", "ae_score": -0.29114415699587226, "qg_score": null}], "content": "Biofeedback refers to a process (or device that enables such a process) that allows an individual to become aware of, and alter physiological activity with the aim of improving health. There is no evidence for the long term use and safety of biofeedback in the management of bruxism. Electromyographic monitoring of the muscles with automatic alerting during periods of clenching and grinding has been prescribed for awake bruxism. Dental appliances with capsules that break and release a taste stimulus when enough force is applied have also been described in sleep bruxism, which would wake the person from sleep in an attempt to prevent bruxism episodes. Unfortunately this resulted in excessive daytime sleepiness.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Biofeedback", "_id": "1000015271--3--5---1", "title": "Bruxism & Biofeedback in the United States"}
{"qas": [{"question": "Why do dentists keep removing bruxism?", "answer": ""}, {"question": "What is another name for occclusal rehabilitation?", "answer": "occlusal equilibration", "ae_score": -2.0953586358780054, "qg_score": null}, {"question": "Why do some dentists try to reorganize the occlusion?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "As an alternative to simply reactively repairing the damage to teeth and conforming to the existing occlusal scheme, occasionally some dentists will attempt to reorganize the occlusion in the belief that this may redistribute the forces and reduce the amount of damage inflicted on the dentition. Sometimes termed \"occlusal rehabilitation\" or \"occlusal equilibration\", this can be a complex procedure, and there is much disagreement between proponents of these techniques on most of the aspects involved, including the indications and the goals. It may involve orthodontics, restorative dentistry or even orthognathic surgery. Some have criticized these occlusal reorganizations as having no evidence base, and irreversibly damaging the dentition on top of the damage already caused by bruxism.", "page_name": "Bruxism", "page_id": "Bruxism", "heading": "Management", "sub_heading": "Occlusal adjustment/reorganization", "_id": "1000015271--3--6---1", "title": "Bruxism | Management | Occlusal adjustment/reorganization"}
{"qas": [{"question": "Isotope markers?", "answer": ""}, {"question": "What is a fluorescent tag usually used for?", "answer": "proteins", "ae_score": -0.5562224749093823, "qg_score": null}, {"question": "Where do you find fluorescent markers on a protein?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "Common species that isotope markers are used for include proteins. In this case, amino acids with stable isotopes of either carbon, nitrogen, or hydrogen are incorporated into polypeptide sequences. These polypeptides are then put through mass spectrometry. Because of the exact defined change that these isotopes incur on the peptides, it is possible to tell through the spectrometry graph which peptides contained the isotopes. By doing so, one can extract the protein of interest from several others in a group. Isotopic compounds play an important role as photochromes, described below.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Methods for tracking biomolecules", "_id": "1000016758--1--0---1", "title": "Isotope Markers in Proteins"}
{"qas": [{"question": "How do we know how many different species of animals are in the world?", "answer": ""}, {"question": "What is used to measure the amount of light in a fluorescent tag?", "answer": "Colorimetric assays", "ae_score": -0.19747297402027544, "qg_score": null}, {"question": "What is used to measure the amount of light in a fluorescent tag?", "answer": "Colorimetric assays", "ae_score": -0.19747297402027544, "qg_score": null}], "content": "Biosensors are attached to a substance of interest. Normally, this substance would not be able to absorb light, but with the attached biosensor, light can be absorbed and emitted on a spectrophotometer. Additionally, biosensors that are fluorescent can be viewed with the naked eye. Some fluorescent biosensors also have the ability to change color in changing environments (ex: from blue to red). A researcher would be able to inspect and get data about the surrounding environment based on what color he or she could see visibly from the biosensor-molecule hybrid species.\nColorimetric assays are normally used to determine how much concentration of one species there is relative to another.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Colorimetric biosensors", "_id": "1000016758--1--1---1", "title": "Biosensors: Colorimetric Assays"}
{"qas": [{"question": "How do photoschromic compounds work?", "answer": ""}, {"question": "What is the most common organic molecule used as a photochrome?", "answer": "diarylethene", "ae_score": -0.2716824605965011, "qg_score": null}, {"question": "What is the most common organic molecule used as a photochrome?", "answer": "diarylethene", "ae_score": -0.2716824605965011, "qg_score": null}], "content": "Photochromic compounds have the ability to switch between a range or variety of colors. Their ability to display different colors lies in how they absorb light. Different isomeric manifestations of the molecule absorbs different wavelengths of light, so that each isomeric species can display a different color based on its absorption. These include photoswitchable compounds, which are proteins that can switch from a non-fluorescent state to that of a fluorescent one given a certain environment.\nThe most common organic molecule to be used as a photochrome is diarylethene.  Other examples of photoswitchable proteins include PADRON-C, rs-FastLIME-s and bs-DRONPA-s, which can be used in plant and mammalian cells alike to watch cells move into different environments.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Photochromic compounds", "_id": "1000016758--1--2---1", "title": "Photochromic Compounds \u2014 How They Can Switch From Fluorescent to Fluor"}
{"qas": [{"question": "Fluorescent biomaterials?", "answer": ""}, {"question": "Where can fluorescent markers be used to see a pathway?", "answer": "external factors", "ae_score": -1.4347131417115013, "qg_score": null}, {"question": "Where can fluorescent markers be used to see a pathway?", "answer": "external factors", "ae_score": -1.4347131417115013, "qg_score": null}], "content": "Fluorescent biomaterials are a possible way of using external factors to observe a pathway more visibly. The method involves fluorescently labeling peptide molecules that would alter an organism's natural pathway. When this peptide is inserted into the organism's cell, it can induce a different reaction. This method can be used, for example to treat a patient and then visibly see the treatment's outcome.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Biomaterials", "_id": "1000016758--1--3---1", "title": "Fluorescent biomaterials are a possible way to use external factors to observe a"}
{"qas": [{"question": "How do electrochemical sensors work?", "answer": ""}, {"question": "What type of sensors are used to identify molecules?", "answer": "Electrochemical sensors", "ae_score": -0.5594855657038956, "qg_score": null}, {"question": "Where is the fluorescent tag located in a cell?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "Electrochemical sensors can used for label-free sensing of biomolecules.  They detect changes and measure current between a probed metal electrode and an electrolyte containing the target analyte.  A known potential to the electrode is then applied from a feedback current and the resulting current can be measured.  For example, one technique using electrochemical sensing includes slowly raising the voltage causing chemical species at the electrode to be oxidized or reduced.  Cell current vs voltage is plotted which can ultimately identify the quantity of chemical species consumed or produced at the electrode. Fluorescent tags can be used in conjunction with electrochemical sensors for ease of detection in a biological system.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Electrochemical sensors", "_id": "1000016758--1--4---1", "title": "Electrochemical Sensors for Label-Free Sensing of Biomolecules"}
{"qas": [{"question": "Why do we need fluorescent labels?", "answer": ""}, {"question": "What is the name of the synthetic fluorescence tag?", "answer": "Spinach aptamer", "ae_score": -0.30687335490045836, "qg_score": null}, {"question": "What is the name of the synthetic fluorescence tag?", "answer": "Spinach aptamer", "ae_score": -0.30687335490045836, "qg_score": null}], "content": "Of the various methods of labeling biomolecules, fluorescent labels are advantageous in that they are highly sensitive even at low concentration and non-destructive to the target molecule folding and function.\nGreen fluorescent protein is a naturally occurring fluorescent protein from the jellyfish ''Aequorea victoria'' that is widely used to tag proteins of interest.  GFP emits a photon in the green region of the light spectrum when excited by the absorption of light.  The chromophore consists of an oxidized tripeptide -Ser^65-Tyr^66-Gly^67 located within a \u03b2 barrel.  GFP catalyzes the oxidation andonly requires molecular oxygen.  GFP has been modified by changing the wavelength of light absorbed to include other colors of fluorescence.  YFP or yellow fluorescent protein, BFP or blue fluorescent protein, and CFP or cyan fluorescent protein are examples of GFP variants.  These variants are produced by the genetic engineering of the GFP gene.\nAn equivalent RNA mimic version of GFP has also been developed, known as the Spinach aptamer. Similar to GFP, Spinach can be genetically encoded on the mRNA level for cellular imaging without the need of chemical ligation or hybridization.\nSynthetic fluorescent probes can also be used as fluorescent labels.  Advantages of these labels include a smaller size with more variety in color.  They can be used to tag proteins of interest more selectively by various methods including chemical recognition-based labeling, such as utilizing metal-chelating peptide tags, and biological recognition-based labeling utilizing enzymatic reactions.  However, despite their wide array of excitation and emission wavelengths as well as better stability, synthetic probes tend to be toxic to the cell and so are not generally used in cell imaging studies.\nFluorescent labels can be hybridized to mRNA to help visualize interaction and activity, such as mRNA localization. An antisense strand labeled with the fluorescent probe is attached to a single mRNA strand, and can then be viewed during cell development to see the movement of mRNA within the cell.", "page_name": "Fluorescent tag", "page_id": "Fluorescent%20tag", "heading": "Methods for tracking biomolecules", "sub_heading": "Fluorescent labels", "_id": "1000016758--1--5---1", "title": "Fluorescent Labels and Molecular Imaging"}
{"qas": [{"question": "How did the idea of a dharmic life come about?", "answer": ""}, {"question": "What is the term for ethics in hinduism?", "answer": "Nitisastra", "ae_score": -0.21639092424333228, "qg_score": null}, {"question": "What is the hindu word for acceptance of circumstances with optimism?", "answer": "OSHA", "ae_score": null, "qg_score": null}], "content": "Ethics is called Nitisastra (Sanskrit: \u0928\u0940\u0924\u093f\u0936\u093e\u0938\u094d\u0924\u094d\u0930) in ancient texts of Hinduism. Ethics and virtue are a much debated<ref>Roderick Hindery (2004), Comparative Ethics in Hindu and Buddhist Traditions, ISBN 978-8120808669; pages 268-72;\nEthics are explained in Hindu philosophy as something that cannot be imposed, but something that is realized and voluntarily lived up to by each individual. For example, Apastamba explained it thus: \"virtue and vice do not go about saying - here we are!; neither the Gods, Gandharvas, nor ancestors can convince us - this is right, this is wrong; virtue is an elusive concept, it demands careful and sustained reflection by every man and woman before it can become part of one's life.<ref>Phillip Wagoner, see Foreword, in Srinivasan, Dharma: Hindu Approach to a Purposeful Life, ISBN 978-1-62209-672-5;\nEthics that constitute a dharmic life  - that is a moral, ethical, virtuous life - evolve in vedas and upanishads. Ethical subjects and questions are debated by various schools of Hinduism, quite extensively, in numerous texts on what is right conduct, when, how and why.<ref name=agw/> Over time, new virtues were conceptualized and added by ancient Hindu scholars, some replaced, others merged. For example, Manusamhita initially listed ten virtues necessary for a human being to live a ''dharmic'' life: ''Dhriti'' (courage), ''Kshama'' (forgiveness), ''Dama'' (temperance), ''Asteya'' (Non-covetousness/Non-stealing), ''Saucha'' (inner purity), ''Indriyani-graha'' (control of senses), ''dhi'' (reflective prudence), ''vidya'' (wisdom), ''satyam'' (truthfulness), ''akrodha'' (freedom from anger). In later verses, this list was reduced to five virtues by the same scholar, by merging and creating a more broader concept. The shorter list of virtues became: ''Ahimsa'' (Non-violence), ''Dama'' (self restraint), ''Asteya'' (Non-covetousness/Non-stealing), ''Saucha'' (inner purity), ''Satyam'' (truthfulness).\nThe Persian historian Al Biruni who visited and lived in India for 16 years in the early 11th century, describes the concept of ethics and virtuous behavior among Hindus of his times. Of ethical mandates among Hindus, a literal translation of his Persian language manuscript includes (1) A man shall not kill; (2) nor lie; (3) nor steal; (4) nor whore; (5) nor hoard up treasures. These correspond to five ''Yamas'' of ancient Hindu ethics: Ahimsa (non-violence), Satya (truth, non-falsehood), Asteya (non-stealing), Brahmacharya (celibacy if unmarried and non-cheating on one's partner if married), and Aparigraha (non-possessiveness). In addition to these five negative things to abstain from, Hindu ethics also recommends five positive things to strive for as ''Niyamas'': ''\u015aauca'' (purity in body, speech and mind), ''Santosha'' (contentment, acceptance of circumstances with optimism), ''Tapas'' (perseverance, meditation, austerity), ''Swadhyaya'' (lifelong learning) and ''Pranidhan'' (right attitude, contemplation).<ref name=ah/> An ethical life in Hinduism is essential for a liberated life, one without craving, one that is content, attained through knowledge and by abstaining from evil.\nHindu literature variously discuss ethics as one or more of four topics: (1) ''Gunas'' that is inner tendencies of conduct found in every individual (in large measure, psychology); (2) ''Purushartha'' that is proper aims of life for every individual for self-development and happiness (dharma, artha, kama and moksha); (3) ''Ashramas'' that is ethics for an individual in different periods of one's lifetime (ethical expectations for a child are distinguished from those for adults, old age); and (4) ''Varnasramas'' that is ethics and conduct for every individual in relation to society.<ref name=agw/> Ancient literature at the foundation of various Hindu traditions primarily discuss the first three, while the last has attracted greater attention since the 18th century. Some early 20th century literature wondered if ethics was ever a serious topic of study in Hinduism. Later studies have yielded the above four approaches to ethics in different schools of Hinduism, tied together with three common themes:<ref name=agw/><ref name=wfg/> (1) ethics is an essential part of dharma concept,<ref name=wfg2/> (2) Ahimsa (non-violence) is the foundational premise without which - suggests Hinduism - ethics and any consistent ethical theory is impossible, and (3) Ethics cannot always be dualistically or non-dualistically reduced from first principles, ethics is closely related to moksha (self realization and spiritual freedom) with Vivekacudamani stating, \"individuals with self knowledge and spiritual freedom are inherently self examining and ethical\" and \"ethics, freedom and knowledge require each other\". In addition to the above four topics in Hindu ethics, scholars state that the karma doctrine of Hinduism is part of its ethical theory compendium.\nThe Bhagavad Gita\u2014considered one of the epitomes of historic Hindu discussion of virtues and an allegorical debate on what is right and what is wrong\u2014argues some virtues are not necessarily always absolute, but sometimes relational; for example, it explains a virtue such as Ahimsa must be re-examined when one is faced with war or violence from the aggressiveness, immaturity or ignorance of others.", "page_name": "Ethics in religion", "page_id": "Ethics%20in%20religion", "heading": "Hindu ethics", "sub_heading": "Hindu ethics", "_id": "1000017381--4---1---1", "title": "Ethics in Hinduism"}
{"qas": [{"question": "What is the difference between secularism and nihilism?", "answer": ""}, {"question": "What is the name for a moral philosophy in which ethics are based solely on human faculties?", "answer": "Secular ethics", "ae_score": -0.6011887853310278, "qg_score": null}, {"question": "What are the different types of secular ethics?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": " Secular ethics is a moral philosophy in which ethics are based solely on human faculties such as scientific reason, sociobiological composition, or ethical intuition, and not derived from purported supernatural revelation or guidance. Secular ethics comprise a wide variety of moral and ethical systems including consequentialism, freethinking, humanism, secular humanism, and utilitarianism, among others.\nThe majority of secular moral concepts are based on the acceptance of natural rights and social contracts, and on a more individual scale of either some form of attribution of intrinsic value to things, Kantianesque ethical intuitionism or of a logical deduction that establishes a preference for one thing over another, as with Occam's razor. Approaches such as ethical egoism, moral relativism, moral skepticism, and moral nihilism are also considered.", "page_name": "Ethics in religion", "page_id": "Ethics%20in%20religion", "heading": "Secular ethics", "sub_heading": "Secular ethics", "_id": "1000017381--9---1---1", "title": "Secular Ethics (Secular Humanism)"}
{"qas": [{"question": "What is the difference between an ASD diagnosis and an Autism diagnosis?", "answer": ""}, {"question": "What is the most common form of autism?", "answer": "Asperger syndrome", "ae_score": -0.25057788355927274, "qg_score": null}, {"question": "What is the most common form of autism?", "answer": "Asperger syndrome", "ae_score": -0.25057788355927274, "qg_score": null}], "content": "A revision to '''autism spectrum disorder''' ('''ASD''') was presented in the ''Diagnostic and Statistical Manual of Mental Disorders'' version 5 (DSM-5), released May 2013. The new diagnosis encompasses previous diagnoses of autistic disorder, Asperger's disorder, childhood disintegrative disorder, and PDD-NOS. Compared with the DSM-IV diagnosis of autistic disorder, the DSM-5 diagnosis of ASD no longer includes communication as a separate criterion, and has merged social interaction and communication into one category.\nRather than categorizing these diagnoses, the DSM-5 has adopted a dimensional approach to diagnosing disorders that fall underneath the autism spectrum umbrella. Some have proposed that individuals on the autism spectrum may be better represented as a single diagnostic category. Within this category, the DSM-5 has proposed a framework of differentiating each individual by dimensions of severity, as well as associated features (i.e., known genetic disorders, and intellectual disability).\nAnother change to the DSM includes collapsing social and communication deficits into one domain. Thus, an individual with an ASD diagnosis will be described in terms of severity of social communication symptoms, severity of fixated or restricted behaviors or interests, and associated features. The restriction of onset age has also been loosened from 3 years of age to \"early developmental period\", with a note that symptoms may manifest later when demands exceed capabilities.\nAutism forms the core of the autism spectrum disorders. Asperger syndrome is closest to autism in signs and likely causes; unlike autism, people with Asperger syndrome have no significant delay in language development, according to the older DSM-4 criteria. PDD-NOS is diagnosed when the criteria are not met for a more specific disorder. Some sources also include Rett syndrome and childhood disintegrative disorder, which share several signs with autism but may have unrelated causes; other sources differentiate them from ASD, but group all of the above conditions into the pervasive developmental disorders.\nAutism, Asperger syndrome, and PDD-NOS are sometimes called the ''autistic disorders'' instead of ASD, whereas autism itself is often called ''autistic disorder'', ''childhood autism'', or ''infantile autism''.<ref name=Piven/> Although the older term ''pervasive developmental disorder'' and the newer term ''autism spectrum disorder'' largely or entirely overlap, the earlier was intended to describe a specific set of diagnostic labels, whereas the latter refers to a postulated spectrum disorder linking various conditions. ASD is a subset of the broader autism phenotype (BAP), which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.", "page_name": "Autism spectrum", "page_id": "Autism%20spectrum", "heading": "Classification", "sub_heading": "Classification", "_id": "1000019243--0---1---1", "title": "Autism Spectrum Disorder: A New Diagnostic Diagnostic Approach"}
{"qas": [{"question": "Why do people with autism have such a hard time speaking?", "answer": ""}, {"question": "What is it called when a child can display outstanding skills in music, art, and?", "answer": "autistic savantism", "ae_score": -0.30078408128494194, "qg_score": null}, {"question": "What is it called when a child can display outstanding skills in music, art, and?", "answer": "autistic savantism", "ae_score": -0.30078408128494194, "qg_score": null}], "content": "Under the DSM-5, autism is characterized by persistent deficits in social communication and interaction across multiple contexts, as well as restricted, repetitive patterns of behavior, interests, or activities. These deficits are present in early childhood, and lead to clinically significant functional impairment. There is also a unique form of autism called autistic savantism, where a child can display outstanding skills in music, art, and numbers with no practice. Because of its relevance to different populations, self-Injurious behaviors (SIB) are not considered a core characteristic of the ASD population however approximately 50% of those with ASD take part in some type of SIB (head-banging, self-biting) and are more at risk than other groups with developmental disabilities.\nSome of the language behaviors typically seen in children with autism may include repetitive or rigid language, specific interests in conversation, atypical language development, or poor nonverbal communication skills, including lack of eye contact and meaningful gestures and facial expressions. \nAsperger syndrome was distinguished from autism in the DSM-IV by the lack of delay or deviance in early language development. Additionally, individuals diagnosed with Asperger syndrome did not have significant cognitive delays. PDD-NOS was considered \"subthreshold autism\" and \"atypical autism\" because it was often characterized by milder symptoms of autism or symptoms in only one domain (such as social difficulties). In the DSM-5, both Asperger syndrome and PDD-NOS have been incorporated into autism spectrum disorder.\nAutism spectrum disorders are thought to follow two possible developmental courses, although most parents report that symptom onset occurred within the first year of life. One course of development is more gradual in nature, in which parents report concerns in development over the first two years of life and diagnosis is made around 3\u20134 years of age. Some of the early signs of ASDs in this course include decreased looking at faces, failure to turn when name is called, failure to show interests by showing or pointing, and delayed pretend play.\nA second course of development is characterized by normal or near-normal development followed by loss of skills or regression in the first 2\u20133 years. Regression may occur in a variety of domains, including communication, social, cognitive, and self-help skills; however, the most common regression is loss of language.\nThere continues to be a debate over the differential outcomes based on these two developmental courses. Some studies suggest that regression is associated with poorer outcomes and others report no differences between those with early gradual onset and those who experience a regression period. While there is conflicting evidence surrounding language outcomes in ASD, some studies have shown that cognitive and language abilities at age  may help predict language proficiency and production after age 5. Overall, the literature stresses the importance of early intervention in achieving positive longitudinal outcomes.", "page_name": "Autism spectrum", "page_id": "Autism%20spectrum", "heading": "Characteristics", "sub_heading": "Characteristics", "_id": "1000019243--1---1---1", "title": "Autism Spectrum Disorder \u2014 A Brief Overview"}
{"qas": [{"question": "What would happen if the Bear Stearns funds were auctioned?", "answer": ""}, {"question": "Who is the manager of the world's largest bond fund?", "answer": "PIMCO", "ae_score": -0.18630284051087542, "qg_score": null}, {"question": "What type of securities were the biggest losers in the housing market?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "In March 2007, the United States' subprime mortgage industry collapsed due to higher-than-expected home foreclosure rates, with more than 25 subprime lenders declaring bankruptcy, announcing significant losses, or putting themselves up for sale. The stock of the country's largest subprime lender, New Century Financial, plunged 84% amid Justice Department investigations, before ultimately filing for Chapter 11 bankruptcy on 2 April 2007 with liabilities exceeding $100 million.\nThe manager of the world's largest bond fund PIMCO, warned in June 2007 that the subprime mortgage crisis was not an isolated event and would eventually take a toll on the economy and impact the impaired prices of homes. Bill Gross, \"a most reputable financial guru\", sarcastically and ominously criticized the credit ratings of the mortgage-based CDOs now facing collapse: \nFinancial analysts predicted that the subprime mortgage collapse would result in earnings reductions for large Wall Street investment banks trading in mortgage-backed securities, especially Bear Stearns, Lehman Brothers, Goldman Sachs, Merrill Lynch, and Morgan Stanley. The solvency of two troubled hedge funds managed by Bear Stearns was imperliled in June 2007 after Merrill Lynch sold off assets seized from the funds and three other banks closed out their positions with them. The Bear Stearns funds once had over $20 billion of assets, but lost billions of dollars on securities backed by subprime mortgages.\nH&R Block reported a quarterly loss of $677 million on discontinued operations, which included subprime lender Option One, as well as writedowns, loss provisions on mortgage loans and the lower prices available for mortgages in the secondary market for mortgages. The units net asset value fell 21% to $1.1 billion as of April 30, 2007. The head of the mortgage industry consulting firm Wakefield Co. warned, \"This is going to be a meltdown of unparalleled proportions. Billions will be lost.\" Bear Stearns pledged up to US$3.2 billion in loans on 22 June 2007 to bail out one of its hedge funds that was collapsing because of bad bets on subprime mortgages.\nPeter Schiff, president of Euro Pacific Capital, argued that if the bonds in the Bear Stearns funds were auctioned on the open market, much weaker values would be plainly revealed. Schiff added, \"This would force other hedge funds to similarly mark down the value of their holdings. Is it any wonder that Wall street is pulling out the stops to avoid such a catastrophe? ... Their true weakness will finally reveal the abyss into which the housing market is about to plummet.\"\nA ''The New York Times'' report connected the hedge fund crisis with lax lending standards: \"The crisis this week from the near collapse of two hedge funds managed by Bear Stearns stems directly from the slumping housing market and the fallout from loose lending practices that showered money on people with weak, or subprime, credit, leaving many of them struggling to stay in their homes.\"\nIn the wake of the mortgage industry meltdown, Senator Chris Dodd, Chairman of the Banking Committee held hearings in March 2007 and asked executives from the top five subprime mortgage companies to testify and explain their lending practices.  Dodd said, \"Predatory lending practices endangered the home ownership for millions of people\". Moreover, Democratic senators such as Senator Charles Schumer of New York were proposing a federal government bailout of subprime borrowers in order to save homeowners from losing their residences. Opponents of such proposal asserted that government bailout of subprime borrowers was not in the best interests of the U.S. economy because it would set a bad precedent, create a moral hazard, and worsen the speculation problem in the housing market.\nLou Ranieri of Salomon Brothers, inventor of the mortgage-backed securities market in the 1970s, warned of the future impact of mortgage defaults: \"This is the leading edge of the storm. ... If you think this is bad, imagine what it's going to be like in the middle of the crisis.\" In his opinion, more than $100 billion of home loans are likely to default when the problems in the subprime industry appear in the prime mortgage markets. Fed Chairman Alan Greenspan praised the rise of the subprime mortgage industry and the tools used to assess credit-worthiness in an April 2005 speech: \nBecause of these remarks, along with his encouragement for the use of adjustable-rate mortgages, Greenspan was criticized for his role in the rise of the housing bubble and the subsequent problems in the mortgage industry.", "page_name": "United States housing market correction", "page_id": "United%20States%20housing%20market%20correction", "heading": "Major downturn and subprime mortgage collapse, 2007", "sub_heading": "Major downturn and subprime mortgage collapse, 2007", "_id": "1000024211--2--0---1", "title": "The Subprime Mortgage Crisis"}
{"qas": [{"question": "Why is it so hard for people to refinance their homes?", "answer": ""}, {"question": "How many homes are unsold in the us?", "answer": "4.2 million", "ae_score": -0.3392357979068345, "qg_score": null}, {"question": "What type of programs are going out of business in the us?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "The 30-year mortgage rates increased by more than a half a percentage point to 6.74 percent during May\u2013June 2007, affecting borrowers with the best credit just as a crackdown in subprime lending standards limits the pool of qualified buyers. The national median home price is poised for its first annual decline since the Great Depression, and the NAR reported that supply of unsold homes is at a record 4.2 million.\nGoldman Sachs and Bear Stearns, respectively the world's largest securities firm and largest underwriter of mortgage-backed securities in 2006, said in June 2007 that rising foreclosures reduced their earnings and the loss of billions from bad investments in the subprime market imperiled the solvency of several hedge funds. Mark Kiesel, executive vice president of a California-based Pacific Investment Management Co. said, \n According to Donald Burnette of Brightgreen Homeloans in Florida (one of the states hit hardest by the bursting housing bubble) the corresponding loss in equity from the drop in housing values caused new problems. \"It is keeping even borrowers with good credit and solid resources from refinancing to much better terms. Even with tighter lending restrictions and the disappearance of subprime programs, there are many borrowers who would indeed qualify as \"A\" borrowers who can't refinance as they no longer have the equity in their homes that they had in 2005 or 2006. They will have to wait for the market to recover to refinance to the terms they deserve, and that could be years, or even a decade.\" It is foreseen, especially in California, that this recovery process could take until 2014 or later.\nA 2012 report from the University of Michigan analyzed data from the Panel Study of Income Dynamics (PSID), which surveyed roughly 9,000 representative households in 2009 and 2011. The data seemed to indicate that, while conditions were still difficult, in some ways the crisis was easing: Over the period studied, the percentage of families behind on mortgage payments fell from 2.2 to 1.9; homeowners who thought it was \"very likely or somewhat likely\" that they would fall behind on payments fell from 6% to 4.6% of families. On the other hand, family's financial liquidity had decreased: \u201cAs of 2009, 18.5% of families had no liquid assets, and by 2011 this had grown to 23.4% of families.\u201d", "page_name": "United States housing market correction", "page_id": "United%20States%20housing%20market%20correction", "heading": "Foreclosure rates increase", "sub_heading": "Foreclosure rates increase", "_id": "1000024211--4---1---1", "title": "Refinancing to the best terms could take years or even a decade"}
{"qas": [{"question": "Why is there such a push for a government bailout of subprime mortgage companies?", "answer": ""}, {"question": "Who was the chairman of the federal reserve at the time of the housing bubble?", "answer": "Alan Greenspan", "ae_score": -0.2776258569157197, "qg_score": null}, {"question": "What type of housing crisis was blamed for the collapse of the housing market?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "In March 2007, the United States' subprime mortgage industry collapsed due to higher-than-expected home foreclosure rates (no verifying source), with more than 25 subprime lenders declaring bankruptcy, announcing significant losses, or putting themselves up for sale. The stock of the country's largest subprime lender, New Century Financial, plunged 84% amid Justice Department investigations, before ultimately filing for Chapter 11 bankruptcy on April 2, 2007, with liabilities exceeding $100 million.\nThe manager of the world's largest bond fund, PIMCO, warned in June 2007 that the subprime mortgage crisis was not an isolated event and would eventually take a toll on the economy and ultimately have an impact in the form of impaired home prices. Bill Gross, a \"most reputable financial guru\", sarcastically and ominously criticized the credit ratings of the mortgage-based CDOs now facing collapse: \nBusiness Week has featured predictions by financial analysts that the subprime mortgage market meltdown would result in earnings reductions for large Wall Street investment banks trading in mortgage-backed securities, especially Bear Stearns, Lehman Brothers, Goldman Sachs, Merrill Lynch, and Morgan Stanley. The solvency of two troubled hedge funds managed by Bear Stearns was imperiled in June 2007 after Merrill Lynch sold off assets seized from the funds and three other banks closed out their positions with them. The Bear Stearns funds once had over $20 billion of assets, but lost billions of dollars on securities backed by subprime mortgages.\nH&R Block reported that it had made a quarterly loss of $677 million on discontinued operations, which included the subprime lender Option One, as well as writedowns, loss provisions for mortgage loans and the lower prices achievable for mortgages in the secondary market. The unit's net asset value had fallen 21% to $1.1 billion as of April 30, 2007. The head of the mortgage industry consulting firm Wakefield Co. warned, \"This is going to be a meltdown of unparalleled proportions. Billions will be lost.\" Bear Stearns pledged up to U.S. $3.2 billion in loans on June 22, 2007, to bail out one of its hedge funds that was collapsing because of bad bets on subprime mortgages.\nPeter Schiff, president of Euro Pacific Capital, argued that if the bonds in the Bear Stearns funds were auctioned on the open market, much weaker values would be plainly revealed. Schiff added, \"This would force other hedge funds to similarly mark down the value of their holdings. Is it any wonder that Wall street is pulling out the stops to avoid such a catastrophe?... Their true weakness will finally reveal the abyss into which the housing market is about to plummet.\" The ''New York Times'' report connects the hedge fund crisis with lax lending standards: \"The crisis this week from the near collapse of two hedge funds managed by Bear Stearns stems directly from the slumping housing market and the fallout from loose lending practices that showered money on people with weak, or subprime, credit, leaving many of them struggling to stay in their homes.\"\nOn August 9, 2007, BNP Paribas announced that it could not fairly value the underlying assets in three funds because of its exposure to U.S. subprime mortgage lending markets.  Faced with potentially massive (though unquantifiable) exposure, the European Central Bank (ECB) immediately stepped in to ease market worries by opening lines of \u20ac96.8 billion (U.S. $130 billion) of low-interest credit. One day after the financial panic about a credit crunch had swept through Europe, the U.S. Federal Reserve Bank conducted an \"open market operation\" to inject U.S. $38 billion in temporary reserves into the system to help overcome the ill effects of a spreading credit crunch, on top of a similar move the previous day.  In order to further ease the credit crunch in the U.S. credit market, at 8:15 a.m. on August 17, 2007, the chairman of the Federal Reserve Bank Ben Bernanke decided to lower the discount window rate, which is the lending rate between banks and the Federal Reserve Bank, by 50 basis points to 5.75% from 6.25%. The Federal Reserve Bank stated that the recent turmoil in the U.S. financial markets had raised the risk of an economic downturn.\nIn the wake of the mortgage industry meltdown, Senator Chris Dodd, Chairman of the Banking Committee held hearings in March 2007 in which he asked executives from the top five subprime mortgage companies to testify and explain their lending practices. Dodd said that \"predatory lending practices\" were endangering home ownership for millions of people. In addition, Democratic senators such as Senator Charles Schumer of New York were already proposing a federal government bailout of subprime borrowers like the bailout made in the Savings and Loan crisis, in order to save homeowners from losing their residences. Opponents of such a proposal asserted that a government bailout of subprime borrowers is not in the best interests of the U.S. economy because it would simply set a bad precedent, create a moral hazard, and worsen the speculation problem in the housing market.\nLou Ranieri of Salomon Brothers, creator of the mortgage-backed securities market in the 1970s, warned of the future impact of mortgage defaults: \"This is the leading edge of the storm\u2026If you think this is bad, imagine what it's going to be like in the middle of the crisis.\" In his opinion, more than $100 billion of home loans are likely to default when the problems seen in the subprime industry also emerge in the prime mortgage markets.\nFormer Federal Reserve Chairman Alan Greenspan had praised the rise of the subprime mortgage industry and the tools which it uses to assess credit-worthiness in an April 2005 speech. Because of these remarks, as well as his encouragement of the use of adjustable-rate mortgages, Greenspan has been criticized for his role in the rise of the housing bubble and the subsequent problems in the mortgage industry that triggered the economic crisis of 2008. Concerning the subprime mortgage mess, Greenspan later admitted that \"I really didn't get it until very late in 2005 and 2006.\"\nOn September 13, 2007, the British bank Northern Rock applied to the Bank of England for emergency funds because of liquidity problems related to the subprime crisis. This precipitated a bank run at Northern Rock branches across the UK by concerned customers who took out \"an estimated \u00a32bn withdrawn in just three days\".", "page_name": "United States housing bubble", "page_id": "United%20States%20housing%20bubble", "heading": "Housing market correction", "sub_heading": "Housing market correction", "_id": "1000028300--4--0---1", "title": "The U.S. Subprime Mortgage Crisis and the U.S. Housing Market"}
{"qas": [{"question": "Why are there so many cases of cataracts and glaucoma?", "answer": ""}, {"question": "What is responsible for 6 million cases of blindness?", "answer": "glaucoma", "ae_score": -0.2010161652514354, "qg_score": null}, {"question": "What is responsible for 6 million cases of blindness?", "answer": "glaucoma", "ae_score": -0.2010161652514354, "qg_score": null}], "content": "Of these, cataract is responsible for >65%, or more than 22 million cases of blindness, and glaucoma is responsible for 6 million cases.\nCataracts: is the congenital and pediatric pathology that describes the greying or opacity of the crystalline lens, which is most commonly caused by intrauterine infections, metabolic disorders, and genetically transmitted syndromes. Cataracts are the leading cause of child and adult blindness that doubles in prevalence with every ten years after the age of 40. Consequently, today cataracts are more common among adults than in children. That is, people face higher chances of developing cataracts as they age. Nonetheless, cataracts tend to have a greater financial and emotional toll upon children as they must undergo expensive diagnosis, long term rehabilitation, and visual assistance. Also, according to the Saudi Journal for Health Sciences, sometimes patients experience irreversible amblyopia after pediatric cataract surgery because the cataracts prevented the normal maturation of vision prior to operation. Despite the great progress in treatment, cataracts remain a global problem in both economically developed and developing countries. At present, with the variant outcomes as well as the unequal access to cataract surgery, the best way to reduce the risk of developing cataracts is to avoid smoking and extensive exposure to sun light (i.e. UV-B rays).", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Cause", "_id": "1000029210--2--0---1", "title": "Cataracts and Glaucoma in Saudi Arabia"}
{"qas": [{"question": "What is the most common cause of pediatric glaucoma?", "answer": ""}, {"question": "What is the most common treatment for pediatric glaucoma?", "answer": "cataract removal surgery", "ae_score": -0.1664442536796585, "qg_score": null}, {"question": "What is the most common treatment for pediatric glaucoma?", "answer": "cataract removal surgery", "ae_score": -0.1664442536796585, "qg_score": null}], "content": "Glaucoma is a congenital and pediatric eye disease characterized by increased pressure within the eye or intraocular pressure (IOP).<ref name=\"go.galegroup.com\">Krader, Cheryl Guttman. \"Etiology Determines IOP Treatment: Customized Approach Needed for Managing Elevated Pressure in Patients with Uveitis.\" Ophthalmology Times 15 May 2012: 24. Academic OneFile. Web. 5 Dec. 2013.\n Glaucoma causes visual field loss as well as severs the optic nerve.<ref name=\"glaucoma.org\">Glaucoma Research Foundation. \"High Eye Pressure and Glaucoma.\" Glaucoma Research Foundation. N.p., 5 Sept. 2013. Web.\n Early diagnosis and treatment of glaucoma in patients is imperative because glaucoma is triggered by non-specific levels of IOP. Also, another challenge in accurately diagnosing glaucoma is that the disease has four etiologies: 1) inflammatory ocular hypertension syndrome (IOHS); 2) severe uveitic angle closure; 3) corticosteroid-induced; and 4) a heterogonous mechanism associated with structural change and chronic inflammation. In addition, often pediatric glaucoma differs greatly in etiology and management from the glaucoma developed by adults.<ref name=\"Meszaros, Liz 2013\">Meszaros, Liz. \"Pediatric, Adult Glaucoma Differ in Management: Patient Populations Not Same, so Diagnosis/clinical Approach Should Reflect Their Uniqueness.\" Ophthalmology Times 15 Sept. 2013: 11. Academic OneFile. Web. 5 Dec. 2013. \n Currently, the best sign of pediatric glaucoma is an IOP of 21 mm Hg or greater present within a child. One of the most common causes of pediatric glaucoma is cataract removal surgery, which leads to an incidence rate of about 12.2% among infants and 58.7% among 10-year-olds.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Glaucoma", "_id": "1000029210--2--1---1", "title": "Pediatric Glaucoma \u2014 Symptoms and Treatment"}
{"qas": [{"question": "Why is trachoma the number one cause of blindness worldwide?", "answer": ""}, {"question": "What is a significant cause of monocular blindness worldwide?", "answer": "Central corneal ulceration", "ae_score": -0.2895995258760188, "qg_score": null}, {"question": "What is a significant cause of monocular blindness worldwide?", "answer": "Central corneal ulceration", "ae_score": -0.2895995258760188, "qg_score": null}], "content": "Childhood blindness can be caused by conditions related to pregnancy, such as congenital rubella syndrome and retinopathy of prematurity. Leprosy and onchocerciasis each blind approximately 1 million individuals in the developing world.\nThe number of individuals blind from trachoma has decreased in the past 10 years from 6 million to 1.3 million, putting it in seventh place on the list of causes of blindness worldwide.\nCentral corneal ulceration is also a significant cause of monocular blindness worldwide, accounting for an estimated 850,000 cases of corneal blindness every year in the Indian subcontinent alone. As a result, corneal scarring from all causes is now the fourth greatest cause of global blindness.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Infections", "_id": "1000029210--2--2---1", "title": "Causes of Blindness in the World"}
{"qas": [{"question": "Why do people with eye injuries lose their ability to see?", "answer": ""}, {"question": "What is the leading cause of monocular blindness?", "answer": "Eye injuries", "ae_score": -0.31246617087319184, "qg_score": null}, {"question": "What is the leading cause of monocular blindness?", "answer": "Eye injuries", "ae_score": -0.31246617087319184, "qg_score": null}], "content": "Eye injuries, most often occurring in people under 30, are the leading cause of monocular blindness (vision loss in one eye) throughout the United States. Injuries and cataracts affect the eye itself, while abnormalities such as optic nerve hypoplasia affect the nerve bundle that sends signals from the eye to the back of the brain, which can lead to decreased visual acuity.\nCortical blindness results from injuries to the occipital lobe of the brain that prevent the brain from correctly receiving or interpreting signals from the optic nerve. Symptoms of cortical blindness vary greatly across individuals and may be more severe in periods of exhaustion or stress. It is common for people with cortical blindness to have poorer vision later in the day.\nBlinding has been used as an act of vengeance and torture in some instances, to deprive a person of a major sense by which they can navigate or interact within the world, act fully independently, and be aware of events surrounding them. An example from the classical realm is Oedipus, who gouges out his own eyes after realizing that he fulfilled the awful prophecy spoken of him. Having crushed the Bulgarians, the Byzantine Emperor Basil II blinded as many as 15,000 prisoners taken in the battle, before releasing them. Contemporary examples include the addition of methods such as acid throwing as a form of disfigurement.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Injuries", "_id": "1000029210--2--3---1", "title": "Blinding \u2014 A History of Blinding"}
{"qas": [{"question": "Why do some people have low vision or blindness?", "answer": ""}, {"question": "What is the name of the genetic disorder that causes blindness?", "answer": "Bardet-Biedl syndrome", "ae_score": -0.13145003823150336, "qg_score": null}, {"question": "What can cause total blindness or severe sight loss from birth or early childhood?", "answer": "Leber\u2019s congenital amaurosis", "ae_score": null, "qg_score": null}], "content": "People with albinism often have vision loss to the extent that many are legally blind, though few of them actually cannot see. Leber's congenital amaurosis can cause total blindness or severe sight loss from birth or early childhood.\nRecent advances in mapping of the human genome have identified other genetic causes of low vision or blindness. One such example is Bardet-Biedl syndrome.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Genetic defects", "_id": "1000029210--2--4---1", "title": "The Genetic Causes of Blindness and Vision Loss"}
{"qas": [{"question": "How does alcohol cause blindness?", "answer": ""}, {"question": "What is an example of a substance that can cause blindness?", "answer": "methanol", "ae_score": -0.5674185173693332, "qg_score": null}, {"question": "What is an example of a substance that can cause blindness?", "answer": "methanol", "ae_score": -0.5674185173693332, "qg_score": null}], "content": "Rarely, blindness is caused by the intake of certain chemicals. A well-known example is methanol, which is only mildly toxic and minimally intoxicating, and breaks down into the substances formaldehyde and formic acid which in turn can cause blindness, an array of other health complications, and death. When competing with ethanol for metabolism, ethanol is metabolized first, and the onset of toxicity is delayed. Methanol is commonly found in methylated spirits, denatured ethyl alcohol, to avoid paying taxes on selling ethanol intended for human consumption. Methylated spirits are sometimes used by alcoholics as a desperate and cheap substitute for regular ethanol alcoholic beverages.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Cause", "sub_heading": "Poisoning", "_id": "1000029210--2--5---1", "title": "Methanol, Alcohol, and Other Chemicals"}
{"qas": [{"question": "How does LCA gene therapy work?", "answer": ""}, {"question": "What type of tissue can be transplanted for visual impairments?", "answer": "fetal retinal cells", "ae_score": -0.30838796260433593, "qg_score": null}, {"question": "What type of tissue can be transplanted for visual impairments?", "answer": "fetal retinal cells", "ae_score": -0.30838796260433593, "qg_score": null}], "content": "A 2008 study tested the effect of using gene therapy to help restore the sight of patients with a rare form of inherited blindness, known as Leber's congenital amaurosis or LCA. Leber's Congenital Amaurosis damages the light receptors in the retina and usually begins affecting sight in early childhood, with worsening vision until complete blindness around the age of 30.\nThe study used a common cold virus to deliver a normal version of the gene called RPE65 directly into the eyes of affected patients. Remarkably, all 3 patients, aged 19, 22 and 25, responded well to the treatment and reported improved vision following the procedure. Due to the age of the patients and the degenerative nature of LCA, the improvement of vision in gene therapy patients is encouraging for researchers. It is hoped that gene therapy may be even more effective in younger LCA patients who have experienced limited vision loss, as well as in other blind or partially blind individuals.\nTwo experimental treatments for retinal problems include a cybernetic replacement and transplant of fetal retinal cells.", "page_name": "Visual impairment", "page_id": "Visual%20impairment", "heading": "Research", "sub_heading": "Research", "_id": "1000029210--8---1---1", "title": "Gene Therapy for Leber's Congenital Amaurosis Patients"}
{"qas": [{"question": "Habermas and Habermas?", "answer": ""}, {"question": "Which french psychoanalyst linked psychoanalysis with kantian ethics?", "answer": "Jacques Lacan", "ae_score": -0.3486947627309742, "qg_score": null}, {"question": "What is the foundation of kantian ethics?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "German philosopher J\u00fcrgen Habermas has proposed a theory of discourse ethics that he claims is a descendant of Kantian ethics. He proposes that action should be based on communication between those involved, in which their interests and intentions are discussed so they can be understood by all. Rejecting any form of coercion or manipulation, Habermas believes that agreement between the parties is crucial for a moral decision to be reached. Like Kantian ethics, discourse ethics is a cognitive ethical theory, in that it supposes that truth and falsity can be attributed to ethical propositions. It also formulates a rule by which ethical actions can be determined and proposes that ethical actions should be universalisable, in a similar way to Kant's ethics.\nHabermas argues that his ethical theory is an improvement on Kant's ethics.<ref name=Shabani/> He rejects the dualistic framework of Kant's ethics. Kant distinguished between the phenomena world, which can be sensed and experienced by humans, and the noumena, or spiritual world, which is inaccessible to humans. This dichotomy was necessary for Kant because it could explain the autonomy of a human agent: although a human is bound in the phenomenal world, their actions are free in the intelligible world. For Habermas, morality arises from discourse, which is made necessary by their rationality and needs, rather than their freedom.\nThe social contract theory of political philosopher John Rawls, developed in his work ''A Theory of Justice'', was influenced by Kant's ethics. Rawls argued that a just society would be fair. To achieve this fairness, he proposed a hypothetical moment prior to the existence of a society, at which the society is ordered: this is the original position. This should take place from behind a veil of ignorance, where no one knows what their own position in society will be, preventing people from being biased by their own interests and ensuring a fair result. Rawls' theory of justice rests on the belief that individuals are free, equal, and moral; he regarded all human beings as possessing some degree of reasonableness and rationality, which he saw as the constituents of morality and entitling their possessors to equal justice. Rawls dismissed much of Kant's dualism, arguing that the structure of Kantian ethics, once reformulated, is clearer without it\u2014he described this as one of the goals of ''A Theory of Justice''.\nFrench psychoanalyst Jacques Lacan linked psychoanalysis with Kantian ethics in his works ''The Ethics of Psychoanalysis'' and ''Kant avec Sade'' and compared Kant with the Marquis de Sade. Lacan argued that Sade's maxim of jouissance\u2014the pursuit of sexual pleasure or enjoyment\u2014is morally acceptable by Kant's criteria because it can be universalised. He proposed that, while Kant presented human freedom as critical to the moral law, Sade further argued that human freedom is only fully realised through the maxim of jouissance.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Significance of Kantian ethics", "_id": "1000030624--2--0---1", "title": "Kant's Ethics: A Theory of Discourse Ethics"}
{"qas": [{"question": "Kantian Ethics?", "answer": ""}, {"question": "Who did onora o'neill study under at oxford university?", "answer": "John Rawls", "ae_score": -0.7518845393186294, "qg_score": null}, {"question": "Who did onora o'neill study under at oxford university?", "answer": "John Rawls", "ae_score": -0.7518845393186294, "qg_score": null}], "content": "Philosopher Onora O'Neill, who studied under John Rawls at Oxford University, is a contemporary Kantian ethicist who supports a Kantian approach to issues of social justice. O'Neill argues that a successful Kantian account of social justice must not rely on any unwarranted idealisations or assumption. She notes that philosophers have previously charged Kant with idealising humans as autonomous beings, without any social context or life goals, though maintains that Kant's ethics can be read without such an idealisation. O'Neill prefers Kant's conception of reason as practical and available to be used by humans, rather than as principles attached to every human being. Conceiving of reason as a tool to make decisions with means that the only thing able to restrain the principles we adopt is that they could be adopted by all. If we cannot will that everyone adopts a certain principle, then we cannot give them reasons to adopt it. To use reason, and to reason with other people, we must reject those principles that cannot be universally adopted. In this way, O'Neill reached Kant's formulation of universalisability without adopting an idealistic view of human autonomy. This model of universalisability does not require that we adopt all universalisable principles, but merely prohibits us from adopting those that are not.\nFrom this model of Kantian ethics, O'Neill begins to develop a theory of justice. She argues that the rejection of certain principles, such as deception and coercion, provides a starting point for basic conceptions of justice, which she argues are more determinate for human beings that the more abstract principles of equality or liberty. Nevertheless, she concedes that these principles may seem to be excessively demanding: there are many actions and institutions that do rely on non-universalisable principles, such as injury.\nIn his paper ''The Schizophrenia of Modern Ethical Theories'', philosopher Michael Stocker challenges Kantian ethics (and all modern ethical theories) by arguing that actions from duty lack certain moral value. He gives the example of Smith, who visits his friend in hospital out of duty, rather than because of the friendship; he argues that this visit seems morally lacking because it is motivated by the wrong thing. Marcia Baron has attempted to defend Kantian ethics on this point. After presenting a number of reasons that we might find acting out of duty objectionable, she argues that these problems only arise when people misconstrue what their duty is. Acting out of duty is not intrinsically wrong, but immoral consequences can occur when people misunderstand what they are duty-bound to do. Duty need not be seen as cold and impersonal: one may have a duty to cultivate their character or improve their personal relationships. Baron further argues that duty should be construed as a secondary motive\u2014that is, a motive that regulates and sets conditions on what may be done, rather the prompts specific actions. She argues that, seen this way, duty neither reveals a deficiency in one's natural inclinations to act, nor undermines the motives and feelings that are essential to friendship. For Baron, being governed by duty does not mean that duty is always the primary motivation to act; rather, it entails that considerations of duty are always action-guiding. A responsible moral agent should take an interest in moral questions, such as questions of character. These should guide moral agents to act from duty.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Contemporary Kantian ethicists", "_id": "1000030624--2--1---1", "title": "Kant's Philosophy of Social Justice"}
{"qas": [{"question": "Kantian Ethics?", "answer": ""}, {"question": "Who argued that kant's ethics lacked content and thus cannot constitute a supreme principle of?", "answer": "G. W. F. Hegel", "ae_score": -0.826832190888696, "qg_score": null}, {"question": "Who argued that kant's ethics lacked content and thus cannot constitute a supreme principle of?", "answer": "G. W. F. Hegel", "ae_score": -0.826832190888696, "qg_score": null}], "content": "German philosopher G. W. F. Hegel presented two main criticisms of Kantian ethics. He first argued that Kantian ethics provides no specific information about what people should do because Kant's moral law is solely a principle of non-contradiction. He argued that Kant's ethics lack any content and so cannot constitute a supreme principle of morality. To illustrate this point, Hegel and his followers have presented a number of cases in which the Formula of Universal Law either provides no meaningful answer or gives an obviously wrong answer. Hegel used Kant's example of being trusted with another man's money to argue that Kant's Formula of Universal Law cannot determine whether a social system of property is a morally good thing, because either answer can entail contradictions. He also used the example of helping the poor: if everyone helped the poor, there would be no poor left to help, so beneficence would be impossible if universalised, making it immoral according to Kant's model. Hegel's second criticism was that Kant's ethics forces humans into an internal conflict between reason and desire. For Hegel, it is unnatural for humans to suppress their desire and subordinate it to reason. This means that, by not addressing the tension between self-interest and morality, Kant's ethics cannot give humans any reason to be moral.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Critics of Kantian ethics", "_id": "1000030624--2--2--0", "title": "Kant's Ethics: A Critical Criticism of Kant's Ethics"}
{"qas": [{"question": "Kantian Ethics?", "answer": ""}, {"question": "Which german philosopher criticized kant's belief that ethics should concern what ought to be?", "answer": "Arthur Schopenhauer", "ae_score": -0.569467843155836, "qg_score": null}, {"question": "According to arthur schopenhauer, what should be the most important aspect of?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "German philosopher Arthur Schopenhauer criticised Kant's belief that ethics should concern what ought to be done, insisting that the scope of ethics should be to attempt to explain and interpret what actually happens. Whereas Kant presented an idealised version of what ought to be done in a perfect world, Schopenhaur argued that ethics should instead be practical and arrive at conclusions that could work in the real world, capable of being presented as a solution to the world's problems. Schopenhauer drew a parallel with aesthetics, arguing that in both cases prescriptive rules are not the most important part of the discipline. Because he believed that virtue cannot be taught\u2014a person is either virtuous or is not\u2014he cast the proper place of morality as restraining and guiding people's behaviour, rather than presenting unattainable universal laws.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Arthur Schopenhauer", "_id": "1000030624--2--2--1", "title": "Philosopher Arthur Schopenhauer: Kant and Ethics"}
{"qas": [{"question": "Nietzsche's Philosophy?", "answer": ""}, {"question": "What did nietzsche believe to be the foundation of morality?", "answer": "moral intuition", "ae_score": -0.7310867336680646, "qg_score": null}, {"question": "What type of force does nietzsche believe all modern moral systems share?", "answer": "normative ethics", "ae_score": null, "qg_score": null}], "content": "Philosopher Friedrich Nietzsche criticised all contemporary moral systems, with a special focus on Christian and Kantian ethics. He argued that all modern ethical systems share two problematic characteristics: first, they make a metaphysical claim about the nature of humanity, which must be accepted for the system to have any normative force; and second, the system benefits the interests of certain people, often over those of others. Although Nietzsche's primary objection is not that metaphysical claims about humanity are untenable (he also objected to ethical theories that do not make such claims), his two main targets\u2014Kantianism and Christianity\u2014do make metaphysical claims, which therefore feature prominently in Nietzsche's criticism.\nNietzsche rejected fundamental components of Kant's ethics, particularly his argument that morality, God and immorality can be shown through reason. Nietzsche cast suspicion on the use of moral intuition, which Kant used as the foundation of his morality, arguing that it has no normative force in ethics. He further attempted to undermine key concepts in Kant's moral psychology, such as the will and pure reason. Like Kant, Nietzsche developed a concept of autonomy; however, he rejected Kant's idea that valuing our own autonomy requires us to respect the autonomy of others. A naturalist reading of Nietzsche's moral psychology stands contrary to Kant's conception of reason and desire. Under the Kantian model, reason is a fundamentally different motive to desire because it has the capacity to stand back from a situation and make an independent decision. Nietzsche conceives of the self as a social structure of all our different drives and motivations; thus, when it seems that our intellect has made a decision against our drives, it is actually just an alternative drive taking dominance over another. This is in direct contrast with Kant's view of the intellect as opposed to instinct; instead, it is just another instinct. There is thus no self capable of standing back and making a decision; the decision the self makes is simply determined by the strongest drive. Kantian commentators have argued that Nietzsche's practical philosophy requires the existence of a self capable of standing back in the Kantian sense. For an individual to create values of their own, which is a key idea in Nietzsche's philosophy, they must be able to conceive of themselves as a unified agent. Even if the agent is influenced by their drives, he must regard them as his own, which undermines Nietzsche's conception of autonomy.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Friedrich Nietzsche", "_id": "1000030624--2--2--2", "title": "Nietzsche's Criticism of Kant and Christianity"}
{"qas": [{"question": "What is the difference between utilitarianism and Kantian morality?", "answer": ""}, {"question": "Who argued that kant's ethics could not explain why certain actions are wrong without appealing?", "answer": "John Stuart Mill", "ae_score": -0.47548792847216187, "qg_score": null}, {"question": "Who argued that kant's ethics could not explain why certain actions are wrong without appealing?", "answer": "John Stuart Mill", "ae_score": -0.47548792847216187, "qg_score": null}], "content": "Utilitarian philosopher John Stuart Mill criticised Kant for not realising that moral laws are justified by a moral intuition based on utilitarian principles (that the greatest good for the greatest number ought to be sought). Mill argued that Kant's ethics could not explain why certain actions are wrong without appealing to utilitarianism. As basis for morality, Mill believed that his principle of utility has a stronger intuitive grounding than Kant's reliance on reason, and can better explain why certain actions are right or wrong.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "John Stuart Mill", "_id": "1000030624--2--2--3", "title": "Utilitarian philosopher John Stuart Mill criticised Kant for not realising that moral"}
{"qas": [{"question": "Virtue Ethics?", "answer": ""}, {"question": "What is the term for an ethical theory that emphasises the character of an agent rather?", "answer": "Virtue ethics", "ae_score": -0.668064029646304, "qg_score": null}, {"question": "What is the term for an ethical theory that emphasises the character of an agent rather?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Virtue ethics is a form of ethical theory which emphasises the character of an agent, rather than specific acts; many of its proponents have criticised Kant's deontological approach to ethics. Elizabeth Anscombe criticised modern ethical theories, including Kantian ethics, for their obsession with law and obligation. As well as arguing that theories which rely on a universal moral law are too rigid, Anscombe suggested that, because a moral law implies a moral lawgiver, they are irrelevant in modern secular society. In his work After Virtue, Alasdair MacIntyre criticises Kant's formulation of universalisability, arguing that various trivial and immoral maxims can pass the test, such as \"Keep all your promises throughout your entire life except one\". He further challenges Kant's formulation of humanity as an ends in itself by arguing that Kant provided no reason to treat others as means: the maxim \"Let everyone except me be treated as a means\", though seemingly immoral, can be universalised. Bernard Williams argues that, by abstracting persons from character, Kant misreprents persons and morality and Philippa Foot identified Kant as one of a select group of philosophers responsible for the neglect of virtue by analytic philosophy.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Virtue ethics", "_id": "1000030624--2--2--4", "title": "Virtue Ethics \u2014 Kant's Deontological Approach"}
{"qas": [{"question": "What is the difference between Christian ethics and Kant's?", "answer": ""}, {"question": "What is it called when we are co-legislators of morality?", "answer": "Kantian ethics", "ae_score": -0.6243410916784133, "qg_score": null}, {"question": "What type of ethics did kant believe were closer to aristotle's?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "The Catholic Church has criticised Kantian ethics for its apparent contradiction, arguing that humans being co-legislators of morality contradicts the claim that morality is a priori. If something is universally a priori (i.e., existing unchangingly prior to experience), then it cannot also be in part dependent upon humans, who have not always existed\nRoman Catholic priest Servais Pinckaers criticised the modern desire for ethics to be autonomous and free from the authorities such as the Church, a development he partially attributed to thinkers such as Kant. Pinckaers saw this as potentially threatening to the legitimacy of the Magisterium, but maintained that the link between the gospel and the moral law, and the shortcomings of human reason, leave a place for the moral authority of the Church. Pinckaers regarded Christian ethics as closer to the virtue ethics of Aristotle than Kant's ethics. He presented virtue ethics as ''freedom for excellence'', which regards freedom as acting in accordance with nature to develop one's virtues. Initially, this requires following rules\u2014but the intention is that the agent develop virtuously, and regard acting morally as a joy. This is in contrast with ''freedom of indifference'', which Pinckaers attributes to William Ockham and likens to Kant. On this view, freedom is set against nature: free actions are those not determined by passions or emotions. There is no development or progress in an agent's virtue, merely the forming of habit. This is closer to Kant's view of ethics, because Kant's conception of autonomy requires that an agent is not merely guided by their emotions, and is set in contrast with Pinckaer's conception of Christian ethics.", "page_name": "Kantian ethics", "page_id": "Kantian%20ethics", "heading": "Significance of Kantian ethics", "sub_heading": "Catholic Church", "_id": "1000030624--2--2--5", "title": "Pinckaers vs. Pinckaer vs. Kant "}
{"qas": [{"question": "How does BENTA disease cause malignancy?", "answer": ""}, {"question": "What gene is responsible for benta disease?", "answer": "CARD11", "ae_score": -0.9737711295087473, "qg_score": null}, {"question": "Where does bena disease take place on a chromosome?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "BENTA disease is caused by germline-encoded  gain-of-function mutations in the gene CARD11.  This is a 138 kB gene mapping to chromosome 7p22 with 26 exons encoding a 1,154 amino acid protein. The CARD11 protein (also known as CARMA1) is a  scaffolding protein required for NF-\u03baB activation in both B and T lymphocytes.  Gain-of-function mutations drive constitutive NF-\u03baB activation in both types of cells.  Most mutations are localized within or just upstream of the coiled-coil domain (exons 4-9) of the protein. Patient phenotypes also suggest that  B cell differentiation might be partially impaired in BENTA disease, contributing to a low percentage of class-switched and memory B cells.\nGermline gain-of-function mutations in CARD11 manifest a less severe illness than  loss-of-function mutations seen in CARD11 deficiency (OMIM #615206), an  autosomal recessive condition manifesting in severe combined immunodeficiency.\nThe gain-of-function CARD11 mutations associated with BENTA disease may also predispose patients to B cell malignancy. Importantly, overactive NF-\u03baB is frequently associated with  B cell malignancy and, specifically, somatic gain-of-function CARD11 mutations are seen frequently in diffuse large B cell lymphoma (DLBCL). However, most BENTA patients present with polyclonal B cell accumulation with no evidence of oligoclonal or monoclonal populations (i.e. malignancy). These mutations do not appear to be associated with  T cell malignancies.", "page_name": "BENTA disease", "page_id": "BENTA%20disease", "heading": "Genetics and function", "sub_heading": "Genetics and function", "_id": "1000036731--0---1---1", "title": "BENTA Disease: Germline Gain-of-Factor Mutations in C"}
{"qas": [{"question": "What is the difference between Tesla Powerwall and regular battery?", "answer": ""}, {"question": "How much does a tesla powerwall save customers?", "answer": "20%", "ae_score": -0.1802621659424945, "qg_score": null}, {"question": "What is the cathode of the tesla battery?", "answer": "cathode", "ae_score": null, "qg_score": null}], "content": "Tesla started development in 2012, installing prototypes at selected industrial customers. In some cases, PowerPacks have saved 20% of the electrical bill.\nThe Powerwall was originally announced at the April 30, 2015 product launch with power output of 2 kW steady and 3.3 kW peak, but Musk said at the June 2015 Tesla shareholders meeting that this would be more than doubled to 5 kW steady with 7 kW peak, with no increase in price. He also announced that Powerwall deliveries would be prioritized to partners who minimize the cost to the end user, with a Powerwall installation price of .\nWhen originally announced in 2015, there were to be two models of Powerwall delivered:  10 kWh capacity for backup applications and 7 kWh capacity for daily cycle applications.<ref name=tpw/>But by March 2016, Tesla had \"quietly removed all references to its 10-kilowatt-hour residential battery from the Powerwall website, as well as the company's press kit. The company's smaller battery designed for daily cycling is all that remains.\"\nThe 10 kWh battery as originally announced has a nickel-cobalt-aluminum cathode, like the Tesla Model S, which was projected to be used as a backup/uninterruptible power supply, and had a projected cycle life of 1000\u20131500 cycles.\nIn October 2016, Tesla announced that nearly 300 MWh of Tesla batteries had been deployed in 18 countries.\nThe '''Powerwall 2''' was unveiled in October 2016 at Universal Studios' Colonial Street, Los Angeles, backlot street set and is designed to work with the solar panel roof tiles to be produced by SolarCity.", "page_name": "Tesla Powerwall", "page_id": "Tesla%20Powerwall", "heading": "History", "sub_heading": "History", "_id": "1000038172--0---1---1", "title": "Tesla Powerwall | History"}
{"qas": [{"question": "Why is water vapor from the Pacific Ocean so much more dense than water from the Atlantic Ocean?", "answer": ""}, {"question": "What is the relationship between the \u03b4d and vsmow values of lakes and?", "answer": "local precipitation", "ae_score": -0.5001403778771135, "qg_score": null}, {"question": "What process results in disequilibrium in the \u03b4d values?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "Variations in \u03b4D value of different water sources and ice caps are observed due to evaporation and condensation processes. [See section 6 for more details] When the ocean water is well-mixed, the \u03b4D at equilibrium is close to 0\u2030 (\u2030 SMOW) with a D/H ratio of 0.00015576. However, continuous variations in \u03b4D values are caused by evaporation or precipitation processes which lead to disequilibrium in fractionation processes. A large H isotopic gradient (variations in \u03b4D values) is observed in surface waters of the oceans, and the fluctuation value in the Northwest Atlantic surface water is around 20\u2030.According to the data examining the southern supersegment of the Pacific Ocean, as the latitude (\u02daS) decreases from -65\u02daS to -40\u02daS, the \u03b4D value fluctuates between around -50\u2030 and -70\u2030.\nThe isotope composition of seawater (not just the surface water) is mostly in the range of 0-(-10) \u2030. The estimates of the \u03b4D values for different parts of the oceans across the world are shown on the map.\nThe typical \u03b4D values for the ice sheets in the polar regions range from around -400\u2030 to -300\u2030 (\u2030SMOW). The \u03b4D values for ice caps are affected by the distance from the open ocean, latitude, atmospheric circulation as well as the amount of insolation and temperature. The temperature change affects the deuterium content of ice caps, so the H/D isotopic composition of ice can give estimates for the historical climate cycles such as the timelines for interglacial and glacial periods. [See section 7.2. Paleo-reconstruction for more details]\nThe \u03b4D values of ice caps from 70 km south of Vostok Station and in East Antarctica are -453.7\u2030 and -448.4\u2030 respectively, and are shown on the map.\nThe analysis done based on satellite measurement data estimates the \u03b4D values for the atmosphere in various regions of the world. The general trend is that the \u03b4D values are more negative at higher-latitude regions, so the atmosphere above the Antarctica and the arctic regions is observed to be highly D-depleted to around -230\u2030 to -260\u2030 or even lower.\nThe estimates of the atmospheric \u03b4D values are shown on the map.\nA vast portion of the global atmospheric water vapor comes from the western Pacific Ocean near the tropical zone, (mean 2009) and the H/D isotopic composition of atmosphere varies depending on the temperature and humidity. In general, higher \u03b4D values are observed in humid regions with a high temperature. Water vapor in the atmosphere is in general more depleted than the terrestrial water sources, since the rate of evaporation for HO is faster than HDO due to a higher vapor pressure. On the other hand, the rain water (precipitation) is in general more enriched than the atmospheric water vapor. (Sacese et al.) [See Section 6. Hydrologic Cycle for more details]\nThe \u03b4D values of the annual precipitation in different regions of the world are shown on the map. The precipitation is more D-enriched near the equator in the Tropical regions. The values of \u03b4D generally fall in the range of around -30~-150\u2030 in the northern hemisphere and -30~+30\u2030 over the land areas of the southern hemisphere. In North America, the \u03b4D values of average monthly precipitation across regions are more negative in January (ranging up to around -300\u2030 in Canada) compared to July (up to around -190\u2030).\nThe overall mean precipitation is determined by balance between the evaporation of water from the oceans and surface water sources and the condensation of the atmospheric water vapor in the form of rain. The net evaporation should equal the net precipitation, and the \u03b4D value for the mean isotopic composition of global precipitation is around -22\u2030 (global average). The Global Network of Isotopes in Precipitation (GNIP) investigates and monitors the isotopic composition of precipitation at various sites all over the world. The mean precipitation can be estimated by the equation, \u03b4H = 8.17(\u00b10.07) \u03b4O + 11.27(\u00b10.65)\u2030 VSMOW. (Rozanski et al., 1993) This equation is the slightly modified version from the general 'Global Meteoric Water Line (GMWL)' equation, \u03b4H = 8.13\u03b4O + 10.8, which provides the average relationship between \u03b4H and \u03b4O of natural terrestrial waters. [See Section 6.1. Isotopic fractionation in the hydrologic cycle for more details]\nThe \u03b4D values vs. VSMOW of lakes in different regions are shown on the map. The general pattern observed indicates that the \u03b4D values of the surface waters including lakes and rivers are similar to that of local precipitation. [See Section 7.1. Isotope hydrology for more details]\nThe isotopic composition of soil is controlled by the input of precipitation. Therefore, the \u03b4D values of soil across regions are similar to that of local precipitation. However, due to evaporation, soil tends to be more D-enriched than precipitation. The degree of enrichment varies greatly depending on the atmospheric humidity, local temperature as well as the depth of the soil beneath the surface. According to the study done by Meinzer et al. (1999), as the depth in the soil increases, the \u03b4D of soil water decreases. [See Section 7.1. Isotope hydrology for more details]\n'''\n'''", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Observed variations in isotope abundance", "_id": "1000040249--3--0---1", "title": "D values of the oceans and ice caps in different regions of the world"}
{"qas": [{"question": "Why do some algal lipids have a higher D/H fractionation than others?", "answer": ""}, {"question": "When was the first study done on hydrogen isotope?", "answer": "2009", "ae_score": -0.8085939957370955, "qg_score": null}, {"question": "When was the first study done on hydrogen isotope?", "answer": "2009", "ae_score": -0.8085939957370955, "qg_score": null}], "content": "The factors affecting \u03b4D values of algal lipids are the followings: \u03b4D of water, algal species (up to 160%), lipid type (up to 170%), salinity (+0.9\u00b10.2% per PSU), growth rate (0 ~ -30% per day) and temperature (-2 ~ -8% per \u00b0C).\nIn the study done by Zhang et al. (2009), the \u03b4D values of fatty acids in Thakassiosira pseudonana chemostat cultures were -197.3\u2030, -211.2\u2030 and -208.0\u2030 for C14, C16 and C18 fatty acids respectively.  Moreover, the \u03b4D value of C16 fatty acid in an algal specie named A. E. unicocca at 25 \u00b0C was determined using the empirical equation y = 0.890x - 91.730 where x is the \u03b4D of water at harvest. For another algal specie named B. V. aureus, the equation was y = 0.869x -74.651.\nThe degree of D/H fractionation in most algal lipids increases with increasing temperature and decreases with increasing salinity. The growth rates have different impacts on the D/H fractionation depending on the specie types.", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Biosphere", "_id": "1000040249--3--1--0", "title": "D of water, algal species, lipid type, salinity, growth"}
{"qas": [{"question": "How is the isotopic fractionation between lipids and methane calculated?", "answer": ""}, {"question": "Where does h2 come from in the body?", "answer": "photoautotrophs", "ae_score": -0.9119917279732029, "qg_score": null}, {"question": "What is the relationship between uptake and utilization of substrate hydrogen?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "The \u03b4D values of lipids from phytoplankton is largely affected by \u03b4D of water, and there seems to be a linear correlation between those two values. The \u03b4D of most other biosynthetic products found in phytoplankton or cyanobacteria are more negative than that of the surrounding water. The \u03b4D values of fatty acids in methanotrophs living in seawater lie between -50 and -170\u2030, and that of sterols and hopanols range between -150 and -270\u2030. [See Section 7.5.3. Microbial metabolism for more details]\nThe H isotopic composition of photoautotrophs can be estimated using the equation below:\nR = X*\u03b1*R + (1- X)*\u03b1*R,\nwhere R, R, and R are the D/H ratios of lipids, water, and substrates, respectively. X is the mole fraction of lipid H derived from external water, whereas \u03b1 and \u03b1 denote the net isotopic fractionations associated with uptake and utilization of water and substrate hydrogen, respectively.\nFor Phototrophs, R is calculated assuming that X equals to 1. The isotopic fractionation between lipids and methane (\u03b1) is 0.94 for fatty acids and 0.79 for isoprenoid lipids. The isotopic fractionation between lipids and water (\u03b1) is 0.95 for fatty acids and 0.85 for isoprenoid lipids. For plants and algae, the isotopic fractionation between lipids and methane (\u03b1) is 0.94 for fatty acids and 0.79 for isoprenoid lipids.", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Phytoplankton and Bacteria", "_id": "1000040249--3--1--1", "title": "D of lipids in phytoplankton"}
{"qas": [{"question": "Why is it that when I'm in the shower I feel like I need to pee, but when I go to bed I don't?", "answer": ""}, {"question": "What causes d-enriched leaf water in grasses to be?", "answer": "transpiration", "ae_score": -0.5899110279360167, "qg_score": null}, {"question": "What causes d-enriched leaf water in grasses to be?", "answer": "transpiration", "ae_score": -0.5899110279360167, "qg_score": null}], "content": "]\nFor plant leaf wax, the relative humidity, the timing of leaf wax formation and the growth conditions including light levels affect the D/H fractionation of plant wax. From the Craig\u2013Gordon model, it can be understood that leaf water in the growth chamber grasses is significantly D-enriched due to transpiration.[See Section 7.2.2.2. Plant leaf waxes for more details]\nThe relative global abundance of D in plants is in the following order: phenylpropanoids>carbohydrates>bulk material>hydrolysable lipids>steroids.  In plants, \u03b4D values of carbohydrates, which typically range around -70\u2030 to -140\u2030, are good indicators of the photosynthetic metabolism. Photosynthetically produced Hydrogens which are bound to carbon backbones are around 100-170\u2030 more D-depleted than the water found in plant tissues.\nThe heterotrophic processing of carbohydrates involves isomerization of triose phosphates and interconversion between fructose-6-phosphate and glucose-6-phosphate. These cellular processes promote the exchange between organic H and HO within the plant tissues leading to around 158\u2030 of D-enrichment of those exchanged sites. The \u03b4D of C3 plants such as Sugar beet, orange and grape ranges from -132\u2030 to -117\u2030, and that of C4 plants such as sugar cane and maize ranges from -91\u2030 to -75\u2030. The \u03b4D of CAM such as pineapple is estimated to be around -75\u2030. Sugar beet and sugar cane contain sucrose, and maize contain glucose. Orange and pineapple are the sources of glucose and fructose.\nThe deuterium content of the sugars from the above plant species are not distinctive. In C3 plants, Hydrogens attached to Carbons in 4 and 5 positions of the glucose typically come from NADPH in the photosynthetic pathway, and are found to be more D-enriched. Whereas in C4 plants, Hydrogens attached to Carbons 1 and 6 positions are more D-enriched. D-enrichment patterns in CAM species tend to be closer to that in C3 species.\nThe H/D isotopic composition of the leaf water is variable during the biosynthesis, and the enrichment in the whole leaf can be described by the equation, \u25b3D = \u25b3D * ((1-e)/P) (Hou et al., 2008, Sachse et al., 2012)\nThe typical \u03b4D value of bulk plant is around -160\u2030 where \u03b4D values for cellulose and lignin are  -110\u2030 and -70\u2030 respectively.", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Plants", "_id": "1000040249--3--1--2", "title": "Hydrogen isotope biogeochemistry | Observed variations in isotope abundance | Plants"}
{"qas": [{"question": "Why is the \u03b4D of a lipid so much lower than that of a normal lipid?", "answer": ""}, {"question": "What is the most abundant isotope of hydrogen?", "answer": "Lipids", "ae_score": -0.014686410553118003, "qg_score": null}, {"question": "What is the most abundant isotope of hydrogen?", "answer": "Lipids", "ae_score": -0.014686410553118003, "qg_score": null}], "content": "The hydrogen isotopic composition in animal tissues are difficult to estimate due to complexities in the diet intake and the isotopic composition of surrounding water sources. When fish species were investigated, average hydrogen isotopic composition of proteins was in a large range of \u2013128 \u2030 ~ +203 \u2030. In the bulk tissue of organisms, all lipids were found to be D-depleted, and the values of \u03b4D for lipids tend to be lower than that for proteins. The average \u03b4D for Chironomid and fish protein was estimated to be in the range of -128\u2030 to +203\u2030.\nMost hydrogens in heterotrophic tissues come from water not from diet sources, but the proportion coming from water varies. In general, Hydrogen from water is transferred to NADPH and then taken up to the tissues. An apparent trophic effect (compounding effect) can be observed for \u03b4D in heterotrophs, so significant D-enrichments result from the intake of surrounding water the in aquatic food webs. The \u03b4D of proteins in animal tissues are in cases affected more by diet sources than by surrounding water.\nAlthough different \u03b4D values for the same class of compounds may arise in different organisms growing in water with the same \u03b4D value, those compounds generally have the same \u03b4D value within each organism itself. [See Section 7.5. Ecology for more details]\nLipids:\nThe \u03b4D values of fatty acids found in living organisms typically range from -73\u2030 to -237\u2030. The values of \u03b4D for individual fatty acids vary widely between cultures (-362\u2030 to +331\u2030), but typically by less than around 30\u2030 between different fatty acids from the same species.\nThe differences in \u03b4D for the compounds within the same lipid class is generally smaller than 50\u2030, whereas the difference falls in the range of 50-150\u2030 for the compounds in different lipid classes.\n\u03b4D values for typical lipid groups are determined using the following equation:\n\u03b5 = (D/H)/(D/H)\u22121 = [(\u03b4D + 1)/(\u03b4D + 1)]\u22121   (Sachse et al.) where \u03b5 = net or apparent fractionation, \u03b4D = lipid product and \u03b4D = source water.\nPolyisoprenoid lipids are more depleted than acetogenic (n-alkyl) lipids with more negative \u03b4D values.\n'''\n'''", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Animals", "_id": "1000040249--3--1--3", "title": "D of Proteins in Animal Tissues"}
{"qas": [{"question": "How do we know how many coals are in a given area?", "answer": ""}, {"question": "What is the most abundant isotope of hydrogen?", "answer": "Alkenones", "ae_score": -0.2661140390804331, "qg_score": null}, {"question": "What is the effect of incomplete electrolysis of water on hydrogen gas?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "[See Section 7.3.3. Oil for more details]\nThe isotopic composition of alkenones often reflect the isotopic enrichment or depletion of the surrounding environment, and the \u03b4D values of alkenones in different regions are shown on the map.\n[See Section 7.2.2.3. Alkenones for more details.]\nAccording to the studies done by Reddings et al., \u03b4D for coals from various sources range from around -90\u2030 to -170\u2030.\nThe \u03b4D values of coals in different regions are shown on the map.\n[See Section 7.3.1. Kerogens and Coals for more details]\nMethane produced from marine methanogens is typically more D-enriched than methane produced from methanogens grown in freshwater. The \u03b4D values for thermogenic methane range from -275\u2030 to -100\u2030, and from -400\u2030 to -150\u2030 for microbial methane.\n[See Section 7.3.2. Natural gas for more details.]\nThe \u03b4D value observed for atmospheric H is around +180\u2030, which is the biggest delta value observed for natural terrestrials. (The mole fraction of H: 0.0001838) The \u03b4D value for natural gas from a Kansas well is around -836\u2030 (The mole fraction of Deuterium is 0.0000255)During the process of electrolysis of water, hydrogen gas is produced at the cathode, but an incomplete electrolysis of water may cause isotopic fractionation leading to enrichment of D in the sample water and the production of hydrogen gas with deuterium components.\nThe \u03b4D values of hydroxyl-bearing minerals of mantle were estimated to be -80\u2030 ~ -40\u2030 through the analysis of the isotopic composition for juvenile water. Hydrogen Minerals generally have large isotope effects, and the isotopic composition often follows the pattern observed for precipitation.\nClay mineralsThe D/H fractionations in clays such as kaolinite, illite, smectite are in most cases consistent when no significant external forces are applied under constant temperature and pressure.\nThe following is an empirically determined equation for estimating the D/H fractionation factor: 1000 In \u03b1 = -2.2 x 10 x T - 7.7.\nThe \u03b4D values vs. \u2030SMOW for Hydrogen minerals found in mantle, Metamorphic rock, shales, marine clays, marine carbonates and sedimentary rocks are shown in the table.\n'''\n'''", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Geosphere", "_id": "1000040249--3--2---1", "title": "D Values of Hydroxyl-Bearing Minerals in Mantle"}
{"qas": [{"question": "Why are the ratios of Jupiter and Saturn so much higher than the ratios for Uranus and Neptune?", "answer": ""}, {"question": "What is the most abundant element in the universe?", "answer": "Hydrogen", "ae_score": -0.2516389798628197, "qg_score": null}, {"question": "What is the most abundant element in the universe?", "answer": "Hydrogen", "ae_score": -0.2516389798628197, "qg_score": null}], "content": "Variations of D/H ratio in the solar system\nThe H isotope composition of mantle rocks on earth is highly variable, and that of mantle water is around -80\u2030 ~ -50\u2030 depending on its states such as fluid, hydrous phase, hydroxyl point defect, Juvenile water (from degassing of the mantle), magmatic water (water equilibrated with a magma).\nThe D/H ratio of the sun is around 21 \u00b1 5 \u00d7 10.\nThe current Hydrogen isotope composition is enriched by a factor of 5 relative to terrestrial ocean water due to continual losses of H in Martian atmosphere. Therefore, the \u03b4D value is estimated to be around +4000\u2030.\nThe D/H ratios for Jupiter and Saturn is nearly in the order of 10, and the D/H ratios of Uranus and Neptune is closer to the order of 10.\nHydrogen is the most abundant element in the universe. Variations in isotopic composition of extraterrestrial materials stem from planetary accretion or other planetary processes such as atmospheric escape, and are larger for H and N than for C and O. The preservation of D-enrichment is observed in chondritic meteorites, interplanetary dust particles and cometary volatiles.\nFrom the Helium isotope abundance data, the cosmic D/H value is estimated to be around 20 ppm which is much lower than the terrestrial D/H ratio of 150 ppm. The enrichment of D/H from the proto-solar reservoir occurs for most of the planets except for Jupiter and Saturn, the massive gaseous planets. The D/H ratios of the atmospheres of Venus and Mars are ~2 \u00d7 10 and ~8 \u00d7 10 respectively. The D/H ratios of Uranus and Neptune is larger than that of protosolar reservoir by a factor of around 3 due to their Deuterium-rich icy cores. The D/H ratios for comets are much larger than the values for the planets in the solar system with \u03b4D value of around 1000\u2030.\nThe Hydrogen isotope compositions in the galaxy and the solar system are shown in the table.", "page_name": "Hydrogen isotope biogeochemistry", "page_id": "Hydrogen%20isotope%20biogeochemistry", "heading": "Observed variations in isotope abundance", "sub_heading": "Extraterrestrial Objects", "_id": "1000040249--3--3---1", "title": "Hydrogen isotope biogeochemistry | Observed variations in isotope abundance | Extraterrestrial Objects"}
{"qas": [{"question": "What is the difference between mirtazapine and other antidepressants?", "answer": ""}, {"question": "What is the name of the anti-oxidant?", "answer": "mirtazapine", "ae_score": -0.060411880154092636, "qg_score": null}, {"question": "What is the name of the anti-oxidant?", "answer": "mirtazapine", "ae_score": -0.060411880154092636, "qg_score": null}], "content": "Mirtazapine's primary use is the treatment of major depressive disorder and other mood disorders.\nIn a meta-analysis published in 2009 that compared the efficacy and tolerability of 12 second-generation antidepressants, mirtazapine was found to be superior to all of the included selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs), reboxetine and bupropion in terms of antidepressant efficacy, while it was average in regard to tolerability. However, its superior efficacy over the other medications in the top four (escitalopram, sertraline and venlafaxine) did not reach statistical significance.\nHowever, it has also been found useful in alleviating the following conditions and may be prescribed off-label for their treatment:\nMirtazapine has had literature published on its efficacy in the experimental treatment of these conditions:\nMirtazapine is sometimes prescribed as an appetite stimulant for cats or dogs experiencing anorexia due to medical conditions such as chronic kidney disease. It is especially useful for treating combined poor appetite and nausea in cats and dogs.\nIn clinical studies, mirtazapine has been found to be an effective antidepressant with a generally tolerable side-effect profile relative to other antidepressants.\nIn a major meta-analysis published in 2009 that compared the efficacy and tolerability of 12 second-generation antidepressants, mirtazapine was found to be superior to all of the included selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs), reboxetine and bupropion in terms of antidepressant efficacy, while it was average in regard to tolerability.\nCompared to earlier antidepressants, mirtazapine has been found to be significantly superior to trazodone, while it has been shown to be approximately equivalent in efficacy to several of the tricyclic antidepressants  including amitriptyline, doxepin and clomipramine. However, two other studies found mirtazapine to be significantly inferior to imipramine, another TCA.\nIn general, all antidepressants, including mirtazapine, require at least a week for their therapeutic benefits on depressive and anxious symptoms to become apparent. Mirtazapine has a faster onset of antidepressant action when compared to SSRIs, with an initial reduction in affective symptoms being seen within the first week of treatment, and the maximal change in improvement occurring over the course of the first two weeks, however ingesting small doses sporadically can cause some of the same short term side effects as opiates such as minor pain relief  as well as constricting of the pupils.", "page_name": "Mirtazapine", "page_id": "Mirtazapine", "heading": "Medical uses", "sub_heading": "Medical uses", "_id": "1000042903--0---1---1", "title": "Mirtazapine \u2014 A New Antidepressant"}
{"qas": [{"question": "How do thermodynamic cycles work?", "answer": ""}, {"question": "What type of process is a cyclic process similar to?", "answer": "isothermal process", "ae_score": -0.8366396527202985, "qg_score": null}, {"question": "What type of process is a cyclic process similar to?", "answer": "isothermal process", "ae_score": -0.8366396527202985, "qg_score": null}], "content": "Because the net variation in state properties during a thermodynamic cycle is zero, it forms a closed loop on a PV diagram. A PV diagram's ''Y'' axis shows pressure (''P'') and ''X'' axis shows volume (''V''). The area enclosed by the loop is the work (''W'') done by the process:\nThis work is equal to the balance of heat (Q) transferred into the system:\nEquation (2) makes a cyclic process similar to an isothermal process: even though the internal energy changes during the course of the cyclic process, when the cyclic process finishes the system's energy is the same as the energy it had when the process began.\nIf the cyclic process moves clockwise around the loop, then W will be positive, and it represents a heat engine. If it moves counterclockwise, then W will be negative, and it represents a heat pump.", "page_name": "Thermodynamic cycle", "page_id": "Thermodynamic%20cycle", "heading": "Heat and work", "sub_heading": "Heat and work", "_id": "1000043864--0--0---1", "title": "Thermodynamic Cycles: A closed loop on a PV diagram"}
{"qas": [{"question": "What is the difference between Isobaric and Hebaric pressure?", "answer": ""}, {"question": "What is the name of the process by which the earth rotates?", "answer": "Thermodynamic Processes", "ae_score": -0.07869608118374383, "qg_score": null}, {"question": "What is the name of the process by which the earth rotates?", "answer": "Thermodynamic Processes", "ae_score": -0.07869608118374383, "qg_score": null}], "content": "Otto Cycle:\n1\u21922: Isentropic Expansion: Constant entropy (s), Decrease in pressure (P), Increase in volume (v), Decrease in temperature (T)\n2\u21923: Isochoric Cooling: Constant volume(v), Decrease in pressure (P), Decrease in entropy (S), Decrease in temperature (T)\n3\u21924: Isentropic Compression: Constant entropy (s), Increase in pressure (P), Decrease in volume (v), Increase in temperature (T)\n4\u21921: Isochoric Heating: Constant volume (v), Increase in pressure (P), Increase in entropy (S), Increase in temperature (T)\nA List of Thermodynamic Processes:\nAdiabatic : No energy transfer as heat (Q) during that part of the cycle would amount to \u03b4Q=0. This does not exclude energy transfer as work.\nIsothermal : The process is at a constant temperature during that part of the cycle (T=constant, \u03b4T=0). This does not exclude energy transfer as heat or work.\nIsobaric : Pressure in that part of the cycle will remain constant. (P=constant, \u03b4P=0). This does not exclude energy transfer as heat or work.\nIsochoric : The process is constant volume (V=constant, \u03b4V=0). This does not exclude energy transfer as heat or work.\nIsentropic : The process is one of constant entropy (S=constant, \u03b4S=0). This excludes the transfer of heat but not work.", "page_name": "Thermodynamic cycle", "page_id": "Thermodynamic%20cycle", "heading": "Heat and work", "sub_heading": "Each Point in the Cycle", "_id": "1000043864--0--1---1", "title": "Thermodynamic Processes in Otto Cycle"}
{"qas": [{"question": "Why is the volume of a bottle 4-1 and 2-3?", "answer": ""}, {"question": "A model of the energy cycle of a car is called?", "answer": "idealized models", "ae_score": -0.4894740310995935, "qg_score": null}, {"question": "A model of the energy cycle of a car is called?", "answer": "idealized models", "ae_score": -0.4894740310995935, "qg_score": null}], "content": "Thermodynamic power cycles are the basis for the operation of heat engines, which supply most of the world's electric power and run the vast majority of motor vehicles. Power cycles can be organized into two categories: real cycles and ideal cycles. Cycles encountered in real world devices (real cycles) are difficult to analyze because of the presence of complicating effects (friction), and the absence of sufficient time for the establishment of equilibrium conditions. For the purpose of analysis and design, idealized models (ideal cycles) are created; these ideal models allow engineers to study the effects of major parameters that dominate the cycle without having to spend significant time working out intricate details present in the real cycle model.\nPower cycles can also be divided according to the type of heat engine they seek to model. The most common cycles used to model internal combustion engines are the Otto cycle, which models gasoline engines, and the Diesel cycle, which models diesel engines. Cycles that model external combustion engines include the Brayton cycle, which models gas turbines, the Rankine cycle, which models steam turbines, the Stirling cycle, which models hot air engines, and the Ericsson cycle, which also models hot air engines.\nFor example, the pressure-volume mechanical work output from the heat engine cycle (net work out), consisting of 4 thermodynamic processes, is:\nIf no volume change happens in process 4-1 and 2-3, equation (3) simplifies to:", "page_name": "Thermodynamic cycle", "page_id": "Thermodynamic%20cycle", "heading": "Heat and work", "sub_heading": "Power cycles", "_id": "1000043864--0--2---1", "title": "Thermodynamic Power Cycles"}
{"qas": [{"question": "Thermodynamic heat pump cycles?", "answer": ""}, {"question": "What is the most common refrigeration cycle?", "answer": "vapor compression cycle", "ae_score": -0.6371267594630559, "qg_score": null}, {"question": "What is the most common refrigeration cycle?", "answer": "vapor compression cycle", "ae_score": -0.6371267594630559, "qg_score": null}], "content": "Thermodynamic heat pump cycles are the models for household heat pumps and refrigerators. There is no difference between the two except the purpose of the refrigerator is to cool a very small space while the household heat pump is intended to warm a house. Both work by moving heat from a cold space to a warm space. The most common refrigeration cycle is the vapor compression cycle, which models systems using refrigerants that change phase. The absorption refrigeration cycle is an alternative that absorbs the refrigerant in a liquid solution rather than evaporating it. Gas refrigeration cycles include the reversed Brayton cycle and the Hampson-Linde cycle. Multiple compression and expansion cycles allow gas refrigeration systems to liquify gases.", "page_name": "Thermodynamic cycle", "page_id": "Thermodynamic%20cycle", "heading": "Heat and work", "sub_heading": "Heat pump cycles", "_id": "1000043864--0--3---1", "title": "Thermodynamic Heat Pump Cycles"}
{"qas": [{"question": "What is the difference between zinc and copper?", "answer": ""}, {"question": "What is the most familiar form of zinc metal?", "answer": "galvanization", "ae_score": -0.41524562490536987, "qg_score": null}, {"question": "What is a protective surface layer of oxide and carbonate?", "answer": "carbon exchange reservoir", "ae_score": null, "qg_score": null}], "content": "Zinc is most commonly used as an anti-corrosion agent, and galvanization (coating of iron or steel) is the most familiar form. In 2009 in the United States, 55% or 893 thousand tonnes of the zinc metal was used for galvanization.\nZinc is more reactive than iron or steel and thus will attract almost all local oxidation until it completely corrodes away. A protective surface layer of oxide and carbonate ( forms as the zinc corrodes. This protection lasts even after the zinc layer is scratched but degrades through time as the zinc corrodes away. The zinc is applied electrochemically or as molten zinc by hot-dip galvanizing or spraying. Galvanization is used on chain-link fencing, guard rails, suspension bridges, lightposts, metal roofs, heat exchangers, and car bodies.\nThe relative reactivity of zinc and its ability to attract oxidation to itself makes it an efficient sacrificial anode in cathodic protection (CP). For example, cathodic protection of a buried pipeline can be achieved by connecting anodes made from zinc to the pipe. Zinc acts as the anode (negative terminus) by slowly corroding away as it passes electric current to the steel pipeline. Zinc is also used to cathodically protect metals that are exposed to sea water. A zinc disc attached to a ship's iron rudder will slowly corrode while the rudder stays intact.<ref name=Stwertka1998p99/> Similarly, a zinc plug attached to a propeller or the metal protective guard for the keel of the ship provides temporary protection.\nWith a standard electrode potential (SEP) of \u22120.76 volts, zinc is used as an anode material for batteries. (More reactive lithium (SEP \u22123.04 V) is used for anodes in lithium batteries ). Powdered zinc is used in this way in alkaline batteries and the case (which also serves as the anode) of zinc\u2013carbon batteries is formed from sheet zinc. Zinc is used as the anode or fuel of the zinc-air battery/fuel cell. The zinc-cerium redox flow battery also relies on a zinc-based negative half-cell.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Applications", "_id": "1000049108--4--0---1", "title": "Zinc \u2014 The Anti-Corrosion Agent."}
{"qas": [{"question": "What is zinc and why is it used in die casting?", "answer": ""}, {"question": "What is a widely used zinc alloy?", "answer": "brass", "ae_score": -0.2614912446798473, "qg_score": null}, {"question": "What is a widely used zinc alloy?", "answer": "brass", "ae_score": -0.2614912446798473, "qg_score": null}], "content": "A widely used zinc alloy is brass, in which copper is alloyed with anywhere from 3% to 45% zinc, depending upon the type of brass. Brass is generally more ductile and stronger than copper, and has superior corrosion resistance. These properties make it useful in communication equipment, hardware, musical instruments, and water valves.\nOther widely used zinc alloys include nickel silver, typewriter metal, soft and aluminium solder, and commercial bronze. Zinc is also used in contemporary pipe organs as a substitute for the traditional lead/tin alloy in pipes. Alloys of 85\u201388% zinc, 4\u201310% copper, and 2\u20138% aluminium find limited use in certain types of machine bearings. Zinc is the primary metal in American one cent coins (pennies) since 1982. The zinc core is coated with a thin layer of copper to give the appearance of a copper coin. In 1994, 33200 t of zinc were used to produce 13.6 billion pennies in the United States.\nAlloys of zinc with small amounts of copper, aluminium, and magnesium are useful in die casting as well as spin casting, especially in the automotive, electrical, and hardware industries. These alloys are marketed under the name Zamak. An example of this is zinc aluminium. The low melting point together with the low viscosity of the alloy makes possible the production of small and intricate shapes. The low working temperature leads to rapid cooling of the cast products and fast production for assembly. Another alloy, marketed under the brand name Prestal, contains 78% zinc and 22% aluminium, and is reported to be nearly as strong as steel but as malleable as plastic. This superplasticity of the alloy allows it to be molded using die casts made of ceramics and cement.\nSimilar alloys with the addition of a small amount of lead can be cold-rolled into sheets. An alloy of 96% zinc and 4% aluminium is used to make stamping dies for low production run applications for which ferrous metal dies would be too expensive. For building facades, roofing, and other applications for sheet metal formed by deep drawing, roll forming, or bending, zinc alloys with titanium and copper are used. Unalloyed zinc is too brittle for these manufacturing processes.\nAs a dense, inexpensive, easily worked material, zinc is used as a lead replacement. In the wake of lead concerns, zinc appears in weights for various applications ranging from fishing to tire balances and flywheels.\nCadmium zinc telluride (CZT) is a semiconductive alloy that can be divided into an array of small sensing devices. These devices are similar to an integrated circuit and can detect the energy of incoming gamma ray photons. When behind an absorbing mask, the CZT sensor array can determine the direction of the rays.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Alloys", "_id": "1000049108--4--1---1", "title": "What Is Zinc Alloy?"}
{"qas": [{"question": "What is the difference between Zinc Chloride and Zinc methyl?", "answer": ""}, {"question": "What is used to make zinc bars?", "answer": "Zinc sheet metal", "ae_score": -0.24984538793801145, "qg_score": null}, {"question": "What is used to make zinc bars?", "answer": "Zinc sheet metal", "ae_score": -0.24984538793801145, "qg_score": null}], "content": "Roughly one quarter of all zinc output in the United States in 2009 was consumed in zinc compounds; a variety of which are used industrially. Zinc oxide is widely used as a white pigment in paints and as a catalyst in the manufacture of rubber to disburse heat. Zinc oxide is used to protect rubber polymers and plastics from ultraviolet radiation (UV). The semiconductor properties of zinc oxide make it useful in varistors and photocopying products. The zinc zinc-oxide cycle is a two step thermochemical process based on zinc and zinc oxide for hydrogen production.\nZinc chloride is often added to lumber as a fire retardant and sometimes as a wood preservative. It is used in the manufacture of other chemicals. Zinc methyl () is used in a number of organic syntheses. Zinc sulfide (ZnS) is used in luminescent pigments such as on the hands of clocks, X-ray and television screens, and luminous paints. Crystals of ZnS are used in lasers that operate in the mid-infrared part of the spectrum. Zinc sulfate is a chemical in dyes and pigments. Zinc pyrithione is used in antifouling paints.\nZinc powder is sometimes used as a propellant in model rockets. When a compressed mixture of 70% zinc and 30% sulfur powder is ignited there is a violent chemical reaction. This produces zinc sulfide, together with large amounts of hot gas, heat, and light.\nZinc sheet metal is used to make zinc bars.\n, the most abundant isotope of zinc, is very susceptible to neutron activation, being transmuted into the highly radioactive , which has a half-life of 244 days and produces intense gamma radiation. Because of this, zinc oxide used in nuclear reactors as an anti-corrosion agent is depleted of  before use, this is called depleted zinc oxide. For the same reason, zinc has been proposed as a salting material for nuclear weapons (cobalt is another, better-known salting material). A jacket of isotopically enriched  would be irradiated by the intense high-energy neutron flux from an exploding thermonuclear weapon, forming a large amount of  significantly increasing the radioactivity of the weapon's fallout. Such a weapon is not known to have ever been built, tested, or used.\n is used as a tracer to study how alloys that contain zinc wear out, or the path and the role of zinc in organisms.\nZinc dithiocarbamate complexes are used as agricultural fungicides; these include Zineb, Metiram, Propineb and Ziram. Zinc naphthenate is used as wood preservative. Zinc in the form of ZDDP, is used as an anti-wear additive for metal parts in engine oil.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Other industrial uses", "_id": "1000049108--4--2---1", "title": "Zinc Oxide & Zinc Oxide"}
{"qas": [{"question": "What is Zinc and how does it work?", "answer": ""}, {"question": "What is attenuated by ingestion of zinc?", "answer": "Gastroenteritis", "ae_score": -0.3869628983742638, "qg_score": null}, {"question": "What is attenuated by ingestion of zinc?", "answer": "Gastroenteritis", "ae_score": -0.3869628983742638, "qg_score": null}], "content": "In most single-tablet, over-the-counter, daily vitamin and mineral supplements, zinc is included in such forms as zinc oxide, zinc acetate, or zinc gluconate. Zinc is generally considered to be an antioxidant. However, it is redox inert and thus can serve such a function only indirectly.  As such may protect against accelerated aging of the skin and muscles of the body; studies differ as to its effectiveness. Zinc also helps speed up the healing process after an injury. It is also suspected of being beneficial to the human immune system, and deficiency may be deleterious to virtually all parts of the system.\nZinc deficiency has been associated with major depressive disorder (MDD), and zinc supplements may be an effective treatment. Zinc supplementation may reduce the minimum effective dose of amphetamine when it is used for the treatment of ADHD.\nZinc serves as a simple, inexpensive, and critical tool for treating diarrheal episodes among children in the developing world. Zinc becomes depleted in the body during diarrhea, but recent studies suggest that replenishing zinc with a 10- to 14-day course of treatment can reduce the duration and severity of diarrheal episodes and may also prevent future episodes for as long as three months.\nThe Age-Related Eye Disease Study determined that zinc can be part of an effective treatment for age-related macular degeneration. Zinc supplement is an effective treatment for acrodermatitis enteropathica, a genetic disorder affecting zinc absorption that was previously fatal to affected infants.\nGastroenteritis is strongly attenuated by ingestion of zinc, possibly by direct antimicrobial action of the ions in the gastrointestinal tract, or by the absorption of the zinc and re-release from immune cells (all granulocytes secrete zinc), or both.\nIn 2011, researchers at John Jay College of Criminal Justice reported that dietary zinc supplements can mask the presence of drugs in urine. Similar claims appear in web forums.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Dietary supplement", "_id": "1000049108--4--3---1", "title": "Zinc Supplements for the Treatment of Gastroenteritis"}
{"qas": [{"question": "What is Cheetah Zinc and how does it work?", "answer": ""}, {"question": "What is an effective antimicrobial agent even at low concentrations?", "answer": "Zinc ions", "ae_score": -0.14363571293752542, "qg_score": null}, {"question": "What is an effective antimicrobial agent even at low concentrations?", "answer": "Zinc ions", "ae_score": -0.14363571293752542, "qg_score": null}], "content": "Topical preparations of zinc include those used on the skin, often in the form of zinc oxide. Zinc preparations can protect against sunburn in the summer and windburn in the winter. Applied thinly to a baby's diaper area (perineum) with each diaper change, it can protect against diaper rash.\nChelated zinc is used in toothpastes and mouthwashes to prevent bad breath.\nZinc pyrithione is widely included in shampoos to prevent dandruff.\nZinc ions are effective antimicrobial agents even at low concentrations.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Topical use", "_id": "1000049108--4--5---1", "title": "Zinc Ions \u2014 Antimicrobial Agents"}
{"qas": [{"question": "Why is zinc used as a catalyst for organic synthesis?", "answer": ""}, {"question": "What is the science of compounds that contain carbon-zinc bonds?", "answer": "Organozinc chemistry", "ae_score": -0.7356337813191812, "qg_score": null}, {"question": "What is the science of compounds that contain carbon-zinc bonds?", "answer": "Organozinc chemistry", "ae_score": -0.7356337813191812, "qg_score": null}], "content": "Organozinc chemistry is the science of compounds that contain carbon-zinc bonds, describing the physical properties, synthesis, and chemical reactions.Many organozinc compounds are important. Among important applications are\nZinc has found many applications as catalyst in organic synthesis including asymmetric synthesis, being cheap and easily available alternative to precious metal complexes. The results (yield and ee) obtained with chiral zinc catalysts are comparable to those achieved with palladium, ruthenium, iridium and others, and zinc becomes metal catalyst of choice.", "page_name": "Zinc", "page_id": "Zinc", "heading": "Applications", "sub_heading": "Organic chemistry", "_id": "1000049108--4--6---1", "title": "Organozinc Chemistry \u2014 The science of compounds that contain carbon-zinc bonds,"}
{"qas": [{"question": "What was the impact of the Great Depression on the economy?", "answer": ""}, {"question": "Who came up with the austrian business cycle theory?", "answer": "Maurice Allais", "ae_score": -0.09911994452244431, "qg_score": null}, {"question": "Who came up with the austrian business cycle theory?", "answer": "Maurice Allais", "ae_score": -0.09911994452244431, "qg_score": null}], "content": "According to Nicholas Kaldor, Hayek's work on the Austrian business cycle theory had at first \"fascinated the academic world of economists,\" but attempts to fill in the gaps in theory led to the gaps appearing \"larger, instead of smaller,\" until ultimately \"one was driven to the conclusion that the basic hypothesis of the theory, that scarcity of capital causes crises, must be wrong.\"\nLionel Robbins, who had embraced the Austrian theory of the business cycle in ''The Great Depression'' (1934), later regretted having written that book and accepted many of the Keynesian counterarguments.\nThe Nobel Prize Winner Maurice Allais was a proponent of Austrian business cycle theory and their perspective on the Great Depression and often quoted Ludwig Von Mises and Murray N. Rothbard.\nWhen, in 1937, the League of Nations examined the causes of and solutions to business cycles, the Austrian business cycle theory alongside the Keynesian and Marxian theory were the three main theories examined.", "page_name": "Austrian business cycle theory", "page_id": "Austrian%20business%20cycle%20theory", "heading": "Reactions of economists and policymakers", "sub_heading": "Reactions of economists and policymakers", "_id": "1000051171--4---1---1", "title": "Austrian Business Cycle Theory"}
{"qas": [{"question": "Why is the Australian dollar falling so rapidly?", "answer": ""}, {"question": "When did the austrian business cycle theory come into being?", "answer": "1998", "ae_score": -0.26888482934031094, "qg_score": null}, {"question": "When did the austrian business cycle theory come into being?", "answer": "1998", "ae_score": -0.26888482934031094, "qg_score": null}], "content": "Some economists argue that the Austrian business cycle theory requires bankers and investors to exhibit a kind of irrationality, because their theory requires bankers to be regularly fooled into making unprofitable investments by temporarily low interest rates. In response, historian Thomas Woods argues that few bankers and investors are familiar enough with the Austrian business cycle theory to consistently make sound investment decisions. Austrian economists Anthony Carilli and Gregory Dempster argue that a banker or firm loses market share if it does not borrow or loan at a magnitude consistent with current interest rates, regardless of whether rates are below their natural levels. Thus businesses are forced to operate as though rates were set appropriately, because the consequence of a single entity deviating would be a loss of business. Austrian economist Robert Murphy argues that it is difficult for bankers and investors to make sound business choices because they cannot know what the interest rate would be if it were set by the market. Austrian economist Sean Rosenthal argues that widespread knowledge of the Austrian business cycle theory increases the amount of malinvestment during periods of artificially low interest rates.\nEconomist Paul Krugman has argued that the theory cannot explain changes in unemployment over the business cycle. Austrian business cycle theory postulates that business cycles are caused by the misallocation of resources from consumption to investment during \"booms\", and out of investment during \"busts\". Krugman argues that because total spending is equal to total income in an economy, the theory implies that the reallocation of resources during \"busts\" would increase employment in consumption industries, whereas in reality, spending declines in all sectors of an economy during recessions. He also argues that according to the theory the initial \"booms\" would also cause resource reallocation, which implies an increase in unemployment during booms as well. In response, Austrian economist David Gordon argues that Krugman's argument is dependent on a misrepresentation of the theory. He furthermore argues that prices on consumption goods may go up as a result of the investment bust, which could mean that the amount spent on consumption could increase even though the quantity of goods consumed has not. Furthermore, Roger Garrison argues that a false boom caused by artificially low interest rates would cause a boom in consumption goods as well as investment goods (with a decrease in \"middle goods\"), thus explaining the jump in unemployment at the end of a boom. Many Austrians also argue that capital allocated to investment goods cannot quickly be augmented to create consumption goods and therefore the transition costs associated with moving back to a more balanced economy once the boom is over explains the often observed extended periods of unemployment.\nEconomist Bryan Caplan has examined ABCT and Caplan denies that the shift must reverse itself or \"that the artificially stimulated investments have any tendency to become malinvestments\".\nIn a 1998 interview, Friedman expressed dissatisfaction with the policy implications of the theory:", "page_name": "Austrian business cycle theory", "page_id": "Austrian%20business%20cycle%20theory", "heading": "Criticisms", "sub_heading": "Criticisms", "_id": "1000051171--7--0---1", "title": "Austrian Business Cycle Theory \u2014 A Review"}
{"qas": [{"question": "What is the difference between Austrian Economics and Friedman Economics?", "answer": ""}, {"question": "Who proposed the austrian business cycle theory?", "answer": "Walter Block", "ae_score": -0.6868640343534638, "qg_score": null}, {"question": "According to the austrian business cycle theory, credit expansion, recession and credit expansion are?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "Hummel argues that the Austrian explanation of the business cycle fails on empirical grounds. In particular, he notes that investment spending remained positive in all recessions where there are data, except for the Great Depression. He argues that this casts doubt on the notion that recessions are caused by a reallocation of resources from industrial production to consumption, since he argues that the Austrian business cycle theory implies that net investment should be below zero during recessions. In response, Austrian economist Walter Block argues that the misallocation during booms does not preclude the possibility of demand increasing overall.\nIn 1969, economist Milton Friedman, after examining the history of business cycles in the U.S., concluded that \"The Hayek\u2013Mises explanation of the business cycle is contradicted by the evidence. It is, I believe, false.\"<ref name=Friedman1969/> He analyzed the issue using newer data in 1993, and again reached the same conclusion.Economist Jesus Huerta de Soto claims that Friedman has not proven his conclusion because he focuses on  the contraction of GDP being as high as the previous contraction, but that the theory \"establishes a correlation between credit expansion, microeconomic malinvestment and recession, not between economic expansion and recession, both of which are measured by an aggregate (GDP)\" and that the empirical record shows strong correlation.\nReferring to Friedman's discussion of the business cycle, Austrian economist Roger Garrison stated, \"Friedman's empirical findings are broadly consistent with both Monetarist and Austrian views,\" and goes on to argue that although Friedman's model \"describes the economy's performance at the highest level of aggregation; Austrian theory offers an insightful account of the market process that might underlie those aggregates.\"", "page_name": "Austrian business cycle theory", "page_id": "Austrian%20business%20cycle%20theory", "heading": "Criticisms", "sub_heading": "Empirical objections", "_id": "1000051171--7--1---1", "title": "The Austrian Business Cycle Theories"}
{"qas": [{"question": "Why are there so many socialist movements in the world?", "answer": ""}, {"question": "What is the dominant economic system in the world today?", "answer": "capitalism", "ae_score": -0.4509875843779765, "qg_score": null}, {"question": "What type of credit crisis occurred in 2008?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "By the beginning of the 21st century, capitalism had become the pervasive economic system worldwide. The collapse of the Soviet bloc in 1991 significantly reduced the influence of Socialism as an alternative economic system. Socialist movements continue to be influential in some parts of the world, most notably Latin-American Bolivarianism, with some having ties to more traditional anti-capitalist movements, such as Bolivarian Venezuela's ties to communist Cuba.\nIn many emerging markets, the influence of banking and financial capital have come to increasingly shape national developmental strategies, leading some to argue we are in a new phase of financial capitalism.\nState intervention in global capital markets following the financial crisis of 2007\u20132010 was perceived by some as signaling a crisis for free-market capitalism. Serious turmoil in the banking system and financial markets due in part to the subprime mortgage crisis reached a critical stage during September 2008, characterized by severely contracted liquidity in the global credit markets posed an existential threat to investment banks and other institutions.", "page_name": "History of capitalism", "page_id": "History%20of%20capitalism", "heading": "Today", "sub_heading": "Today", "_id": "1000051617--4---1---1", "title": "Financial Capitalism and the Emerging Markets"}
{"qas": [{"question": "How did the ratings agencies like Standard  &  Poor's make money during the financial crisis?", "answer": ""}, {"question": "What act did the federal government pass in 1984 to improve the marketability of private-?", "answer": "Secondary Mortgage Market Enhancement Act", "ae_score": -0.9912133870367121, "qg_score": null}, {"question": "What type of financial products were cds and other structured finance products linked to?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "The ratings agencies were heavily involved in the markets that enabled the subprime credit bubble of 2000-2008 and the subsequent financial crisis. In 1984 the federal government of the United States passed the Secondary Mortgage Market Enhancement Act (SMMEA) to improve the marketability of private-label (non-agency) mortgage-backed securities, which declared NRSRO AA-rated mortgage-backed securities to be legal investments equivalent to Treasury securities and other federal government bonds for federally-charted banks (such as federal savings banks, federal savings associations, etc.), state-chartered financial institutions (such as depository banks and insurance companies) unless overridden by state law by October 1991 (of which 21 states did so), and Department of Labor-regulated pension funds.\nThe agencies made massive profits from rating Collateralized debt obligations, residential mortgage-backed securities, and other creatures of structured finance intimately connected to the subprime industry. The ratings on these products were essential to the way the banks marketed the products. Buyers, like pension funds, university endowments, and cities (a classic example being the city of Narvik, Norway), relied on these ratings in their decisions to purchase CDOs and other structured finance products. The activities of the ratings agencies have been detailed in many books, including ''The Big Short'', by Michael Lewis, ''Confidence Game'' by Christine S. Richard, ''All The Devils are Here'' by Bethany McClean and Joe Nocera, and in many other accounts of the financial crisis. Janet Tavakoli, author of ''Structured Finance and Collateralized Debt Obligations'', has suggested that these agencies lose their NRSRO status in relation to certain financial products. In 2011, the US Senate released the Levin-Coburn report on \"Wall Street and the Financial Crisis\"; it did a case study of the behavior of some of the CRAs during the crisis.", "page_name": "Nationally recognized statistical rating organization", "page_id": "Nationally%20recognized%20statistical%20rating%20organization", "heading": "Subprime mortgages, CDOs, and the financial crisis", "sub_heading": "Subprime mortgages, CDOs, and the financial crisis", "_id": "1000053361--2---1---1", "title": "The Ratings Agencies of the Subprime Credit Bubble of 2000-2008"}
{"qas": [{"question": "What is Tiagabine and how does it work?", "answer": ""}, {"question": "Who approves the use of tiagabine for seizures?", "answer": "U.S. Food and Drug Administration", "ae_score": -0.4120257303026829, "qg_score": null}, {"question": "Who approves the use of tiagabine for seizures?", "answer": "U.S. Food and Drug Administration", "ae_score": -0.4120257303026829, "qg_score": null}], "content": "Tiagabine is approved by U.S. Food and Drug Administration (FDA) as an adjunctive treatment for partial seizures in individuals of age 12 and up. It may also be prescribed off-label by physicians to treat anxiety disorders and panic disorder as well as neuropathic pain (including fibromyalgia). For anxiety and neuropathic pain, tiagabine is used primarily to augment other treatments. Tiagabine may be used alongside selective serotonin reuptake inhibitors, serotonin-norepinephrine reuptake inhibitors, or benzodiazepines for anxiety, or antidepressants, gabapentin, other anticonvulsants, or opioids for neuropathic pain.", "page_name": "Tiagabine", "page_id": "Tiagabine", "heading": "Medical uses", "sub_heading": "Medical uses", "_id": "1000054038--0---1---1", "title": "Tiagabine is an adjunctive treatment for anxiety and neuropathic pain."}
{"qas": [{"question": "If the immune system is so strong, why do we not get sick from our own immune system?", "answer": ""}, {"question": "What is the most common cause of immunodeficiency in developing countries?", "answer": "malnutrition", "ae_score": -0.34600114441876795, "qg_score": null}, {"question": "The loss of the thymus at an early age is called?", "answer": "severe combined immunodeficiency", "ae_score": null, "qg_score": null}], "content": "The immune system is a remarkably effective structure that incorporates specificity, inducibility and adaptation. Failures of host defense do occur, however, and fall into three broad categories: immunodeficiencies, autoimmunity, and hypersensitivities.\nImmunodeficiencies occur when one or more of the components of the immune system are inactive. The ability of the immune system to respond to pathogens is diminished in both the young and the elderly, with immune responses beginning to decline at around 50 years of age due to immunosenescence. In developed countries, obesity, alcoholism, and drug use are common causes of poor immune function. However, malnutrition is the most common cause of immunodeficiency in developing countries. Diets lacking sufficient protein are associated with impaired cell-mediated immunity, complement activity, phagocyte function, IgA antibody concentrations, and cytokine production. Additionally, the loss of the thymus at an early age through genetic mutation or surgical removal results in severe immunodeficiency and a high susceptibility to infection.\nImmunodeficiencies can also be inherited or 'acquired'. Chronic granulomatous disease, where phagocytes have a reduced ability to destroy pathogens, is an example of an inherited, or congenital, immunodeficiency. AIDS and some types of cancer cause acquired immunodeficiency.\nOveractive immune responses comprise the other end of immune dysfunction, particularly the autoimmune disorders. Here, the immune system fails to properly distinguish between self and non-self, and attacks part of the body. Under normal circumstances, many T cells and antibodies react with \"self\" peptides. One of the functions of specialized cells (located in the thymus and bone marrow) is to present young lymphocytes with self antigens produced throughout the body and to eliminate those cells that recognize self-antigens, preventing autoimmunity.\nHypersensitivity is an immune response that damages the body's own tissues. They are divided into four classes (Type I \u2013 IV) based on the mechanisms involved and the time course of the hypersensitive reaction. Type I hypersensitivity is an immediate or anaphylactic reaction, often associated with allergy. Symptoms can range from mild discomfort to death. Type I hypersensitivity is mediated by IgE, which triggers degranulation of mast cells and basophils when cross-linked by antigen.Type II hypersensitivity occurs when antibodies bind to antigens on the patient's own cells, marking them for destruction. This is also called antibody-dependent (or cytotoxic) hypersensitivity, and is mediated by IgG and IgM antibodies.Immune complexes (aggregations of antigens, complement proteins, and IgG and IgM antibodies) deposited in various tissues trigger Type III hypersensitivity reactions. Type IV hypersensitivity (also known as cell-mediated or ''delayed type hypersensitivity'') usually takes between two and three days to develop. Type IV reactions are involved in many autoimmune and infectious diseases, but may also involve ''contact dermatitis'' (poison ivy). These reactions are mediated by T cells, monocytes, and macrophages.", "page_name": "Immune system", "page_id": "Immune%20system", "heading": "Disorders of human immunity", "sub_heading": "Disorders of human immunity", "_id": "1000055147--4---1---1", "title": "Immunodeficiencies, Autoimmunity, and Hypersensi"}
{"qas": [{"question": "What is the difference between hearing loss and hearing loss?", "answer": ""}, {"question": "What is the general name of the operation to repair the middle ear's eardrum?", "answer": "Tympanoplasty", "ae_score": -0.37356802791745863, "qg_score": null}, {"question": "What is it called when deafness is caused by damage to the inner ear?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Hearing loss may be either partial or total. This may be a result of injury or damage, congenital disease, or physiological causes. When hearing loss is a result of injury or damage to the outer ear or middle ear, it is known as conductive hearing loss. When deafness is a result of injury or damage to the inner ear, vestibulochoclear nerve, or brain, it is known as sensorineural hearing loss.\nCauses of conductive hearing loss include an ear canal blocked by ear wax, ossicles that are fixed together or absent, or holes in the eardrum. Conductive hearing loss may also result from middle ear inflammation causing fluid build-up in the normally air-filled space, such as by otitis media. Tympanoplasty is the general name of the operation to repair the middle ear's eardrum and ossicles. Grafts from muscle fascia are ordinarily used to rebuild an intact eardrum. Sometimes artificial ear bones are placed to substitute for damaged ones, or a disrupted ossicular chain is rebuilt in order to conduct sound effectively.\nHearing aids or cochlear implants may be used if the hearing loss is severe or prolonged. Hearing aids work by amplifying the sound of the local environment and are best suited to conductive hearing loss. Cochlear implants transmit the sound that is heard as if it were a nervous signal, bypassing the cochlea.", "page_name": "Ear", "page_id": "Ear", "heading": "Clinical significance", "sub_heading": "Clinical significance", "_id": "2000001423--3--0---1", "title": "Hearing Aids and Cochlear Implants for Hearing Loss"}
{"qas": [{"question": "What is the difference between hearing loss and congenital deafness?", "answer": ""}, {"question": "How many children suffer from congenital deafness due to the development of the inner ear?", "answer": "one out of one thousand", "ae_score": -0.7715573982238383, "qg_score": null}, {"question": "Ring 18 is an example of what type of syndromes?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "Anomalies and malformations of the pinna are common. These anomalies include chromosome syndromes such as ring 18. Children may also present cases of abnormal ear canals and low ear implantation.<ref name=moore2008/> In rare cases no pinna is formed (atresia), or is extremely small (microtia). Small pinnae can develop when the auricular hillocks do not develop properly. The ear canal can fail to develop if it does not channelise properly or if there is an obstruction.<ref name=moore2008/> Reconstructive surgery to treat hearing loss is considered as an option for children older than five, with a cosmetic surgical procedure to reduce the size or change the shape of the ear is called an otoplasty. The initial medical intervention is aimed at assessing the baby's hearing and the condition of the ear canal, as well as the middle and inner ear. Depending on the results of tests, reconstruction of the outer ear is done in stages, with planning for any possible repairs of the rest of the ear.\nApproximately one out of one thousand children suffer some type of congenital deafness related to the development of the inner ear. Inner ear congenital anomalies are related to sensorineural hearing loss and are generally diagnosed with a computed tomography (CT) scan or a magnetic resonance imaging (MRI) scan.<ref name=kliegman2007/> Hearing loss problems also derive from inner ear anomalies because its development is separate from that of the middle and external ear.<ref name=moore2008/> Middle ear anomalies can occur because of errors during head and neck development. The first pharyngeal pouch syndrome associates middle ear anomalies to the malleus and incus structures as well as to the non-differentiation of the annular stapedial ligament. Temporal bone and ear canal anomalies are also related to this structure of the ear and are known to be associated with sensorineural hearing loss and conductive hearing loss.<ref name=kliegman2007/>", "page_name": "Ear", "page_id": "Ear", "heading": "Clinical significance", "sub_heading": "Congenital abnormalities", "_id": "2000001423--3--1---1", "title": "Ear | Clinical significance | Congenital abnormalities"}
{"qas": [{"question": "What is vertigo?", "answer": ""}, {"question": "Where is the otolith located on the ear?", "answer": "cupola", "ae_score": -0.5800842209635503, "qg_score": null}, {"question": "What does M\u00e9ni\u00e8re's disease, labyrinthitis, strokes, and other infective?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Vertigo refers to the inappropriate perception of motion. This is due to dysfunction of the vestibular system. One common type of vertigo is benign paroxysmal positional vertigo, when an otolith is displaced from the ventricles to the semicircular canal. The displaced otolith rests on the cupola, causing a sensation of movement when there is none. M\u00e9ni\u00e8re's disease, labyrinthitis, strokes, and other infective and congenital diseases may also result in the perception of vertigo.", "page_name": "Ear", "page_id": "Ear", "heading": "Clinical significance", "sub_heading": "Vertigo", "_id": "2000001423--3--2---1", "title": "Vertigo Symptoms and Treatment"}
{"qas": [{"question": "Why do people lose hearing in industrial environments?", "answer": ""}, {"question": "What is the discharge from the ear called?", "answer": "otorrhea", "ae_score": -0.6179277966423541, "qg_score": null}, {"question": "What is one of the principal damage mechanisms to the inner ear?", "answer": "overstimulation of hair cells", "ae_score": null, "qg_score": null}], "content": "Injuries to the external ear occur fairly frequently, and can leave minor to major deformity. Injuries include: laceration, avulsion injuries, burn and repeated twisting or pulling of an ear, for discipline or torture. Chronic damage to the ears can cause cauliflower ear, a common condition in boxers and wrestlers in which the cartilage around the ears becomes lumpy and distorted owing to persistence of a haematoma around the perichondrium, which can impair blood supply and healing. Owing to its exposed position, the external ear is susceptible to frostbite as well as skin cancers, including squamous-cell carcinoma and basal-cell carcinomas.\nThe ear drum may become perforated in the event of a large sound or explosion, when diving or flying (called barotrauma), or by objects inserted into the ear. Another common cause of injury is due to an infection such as otitis media. These may cause a discharge from the ear called otorrhea, and are often investigated by otoscopy and audiometry. Treatment may include watchful waiting, antibiotics and possibly surgery, if the injury is prolonged or the position of the ossicles is affected. Skull fractures that go through the part of the skull containing the ear structures (the temporal bone) can also cause damage to the middle ear. A cholesteatoma is a cyst of squamous skin cells that may develop from birth or secondary to other causes such as chronic ear infections. It may impair hearing or cause dizziness or vertigo, and is usually investigated by otoscopy and may require a CT scan. The treatment for cholesteatoma is surgery.\nThere are two principal damage mechanisms to the inner ear in industrialised society, and both injure hair cells. The first is exposure to elevated sound levels (noise trauma), and the second is exposure to drugs and other substances (ototoxicity). A large number of people are exposed to sound levels on a daily basis that are likely to lead to significant hearing loss. The National Institute for Occupational Safety and Health has recently published research on the estimated numbers of persons with hearing difficulty (11%) and the percentage of those that can be attributed to occupational noise exposure (24%). Furthermore, according to the National Health and Nutrition Examination Survey (NHANES), approximately twenty-two million (17%) US workers reported exposure to hazardous workplace noise. Workers exposed to hazardous noise further exacerbate the potential for developing noise-induced hearing loss when they do not wear hearing protection.", "page_name": "Ear", "page_id": "Ear", "heading": "Clinical significance", "sub_heading": "Injury", "_id": "2000001423--3--3---1", "title": "Noise-Induced Hearing Loss"}
{"qas": [{"question": "Why do some people have tinnitus and others don't?", "answer": ""}, {"question": "What is the term for the hearing of sound when no external sound is present?", "answer": "Tinnitus", "ae_score": -0.3451063380546808, "qg_score": null}, {"question": "What is the most common cause of tinnitus?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Tinnitus is the hearing of sound when no external sound is present. While often described as a ringing, it may also sound like a clicking, hiss or roaring.<ref name=NIH2014/> Rarely, unclear voices or music are heard.<ref name=Lancet2013/> The sound may be soft or loud, low pitched or high pitched and appear to be coming from one ear or both. Most of the time, it comes on gradually. In some people, the sound causes depression, anxiety, or concentration difficulties.<ref name=NIH2014/>\nTinnitus is not a disease but a symptom that can result from a number of underlying causes. One of the most common causes is noise-induced hearing loss. Other causes include: ear infections, disease of the heart or blood vessels, M\u00e9ni\u00e8re's disease, brain tumors, emotional stress, exposure to certain medications, a previous head injury, and earwax.<ref name=NIH2014/> It is more common in those with depression.<ref name=Lancet2013/>", "page_name": "Ear", "page_id": "Ear", "heading": "Clinical significance", "sub_heading": "Tinnitus", "_id": "2000001423--3--4---1", "title": "Ear | Clinical significance | Tinnitus"}
{"qas": [{"question": "What are the advantages and disadvantages of the crossover experiment?", "answer": ""}, {"question": "How are the results of a crossover experiment obtained?", "answer": "direct characterization of the product", "ae_score": -0.8786127019286472, "qg_score": null}, {"question": "How are the results of a crossover experiment obtained?", "answer": "direct characterization of the product", "ae_score": -0.8786127019286472, "qg_score": null}], "content": "A major advantage of the crossover experiment is that the results of the experiment are obtained by direct characterization of the product. The techniques involved are therefore those already familiar to the experimental chemist. Mass spectrometry and NMR spectroscopy are the two most common ways of determining the products and their relative ratios. NMR spectroscopy is particularly useful for isotopic labeling studies that use isotopes of hydrogen or carbon.\nIR spectroscopy can be useful in specialized situations, such as when CO was used to probe the mechanism of alkyl insertion into metal-carbon monoxide bonds to form metal-acyl complexes. Tracking the CO in the products was accomplished using IR spectroscopy because the greater mass of C compared to C produces a distinctive shift of the \u03bd(CO) stretching frequency to lower energy.", "page_name": "Crossover experiment (chemistry)", "page_id": "Crossover%20experiment%20(chemistry)", "heading": "Characterization", "sub_heading": "Characterization", "_id": "2000008408--4---1---1", "title": "(CO) Stretching Frequency (CO) Stretching Freque"}
{"qas": [{"question": "What is 5-HT receptor activation and how does it work?", "answer": ""}, {"question": "What is the role of 5 t1a receptors in the human body?", "answer": "neuromodulation", "ae_score": -0.4097124670744323, "qg_score": null}, {"question": "Serotonin reuptake inhibitors ( ssris ) are an example of?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "5-HT receptor agonists are involved in neuromodulation. They decrease blood pressure and heart rate via a central mechanism, by inducing peripheral vasodilation, and by stimulating the vagus nerve. These effects are the result of activation of 5-HT receptors within the rostral ventrolateral medulla. The sympatholytic antihypertensive drug urapidil is an \u03b1-adrenergic receptor antagonist and 5-HT receptor agonist, and it has been demonstrated that the latter property contributes to its overall therapeutic effects. Vasodilation of the blood vessels in the skin via central 5-HT activation increases heat dissipation from the organism out into the environment, causing a decrease in body temperature.\nActivation of central 5-HT receptors triggers the release or inhibition of norepinephrine depending on species, presumably from the locus coeruleus, which then reduces or increases neuronal tone to the iris sphincter muscle by modulation of postsynaptic \u03b1-adrenergic receptors within the Edinger-Westphal nucleus, resulting in pupil dilation in rodents, and pupil constriction in primates including humans.\n5-HT receptor agonists like buspirone and flesinoxan show efficacy in relieving anxiety and depression, and buspirone and tandospirone are currently approved for these indications in various parts of the world. Others such as gepirone, flesinoxan, flibanserin, and naluzotan have also been investigated, though none have been fully developed and approved yet. Some of the atypical antipsychotics like aripiprazole are also partial agonists at the 5-HT receptor and are sometimes used in low doses as augmentations to standard antidepressants like the selective serotonin reuptake inhibitors (SSRIs).\n5-HT autoreceptor desensitization and increased 5-HT receptor postsynaptic activation via general increases in serotonin levels by serotonin precursor supplementation, serotonin reuptake inhibition, or monoamine oxidase inhibition has been shown to be a major mediator in the therapeutic benefits of most mainstream antidepressant supplements and pharmaceuticals, including serotonin precursors like L-tryptophan and 5-HTP, selective serotonin reuptake inhibitors (SSRIs), serotonin-norepinephrine reuptake inhibitors (SNRIs), tricyclic antidepressants (TCAs), tetracyclic antidepressants (TeCAs), and monoamine oxidase inhibitors (MAOIs). 5-HT receptor activation likely plays a significant role in the positive effects of serotonin releasing agents (SRAs) like MDMA (\"Ecstasy\") as well.\n5-HT receptors in the dorsal raphe nucleus are co-localized with neurokinin 1 (NK) receptors and have been shown to inhibit the release of substance P, their endogenous ligand. In addition to being antidepressant and anxiolytic in effect, 5-HT receptor activation has also been demonstrated to be antiemetic and analgesic, and all of these properties may be mediated in part or full, depending on the property in question, by NK receptor inhibition. Consequently, novel NK receptor antagonists are now in use for the treatment of nausea and emesis, and are also being investigated for the treatment of anxiety and depression.\n5-HT receptor activation has been shown to increase dopamine release in the medial prefrontal cortex, striatum, and hippocampus, and may be useful for improving the symptoms of schizophrenia and Parkinson's disease. As mentioned above, some of the atypical antipsychotics are 5-HT receptor partial agonists, and this property has been shown to enhance their clinical efficacy. Enhancement of dopamine release in these areas may also play a major role in the antidepressant and anxiolytic effects seen upon postsynaptic activation of the 5-HT receptor.\nActivation of 5-HT receptors has been demonstrated to impair certain aspects of memory (affecting declarative and non-declarative memory functions) and learning (due to interference with memory-encoding mechanisms), by inhibiting the release of glutamate and acetylcholine in various areas of the brain. 5-HT activation are known to improve cognitive functions associated with the prefrontal cortex, possibly via inducing prefrontal cortex dopamine and acetylcholine release. Conversely, 5-HT receptor antagonists such as lecozotan have been shown to facilitate certain types of learning and memory in rodents, and as a result, are being developed as novel treatments for Alzheimer's disease.\nOther effects of 5-HT activation that have been observed in scientific research include:", "page_name": "5-HT1A receptor", "page_id": "5-HT1A%20receptor", "heading": "Function", "sub_heading": "Function", "_id": "2000009888--1--0---1", "title": "Antidepressants and Antipsychotics"}
{"qas": [{"question": "How does the 5-HT receptor work?", "answer": ""}, {"question": "How many receptors are there on the 5-ht1a receptor?", "answer": "5", "ae_score": null, "qg_score": null}, {"question": "How many receptors are there on the 5-ht1a receptor?", "answer": "5", "ae_score": null, "qg_score": null}], "content": "5-HT receptor activation induces the secretion of various hormones including cortisol, corticosterone, adrenocorticotropic hormone (ACTH), oxytocin, prolactin, growth hormone, and \u03b2-endorphin. The receptor does not affect vasopressin or renin secretion, unlike the 5-HT receptors. It has been suggested that oxytocin release may contribute to the prosocial, antiaggressive, and anxiolytic properties observed upon activation of the receptor. \u03b2-Endorphin secretion may contribute to antidepressant, anxiolytic, and analgesic effects.", "page_name": "5-HT1A receptor", "page_id": "5-HT1A%20receptor", "heading": "Function", "sub_heading": "Endocrinology", "_id": "2000009888--1--1---1", "title": "-Endorphin Secretion and Antidepressant Effects"}
{"qas": [{"question": "Why do antidepressants take so long to kick in?", "answer": ""}, {"question": "What are the receptors that release serotonin called?", "answer": "autoreceptors", "ae_score": -0.4539181862023375, "qg_score": null}, {"question": "Mdai and maii are examples of what type of antidepressants?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "5-HT receptors can be located on the cell body, dendrites, axons, and both presynaptically and postsynaptically in nerve terminals or synapses. Those located on the soma and dendrites are referred to as somatodendritic, and those located presynaptically in the synapse are simply referred to as presynaptic. As a group, receptors that are sensitive to the neurotransmitter that is released by the neuron on which the receptors are located are known as autoreceptors; they typically constitute the key component of an ultra-short negative feedback loop whereby the neuron's release of neurotransmitter inhibits its further release of neurotransmitter. Stimulation of 5-HT autoreceptors inhibits the release of serotonin in nerve terminals. For this reason, 5-HT receptor agonists tend to exert a biphasic mode of action; they decrease serotonin release and postsynaptic 5-HT receptor activity in low doses, and further decrease serotonin release but increase postsynaptic 5-HT receptor activity at higher doses by directly stimulating the receptors in place of serotonin.\nThis autoreceptor-mediated inhibition of serotonin release has been theorized to be a major factor in the therapeutic lag that is seen with serotonergic antidepressants such as the SSRIs. The autoreceptors must first densensitize before the concentration of extracellular serotonin in the synapse can become elevated appreciably. Though the responsiveness of the autoreceptors is somewhat reduced with chronic treatment, they still remain effective at constraining large increases in extracellular serotonin concentrations. For this reason, serotonin reuptake inhibitors that also have 5-HT receptor antagonistic or partial agonistic properties, such as vilazodone and SB-649,915, are being investigated and introduced as novel antidepressants with the potential for a faster onset of action and improved effectiveness compared to those currently available.\nUnlike most drugs that elevate extracellular serotonin levels like the SSRIs and MAOIs, SRAs such as fenfluramine and MDMA bypass serotonin autoreceptors such as 5-HT. They do this by directly acting on the release mechanisms of serotonin neurons and forcing release to occur regardless of autoreceptor-mediated inhibition. As such, SRAs induce immediate and much greater increases in extracellular serotonin concentrations compared to other serotonin-elevating agents such as the SSRIs. In contrast to SRAs, SSRIs actually ''decrease'' serotonin levels initially and require several weeks of chronic dosing before serotonin concentrations reach their maximal elevation and full clinical benefits for conditions such as depression and anxiety are seen. For these reasons, selective serotonin releasing agents (SSRAs) such as MDAI and MMAI have been proposed as novel antidepressants with a putatively faster onset of action and improved effectiveness compared to current treatments.\nSimilarly to SRAs, sufficiently high doses of 5-HT receptor agonists also bypass the 5-HT autoreceptor-mediated inhibition of serotonin release and therefore increase 5-HT postsynaptic receptor activation by directly agonizing the postsynaptic receptors in lieu of serotonin. However, in contrast to SRAs, 5-HT receptor agonists do not bypass the inhibitory effect of 5-HT receptors located as heteroreceptors in non-serotonergic synapses where 5-HT postsynaptic receptors are not present, which, instead of serotonin, modulate the release of other neurotransmitters such as dopamine or glutamate. The therapeutic consequences of this difference, if any, are unknown.", "page_name": "5-HT1A receptor", "page_id": "5-HT1A%20receptor", "heading": "Function", "sub_heading": "Autoreceptors", "_id": "2000009888--1--2---1", "title": "Serotonin Reuptake Inhibitors"}
{"qas": [{"question": "What is the difference between homozygous and recessive genes?", "answer": ""}, {"question": "How many copies of the allele that codes for the dominant trait are there?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "Where does the zygote gene come from on a chromosome?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "A cell is said to be homozygous for a particular gene when identical alleles of the gene are present on both homologous chromosomes. The cell or organism in question is called a '''homozygote'''. True breeding organisms are always homozygous for the traits that are to be held constant.\nAn individual that is '''homozygous-dominant''' for a particular trait carries two copies of the allele that codes for the dominant trait. This allele, often called the \"dominant allele\", is normally represented by a capital letter (such as \"P\" for the dominant allele producing purple flowers in pea plants). When an organism is homozygous-dominant for a particular trait, the genotype is represented by a doubling of the symbol for that trait, such as \"PP\".\nAn individual that is '''homozygous-recessive''' for a particular trait carries two copies of the allele that codes for the recessive trait. This allele, often called the \"recessive allele\", is usually represented by the lowercase form of the letter used for the corresponding dominant trait (such as, with reference to the example above, \"p\" for the recessive allele producing white flowers in pea plants). The genotype of an organism that is homozygous-recessive for a particular trait is represented by a doubling of the appropriate letter, such as \"pp\".", "page_name": "Zygosity", "page_id": "Zygosity", "heading": "Types", "sub_heading": "Types", "_id": "2000013069--0--0---1", "title": "Zygosity | Types"}
{"qas": [{"question": "What is the difference between heterozygosity and dominance?", "answer": ""}, {"question": "Where is the capital letter of a heterozygote written?", "answer": "first", "ae_score": null, "qg_score": null}, {"question": "Where is the capital letter of a heterozygote written?", "answer": "first", "ae_score": null, "qg_score": null}], "content": "A diploid organism is heterozygous at a gene locus when its cells contain two different alleles of a gene. The cell or organism is called a '''heterozygote''' ''specifically'' for the allele in question, and therefore, heterozygosity refers to a specific genotype. Heterozygous genotypes are represented by a capital letter (representing the dominant allele) and a lowercase letter (representing the recessive allele), such as \"Rr\" or \"Ss\". Alternatively, a heterozygote for gene \"R\" is assumed to be \"Rr\". The capital letter is usually written first.\nIf the trait in question is determined by simple (complete) dominance, a heterozygote will express only the trait coded by the dominant allele, and the trait coded by the recessive allele will not be present. In more complex dominance schemes the results of heterozygosity can be more complex.", "page_name": "Zygosity", "page_id": "Zygosity", "heading": "Types", "sub_heading": "Heterozygous", "_id": "2000013069--0--1---1", "title": "Heterozygosity \u2014 a '''heterozy"}
{"qas": [{"question": "How does the hemizygous system work?", "answer": ""}, {"question": "How many copies of a gene are there in a diploid organism?", "answer": "one", "ae_score": null, "qg_score": null}, {"question": "What part of the chromosome is hemizygous?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "A chromosome  in a diploid organism is hemizygous when only one copy is present. The cell or organism is called a ''hemizygote''. Hemizygosity is also observed when one copy of a gene is deleted, or in the heterogametic sex when a gene is located on a sex chromosome. For organisms in which the male is heterogametic, such as humans, almost all X-linked genes are hemizygous in males with normal chromosomes because they have only one X chromosome and few of the same genes are on the Y chromosome. Transgenic mice generated through exogenous DNA microinjection of an embryo's pronucleus are also considered to be hemizygous because the introduced allele is expected to be incorporated into only one copy of any locus.  A transgenic can later be bred to homozygosity and maintained as an inbred line to reduce the need to confirm the genotypes of each litter.\nIn cultured mammalian cells, such as the Chinese hamster ovary cell line, a number of genetic loci are present in a functional hemizygous state, due to mutations or deletions in the other alleles.", "page_name": "Zygosity", "page_id": "Zygosity", "heading": "Types", "sub_heading": "Hemizygous", "_id": "2000013069--0--2---1", "title": "Hemizygosity in Humans"}
{"qas": [{"question": "What is the difference between homozygous null and homozygose null?", "answer": ""}, {"question": "How many mutant alleles does a nullizygous organism carry?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many mutant alleles does a nullizygous organism carry?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "A nullizygous organism carries two mutant alleles for the same gene. The mutant alleles are both complete loss-of-function or 'null' alleles, so homozygous null and nullizygous are synonymous. The mutant cell or organism is called a ''nullizygote''.", "page_name": "Zygosity", "page_id": "Zygosity", "heading": "Types", "sub_heading": "Nullizygous", "_id": "2000013069--0--3---1", "title": "Zygosity | Types | Nullizygous"}
{"qas": [{"question": "How did plants evolve to be so good at growing?", "answer": ""}, {"question": "What type of breeding is used to produce transgenic animals?", "answer": "Selective plant breeding", "ae_score": -0.32012117901550224, "qg_score": null}, {"question": "What type of animals are produced by selective breeding?", "answer": "transgenic", "ae_score": null, "qg_score": null}], "content": "Plant breeding has been used for thousands of years, and began with the domestication of wild plants into uniform and predictable agricultural cultigens. High-yielding varieties have been particularly important in agriculture.\nSelective plant breeding is also used in research to produce transgenic animals that breed \"true\" (i.e., are homozygous) for artificially inserted or deleted genes.", "page_name": "Selective breeding", "page_id": "Selective%20breeding", "heading": "Plant breeding", "sub_heading": "Plant breeding", "_id": "2000015941--2---1---1", "title": "Plant Breeding \u2014 The Evolution of Plant Breeding"}
{"qas": [{"question": "Why is there so much controversy about the effectiveness of antidepressants?", "answer": ""}, {"question": "Which drug is used to treat depression in children?", "answer": "citalopram", "ae_score": -0.11813299258665239, "qg_score": null}, {"question": "What type of drugs are used to treat depression?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "In the National Institute for Health and Clinical Excellence ranking of 10 antidepressants for efficacy and cost-effectiveness citalopram is fifth in effectiveness (after mirtazapine, escitalopram, venlafaxine, and sertraline) and fourth in cost-effectiveness. The ranking results were based on the meta-analysis by Andrea Cipriani. In another analysis by Cipriani, citalopram turned out to be more efficacious than paroxetine and reboxetine and more acceptable than tricyclics, reboxetine, and venlafaxine, but it seemed to be less efficacious than escitalopram.\nEvidence for effectiveness of citalopram for treating depression in children is uncertain.\nControversy exists regarding the efficacy of antidepressants in treating depression depending on its severity and duration, as discussed in Selective serotonin reuptake inhibitor.", "page_name": "Citalopram", "page_id": "Citalopram", "heading": "Medical uses", "sub_heading": "Medical uses", "_id": "2000015958--0--0---1", "title": "Citalopram is fifth in efficacy and fourth in cost-effectiveness"}
{"qas": [{"question": "How does Citalopram work?", "answer": ""}, {"question": "What is the name of the drug used to treat panic disorder?", "answer": "Citalopram", "ae_score": -0.3438535493183391, "qg_score": null}, {"question": "What is the name of the drug used to treat panic disorder?", "answer": "Citalopram", "ae_score": -0.3438535493183391, "qg_score": null}], "content": "Citalopram is licensed in the UK and other European countries  for panic disorder, with or without agoraphobia. The dose is 10 mg/d for a week, increasing to 20\u201330 mg/d, with a maximum of 40 mg/d.", "page_name": "Citalopram", "page_id": "Citalopram", "heading": "Medical uses", "sub_heading": "Panic disorder", "_id": "2000015958--0--1---1", "title": "Citalopram for panic disorder with or without agoraphobia."}
{"qas": [{"question": "Why is it that when you have a hot flash, you can't get rid of it?", "answer": ""}, {"question": "What is the name of the drug used to treat anxiety?", "answer": "Citalopram", "ae_score": -0.0863203727644778, "qg_score": null}, {"question": "What is the name of the drug used to treat anxiety?", "answer": "Citalopram", "ae_score": -0.0863203727644778, "qg_score": null}], "content": "Citalopram is frequently used off-label to treat anxiety, panic disorder, dysthymia premenstrual dysphoric disorder, body dysmorphic disorder and obsessive\u2013compulsive disorder.\nIt has been shown to be effective in 85% of patients with generalized anxiety disorder, including some who had failed with other SSRIs. It also appears to be as effective as fluvoxamine and paroxetine in obsessive-compulsive disorder. Some data suggest the effectiveness of intravenous infusion of citalopram in resistant OCD. Citalopram 40 mg/d is well tolerated and as effective as moclobemide in social anxiety disorder. There are studies suggesting that citalopram can be useful in reducing aggressive and impulsive behavior. It appears to be superior to placebo for behavioural disturbances associated with dementia. It has also been used successfully for hypersexuality in early Alzheimer\u2019s disease.\nA meta-analysis, including studies with fluoxetine, paroxetine, sertraline, escitalopram, and citalopram versus placebo, showed SSRIs to be effective in reducing symptoms of premenstrual syndrome, whether taken continuously or just in the luteal phase.Citalopram has produced a modest reduction in alcoholic drink intake and increase in drink-free days in studies of alcoholics, possibly by decreasing desire or reducing the reward.\nCitalopram has been found to reduce the symptoms of diabetic neuropathy.\nWhile on its own citalopram is less effective than amitriptyline in the prevention of migraines, in refractory cases, combination therapy may be more effective.\nCitalopram and other SSRIs can be used to treat hot flashes.\nA 2009 multisite randomized controlled study found no benefit and some adverse effects in autistic children from citalopram, raising doubts whether SSRIs are effective for treating repetitive behavior in children with autism.\nSome research suggests citalopram interacts with cannabinoid protein-couplings in the rat brain, and this is put forward as a potential cause of some of the drug's antidepressant effect.", "page_name": "Citalopram", "page_id": "Citalopram", "heading": "Medical uses", "sub_heading": "Off-label", "_id": "2000015958--0--2---1", "title": "Citalopram and Other SSRIs for Depression"}
{"qas": [{"question": "Why is Citalopram so popular?", "answer": ""}, {"question": "What is the name of the medication that helps prevent nausea?", "answer": "Citalopram", "ae_score": -0.6796653545545526, "qg_score": null}, {"question": "What is the name of the medication that helps prevent nausea?", "answer": "Citalopram", "ae_score": -0.6796653545545526, "qg_score": null}], "content": "Citalopram is typically taken in one dose, either in the morning or evening. It can be taken with or without food. Its absorption does not increase when taken with food, but doing so can help prevent nausea.  Nausea is often caused when the 5HT3 receptors actively absorb free serotonin, as this receptor is present within the digestive tract. The 5HT3 receptors stimulate vomiting. This side effect, if present, should subside as the body adjusts to the medication.\nCitalopram is considered safe and well tolerated in the therapeutic dose range. Distinct from some other agents in its class, it exhibits linear pharmacokinetics and minimal drug interaction potential, making it a better choice for the elderly or comorbid patients.", "page_name": "Citalopram", "page_id": "Citalopram", "heading": "Medical uses", "sub_heading": "Administration", "_id": "2000015958--0--3---1", "title": "Citalopram is a drug that can be used to treat nausea and vomiting"}
{"qas": [{"question": "What is the minimum weight cycle basis for a planar graph?", "answer": ""}, {"question": "Where is the cycle space found in a graph?", "answer": "planar graphs", "ae_score": -0.2098509948141456, "qg_score": null}, {"question": "Where is the cycle space found in a graph?", "answer": "planar graphs", "ae_score": -0.2098509948141456, "qg_score": null}], "content": "If a planar graph is embedded into the plane, its chain complex of edges and vertices may be embedded into a higher dimensional chain complex that also includes the sets of faces of the graph. The  boundary map of this chain complex takes any 2-chain (a set of faces) to the set of edges that belong to an odd number of faces in the 2-chain.The boundary of a 2-chain is necessarily an Eulerian subgraph, and every Eulerian subgraph can be generated in this way from exactly two different 2-chains (each of which is the complement of the other). It follows from this that the set of bounded faces of the embedding forms a cycle basis for the planar graph: removing the unbounded face from this set of cycles reduces the number of ways each Eulerian subgraph can be generated from two to exactly one.\nMac Lane's planarity criterion, named after Saunders Mac Lane, characterizes planar graphs in terms of their cycle spaces and cycle bases. It states that a finite undirected graph is planar if and only if the graph has a cycle basis in which each edge of the graph participates in at most two basis cycles. In a planar graph, a cycle basis formed by the set of bounded faces of an embedding necessarily has this property: each edge participates only in the basis cycles for the two faces it separates. Conversely, if a cycle basis has at most two cycles per edge, then its cycles can be used as the set of bounded faces of a planar embedding of its graph.\nThe cycle space of a planar graph is the cut space of its dual graph, and vice versa.The minimum weight cycle basis for a planar graph is not necessarily the same as the basis formed by its bounded faces: it can include cycles that are not faces, and some faces may not be included as cycles in the minimum weight cycle basis. There exists a minimum weight cycle basis in which no two cycles cross each other: for every two cycles in the basis, either the cycles enclose disjoint subsets of the bounded faces, or one of the two cycles encloses the other one.  Following the duality between cycle spaces and cut spaces, this basis for a planar graph corresponds to a Gomory\u2013Hu tree of the dual graph, a minimum weight basis for its cut space.\nIn planar graphs, colorings with \n distinct colors are dual to nowhere zero flows over the ring \n. In this duality, the difference between the colors of two adjacent regions is represented by a flow value across the edge separating the regions. In particular, the existence of nowhere zero 4-flows is equivalent to the four color theorem. The snark theorem generalizes this result to nonplanar graphs.", "page_name": "Cycle space", "page_id": "Cycle%20space", "heading": "Planar graphs", "sub_heading": "Planar graphs", "_id": "2000016741--3---1---1", "title": "Planar Graphs \u2014 Part 1"}
{"qas": [{"question": "Why is it so hard for children with autism to grasp the concept of empathy?", "answer": ""}, {"question": "What cognitive structural theory addresses how adults conceive or understand the personhood of patients?", "answer": "Empathetic maturity", "ae_score": -0.2732257167916453, "qg_score": null}, {"question": "What is the most important characteristic of a child when it comes to empathy?", "answer": "belief", "ae_score": null, "qg_score": null}], "content": "By the age of two years, children normally begin to display the fundamental behaviors of empathy by having an emotional response that corresponds with another person's emotional state. Even earlier, at one year of age, infants have some rudiments of empathy, in the sense that they understand that, just like their own actions, other people's actions have goals. Sometimes, toddlers will comfort others or show concern for them at as early an age as two. Also during the second year, toddlers will play games of falsehood or \"pretend\" in an effort to fool others, and this requires that the child know what others believe before he or she can manipulate those beliefs.  In order to develop these traits, it is essential to expose your child to face-to-face interactions and opportunities and lead them away from a sedentary lifestyle.\nAccording to researchers at the University of Chicago who used functional magnetic resonance imaging (fMRI), children between the ages of 7 and 12 years appear to be naturally inclined to feel empathy for others in pain. Their findings are consistent with previous fMRI studies of pain empathy with adults. The research also found additional aspects of the brain were activated when youngsters saw another person intentionally hurt by another individual, including regions involved in moral reasoning.\nDespite being able to show some signs of empathy, including attempting to comfort a crying baby, from as early as 18 months to two years, most children do not show a fully fledged theory of mind until around the age of four. Theory of mind involves the ability to understand that other people may have beliefs that are different from one's own, and is thought to involve the cognitive component of empathy. Children usually become capable of passing \"false belief\" tasks, considered to be a test for a theory of mind, around the age of four. Individuals with autism often find using a theory of mind very difficult (e.g. Baron-Cohen, Leslie & Frith, 1988; the Sally-Anne test).\nEmpathetic maturity is a cognitive structural theory developed at the Yale University School of Nursing and addresses how adults conceive or understand the personhood of patients. The theory, first applied to nurses and since applied to other professions, postulates three levels that have the properties of cognitive structures. The third and highest level is held to be a meta-ethical theory of the moral structure of care. Those adults operating with level-III understanding synthesize systems of justice and care-based ethics.", "page_name": "Empathy", "page_id": "Empathy", "heading": "Development", "sub_heading": "Development", "_id": "2000017164--6---1---1", "title": "Empathy: The Cognitive Structures of Care"}
{"qas": [{"question": "Why do people with autism make eye contact with each other?", "answer": ""}, {"question": "What is the term for the inability to articulate emotional arousal in oneself or others?", "answer": "alexithymia", "ae_score": -0.39138236810487004, "qg_score": null}, {"question": "People with asperger syndrome may have problems understanding others' perspectives in terms of theory?", "answer": "mind autism", "ae_score": null, "qg_score": null}], "content": "The interaction between empathy and autism is a complex and ongoing field of research. Several different factors are proposed to be at play.\nA study of high-functioning adults with autism spectrum disorders found an increased prevalence of alexithymia, a personality construct characterized by the inability to recognize and articulate emotional arousal in oneself or others. Based on fMRI studies, alexithymia is responsible for a lack of empathy. The lack of empathic attunement inherent to alexithymic states may reduce quality and satisfaction of relationships. Recently, a study has shown that high-functioning adults with autism appear to have a range of responses to music similar to that of neurotypical individuals, including the deliberate use of music for mood management. Clinical treatment of alexithymia could involve using a simple associative learning process between musically induced emotions and their cognitive correlates. A study has suggested that the empathy deficits associated with the autism spectrum may be due to significant comorbidity between alexithymia and autism spectrum conditions rather than a result of social impairment.\nOne study found that, relative to typically developing children, high-functioning children with autism showed reduced mirror neuron activity in the brain's inferior frontal gyrus (pars opercularis) while imitating and observing emotional expressions. EEG evidence revealed that there was significantly greater mu suppression in the sensorimotor cortex of autistic individuals. Activity in this area was inversely related to symptom severity in the social domain, suggesting that a dysfunctional mirror neuron system may underlie social and communication deficits observed in autism, including impaired theory of mind and empathy. The mirror neuron system is essential for emotional empathy.\nPrevious studies have suggested that autistic individuals have an impaired theory of mind. Theory of mind is the ability to understand the perspectives of others. The terms cognitive empathy and theory of mind are often used synonymously, but due to a lack of studies comparing theory of mind with types of empathy, it is unclear whether these are equivalent. Theory of mind relies on structures of the temporal lobe and the pre-frontal cortex, and empathy, i.e. the ability to share the feelings of others, relies on the sensorimotor cortices as well as limbic and para-limbic structures. The lack of clear distinctions between theory of mind and empathy may have resulted in an incomplete understanding of the empathic abilities of those with Asperger syndrome; many reports on the empathic deficits of individuals with Asperger syndrome are actually based on impairments in theory of mind.\nStudies have found that individuals on the autism spectrum self-report lower levels of empathic concern, show less or absent comforting responses toward someone who is suffering, and report equal or higher levels of personal distress compared to controls, which may be a result of high egocentrism found in autistic individuals. The combination in those on the autism spectrum of reduced empathic concern and increased personal distress may lead to the overall reduction of empathy. Professor Simon Baron-Cohen suggests that those with classic autism often lack both cognitive and affective empathy. Research also suggests that people with Asperger syndrome may have problems understanding others' perspectives in terms of theory of mind, but the average person with the condition demonstrates equal empathic concern as, and higher personal distress, than controls. The existence of individuals with heightened personal distress on the autism spectrum has been offered as an explanation as to why at least some people with autism would appear to have heightened emotional empathy, although increased personal distress may be an effect of heightened egocentrism, emotional empathy depends on mirror neuron activity (which, as described previously, has been found to be reduced in those with autism), and empathy in people on the autism spectrum is generally reduced. The empathy deficits present in autism spectrum disorders may be more indicative of impairments in the ability to take the perspective of others, while the empathy deficits in psychopathy may be more indicative of impairments in responsiveness to others\u2019 emotions.These \u201cdisorders of empathy\u201d further highlight the importance of the ability to empathize by illustrating some of the consequences to disrupted empathy development.\nThe empathizing\u2013systemizing theory (E-S) suggests that people may be classified on the basis of their capabilities along two independent dimensions, empathizing (E) and systemizing (S). These capabilities may be inferred through tests that measure someone's Empathy Quotient (EQ) and Systemizing Quotient (SQ). Five different \"brain types\" can be observed among the population based on the scores, which should correlate with differences at the neural level. In the E-S theory, autism and Asperger syndrome are associated with below-average empathy and average or above-average systemizing. The E-S theory has been extended into the Extreme Male Brain theory, which suggests that people with an autism spectrum condition are more likely to have an \"Extreme Type S\" brain type, corresponding with above-average systemizing but challenged empathy.\nIt has been shown that males are generally less empathetic than females. The Extreme Male Brain (EMB) theory proposes that individuals on the autistic spectrum are characterized by impairments in empathy due to sex differences in the brain: specifically, people with autism spectrum conditions show an exaggerated male profile. A study showed that some aspects of autistic neuroanatomy seem to be extremes of typical male neuroanatomy, which may be influenced by elevated levels of fetal testosterone rather than gender itself. Another study involving brain scans of 120 men and women suggested that autism affects male and female brains differently; females with autism had brains that appeared to be closer to those of non-autistic males than females, yet the same kind of difference was not observed in males with autism.", "page_name": "Empathy", "page_id": "Empathy", "heading": "Atypical response", "sub_heading": "Atypical response", "_id": "2000017164--10--0---1", "title": "Emotional Empathy and Autism"}
{"qas": [{"question": "Why do people with psychopathic tendencies tend to be more sad than people with normal emotions?", "answer": ""}, {"question": "What personality disorder is characterized by a lack of empathy?", "answer": "Psychopathy", "ae_score": -0.30468053113129834, "qg_score": null}, {"question": "What type of deficits in psychopathy are pervasive across emotions?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Psychopathy is a personality disorder partly characterized by antisocial and aggressive behaviors, as well as emotional and interpersonal deficits including shallow emotions and a lack of remorse and empathy. The ''Diagnostic and Statistical Manual of Mental Disorders'' (DSM) and ''International Classification of Diseases'' (ICD) list antisocial personality disorder (ASPD) and dissocial personality disorder, stating that these have been referred to or include what is referred to as psychopathy.\nA large body of research suggests that psychopathy is associated with atypical responses to distress cues (e.g. facial and vocal expressions of fear and sadness), including decreased activation of the fusiform and extrastriate cortical regions, which may partly account for impaired recognition of and reduced autonomic responsiveness to expressions of fear, and impairments of empathy. Studies on children with psychopathic tendencies have also shown such associations. The underlying biological surfaces for processing expressions of happiness are functionally intact in psychopaths, although less responsive than those of controls. The neuroimaging literature is unclear as to whether deficits are specific to particular emotions such as fear. Some recent fMRI studies have reported that emotion perception deficits in psychopathy are pervasive across emotions (positives and negatives).\nA recent study on psychopaths found that, under certain circumstances, they could willfully empathize with others, and that their empathic reaction initiated the same way it does for controls. Psychopathic criminals were brain-scanned while watching videos of a person harming another individual. The psychopaths' empathic reaction initiated the same way it did for controls when they were instructed to empathize with the harmed individual, and the area of the brain relating to pain was activated when the psychopaths were asked to imagine how the harmed individual felt. The research suggests how psychopaths could switch empathy on at will, which would enable them to be both callous and charming. The team who conducted the study say it is still unknown how to transform this willful empathy into the spontaneous empathy most people have, though they propose it could be possible to bring psychopaths closer to rehabilitation by helping them to activate their \"empathy switch\". Others suggested that despite the results of the study, it remained unclear whether psychopaths' experience of empathy was the same as that of controls, and also questioned the possibility of devising therapeutic interventions that would make the empathic reactions more automatic.\nWork conducted by Professor Jean Decety with large samples of incarcerated psychopaths offers additional insights. In one study, psychopaths were scanned while viewing video clips depicting people being intentionally hurt. They were also tested on their responses to seeing short videos of facial expressions of pain. The participants in the high-psychopathy group exhibited significantly less activation in the ventromedial prefrontal cortex, amygdala and periaqueductal gray parts of the brain, but more activity in the striatum and the insula when compared to control participants. In a second study, individuals with psychopathy exhibited a strong response in pain-affective brain regions when taking an imagine-self perspective, but failed to recruit the neural circuits that were activated in controls during an imagine-other perspective\u2014in particular the ventromedial prefrontal cortex and amygdala\u2014which may contribute to their lack of empathic concern.\nIt was predicted that people who have high levels of psychopathy would have sufficient levels of cognitive empathy but would lack in their ability to use affective empathy. People that scored highly on psychopathy measures were less likely to portray affective empathy. There was a strong negative correlation showing that psychopathy and affective empathy are correspond strongly. The DANVA-2 portrayed those who scored highly on the psychopathy scale do not lack in recognising emotion in facial expressions. Therefore, individuals who have high scores on psychopathy and do not lack in perspective-talking ability but do lack in compassion and the negative incidents that happen to others.\nDespite studies suggesting deficits in emotion perception and imagining others in pain, professor Simon Baron-Cohen claims psychopathy is associated with intact cognitive empathy, which would imply an intact ability to read and respond to behaviors, social cues and what others are feeling. Psychopathy is, however, associated with impairment in the other major component of empathy\u2014affective (emotional) empathy\u2014which includes the ability to ''feel'' the suffering and emotions of others (what scientists would term as emotional contagion), and those with the condition are therefore not distressed by the suffering of their victims. Those with autism, on the other hand, are often impaired in both affective and cognitive empathy.", "page_name": "Empathy", "page_id": "Empathy", "heading": "Atypical response", "sub_heading": "Psychopathy", "_id": "2000017164--10--1---1", "title": "Psychopaths Could Switch Empathy On At Will"}
{"qas": [{"question": "Why is it that when I'm in pain, I feel like I'm being watched?", "answer": ""}, {"question": "What is the most common symptom of narcissistic personality disorder?", "answer": "lack of empathy", "ae_score": -0.31358777313743325, "qg_score": null}, {"question": "What is the most common symptom of narcissistic personality disorder?", "answer": "lack of empathy", "ae_score": -0.31358777313743325, "qg_score": null}], "content": "Research indicates atypical empathic responses are also correlated with a variety of other conditions.\nBorderline personality disorder is characterized by extensive behavioral and interpersonal difficulties that arise from emotional and cognitive dysfunction. Dysfunctional social and interpersonal behavior has been shown to play a crucial role in the emotionally intense way people with borderline personality disorder react.<ref name=Harari/> While individuals with borderline personality disorder may show their emotions too much, several authors have suggested that they might have a compromised ability to reflect upon mental states (impaired cognitive empathy), as well as an impaired theory of mind.<ref name=Harari/> People with borderline personality disorder have been shown to be very good at recognizing emotions in people's faces, suggesting increased empathic capacities. It is, therefore, possible that impaired cognitive empathy (the capacity for understanding another person's experience and perspective) may account for borderline personality disorder individuals' tendency for interpersonal dysfunction, while \"hyper-emotional empathy\" may account for the emotional over-reactivity observed in these individuals.<ref name=Harari/> One primary study confirmed that patients with borderline personality disorder were significantly impaired in cognitive empathy, yet there was no sign of impairment in affective empathy.\nOne diagnostic criterion of narcissistic personality disorder is a lack of empathy and an unwillingness or inability to recognize or identify with the feelings and needs of others.\nCharacteristics of schizoid personality disorder include emotional coldness, detachment, and impaired affect corresponding with an inability to be empathetic and sensitive towards others.\nA study conducted by Jean Decety and colleagues at the University of Chicago demonstrated that subjects with aggressive conduct disorder elicit atypical empathic responses to viewing others in pain. Subjects with conduct disorder were at least as responsive as controls to the pain of others but, unlike controls, subjects with conduct disorder showed strong and specific activation of the amygdala and ventral striatum (areas that enable a general arousing effect of reward), yet impaired activation of the neural regions involved in self-regulation and metacognition (including moral reasoning), in addition to diminished processing between the amygdala and the prefrontal cortex.\nSchizophrenia is characterized by impaired affective empathy, as well as severe cognitive and empathy impairments as measured by the Empathy Quotient (EQ). These empathy impairments are also associated with impairments in social cognitive tasks. \nBipolar individuals have been observed to have impaired cognitive empathy and theory of mind, but increased affective empathy. Despite cognitive flexibility being impaired, planning behavior is intact. It has been suggested that dysfunctions in the prefrontal cortex could result in the impaired cognitive empathy, since impaired cognitive empathy has been related with neurocognitive task performance involving cognitive flexibility.\nLieutenant Colonel Dave Grossman, in his book ''On Killing'', suggests that military training artificially creates depersonalization in soldiers, suppressing empathy and making it easier for them to kill other human beings.", "page_name": "Empathy", "page_id": "Empathy", "heading": "Atypical response", "sub_heading": "Other conditions", "_id": "2000017164--10--2---1", "title": "Borderline Personality Disorder"}
{"qas": [{"question": "How does the U.S. government provide billions of dollars to other countries during the financial crisis?", "answer": ""}, {"question": "Who was the professor of economics at princeton who blamed the rapid re-repack?", "answer": "Harold James", "ae_score": -0.257508756572244, "qg_score": null}, {"question": "The bundling of what type of mortgages led to the great recession?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "The term financial innovation refers to the ongoing development of financial products designed to achieve particular client objectives, such as offsetting a particular risk exposure (such as the default of a borrower) or to assist with obtaining financing. Examples pertinent to this crisis included: the adjustable-rate mortgage; the bundling of subprime mortgages into mortgage-backed securities (MBS) or collateralized debt obligations (CDO) for sale to investors, a type of securitization;  and a form of credit insurance called credit default swaps(CDS).  The usage of these products expanded dramatically in the years leading up to the crisis. These products vary in complexity and the ease with which they can be valued on the books of financial institutions.\nThe CDO in particular enabled financial institutions to obtain investor funds to finance subprime and other lending, extending or increasing the housing bubble and generating large fees. Approximately $1.6 trillion in CDO's were originated between 2003-2007. A CDO essentially places cash payments from multiple mortgages or other debt obligations into a single pool, from which the cash is allocated to specific securities in a priority sequence. Those securities obtaining cash first received investment-grade ratings from rating agencies. Lower priority securities received cash thereafter, with lower credit ratings but theoretically a higher rate of return on the amount invested. A sample of 735 CDO deals originated between 1999 and 2007 showed that subprime and other less-than-prime mortgages represented an increasing percentage of CDO assets, rising from 5% in 2000 to 36% in 2007.\nFor a variety of reasons, market participants did not accurately measure the risk inherent with this innovation or understand its impact on the overall stability of the financial system. For example, the pricing model for CDOs clearly did not reflect the level of risk they introduced into the system. The average recovery rate for \"high quality\" CDOs has been approximately 32 cents on the dollar, while the recovery rate for mezzanine CDO's has been approximately five cents for every dollar. These massive, practically unthinkable, losses have dramatically impacted the balance sheets of banks across the globe, leaving them with very little capital to continue operations.\nOthers have pointed out that there were not enough of these loans made to cause a crisis of this magnitude. In an article in Portfolio Magazine, Michael Lewis spoke with one trader who noted that \"There weren\u2019t enough Americans with [bad] credit taking out [bad loans] to satisfy investors\u2019 appetite for the end product.\" Essentially, investment banks and hedge funds used financial innovation to synthesize more loans using derivatives. \"They were creating [loans] out of whole cloth. One hundred times over! That\u2019s why the losses are so much greater than the loans.\"\nPrinceton professor Harold James wrote that one of the byproducts of this innovation was that MBS and other financial assets were \"repackaged so thoroughly and resold so often that it became impossible to clearly connect the thing being traded to its underlying value.\" He called this a \"...profound flaw at the core of the U.S. financial system...\"\nAnother example relates to AIG, which insured obligations of various financial institutions through the usage of credit default swaps. The basic CDS transaction involved AIG receiving a premium in exchange for a promise to pay money to party A in the event party B defaulted. However, AIG did not have the financial strength to support its many CDS commitments as the crisis progressed and was taken over by the government in September 2008. U.S. taxpayers provided over $180 billion in government support to AIG during 2008 and early 2009, through which the money flowed to various counterparties to CDS transactions, including many large global financial institutions.\nAuthor Michael Lewis wrote that CDS enabled speculators to stack bets on the same mortgage bonds and CDO's. This is analogous to allowing many persons to buy insurance on the same house. Speculators that bought CDS insurance were betting that significant defaults would occur, while the sellers (such as AIG) bet they would not.  In addition, Chicago Public Radio and the ''Huffington Post'' reported in April 2010 that market participants, including a hedge fund called Magnetar Capital, encouraged the creation of CDO's containing low quality mortgages, so they could bet against them using CDS. NPR reported that Magnetar encouraged investors to purchase CDO's while simultaneously betting against them, without disclosing the latter bet.", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Financial market factors", "_id": "2000019331--5--0---1", "title": "Financial Innovation and the Financial Crisis of the 2021"}
{"qas": [{"question": "Why did the U.S. go from a AAA rating to an A rating?", "answer": ""}, {"question": "How much of the mortgage-backed securities were under downgrade between q3 2007 and q?", "answer": "$1.9 trillion", "ae_score": -0.20322540432720948, "qg_score": null}, {"question": "What was the main source of revenue for rating agencies during the great recession?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "Credit rating agencies are under scrutiny for having given investment-grade ratings to MBSs based on risky subprime mortgage loans. These high ratings enabled these MBS to be sold to investors, thereby financing the housing boom. These ratings were believed justified because of risk reducing practices, such as credit default insurance and equity investors willing to bear the first losses. However, there are also indications that some involved in rating subprime-related securities knew at the time that the rating process was faulty.\nAn estimated $3.2 trillion in loans were made to homeowners with bad credit and undocumented incomes (e.g., subprime or Alt-A mortgages) between 2002 and 2007. Economist Joseph Stiglitz stated: \"I view the rating agencies as one of the key culprits...They were the party that performed the alchemy that converted the securities from F-rated to A-rated. The banks could not have done what they did without the complicity of the rating agencies.\" Without the AAA ratings, demand for these securities would have been considerably less. Bank writedowns and losses on these investments totaled $523 billion as of September 2008.\nThe ratings of these securities was a lucrative business for the rating agencies, accounting for just under half of Moody's total ratings revenue in 2007. Through 2007, ratings companies enjoyed record revenue, profits and share prices. The rating companies earned as much as three times more for grading these complex products than corporate bonds, their traditional business. Rating agencies also competed with each other to rate particular MBS and CDO securities issued by investment banks, which critics argued contributed to lower rating standards. Interviews with rating agency senior managers indicate the competitive pressure to rate the CDO's favorably was strong within the firms. This rating business was their \"golden goose\" (which laid the proverbial golden egg or wealth) in the words of one manager. Author Upton Sinclair (1878\u20131968) famously stated: \"It is difficult to get a man to understand something when his job depends on not understanding it.\" From 2000-2006, structured finance (which includes CDO's) accounted for 40% of the revenues of the credit rating agencies. During that time, one major rating agency had its stock increase six-fold and its earnings grew by 900%.\nCritics allege that the rating agencies suffered from conflicts of interest, as they were paid by investment banks and other firms that organize and sell structured securities to investors. On 11 June 2008, the SEC proposed rules designed to mitigate perceived conflicts of interest between rating agencies and issuers of structured securities. On 3 December 2008, the SEC approved measures to strengthen oversight of credit rating agencies, following a ten-month investigation that found \"significant weaknesses in ratings practices,\" including conflicts of interest.\nBetween Q3 2007 and Q2 2008, rating agencies lowered the credit ratings on $1.9 trillion in mortgage-backed securities. Financial institutions felt they had to lower the value of their MBS and acquire additional capital so as to maintain capital ratios. If this involved the sale of new shares of stock, the value of the existing shares was reduced. Thus ratings downgrades lowered the stock prices of many financial firms.", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Inaccurate credit ratings", "_id": "2000019331--5--1---1", "title": "Credit Rating Agencies and the Housing Boom"}
{"qas": [{"question": "What caused the collapse of the financial system?", "answer": ""}, {"question": "Who said the great recession was caused by synthetic money?", "answer": "George Soros", "ae_score": -0.49741768984998525, "qg_score": null}, {"question": "What was the cause of the great recession?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The limitations of many, widely used financial models also were not properly understood (see for example ). Li's Gaussian copula formula assumed that the price of CDS was correlated with and could predict the correct price of mortgage backed securities. Because it was highly tractable, it rapidly came to be used by a huge percentage of CDO and CDS investors, issuers, and rating agencies. According to one wired.com article: \"Then the model fell apart. Cracks started appearing early on, when financial markets began behaving in ways that users of Li's formula hadn't expected. The cracks became full-fledged canyons in 2008\u2014when ruptures in the financial system's foundation swallowed up trillions of dollars and put the survival of the global banking system in serious peril... Li's Gaussian copula formula will go down in history as instrumental in causing the unfathomable losses that brought the world financial system to its knees.\"\nAs financial assets became more complex, less transparent, and harder and harder to value, investors were reassured by the fact that both international bond rating agencies and bank regulators, who came to rely on them, accepted as valid some complex mathematical models that theoretically showed the risks were much smaller than they turned out to be.  George Soros commented that \"The super-boom got out of hand when the new products became so complicated that the authorities could no longer calculate the risks and started relying on the risk management methods of the banks themselves. Similarly, the rating agencies relied on the information provided by the originators of synthetic products. It was a shocking abdication of responsibility.\" ", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Lack of transparency and independence in financial modeling", "_id": "2000019331--5--2---1", "title": "Li's Gaussian Copula Formula and the Financial Crisis"}
{"qas": [{"question": "What happened to the banks during the financial crisis of 2008?", "answer": ""}, {"question": "Who was the author of the book the great recession?", "answer": "Robin Blackburn", "ae_score": -0.49871541379739476, "qg_score": null}, {"question": "What were the main causes of the great recession?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "Complex financing structures called structured investment vehicles (SIV) or conduits enabled banks to move significant amounts of assets and liabilities, including unsold CDO's, off their books.  This had the effect of helping the banks maintain regulatory minimum capital ratios. They were then able to lend anew, earning additional fees. Author Robin Blackburn explained how they worked:  Off balance sheet financing also made firms look less leveraged and enabled them to borrow at cheaper rates.\nBanks had established automatic lines of credit to these SIV and conduits. When the cash flow into the SIV's began to decline as subprime defaults mounted, banks were contractually obligated to provide cash to these structures and their investors. This \"conduit-related balance sheet pressure\" placed strain on the banks' ability to lend, both raising interbank lending rates and reducing the availability of funds.\nIn the years leading up to the crisis, the top four U.S. depository banks moved an estimated $5.2 trillion in assets and liabilities off-balance sheet into these SIV's and conduits. This enabled them to essentially bypass existing regulations regarding minimum capital ratios, thereby increasing leverage and profits during the boom but increasing losses during the crisis. Accounting guidance was changed in 2009 that will require them to put some of these assets back onto their books, which significantly reduces their capital ratios. One news agency estimated this amount at between $500 billion and $1 trillion. This effect was considered as part of the stress tests performed by the government during 2009.\nDuring March 2010, the bankruptcy court examiner released a report on Lehman Brothers, which had failed spectacularly in September 2008. The report indicated that up to $50 billion was moved off-balance sheet in a questionable manner by management during 2008, with the effect of making its debt level (leverage ratio) appear smaller. Analysis by the Federal Reserve Bank of New York indicated big banks mask their risk levels just prior to reporting data quarterly to the public.", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Off-balance-sheet financing", "_id": "2000019331--5--3---1", "title": "How Off Balance Sheet Financing Made Banks Look Less Leveraged"}
{"qas": [{"question": "Why are banks allowed to continue to operate even though they have been bailed out by the government?", "answer": ""}, {"question": "When did martin wolf write about the root causes of the great recession?", "answer": "June 2009", "ae_score": -0.6221169863669498, "qg_score": null}, {"question": "When did martin wolf write about the root causes of the great recession?", "answer": "June 2009", "ae_score": -0.6221169863669498, "qg_score": null}], "content": "Certain financial innovation may also have the effect of circumventing regulations, such as off-balance sheet financing that affects the leverage or capital cushion reported by major banks. For example, Martin Wolf wrote in June 2009: \"...an enormous part of what banks did in the early part of this decade \u2013 the off-balance-sheet vehicles, the derivatives and the 'shadow banking system' itself \u2013 was to find a way round regulation.\"", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Regulatory avoidance", "_id": "2000019331--5--4---1", "title": "Financial innovation may also have the effect of circumventing regulations."}
{"qas": [{"question": "Why is the mortgage securitization market so bad?", "answer": ""}, {"question": "Who said the financial sector became concentrated in the years leading up to the great recession?", "answer": "Niall Ferguson", "ae_score": -0.5152090596190851, "qg_score": null}, {"question": "What type of securitization was the cause of the great recession?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Niall Ferguson wrote that the financial sector became increasingly concentrated in the years leading up to the crisis, which made the stability of the financial system more reliant on just a few firms, which were also highly leveraged:\nBy contrast, some scholars have argued that fragmentation in the mortgage securitization market led to increased risk taking and a deterioration in underwriting standards.", "page_name": "Causes of the Great Recession", "page_id": "Causes%20of%20the%20Great%20Recession", "heading": "Financial market factors", "sub_heading": "Financial sector concentration", "_id": "2000019331--5--5---1", "title": "The Crisis of the Financial Sector"}
{"qas": [{"question": "Why do we treat animals with the same respect as humans?", "answer": ""}, {"question": "Who is known as the father of biocentric egalitarianism?", "answer": "Paul Taylor", "ae_score": -0.20516553797160877, "qg_score": null}, {"question": "Who is known as the father of biocentric egalitarianism?", "answer": "Paul Taylor", "ae_score": -0.20516553797160877, "qg_score": null}], "content": "Biocentric ethics differs from classical and traditional ethical thinking. Rather than focusing on strict moral rules, as in Classical ethics, it focuses on attitudes and character. In contrast with traditional ethics, it is nonhierarchical and gives priority to the natural world rather than to humankind exclusively. \nBiocentric ethics includes Albert Schweitzer\u2019s ethics of \"Reverence for Life\", Peter Singer\u2019s ethics of Animal Liberation and Paul Taylor (philosopher)\u2019s ethics of biocentric egalitarianism. \nAlbert Schweitzer's \u201creverence for life\u201d principle was a precursor of modern biocentric ethics. In contrast with traditional ethics, the ethics of \"reverence for life\" denies any distinction between \"high and low\" or \"valuable and less valuable\" life forms, dismissing such categorization as arbitrary and subjective. Conventional ethics concerned itself exclusively with human beings - that is to say, morality applied only to interpersonal relationships - whereas Schweitzer\u2019s ethical philosophy introduced a \u201cdepth, energy, and function that differ[s] from the ethics that merely involved humans.\u201d \"Reverence for life\" was a \"new ethics, because it is not only an extension of ethics, but also a transformation of the nature of ethics.\" \nSimilarly, Peter Singer argues that non-human animals deserve the same equality of consideration that we extend to human beings.   His argument is roughly as follows:\nBiocentrism is most commonly associated with the work of Paul Taylor, especially his book ''Respect for Nature: A Theory of Environmental Ethics'' (1986). Taylor maintains that biocentrism is an \"attitude of respect for nature\", whereby one attempts to make an effort to live one's life in a way that respects the welfare and inherent worth of all living creatures. Taylor states that:\nHistorian Donald Worster traces today's biocentric philosophies, which he sees as part of a recovery of a sense of kinship between man and nature, to the reaction by the British intelligencia of the Victorian era against the Christian ethic of dominion over nature. He has pointed to Charles Darwin as an important spokesman for the biocentric view in ecological thought and quotes from Darwin's ''Notebook on Transmutation of Species'' (1837)  \nIn 1859, Charles Darwin published his book ''On the Origin of Species''. This publication sparked the beginning of biocentrist views by introducing evolution and \"its removal of humans from their supernatural origins andplacement into the framework of natural laws\" \nThe work of Aldo Leopold has also been associated with biocentrism. The essay ''The Land Ethic'' in Leopold's book Sand County Almanac (1949) points out that although throughout history women and slaves have been considered property, all people have now been granted rights and freedoms.  Leopold notes that today land is still considered property as people once were. He asserts that ethics should be extended to the land as \"an evolutionary possibility and an ecological necessity\". He argues that while people's instincts encourage them to compete with others, their ethics encourage them to co-operate with others.  He suggests that \"the land ethic simply enlarges the boundaries of the community to include soils, waters, plants, and animals, or collectively: the land\". In a sense this attitude would encourage humans to co-operate with the land rather than compete with it.\nOutside of formal philosophical works biocentric thought is common among pre-colonial tribal peoples who knew no world other than the natural world.", "page_name": "Biocentrism (ethics)", "page_id": "Biocentrism%20(ethics)", "heading": "History and development", "sub_heading": "History and development", "_id": "2000026006--2---1---1", "title": "Biocentrism and the Evolution of Morality"}
{"qas": [{"question": "Why is it that when I'm in the shower I feel like I need to pee, but when I go to bed I don't?", "answer": ""}, {"question": "How to test linear independence in vector space?", "answer": "Gaussian elimination", "ae_score": -0.6242278205254991, "qg_score": null}, {"question": "How to test linear independence in vector space?", "answer": "Gaussian elimination", "ae_score": -0.6242278205254991, "qg_score": null}], "content": "In any vector space, and more generally in any matroid, a minimum weight basis may be found by a greedy algorithm that considers potential basis elements one at a time, in sorted order by their weights, and that includes an element in the basis when it is linearly independent of the previously chosen basis elements. Testing for linear independence can be done by Gaussian elimination. However, an undirected graph may have an exponentially large set of simple cycles, so it would be computationally infeasible to generate and test all such cycles. \n provided the first polynomial time algorithm for finding a minimum weight basis, in graphs for which every edge weight is positive. His algorithm uses this generate-and-test approach, but restricts the generated cycles to a small set of \n cycles, called ''Horton cycles''.  A Horton cycle is a fundamental cycle of a shortest path tree of the given graph. There are ''n'' different shortest path trees (one for each starting vertex) and each has fewer than ''m'' fundamental cycles, giving the bound on the total number of Horton cycles. As Horton showed, every cycle in the minimum weight cycle basis is a Horton cycle. Using Dijkstra's algorithm to find each shortest path tree and then using Gaussian elimination to perform the testing steps of the greedy basis algorithm leads to a polynomial time algorithm for the minimum weight cycle basis.Subsequent researchers have developed improved algorithms for this problem, reducing the worst-case time complexity for finding a minimum weight cycle basis in a graph with \n edges and \n vertices to \n.", "page_name": "Cycle basis", "page_id": "Cycle%20basis", "heading": "Minimum weight", "sub_heading": "Minimum weight", "_id": "2000026466--2--0---1", "title": "Finding a minimum weight cycle basis in a graph with edges and vertices"}
{"qas": [{"question": "Why is it NP-hard to find a minimum possible weight?", "answer": ""}, {"question": "The minimum weight cycle basis of a graph is?", "answer": "Hamiltonian", "ae_score": null, "qg_score": null}, {"question": "The minimum weight cycle basis of a graph is?", "answer": "Hamiltonian", "ae_score": null, "qg_score": null}], "content": "Finding the fundamental basis with the minimum possible weight is closely related to the problem of finding a spanning tree that minimizes the average of the pairwise distances; both are NP-hard. Finding a minimum weight weakly fundamental basis is also NP-hard, and approximating it is MAXSNP-hard. If negative weights and negatively weighted cycles are allowed, then finding a minimum cycle basis (without restriction) is also NP-hard, as it can be used to find a Hamiltonian cycle: if a graph is Hamiltonian, and all edges are given weight \u22121, then a minimum weight cycle basis necessarily includes at least one Hamiltonian cycle.", "page_name": "Cycle basis", "page_id": "Cycle%20basis", "heading": "Minimum weight", "sub_heading": "NP-hardness", "_id": "2000026466--2--1---1", "title": "Finding a minimum weight fundamental basis is NP-hard, and approximating it"}
{"qas": [{"question": "Why is it that when I'm in the shower I feel like I need to pee, but when I go to bed I don't?", "answer": ""}, {"question": "The minimum weight cycle basis of a planar graph has how many cycles?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "The minimum weight cycle basis of a planar graph has how many cycles?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "The minimum weight cycle basis for a planar graph is not necessarily the same as the basis formed by its bounded faces: it can include cycles that are not faces, and some faces may not be included as cycles in the minimum weight cycle basis. However, there exists a minimum weight cycle basis in which no two cycles cross each other: for every two cycles in the basis, either the cycles enclose disjoint subsets of the bounded faces, or one of the two cycles encloses the other one. This set of cycles corresponds, in the dual graph of the given planar graph, to a set of cuts that form a Gomory\u2013Hu tree of the dual graph, the minimum weight basis of its cut space. Based on this duality, an implicit representation of the minimum weight cycle basis in a planar graph can be constructed in time \n.", "page_name": "Cycle basis", "page_id": "Cycle%20basis", "heading": "Minimum weight", "sub_heading": "In planar graphs", "_id": "2000026466--2--2---1", "title": "Minimum Weight Cycle Basis in Planar Graphs"}
{"qas": [{"question": "Why is it that in mice, the cochlear ducts are shortened, but in humans, they are not?", "answer": ""}, {"question": "Where are vestibular hair cells found in the body?", "answer": "Kolliker's organ", "ae_score": -1.0455942950771773, "qg_score": null}, {"question": "What does the lack of cjc and jjc mutations cause?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "In the mouse, the truncating mutations ''jc'' and ''jc'' lead to profound hearing loss and erratic circling behavior.  Specifically, the cochlear duct is shortened,  the organ of Corti exhibits supernumerary outer hair cells, mirror image duplications of tunnel of Corti and inner hair cells, as well as ectopic expression of patches of vestibular-like hair cells in Kolliker's organ.   The vestibular end organs have a smaller surface area and are thicker.", "page_name": "Sobp", "page_id": "Sobp", "heading": "Phenotypes", "sub_heading": "Phenotypes", "_id": "2000032071--3---1---1", "title": "''Jc'' and ''jc'' in the mouse"}
{"qas": [{"question": "Why do we lose hearing when we grow up?", "answer": ""}, {"question": "What mutation causes bilateral sensorineural hearing loss?", "answer": "p.W301X missense mutation", "ae_score": -0.8640361912677789, "qg_score": null}, {"question": "What type of hearing loss do mice of the black swiss strain develop?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Mice of the Black Swiss strain develop early-onset slowly progressing sensorineural hearing loss.  A genetic study identified two quantitative trait loci (QTL) that control hearing function.   One QTL, named age-related hearing loss 5 (''ahl5'') localizes to chromosome 10 and accounted for ca. 60% of the variation in hearing thresholds.  A second QTL, ''ahl6'', localized to chromosome 18 and has a smaller effect size.  Besides their hearing impairment, Black Swiss mice also are hypersensitive to acoustic stimulation, reacting with seizures (audiogenic seizures) to loud white noise.  A genetic locus conferring susceptibility was identified (juvenile audiogenic monogenic seizures1, ''jams1'') on chromosome 10.  A positional cloning approach aimed to decipher the genetic basis of both the hearing loss and audiogenic seizure susceptibility subsequently identified the glycine to arginine substitution in Gipc3 as the underlying cause.\nIn humans, individuals with the p.W301X missense mutation (DFNB95) exhibit bilateral sensorineural hearing loss with threshold shifts of 70-80 dB hearing levels as early as 11 months of age.", "page_name": "GIPC3", "page_id": "GIPC3", "heading": "Phenotypes", "sub_heading": "Phenotypes", "_id": "2000032282--3---1---1", "title": "Black Swiss Mice Develop Early-onset Slowly Progressing Sensorineural Hearing Loss with"}
{"qas": [{"question": "Ethical pragmatism?", "answer": ""}, {"question": "How does pragmatism differ from other approaches?", "answer": "theoretically", "ae_score": -0.515326133389095, "qg_score": null}, {"question": "Pragmatic ethics is an example of what type of ethics?", "answer": "normative ethics", "ae_score": null, "qg_score": null}], "content": "Much as it is appropriate for scientists to act as though a hypothesis were true despite expecting future inquiry to supplant it, ethical pragmatists acknowledge that it can be appropriate to practice a variety of other normative approaches (e.g. consequentialism, deontological ethics, and virtue ethics), yet acknowledge the need for mechanisms which allow society to advance beyond such approaches, a freedom for discourse which does not take any such theory as assumed. Thus, aimed at social innovation, the ''practice'' of pragmatic ethics supplements the practice of other normative approaches with what John Stuart Mill called \"experiments of living\".\nPragmatic ethics also differs from other normative approaches ''theoretically'', according to :", "page_name": "Pragmatic ethics", "page_id": "Pragmatic%20ethics", "heading": "Contrast with other normative theories", "sub_heading": "Contrast with other normative theories", "_id": "2000033264--0---1---1", "title": "Pragmatic Ethics \u2014 Towards Social Innovation and Innovation"}
{"qas": [{"question": "What is pragmatic ethics?", "answer": ""}, {"question": "The theory of pragmatic ethics that deals with the way people make moral judgments is called?", "answer": "Pragmatic ethics", "ae_score": -0.667892120429121, "qg_score": null}, {"question": "Pragmatic ethics is contrasted with what type of ethics?", "answer": "descriptive ethics", "ae_score": null, "qg_score": null}], "content": "Pragmatic ethics has been criticized as conflating descriptive ethics  with normative ethics, as describing the way people ''do'' make moral judgments rather than the way they ''should'' make them. While some ethical pragmatists may have questioned the distinction between normative and descriptive truth, the theory of pragmatic ethics itself does not conflate them any more than science conflates truth about its subject matter with current opinion about it.<ref name=Liszka/>", "page_name": "Pragmatic ethics", "page_id": "Pragmatic%20ethics", "heading": "Criticisms", "sub_heading": "Criticisms", "_id": "2000033264--2---1---1", "title": "Pragmatic Ethics \u2014 The Theory of Pragmatic Ethics"}
{"qas": [{"question": "What is titanium disulfide and why is it better than all-solid state batteries?", "answer": ""}, {"question": "Who discovered the use of titanium disulfide in rechargeable batteries?", "answer": "M. Stanley Whittingham", "ae_score": -0.3696208158924145, "qg_score": null}, {"question": "What property does titanium disulfide have in a solid state battery?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "The promise of titanium disulfide as a cathode material in rechargeable batteries was described in 1973 by M. Stanley Whittingham. The Group IV and V dichalcogenides attracted attention for their high electrical conductivities. The originally described battery used a lithium anode and a titanium disulfide cathode. This battery had high energy density and the diffusion of lithium ions into the titanium disulfide cathode was reversible, making the battery rechargeable. Titanium disulfide was chosen because it is the lightest and cheapest chalcogenide. Titanium disulfide also has the fastest rate of lithium ion diffusion into the crystal lattice.  The main problem was degradation of the cathode after multiple recycles.  This reversible intercalation process allows the battery to be rechargeable. Additionally, titanium disulfide is the lightest and the cheapest of all group IV and V layered dichalcogenides. In the 1990s, titanium disulfide was replaced by other cathode materials (manganese and cobalt oxides) in most rechargeable batteries.\nThe use of TiS cathodes remains of interest for use in solid-state lithium batteries, e.g., for hybrid electric vehicles and plug-in electric vehicles.\nIn contrast to the all-solid state batteries, most lithium batteries employ liquid electrolytes, which pose safety issues due to their flammability.  Many different solid electrolytes have been proposed to replace these hazardous liquid electrolytes. For most solid-state batteries, high interfacial resistance lowers the reversibility of the intercalation process, shortening the life cycle.  These undesirable interfacial effects are less problematic for TiS.  One all-solid-state lithium battery exhibited a power density of 1000 W/kg over 50 cycles with a maximum power density of 1500 W/kg.  Additionally, the average capacity of the battery decreased by less than 10% over 50 cycles. Although titanium disulfide has high electrical conductivity, high energy density, and high power, its discharge voltage is relatively low compared to other lithium batteries where the cathodes have higher reduction potentials.", "page_name": "Titanium disulfide", "page_id": "Titanium%20disulfide", "heading": "Applications", "sub_heading": "Applications", "_id": "2000033874--3---1---1", "title": "Titanium Disulfide as a Cathode Material in Lithium Batterie"}
{"qas": [{"question": "Why is it that people who suffer from low attention control tend to be more likely to suffer from mental illnesses?", "answer": ""}, {"question": "Why are executive functions disrupted across many different disorder groups?", "answer": "poorly understood", "ae_score": -0.4200023154347168, "qg_score": null}, {"question": "A person who has low attentional control is known as?", "answer": "hyperactivity", "ae_score": null, "qg_score": null}], "content": "Disrupted attentional control have been noted not just in the early development of conditions for which the core deficit is related to attention such as ADHD, but also in conditions such as autism and anxiety. Disrupted attentional control has also been reported in infants born preterm, as well as in infants with genetic disorders such as Down syndrome and Williams syndrome. Several groups have also reported impaired attentional control early in development in children from lower socioeconomic status families.\nThe patterns of disrupted attentional control relate to findings of disrupted performance on executive functions tasks such as working memory across a wide number of different disorder groups. The question of why the executive functions appear to be disrupted across so many different disorder groups remains, however, poorly understood.\nStudies have shown that there is a high probability that those who suffer from low attentional control also experience other mental conditions. Low attentional control is more common among those with attention deficit hyperactivity disorder (ADHD),\"a disorder with persistent age-inappropriate symptoms of inattention, hyperactivity, and impulsivity that are sufficient to cause impairment in major life activities\". Also low attentional control is common in individuals with Schizophrenia and  Alzheimer's disease, those with social anxiety, trait anxiety, and depression, and attention difficulties following a stroke. Individuals also respond quicker, and have better overall executive control when they have low levels of anxiety and depression.  Low levels of attentional control are also thought to increase chances of developing a psychopathology because the ability to shift one\u2019s focus away from threat information is important in processing emotions.  More researchers are also accounting for attentional control in studies that might not necessarily focus on attention by having participants fill out an Attentional Control Scale (ACS) or a Cognitive Attentional Syndrome-1 (CAS1), both of which are self-reporting questionnaires measuring attention focusing and attention shifting. Researchers are also suggesting others in the field use experimental and longitudinal designs to address the relationship between ACS, emotional functioning, CAS, and attention to threat. This is due to the increasing problematic occurrences experts are seeing in the field regarding attentional control in relation to other mental illnesses.\nAttention problems are also characteristic of anxiety disorders like PTSD. Attentional bias causes a person to processes emotionally negative information preferentially over emotionally positive information. Participants were selected after being measured on scales for PTSD, anxiety proneness, attentional control, and attentional bias. Results indicated attentional control was inversely related to attentional bias. PTSD patients with higher attentional control exhibited less attentional bias. Individual differences in attentional control had an effect on anxiety problems in PTSD.", "page_name": "Attentional control", "page_id": "Attentional%20control", "heading": "Abnormal development", "sub_heading": "Abnormal development", "_id": "2000034059--2---1---1", "title": "Attentional Control and Anxiety Disorders"}
{"qas": [{"question": "Why do we lose our eyesight as we get older?", "answer": ""}, {"question": "When does blindness begin in the eyes?", "answer": "infancy", "ae_score": -0.4749375753936744, "qg_score": null}, {"question": "What is the most common cause of childhood blindness?", "answer": "Leber\u2019s congenital amaurosis", "ae_score": null, "qg_score": null}], "content": "Childhood blindness has many causes, and each cause has its own method of damaging the eyes. Leber congenital amaurosis primarily affects the retina, typically severe visual impairment begins in infancy. Mutations in Aryl hydrocarbon receptor interacting protein like-1 have been linked to Leber congenital amaurosis (LCA).", "page_name": "Childhood blindness", "page_id": "Childhood%20blindness", "heading": "Mechanism", "sub_heading": "Mechanism", "_id": "2000037035--1---1---1", "title": "Leber congenital amaurosis (LCA)"}
{"qas": [{"question": "What exactly is Stephen Hawking trying to accomplish?", "answer": ""}, {"question": "Who does carlos osuna live with at his age?", "answer": "his fathers", "ae_score": -0.1003619175280724, "qg_score": null}, {"question": "Who does carlos osuna live with at his age?", "answer": "his fathers", "ae_score": -0.1003619175280724, "qg_score": null}], "content": "Carlos is a practicing Jew close to his community. He loves baseball and American Football. In 1994, he made his reglementary social service before graduation at the Museum of Contemporary Art (MARCO) where he was tasked on finding works of art from a particular artist, scatters throughout the world.  He also worked that same year, and the year before on the local newspaper El Norte where he published several editorials regarding life and youth, which were published on a special supplement for youngsters.\nHe has worked in several inclusion initiatives specially for people with Autism and Asperger syndrome helping others understand the complexities of the mind of children inside the Autism spectrum.  As a computer programmer and a specialist in computer science, he knows the connections and touch points between computer communications and human interaction.  His goal is to one day resolve the Autism Question by using computer models simulating this interaction.  He also wants to someday specialize in Bioinformatics so as to use help research '''in silicio''' that will create new DNA molecules which could later be tested ''in vitro'', thus speeding the process of genetic manipulation.\nHe currently lives with his fathers caring for them at their old age.", "page_name": "Carlos Osuna", "page_id": "Carlos%20Osuna", "heading": "Personal life", "sub_heading": "Personal life", "_id": "2000040364--4---1---1", "title": "Carlos is a computer programmer and a specialist in Bioinformatics"}
{"qas": [{"question": "What caused the outsourcing of jobs in the 1990s?", "answer": ""}, {"question": "When did the g20 replace the g8 as the main economic council?", "answer": "2009", "ae_score": -0.6300130424348266, "qg_score": null}, {"question": "When did the g20 replace the g8 as the main economic council?", "answer": "2009", "ae_score": -0.6300130424348266, "qg_score": null}], "content": "The removal of trade and investment barriers, the growth of domestic markets, artificially low currencies, the proliferation of education, the rapid development of high tech and information systems industries and the growth of the world economy lead to a significant growth of offshore outsourcing during the decade as many multinational corporations significantly increased subcontracting of manufacturing (and increasingly, services) across national boundaries in developing countries and particularly in China and India, due to many benefits and mainly because the two countries which are the two most populous countries in the world provide huge pools from which to find talent and as because both countries are low cost sourcing countries. As a result of this growth, many of these developing countries accumulated capital and started investing abroad. Other countries, including the United Arab Emirates, Australia, Brazil and Russia, benefited from increased demand for their mineral and energy resources that global growth generated. The hollowing out of manufacturing was felt in Japan and parts of the United States and Europe which had not been able to develop successful innovative industries. Opponents point out that the practice of offshore outsourcing by countries with higher wages leads to the reduction of their own domestic employment and domestic investment. As a result, many customer service jobs as well as jobs in the information technology sectors (data processing, computer programming, and technical support) in countries such as the United States and the United Kingdom have been or are potentially affected.\nWhile global trade rose in the decade (partially driven by China's entry into the WTO in 2001), there was little progress in the multilateral trading system. International trade continued to expand during the decade as emerging economies and developing countries, in particular China and South-Asian countries, benefited low wages costs and most often undervalued currencies. However, global negotiations to reduce tariffs did not make any progress, as member countries of the World Trade Organization did not succeed in finding agreements to stretch the extent of free trade. The Doha Round of negotiations, launched in 2001 by the WTO to promote development, failed to be completed because of growing tensions between regional areas. Nor did the Canc\u00fan Conference in 2003 find a consensus on services trade and agricultural subsidies.\nThe comparative rise of China, India, and other developing countries also contributed to their growing clout in international fora. In 2009, it was determined that the G20, originally a forum of finance ministers and central bank governors, would replace the G8 as the main economic council.\n'''2007 Chinese export recalls'''In 2007 a series of product recalls and import bans were imposed by the product safety institutions of the United States, Canada, the European Union, Australia and New Zealand against products manufactured in and exported from the mainland of the People's Republic of China (PRC) because of numerous alleged consumer safety issues.\nEvents in the confidence crisis included recalls on consumer goods such as pet food, toys, toothpaste and lipstick, and a ban on certain types of seafood. Also included are reports on the poor crash safety of Chinese automobiles, slated to enter the American and European markets in 2008. This created adverse consequences for the confidence in the safety and quality of mainland Chinese manufactured goods in the global economy.", "page_name": "2000s (decade)", "page_id": "2000s%20(decade)", "heading": "Economics", "sub_heading": "Globalization and its discontents", "_id": "2000049240--4--1---1", "title": "'''Decennial of the Global Economy''''"}
{"qas": [{"question": "What is the meaning of the phrase \"the new world order has been created\"?", "answer": ""}, {"question": "Who was chancellor of the exchequer in 2007?", "answer": "Gordon Brown", "ae_score": -0.20487868505679513, "qg_score": null}, {"question": "The global financial crisis was caused by the securitization of what type of mortgages?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "The decade was marked by two financial and economic crises. In 2000, the Dot-com bubble burst, causing turmoil in financial markets and a decline in economic activity in the developed economies, in particular in the United States. However, the impact of the crisis on the activity was limited thanks to the intervention of the central banks, notably the U.S. Federal Reserve System. Indeed, Alan Greenspan, leader of the Federal Reserve until 2006, cut the interest rates several times to avoid a severe recession, allowing an economic revival in the U.S.\nAs the Federal Reserve maintained low interest rates to favor economic growth, a housing bubble began to appear in the United States. In 2007, the rise in interest rates and the collapse of the housing market caused a wave of loan payment failures in the U.S. The subsequent mortgage crisis caused a global financial crisis, because the subprime mortgages had been securitized and sold to international banks and investment funds. Despite the extensive intervention of central banks, including partial and total nationalization of major European banks, the crisis of sovereign debt became particularly acute, first in Iceland, though as events of the early 2010s would show, it was not an isolated European example. Economic activity was severely affected around the world in 2008 and 2009, with disastrous consequences for carmakers.\nIn 2007, the UK's Chancellor of the Exchequer Gordon Brown, delivered his final Mansion House speech as Chancellor before he moved into Number 10. Addressing financiers: \"A new world order has been created\", Everyone needed to follow the City's \"great example\", \"an era that history will record as the beginning of a new Golden Age\".\nReactions of governments in all developed and developing countries against the economic slowdown were largely inspired by keynesian economics. The end of the decade was characterized by a Keynesian resurgence, while the influence and media popularity of left-wing economists Joseph Stiglitz and Paul Krugman (Nobel Prize recipients in 2001 and 2008, respectively) did not stop growing during the decade. Several international summits were organized to find solutions against the economic crisis and to impose greater control on the financial markets. The G-20 became in 2008 and 2009 a major organization, as leaders of the member countries held two major summits in Washington in November 2008 and in London in April 2009 to regulate the banking and financial sectors, and also succeeding in coordinating their economic action and in avoiding protectionist reactions.", "page_name": "2000s (decade)", "page_id": "2000s%20(decade)", "heading": "Economics", "sub_heading": "The age of turbulence", "_id": "2000049240--4--2---1", "title": "Keynesian economics and the G-20"}
{"qas": [{"question": "Why did the price of crude oil go up so much in the 1980s?", "answer": ""}, {"question": "Where was the fastest growing economy in the world in the 2000s?", "answer": "Asia", "ae_score": -0.6677191970573911, "qg_score": null}, {"question": "Where was the fastest growing economy in the world in the 2000s?", "answer": "Asia", "ae_score": -0.6677191970573911, "qg_score": null}], "content": "From the mid-1980s to September 2003, the inflation-adjusted price of a barrel of crude oil on NYMEX was generally under $25/barrel. During 2003, the price rose above $30, reached $60 by August 11, 2005, and peaked at $147.30 in July 2008. Commentators attributed these price increases to many factors, including reports from the United States Department of Energy and others showing a decline in petroleum reserves, worries over peak oil, Middle East tension, and oil price speculation.\nFor a time, geopolitical events and natural disasters indirectly related to the global oil market had strong short-term effects on oil prices. These events and disasters included North Korean missile tests, the 2006 conflict between Israel and Lebanon, worries over Iranian nuclear plants in 2006 and Hurricane Katrina. By 2008, such pressures appeared to have an insignificant impact on oil prices given the onset of the global recession. The recession caused demand for energy to shrink in late 2008 and early 2009 and the price plunged as well. However, it surged back in May 2009, bringing it back to November 2008 levels.\nMany fast-growing economies throughout the world, especially in Asia, also were a major factor in the rapidly increasing demand for fossil fuels, which\u2014along with fewer new petroleum finds, greater extraction costs, and political turmoil\u2014forced two other trends: a soar in the price of petroleum products and a push by governments and businesses to promote the development of environmentally friendly technology (known informally as \"green\" technology). However, a side-effect of the push by some industrial nations to \"go green\" and utilize biofuels was a decrease in the supply of food and a subsequent increase in the price of the same. It partially caused the 2007 food price crisis, which seriously affected the world's poorer nations with an even more severe shortage of food.", "page_name": "2000s (decade)", "page_id": "2000s%20(decade)", "heading": "Economics", "sub_heading": "Energy crisis", "_id": "2000049240--4--3---1", "title": "The Global Oil Price Crisis: A Brief History"}
{"qas": [{"question": "How did the euro become the world's largest reserve currency?", "answer": ""}, {"question": "What is the most traded currency in the world?", "answer": "US$", "ae_score": -0.45797258017310183, "qg_score": null}, {"question": "What is the most traded currency in the world?", "answer": "US$", "ae_score": -0.45797258017310183, "qg_score": null}], "content": "A common currency for most E.U.member states, the euro, was established electronically in 1999, officially tying all the currencies of each participating nation to each other. The new currency was put into circulation in 2002 and the old currencies were phased out. Only three countries of the then 15 member states decided not to join the euro (The United Kingdom, Denmark and Sweden). In 2004 the E.U.undertook a major eastward enlargement, admitting 10 new member states (eight of which were former communist states). Two more, Bulgaria and Romania, joined in 2007, establishing a union of 27 nations.\nThe euro has since become the second largest reserve currency and the second most traded currency in the world after the US$.As of 10 2009, with more than \u20ac790 billion in circulation, the euro was the currency with the highest combined value of banknotes and coins in circulation in the world, having surpassed the US$.", "page_name": "2000s (decade)", "page_id": "2000s%20(decade)", "heading": "Economics", "sub_heading": "The rise of the euro", "_id": "2000049240--4--4---1", "title": "The E.U. is the second largest reserve currency in the world after the US$."}
{"qas": [{"question": "Why is there a gap between high tide and low tide?", "answer": ""}, {"question": "What causes rocks to press down on deeper rocks?", "answer": "Gravitational forces", "ae_score": -0.7192693373339929, "qg_score": null}, {"question": "What causes rocks to press down on deeper rocks?", "answer": "Gravitational forces", "ae_score": -0.7192693373339929, "qg_score": null}], "content": "The gravitational pull of the Moon and Sun give rise to two high tides and two low tides every lunar day, or every 24 hours and 50 minutes. Therefore, there is a gap of 12 hours and 25 minutes between every high tide and between every low tide.\nGravitational forces make rocks press down on deeper rocks, increasing their density as the depth increases. Measurements of gravitational acceleration and gravitational potential at the Earth's surface and above it can be used to look for mineral deposits (see gravity anomaly and gravimetry).<ref name=Telford/> The surface gravitational field provides information on the dynamics of tectonic plates. The geopotential surface called the geoid is one definition of the shape of the Earth. The geoid would be the global mean sea level if the oceans were in equilibrium and could be extended through the continents (such as with very narrow canals).<ref name=Lowrie/>", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Physical phenomena", "_id": "2000049689--0--0---1", "title": "Gravitational Fields and Gravitational Potential"}
{"qas": [{"question": "Where does the heat come from?", "answer": ""}, {"question": "How many thermal boundary layers are there on the earth?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many thermal boundary layers are there on the earth?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "The Earth is cooling, and the resulting heat flow generates the Earth's magnetic field through the geodynamo and plate tectonics through mantle convection. The main sources of heat are the primordial heat and radioactivity, although there are also contributions from phase transitions. Heat is mostly carried to the surface by thermal convection, although there are two thermal boundary layers \u2013 the core-mantle boundary and the lithosphere \u2013 in which heat is transported by conduction. Some heat is carried up from the bottom of the mantle by mantle plumes. The heat flow at the Earth's surface is about , and it is a potential source of geothermal energy.", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Heat flow", "_id": "2000049689--0--1---1", "title": "Geothermal Energy \u2014 Earth's Surface"}
{"qas": [{"question": "How do we know how deep the Earth is?", "answer": ""}, {"question": "Changes in the travel direction of seismic waves are called what?", "answer": "refraction", "ae_score": -0.26622889881216627, "qg_score": null}, {"question": "Changes in the travel direction of seismic waves are called what?", "answer": "refraction", "ae_score": -0.26622889881216627, "qg_score": null}], "content": "Seismic waves are vibrations that travel through the Earth's interior or along its surface. The entire Earth can also oscillate in forms that are called normal modes or free oscillations of the Earth. Ground motions from waves or normal modes are measured using seismographs. If the waves come from a localized source such as an earthquake or explosion, measurements at more than one location can be used to locate the source. The locations of earthquakes provide information on plate tectonics and mantle convection.\nMeasurements of seismic waves are a source of information on the region that the waves travel through. If the density or composition of the rock changes suddenly, some waves are reflected. Reflections can provide information on near-surface structure. Changes in the travel direction, called refraction, can be used to infer the deep structure of the Earth.<ref name=Stein/>\nEarthquakes pose a risk to humans. Understanding their mechanisms, which depend on the type of earthquake (e.g., intraplate or deep focus), can lead to better estimates of earthquake risk and improvements in earthquake engineering.", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Vibrations", "_id": "2000049689--0--2---1", "title": "Seismographs and Earthquakes"}
{"qas": [{"question": "How do geophysicists measure electrical potential?", "answer": ""}, {"question": "What is the average charge of the downward electric field near the surface?", "answer": "120 volts per meter", "ae_score": -0.5227711637406137, "qg_score": null}, {"question": "What is the average charge of the downward electric field near the surface?", "answer": "120 volts per meter", "ae_score": -0.5227711637406137, "qg_score": null}], "content": "Although we mainly notice electricity during thunderstorms, there is always a downward electric field near the surface that averages 120 volts per meter. Relative to the solid Earth, the atmosphere has a net positive charge due to bombardment by cosmic rays. A current of about 1800 amperes flows in the global circuit.<ref name=Harrison/> It flows downward from the ionosphere over most of the Earth and back upwards through thunderstorms. The flow is manifested by lightning below the clouds and sprites above.\nA variety of electric methods are used in geophysical survey. Some measure spontaneous potential, a potential that arises in the ground because of man-made or natural disturbances. Telluric currents flow in Earth and the oceans. They have two causes: electromagnetic induction by the time-varying, external-origin geomagnetic field and motion of conducting bodies (such as seawater) across the Earth's permanent magnetic field. The distribution of telluric current density can be used to detect variations in electrical resistivity of underground structures. Geophysicists can also provide the electric current themselves (see induced polarization and electrical resistivity tomography).", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Electricity", "_id": "2000049689--0--3---1", "title": "Electromagnetic Currents in Earth and Oceans"}
{"qas": [{"question": "What is the difference between Dawn Chorus and Hiss?", "answer": ""}, {"question": "Besides transient electromagnetics, what other geophysical methods are used?", "answer": "magnetotellurics", "ae_score": -0.6907374165732901, "qg_score": null}, {"question": "Besides transient electromagnetics, what other geophysical methods are used?", "answer": "magnetotellurics", "ae_score": -0.6907374165732901, "qg_score": null}], "content": "Electromagnetic waves occur in the ionosphere and magnetosphere as well as the Earth's outer core. Dawn chorus is believed to be caused by high-energy electrons that get caught in the Van Allen radiation belt. Whistlers are produced by lightning strikes. Hiss may be generated by both. Electromagnetic waves may also be generated by earthquakes (see seismo-electromagnetics).\nIn the Earth's outer core, electric currents in the highly conductive liquid iron create magnetic fields by electromagnetic induction (see geodynamo). Alfv\u00e9n waves are magnetohydrodynamic waves in the magnetosphere or the Earth's core. In the core, they probably have little observable effect on the geomagnetic field, but slower waves such as magnetic Rossby waves may be one source of geomagnetic secular variation.<ref name=Merrill/>\nElectromagnetic methods that are used for geophysical survey include transient electromagnetics and magnetotellurics.", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Electromagnetic waves", "_id": "2000049689--0--4---1", "title": "Geophysical Survey of the Earth"}
{"qas": [{"question": "How does the Earth's magnetic polarity change over time?", "answer": ""}, {"question": "What is it called when the earths field is roughly like a tilted dipole?", "answer": "geomagnetic secular variation", "ae_score": -0.755920945844754, "qg_score": null}, {"question": "What is it called when the polarity of the earths field changes over time?", "answer": "geomagnetic reversals", "ae_score": null, "qg_score": null}], "content": "The Earth's magnetic field protects the Earth from the deadly solar wind and has long been used for navigation. It originates in the fluid motions of the Earth's outer core (see geodynamo).<ref name=Merrill/> The magnetic field in the upper atmosphere gives rise to the auroras.\nThe Earth's field is roughly like a tilted dipole, but it changes over time (a phenomenon called geomagnetic secular variation). Mostly the geomagnetic pole stays near the geographic pole, but at random intervals averaging 440,000 to a million years or so, the polarity of the Earth's field reverses. These geomagnetic reversals, analyzed within a Geomagnetic Polarity Time Scale, contain 184 polarity intervals in the last 83 million years, with change in frequency over time, with the most recent brief complete reversal of the Laschamp event occurring 41,000 years ago during the last glacial period. Geologists observed geomagnetic reversal recorded in volcanic rocks, through magnetostratigraphy correlation (see natural remanent magnetization) and their signature can be seen as parallel linear magnetic anomaly stripes on the seafloor. These stripes provide quantitative information on seafloor spreading, a part of plate tectonics. They are the basis of magnetostratigraphy, which correlates magnetic reversals with other stratigraphies to construct geologic time scales. In addition, the magnetization in rocks can be used to measure the motion of continents.<ref name=Merrill/>", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Magnetism", "_id": "2000049689--0--5---1", "title": "Geomagnetic Reversals in Volcanoes"}
{"qas": [{"question": "How does radioactive decay affect geology?", "answer": ""}, {"question": "What accounts for about  of the earths internal heat?", "answer": "Radioactive decay", "ae_score": -0.9080763334206807, "qg_score": null}, {"question": "What accounts for about  of the earths internal heat?", "answer": "Radioactive decay", "ae_score": -0.9080763334206807, "qg_score": null}], "content": "Radioactive decay accounts for about  of the Earth's internal heat, powering the geodynamo and plate tectonics. The main heat-producing isotopes are potassium-40, uranium-238, uranium-235, and thorium-232.Radioactive elements are used for radiometric dating, the primary method for establishing an absolute time scale in geochronology.Unstable isotopes decay at predictable rates, and the decay rates of different isotopes cover several orders of magnitude, so radioactive decay can be used to accurately date both recent events and events in past geologic eras. Radiometric mapping using ground and airborne gamma spectrometry can be used to map the concentration and distribution of radioisotopes near the Earth's surface, which is useful for mapping lithology and alteration.", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Radioactivity", "_id": "2000049689--0--6---1", "title": "Geochronology Using Radiometric Dating"}
{"qas": [{"question": "How do we know what is going on in the magnetosphere?", "answer": ""}, {"question": "Waves and other phenomena in the magnetosphere can be modeled using what?", "answer": "magnetohydrodynamics", "ae_score": -0.10751411407213869, "qg_score": null}, {"question": "Waves and other phenomena in the magnetosphere can be modeled using what?", "answer": "magnetohydrodynamics", "ae_score": -0.10751411407213869, "qg_score": null}], "content": "Fluid motions occur in the magnetosphere, atmosphere, ocean, mantle and core. Even the mantle, though it has an enormous viscosity, flows like a fluid over long time intervals (see geodynamics). This flow is reflected in phenomena such as isostasy, post-glacial rebound and mantle plumes. The mantle flow drives plate tectonics and the flow in the Earth's core drives the geodynamo.<ref name=Merrill/>\nGeophysical fluid dynamics is a primary tool in physical oceanography and meteorology. The rotation of the Earth has profound effects on the Earth's fluid dynamics, often due to the Coriolis effect. In the atmosphere it gives rise to large-scale patterns like Rossby waves and determines the basic circulation patterns of storms. In the ocean they drive large-scale circulation patterns as well as Kelvin waves and Ekman spirals at the ocean surface. In the Earth's core, the circulation of the molten iron is structured by Taylor columns.<ref name=Merrill/>\nWaves and other phenomena in the magnetosphere can be modeled using magnetohydrodynamics.", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Fluid dynamics", "_id": "2000049689--0--7---1", "title": "Geodynamics and Magnetohydrodynamics"}
{"qas": [{"question": "How do we know the composition of the Earth's interior?", "answer": ""}, {"question": "Where do the many phases of ice form?", "answer": "cryosphere", "ae_score": -0.40666399926114527, "qg_score": null}, {"question": "Where do the many phases of ice form?", "answer": "cryosphere", "ae_score": -0.40666399926114527, "qg_score": null}], "content": "The physical properties of minerals must be understood to infer the composition of the Earth's interior from seismology, the geothermal gradient and other sources of information. Mineral physicists study the elastic properties of minerals; their high-pressure phase diagrams, melting points and equations of state at high pressure; and the rheological properties of rocks, or their ability to flow. Deformation of rocks by creep make flow possible, although over short times the rocks are brittle. The viscosity of rocks is affected by temperature and pressure, and in turn determines the rates at which tectonic plates move (see geodynamics).<ref name=Poirier/>\nWater is a very complex substance and its unique properties are essential for life. Its physical properties shape the hydrosphere and are an essential part of the water cycle and climate. Its thermodynamic properties determine evaporation and the thermal gradient in the atmosphere. The many types of precipitation involve a complex mixture of processes such as coalescence, supercooling and supersaturation. Some precipitated water becomes groundwater, and groundwater flow includes phenomena such as percolation, while the conductivity of water makes electrical and electromagnetic methods useful for tracking groundwater flow. Physical properties of water such as salinity have a large effect on its motion in the oceans.<ref name=Pedlosky/>\nThe many phases of ice form the cryosphere and come in forms like ice sheets, glaciers, sea ice, freshwater ice, snow, and frozen ground (or permafrost).", "page_name": "Geophysics", "page_id": "Geophysics", "heading": "Physical phenomena", "sub_heading": "Mineral physics", "_id": "2000049689--0--8---1", "title": "Physical Properties of Water"}
{"qas": [{"question": "How does the kanamycin biosynthetic pathway work?", "answer": ""}, {"question": "What is the main product of streptomyces?", "answer": "kanamycin A", "ae_score": -0.2917829391488859, "qg_score": null}, {"question": "What is the main product of streptomyces?", "answer": "kanamycin", "ae_score": null, "qg_score": null}], "content": "While the main product produced by ''Streptomyces kanamyceticus'' is kanamycin A, additional products are also produced, including kanamycin B, kanamycin C, kanamycin D and kanamycin X.\nThe kanamycin biosynthetic pathway can be divided into two parts. The first part is common to several aminoglycoside antibiotics, such as butirosin and neomycin. In it a unique aminocyclitol, 2-deoxystreptamine, is biosynthesized from D-glucopyranose 6-phosphate in four steps. At this point the kanamycin pathway splits into two branches due to the promiscuity of the next enzyme, which can utilize two different glycosyl donors - UDP-N-acetyl-\u03b1-D-glucosamine and UDP-\u03b1-D-glucose. One of the branches forms kanamycin C and kanamycin B, while the other branch forms kanamycin D and kanamycin X. However, both kanamycin B and kanamycin D can be converted to kanamycin A, so both branches of the pathway converge at kanamycin A.", "page_name": "Kanamycin A", "page_id": "Kanamycin%20A", "heading": "Biosynthesis", "sub_heading": "Biosynthesis", "_id": "2000050279--4---1---1", "title": "''Streptomyces kanamyceticus'' Bios"}
{"qas": [{"question": "Why do some plants have a gene that allows them to be resistant to bacteria?", "answer": ""}, {"question": "What is the name of the agent used to isolate bacteria?", "answer": "Kanamycin", "ae_score": null, "qg_score": null}, {"question": "Kanamycin is an agent that selectively targets which type of bacteria?", "answer": "plasmid", "ae_score": null, "qg_score": null}], "content": "Kanamycin is used in molecular biology as a selective agent most commonly to isolate bacteria (e.g., ''E. coli'') which have taken up genes (e.g., of plasmids) coupled to a gene coding for kanamycin resistance (primarily Neomycin phosphotransferase II [NPT II/Neo]). Bacteria that have been transformed with a plasmid containing the kanamycin resistance gene are plated on kanamycin (50-100 ug/ml) containing agar plates or are grown in media containing kanamycin (50-100 ug/ml). Only the bacteria that have successfully taken up the kanamycin resistance gene become resistant and will grow under these conditions. As a powder, kanamycin is white to off-white and is soluble in water (50 mg/ml).\nAt least one such gene, ''Atwbc19'' is native to a plant species, of comparatively large size and its coded protein acts in a manner which decreases the possibility of horizontal gene transfer from the plant to bacteria; it may be incapable of giving resistance to bacteria even if gene transfer occurs.", "page_name": "Kanamycin A", "page_id": "Kanamycin%20A", "heading": "Use in research", "sub_heading": "Use in research", "_id": "2000050279--5---1---1", "title": "Kanamycin Resistance Genes in Bacteria"}
{"qas": [{"question": "How did the concept of entrainment come about?", "answer": ""}, {"question": "When was the concept of brain wave entrainment discovered?", "answer": "1665", "ae_score": -0.2696283356778159, "qg_score": null}, {"question": "When was the concept of brain wave entrainment discovered?", "answer": "1665", "ae_score": -0.2696283356778159, "qg_score": null}], "content": "Entrainment is a term originally derived from  complex systems theory, and denotes the way that two or more independent, autonomous oscillators with differing rhythms or frequencies, when situated in a context and at a proximity where they can interact for long enough, influence each other mutually, to a degree dependent on coupling force, such that they adjust until both oscillate with the same frequency.Examples include the mechanical entrainment or cyclic synchronization of two electric clothes dryers placed in close proximity, and the biological entrainment evident in the synchronized illumination of fireflies.\nEntrainment is a concept first identified by the Dutch physicist Christiaan Huygens in 1665 who discovered the phenomenon during an experiment with pendulum clocks: He set them each in motion and found that when he returned the next day, the sway of their pendulums had all synchronized.\nSuch entrainment occurs because small amounts of energy are transferred between the two systems when they are out of phase in such a way as to produce negative feedback. As they assume a more stable phase relationship, the amount of energy gradually reduces to zero, with system of greater frequency slowing down, and the other speeding up.\nSubsequently, the term 'entrainment' has been used to describe a shared tendency of many physical and biological systems to synchronize their periodicity and rhythm through interaction. This tendency has been identified as specifically pertinent to the study of sound and music generally, and acoustic rhythms specifically. The most ubiquitous and familiar examples of neuromotor entrainment to acoustic stimuli is observable in spontaneous foot or finger tapping to the rhythmic beat of a song.", "page_name": "Brainwave entrainment", "page_id": "Brainwave%20entrainment", "heading": "Entrainment", "sub_heading": "Entrainment", "_id": "2000050913--4--0---1", "title": "Entrainment in Music"}
{"qas": [{"question": "How do animals know how to sing?", "answer": ""}, {"question": "What does eeg stand for in brainwave entrainment?", "answer": "electroencephalogram", "ae_score": -0.8006656537382126, "qg_score": null}, {"question": "What does eeg stand for in brainwave entrainment?", "answer": "electroencephalogram", "ae_score": -0.8006656537382126, "qg_score": null}], "content": "Exogenous rhythmic entrainment, which occurs outside the body, has been identified and documented for a variety of human activities, which include the way people adjust the rhythm of their speech patterns to those of the subject with whom they communicate, and the rhythmic unison of an audience clapping.\nEven among groups of strangers, the rate of breathing, locomotive and subtle expressive motor movements, and rhythmic speech patterns have been observed to synchronize and entrain, in response to an auditory stimuli, such as a piece of music with a consistent rhythm.Furthermore, motor synchronization to repetitive tactile stimuli occurs in animals, including cats and monkeys as well as humans, with accompanying shifts in electroencephalogram (EEG) readings.", "page_name": "Brainwave entrainment", "page_id": "Brainwave%20entrainment", "heading": "Entrainment", "sub_heading": "Exogenous entrainment", "_id": "2000050913--4--1---1", "title": "Exogenous rhythmic entrainment has been identified and documented for a variety of"}
{"qas": [{"question": "How does sleep entrainment work?", "answer": ""}, {"question": "How long is the cycle of light and dark?", "answer": "24-hour", "ae_score": null, "qg_score": null}, {"question": "How long is the cycle of light and dark?", "answer": "24-hour", "ae_score": null, "qg_score": null}], "content": "Examples of endogenous entrainment, which occurs within the body, include the synchronizing of human circadian sleep-wake cycles to the 24-hour cycle of light and dark.and the synchronization of a heartbeat to a cardiac pacemaker.", "page_name": "Brainwave entrainment", "page_id": "Brainwave%20entrainment", "heading": "Entrainment", "sub_heading": "Endogenous entrainment", "_id": "2000050913--4--2---1", "title": "Endogenous Entrainment in the Body"}
{"qas": [{"question": "Huygens' discovery of synchronicity?", "answer": ""}, {"question": "What is the term used to describe the way in which the aggregate frequency of oscillations?", "answer": "Brainwave entrainment", "ae_score": -0.41069190166209923, "qg_score": null}, {"question": "What is the term used to describe the way in which the aggregate frequency of oscillations?", "answer": "Brainwave entrainment", "ae_score": -0.41069190166209923, "qg_score": null}], "content": "Brainwaves, or neural oscillations, share the fundamental constituents with acoustic and optical  wave forms, including frequency, amplitude, and periodicity. Consequently, Huygens' discovery precipitated inquiry into whether or not the synchronous electrical activity of cortical neural ensembles might not only alter in response to external acoustic or optical stimuli but also entrain or synchronize their frequency to that of a specific stimulus.\nBrainwave entrainment is a colloquialism for such 'neural entrainment', which is a term used to denote the way in which the aggregate frequency of oscillations produced by the synchronous electrical activity in ensembles of cortical neurons can adjust to synchronize with the periodic vibration of an external stimuli, such as a sustained acoustic frequency perceived as pitch, a regularly repeating pattern of intermittent sounds, perceived as rhythm, or of a regularly rhythmically intermittent flashing light.", "page_name": "Brainwave entrainment", "page_id": "Brainwave%20entrainment", "heading": "Entrainment", "sub_heading": "Brainwave entrainment", "_id": "2000050913--4--3---1", "title": "Brainwave Entrainment: A Neuroscience Approach"}
{"qas": [{"question": "Why is it that the stock market can rise and fall at the same time?", "answer": ""}, {"question": "Who called the need to guess the intentions of others'reflexivity'?", "answer": "George Soros", "ae_score": -0.629511056281493, "qg_score": null}, {"question": "Who called the need to guess the intentions of others'reflexivity'?", "answer": "George Soros", "ae_score": -0.629511056281493, "qg_score": null}], "content": "It is often observed that successful investment requires each investor in a financial market to guess what other investors will do. George Soros has called this need to guess the intentions of others 'reflexivity'. Similarly, John Maynard Keynes compared financial markets to a beauty contest game in which each participant tries to predict which model ''other'' participants will consider most beautiful.  Circularity and self-fulfilling prophecies may be exaggerated when reliable information is not available because of opaque disclosures or a lack of disclosure.\nFurthermore, in many cases investors have incentives to coordinate their choices. For example, someone who thinks other investors want to buy lots of Japanese yen may expect the yen to rise in value, and therefore has an incentive to buy yen too. Likewise, a depositor in IndyMac Bank who expects other depositors to withdraw their funds may expect the bank to fail, and therefore has an incentive to withdraw too. Economists call an incentive to mimic the strategies of others ''strategic complementarity''.\nIt has been argued that if people or firms have a sufficiently strong incentive to do the same thing they expect others to do, then ''self-fulfilling prophecies'' may occur. For example, if investors expect the value of the yen to rise, this may cause its value to rise; if depositors expect a bank to fail this may cause it to fail. Therefore, financial crises are sometimes viewed as a vicious circle in which investors shun some institution or asset because they expect others to do so.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Causes and consequences", "_id": "2000051860--1--0---1", "title": "Investing in Financial Markets: Circularity and Self-fulfilling Prophe"}
{"qas": [{"question": "How did financial institutions become so powerful during the financial crisis?", "answer": ""}, {"question": "When did the financial crisis start in the us?", "answer": "1929", "ae_score": -0.566710141111682, "qg_score": null}, {"question": "When did the financial crisis start in the us?", "answer": "1929", "ae_score": -0.566710141111682, "qg_score": null}], "content": "''Leverage'', which means borrowing to finance investments, is frequently cited as a contributor to financial crises. When a financial institution (or an individual) only invests its own money, it can, in the very worst case, lose its own money. But when it borrows in order to invest more, it can potentially earn more from its investment, but it can also lose more than all it has. Therefore, leverage magnifies the potential returns from investment, but also creates a risk of bankruptcy. Since bankruptcy means that a firm fails to honor all its promised payments to other firms, it may spread financial troubles from one firm to another (see 'Contagion' below).\nThe average degree of leverage in the economy often rises prior to a financial crisis. For example, borrowing to finance investment in the stock market (\"margin buying\") became increasingly common prior to the Wall Street Crash of 1929.  In addition, some scholars have argued that financial institutions can contribute to fragility by hiding leverage, and thereby contributing to underpricing of risk.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Leverage", "_id": "2000051860--1--1---1", "title": "''Leverage'': A Contributor to Financial Crisis"}
{"qas": [{"question": "What caused the 2008 financial crisis?", "answer": ""}, {"question": "What are emerging market governments selling bonds denominated in?", "answer": "US dollars", "ae_score": -0.32161922008674837, "qg_score": null}, {"question": "What is the risk of emerging market governments being unable to sell bonds denominated in their?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "Another factor believed to contribute to financial crises is ''asset-liability mismatch'', a situation in which the risks associated with an institution's debts and assets are not appropriately aligned. For example, commercial banks offer deposit accounts which can be withdrawn at any time and they use the proceeds to make long-term loans to businesses and homeowners. The mismatch between the banks' short-term liabilities (its deposits) and its long-term assets (its loans) is seen as one of the reasons bank runs occur (when depositors panic and decide to withdraw their funds more quickly than the bank can get back the proceeds of its loans). Likewise, Bear Stearns failed in 2007\u201308 because it was unable to renew the short-term debt it used to finance long-term investments in mortgage securities.\nIn an international context, many emerging market governments are unable to sell bonds denominated in their own currencies, and therefore sell bonds denominated in US dollars instead. This generates a mismatch between the currency denomination of their liabilities (their bonds) and their assets (their local tax revenues), so that they run a risk of sovereign default due to fluctuations in exchange rates.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Asset-liability mismatch", "_id": "2000051860--1--2---1", "title": "Financial crises: Asset-Liability Mismatch"}
{"qas": [{"question": "What is the role of human error in a financial crisis?", "answer": ""}, {"question": "Who is the historian who said that financial crises follow soon after major technological innovations?", "answer": "Charles P. Kindleberger", "ae_score": -0.5126961484141104, "qg_score": null}, {"question": "Who is the historian who said that financial crises follow soon after major technological innovations?", "answer": "Charles P. Kindleberger", "ae_score": -0.5126961484141104, "qg_score": null}], "content": "Many analyses of financial crises emphasize the role of investment mistakes caused bylack of knowledge or the imperfections of human reasoning. Behavioral finance studieserrors in economic and quantitative reasoning. Psychologist Torbjorn K A Eliazon has also analyzed failuresof economic reasoning in his concept of '\u0153copathy'.\nHistorians, notably Charles P. Kindleberger, have pointed out that crisesoften follow soon after major financial or technical innovations that presentinvestors with new types of financial opportunities, which he called \"displacements\"of investors' expectations.Early examples include the South Sea Bubble and Mississippi Bubble of 1720,which occurred when the notion of investment in shares of company stock wasitself new and unfamiliar,and the Crash of 1929, which followed the introduction of new electrical and transportationtechnologies.More recently, many financial crises followed changes in the investmentenvironment brought about by financial deregulation, and the crash of the dot com bubblein 2001 arguably began with \"irrational exuberance\" about Internet technology.\nUnfamiliarity with recent technical and financial innovations may help explain howinvestors sometimes grossly overestimate asset values. Also, if the first investorsin a new class of assets (for example, stock in \"dot com\" companies)profit from rising asset values as other investors learn about the innovation(in our example, as others learn about the potential of the Internet),then still more others may follow their example, driving the price even higheras they rush to buy in hopes of similar profits. If such \"herd behavior\" causesprices to spiral up far above the true value of the assets, a crash may become inevitable.If for any reason the price briefly falls, so that investors realizethat further gains are not assured, then the spiral may go into reverse,with price decreases causing a rush of sales, reinforcing the decrease in prices.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Uncertainty and herd behavior", "_id": "2000051860--1--3---1", "title": "Financial Crises \u2014 Why They Happen"}
{"qas": [{"question": "How did the financial institutions that caused the 2008 financial crisis fail?", "answer": ""}, {"question": "Who was the managing director of the international monetary fund during the financial crisis of 2008?", "answer": "Dominique Strauss-Kahn", "ae_score": -0.26120386435598125, "qg_score": null}, {"question": "What type of swaps were being regulated during the financial crisis of 2008?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "Governments have attempted to eliminate or mitigate financial crises by regulating the financial sector. One major goal of regulation is transparency: making institutions' financial situations publicly known by requiring regular reporting under standardized accounting procedures. Another goal of regulation is making sure institutions have sufficient assets to meet their contractual obligations, through reserve requirements, capital requirements, and other limits on leverage.\nSome financial crises have been blamed on insufficient regulation, and have led to changes in regulation in order to avoid a repeat. For example, the former Managing Director of the International Monetary Fund, Dominique Strauss-Kahn, has blamed the financial crisis of 2008 on 'regulatory failure to guard against excessive risk-taking in the financial system, especially in the US'. Likewise, the New York Times singled out the deregulation of credit default swaps as a cause of the crisis.\nHowever, excessive regulation has also been cited as a possible cause of financial crises. In particular, the Basel II Accord has been criticized for requiring banks to increase their capital when risks rise, which might cause them to decrease lending precisely when capital is scarce, potentially aggravating a financial crisis.\nInternational regulatory convergence has been interpreted in terms of regulatory herding, deepening market herding (discussed above) and so increasing systemic risk. From this perspective, maintaining diverse regulatory regimes would be a safeguard.\nFraud has played a role in the collapse of some financial institutions, when companies have attracted depositors with misleading claims about their investment strategies, or have embezzled the resulting income. Examples include Charles Ponzi's scam in early 20th century Boston, the collapse of the MMM investment fund in Russia in 1994, the scams that led to the Albanian Lottery Uprising of 1997, and the collapse of Madoff Investment Securities in 2008.\nMany rogue traders that have caused large losses at financial institutions have been accused of acting fraudulently in order to hide their trades. Fraud in mortgage financing has also been cited as one possible cause of the 2008 subprime mortgage crisis; government officials stated on September 23, 2008 that the FBI was looking into possible fraud by mortgage financing companies Fannie Mae and Freddie Mac, Lehman Brothers, and insurer American International Group. Likewise it has been argued that many financial companies failed in the recent crisis because their managers failed to carry out their fiduciary duties.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Regulatory failures", "_id": "2000051860--1--4---1", "title": "The Role of Regulation in Financial Crisis"}
{"qas": [{"question": "What is systemic risk?", "answer": ""}, {"question": "When did the thai financial crisis start?", "answer": "1997", "ae_score": -0.3868678509228917, "qg_score": null}, {"question": "What happens when a country's currency runs out of money?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "''Contagion'' refers to the idea that financial crises may spread from one institution to another, as when a bank run spreads from a few banks to many others, or from one country to another, as when currency crises, sovereign defaults, or stock market crashes spread across countries. When the failure of one particular financial institution threatens the stability of many other institutions, this is called ''systemic risk''.\nOne widely cited example of contagion was the spread of the Thai crisis in 1997 to other countries like South Korea. However, economists often debate whether observing crises in many countries around the same time is truly caused by contagion from one market to another, or whether it is instead caused by similar underlying problems that would have affected each country individually even in the absence of international linkages.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Contagion", "_id": "2000051860--1--5---1", "title": "''Contagion'' is the spread of financial crises from one financial"}
{"qas": [{"question": "How does a financial crisis affect the economy?", "answer": ""}, {"question": "When did the wall street crash happen?", "answer": "1987", "ae_score": -0.689819470451363, "qg_score": null}, {"question": "What is the effect of a financial crisis on the economy?", "answer": "model recession", "ae_score": null, "qg_score": null}], "content": "Some financial crises have little effect outside of the financial sector, like the Wall Street crash of 1987, but other crises are believed to have played a role in decreasing growth in the rest of the economy. There are many theories why a financial crisis could have a recessionary effect on the rest of the economy. These theoretical ideas include the 'financial accelerator', 'flight to quality' and 'flight to liquidity', and the Kiyotaki-Moore model. Some 'third generation' models of currency crises explore how currency crises and banking crises together can cause recessions.", "page_name": "Financial crisis", "page_id": "Financial%20crisis", "heading": "Causes and consequences", "sub_heading": "Recessionary effects", "_id": "2000051860--1--6---1", "title": "Why a Financial Crisis Could Have a Recessionary Effect on the Rest of the Economy"}
{"qas": [{"question": "Why does calcium oxalate monohydrate (TGA) have a higher mass than calcium oxide monohydrate?", "answer": ""}, {"question": "What is the name of the precursor molecule for thermogravimetric analysis?", "answer": "CaAlCHON", "ae_score": -0.130657797712433, "qg_score": null}, {"question": "The last mass loss in tga is due to the decomposition of calcium oxal?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "Ceramic yield is defined as the mass percent of starting material found in the end product.  From this, stoichiometry can then be used to calculate the percent mass of the substance in the sample.\nMetal aluminates (MAlO) are an important type of mixed-cation oxide ceramics that have many applications.<ref name=ref5>{{cite journal | title = Synthesis and Characterization of Precursors for Group II Metal Aluminates | journal = Appl. Organomet. Chem. | year = 1997 | volume = 11 | pages = 919\u2013927 | doi = 10.1002/(SICI)1099-0739(199710/11)11:10/11\n  The metal aluminate CaAlO is used in the cement industry as a hydraulic material.<ref name=ref5>{{cite journal | title = Synthesis and Characterization of Precursors for Group II Metal Aluminates | journal = Appl. Organomet. Chem. | year = 1997 | volume = 11 | pages = 919\u2013927 | doi = 10.1002/(SICI)1099-0739(199710/11)11:10/11\n  Its precursor is CaAlCHON.<ref name=ref5>{{cite journal | title = Synthesis and Characterization of Precursors for Group II Metal Aluminates | journal = Appl. Organomet. Chem. | year = 1997 | volume = 11 | pages = 919\u2013927 | doi = 10.1002/(SICI)1099-0739(199710/11)11:10/11\n The formation of CaAlO occurs during the thermogravimetric analysis. This is how the theoretical ceramic yield is calculated for this example:\nTherefore, the theoretical ceramic yield for the thermogravimetric analysis of  CaAlCHON is 29.6%. This correlates well with the experimentally determined ceramic yield of 28.9%.\nAs another example of calculating theoretical ceramic yield, take the TGA of calcium oxalate monohydrate. Using the same process detailed above, the theoretical ceramic yield can be calculated: the formula weight of calcium oxalate monohydrate is 146 g/mol. The final ceramic product is CaO, with a formula weight of 56 g/mol. The theoretical ceramic yield is therefore 38.4%.  The actual yield from the TGA was found to be 39.75%. Some reasons for discrepancies between the theoretical and actual yields are trapped CO and the formation of metal carbides.\nIn the TGA trace of calcium oxalate monohydrate, the first mass loss corresponds to loss of water of hydration.  The second mass loss corresponds to decomposition of dehydrated calcium oxalate to calcium carbonate and carbon monoxide and carbon dioxide.  The last mass loss is due to the decomposition of calcium carbonate to calcium oxide and carbon dioxide.\nThe differences between thermograms can be seen in the example of four different chloro-polymers: (a) polyvinyl chloride, (b) chlorinated polyvinyl chloride, (c) chlorinated rubber, and (d) polyvinylidene chloride. There are two stages of degradation in these four polymers. The first stage is the loss of hydrogen chloride, and is complete around 250 \u00b0C.  This first step occurs at lower temperatures for the polymers containing more chlorine (chlorinated polyvinyl chloride, chlorinated rubber, and polyvinylidene chloride), implying that these chloride groupings are less stable than in polyvinyl chloride.\nThe second stage is the carbonization of the polymer, and takes place between 250 \u00b0C and 500 \u00b0C. This is seen by the large loss of mass between 250 \u00b0C and 500 \u00b0C. Tar and simple gases, such as hydrogen and methane, are evolved and the carbon that remains loses very little mass between 500 \u00b0C and 900 \u00b0C. In this second stage, the higher the chlorine content of the polymer, the lower the yield of tar. This is because chlorine is able to remove hydrogen, which would otherwise be used in the compounds that form tar.", "page_name": "Thermogravimetric analysis", "page_id": "Thermogravimetric%20analysis", "heading": "Ceramic yield", "sub_heading": "Ceramic yield", "_id": "2000052365--3---1---1", "title": "Theoretical Ceramic Yield Calculation"}
{"qas": [{"question": "How does conjugation work?", "answer": ""}, {"question": "What type of transfer is required for mycobacterium smegmatis to?", "answer": "Conjugal DNA transfer", "ae_score": -0.9828050189334305, "qg_score": null}, {"question": "Where does mycobacterium smegmatis get its protein from?", "answer": "genomes", "ae_score": null, "qg_score": null}], "content": "Conjugal DNA transfer in ''M. smegmatis'' requires stable and extended contact between a donor and a recipient strain, is DNase resistant, and the transferred DNA is incorporated into the recipient\u2019s chromosome by homologous recombination.  However, in contrast to the well-known ''E. coli'' Hfr conjugation system, in ''M. smegmatis'' all regions of the chromosome are transferred with comparable efficiencies and mycobacterial conjugation is chromosome, rather than plasmid based.  Gray et al. reported substantial blending of the parental genomes resulting from conjugation and referred to this blending as reminiscent of that seen in the meiotic products of sexual reproduction (see Origin of sexual reproduction)", "page_name": "Mycobacterium smegmatis", "page_id": "Mycobacterium%20smegmatis", "heading": "Conjugation", "sub_heading": "Conjugation", "_id": "2000053645--3---1---1", "title": "Conjugal DNA transfer in ''M. smegmatis\u2019\u2019"}
{"qas": [{"question": "Why is abiogenic oil not considered a viable alternative to fossil fuels?", "answer": ""}, {"question": "When did thomas gold write about biogenic petroleum?", "answer": "1999", "ae_score": -0.8107172285771915, "qg_score": null}, {"question": "Where does the carbon in methane come from?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "Thomas Gold, in a 1999 book, cited the discovery of thermophile bacteria in the Earth's crust as new support for the postulate that these bacteria could explain the existence of certain biomarkers in extracted petroleum. A rebuttal of biogenic origins based on biomarkers has been offered by Kenney, et al. (2001).<ref name=glasby2006/>\nMethane is ubiquitous in crustal fluid and gas. Research continues to attempt to characterise crustal sources of methane as biogenic or abiogenic using carbon isotope fractionation of observed gases (Lollar & Sherwood 2006). There are few clear examples of abiogenic methane-ethane-butane, as the same processes favor enrichment of light isotopes in all chemical reactions, whether organic or inorganic. \u03b4C of methane overlaps that of inorganic carbonate and graphite in the crust, which are heavily depleted in C, and attain this by isotopic fractionation during metamorphic reactions.\nOne argument for abiogenic oil cites the high carbon depletion of methane as stemming from the observed carbon isotope depletion with depth in the crust. However, diamonds, which are definitively of mantle origin, are not as depleted as methane, which implies that methane carbon isotope fractionation is not controlled by mantle values.\nCommercially extractable concentrations of helium (greater than 0.3%) are present in natural gas from the Panhandle-Hugoton fields in the USA, as well as from some Algerian and Russian gas fields.\nHelium trapped within most petroleum occurrences, such as the occurrence in Texas, is of a distinctly crustal character with an ''Ra'' ratio of less than 0.0001 that of the atmosphere.\nThe Chimaera gas seep, near Antalya (SW Turkey), new and thorough molecular and isotopic analyses including methane (~87% v/v; D13C1 from -7.9 to -12.3 \u2030; D13D1 from -119 to -124 \u2030), light alkanes (C2+C3+C4+C5 = 0.5%; C6+: 0.07%; D13C2 from -24.2 to -26.5 \u2030; D13C3 from -25.5 to -27 \u2030), hydrogen (7.5 to 11%), carbon dioxide (0.01-0.07%; D13CCO2: -15 \u2030), helium (~80 ppmv; R/Ra: 0.41) and nitrogen (2-4.9%; D15N from -2 to -2.8 \u2030) converge to indicate that the seep releases a mixture of organic thermogenic gas, related to mature Type III kerogen occurring in Paleozoic and Mesozoic organic rich sedimentary rocks, and abiogenic gas produced by low temperature serpentinization in the Tekirova ophiolitic unit.", "page_name": "Abiogenic petroleum origin", "page_id": "Abiogenic%20petroleum%20origin", "heading": "Biotic (microbial) hydrocarbons", "sub_heading": "Biotic (microbial) hydrocarbons", "_id": "3000000697--5--0---1", "title": "Biogenic or abiogenic?"}
{"qas": [{"question": "How do we know that petroleum is a living thing?", "answer": ""}, {"question": "Where does the chemical in crude oil come from?", "answer": "kerogen", "ae_score": -0.615773233961529, "qg_score": null}, {"question": "Where does the chemical in crude oil come from?", "answer": "kerogen", "ae_score": -0.615773233961529, "qg_score": null}], "content": "Certain chemicals found in naturally occurring petroleum contain chemical and structural similarities to compounds found within many living organisms. These include terpenoids, terpenes, pristane, phytane, cholestane, chlorins and porphyrins, which are large, chelating molecules in the same family as heme and chlorophyll. Materials which suggest certain biological processes include \nThe presence of these chemicals in crude oil is a result of the inclusion of biological material in the oil; these chemicals are released by kerogen during the production of hydrocarbon oils, as these are chemicals highly resistant to degradation and plausible chemical paths have been studied. Abiotic defenders state that biomarkers get into oil during its way up as it gets in touch with ancient fossils. However a more plausible explanation is that biomarkers are traces of biological molecules from bacteria (archaea) that feed on primordial hydrocarbons and die in that environment. For example, hopanoids are just parts of the bacterial cell wall present in oil as contaminant.", "page_name": "Abiogenic petroleum origin", "page_id": "Abiogenic%20petroleum%20origin", "heading": "Biotic (microbial) hydrocarbons", "sub_heading": "Biomarker chemicals", "_id": "3000000697--5--1---1", "title": "Chemicals in Oil"}
{"qas": [{"question": "Why are there so many trace elements in oil?", "answer": ""}, {"question": "How many trace elements in oils are there?", "answer": "22", "ae_score": -0.3459574928324897, "qg_score": null}, {"question": "How many trace elements in oils are there?", "answer": "22", "ae_score": -0.3459574928324897, "qg_score": null}], "content": "Nickel (Ni), vanadium (V), lead (Pb), arsenic (As), cadmium (Cd), mercury (Hg) and others metals frequently occur in oils. Some heavy crude oils, such as Venezuelan heavy crude have up to 45% vanadium pentoxide content in their ash, high enough that it is a commercial source for vanadium. Abiotic supporters argue that these metals are common in Earth's mantle, but relatively high contents of nickel, vanadium, lead and arsenic can be usually found in almost all marine sediments.\nAnalysis of 22 trace elements in oils correlate significantly better with chondrite, serpentinized fertile mantle peridotite, and the primitive mantle than with oceanic or continental crust, and shows no correlation with seawater.", "page_name": "Abiogenic petroleum origin", "page_id": "Abiogenic%20petroleum%20origin", "heading": "Biotic (microbial) hydrocarbons", "sub_heading": "Trace metals", "_id": "3000000697--5--2---1", "title": "Nickel, Vanadium, Lead, Arsenic, Cadmium, Mercury,"}
{"qas": [{"question": "Why is there so much oil in natural living media?", "answer": ""}, {"question": "What is the name of the unsaturated hydrocarbons found in petroleum?", "answer": "Olefins", "ae_score": -0.13291930822728307, "qg_score": null}, {"question": "What is the name of the unsaturated hydrocarbons found in petroleum?", "answer": "Olefins", "ae_score": -0.13291930822728307, "qg_score": null}], "content": "Sir Robert Robinson studied the chemical makeup of natural petroleum oils in great detail, and concluded that they were mostly far too hydrogen-rich to be a likely product of the decay of plant debris, assuming a dual origin for Earth hydrocarbons.   However, several processes which generate hydrogen could supply kerogen hydrogenation which is compatible with the conventional explanation.\nOlefins, the unsaturated hydrocarbons, would have been expected to predominate by far in any material that was derived in that way. He also wrote: \"Petroleum ... [seems to be] a primordial hydrocarbon mixture into which bio-products have been added.\"\nThis has however been demonstrated later to be a misunderstanding by Robinson, related to the fact that only short duration experiments were available to him.  Olefins are thermally very unstable (that is why natural petroleum normally does not contain such compounds) and in laboratory experiments that last more than a few hours, the olefins are no longer present.\nThe presence of low-oxygen and hydroxyl-poor hydrocarbons in natural living media is supported by the presence of natural waxes (n=30+), oils (n=20+) and lipids in both plant matter and animal matter, for instance fats in phytoplankton, zooplankton and so on. These oils and waxes, however, occur in quantities too small to significantly affect the overall hydrogen/carbon ratio of biological materials.However, after the discovery of highly aliphatic biopolymers in algae, and that oil generating kerogen essentially represent concentrates of such materials, no theoretical problem exists anymore.  Also, the millions of source rock samples that have been analyzed for petroleum yield by the petroleum industry have confirmed the large quantities of petroleum found in sedimentary basins.", "page_name": "Abiogenic petroleum origin", "page_id": "Abiogenic%20petroleum%20origin", "heading": "Biotic (microbial) hydrocarbons", "sub_heading": "Reduced carbon", "_id": "3000000697--5--3---1", "title": "Sir Robert Robinson's Theory of Petroleum Oils"}
{"qas": [{"question": "Why is there such a high frequency of seismic noise in the ocean?", "answer": ""}, {"question": "What can be used as a seismic source?", "answer": "dynamite", "ae_score": -0.5917311003236196, "qg_score": null}, {"question": "What shift in hearing can lower-level noise cause?", "answer": "Threshold shift", "ae_score": null, "qg_score": null}], "content": "As with all human activities, seismic reflection surveys may have some impact on the Earth's natural environment and both the hydrocarbon industry and environmental groups partake in research to investigate these effects.\nOn land, conducting a seismic survey may require the building of roads, for transporting equipment and personnel, and vegetation may need to be cleared for the deployment of equipment.  If the survey is in a relatively undeveloped area, significant habitat disturbance may occur and many governments require seismic companies to follow strict rules regarding destruction of the environment; for example, the use of dynamite as a seismic source may be disallowed.  Seismic processing techniques allow for seismic lines to deviate around natural obstacles, or use pre-existing non-straight tracks and trails.  With careful planning, this can greatly reduce the environmental impact of a land seismic survey.  The more recent use of inertial navigation instruments for land survey instead of theodolites decreased the impact of seismic by allowing the winding of survey lines between trees.\nThe main environmental concern for marine seismic surveys is the potential for noise associated with the high-energy seismic source to disturb or injure animal life, especially cetaceans such as whales, porpoises, and dolphins, as these mammals use sound as their primary method of communication with one another.  High-level and long-duration sound can cause physical damage, such as hearing loss, whereas lower-level noise can cause temporary threshold shifts in hearing, obscuring sounds that are vital to marine life, or behavioural disturbance.\nA study has shown that migrating humpback whales will leave a minimum 3 km gap between themselves and an operating seismic vessel, with resting humpback whale pods with cows exhibiting increased sensitivity and leaving an increased gap of 7\u201312 km.  Conversely, the study found that male humpback whales were attracted to a single operating airgun as they were believed to have confused the low-frequency sound with that of whale breaching behaviour.  In addition to whales, sea turtles, fish and squid all showed alarm and avoidance behaviour in the presence of an approaching seismic source.  It is difficult to compare reports on the effects of seismic survey noise on marine life because methods and units are often inadequately documented.\nThe gray whale will avoid its regular migratory and feeding grounds by >30 km in areas of seismic testing. Similarly the breathing of gray whales was shown to be more rapid, indicating discomfort and panic in the whale. It is circumstantial evidence such as this that has led researchers to believe that avoidance and panic might be responsible for increased whale beachings although research is ongoing into these questions.\nOffering another point of view, a joint paper from the International Association of Geophysical Contractors (IAGC) and the International Association of Oil and Gas Producers (OGP) argue that the noise created by marine seismic surveys is comparable to natural sources of seismic noise, stating:", "page_name": "Reflection seismology", "page_id": "Reflection%20seismology", "heading": "Environmental impact", "sub_heading": "Environmental impact", "_id": "3000000927--2---1---1", "title": "Environmental Impacts of Seismic Surveys"}
{"qas": [{"question": "What is the difference between continuous flow and inlet IRMS?", "answer": ""}, {"question": "Measurement of the abundances of stable isotopes of the same element is known as?", "answer": "stable isotope analysis", "ae_score": -0.5484505254564049, "qg_score": null}, {"question": "What is the effect of differences in mass between different isotopes of the same element?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "Measurement of natural variations in the abundances of stable isotopes of the same element is normally referred to as stable isotope analysis. This field is of interest because the differences in mass between different isotopes leads to isotope fractionation, causing measurable effects on the isotopic composition of samples, characteristic of their biological or physical history.\nAs a specific example, the hydrogen isotope deuterium (heavy hydrogen) is almost double the mass of the common hydrogen isotope. Water molecules containing the common hydrogen isotope (and the common oxygen isotope, mass 16) have a mass of 18. Water incorporating a deuterium atom has a mass of 19, over 5% heavier. The energy to vaporise the heavy water molecule is higher than that to vaporize the normal water so isotope fractionation occurs during the process of evaporation. Thus a sample of sea water will exhibit a quite detectable isotopic-ratio difference when compared to Antarctic snowfall.\nSamples must be introduced to the mass spectrometer as pure gases, achieved through combustion, gas chromatographic feeds, or chemical trapping. By comparing the detected isotopic ratios to a measured standard, an accurate determination of the isotopic make up of the sample is obtained. For example, carbon isotope ratios are measured relative to the international standard for C. The C standard is produced from a fossil belemnite found in the Peedee Formation, which is a limestone formed in the Cretaceous period in South Carolina, U.S.A. The fossil is referred to as VPDB (Vienna Pee Dee Belemnite) and has C:C ratio of 0.0112372. Oxygen isotope ratios are measured relative the standard, V-SMOW (Vienna Standard Mean Ocean Water).\nIt is critical that the sample be processed before entering the mass spectrometer so that only a single chemical species enters at a given time.  Generally, samples are combusted or pyrolyzed and the desired gas species (usually hydrogen (H), nitrogen (N), carbon dioxide (CO), or sulfur dioxide (SO)) is purified by means of traps, filters, catalysts and/or chromatography.\nThe two most common types of IRMS instruments are continuous flow<ref name=\"pmid9538528\">{{cite journal |vauthors=Brenna JT, Corso TN, Tobias HJ, Caimi RJ |title=High-precision continuous-flow isotope ratio mass spectrometry |journal=Mass spectrometry reviews |volume=16 |issue=5 |pages=227\u201358 |year=1997 |pmid=9538528 |doi=10.1002/(SICI)1098-2787(1997)16:5\n and dual inlet. In dual inlet IRMS, purified gas obtained from a sample is alternated rapidly with a standard gas (of known isotopic composition) by means of a system of valves, so that a number of comparison measurements are made of both gases.  In continuous flow IRMS, sample preparation occurs immediately before introduction to the IRMS, and the purified gas produced from the sample is measured just once.  The standard gas may be measured before and after the sample or after a series of sample measurements.  While continuous-flow IRMS instruments can achieve higher sample throughput and are more convenient to use than dual inlet instruments, the yielded data is of approximately 10-fold lower precision.", "page_name": "Isotope-ratio mass spectrometry", "page_id": "Isotope-ratio%20mass%20spectrometry", "heading": "Gas source mass spectrometry", "sub_heading": "Gas source mass spectrometry", "_id": "3000002333--1---1---1", "title": "Stable Isotope Analysis Using IRMS"}
{"qas": [{"question": "Asperger syndrome and high functioning autism?", "answer": ""}, {"question": "What are the two main causes of autism?", "answer": "high-functioning autism", "ae_score": -0.7060636816344021, "qg_score": null}, {"question": "What are the two main causes of autism?", "answer": "high-functioning autism", "ae_score": -0.7060636816344021, "qg_score": null}], "content": "The social construct theory says that the boundary between normal and abnormal is subjective and arbitrary, so autism does not exist as an objective entity, but only as a social construct. It further argues that autistic individuals themselves have a way of being that is partly socially constructed.\nAsperger syndrome and high-functioning autism are particular targets of the theory that social factors determine what it means to be autistic. The theory hypothesizes that individuals with these diagnoses inhabit the identities that have been ascribed to them, and promote their sense of well-being by resisting or appropriating autistic ascriptions.", "page_name": "Causes of autism", "page_id": "Causes%20of%20autism", "heading": "Social construct", "sub_heading": "Social construct", "_id": "3000002421--6---1---1", "title": "The Social Construct Theory of Autism"}
{"qas": [{"question": "How did the reality show \"The Big Bang Theory\" change from a 1-10 scoring system to a 10-10 score system?", "answer": ""}, {"question": "Who won america's next top model season 19?", "answer": "Leila Goldkuhl", "ae_score": -0.3629876415098607, "qg_score": null}, {"question": "Who won america's next top model season 19?", "answer": "Leila Goldkuhl", "ae_score": -0.3629876415098607, "qg_score": null}], "content": "This was the first cycle to feature a cast of all-new contestants since cycle 16 (cycle 17 (''All-Stars'') featured only returning contestants from previous cycles, while cycle 18 (''British Invasion'') featured seven new American models alongside seven returning contestants from previous cycles of ''Britain & Ireland's Next Top Model'').\nJudge and fashion photographer Nigel Barker, runway coach Miss J. Alexander and photo shoot creative director Jay Manuel were dismissed from the show after the previous cycle in an attempt to revitalize the show. They were replaced by British model Rob Evans and Filipino fashion blogger Bryanboy. Johnny Wujek also joined the crew as the new creative director of photo shoots. Evans and Bryanboy joined the judging panel with Banks and Cutrone, marking the return of four permanent judges since cycle 12. This cycle did not feature guest judges at panel\nAnother change was the incorporation of public voting as a factor in eliminations. A 1\u201310 scoring system was implemented to determine the merits of each contestant's performances at challenges and photo shoots, and the results for each week were calculated on a 50-point scale, with a maximum possible score of 10 from each of the three judges (Banks, Cutrone and Evans) and for each challenge and a maximum possible average social media score of 10.0. Each week, the girl with the lowest combined score was eliminated from the competition.\nThe eliminated girls still participated in every photo shoot (including those taking place after the comeback competition was finished), and their photos were also still available to be voted on by the public. This separate competition was documented on the \"Comeback series\", which was untelevised and instead shown on The CW's official website. It lasted for six weeks, and the winning contestant, with the highest average social media score throughout the cycle (Leila Goldkuhl), was allowed to rejoin the main competition.", "page_name": "America's Next Top Model (cycle 19)", "page_id": "America's%20Next%20Top%20Model%20(cycle%2019)", "heading": "Format changes", "sub_heading": "Format changes", "_id": "3000005457--0---1---1", "title": "''Comeback'': The CW's ''All-"}
{"qas": [{"question": "How do we know the age of the universe?", "answer": ""}, {"question": "How can the identity of decacarbonyl be confirmed?", "answer": "mass spectrometry", "ae_score": -0.1967818979395881, "qg_score": null}, {"question": "How can the identity of decacarbonyl be confirmed?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "The crystal structure of Re(CO) is relatively well known. The compound consists of a pair of square pyramidal Re(CO) units linked by a Re-Re bond. There are two different conformations that can occur: staggered and eclipsed. The eclipsed conformation occurs about 30% of the time, producing a D point group, but the staggered form, with point group D, is more stable. The Re-Re bond length was experimentally found to be 3.04\u00c5.\nThe Re atom exists in a slightly distorted octahedral configuration with the C axial-Re-C equatorial angle equal to 88\u00b0. The mean Re-C bond length of 2.01 \u00c5 is the same for the axial and equatorial positions. The mean C-O distance is 1.16 \u00c5.\nThis compound has a broad IR absorption band at 1800 cm region can be assigned to two components centered at 1780 and 1830 cm, resulting from CO adsorption. The remaining nine CO groups in Re(CO) give the complex IR absorption in the 1950\u20132150 cm region.  Free Re(CO) (point symmetry  D ) has a CO stretch representation of 2A+E + E+ 2B +E, where 2B + E are IR active.  For an axially perturbed (C) Re(CO) molecule, the CO stretch representation was found to be  2E+B+B+3A, where the IR active modes are 2E+3A.\nIts identity can also be confirmed by mass spectrometry, using the isotopic pattern of rhenium (Re and Re).", "page_name": "Dirhenium decacarbonyl", "page_id": "Dirhenium%20decacarbonyl", "heading": "Structure and properties", "sub_heading": "Structure and properties", "_id": "3000009805--1---1---1", "title": "The Crystal Structure of Re(CO)"}
{"qas": [{"question": "What is silicon nanowire and why is it important?", "answer": ""}, {"question": "What is the voltage of a silicon nanowire battery?", "answer": "3.4V", "ae_score": -0.3134175978004796, "qg_score": null}, {"question": "What type of battery is made up of silicon anodes?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Silicon is a desirable material for lithium battery anodes because it offers extremely desirable material properties. Silicon has a low discharge potential and a high theoretical charge capacity ten times higher than that of typical graphite anodes currently used in industry. Nanowires could improve these properties by increasing the amount of available surface area in contact with the electrolyte, thereby increasing the anode\u2019s power density and allowing for faster charging and higher current delivery. However, the use of silicon anodes in batteries have been limited by the volume expansion during lithiation. Silicon swells by 400% as it intercalates lithium during charging, resulting in degradation of the material. This volume expansion occurs anisotropically, caused by crack propagation immediately following a moving lithiation front. These cracks result in pulverization and substantial capacity loss noticeable within the first few cycles.\nResearch done at Stanford University indicates that  silicon nanowires (SiNWs) grown directly on the current collector (via VLS growth methods) are able to circumvent the negative effects associated with volume expansion. This geometry lends itself to several advantages. First, the nanowire diameter allows for improved accommodation of volume changes during lithiation without fracture. Second, each nanowire is attached to the current collector such that each can contribute to the overall capacity. Third, the nanowires are direct pathways for charge transport; in particle-based electrodes, charges are forced to navigate interparticle contact areas (a less efficient process). Silicon Nanowires have a theoretical capacity of roughly 4,200 mAh g^-1, which is larger than the capacity of other forms of silicon. This value indicates a significant improvement over graphite, which has a theoretical capacity of 372 mAh g^-1.\nAdditional research has involved depositing a carbon coating onto the silicon nanowires, which helps stabilize the material such that a stable solid electrolyte interphase (SEI) forms. An SEI is an inevitable byproduct of the electrochemistry that occurs in the battery; its formation contributes to decreased capacity in the battery since it is an electrically insulating phase (despite being ionically conductive). It can also dissolve and reform over multiple battery cycles. Hence, a stable SEI is preferable in order to prevent continued capacity loss as the battery is used. When carbon is coated onto silicon nanowires, capacity retention has been observed at 89% of the initial capacity after 200 cycles. This capacity retention is on par with that of graphitic anodes today.\nOne design uses a stainless steel anode covered in Silicon Nanowires. Silicon stores ten times more lithium than graphite, offering increased energy density. The large surface area increases the anode's power density, allowing for fast charging and high current delivery. The anode was invented at Stanford University in 2007.\nIn September 2010, researchers demonstrated 250 charge cycles maintaining above 80 percent of initial storage capacity. However, some studies pointed out that Si nanowire anodes shows significant fade in energy capacity with more charge cycles caused by the volumetric expansion of Si nanowires during lithiation process. Researchers has proposed many solutions to remedy this problem: published results in 2012 showed doping impurities to the nanowire anode improves the battery performance, and it is shown that phosphorus doped Si nanowires achieved better performance compared with boron and undoped nanowire electrode; researchers also demonstrated the possibility of sustaining an 85% of initial capacity after cycling over 6,000 times by replacing nominally undoped silicon anode into a doubled-walled silicon nanotube with silicon oxide ion-permeating layer as coating.\nThe silicon nanowire-based battery cell also provides opportunity for dimensional flexible energy source, which would also leads to the development of wearable technological device. Scientist from Rice University showed this possibility by depositing porous copper nanoshells around the silicon nanowire within a polymer matrix. This lithium-polymer silicon nanowire battery (LIOPSIL) has a sufficient operational full cell voltage of 3.4V and is mechanically flexible and scalable.\nCommercialization was originally expected to occur in 2012, but was later deferred to 2014.<ref name=time/> A related company, Amprius, shipped a related device with silicon and other materials in 2013. Canonical announced on July 22, 2013, that its Ubuntu Edge smartphone would contain a silicon-anode lithium-ion battery.\nIn January 2015, EaglePicher announced that it has signed an engineering agreement and a license agreement with OneD Material, a spin-out from Nanosys, to vertically integrate the production of a \"silicon nanowire on graphite\" anode called SiNANOde into new high energy density cells and batteries manufactured in Joplin, Missouri.", "page_name": "Nanowire battery", "page_id": "Nanowire%20battery", "heading": "Silicon", "sub_heading": "Silicon", "_id": "3000010874--0---1---1", "title": "Silicon Nanowires in Lithium Batteries"}
{"qas": [{"question": "Germanium nanowires?", "answer": ""}, {"question": "How many times more effective is germanium in intercalating lithium than silicon?", "answer": "400", "ae_score": null, "qg_score": null}, {"question": "Germanium is 400 times more effective at intercalating lithium than what other metal?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "An anode using germanium nanowire was claimed to have the ability to increase the energy density and cycle durability of lithium-ion batteries. Like silicon, germanium has a high theoretical capacity (1600 mAh g-1), expands during charging, and disintegrates after a small number of cycles. However, germanium is 400 times more effective at intercalating lithium than silicon, making it an attractive anode material. The anodes claimed to retain capacities of 900 mAh/g after 1100 cycles, even at discharge rates of 20\u2013100C. This performance was attributed to a restructuring of the nanowires that occurs within the first 100 cycles to form a mechanically robust, continuously porous network. Once formed, the restructured anode loses only 0.01% of capacity per cycle thereafter. The material forms a stable structure after these initial cycles that is capable of withstanding pulverization. In 2014, researchers at Missouri University of Science and Technology developed a simple way to produce nanowires of germanium from an aqueous solution.", "page_name": "Nanowire battery", "page_id": "Nanowire%20battery", "heading": "Germanium", "sub_heading": "Germanium", "_id": "3000010874--1---1---1", "title": "Germanium Nanowires Can Increase Energy Density and Durability of Lithium Batterie"}
{"qas": [{"question": "Why is the probability of a crack greater than the chance of the crack breaking?", "answer": ""}, {"question": "If t is the number of cycles to failure then what is the function called?", "answer": "the cumulative distribution function", "ae_score": -0.23523474279287157, "qg_score": null}, {"question": "What is it called when a crack is placed under repeated stresses?", "answer": "distribution cycles", "ae_score": null, "qg_score": null}], "content": "This distribution was developed to model failures due to cracks. A material is placed under repeated cycles of stress. The ''j'' cycle leads to an increase in the crack by ''X'' amount. The sum of the ''X'' is assumed to be normally distributed with mean ''n\u03bc'' and variance ''n\u03c3''. The probability that the crack does not exceed a critical length ''\u03c9'' is\nwhere ''\u03a6''() is the cdf of normal distribution.\nIf ''T'' is the number of cycles to failure then the cumulative distribution function (cdf) of ''T'' is\nThe more usual form of this distribution is:\nHere ''\u03b1'' is the shape parameter and ''\u03b2'' is the location parameter.", "page_name": "Birnbaum\u2013Saunders distribution", "page_id": "Birnbaum%E2%80%93Saunders%20distribution", "heading": "Theory", "sub_heading": "Theory", "_id": "3000011112--0---1---1", "title": "Birnbaum\u2013Saunders distribution | Theory"}
{"qas": [{"question": "What is the difference between bacterial conjugation and bacterial adaptation?", "answer": ""}, {"question": "What process involves the incorporation of foreign dna into the bacterial chromosome?", "answer": "bacterial transformation", "ae_score": -0.42107341250020386, "qg_score": null}, {"question": "What part of a host cell is used for sexual reproduction?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "Three distinct processes in prokaryotes are regarded as similar to eukaryotic sex: bacterial transformation, which involves the incorporation of foreign DNA into the bacterial chromosome; bacterial conjugation, which is a transfer of plasmid DNA between bacteria, but the plasmids are rarely incorporated into the bacterial chromosome; and gene transfer and genetic exchange in archaea.\nBacterial transformation involves the recombination of genetic material and its function is mainly associated with DNA repair. Bacterial transformation is a complex process encoded by numerous bacterial genes, and is a bacterial adaptation for DNA transfer. This process occurs naturally in at least 40 bacterial species. For a bacterium to bind, take up, and recombine exogenous DNA into its chromosome, it must enter a special physiological state referred to as competence (see Natural competence). Sexual reproduction in early single-celled eukaryotes may have evolved from bacterial transformation, or from a similar process in archaea (see below).\nOn the other hand, bacterial conjugation is a type of direct transfer of DNA between two bacteria through an external appendage called the conjugation pilus. Bacterial conjugation is controlled by plasmid genes that are adapted for spreading copies of the plasmid between bacteria. The infrequent integration of a plasmid into a host bacterial chromosome, and the subsequent transfer of a part of the host chromosome to another cell do not appear to be bacterial adaptations.\nExposure of hyperthermophilic archaeal Sulfolobus species to DNA damaging conditions induces cellular aggregation accompanied by high frequency genetic marker exchange.  Ajon et al. hypothesized that this cellular aggregation enhances species-specific DNA repair by homologous recombination.  DNA transfer in Sulfolobus may be an early form of sexual interaction similar to the more well-studied bacterial transformation systems that also involve species-specific DNA transfer leading to homologous recombinational repair of DNA damage.", "page_name": "Sexual reproduction", "page_id": "Sexual%20reproduction", "heading": "Bacteria and archaea", "sub_heading": "Bacteria and archaea", "_id": "3000011390--6---1---1", "title": "Bacterial Conjugation in Archaea"}
{"qas": [{"question": "Cycle double cover conjecture?", "answer": ""}, {"question": "When can a bridgeless graph be covered by using the same cycle?", "answer": "more than once", "ae_score": -2.19486914202148, "qg_score": null}, {"question": "When can a bridgeless graph be covered by using the same cycle?", "answer": "more than once", "ae_score": -2.19486914202148, "qg_score": null}], "content": "The usual formulation of the cycle double cover conjecture asks whether every bridgeless undirected graph has a collection of cycles such that each edge of the graph is contained in exactly two of the cycles. The requirement that the graph be bridgeless is an obvious necessary condition for such a set of cycles to exist, because a bridge cannot belong to any cycle. A collection of cycles satisfying the condition of the cycle double cover conjecture is called a '''cycle double cover'''. Some graphs such as cycle graphs and bridgeless cactus graphs can only be covered by using the same cycle more than once, so this sort of duplication is allowed in a cycle double cover.", "page_name": "Cycle double cover", "page_id": "Cycle%20double%20cover", "heading": "Formulation", "sub_heading": "Formulation", "_id": "3000011548--0---1---1", "title": "The Cycle Double Cover Conjecture"}
{"qas": [{"question": "Who are the credited scientists for the creation of the universe?", "answer": ""}, {"question": "Who is credited with developing the nanoball battery?", "answer": "Byoungwoo Kang", "ae_score": -0.31051157064144974, "qg_score": null}, {"question": "What type of materials are nanoballs made of?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "Nanoball batteries show a lot of potential but improvements have to be made before they become a viable option to replace current batteries.  Future research would include trying to integrate the nanoballs into the cathode of a lithium cell or merging nanoballs with other materials like silicon in batteries.  Research done at the School of Material Science and Engineering at East China University of Science and Technology has shown that coating silicon nanoballs with a graphene/carbon coating keeps the silicon nanoball from degrading too quickly and improving the overall electromechanical performance of the battery. For commercial use in cars and other electrical vehicles, the nanoball battery would need to be able to charge the vehicle using less energy.  Even though the battery can discharge very quickly, too much energy is needed to go into the battery.  Another issue that needs correcting is that even though the battery can discharge very quickly, it has difficulty holding on to that much energy for very long.  Increasing the limit of how much energy the battery could hold would make the battery much more efficient.  The technology may also allow for smaller batteries as the cathode material degrades at a slower rate than in current production batteries.\nThe credited scientists are Byoungwoo Kang and Gerbrand Ceder.", "page_name": "Nanoball batteries", "page_id": "Nanoball%20batteries", "heading": "Future", "sub_heading": "Future", "_id": "3000012278--3---1---1", "title": "Nanoball Batteries Show Potential but Need Improvements"}
{"qas": [{"question": "What causes hearing loss?", "answer": ""}, {"question": "How many dB correction can be made for elderly hearing loss?", "answer": "10", "ae_score": null, "qg_score": null}, {"question": "What is a neurological condition that can cause hearing loss?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Similarly to vision loss, hearing loss can vary from full or partial inability to detect some or all frequencies of sound which can typically be heard by members of their species.  For humans, this range is approximately 20 Hz to 20 kHz at ~6.5 dB, although a 10 dB correction is often allowed for the elderly.  Primary causes of hearing loss due to an impaired sensory system include long-term exposure to environmental noise, which can damage the mechanoreceptors responsible for receiving sound vibrations, as well as multiple diseases, such as HIV or meningitis, which damage the cochlea and auditory nerve, respectively.\nHearing loss may be gradual or sudden. Hearing loss may be very mild, resulting in minor difficulties with conversation, or as severe as complete deafness. The speed with which hearing loss occurs may give clues as to the cause. If hearing loss is sudden, it may be from trauma or a problem with blood circulation. A gradual onset is suggestive of other causes such as aging or a tumor. If you also have other associated neurological problems, such as tinnitus or vertigo, it may indicate a problem with the nerves in the ear or brain. Hearing loss may be unilateral or bilateral. Unilateral hearing loss is most often associated with conductive causes, trauma, and acoustic neuromas. Pain in the ear is associated with ear infections, trauma, and obstruction in the canal.", "page_name": "Sensory loss", "page_id": "Sensory%20loss", "heading": "Hearing loss", "sub_heading": "Hearing loss", "_id": "3000019050--1---1---1", "title": "Hearing Loss Symptoms, Causes, and Treatments"}
{"qas": [{"question": "Why is the Conservative Institute of Slovakia recognized as one of the best universities in the world?", "answer": ""}, {"question": "What is the name of the website that promotes transparency in government?", "answer": "Sunshine Review", "ae_score": -0.08782132895334956, "qg_score": null}, {"question": "What is the name of the website that promotes transparency in government?", "answer": "Sunshine Review", "ae_score": -0.08782132895334956, "qg_score": null}], "content": "The following awards were made in 2009:\nThe New Economic School in the Republic of Georgia was selected for their efforts to influence the political debate in favor of free-market policies.\nThe Free Market Foundation of South Africa won for publishing the book \"Jobs for the Jobless\", a condemnation of South African labor laws said to lead to widespread unemployment.\nSamasource won for its programs that offer training to small businesses in Africa and introduce them to American clients.\nFundaci\u00f3n Paraguaya was selected for its San Francisco Agricultural School that trains poor youth to become entrepreneurs.\nThe Conservative Institute of Slovakia was recognized for its lecture programs that have hosted distinguished speakers on the topics of economics and ethics since 2005\nThe Globalization Institute won for publishing \"The Mythology of the Greenhouse Effect\", right before the 2008 United Nations Climate Change Conference in Pozna\u0144.\nThe Foundation for Individual Rights in Education won for its Campus Freedom Network, an effort to educate students and organize them to be activists for individual liberty.\nInstitute Invertir of Peru received an award for its program bringing over 200 top university students from all over Peru to learn how to start and run a their own businesses.\nThe Centre for Civil Society (India) was recognized for its School Choice Campaign operating in seven states for its successful awareness through street theater campaign in the states of Rajasthan and Orissa, demonstration at the political rally sites of the 2009 general election, and 151 news stories in one year.\nThe Institute for Information on the Crimes of Communism of Sweden was awarded a prize for its approach to communicating problems under communist rule.\nThe Sam Adams Alliance was recognized for Sunshine Review, a website dedicated to government transparency.\nThe Free to Choose Network won for its video website, Izzit.org.\nThe Center for Ethics and Entrepreneurship at Rockford College won for launching six courses focusing on the ethics of entrepreneurship and the ethical foundations of free society.\nThe Center for Entrepreneurship and Innovation at Universidad del Desarrollo in Chile was recognized for high quality research on entrepreneurship and improving curricula and teaching methods.\nInstituto Millenium of Brazil won for attracting more than 1000 students to two forums, placing more than 100 articles in newspapers and magazines, producing 30 online videos, publishing two books, and publishing a weekly newsletter with over 5000 subscribers.\nThe Egyptian Union of Liberal Youth won for starting one of the first essay contests in the Arabic world in cooperation with the Friedrich Naumann Foundation asking students to answer the question: \u201cWhy am I a liberal?\u201d The program received attention from 6 major newspapers, a youth radio station, and two major Egyptian political parties.", "page_name": "Templeton Freedom Awards", "page_id": "Templeton%20Freedom%20Awards", "heading": "2009 awards", "sub_heading": "2009 awards", "_id": "3000019146--2---1---1", "title": "The Best Awards of the Year in 2009"}
{"qas": [{"question": "Why is autism so much more prevalent in the US than it is in other developed countries?", "answer": ""}, {"question": "When was the first autism movie made?", "answer": "1988", "ae_score": -0.4839592704282122, "qg_score": null}, {"question": "The social and cultural aspects of autism are known as?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Much of the public perception of autism is based on its portrayals in biographies, movies, novels, and TV series. Many of these portrayals have been inaccurate, and have contributed to a harmful divergence between public perception and the clinical reality of autism. For example, in the movie ''Mozart and the Whale'' (2005), the opening scene gives four clues that a leading character has Asperger syndrome, and two of these clues are extraordinary savant skills. The savant skills are not needed in the film, but in the movies savant skills have become a stereotype for the autism spectrum, regardless of the fact that most autistic people are not savants.\nSome works from the 1970s have autistic characters, who are rarely labeled. In contrast, in the BBC2 television miniseries  ''The Politician's Husband'' (2013), the impact of Noah Hoynes' Aspergers on the boy's behavior and on his family, and steps Noah's loved ones take to accommodate and address it, are prominent plot points in all three episodes.\nThe Internet has furthered understanding of autism, although incorrect online articles have also hurt public perception.\nMass media has begun to portray autism in a better light, despite the controversy over vaccinations,  and has depicted special talents of some children with autism, including exceptional abilities as seen in the movie ''Rain Man'' (1988).", "page_name": "Sociological and cultural aspects of autism", "page_id": "Sociological%20and%20cultural%20aspects%20of%20autism", "heading": "Media portrayals", "sub_heading": "Media portrayals", "_id": "3000024153--6---1---1", "title": "Public Perceptions of Autism"}
{"qas": [{"question": "Why is it so hard to learn to trust a religion?", "answer": ""}, {"question": "What are the foundations of all ethical decisions?", "answer": "Trust relationships", "ae_score": -0.2195717260146741, "qg_score": null}, {"question": "What are the foundations of all ethical decisions?", "answer": "Trust relationships", "ae_score": -0.2195717260146741, "qg_score": null}], "content": "Trust relationships are the foundations of all ethical decisions. One must learn what is good and ethical from some role model or moral example. Religion often raises certain stories about certain people to this level deliberately.", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "Ethical decision-making in eastern religions", "_id": "3000027997--2--0---1", "title": "Trust relationships are the foundations of all ethical decisions."}
{"qas": [{"question": "How do we know what we are supposed to do?", "answer": ""}, {"question": "What is the term for moral judgement?", "answer": "normative ethics", "ae_score": -0.2772513180849328, "qg_score": null}, {"question": "What is the term for moral judgement?", "answer": "normative ethics", "ae_score": null, "qg_score": null}], "content": "All ethical and moral judgement attempts to make consistent descriptions of complex situations and difficult decisions.  It is considered to be important because, to those who practice the ethical tradition in which the descriptions are applied, it answers the big question: \"How should we live?\"\nThe very questions presupposes that we can define \"how\" (method), \"should\" (ambition), \"we\" (a group seeking consensus), \"live\" (beings with bodies).\nWithout this context, ethics is generally just talk implying moral judgement ''- called normative ethics, and covered again in separate article.''\nThe remainder of this article is about practical approaches to '''ethical decision'''s that are observed in ordinary people's daily lives and in politics in particular:", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "Consistent description", "_id": "3000027997--2--1---1", "title": "How should we live?''"}
{"qas": [{"question": "What would happen if a war broke out between the US and Russia?", "answer": ""}, {"question": "What is unlikely to recur at this point?", "answer": "the conflict", "ae_score": -0.4169300213783741, "qg_score": null}, {"question": "What is unlikely to recur at this point?", "answer": "the conflict", "ae_score": -0.4169300213783741, "qg_score": null}], "content": "An ethical decision is often thought of as the one that reduces future conflict.  In sociology and political science, practical and applied ethics itself is often defined as a process of de-escalating moral conflicts to the point of:\nAt this point the conflict is unlikely to recur.", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "De-escalating", "_id": "3000027997--2--2---1", "title": "Ethical Decisions \u2014 The Process of De-escalating Conflicts"}
{"qas": [{"question": "Why is violence so common in the US?", "answer": ""}, {"question": "\"i am right and you are wrong and you do what i say\" is called?", "answer": "moral absolutism", "ae_score": -0.27585081538249684, "qg_score": null}, {"question": "\"i am right and you are wrong and you do what i say\" is called?", "answer": "moral absolutism", "ae_score": -0.27585081538249684, "qg_score": null}], "content": "Without this, we fall back to the simplistic view, which is \"I am right and you are wrong and you do what I say.\" (''This is usually called moral absolutism'').  This kind of assertion, backed by force, is the basis of much authority and it leads to violence very often.  So much so that it turns out not to be the simplest way to live among humans in the long run, even if it is accepted by small groups (say a whole family) in the short run.", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "Avoiding right vs. wrong", "_id": "3000027997--2--3---1", "title": "I am right and you are wrong and you do what I say''"}
{"qas": [{"question": "What is the difference between right and wrong?", "answer": ""}, {"question": "How many individuals must assert \"right\" and require ethical help?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many individuals must assert \"right\" and require ethical help?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "A simple, practical view is that ethics balances \"right versus right\":  if there's a dispute we care to hear, then each side must have some right on it.  However, this presupposes some instinctive moral core of the individual that must recognize right and wrong, else we do not have two individuals asserting \"right\" and requiring ethical help:  if either in fact secretly believes themselves \"wrong\" then they are engaging in tactics to reduce the chance of getting caught or alerting others to it, neither of which is studied by ethics.", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "Right versus right", "_id": "3000027997--2--4---1", "title": "Ethics: Right vs. Right"}
{"qas": [{"question": "Why is it so hard for police officers to find a suspect in a murder case?", "answer": ""}, {"question": "What rests on a moral fulcrum of pre-existing assumptions?", "answer": "Ethics", "ae_score": -0.7674056372118458, "qg_score": null}, {"question": "What rests on a moral fulcrum of pre-existing assumptions?", "answer": "Ethics", "ae_score": -0.7674056372118458, "qg_score": null}], "content": "Ethics can thus be viewed as a lever but one that rests on a moral fulcrum of pre-existing assumptions, like the bodies of the beings in conflict, placed there by circumstances, environments, situations, mostly out of their control - only the choice of resolution is under their own control.  When the environment or context has some status in the decision, as in ecological ethics, there is said to be a situated ethics.\n''This is not the same as situational ethics which is about single decisions unlikely to recur.''", "page_name": "Ethical decision", "page_id": "Ethical%20decision", "heading": "Ethical decision-making in eastern religions", "sub_heading": "An environment or context", "_id": "3000027997--2--5---1", "title": "Ethical decision | Ethical decision-making in eastern religions | An environment or context"}
{"qas": [{"question": "What is the difference between high functioning autism and Asperger syndrome?", "answer": ""}, {"question": "What are the symptoms of autism spectrum disorder?", "answer": "anxiety", "ae_score": -0.19511906685466268, "qg_score": null}, {"question": "What are the symptoms of autism spectrum disorder?", "answer": "anxiety", "ae_score": -0.19511906685466268, "qg_score": null}], "content": "High-functioning autism is characterized by features very similar to those of Asperger syndrome. The defining characteristic most widely recognized by psychologists is a significant delay in the development of early speech and language skills, before the age of three years. The diagnostic criteria of Asperger syndrome exclude a general language delay.\nFurther differences in features between people with high-functioning autism and those with Asperger syndrome, include the following: \nIndividuals with autism spectrum disorders, including high-functioning autism, risk developing symptoms of anxiety. While anxiety is one of the most commonly occurring mental health symptoms, children and adolescents with high functioning autism are at an even greater risk of developing symptoms.\nThere are other comorbidities, the presence of one or more disorders in addition to the primary disorder, associated with high-functioning autism. Some of these include depression, bipolar disorder, and obsessive compulsive disorder (OCD). In particular the link between HFA and OCD, has been studied; both have abnormalities associated with serotonin.\nObservable comorbidities associated with HFA include ADHD, Tourette syndrome, and possibly criminal behavior. While the association between HFA and criminal behavior is not completely characterized, several studies have shown that the features associated with HFA may increase the probability of engaging in criminal behavior. While there is still a great deal of research that needs to be done in this area, recent studies on the correlation between HFA and criminal actions suggest that there is a need to understand the attributes of HFA that may lead to violent behavior. There have been several case studies that link the lack of empathy and social na\u00efvet\u00e9 associated with HFA to criminal actions.\nHFA does not cause nor include intellectual disabilities. This characteristic distinguishes HFA from the rest of the autism spectrum; between 40 and 55% of individuals with autism also have an intellectual disability.", "page_name": "High-functioning autism", "page_id": "High-functioning%20autism", "heading": "Characterization", "sub_heading": "Characterization", "_id": "3000028045--0---1---1", "title": "High-Focunding Autism and Criminal Behavior"}
{"qas": [{"question": "What is a bounce in string theory?", "answer": ""}, {"question": "What is predicted to play an essential role stabilizing the cycle?", "answer": "Dark energy", "ae_score": -0.41645943430518356, "qg_score": null}, {"question": "What is predicted to play an essential role stabilizing the cycle?", "answer": "Dark energy", "ae_score": -0.41645943430518356, "qg_score": null}], "content": "Steinhardt has been a leading developer of cyclic and ekpyrotic cosmology.\nWorking with Justin Khoury, Burt A. Ovrut and Neil Turok, Steinhardt introduced the ekpyrotic theory, which imagines a big bounce instead of a big bang. According to this model, the current expanding universe emerges from a bounce that occurred 13.7 billion years ago and that is a result of the preceding (contracting) universe.  The smoothing and flattening of the universe and the generation of density variations occur during the phase of slow contraction before the bounce and remain after the bounce.\nIn the original example, the bounce corresponded to a collision and recoil of branes along an extra dimension in string theory (brane is derived from \"membrane,\" a basic object in string theory). But more recent versions do not require extra dimensions or string theory; instead, quantum fields with potential energy evolving in space-time, similar to inflationary models, can be used.  \nSteinhardt and Turok then incorporated the ekpyrotic idea into a bolder proposal: the cyclic theory of the universe.\nAccording to this model, the bounce represents the end of a cycle of evolution, the transition between a preceding period of contraction and the next period of expansion. This cycle repeats at regular intervals every trillion years or so.  Dark energy is predicted by the model and plays an essential role stabilizing the cycles. Steinhardt and Turok proved that the cyclic process can repeat itself not just indefinitely, but also infinitely into the past and the future.", "page_name": "Paul Steinhardt", "page_id": "Paul%20Steinhardt", "heading": "Cyclic/ekpyrotic theory of the universe", "sub_heading": "Cyclic/ekpyrotic theory of the universe", "_id": "3000028469--2--0---1", "title": "Steinhardt and Turok: The Cyclic Theory of the Universe"}
{"qas": [{"question": "What is the difference between a cyclic model and a new model?", "answer": ""}, {"question": "When does the universe contract and the entropy produced in previous cycles lies within the observable universe?", "answer": "the beginning of the next cycle", "ae_score": null, "qg_score": null}, {"question": "When does the universe contract and the entropy produced in previous cycles lies within the observable universe?", "answer": "the beginning of the next cycle", "ae_score": null, "qg_score": null}], "content": "Earlier cyclic-type cosmological models had an entropy problem that the new cyclic model evades.  According to the second law of thermodynamics, entropy always increases.  The entropy produced in one cycle adds to the entropy produced in earlier cycles. If the universe contracts and the entropy produced in previous cycles lies within the observable universe at the beginning of the next cycle, the added entropy will cause the next cycle to be longer than the one before; or, projecting backwards in time, earlier cycles would have to be shorter and shorter, eventually reducing to zero duration.  This reintroduces the problem that time must have a beginning.  In the new cyclic model, the observable universe just after a bounce only occupies a tiny fraction of the space occupied by the observable universe a cycle earlier and so only contains a negligible fraction of the total entropy.  The entropy building up over the cycles is almost entirely beyond what can be seen and cannot influence the next cycle.\nCyclic models have two big advantages over inflationary models.  First, they do not produce a multiverse because the smoothing and flattening occur during contraction rather than inflation.   This means that, unlike inflation,  cyclic models make definite predictions and are falsifiable.  Second, cyclic models explain why there must be dark energy.  The accelerated expansion caused by dark energy starts the smoothing process and the decay of dark energy starts the contraction.", "page_name": "Paul Steinhardt", "page_id": "Paul%20Steinhardt", "heading": "Cyclic/ekpyrotic theory of the universe", "sub_heading": "Notable features", "_id": "3000028469--2--1---1", "title": "The New Cyclic Model Explains Why There Must be Dark Energy"}
{"qas": [{"question": "What is the significance of the Higgs Boson discovery?", "answer": ""}, {"question": "What may explain why the cosmological constant is exponentially small and positive?", "answer": "The cyclic model", "ae_score": -0.8133671778641284, "qg_score": null}, {"question": "What may explain why the cosmological constant is exponentially small and positive?", "answer": "The cyclic model", "ae_score": -0.8133671778641284, "qg_score": null}], "content": "Because cyclic/ekpyrotic models do not produce a multiverse, they make definite predictions which, if shown to be wrong, disprove the theory.  One prediction is that, unlike inflation, no detectable gravitational waves are generated during the smoothing and flattening process.  A second prediction is that the current acceleration expansion must eventually stop and the vacuum must be eventually decay in order to initiate the next cycle.  (Other predictions depend on the specific fields (or branes) that cause the contraction.)\nThe cyclic model may naturally explain why the cosmological constant is exponentially small and positive, compared to the enormous value expected by quantum gravity theories.  The cosmological constant might begin large, as expected, but then slowly decay over the course of many cycles to the tiny value observed today.\nThe discovery of the Higgs field at the Large Hadron Collider (LHC) may provide added support for the cyclic model.  Evidence from the LHC suggests that the current vacuum may decay in the future, according to calculations made by Steinhardt, Turok and Itzhak Bars. The decay of the current vacuum is required by the cyclic model in order to end the current phase of expansion, contract, bounce and a new era of expansion; the Higgs provides a possible mechanism of decay that can be tested. The Higgs field is a viable candidate for the field that drives the cycles of expansion and contraction.", "page_name": "Paul Steinhardt", "page_id": "Paul%20Steinhardt", "heading": "Cyclic/ekpyrotic theory of the universe", "sub_heading": "Predictions", "_id": "3000028469--2--2---1", "title": "The Higgs Field at the Large Hadron Collider (LHC) Could Support"}
{"qas": [{"question": "Why is it that some people with autism are able to remember things better than others?", "answer": ""}, {"question": "Where is the marble located in the sally anne test?", "answer": "the pocket of the investigator", "ae_score": -0.3651826816718174, "qg_score": null}, {"question": "The sally-anne test is used to test the theory of?", "answer": "mind autism", "ae_score": null, "qg_score": null}], "content": "While Baron-Cohen et al.'s data have been purported to indicate a lack of theory of mind in autistic children, there are other possible factors affecting them. For instance, individuals with autism may pass the cognitively simpler recall task, but language issues in both autistic children and deaf controls tend to confound results.\nRuffman, Garnham, and Rideout (2001) further investigated links between the Sally\u2013Anne test and autism in terms of eye gaze as a social communicative function. They added a third possible location for the marble: the pocket of the investigator.  When autistic children and children with moderate learning disabilities were tested in this format, they found that both groups answered the Belief Question equally well; however, participants with moderate learning disabilities reliably looked at the correct location of the marble, while autistic participants did not, ''even if'' the autistic participant answered the question correctly. These results may be an expression of the social deficits relevant to autism.\nTager-Flusberg (2007) states that in spite of the empirical findings with the Sally-Anne task, there is a growing uncertainty among scientists about the importance of the underlying theory-of-mind hypothesis of autism. In all studies that have been done, some children with autism pass false-belief tasks such as Sally-Anne.", "page_name": "Sally\u2013Anne test", "page_id": "Sally%E2%80%93Anne%20test", "heading": "Criticism", "sub_heading": "Criticism", "_id": "3000029205--2---1---1", "title": "The Theory of Mind Hypothesis of Autism"}
{"qas": [{"question": "How did we determine the age of ancient sediments?", "answer": ""}, {"question": "Where is luminescence dating used in mongolia?", "answer": "Lake Ulaan", "ae_score": null, "qg_score": null}, {"question": "What type of radiocarbon is used for luminescence dating?", "answer": "radiocarbon", "ae_score": null, "qg_score": null}], "content": "Unlike carbon-14 dating, luminescence dating methods do not require a contemporary organic component of the sediment to be dated; just quartz, potassium feldspar, or certain other mineral grains that have been fully bleached during the event being dated. These methods also do not suffer from overestimation of dates when the sediment in question has been mixed with \u201cold carbon\u201d, or -deficient carbon that is not the same isotopic ratio as the atmosphere. In a study of the chronology of arid-zone lacustrine sediments from Lake Ulaan in southern Mongolia, Lee et al. discovered that OSL and radiocarbon dates agreed in some samples, but the radiocarbon dates were up to 5800 years older in others.\nThe sediments with disagreeing ages were determined to be deposited by aeolian processes.  Westerly winds delivered an influx of -deficient carbon from adjacent soils and Paleozoic carbonate rocks, a process that is also active today. This reworked carbon changed the measured isotopic ratios, giving a false older age. However, the wind-blown origin of these sediments were ideal for OSL dating, as most of the grains would have been completely bleached by sunlight exposure during transport and burial. Lee et al. concluded that when aeolian sediment transport is suspected, especially in lakes of arid environments, the OSL dating method is superior to the radiocarbon dating method, as it eliminates a common \u2018old-carbon\u2019 error problem.", "page_name": "Luminescence dating", "page_id": "Luminescence%20dating", "heading": "Comparison to radiocarbon dating", "sub_heading": "Comparison to radiocarbon dating", "_id": "3000030146--4---1---1", "title": "OSL and Radiocarbon Dating in Lake Ulaan"}
{"qas": [{"question": "What is the difference between a boy and an autistic child?", "answer": ""}, {"question": "Who came up with the distinction between verstehen and einf\u00fchlung?", "answer": "Robert Vischer", "ae_score": -0.2104469699084542, "qg_score": null}, {"question": "The empathizing systemizing theory ( e-s ) is a theory of?", "answer": "mind autism", "ae_score": null, "qg_score": null}], "content": "E-S theory was developed by psychologist Simon Baron-Cohen as a major reconceptualization of cognitive sex differences in the general population and in an effort to understand why the cognitive difficulties in autism appeared to lie in domains in which he says on average females outperformed males and why cognitive strengths in autism appeared to lie in domains in which on average males outperformed females.\nHe had previously proposed the mind-blindness theory in 1985, which argued that children with autism are delayed in their development of a theory of mind, that is, the ability to understand the thoughts and feelings of themselves or others. Baron-Cohen says a strength of this theory lies in its power to explain one of the core features of autism (the social and communication difficulties), but a limitation of the mindblindness theory is that it ignored the other main domain in autism (unusually narrow interests and highly repetitive behaviors, also called 'resistance to change or need for sameness'). To address this, Baron-Cohen put forward the E-S theory.\nSuch a distinction can be traced back to Robert Vischer in 1873 who postulated the as yet undescribed distinction between verstehen and einf\u00fchlung. it has become common to describe normative masculine pedagogical traits in boys and autistic children from this framework where parents and caregivers often mistakenly consider autistic children to be lacking in empathy.", "page_name": "Empathizing\u2013systemizing theory", "page_id": "Empathizing%E2%80%93systemizing%20theory", "heading": "History", "sub_heading": "History", "_id": "3000030990--0---1---1", "title": "The E-S Theory"}
{"qas": [{"question": "Why do people with autism tend to be more emotional than those with depression?", "answer": ""}, {"question": "How many major components are there in empathy?", "answer": "two", "ae_score": -0.23921472890631257, "qg_score": null}, {"question": "How many major components are there in empathy?", "answer": "two", "ae_score": -0.23921472890631257, "qg_score": null}], "content": "Empathy can been subdivided into two major components: \nStudies found that individuals with autism spectrum disorder (ASD) self-report lower levels of empathic concern, show less or absent comforting responses toward someone who is suffering, and report equal or higher levels of personal distress compared to controls.<ref name = response/> The combination of reduced empathic concern and increased personal distress may lead to the overall reduction of empathy in ASD.<ref name = response/>\nStudies also suggest that individuals with ASD may have impaired theory of mind, involving the ability to understand the perspectives of others. The terms ''cognitive empathy'' and ''theory of mind'' are often used synonymously, but due to a lack of studies comparing theory of mind with types of empathy, it is unclear whether these are equivalent.<ref name = Rogers/> Notably, many reports on the empathic de\ufb01cits of individuals with Asperger syndrome are actually based on impairments in theory of mind.<ref name = Rogers/>\nBaron-Cohen argued that psychopathy is associated with intact cognitive empathy but reduced affective empathy while ASD is associated with both reduced cognitive and affective empathy.", "page_name": "Empathizing\u2013systemizing theory", "page_id": "Empathizing%E2%80%93systemizing%20theory", "heading": "Cognitive versus affective empathy", "sub_heading": "Cognitive versus affective empathy", "_id": "3000030990--6---1---1", "title": "Empathy in Autism Spectrum Disorder: Cognitive and Affective Empathy"}
{"qas": [{"question": "Ka\u010d\u00e1k Event?", "answer": ""}, {"question": "What type of event is the ka\u010dak event?", "answer": "anoxic", "ae_score": -1.050021719424711, "qg_score": null}, {"question": "The ka\u010d\u00e1k event is a marked negative excursion in the \u03b4c?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "At the level of the Ka\u010d\u00e1k Event there is a marked negative excursion in the \u03b4C level, interpreted to be a result of the anoxic event. This reduction matches closely to an increase in both total organic carbon and a change in the fractionation of carbon between carbonates and organic 'reservoirs'.", "page_name": "Ka\u010d\u00e1k Event", "page_id": "Ka%C4%8D%C3%A1k%20Event", "heading": "Geochemistry", "sub_heading": "Geochemistry", "_id": "3000034501--2---1---1", "title": "The Ka\u00e1k Event and the Ka\u00e1k Event"}
{"qas": [{"question": "Lithium-Titanate Battery?", "answer": ""}, {"question": "What is the name of the battery that uses lithium titanate?", "answer": "lithium\u2013titanate battery", "ae_score": -0.9180394880240916, "qg_score": null}, {"question": "Where does lithium titanate come from in a battery?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "The lithium\u2013titanate battery is a rechargeable battery that is much faster to charge than other lithium-ion batteries. It differs from other lithium-ion batteries because it uses lithium-titanate on the anode surface rather than carbon. This is advantageous because it does not create an SEI layer (Solid Electrolyte Interface), which acts as a barrier to the ingress and egress of Li-ion to and from the anode. This allows lithium-titanate batteries to be recharged more quickly and provide higher currents when necessary.  A disadvantage of the lithium-titanate battery is a much lower capacity and voltage than the conventional lithium-ion battery. The lithium-titanate battery is currently being used in battery electric vehicles and other specialist applications.", "page_name": "Lithium titanate", "page_id": "Lithium%20titanate", "heading": "Lithium-titanate battery", "sub_heading": "Lithium-titanate battery", "_id": "3000035680--3---1---1", "title": "Lithium-Titanate Batteries \u2014 The Future of Batteries"}
{"qas": [{"question": "What is the difference between off-line and on-line sampling?", "answer": ""}, {"question": "What does ei stand for in aerosol mass spectrometry?", "answer": "electron ionization", "ae_score": -0.5207980314565881, "qg_score": null}, {"question": "What type of spectrometry is used for aerosol analysis?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "Off-line is an older method then on-line and involves the chemical analysis of sampled aerosols collected traditionally on filters or with cascade impactors (shown to the right) in the field and analyzed back in the lab. Cascade impactors collects particles as they transverse a series of impaction plates, and separate them based on size. The aerosol samples are analyzed by the coupling of pre-separation methods with mass spectrometry.  The benefit of this method relative to on-line sampling is greater molecular and structural speciation. The greater molecular and structural speciation is due to the pre-separation.  There are many different types of instrumentation used for the analysis due to various type and combinations of the ionization, separation, and mass detection methods. Not one combination is best for all samples, and as such depending on the need for analysis, different instrumentation is used.\nThe most commonly used ionization method for off-line instrument is electron ionization (EI) which is a hard ionization technique that utilized 70 eV to ionize the sample, which causes significant fragmentation that can be used in a library search to identify the compounds.  The separation method that EI is usually coupled with is gas chromatography (GC), where in GC the particles are separated by their boiling points and polarity, followed by solvent extraction of the samples collected on the filters.  An alternative to solvent-based extraction for particulates on filters is the use of thermal extraction (TE)-GC/MS, which utilizes oven interfaced with the GC inlet to vaporize the analyte of the sample and into the GC inlet.  This technique is more often used then solvent-based extraction, because of its better sensitivity, eliminates need for solvents, and can be fully automated.  To increase the separation of the particles the GC can be coupled with a time of flight (TOF)-MS, which is a mass separation method that separates ions based on their size.  Another method that utilizes EI is isotope ratio mass spectrometry (IR-MS) this instrumentation incorporates a magnetic sector analyzer and a faraday-collector detector array and separates ions based on their isotopic abundance.  Isotopic abundance of carbon, hydrogen, nitrogen, and oxygen isotopic abundance become locally enriched or depleted through a variety of atmospheric processes.  This information helps in determining the source of the aerosols and the interaction it has had.\nEI is a universal ionization method, but it does cause excessive fragmentation, and thus can be substituted with chemical ionization (CI) which is a much softer ionization method, and is often used to determine the molecular ion.  One ionization method the utilizes CI is atmospheric-pressure chemical ionization (APCI).  In APCI the ionization occurs at atmospheric pressure with ions produced by corona discharges on a solvent spray, and it is often coupled with high-performance liquid chromatography (HPLC) which provides quality determination of polar and ionic compounds in the collected atmospheric aerosols. The use of APCI allows for the sampling of the filters without the need of solvents for the extraction.  The APCI is typically connected to a quadruple mass spectrometer.\nOther ionization methods are often used for off-line mass spectrometer inductively coupled plasma (ICP).  ICP is commonly used in the elemental analysis of trace metals, and can be used to determine the source of the particles and there health effects.", "page_name": "Aerosol mass spectrometry", "page_id": "Aerosol%20mass%20spectrometry", "heading": "Off-line", "sub_heading": "Off-line", "_id": "3000036871--1---1---1", "title": "Off-line Analysis of Aerosols"}
{"qas": [{"question": "Ethical practices in language documentation?", "answer": ""}, {"question": "Who has brought the morality of language documentation protocols into question?", "answer": "George van Driem", "ae_score": -0.2449967182007585, "qg_score": null}, {"question": "Who has brought the morality of language documentation protocols into question?", "answer": "George van Driem", "ae_score": -0.2449967182007585, "qg_score": null}], "content": "Ethical practices in language documentation have been the focus of much recent discussion and debate. The Linguistic Society of America has prepared an Ethics Statement, and maintains an Ethics Discussion Blog which is primarily focused on ethics in the language documentation context. The morality of ethics protocols has itself been brought into question by George van Driem.", "page_name": "Language documentation tools and methods", "page_id": "Language%20documentation%20tools%20and%20methods", "heading": "Ethics", "sub_heading": "Ethics", "_id": "3000040144--3---1---1", "title": "Ethical practices in language documentation"}
{"qas": [{"question": "What is the difference between virtue and virtue?", "answer": ""}, {"question": "How many books did christina hoff sommers edit in the 1980s?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "What topic did christina hoff sommers write a book about in the 1980?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "During the mid-1980s, Sommers edited two philosophy textbooks on the subject of ethics:''Vice & Virtue in Everyday Life: Introductory Readings in Ethics'' (1984) and ''Right and Wrong: Basic Readings in Ethics'' (1986). Reviewing ''Vice and Virtue'' for ''Teaching Philosophy'' in 1990, Nicholas Dixon wrote that the book was \"extremely well edited\" and \"particularly strong on the motivation for studying virtue and ethics in the first place, and on theoretical discussions of virtue and vice in general.\"\nBeginning in the late 1980s, Sommers published a series of articles in which she strongly criticized feminist philosophers and American feminism in general<ref>Tom Digby, \"Political Correctness and the Fear of Feminism.\" ''The Humanist'' 52, no. 2 (March 1992), 7.", "page_name": "Christina Hoff Sommers", "page_id": "Christina%20Hoff%20Sommers", "heading": "Early works", "sub_heading": "Early works", "_id": "3000041696--2---1---1", "title": "Feminism and Feminism in the United States"}
{"qas": [{"question": "What is the difference between Asperger Syndrome and Autism?", "answer": ""}, {"question": "What does pd stand for in autism?", "answer": "pervasive developmental disorders", "ae_score": -0.6621066279914769, "qg_score": null}, {"question": "What does pd stand for in autism?", "answer": "pervasive developmental disorders", "ae_score": -0.6621066279914769, "qg_score": null}], "content": "The extent of the overlap between AS and high-functioning autism (HFA\u2014autism unaccompanied by intellectual disability) is unclear. The ASD classification is to some extent an artifact of how autism was discovered, and may not reflect the true nature of the spectrum; methodological problems have beset Asperger syndrome as a valid diagnosis from the outset. In the fifth edition of the ''Diagnostic and Statistical Manual of Mental Disorders'' (DSM-5), published in May 2013, AS, as a separate diagnosis, was eliminated and folded into autism spectrum disorder. Like the diagnosis of Asperger syndrome, the change was controversial and AS was not removed from the WHO's ICD-10.\nThe World Health Organization (WHO) defines Asperger syndrome (AS) as one of the autism spectrum disorders (ASD) or pervasive developmental disorders (PDD), which are a spectrum of psychological conditions that are characterized by abnormalities of social interaction and communication that pervade the individual's functioning, and by restricted and repetitive interests and behavior. Like other psychological development disorders, ASD begins in infancy or childhood, has a steady course without remission or relapse, and has impairments that result from maturation-related changes in various systems of the brain. ASD, in turn, is a subset of the broader autism phenotype, which describes individuals who may not have ASD but do have autistic-like traits, such as social deficits. Of the other four ASD forms, autism is the most similar to AS in signs and likely causes, but its diagnosis requires impaired communication and allows delay in cognitive development; Rett syndrome and childhood disintegrative disorder share several signs with autism but may have unrelated causes; and pervasive developmental disorder not otherwise specified (PDD-NOS) is diagnosed when the criteria for a more specific disorder are unmet.", "page_name": "Asperger syndrome", "page_id": "Asperger%20syndrome", "heading": "Classification", "sub_heading": "Classification", "_id": "3000049154--0---1---1", "title": "Asperger Syndrome and High-Focused Autism"}
{"qas": [{"question": "How do parents of children with Aspergers Syndrome know when their child is developing?", "answer": ""}, {"question": "What was the childhood autism spectrum test (CAST) originally called?", "answer": "Childhood Asperger Syndrome Test", "ae_score": -0.8784732323820034, "qg_score": null}, {"question": "What was the childhood autism spectrum test (CAST) originally called?", "answer": "Childhood Asperger Syndrome Test", "ae_score": -0.8784732323820034, "qg_score": null}], "content": "Parents of children with Asperger syndrome can typically trace differences in their children's development to as early as 30 months of age.<ref name=Foster/> Developmental screening during a routine check-up by a general practitioner or pediatrician may identify signs that warrant further investigation.<ref name=McPart2006/><ref name=NINDS/> The United States Preventive Services Task Force in 2016 found it was unclear if screening was beneficial or harmful among children in whom there is no concerns.\nThe diagnosis of AS is complicated by the use of several different screening instruments,<ref name=NINDS/><ref name=EhlGill/> including the Asperger Syndrome Diagnostic Scale (ASDS), Autism Spectrum Screening Questionnaire (ASSQ), Childhood Autism Spectrum Test (CAST) (previously called the Childhood Asperger Syndrome Test), Gilliam Asperger's disorder scale (GADS), Krug Asperger's Disorder Index (KADI), and the Autism-spectrum quotient (AQ; with versions for children, adolescents and adults). None have been shown to reliably differentiate between AS and other ASDs.<ref name=McPart2006/>", "page_name": "Asperger syndrome", "page_id": "Asperger%20syndrome", "heading": "Screening", "sub_heading": "Screening", "_id": "3000049154--5---1---1", "title": "Asperger syndrome | Screening"}
{"qas": [{"question": "How does alcohol affect the brain?", "answer": ""}, {"question": "What is an example of a sedative?", "answer": "Alcohol", "ae_score": -0.7114593603939752, "qg_score": null}, {"question": "What is an example of a sedative?", "answer": "Alcohol", "ae_score": -0.7114593603939752, "qg_score": null}], "content": "Alcohol is a depressant, the effects of which may vary according to dosage amount, frequency, and chronicity. As a member of the sedative-hypnotic class, at the lowest doses, the individual feels relaxed and less anxious. In quiet settings, the user may feel drowsy, but in settings with increased sensory stimulation, individuals may feel uninhibited and more confident. High doses of alcohol rapidly consumed may produce amnesia for the events that occur during intoxication. Other effects include reduced coordination, which leads to slurred speech, impaired fine-motor skills, and delayed reaction time. The effects of alcohol on the body\u2019s neurochemistry are more difficult to examine than some other drugs. This is because the chemical nature of the substance makes it easy to penetrate into the brain, and it also influences the phospholipid bilayer of neurons. This allows alcohol to have a widespread impact on many normal cell functions and modifies the actions of several neurotransmitter systems. Alcohol inhibits glutamate (a major excitatory neurotransmitter in the nervous system) neurotransmission by reducing the effectiveness at the NMDA receptor, which is related to memory loss associated with intoxication. It also modulates the function of GABA, a major inhibitory amino acid neurotransmitter. The reinforcing qualities of alcohol leading to repeated use \u2013 and thus also the mechanisms of withdrawal from chronic alcohol use \u2013 are partially due to the substance\u2019s action on the dopamine system. This is also due to alcohol\u2019s effect on the opioid systems, or endorphins, that have opiate-like effects, such as modulating pain, mood, feeding, reinforcement, and response to stress.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Psychopharmacological substances", "_id": "3000049351--2--0---1", "title": "The Effects of Alcohol on Brain Function"}
{"qas": [{"question": "How do selective serotonin reuptake inhibitors work?", "answer": ""}, {"question": "What is the oldest class of antidepressants?", "answer": "Monoamine oxidase inhibitors", "ae_score": -0.19973401491890125, "qg_score": null}, {"question": "Monoamine oxidase inhibitors are the oldest class of what?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Antidepressants reduce symptoms of mood disorders primarily through the regulation of norepinephrine and serotonin (particularly the 5-HT receptors). After chronic use, neurons adapt to the change in biochemistry, resulting in a change in pre- and postsynaptic receptor density and second messenger function.\nMonoamine oxidase inhibitors (MAOIs) are the oldest class of antidepressants. They inhibit monoamine oxidase, the enzyme that metabolizes the monoamine neurotransmitters in the presynaptic terminals that are not contained in protective synaptic vesicles. The inhibition of the enzyme increases the amount of neurotransmitter available for release. It increases norepinephrine, dopamine, and 5-HT and thus increases the action of the transmitters at their receptors. MAOIs have been somewhat disfavored because of their reputation for more serious side effects.\nTricyclic antidepressants (TCAs) work through binding to the presynaptic transporter proteins and blocking the reuptake of norepinephrine or 5-HT into the presynaptic terminal, prolonging the duration of transmitter action at the synapse.\nSelective serotonin reuptake inhibitors (SSRIs) selectively block the reuptake of serotonin (5-HT) through their inhibiting effects on the sodium/potassium ATP-dependent serotonin transporter in presynaptic neurons. This increases the availability of 5-HT in the synaptic cleft. The main parameters to consider in choosing an antidepressant are side effects and safety. Most SSRIs are available generically and are relatively inexpensive. Older antidepressants, such as the TCAs and MAOIs usually require more visits and monitoring, and this may offset the low expense of the drugs. The SSRIs are relatively safe in overdose and better tolerated than the TCAs and MAOIs for most patients.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Antidepressants", "_id": "3000049351--2--1---1", "title": "Antidepressants \u2014 Side Effects, Safety, and Cost"}
{"qas": [{"question": "Why do some antipsychotic drugs have a higher serotonin/dopamine ratio than others?", "answer": ""}, {"question": "What are the most serious side effects of antipsychotic drugs?", "answer": "movement disorders", "ae_score": -0.4241381042649587, "qg_score": null}, {"question": "What are the most serious side effects of antipsychotic drugs?", "answer": "movement disorders", "ae_score": -0.4241381042649587, "qg_score": null}], "content": "All antipsychotic substances, except clozapine, are relatively potent postsynaptic dopamine receptor blockers (dopamine antagonists). All of the effective antipsychotics, except clozapine, act on the nigrostriatal system. For an antipsychotic to be effective, it generally requires a dopamine antagonism of 60%-80% of dopamine D receptors.\nFirst generation (typical) antipsychotics: Traditional neuroleptics modify several neurotransmitter systems, but their clinical effectiveness is most likely due to their ability to antagonize dopamine transmission by competitively blocking the receptors or by inhibiting dopamine release. The most serious and troublesome side effects of these classical antipsychotics are movement disorders that resemble the symptoms of Parkinson's disease, because the neuroleptics antagonize dopamine receptors broadly, also reducing the normal dopamine-mediated inhibition of cholinergic cells in the striatum.\nSecond-generation (atypical) antipsychotics: The concept of \u201catypicality\u201d is from the finding that the second generation antipsychotics (SGAs) had a greater serotonin/dopamine ratio than did earlier drugs, and might be associated with improved efficacy (particularly for the negative symptoms of psychosis) and reduced extrapyramidal side effects. Some of the efficacy of atypical antipsychotics may be due to 5-HT antagonism or the blockade of other dopamine receptors. Agents that purely block 5-HT or dopamine receptors other than D have often failed as effective antipsychotics.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Antipsychotics", "_id": "3000049351--2--2---1", "title": "Antipsychotics \u2014 First-Generation (Atypical) and Second-Gen"}
{"qas": [{"question": "How do benzodiazepines work?", "answer": ""}, {"question": "What drug is used to reduce anxiety symptoms, muscle tension, seizure disorders, insomnia,?", "answer": "Benzodiazepines", "ae_score": -0.7237929237445743, "qg_score": null}, {"question": "What drug is used to reduce anxiety symptoms, muscle tension, seizure disorders, insomnia,?", "answer": "Benzodiazepines", "ae_score": -0.7237929237445743, "qg_score": null}], "content": "Benzodiazepines are often used to reduce anxiety symptoms, muscle tension, seizure disorders, insomnia, symptoms of alcohol withdrawal, and panic attack symptoms. Their action is primarily on specific benzodiazepine sites on the GABA receptor. This receptor complex is thought to mediate the anxiolytic, sedative, and anticonvulsant actions of the benzodiazepines. Use of benzodiazepines carries the risk of tolerance (necessitating increased dosage), dependence, and abuse. Taking these drugs for a long period of time can lead to withdrawal symptoms upon abrupt discontinuation.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Benzodiazepines", "_id": "3000049351--2--3---1", "title": "Benzodiazepines: Anxiety, Seizure Disorders, Se"}
{"qas": [{"question": "How do hallucinogens work?", "answer": ""}, {"question": "What causes perceptual and cognitive distortions without delirium?", "answer": "Hallucinogens", "ae_score": -0.8558452658505071, "qg_score": null}, {"question": "What causes perceptual and cognitive distortions without delirium?", "answer": "Hallucinogens", "ae_score": -0.8558452658505071, "qg_score": null}], "content": "Hallucinogens cause perceptual and cognitive distortions without delirium. The state of intoxication is often called a \u201ctrip\u201d. Onset is the first stage after an individual ingests (LSD, psilocybin, or mescaline) or smokes (dimethyltryptamine) the substance. This stage may consist of visual effects, with an intensification of colors and the appearance of geometric patterns that can be seen with one\u2019s eyes closed. This is followed by a plateau phase, where the subjective sense of time begins to slow and the visual effects increase in intensity. The user may experience synesthesia, a crossing-over of sensations (for example, one may \u201csee\u201d sounds and \u201chear\u201d colors). In addition to the sensory-perceptual effects, hallucinogenic substances may induce feelings of depersonalization, emotional shifts to a euphoric or anxious/fearful state, and a disruption of logical thought. Hallucinogens are classified chemically as either indoleamines (specifically tryptamines), sharing a common structure with serotonin, or as phenethylamines, which share a common structure with norepinephrine. Both classes of these drugs are agonists at the 5-HT receptors; this is thought to be the central component of their hallucinogenic properties. Activation of 5-HT may be particularly important for hallucinogenic activity. However, repeated exposure to hallucinogens leads to rapid tolerance, likely through down-regulation of these receptors in specific target cells.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Hallucinogens", "_id": "3000049351--2--4---1", "title": "Hallucinogens and the Effects of Intoxication"}
{"qas": [{"question": "What is the difference between benzodiazepines and hypnotics?", "answer": ""}, {"question": "What is the most commonly prescribed sedative-hypnotics in the us?", "answer": "Benzodiazepines", "ae_score": -0.7019130552118927, "qg_score": null}, {"question": "What is the most commonly prescribed sedative-hypnotics in the us?", "answer": "Benzodiazepines", "ae_score": -0.7019130552118927, "qg_score": null}], "content": "Hypnotics are often used to treat the symptoms of insomnia, or other sleep disorders. Benzodiazepines are still among the most widely prescribed sedative-hypnotics in the United States today. Certain non-benzodiazepine drugs are used as hypnotics as well. Although they lack the chemical structure of the benzodiazepines, their sedative effect is similarly through action on the GABAA receptor. They also have a reputation of being less addictive than benzodiazepines. Melatonin, a naturally-occurring hormone, is often used over the counter (OTC) to treat insomnia and jet lag. This hormone appears to be excreted by the pineal gland early during the sleep cycle and may contribute to human circadian rhythms. Because OTC melatonin supplements are not subject to careful and consistent manufacturing, more specific melatonin agonists are sometimes preferred. They are used for their action on melatonin receptors in the suprachiasmatic nucleus, responsible for sleep-wake cycles. Many barbiturates have or had an FDA-approved indication for use as sedative-hypnotics, but have become less widely used because of their limited safety margin in overdose, their potential for dependence, and the degree of central nervous system depression they induce. The amino-acid L-tryptophan is also available OTC, and seems to be free of dependence or abuse liability. However, it is not as powerful as the traditional hypnotics. Because of the possible role of serotonin in sleep patterns, a new generation of 5-HT antagonists are in current development as hypnotics.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Hypnotics", "_id": "3000049351--2--5---1", "title": "Sleep Hypnotics \u2014 What is the Difference?"}
{"qas": [{"question": "Why do people get \"high\" from smoking weed?", "answer": ""}, {"question": "How many primary cns cannabinoid receptors are there?", "answer": "two", "ae_score": -0.7113509596416369, "qg_score": null}, {"question": "What is one of the main effects of ingesting cannabis?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "Cannabis consumption produces a dose-dependent state of intoxication in humans. There is commonly increased blood flow to the skin, which leads to sensations of warmth or flushing, and heart rate is also increased. It also frequently induces increased hunger. Iversen (2000) categorized the subjective and behavioral effects often associated with cannabis into three stages. The first is the \"buzz,\" a brief period of initial responding, where the main effects are lightheadedness or slight dizziness, in addition to possible tingling sensations in the extremities or other parts of the body. The \"high\" is characterized by feelings of euphoria and exhilaration characterized by mild psychedelia, as well as a sense of disinhibition. If the individual has taken a sufficiently large dose of cannabis, the level of intoxication progresses to the stage of being \u201cstoned,\u201d and the user may feel calm, relaxed, and possibly in a dreamlike state. Sensory reactions may include the feeling of floating, enhanced visual and auditory perception, visual illusions, or the perception of the slowing of time passage, which are somewhat psychedelic in nature.\nThere exist two primary CNS cannabinoid receptors, on which marijuana and the cannabinoids act. Both the CB1 receptor and CB2 receptor are found in the brain. The CB2 receptor is also found in the immune system. CB is expressed at high densities in the basal ganglia, cerebellum, hippocampus, and cerebral cortex. Receptor activation can inhibit cAMP formation, inhibit voltage-sensitive calcium ion channels, and activate potassium ion channels. Many CB receptors are located on axon terminals, where they act to inhibit the release of various neurotransmitters. In combination, these drug actions work to alter various functions of the central nervous system including the motor system, memory, and various cognitive processes.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Cannabis and the cannabinoids", "_id": "3000049351--2--6---1", "title": "Cannabinoids and Cannabis"}
{"qas": [{"question": "How do opiates work?", "answer": ""}, {"question": "What class of drugs do opiates belong to?", "answer": "narcotic analgesics", "ae_score": -0.7308160148443757, "qg_score": null}, {"question": "What class of drugs do opiates belong to?", "answer": "narcotic analgesics", "ae_score": -0.7308160148443757, "qg_score": null}], "content": "The opiate drugs, which include drugs like heroin, morphine, and oxycodone, belong to the class of narcotic analgesics, which reduce pain without producing unconsciousness, but do produce a sense of relaxation and sleep, and at high doses, may result in coma and death. The ability of opiates (both endogenous and exogenous) to relieve pain depends on a complex set of neuronal pathways at the spinal cord level, as well as various locations above the spinal cord. Small endorphin neurons in the spinal cord act on receptors to decrease the conduction of pain signals from the spinal cord to higher brain centers. Descending neurons originating in the periaqueductal gray give rise to two pathways that further block pain signals in the spinal cord. The pathways begin in the locus coeruleus (noradrenaline) and the nucleus of raphe (serotonin). Similar to other abused substances, opiate drugs increase dopamine release in the nucleus accumbens. Opiates are more likely to produce physical dependence than any other class of psychoactive drugs, and can lead to painful withdrawal symptoms if discontinued abruptly after regular use.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Opiates", "_id": "3000049351--2--7---1", "title": "Opiate Drugs \u2014 An Overview"}
{"qas": [{"question": "What is cocaine and how does it affect the brain?", "answer": ""}, {"question": "Which stimulant causes increased alertness, increased confidence, feelings of exhilaration, reduced?", "answer": "Cocaine", "ae_score": -0.4357098417686937, "qg_score": null}, {"question": "Which stimulant causes increased alertness, increased confidence, feelings of exhilaration, reduced?", "answer": "Cocaine", "ae_score": -0.4357098417686937, "qg_score": null}], "content": "Cocaine is one of the more common stimulants, and is a complex drug that interacts with various neurotransmitter systems. It commonly cause heightened alertness, increased confidence, feelings of exhilaration, reduced fatigue, and a generalized sense of well-being. The effects of cocaine are similar to those of the amphetamines, though cocaine tends to have a shorter duration of effect. In high doses and/or with prolonged use, cocaine can result in a number of negative effects as well, including irritability, anxiety, exhaustion, total insomnia, and even psychotic symptomatology. Most of the behavioral and physiological actions of cocaine can be explained by its ability to block the reuptake of the two catecholamines, dopamine and norepinephrine, as well as serotonin. Cocaine binds to transporters that normally clear these transmitters from the synaptic cleft, inhibiting their function. This leads to increased levels of neurotransmitter in the cleft and transmission at the synapses. Based on in-vitro studies using rat brain tissue, cocaine binds most strongly to the serotonin transporter, followed by the dopamine transporter, and then the norepinephrine transporter.\nAmphetamines tend to cause the same behavioral and subjective effects of cocaine. Various forms of amphetamine are commonly used to treat the symptoms of attention deficit hyperactivity disorder (ADHD) and narcolepsy, or are used recreationally. Amphetamine and methamphetamine are indirect agonists of the catecholaminergic systems. They block catecholamine reuptake, in addition to releasing catecholamines from nerve terminals. There is evidence that dopamine receptors play a central role in the behavioral responses of animals to cocaine, amphetamines, and other psychostimulant drugs. One action causes the dopamine molecules to be released from inside the vesicles into the cytoplasm of the nerve terminal, which are then transported outside by the mesolimbic dopamine pathway to the nucleus accumbens. This plays a key role in the rewarding and reinforcing effects of cocaine and amphetamine in animals, and is the primary mechanism for amphetamine dependence.", "page_name": "Psychopharmacology", "page_id": "Psychopharmacology", "heading": "Psychopharmacological substances", "sub_heading": "Stimulants", "_id": "3000049351--2--8---1", "title": "The Psychostimulant Effects of Cocaine and Amphetamine in Animals"}
{"qas": [{"question": "What is the difference between a benzodiazepine and a regular one?", "answer": ""}, {"question": "How many types of psychiatric medication are there?", "answer": "six", "ae_score": -0.0977237431292661, "qg_score": null}, {"question": "The first mood stabilizer to be approved by the us food and drug administration was?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "There are six main groups of psychiatric medications.\nAntidepressants are drugs used to treat clinical depression, and they are also often used for anxiety and other disorders. Most antidepressants will hinder the breakdown of serotonin or norepinephrine or both. A commonly used class of antidepressants are called selective serotonin reuptake inhibitors (SSRIs), which act on serotonin transporters in the brain to increase levels of serotonin in the synaptic cleft. SSRIs will often take 3\u20135 weeks to have a noticeable effect, as the regulation of receptors in the brain adapts. There are multiple classes of antidepressants which have different mechanisms of action. Another type of antidepressant is a monoamine oxidase inhibitor, which is thought to block the action of Monoamine oxidase, an enzyme that breaks down serotonin and norepinephrine. MAOIs are not used as first-line treatment due to the risk of hypertensive crisis related to the consumption of foods containing the amino acid tyramine.\nCommon antidepressants:\nAntipsychotics are drugs used to treat various symptoms of psychosis, such as those caused by psychotic disorders or schizophrenia. Atypical antipsychotics are also used as mood stabilizers in the treatment of bipolar disorder, and they can augment the action of antidepressants in major depressive disorder.Antipsychotics are sometimes referred to as neuroleptic drugs and some antipsychotics are branded \"major tranquilizers\".\nThere are two categories of antipsychotics: typical antipsychotics and atypical antipsychotics. Most antipsychotics are available only by prescription.\nCommon antipsychotics:\nBenzodiazepines are effective as hypnotics, anxiolytics, anticonvulsants, myorelaxants and amnesics.  Having less proclivity for overdose and toxicity, they have widely supplanted barbiturates.\nDeveloped in the 1950s onward, benzodiazepines were originally thought to be non-addictive at therapeutic doses, but are now known to cause withdrawal symptoms similar to barbiturates and alcohol. Benzodiazepines are generally recommended for short-term use.\nZ-drugs are a group of drugs with effects generally similar to benzodiazepines, which are used in the treatment of insomnia.\nCommon benzodiazepines and z-drugs include:\nIn 1949, the Australian John Cade discovered that lithium salts could control mania, reducing the frequency and severity of manic episodes. This introduced the now popular drug lithium carbonate to the mainstream public, as well as being the first mood stabilizer to be approved by the U.S. Food & Drug Administration. Besides lithium, several anticonvulsants and atypical antipsychotics have mood stabilizing activity. The mechanism of action of mood stabilizers is not well understood.\nCommon mood stabilizers:\nA stimulant is a drug that stimulates the central nervous system, increasing arousal, attention and endurance. Stimulants are used in psychiatry to treat attention deficit-hyperactivity disorder. Because the medications can be addictive, patients with a history of drug abuse are typically monitored closely or treated with a non-stimulant.\nCommon stimulants:", "page_name": "Psychiatric medication", "page_id": "Psychiatric%20medication", "heading": "Types", "sub_heading": "Types", "_id": "3000049665--4---1---1", "title": "Psychiatric Medicines: What are they and how do they work?"}
{"qas": [{"question": "What is the difference between practical ethics and theoretical ethics?", "answer": ""}, {"question": "What is the study of ethics called?", "answer": "Teleology", "ae_score": -0.07067104002888783, "qg_score": null}, {"question": "What type of deontological ethics is more rigid?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "Teleology informs the study of ethics.\nBusiness people commonly think in terms of purposeful action as in, for example, management by objectives. Teleological analysis of business ethics leads to consideration of the full range of stakeholders in any business decision, including the management, the staff, the customers, the shareholders, the country, humanity and the environment.\nTeleology provides a moral basis for the professional ethics of medicine, as physicians are generally concerned with outcomes and must therefore know the ''telos'' of a given treatment paradigm.\nThe broad spectrum of consequentialist ethics, of which utilitarianism is a well-known example, focuses on the end result or consequences, with such principles as utilitarian philosopher John Stuart Mill's \"the greatest good for the greatest number\", or the Principle of Utility. Hence this principle is teleological, but in a broader sense than is elsewhere understood in philosophy. In the classical notion, teleology is grounded in the inherent natures of things themselves, whereas in consequentialism, teleology is imposed on nature from outside by the human will. Consequentialist theories justify inherently what most people would call evil acts by their desirable outcomes, if the good of the outcome outweighs the bad of the act. So for example, a consequentialist theory would say it was acceptable to actively kill one person in order to save two or more other people. These theories may be summarized by the maxim \"the ends can justify the means.\"\nConsequentialism stands in contrast to the more classical notions of deontological ethics, such as Immanuel Kant's Categorical Imperative, and Aristotle's virtue ethics (although formulations of virtue ethics are also often consequentialist in derivation). In deontological ethics, the goodness or badness of individual acts is primary and a desirable larger goal is insufficient to justify bad acts committed on the way to that goal, even if the bad acts are relatively minor and the goal is major (like telling a small lie to prevent a war and save millions of lives). In requiring all constituent acts to be good, deontological ethics is much more rigid than consequentialism, which varies by circumstances.\nPractical ethics are usually a mix of the two.  For example, Mill also relies on deontic maxims to guide practical behavior, but they must be justifiable by the principle of utility.", "page_name": "Teleology", "page_id": "Teleology", "heading": "Teleology and ethics", "sub_heading": "Teleology and ethics", "_id": "3000050142--5---1---1", "title": "Teleology and Consequentialist Ethics"}
{"qas": [{"question": "Why do our eyes move rapidly when we think about disturbing memories?", "answer": ""}, {"question": "What type of therapy is particularly important for children with pst?", "answer": "school-based therapy", "ae_score": -0.6143205254906118, "qg_score": null}, {"question": "What type of therapy is particularly important for children with pst?", "answer": "school-based therapy", "ae_score": -0.6143205254906118, "qg_score": null}], "content": "Many forms of psychotherapy have been found to be efficacious for trauma-related problems such as PTSD. Basic counseling practices common to many treatments for PTSD include education about the condition, and provision of safety and support.\nThe psychotherapy programs with the strongest demonstrated efficacy include cognitive behavioral programs, variants of exposure therapy, stress inoculation training (SIT), variants of cognitive therapy (CT), eye movement desensitization and reprocessing (EMDR), mindfulness-based meditation and many combinations of these procedures. EMDR and trauma-focused cognitive behavioral therapy (TFCBT) were recommended as first-line treatments for trauma victims in a 2007 review; however, \"the evidence base [for EMDR] was not as strong as that for TFCBT ... Furthermore, there was limited evidence that TFCBT and EMDR were superior to supportive/non-directive treatments, hence it is highly unlikely that their effectiveness is due to non-specific factors such as attention.\" A meta-analytic comparison of EMDR and cognitive behavioral therapy found both protocols indistinguishable in terms of effectiveness in treating PTSD; however, \"the contribution of the eye movement component in EMDR to treatment outcome\" is unclear.\nFurthermore, the availability of school-based therapy is particularly important for children with PTSD. Children with PTSD are far more likely to pursue treatment at school (because of its proximity and ease) than at a free clinic.\nCognitive behavioral therapy (CBT) seeks to change the way a trauma victim feels and acts by changing the patterns of thinking or behavior, or both, responsible for negative emotions. CBT has been proven to be an effective treatment for PTSD and is currently considered the standard of care for PTSD by the United States Department of Defense. In CBT, individuals learn to identify thoughts that make them feel afraid or upset and replace them with less distressing thoughts. The goal is to understand how certain thoughts about events cause PTSD-related stress.\nRecent research on contextually based third-generation behavior therapies suggests that they may produce results comparable to some of the better validated therapies. Many of these therapy methods have a significant element of exposure and have demonstrated success in treating the primary problems of PTSD and co-occurring depressive symptoms.\nExposure therapy is a type of cognitive behavioral therapy that involves assisting trauma survivors to re-experience distressing trauma-related memories and reminders in order to facilitate habituation and successful emotional processing of the trauma memory. Most exposure therapy programs include both imaginal confrontation with the traumatic memories and real-life exposure to trauma reminders; this therapy modality is well supported by clinical evidence. The success of exposure-based therapies has raised the question of whether exposure is a necessary ingredient in the treatment of PTSD. Some organizations have endorsed the need for exposure. The US Department of Veterans Affairs has been actively training mental health treatment staff in prolonged exposure therapy and Cognitive Processing Therapy in an effort to better treat US veterans with PTSD.\nEye movement desensitization and reprocessing (EMDR) is a form of psychotherapy developed and studied by Francine Shapiro. She had noticed that, when she was thinking about disturbing memories herself, her eyes were moving rapidly. When she brought her eye movements under control while thinking, the thoughts were less distressing.\nIn 2002, Shapiro and Maxfield published a theory of why this might work, called adaptive information processing. This theory proposes that eye movement can be used to facilitate emotional processing of memories, changing the person's memory to attend to more adaptive information. The therapist initiates voluntary rapid eye movements while the person focuses on memories, feelings or thoughts about a particular trauma.<ref name=UK2005/> The therapists uses hand movements to get the person to move their eyes backward and forward, but hand-tapping or tones can also be used.<ref name=UK2005/>  EMDR closely resembles cognitive behavior therapy as it combines exposure (re-visiting the traumatic event), working on cognitive processes and relaxation/self-monitoring.<ref name=UK2005/> However, exposure by way of being asked to think about the experience rather than talk about it has been highlighted as one of the more important distinguishing elements of EMDR.\nThere have been multiple small controlled trials of four to eight weeks of EMDR in adults  as well as children and adolescents. EMDR reduced PTSD symptoms enough in the short term that one in two adults no longer met the criteria for PTSD, but the number of people involved in these trials was small. There was not enough evidence to know whether or not EMDR could eliminate PTSD. There was some evidence that EMDR might prevent depression. There were no studies comparing EMDR to other psychological treatments or to medication. Adverse effects were largely unstudied. The benefits were greater for women with a history of sexual assault compared with people who had experienced other types of traumatizing events (such as accidents, physical assaults and war). There is a small amount of evidence that EMDR may improve re-experiencing symptoms in children and adolescents, but EMDR has not been shown to improve other PTSD symptoms, anxiety, or depression.\nThe eye movement component of the therapy may not be critical for benefit. As there has been no major, high quality randomized trial of EMDR with eye movements versus EMDR without eye movements, the controversy over effectiveness is likely to continue. Authors of a meta-analysis published in 2013 stated, \"We found that people treated with eye movement therapy had greater improvement in their symptoms of post-traumatic stress disorder than people given therapy without eye movements\u2026.Secondly we found that that in laboratory studies the evidence concludes that thinking of upsetting memories and simultaneously doing a task that facilitates eye movements reduces the vividness and distress associated with the upsetting memories.\"\nOther approaches, in particular involving social supports, may also be important. An open trial of interpersonal psychotherapy reported high rates of remission from PTSD symptoms without using exposure. A current, NIMH-funded trial in New York City is now (and into 2013) comparing interpersonal psychotherapy, prolonged exposure therapy, and relaxation therapy.", "page_name": "Posttraumatic stress disorder", "page_id": "Posttraumatic%20stress%20disorder", "heading": "Management", "sub_heading": "Management", "_id": "3000050181--5--0---1", "title": "PTSD Treatments: The Role of Eye Movement in Psychotherapy"}
{"qas": [{"question": "Why is medical marijuana used as a treatment for PTSD?", "answer": ""}, {"question": "What is one type of therapy that can be used to protect against neurodegeneration?", "answer": "Glucocorticoids", "ae_score": -0.2264338772593832, "qg_score": null}, {"question": "What type of medication is used to treat post-traumatic stress disorder?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "While many medications do not have enough evidence to support their use, three (fluoxetine, paroxetine, and venlafaxine) have been shown to have a small benefit over placebo. This study concluded that \"the drugs included were well tolerated overall.\" With many medications, residual PTSD symptoms following treatment is the rule rather than the exception.\nSelective serotonin reuptake inhibitors (SSRIs) and serotonin-norepinephrine reuptake inhibitors (SNRIs) may have some benefit for PTSD symptoms.<ref name=Hos2015/> Tricyclic antidepressants are equally effective but are less well tolerated. Evidence provides support for a small or modest improvement with sertraline, fluoxetine, paroxetine, and venlafaxine.<ref name=Hos2015/> Thus, these four medications are considered to be first-line medications for PTSD.<ref name=Jeffreys-2012/>\nBenzodiazepines are not recommended for the treatment of PTSD due to a lack of evidence of benefit and risk of worsening PTSD symptoms. Some authors believe that the use of benzodiazepines is contraindicated for acute stress, as this group of drugs promotes dissociation and ulterior revivals. Nevertheless, some use benzodiazepines with caution for short-term anxiety and insomnia. While benzodiazepines can alleviate acute anxiety, there is no consistent evidence that they can stop the development of PTSD and may actually increase the risk of developing PTSD 2-5 times.<ref name=Gui2015/> Additionally, benzodiazepines may reduce the effectiveness of psychotherapeutic interventions, and there is some evidence that benzodiazepines may actually contribute to the development and chronification of PTSD. For those who already have PTSD, benzodiazepines may worsen and prolong the course of illness, by worsening psychotherapy outcomes, and causing or exacerbating aggression, depression (including suicidality), and substance use.<ref name=Gui2015/> Drawbacks include the risk of developing a benzodiazepine dependence, tolerance (i.e., short-term benefits wearing off with time), and withdrawal syndrome; additionally, individuals with PTSD (even those without a history of alcohol or drug misuse) are at an increased risk of abusing benzodiazepines. Due to a number of other treatments with greater efficacy for PTSD and less risks (e.g., prolonged exposure, cognitive processing therapy, eye movement desensitization and reprocessing, cognitive restructuring therapy, trauma-focused cognitive behavioral therapy, brief eclectic psychotherapy, narrative therapy, stress inoculation training, serotonergic antidepressants, adrenergic inhibitors, antipsychotics, and even anticonvulsants), benzodiazepines should be considered relatively contraindicated until all other treatment options are exhausted.<ref name=Haa2015/> For those who argue that benzodiazepines should be used sooner in the most severe cases, the adverse risk of disinhibition (associated with suicidality, aggression and crimes) and clinical risks of delaying or inhibiting definitive efficacious treatments, make other alternative treatments preferable (e.g., inpatient, residential, partial hospitalization, intensive outpatient, dialectic behavior therapy; and other fast-acting sedating medications such as trazodone, mirtazapine, amitripytline, doxepin, prazosin, propranolol, guanfacine, clonidine, quetiapine, olanzapine, valproate, gabapentin).<ref name=Berg2009/>\nGlucocorticoids may be useful for short-term therapy to protect against neurodegeneration caused by the extended stress response that characterizes PTSD, but long-term use may actually promote neurodegeneration.\nThere is tentative evidence that medical cannabis may be effective at reducing PTSD symptoms, but, as of , there is insufficient evidence to confirm its effectiveness for this condition. Despite the uncertain evidence, use of cannabis or derived products is widespread among US veterans with PTSD.\nThe cannabinoid nabilone is sometimes used off-label for nightmares in PTSD. Although some short-term benefit was shown, adverse effects are common and it has not been adequately studied to determine efficacy. Additionally, there are other treatments with stronger efficacy and less risks (e.g., psychotherapy, serotonergic antidepressants, adrenergic inhibitors). The use of medical marijuana for PTSD is controversial, with only a handful of states permitting its use for that purpose.", "page_name": "Posttraumatic stress disorder", "page_id": "Posttraumatic%20stress%20disorder", "heading": "Management", "sub_heading": "Medication", "_id": "3000050181--5--1---1", "title": "PTSD Treatments and Treatments"}
{"qas": [{"question": "How do we know how much noise a human can hear?", "answer": ""}, {"question": "Where is the oe test used in early childhood?", "answer": "Utah State University", "ae_score": -0.8126974644459121, "qg_score": null}, {"question": "What is the term for the shift in the audiometric threshold after exposure to noise?", "answer": "Threshold shift", "ae_score": null, "qg_score": null}], "content": "Otoacoustic emissions are clinically important because they are the basis of a simple, non-invasive test for hearing defects in newborn babies and in children who are too young to cooperate in conventional hearing tests.  Many western countries now have national programmes for the universal hearing screening of newborn babies.  Periodic early childhood hearing screenings program are also utilizing OAE technology.  One excellent example has been demonstrated by the Early Childhood Hearing Outreach Initiative at the National Center for Hearing Assessment and Management (NCHAM) at Utah State University, which has helped hundreds of Early Head Start programs across the United States implement OAE screening and follow-up practices in those early childhood educational settings. The primary screening tool is a test for the presence of a click-evoked OAE. Otoacoustic emissions also assist in differential diagnosis of cochlear and higher level hearing losses (e.g., auditory neuropathy).\nThe relationships between otoacoustic emissions and tinnitus have been explored. Several studies suggest that in about 6% to 12% of normal-hearing persons with tinnitus and SOAEs, the SOAEs are at least partly responsible for the tinnitus. Studies have found that some subjects with tinnitus display oscillating or ringing EOAEs, and in these cases, it is hypothesized that the oscillating EOAEs and tinnitus are related to a common underlying pathology rather than the emissions being the source of the tinnitus.\nIn conjunction with audiometric testing, OAE testing can be completed to determine changes in the responses. Studies have found that exposure to noise can cause a decline in OAE responses. In a study, industrial workers who were exposed 84.5 dBA of noise were compared to workers who were exposed to 53.2 dBA of noise by considering hearing thresholds and OAEs before and after 5 days of work. This study revealed that hearing thresholds and OAE results were significantly lower among the workers who were exposed to higher levels of noise.\nIt has been found that distortion product otoacoustic emissions (DPOAE\u2019s) have provided the most information for detecting mild hearing loss in high frequencies when compared to transient evoked otoacoustic emissions (TEOAE). This is an indication that DPOAE\u2019s can help with detecting an early onset of noise-induced hearing loss. A study measuring audiometric thresholds and DPOAEs among individuals in the military showed that there was a decrease in DPOAEs after noise exposure, but did not show a shift in audiometric threshold. This supports OAEs as predicting early signs of noise damage.", "page_name": "Otoacoustic emission", "page_id": "Otoacoustic%20emission", "heading": "Clinical importance", "sub_heading": "Clinical importance", "_id": "3000052751--2---1---1", "title": "Otoacoustic Emissions and Tinnitus"}
{"qas": [{"question": "Why are there so many more people allergic to blood than there are to other things?", "answer": ""}, {"question": "Who is credited with the development of pacemakers and heart valves?", "answer": "Leon Abrams", "ae_score": -0.07332643829903115, "qg_score": null}, {"question": "Who is credited with the development of pacemakers and heart valves?", "answer": "Leon Abrams", "ae_score": -0.07332643829903115, "qg_score": null}], "content": "Bicycles have been manufactured in the Midlands (mainly Birmingham and Coventry) since the mid 19th century. By 1900 Birmingham has the largest number of bicycle makers and component manufacturers in Britain. Several advances in the development of the bicycle take place, one of the longer established high quality manufacturers being the 'Quadrant Cycle Company' of Sheepcote Street, which later manufactures motorbikes (as do many cycle makers).\nOther notable firms are Reynolds (still manufacturing in the city), New Hudson, Rudge-Whitworth (also of Coventry), B.S.A., C.W.S., Dawes, Grundle, James Cycle Co, Ariel, Armstrong Cycles, Phillips Cycles, Excelsior (originally of Coventry), Sun Cycle & Fittings Co, Pashley Cycles (now manufactured in Stratford-upon-Avon) and Hercules Cycle and Motor Company.\nThrough the 20th century, many of Birmingham's bicycle manufacturers evolve into automobile and motorcycle brands, creating one of the busiest and most productive engineering hubs in the world.\nMotor engineering brands such as Wolseley, Lanchester, Metro Cammell, Austin, Morris, Vickers-Armstrongs, New Hudson, Revere, Beardmore, Sun, Ariel, Norton, Rex-Acme, Alldays & Onions, Velocette, Midland Red and BSA either originate or have substantial factories in Birmingham, manufacturing motorbikes, buses, tractors, cars, tanks and aeroplanes.\nOther diverse engineering companies develop to feed the supply chain of the motoring industry such as Webster and Horsfall (pioneering wire for aircraft and cars), Dunlop Rubber (supplying rubber and tyres), Lucas Industries (pioneering electric and lighting), Accles & Pollock (producing tubular sections for aircraft) and Pockley Electric (manufacturing car lights).\n1900: Bournville Village Trust is founded by George Cadbury, this is to make many improvements and set high standards of living and leisure pastimes for factory workers across Britain. Cadbury's still makes chocolate in the city today and Bournville remains a sought after area to live in.\n1900: John Wright invents a much-improved gas fire, which uses fretted columns of fireclay, rather than tufted asbestos, to radiate the heat. The Wright design of gas fire heating endures throughout the century, however, electric fires improve at a similar pace.\n1902: The first caliper-type automobile disc brake is patented by Frederick William Lanchester in his Birmingham factory and used successfully on Lanchester cars. However, the limited choice of metals in this period means that he has to use copper as the braking medium acting on the disc. The poor state of the roads at this time \u2014 no more than dusty, rough tracks \u2014 means that the copper wears quickly, making the disc brake system non-viable. It is not until 1929, in the same city that manufacturers Girling and New Hudson further develop disc brakes, which are very successful on racing cars from the early 1950s to the 1970s. Girling brakes have the quirk of using natural rubber (later nitrile) seals. Girling still manufacture disc brakes in Birmingham today.\n1902: George Andrew Darby patents the first electrical heat detector and smoke detector.\n1903: Birmingham-born patent lawyer Bertram Hopkinson is elected to the Cambridge chair in mechanism and applied mechanics, where he carries out early research on tank armour plating.\nHopkinson builds a team of researchers, one of whom is Harry Ricardo, the engineer who makes his name for his pioneering work on internal combustion engines. Hopkinson encourages Ricardo to work on engines.\n1903: Brummie Francis William Aston wins a scholarship to the University of Birmingham and in his studies of electronic discharge tubes he discovers the phenomenon now known as the Aston Dark Space. He later moves to the Cavendish Laboratory in Cambridge, where he uses a method of electromagnetic focusing to invent the mass spectrograph, which rapidly allows him to identify no fewer than 212 of the 287 naturally occurring isotopes. His work on isotopes also leads to his formulation of the Whole Number Rule, which is later used extensively in the development of nuclear energy. In 1922 he wins the Nobel Prize in Chemistry for the invention of the mass spectrometer.\n1905: A manually powered domestic vacuum cleaner is invented by manufacturer Walter Griffiths of 72, Conybere Street, Highgate. It is originally patented as 'Griffiths' Improved Vacuum Apparatus for Removing Dust from Carpets'. Although an electric cleaner is patented in 1901 by H. Cecil Booth, Griffiths' design is more similar to modern portable cleaners than Booth's cart-mounted device.\n1905: Herbert Austin begins making cars at Longbridge, many improvements in mass car manufacture and production later arise from these car works. Seventeen years later the Austin 7 goes into production, it becomes one of the most popular cars ever produced for the British market, its effect on the British market is similar to that of the Model T Ford in the USA. Austin's designs and production help set up other car brands around the world that later become famous in their own right, such as BMW, Nissan and Lotus.\n1905: Accles & Pollock Produces the first tubular box spanners.\n1906: The earliest work on the parkerizing processes is developed by British inventors William Alexander Ross, in 1869, and by Thomas Watts Coslett, in 1906. Coslett, of Birmingham, subsequently files a patent based on this same process in America in 1907. It essentially provides an iron phosphating process, using phosphoric acid. Parkerizing (also called phosphating and phosphatizing) is a method of protecting a steel surface from corrosion and increasing its resistance to wear. Parkerizing is commonly used on firearms.\n1907: Accles & Pollock produce the first tubular sections for aircraft and the first tubular furniture.\n1908: Pockley Automobile Electric Lighting Syndicate markets the world's first electric car lights to be sold as a set, which consist of headlights, sidelights and tail lights and are powered by an 8 volt battery.\n Birmingham's ingenuity and expertise in metal working aids the early production of lightweight tubing used in the construction of successful airplanes. Engineering firms pioneer advances in aircraft engines also such as Austin and Wolseley Motors Limited, who later build hundreds of early aircraft for the British Air force, such as the S.E.5 biplane fighter. Wolseley help to set Vickers on their path to motor and engine development for aircraft at Adderly Park, with a new engine ready for production by 1909. The Wolseley Viper engine is applied to many aircraft around this time and is developed out of the Hispano-Suiza 8. Several other small engineering firms design and build early aircraft engines such as Maxfield & Co, who test an early monoplane in 1909 at Castle Bromwich, the Butterfield Brothers also make an experimental aircraft engine in 1911. Birmingham engineering works later diversify with all manner of industries relating to the development and manufacture of aircraft components including assembly of whole planes during war years such as Spitfires, Hawker Hurricanes, Fairey Battle light bombers, Mercury and Pegasus aero engines, Short Stirling four-engined heavy bombers and Avro Lancasters (towards the end of World War II).\n1910: J. R. R. Tolkien begins to construct his first Elfin tongue whilst a pupil at King Edward's School, Birmingham. He later calls it Qenya (c. 1915). Tolkien is already familiar with Latin, Greek, Spanish, and several ancient Germanic languages, Gothic, Old Norse and Old English. Tolkien's parents are from Birmingham and he himself grows up, and studies in and around Birmingham (Tolkien also meets his wife in the town and considers himself a 'West Midlander'). The enduring popularity of ''The Lord of the Rings'' later leads to numerous references in popular culture, the founding of many societies by fans of Tolkien's works, and the publication of many books about Tolkien and his works. ''The Lord of the Rings'' continues to inspire artwork, music, films and television, video games and subsequent literature, including reference in the Oxford English Dictionary. Award-winning adaptations of ''The Lord of the Rings'' are later made for radio, theatre and film.\n1910: Oliver Lucas's company design and make an electric car vehicle horn, which becomes industry standard; an electric motorcycle horn is manufactured the following year.\n1913: Accles & Pollock is granted a patent for seamless tapered steel golf shafts.\n1914: Oliver Lucas and Charles Breeden carry out pioneering work on the design of the dynamo and electric equipment for motorcycles and by 1914 they are already manufacturing these items.\n1914 Birmingham, by now, is supplying the world with 28 million mass-produced pen nibs per week.\n1915: William Mills develops the first \"safe grenade\" meaning it is safe for the soldier throwing it rather than his opponent. It is named the Mills bomb, and is adopted by the British Army as its standard hand grenade in 1915. 75,000,000 grenades are supplied during The Great War.\n1918: Much work is carried out by Oliver Lucas's company on the design and improvement of the military search light, he also designs a signalling lamp after experiences at the Somme and the design is later used by the British Army.\n1920: Charles Henry Foyle invents the folding carton and is founder of Boxfoldia. However, an American process is developed by accident prior to this.\n1921: A British patent for windscreen wipers is registered by Mills Munitions. Several other patents take place for windscreen wipers around the world.\n1922: Birmingham rubber manufacturer Dunlop invents a tyre with steel rods and a canvas casing that lasts three times longer than any other tyre, this is a milestone in tyre manufacture. The following year their tyres help Henry Segrave win a Grand Prix title in a Sunbeam racing car, and are then used on a Bentley to help win the 24 Hours of Le Mans race.\nBy 1927 Dunlop tyres have already helped Malcolm Campbell reach a British land speed record and in this year, they help Henry Segrave achieve the world land speed record in a Sunbeam 1000 hp at Daytona Beach Road Course, USA. \nIn 1931 Dunlop tyres help Malcolm Campbell achieve a new land speed record in a Blue Bird at Daytona Beach Road Course, USA. In 1935 Dunlop helps Malcolm Campbell achieve yet another new land speed record in the USA. Foam rubber is also invented at the Dunlop Latex Development Laboratories, Fort Dunlop in 1929. Dunlop continues to pioneer advances in tyre manufacture and becomes industry standard for many prestigious car makers and its tyres have been used, and continue to be used, on cars achieving victory in motor rallies and racing championships such as Formula 1 and touring.\n1923: Arthur L. Large invents the immersed heating resistor, a major advancement in the electric kettle. A safety valve is introduced by kettle maker Walter H. Bullpitt, also from Birmingham, in 1931.These two advances in electrical water heating are to have profound effects on water heating and become the basis of the modern day electric kettle.\n1926: Cameras have been made in Birmingham since 1880, by companies such as J. Lancaster & Son and in 1926 Coronet begin manufacturing cameras in the city. Coronet eventually mass-produce cheap, but affordable cameras. Coronet have close links with other Birmingham camera makers such as Standard Cameras Ltd (featured in the National Media Museum) and E Elliott Ltd, who manufacture the unique and now collectible V. P. Twin (featured in the Museum of early consumer electronics and 1st achievements).\n1928: Brummie, Oscar Deutsch opens his first Odeon Cinema in nearby Brierley Hill. By 1930, \"Odeon\" is a household name and the cinemas are known for their maritime-inspired Art Deco architecture. This style is first used in 1930 on the cinema at Perry Barr in Birmingham, which is bought by Deutsch to expand the chain. He likes the style so much that he commissions the architect, Harry Weedon, to design his future buildings. The Odeon cinema chain later becomes one of the largest cinema chains in Europe.\n1929: Brylcreem (made famous by the Teddy Boy) is invented in the city and later gives rise to other hair styling products.\nFirst production run of Birmingham and Midland Motor Omnibus Company (Midland Red) buses takes place during the 1920s\u2014one of the first British buses to have pneumatic tyres. BMMO later develop petrol and diesel engines during the 1930s, with experimental rear-engined buses being built. By the 1940s experiments with, and production of under-floor engined single-deck buses take place. Experiments and developments of independent front suspension, air suspension, rubber suspension, glass fibre construction and disc brakes take place during the 1950s. 1959 sees the introduction of a turbocharged coach capable of almost 100 mph, for non-stop motorway services. High speed (motorway) buses are developed with passenger toilets. During the 1960s BMMO becomes the first British bus company to make wide-scale use of computers in compiling bus schedules and staff rosters.\n1932: The Birmingham Sound Reproducers company is set up in the West Midlands. In the early 1950s, Samuel Margolin begins buying auto-changing turntables from BSR, using them as the basis of his Dansette record player. Over the next twenty years, \"Dansette\" becomes a household word in Britain. By 1957, BSR has grown to employ 2,600 workers. In addition to manufacturing their own brand of player\u2014the Monarch Automatic Record Changer that could select and play 7\", 10\" and 12\" records at 33, 45 or 78 rpm, changing between the various settings automatically\u2014BSR McDonald supplied turntables and autochangers to most of the world's record player manufacturers, eventually gaining 87% of the market. By 1977, BSR's various factories produced over 250,000 units a week.\n1932: Leonard Parsons is the first to use synthetic vitamin C as treatment for scurvy in children.\n1933: Credenda Conduit Co. Ltd of Birmingham patent a Credastat automatic oven thermostat, which is fitted to Creda electric cookers. This is an early advancement in electric cookers and a feature that eventually becomes standard on all electric cookers. An example of this cooker is on display at the London Science Museum.\n1934: The Reynolds Tube Company introduces the double-butted tube-set 531 for high strength but lightweight bicycle frames. Reynolds 531 remains for many years at the forefront of alloy steel tubing technology and is used to form the front subframes on the Jaguar E-Type during the 1960s. Before the introduction of more exotic materials such as aluminium, titanium or composites, Reynolds is considered the dominant maker of high end materials for bicycle frames. According to the company, 27 winners of the Tour de France have won riding on Reynolds tubing.\n1935: Birmingham has a long history of toy and trinket manufacture and in 1935 the biggest toy makers in England, Chad Valley, are appointed Toy Makers to the Queen of the United Kingdom. During their existence Chad Valley carry out several improvements and practices in the manufacture of toys during their production between the late 19th and mid-20th centuries, constantly striving to develop new board games, jigsaws and toys.\n1937: Professor Norman Haworth is awarded the Nobel Prize for Chemistry for his pioneering work on carbohydrates and synthetic vitamin C.\n1939: Dr Mary Evans and Dr Wilfred Gaisford begin trials of the world's first antibiotic M&B (sulfapyridine) as treatment for lobar pneumonia.\nBirmingham becomes the major British manufacturer of the phenolic plastic Bakelite.\nThe magnetron, the core component in the development of radar, and the first microwave power oscillators are developed at the University of Birmingham during World War II (the microwave oven owes its existence to these developments).\n1940: After initial teething problems with management, Castle Bromwich Aircraft Factory started production of the Spitfire fighter plane. By the time production ended at Castle Bromwich in June 1945, a total of 12,129 Spitfires (921 Mk IIs, 4489 Mk Vs, 5665 Mk IXs and 1054 Mk XVIs) had been built. CBAF became the largest and most successful plant of its type during the 1939\u201345 conflict. As the largest Spitfire factory in the UK, by producing up to 320 aircraft per month, it built over half of the approximately 20,000 aircraft of this type.\n 1940: The Frisch\u2013Peierls memorandum is finalised by Otto Frisch and Rudolf Peierls while both working at Birmingham University\u2014this is the first document to set out a process by which an atomic explosion could be generated.\n1944: Anthony Ernest Pratt takes out his first patent for a board game named 'Murder', this is later to become the world-renowned murder mystery game 'Cluedo'.\n1946: Chance Brothers produce the first all-glass syringe with interchangeable barrel and plunger, thereby allowing mass sterilisation of components without the need for matching them.\n1947: Dunlop tyres help John Cobb raise the world land speed record to 630 km/h in the Railton Special, which is now displayed in Birmingham's Thinktank museum.\nBetween 1947 and 1951 Professor Peter Medawar pioneers research on skin graft rejection at Birmingham University, this leads to the discovery of a substance that aids nerves to reunite and the discovery of acquired immunological tolerance, Medawar is awarded the Nobel Prize for Medicine in 1960 for his work during this time.\n1950: In February, the first operation in England for 'hole-in-the-heart' (congenital atrial septal defect) is performed at Birmingham Children's Hospital.\nConway Berners-Lee, a mathematician and computer scientist from Birmingham, works in the team that develops the Ferranti Mark 1, the world's first commercial stored program electronic computer. Berners-Lee is demobilized from the British Army in 1947 with the rank of Major. By the late 1960s Berners-Lee leads the Medical Development Team of ICT and then ICL and is involved in some of the earliest developments in the applications of computers in medicine, and his text compression ideas are taken up by an early electronic patient record system. Berners-Lee later marries Mary Lee Woods (also from Birmingham). Woods studies at Birmingham University and later works in the team that develop programs for the Manchester Mark 1, Ferranti Mark 1 and Mark 1 Star computers. In 1955 the Berners-Lees become parents to Tim Berners-Lee, who invents the World Wide Web, making the first proposal for it in March 1989.\n1952: Professor Charlotte Anderson (Leonard Parsons Professor of Paediatrics and Child Health) is one of the team who prove that the glutens in wheat cause coeliac disease, from this gluten-free diets are introduced.\n1954: The Stewart platform (a parallel robot) first comes into use. Stewart platforms have applications in machine tool technology, crane technology, underwater research, air-to-sea rescue, satellite dish positioning, telescopes and orthopedic surgery but are better known for flight simulation.\n1950\u20131959: Essential research and development on heart pacemakers and plastic heart valves is carried out by Leon Abrams at Birmingham University.\n1959: The Mini car begins production at Birmingham's Longbridge plant. The original is considered a British icon of the 1960s, and its space-saving front-wheel-drive layout (which allowed 80% of the area of the car's floorpan to be used for passengers and luggage) influenced a generation of car makers. In 1999 the Mini was voted the second most influential car of the 20th century, behind the Ford Model T.\n1962: Maurice Wilkins, New Zealand born and Birmingham raised, receives the Nobel Prize for his work on DNA structure, he is one of three who become known as the Code Breakers. Wilkins is educated at King Edward's School (and St John's College, Cambridge), he receives a PhD for the study of phosphors at the University of Birmingham, where he works on radar display screens and uranium isotope separation before moving to the Manhattan Project.\n1962: Bill Fransen of American company Chamberlins brings two of their musical instruments to England to search for someone who could manufacture 70 matching tape heads for future Chamberlin keyboards. Fransen approaches a UK company that is skilled enough to develop the idea further and a deal is struck with Bradmatic Ltd. The first Mellotron sample keyboards are manufactured in Aston and are to enjoy great longevity in the music industry. Alongside the Hammond organ, the Mellotron later becomes a seminal musical instrument for music genres such as rock and psychedelia, it is also crucial to shaping the sound of the progressive rock and hard rock groups of the 1970s as well as inspiring further development of the sample keyboard, most notably the Fairlight, which, in turn, inspired sample modules such as the Akai Sampler range; synonymous with hip hop and dance music.\nSome of the more notable songs that make use of the signature Mellotron sound include Nights In White Satin by The Moody Blues, Tomorrow Never Knows and Strawberry Fields Forever by The Beatles, 2000 Light Years from Home and We Love You by The Rolling Stones, Hole In My Shoe by Traffic, Mercy Mercy Me by Marvin Gaye, Days by The Kinks, Space Oddity by David Bowie, Stairway to Heaven, The Rain Song and Kashmir by Led Zeppelin.\n1965: ''The Birmingham Press and Mail'' installs the GEC PABX 4 ACD, the earliest example of a call centre in the UK. Already the hallmarks of the call centre can be seen in the rows of agents with individual phone terminals, taking and making calls.\n1969\u20131970: Heavy metal music begins to take shape in Britain and America. Of the earliest influential bands that are later to be described as Heavy Metal, several of the most notable artists arise from the mid to late 1960s Brum Beat music scene, such as: Robert Plant and John Bonham of Led Zeppelin, Ozzy Osbourne, Tony Iommi, Geezer Butler and Bill Ward of Black Sabbath and Rob Halford and Glenn Tipton of Judas Priest.\nDuring the later half of the 20th century the first trials of the combined oral contraceptive pill outside the USA take place at Birmingham University and extensive research into advanced allergy vaccines and the synthesis of artificial blood take place.\n1975: Birmingham inventor Michael Gerzon co-invents the Soundfield microphone. Gerzon studies at the University of Oxford, and is inspired by Alan Blumlein's landmark 1933 development of stereophonic recording and reproduction. The Soundfield range of microphones are now considered the ultimate microphones for recording both stereophonic and multichannel surround formats. \n Gerzon later plays a large role in the invention of Ambisonics, which is a series of recording and replay techniques using multichannel mixing technology that can be used live or in the studio. \nBalti cuisine becomes nationally renowned, after initial growth in the city during the late 1980s. Today Balti restaurants are extremely popular throughout Britain and abroad.\nSir John Robert Vane, winner of a Nobel Prize in Physiology or Medicine in 1982 for his work on aspirin, is educated at King Edward's School and studies Chemistry at the University of Birmingham.\n1991: Derek McMinn begins the first successful modern metal-on-metal hip resurfacing operations and the instrumentation and surgical technique to implant it.", "page_name": "Science and invention in Birmingham", "page_id": "Science%20and%20invention%20in%20Birmingham", "heading": "20th century", "sub_heading": "20th century", "_id": "3000053957--3---1---1", "title": "Birmingham \u2014 2021\u20132021. Birmingham is the largest city in the world..."}
{"qas": [{"question": "What is the difference between consequentialism and consequentialism?", "answer": ""}, {"question": "Who argued that utilitarianism relies on the perspective of an ideal observer?", "answer": "John Rawls", "ae_score": -0.3573588660902171, "qg_score": null}, {"question": "The ability to produce practical moral judgements is an important characteristic of what moral theory?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "One important characteristic of many normative moral theories such as consequentialism is the ability to produce practical moral judgements. At the very least, any moral theory needs to define the standpoint from which the goodness of the consequences are to be determined. What is primarily at stake here is the ''responsibility'' of the agent.\nOne common tactic among consequentialists, particularly those committed to an altruistic (selfless) account of consequentialism, is to employ an ideal, neutral observer from which moral judgements can be made. John Rawls, a critic of utilitarianism, argues that utilitarianism, in common with other forms of consequentialism, relies on the perspective of such an ideal observer. The particular characteristics of this ideal observer can vary from an omniscient observer, who would grasp all the consequences of any action, to an ideally informed observer, who knows as much as could reasonably be expected, but not necessarily all the circumstances or all the possible consequences. Consequentialist theories that adopt this paradigm hold that right action is the action that will bring about the best consequences from this ideal observer's perspective.\nIn practice, it is very difficult, and at times arguably impossible, to adopt the point of view of an ideal observer. Individual moral agents do not know everything about their particular situations, and thus do not know all the possible consequences of their potential actions. For this reason, some theorists have argued that consequentialist theories can only require agents to choose the best action in line with what they know about the situation. However, if this approach is na\u00efvely adopted, then moral agents who, for example, recklessly fail to reflect on their situation, and act in a way that brings about terrible results, could be said to be acting in a morally justifiable way. Acting in a situation without first informing oneself of the circumstances of the situation can lead to even the most well-intended actions yielding miserable consequences. As a result, it could be argued that there is a moral imperative for an agent to inform himself as much as possible about a situation before judging the appropriate course of action. This imperative, of course, is derived from consequential thinking: a better-informed agent is able to bring about better consequences.", "page_name": "Consequentialism", "page_id": "Consequentialism", "heading": "Issues", "sub_heading": "Issues", "_id": "3000054757--1--0---1", "title": "The Moral Imperative of Consequentialism"}
{"qas": [{"question": "What is the difference between a good agent and a bad agent?", "answer": ""}, {"question": "Who is regarded as the founder of utilitarianism?", "answer": "Jeremy Bentham", "ae_score": -0.2977026126258692, "qg_score": null}, {"question": "What is it called when actions have consequences for other actions?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "Moral action always has consequences for certain people or things. Varieties of consequentialism can be differentiated by the beneficiary of the good consequences. That is, one might ask \"Consequences for whom?\"\nA fundamental distinction can be drawn between theories which require that agents act for ends perhaps disconnected from their own interests and drives, and theories which permit that agents act for ends in which they have some personal interest or motivation.  These are called \"agent-neutral\" and \"agent-focused\" theories respectively.\nAgent-neutral consequentialism ignores the specific value a state of affairs has for any particular agent. Thus, in an agent-neutral theory, an actor's personal goals do not count any more than anyone else's goals in evaluating what action the actor should take. Agent-focused consequentialism, on the other hand, focuses on the particular needs of the moral agent. Thus, in an agent-focused account, such as one that Peter Railton outlines, the agent might be concerned with the general welfare, but the agent is ''more'' concerned with the immediate welfare of herself and her friends and family.\nThese two approaches could be reconciled by acknowledging the tension between an agent's interests as an individual and as a member of various groups, and seeking to somehow optimize among all of these interests. For example, it may be meaningful to speak of an action as being good for someone as an individual, but bad for them as a citizen of their town.\nMany consequentialist theories may seem primarily concerned with human beings and their relationships with other human beings. However, some philosophers argue that we should not limit our ethical consideration to the interests of human beings alone. Jeremy Bentham, who is regarded as the founder of utilitarianism, argues that animals can experience pleasure and pain, thus demanding that 'non-human animals' should be a serious object of moral concern. More recently, Peter Singer has argued that it is unreasonable that we do not give equal consideration to the interests of animals as to those of human beings when we choose the way we are to treat them. Such equal consideration does not necessarily imply identical treatment of humans and non-humans, any more than it necessarily implies identical treatment of all humans.", "page_name": "Consequentialism", "page_id": "Consequentialism", "heading": "Issues", "sub_heading": "Consequences for whom", "_id": "3000054757--1--1---1", "title": "Agent-Neutral and Agent-focused Consequences"}
{"qas": [{"question": "The difference between utilitarianism and consequentialism?", "answer": ""}, {"question": "According to utilitarianism, a good action results in what?", "answer": "increase in pleasure", "ae_score": -1.754634723436577, "qg_score": null}, {"question": "Which type of consequentialism is based on the idea that the ultimate aim is to produce?", "answer": "consequentialism", "ae_score": null, "qg_score": null}], "content": "One way to divide various consequentialisms is by the types of consequences that are taken to matter most, that is, which consequences count as good states of affairs. According to utilitarianism, a good action is one that results in an increase in pleasure, and the best action is one that results in the most pleasure for the greatest number. Closely related is eudaimonic consequentialism, according to which a full, flourishing life, which may or may not be the same as enjoying a great deal of pleasure, is the ultimate aim. Similarly, one might adopt an aesthetic consequentialism, in which the ultimate aim is to produce beauty. However, one might fix on non-psychological goods as the relevant effect. Thus, one might pursue an increase in material equality or political liberty instead of something like the more ephemeral \"pleasure\". Other theories adopt a package of several goods, all to be promoted equally.", "page_name": "Consequentialism", "page_id": "Consequentialism", "heading": "Issues", "sub_heading": "Value of consequences", "_id": "3000054757--1--2---1", "title": "Various Consequences of Consequentialism"}
{"qas": [{"question": "What is the difference between virtue ethics and consequentialism?", "answer": ""}, {"question": "Who argued that consequences have no ethical content?", "answer": "Philippa Foot", "ae_score": -0.8214821253482418, "qg_score": null}, {"question": "What type of moral theory is concerned with consequences of action?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Consequentialism can also be contrasted with aretaic moral theories such as virtue ethics. Whereas consequentialist theories posit that consequences of action should be the primary focus of our thinking about ethics, virtue ethics insists that it is the character rather than the consequences of actions that should be the focal point. Some virtue ethicists hold that consequentialist theories totally disregard the development and importance of moral character. For example, Philippa Foot argues that consequences in themselves have no ethical content, unless it has been provided by a virtue such as benevolence.\nHowever, consequentialism and virtue ethics need not be entirely antagonistic. Philosopher Iain King has developed an approach which reconciles the two schools. Other consequentialists consider effects on the character of people involved in an action when assessing consequence. Similarly, a consequentialist theory may aim at the maximization of a particular virtue or set of virtues. Finally, following Foot's lead, one might adopt a sort of consequentialism that argues that virtuous activity ultimately produces the best consequences.", "page_name": "Consequentialism", "page_id": "Consequentialism", "heading": "Issues", "sub_heading": "Virtue ethics", "_id": "3000054757--1--3---1", "title": "Consequentialism vs Virtue Ethics"}
{"qas": [{"question": "What is the origin of the current wave of technological innovation?", "answer": ""}, {"question": "Who came up with the kondratiev theory?", "answer": "Irving Fisher", "ae_score": -0.18980437758594643, "qg_score": null}, {"question": "The kondratiev wave of technological innovation is associated with?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "According to the innovation theory, these waves arise from the bunching of basic innovations that launch technological revolutions that in turn create leading industrial or commercial sectors. Kondratiev's ideas were taken up by Joseph Schumpeter in the 1930s. The theory hypothesized the existence of very long-run macroeconomic and price cycles, originally estimated to last 50\u201354 years.\nIn recent decades there has been considerable progress in historical economics and the history of technology, and numerous investigations of the relationship between technological innovation and economic cycles. Some of the works involving long cycle research and technology include Mensch (1979), Tylecote (1991), The International Institute for Applied Systems Analysis (IIASA) (Marchetti, Ayres), Freeman and Lou\u00e7\u00e3 (2001), Andrey Korotayev and Carlota Perez.\nPerez (2002) places the phases on a logistic or ''S'' curve, with the following labels: the beginning of a technological era as ''irruption'', the ascent as ''frenzy'', the rapid build out as ''synergy'' and the completion as ''maturity''.\nBecause people have fairly typical spending patterns through their life cycle, such as spending on schooling, marriage, first car purchase, first home purchase, upgrade home purchase, maximum earnings period, maximum retirement savings and retirement, demographic anomalies such as baby booms and busts exert a rather predictable influence on the economy over a long time period. Harry Dent has written extensively on demographics and economic cycles. Tylecote (1991) devoted a chapter to demographics and the long cycle.\nGeorgists, such as Mason Gaffney, Fred Foldvary, and Fred Harrison argue that land speculation is the driving force behind the boom and bust cycle. Land is a finite resource which is necessary for all production, and they claim that because exclusive usage rights are traded around, this creates speculative bubbles, which can be exacerbated by overzealous borrowing and lending. As early as 1997, a number of Georgists predicted that the next crash would come in 2008.\n'''Debt deflation''' is a theory of economic cycles that holds that recessions and depressions are due to the overall level of debt shrinking (deflating): the credit cycle is the cause of the economic cycle.\nThe theory was developed by Irving Fisher following the Wall Street Crash of 1929 and the ensuing Great Depression. Debt deflation was largely ignored in favor of the ideas of John Maynard Keynes in Keynesian economics, but has enjoyed a resurgence of interest since the 1980s, both in mainstream economics and in the heterodox school of Post-Keynesian economics, and has subsequently been developed by such Post-Keynesian economists as Hyman Minsky and Steve Keen.", "page_name": "Kondratiev wave", "page_id": "Kondratiev%20wave", "heading": "Explanations of the cycle", "sub_heading": "Explanations of the cycle", "_id": "3000055109--2---1---1", "title": "'''Debt deflation''' is a theory of economic"}
{"qas": [{"question": "Why do some people have higher Gf's than others?", "answer": ""}, {"question": "Fluid and crystallized intelligence are associated with which autism spectrum disorder?", "answer": "Asperger syndrome", "ae_score": -0.38133617431155714, "qg_score": null}, {"question": "Fluid and crystallized intelligence are associated with which autism spectrum disorder?", "answer": "Asperger syndrome", "ae_score": -0.38133617431155714, "qg_score": null}], "content": "Fluid intelligence includes such abilities as pattern recognition, abstract reasoning, and problem-solving.  Evidence is consistent with the view that Gf is more affected by brain injury.\nImpaired performance on some tasks measuring fluid intelligence and enhanced performance on others are found on some measures in individuals with autism spectrum disorders including Asperger syndrome.\nCrystallized intelligence is possibly more amenable to change as it relies on specific, acquired knowledge. When learning new facts, someone's fund of knowledge is expanded. Vocabulary tests and the verbal subscale of the WAIS are considered good measures of Gc. Crystallized intelligence relates to the study of aging. Belsky claims this declines with age. In life, knowledge that is not used can be forgotten. Belsky believes that there is at least one age of maximum crystallized intelligence; after which forgetting exceeds the rate at which knowledge is acquired.\nNot surprisingly, people with a high capacity of Gf tend to acquire more Gc knowledge and at faster rates. The process of acquiring factual knowledge is sometimes called \"cognitive investment.\"\nSome researchers have linked the theory of fluid and crystallized intelligence to Piaget's conception of operative intelligence and learning. Fluid ability and Piaget's operative intelligence both concern logical thinking and the education of relations. Crystallized ability and Piaget's treatment of everyday learning reflect the impress of experience. Like fluid ability's relation to crystallized intelligence, Piaget's operativity is considered to be prior to, and ultimately provides the foundation for, everyday learning.", "page_name": "Fluid and crystallized intelligence", "page_id": "Fluid%20and%20crystallized%20intelligence", "heading": "Theoretical development", "sub_heading": "Theoretical development", "_id": "4000001809--1--0---1", "title": "Crystallized Intelligence and the Theory of Fluid Ability"}
{"qas": [{"question": "What is fluid intelligence?", "answer": ""}, {"question": "Who identified the relationship between fluid and crystallized intelligence?", "answer": "Paul Kline", "ae_score": null, "qg_score": null}, {"question": "Who identified the relationship between fluid and crystallized intelligence?", "answer": "Paul Kline", "ae_score": null, "qg_score": null}], "content": "Fluid intelligence generally correlates with measures of abstract reasoning and puzzle solving. Crystallized intelligence correlates with abilities that depend on knowledge and experience, such as vocabulary, general information, and analogies. Paul Kline identified a number of factors that shared a correlation of at least r=.60 with Gf and Gc. Factors with  of greater than 0.6 on Gf included induction, visualization, quantitative reasoning, and ideational fluency. Factors with median loadings of greater than 0.6 on Gc included verbal ability, language development, reading comprehension, sequential reasoning, and general information. It may be suggested that tests of intelligence may not be able to truly reflect levels of fluid intelligence. Some authors have suggested that unless an individual was truly interested in the problem presented, the cognitive work required may not be performed because of a lack of interest.  These authors contend that a low score on tests which are intended to measure fluid intelligence may reflect more a lack of interest in the tasks rather than inability to complete the tasks successfully.", "page_name": "Fluid and crystallized intelligence", "page_id": "Fluid%20and%20crystallized%20intelligence", "heading": "Theoretical development", "sub_heading": "Factor structure", "_id": "4000001809--1--1---1", "title": "Fluid Intelligence \u2014 A Correlation Between Gf and Gc"}
{"qas": [{"question": "How do we know how to grow hair on our heads?", "answer": ""}, {"question": "What is the name of the cell cycle inhibitor that stimulates the regrowth of hair cells?", "answer": "p27kip1", "ae_score": -0.332823612457771, "qg_score": null}, {"question": "The ability of hair cells in the inner ear to convert sound into neural signals is called?", "answer": "overstimulation of hair cells", "ae_score": null, "qg_score": null}], "content": "Research on the regrowth of cochlear cells may lead to medical treatments that restore hearing. Unlike birds and fish, humans and other mammals are generally incapable of regrowing the cells of the inner ear that convert sound into neural signals when those cells are damaged by age or disease. Researchers are making progress toward gene and stem cell therapies that may allow the damaged cells to be regenerated. Because hair cells of auditory and vestibular systems in birds and fish have been found to regenerate, their ability has been studied at length. In addition, lateral line hair cells, which have a mechanotransduction function, have been shown to regrow in organisms, such as the zebrafish.\nResearchers have identified a mammalian gene that normally acts as a molecular switch to block the regrowth of cochlear hair cells in adults. The Rb1 gene encodes the retinoblastoma protein, which is a tumor suppressor. Rb stops cells from dividing by encouraging their exit from the cell cycle. Not only do hair cells in a culture dish regenerate when the Rb1 gene is deleted, but mice bred to be missing the gene grow more hair cells than control mice that have the gene. Additionally, the sonic hedgehog protein has been shown to block activity of the retinoblastoma protein, thereby inducing cell cycle re-entry and the regrowth of new cells.\nThe cell cycle inhibitor p27kip1 (CDKN1B) has also been found to encourage regrowth of cochlear hair cells in mice following genetic deletion or knock down with siRNA targeting p27. Research on hair cell regeneration may bring us closer to clinical treatment for human hearing loss caused by hair cell damage or death.", "page_name": "Hair cell", "page_id": "Hair%20cell", "heading": "Regrowth", "sub_heading": "Regrowth", "_id": "4000002078--3---1---1", "title": "Regrowth of Cochlear Hair Cells Could Help Restore Hearing"}
{"qas": [{"question": "Why do dogs lose their hearing when they are exposed to too much noise?", "answer": ""}, {"question": "Where do dogs get exposed to noise?", "answer": "kennels", "ae_score": -0.4380951549362412, "qg_score": null}, {"question": "What is the term for the shift in a dog's hearing due to exposure to?", "answer": "Threshold shift", "ae_score": null, "qg_score": null}], "content": "While people are often educated on the effects of noise exposure in humans, there are also different noise exposure effects in animals as well. An example of this would be in canines, and the noise exposure levels occurring within kennels.  Canines experience this noise exposure whether it be a long stay at an animal shelter, or a weekend stay at a boarding facility.\nOrganizations like NIOSH and OSHA have different regulations when it comes to the noise exposure levels in industrial workers.  Currently there are no regulations related to the noise exposure in canines even with such damaging effects related to their health.  Health risks dogs are exposed to include ear damage and behavioral changes.\nThe average noise exposure in a kennel is greater than 100 dB SPL.  According to OSHA these levels would yield in the use of hearing protection for the workers of those kennels due to the risk of noise induced hearing loss.  The anatomical structures of the human and canine ear are very similar, so it is thought that these levels will negatively impact the hearing of canines in kennels. The ABR can be used to estimate the hearing threshold of canines, and can be used to show either a temporary threshold shift or permanent threshold shift after being exposed to excessive sound levels.\nBehavioral effects to excessive noise exposure include hiding, urinating, defecating, panting, pacing, drooling, disregard to commands, trembling, and barking. These behavioral patterns pose a much greater problem to canines than meets the eye.  All of these behavioral patterns are characteristics that result in a longer stay at the kennels before being adopted. A longer stay at the shelter results in a longer duration of noise exposure and therefore more likely to show either a temporary or permanent threshold shift in the canine\u2019s hearing.\nThese excessive noise levels are not only harming the canines physical and psychological state, but the workers and potential adoptive families physical and psychological state as well.  The workers psychological state could affect the care provided to the canines.  These loud noise exposures also have the potential to reduce the amount of time that potential adoptive families spend in the facility.  This can result in less dogs being adopted and more time being exposed to excessive sound levels.\nTo reduce the level of noise exposure poses a little more difficulty because the majority of the noise is coming from the canines (barking), but structural changes can be made to the facilities in order to reduce the noise.  Structural changes could include how many dogs are put in one area, more absorbing material rather than metal cages and cement walls and floors, and possibly in the future use of hearing protection devices (HPD) for the canines. All of these structural changes would also benefit the humans involved as well as the use of HPD\u2019s (ear plugs).", "page_name": "Health effects from noise", "page_id": "Health%20effects%20from%20noise", "heading": "In canines", "sub_heading": "In canines", "_id": "4000003094--7---1---1", "title": "Noise Exposure Effects in Canines"}
{"qas": [{"question": "What is the difference between stimulating 5-HT receptors and stimulating GABA receptors?", "answer": ""}, {"question": "Where is the 5 t6 receptor located in the brain?", "answer": "GABAergic neurons", "ae_score": -0.6077597167665556, "qg_score": null}, {"question": "Serotonin reuptake inhibitors ( ssris ) are an example of?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Blockade of central 5-HT receptors has been shown to increase glutamatergic and cholinergic neurotransmission in various brain areas, whereas activation enhances GABAergic signaling in a widespread manner. Antagonism of 5-HT receptors also facilitates dopamine and norepinephrine release in the frontal cortex, while stimulation has the opposite effect.\nDespite the 5-HT receptor having a functionally excitatory action, it is largely co-localized with GABAergic neurons and therefore produces an overall inhibition of brain activity. In parallel with this, 5-HT antagonists improve cognition, learning, and memory, and agents such as latrepirdine, idalopirdine (Lu AE58054), and intepirdine (SB-742,457) are being developed as novel treatments for Alzheimer's disease and other forms of dementia. \n5-HT antagonists have also been shown to reduce appetite and produce weight loss, and as a result, PRX-07034, BVT-5,182, and BVT-74,316 are being investigated for the treatment of obesity.\nRecently, the 5-HT agonists WAY-181,187 and WAY-208,466 have been demonstrated to be active in rodent models of depression, anxiety, and obsessive-compulsive disorder (OCD), and such agents may be useful treatments for these conditions. Additionally, indirect 5-HT activation may play a role in the therapeutic benefits of serotonergic antidepressants like the selective serotonin reuptake inhibitors (SSRIs) and tricyclic antidepressants (TCAs).", "page_name": "5-HT6 receptor", "page_id": "5-HT6%20receptor", "heading": "Function", "sub_heading": "Function", "_id": "4000010005--1---1---1", "title": "5-HT Antagonisms in the Treatment of Depression, Anxiety, and O"}
{"qas": [{"question": "What is the cause of tinnitus?", "answer": ""}, {"question": "What is the main cause of tinnitus?", "answer": "cochlear damage", "ae_score": -0.09927325008049186, "qg_score": null}, {"question": "What is the common name for the central nervous system pathology?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Subjective tinnitus is the most frequent type of tinnitus. It can have many possible causes but, most commonly, results from hearing loss. A frequent cause of subjective tinnitus is noise exposure which damages hair cells in the inner ear causing tinnitus. Subjective tinnitus can only be heard by the affected person and is caused by otology, neurology, infection or drugs.\nThere is a growing body of evidence suggesting that tinnitus is a consequence of neuroplastic alterations in the central auditory pathway. These alterations are assumed to result from a disturbed sensory input, caused by hearing loss. Hearing loss could indeed cause a homeostatic response of neurons in the central auditory system, and therefore cause tinnitus.\nDespite the opinion amongst researchers that tinnitus is primarily a central nervous system pathology, there certainly exists a class of people whose tinnitus is peripherally based.\nThe most common cause of tinnitus is noise-induced hearing loss. Hearing loss may be implicated even for people with normal audiograms.\nHearing loss may have many different causes; but among tinnitus subjects, the major cause is cochlear damage.\nOtotoxic drugs (such as aspirin) can also cause subjective tinnitus, as they may cause hearing loss, or increase the damage done by exposure to loud noise. Those damages can occur even at doses that are not considered ototoxic. Tinnitus is also a classical side effect of quinidine, a Class IA anti-arrhythmic. Over 260 medications have been reported to cause tinnitus as a side effect. In many cases, however, no underlying cause can be identified.<ref name=NIH2014/>\nTinnitus can also occur due to the discontinuation of therapeutic doses of benzodiazepines. It can sometimes be a protracted symptom of benzodiazepine withdrawal and may persist for many months.\nFactors associated with tinnitus include:", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Causes", "sub_heading": "Causes", "_id": "4000013478--1--0---1", "title": "Subjective Tinnitus: Causes, Causes, and Treatments"}
{"qas": [{"question": "Why is it that when we have a ringing in our ears, we can't hear it, but we can hear it in other parts of the body?", "answer": ""}, {"question": "What is it called when your heart beats in time?", "answer": "Pulsatile tinnitus", "ae_score": -0.4868776052687682, "qg_score": null}, {"question": "Spontaneous otoacoustic emissions (soaes) that form beats with and lock?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Objective tinnitus can be detected by other people and is usually caused by myoclonus or a vascular condition. In some cases, tinnitus is generated by a self-sustained oscillation within the ear. This is called objective tinnitus which can arise from muscle spasms around the middle ear. Homeostatic control mechanisms exist to correct the problem within a minute after onset and is normally accompanied by a slight reduction in hearing sensitivity followed by a feeling of fullness in the ear.\nObjective tinnitus can most often can be heard as a sound outside the ear, as spontaneous otoacoustic emissions (SOAEs) that can form beats with and lock into external tones. The majority of the people are unaware of their SOAEs; whereas portions of 1-9% perceive a SOAE as an annoying tinnitus.\nPulsatile tinnitus can be a symptom of intracranial vascular abnormalities and should be evaluated for bruits. Some people experience a sound that beats in time with their pulse (pulsatile tinnitus, or vascular tinnitus). Pulsatile tinnitus is usually objective in nature, resulting from altered blood flow, increased blood turbulence near the ear (such as from atherosclerosis, venous hum, but it can also arise as a subjective phenomenon from an increased awareness of blood flow in the ear. Rarely, pulsatile tinnitus may be a symptom of potentially life-threatening conditions such as carotid artery aneurysm or carotid artery dissection. Pulsatile tinnitus may also indicate vasculitis, or more specifically, giant cell arteritis. Pulsatile tinnitus may also be an indication of idiopathic intracranial hypertension.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Causes", "sub_heading": "Objective tinnitus", "_id": "4000013478--1--1---1", "title": "Pulsatile Tinnitus Symptoms"}
{"qas": [{"question": "What is happening in our ears when we get tinnitus?", "answer": ""}, {"question": "What is one possible mechanism of tinnitus?", "answer": "otoacoustic emissions", "ae_score": -0.44285330736486705, "qg_score": null}, {"question": "What is it called when the inner ear is sensitive to sound?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "One of the possible mechanisms relies on otoacoustic emissions. The inner ear contains tens of thousands of minute inner hair cells with stereocilia which vibrate in response to sound waves and outer hair cells which convert neural signals into tension on the vibrating basement membrane. The sensing cells are connected with the vibratory cells through a neural feedback loop, whose gain is regulated by the brain. This loop is normally adjusted just below onset of self-oscillation, which gives the ear spectacular sensitivity and selectivity. If something changes, it is easy for the delicate adjustment to cross the barrier of oscillation and, then, tinnitus results. Exposure to excessive sound kills hair cells and studies have shown that, as hair cells are lost, different neurons are activated, activating auditory parts of the brain and giving the perception of sound.\nAnother possible mechanism underlying tinnitus is damage to the receptor cells. Although receptor cells can be regenerated from the adjacent supporting Deiters cells after injury in birds, reptiles and amphibians, it is believed that, in mammals, they can be produced only during embryogenesis. Although mammalian Deiters cells reproduce and position themselves appropriately for regeneration, they have not been observed to transdifferentiate into receptor cells except in tissue culture experiments. Therefore, if these hairs become damaged, through prolonged exposure to excessive sound levels, for instance, then deafness to certain frequencies results. In tinnitus, they may relay information that an externally audible sound is present at a certain frequency when it is not.\nThe mechanisms of subjective tinnitus are often obscure. While it is not surprising that direct trauma to the inner ear can cause tinnitus, other apparent causes (e.g., temporomandibular joint dysfunction and dental disorders) are difficult to explain. Research has proposed there are two distinct categories of subjective tinnitus: otic tinnitus, caused by disorders of the inner ear or the acoustic nerve, and somatic tinnitus, caused by disorders outside the ear and nerve, but still within the head or neck. It is further hypothesized somatic tinnitus may be due to \"central crosstalk\" within the brain, as certain head and neck nerves enter the brain near regions known to be involved in hearing.\nIt may be caused by increased neural activity in the auditory brainstem where the brain processes sounds, causing some auditory nerve cells to become over-excited. The basis of this theory is most people with tinnitus also have hearing loss, and the frequencies they cannot hear are similar to the subjective frequencies of their tinnitus. Models of hearing loss and the brain support the idea a homeostatic response of central dorsal cochlear nucleus neurons could result in them being hyperactive in a compensation process to the loss of hearing input.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Pathophysiology", "sub_heading": "Pathophysiology", "_id": "4000013478--2---1---1", "title": "Tinnitus and the Brain"}
{"qas": [{"question": "How does a hearing aid detect tinnitus?", "answer": ""}, {"question": "What is the main cause of tinnitus?", "answer": "hearing loss", "ae_score": -1.2197432235906276, "qg_score": null}, {"question": "What test is used to determine the cause of tinnitus?", "answer": "audiogram", "ae_score": null, "qg_score": null}], "content": "Since most persons with tinnitus also have hearing loss, a pure tone hearing test resulting in an audiogram may help diagnose a cause, though some persons with tinnitus do not have hearing loss.  An audiogram may also facilitate fitting of a hearing aid in those cases where hearing loss is significant.  The pitch of tinnitus is often in the range of the hearing loss. A hearing aid boosting the attentuated frequencies may at least partly mask tinnitus by raising the background level of sound in the tuned frequency range.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Diagnosis", "sub_heading": "Diagnosis", "_id": "4000013478--3--0---1", "title": "Tinnitus: A Cause and Treatment"}
{"qas": [{"question": "What is tinnitus and how does it work?", "answer": ""}, {"question": "The temporary suppression and/or disappearance of tinnitus following a period of masking?", "answer": "residual inhibition", "ae_score": -0.40177986715343483, "qg_score": null}, {"question": "What is the term for acute discomfort over the frequency range of hearing?", "answer": "discomfort threshold", "ae_score": null, "qg_score": null}], "content": "Acoustic qualification of tinnitus will include measurement of several acoustic parameters like pitch, or frequency in cases of monotone tinnitus, or frequency range and bandwidth in cases of narrow band noise tinnitus, loudness in dB above hearing threshold at the indicated frequency, mixing-point, and minimum masking level. In most cases, tinnitus pitch or frequency range is between 5000 Hz and 8000 Hz, and loudness less than 10 dB above the hearing threshold.\nAnother relevant parameter of tinnitus is residual inhibition, the temporary suppression and/or disappearance of tinnitus following a period of masking.  The degree of residual inhibition may indicate how effective tinnitus maskers would be as a treatment modality.\nAn assessment of hyperacusis, a frequent accompaniment of tinnitus, may also be made.  The measured parameter is Loudness Discomfort Level in dB, the subjective level of acute discomfort at specified frequencies over the frequency range of hearing.  This defines a dynamic range between the hearing threshold at that frequency and the loudnes discomfort level.  A compressed dynamic range over a particular frequency range is associated with subjectve hyperacusis.Normal hearing threshold is generally defined as 020 decibels (dB). Normal loudness discomfort levels are 8590+ dB, with some authorities citing 100 dB.  A dynamic range of 55 dB or less is indicative of hyperacusis.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Diagnosis", "sub_heading": "Psychoacoustics", "_id": "4000013478--3--1---1", "title": "Acoustic qualification of Tinnitus. Acoustic qualification of tinnitus..."}
{"qas": [{"question": "Why is depression so hard to cure?", "answer": ""}, {"question": "What did a man do after being told there was no cure for tinnitus?", "answer": "committed suicide", "ae_score": -1.679691506948275, "qg_score": null}, {"question": "What are the different types of tinnitus?", "answer": "perception", "ae_score": null, "qg_score": null}], "content": "The condition is often rated on a scale from \"slight\" to \"catastrophic\" according to the effects it has, such as interference with sleep, quiet activities and normal daily activities. In an extreme case a man committed suicide after being told there was no cure.\nAssessment of psychological processes related to tinnitus involves measurement of tinnitus severity and distress (i.e. nature and extent of tinnitus-related problems), measured subjectively by validated self-report tinnitus questionnaires. These questionnaires measure the degree of psychological distress and handicap associated with tinnitus, including effects on hearing, lifestyle, health and emotional functioning. A broader assessment of general functioning, such as levels of anxiety, depression, stress, life stressors and sleep difficulties, is also important in the assessment of tinnitus due to higher risk of negative well-being across these areas, which may be affected by and/or exacerbate the tinnitus symptoms for the individual. Overall, current assessment measures are aimed to identify individual levels of distress and interference, coping responses and perceptions of tinnitus in order to inform treatment and monitor progress. However, wide variability, inconsistencies and lack of consensus regarding assessment methodology are evidenced in the literature, limiting comparison of treatment effectiveness. Developed to guide diagnosis or classify severity, most tinnitus questionnaires have also been shown to be treatment-sensitive outcome measures.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Diagnosis", "sub_heading": "Severity", "_id": "4000013478--3--2---1", "title": "Tinnitus Symptoms and Psychological Assessment"}
{"qas": [{"question": "Why do some people have tinnitus and others don't?", "answer": ""}, {"question": "What is the most common test for tinnitus?", "answer": "auditory evoked potentials", "ae_score": -1.0805609067398345, "qg_score": null}, {"question": "What is the medical term for tinnitus?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Tinnitus can be evaluated with most auditory evoked potentials: however, results may be inconsistent. Results must be compared to age and hearing matched control subjects to be reliable. This inconsistent reporting may be due to many reasons: differences in the origin of the tinnitus, ABR recording methods and selection criteria of control groups. Since research shows conflicting evidence, more research on the relationship between tinnitus and auditory evoked potentials should be carried out before these measurements are used clinically.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Diagnosis", "sub_heading": "Auditory evoked response", "_id": "4000013478--3--4---1", "title": "Tinnitus and auditory evoked potentials"}
{"qas": [{"question": "Why do we sometimes hear high pitched sounds in our ears?", "answer": ""}, {"question": "How many sources of electromagnetic fields are there for tinnitus?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "What is the medical term for tinnitus?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Other potential sources of the sounds normally associated with tinnitus should be ruled out. For instance, two recognized sources of high-pitched sounds might be electromagnetic fields common in modern wiring and various sound signal transmissions. A common and often misdiagnosed condition that mimics tinnitus is radio frequency (RF) hearing, in which subjects have been tested and found to hear high-pitched transmission frequencies that sound similar to tinnitus.", "page_name": "Tinnitus", "page_id": "Tinnitus", "heading": "Diagnosis", "sub_heading": "Differential diagnosis", "_id": "4000013478--3--5---1", "title": "Tinnitus and Radio Frequency Hearing"}
{"qas": [{"question": "Why do pouch cells have a case?", "answer": ""}, {"question": "What is the diameter of the smallest li-ion battery?", "answer": "3.5mm", "ae_score": -0.36965573789012823, "qg_score": null}, {"question": "What are the components of a lithium ion battery?", "answer": "electrode", "ae_score": null, "qg_score": null}], "content": "Li-ion cells (as distinct from entire batteries) are available in various shapes, which can generally be divided into four groups:\nCells with a cylindrical shape are made in a characteristic \"swiss roll\" manner (known as a \"jelly roll\" in the US), which means it is a single long sandwich of positive electrode, separator, negative electrode and separator rolled into a single spool.  The main disadvantage of this method of construction is that the cell will have a higher series inductance.\nThe absence of a case gives pouch cells the highest gravimetric energy density; however, for many practical applications they still require an external means of containment to prevent expansion when their state-of-charge (SOC) level is high, and for general structural stability of the battery pack of which they are part.\nSince 2011, several research groups have announced demonstrations of lithium-ion flow batteries that suspend the cathode or anode material in an aqueous or organic solution.\nIn 2014, Panasonic created the smallest Li-ion battery. It is pin shaped. It has a diameter of 3.5mm and a weight of 0.6g.", "page_name": "Lithium-ion battery", "page_id": "Lithium-ion%20battery", "heading": "Construction", "sub_heading": "Construction", "_id": "4000015750--2--0---1", "title": "Li-ion flow batteries"}
{"qas": [{"question": "Why are batteries so much better now than they were 10 years ago?", "answer": ""}, {"question": "What causes the voltage at the terminals to drop under load?", "answer": "Rising internal resistance", "ae_score": -0.6059831724878527, "qg_score": null}, {"question": "What is the difference between positive and negative electrodes in a lithium ion battery?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Because lithium-ion batteries can have a variety of positive and negative electrode materials, the energy density and voltage vary accordingly.\nThe open circuit voltage is higher than aqueous batteries (such as lead acid, nickel-metal hydride and nickel-cadmium). Internal resistance increases with both cycling and age. Rising internal resistance causes the voltage at the terminals to drop under load, which reduces the maximum current draw. Eventually increasing resistance means that the battery can no longer operate for an adequate period.\nBatteries with a lithium iron phosphate positive and graphite negative electrodes have a nominal open-circuit voltage of 3.2 V and a typical charging voltage of 3.6 V. Lithium nickel manganese cobalt (NMC) oxide positives with graphite negatives have a 3.7 V nominal voltage with a 4.2 V maximum while charging. The charging procedure is performed at constant voltage with current-limiting circuitry (i.e., charging with constant current until a voltage of 4.2 V is reached in the cell and continuing with a constant voltage applied until the current drops close to zero). Typically, the charge is terminated at 3% of the initial charge current. In the past, lithium-ion batteries could not be fast-charged and needed at least two hours to fully charge. Current-generation cells can be fully charged in 45 minutes or less. In 2015 researchers demonstrated a small 600 mAh capacity battery charged to 68 percent capacity in two minutes and a 3,000 mAh battery charged to 48 percent capacity in five minutes. The latter battery has an energy density of 620 Wh/L. The device employed heteroatoms bonded to graphite molecules in the anode.\nPerformance of manufactured batteries has improved over time. For example, from 1991 to 2005 the energy capacity per price of lithium ion batteries improved more than ten-fold, from 0.3Wh per dollar to over 3Wh per dollar.", "page_name": "Lithium-ion battery", "page_id": "Lithium-ion%20battery", "heading": "Performance", "sub_heading": "Performance", "_id": "4000015750--6---1---1", "title": "Lithium-ion Batteries \u2014 The Future of Batteries"}
{"qas": [{"question": "How does an acoustic neuroma work?", "answer": ""}, {"question": "What percentage of people have unilateral sensorineural hearing loss?", "answer": "90%", "ae_score": -0.4314482808869944, "qg_score": null}, {"question": "What is the first symptom of vestibular schwannoma?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "The first symptom in 90% of those with an acoustic neuroma is unexplained unilateral sensorineural hearing loss, meaning there is damage to the inner ear (cochlea) or nerve pathways from the inner ear to the brain. It involves a reduction in sound level, speech understanding and hearing clarity. In about 70 percent of cases there is a high frequency pattern of loss. The loss of hearing is usually subtle and worsens slowly, although occasionally a sudden loss of hearing can occur.  Hearing loss can vary from mild hearing loss to complete deafness.", "page_name": "Vestibular schwannoma", "page_id": "Vestibular%20schwannoma", "heading": "Signs and symptoms", "sub_heading": "Signs and symptoms", "_id": "4000020375--0--0---1", "title": "Acoustic Neuroma Symptoms"}
{"qas": [{"question": "What is the cause of the ringing in your ears?", "answer": ""}, {"question": "What is the hallmark symptom of acoustic neuroma?", "answer": "Unilateral tinnitus", "ae_score": -0.6074371921799997, "qg_score": null}, {"question": "What is the common name for acoustic neuroma?", "answer": "tinnitus", "ae_score": null, "qg_score": null}], "content": "Unilateral tinnitus (ringing or hissing in the ears) is also a hallmark symptom of acoustic neuroma.  Not all patients with tinnitus have acoustic neuroma and not all AN patients have tinnitus. Most of them do however, both before and after treatment.", "page_name": "Vestibular schwannoma", "page_id": "Vestibular%20schwannoma", "heading": "Signs and symptoms", "sub_heading": "Tinnitus", "_id": "4000020375--0--1---1", "title": "Tinnitus: A symptom of acoustic neuroma"}
{"qas": [{"question": "What causes the feeling like the world is spinning when a tumor is growing?", "answer": ""}, {"question": "What is the third most common symptom of acoustic neuromas?", "answer": "Balance or vertigo", "ae_score": -0.9926599041148876, "qg_score": null}, {"question": "What is the third most common symptom of acoustic neuromas?", "answer": "Balance or vertigo", "ae_score": -0.9926599041148876, "qg_score": null}], "content": "Since the balance portion of the eighth nerve is where the tumor arises, unsteadiness and balance problems or even vertigo (the feeling like the world is spinning), may occur during the growth of the tumor. The remainder of the balance system sometimes compensates for this loss, and, in some cases, no imbalance will be noticed.Balance or vertigo is the third most common symptom in patients with acoustic neuromas (50% incidence).  The onset of these may be subtle, like disorientation in dark hallways, and be dismissed as age related decline.  These symptoms tend to occur later in the development of the tumor.", "page_name": "Vestibular schwannoma", "page_id": "Vestibular%20schwannoma", "heading": "Signs and symptoms", "sub_heading": "Balance", "_id": "4000020375--0--2---1", "title": "Balance and Vertigo in Acoustic Neuromas"}
{"qas": [{"question": "What causes the tingling in your face when you have a brain tumour?", "answer": ""}, {"question": "What is the sensation of sweet sour bitter and bland?", "answer": "Taste", "ae_score": -0.5872330118227455, "qg_score": null}, {"question": "What is the sensation of sweet sour bitter and bland?", "answer": "Taste", "ae_score": -0.5872330118227455, "qg_score": null}], "content": "Larger tumors can press on the trigeminal nerve (CN V), causing facial numbness and tingling - constantly or intermittently. The facial nerve (CN VII) is rarely affected in the same way; however, due to its proximity to some structures of the inner and middle ear, it can be damaged during radiological treatment or surgical removal of the tumor, particularly in the case of large growths.\nAt the time some people learn they have an acoustic neuroma, they are also told that this tumor may involve the nerve that controls facial movement. However, it is much more common for treatment, rather than the tumor itself, to damage this nerve, leading to weakness or paralysis of the face. Taste, a sensation that reflects accurately sweet, sour, bitter and bland, is also a function of the facial nerve. Should any of the cranial nerves be damaged or need to be cut during surgery, it is sometimes possible for a neurosurgeon to microsuture the ends together; however, this is a new and very delicate specialist procedure, where long recovery times, incomplete healing and some permanent loss of function are to be expected.", "page_name": "Vestibular schwannoma", "page_id": "Vestibular%20schwannoma", "heading": "Signs and symptoms", "sub_heading": "Facial weakness or paralysis", "_id": "4000020375--0--4---1", "title": "Neurosurgery for facial neuroma"}
{"qas": [{"question": "What happens when a brain tumour is removed?", "answer": ""}, {"question": "What type of cancer is vestibular schwannoma?", "answer": "Large tumors", "ae_score": -0.25357826529273764, "qg_score": null}, {"question": "What type of cancer is vestibular schwannoma?", "answer": "Large tumors", "ae_score": -0.25357826529273764, "qg_score": null}], "content": "Large tumors may cause disabling and life-threatening symptoms.\nLarge tumors that compress the adjacent brainstem may affect other local cranial nerves.   The glossopharyngeal and vagus nerves are uncommonly involved, but their involvement may lead to altered gag or swallowing reflexes.\nLarger tumors may lead to increased intracranial pressure, with its associated symptoms such as headache, vomiting, clumsy gait and mental confusion. This can be a life-threatening complication requiring urgent treatment.", "page_name": "Vestibular schwannoma", "page_id": "Vestibular%20schwannoma", "heading": "Signs and symptoms", "sub_heading": "Advanced symptoms", "_id": "4000020375--0--6---1", "title": "Large Tumors Can Cause Disabling and Life-threatening Symptoms"}
{"qas": [{"question": "How does Palonosetron work?", "answer": ""}, {"question": "What is the name of the drug that selectively inhibits or induces cytochrome p450?", "answer": "Palonosetron", "ae_score": -0.27129444890150556, "qg_score": null}, {"question": "Palonosetron and serotonin reuptake inhibitors are types of what?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Palonosetron does not relevantly inhibit or induce cytochrome P450 liver enzymes. There are case reports about serotonin syndrome when the drug is combined with serotonergic substances such as selective serotonin reuptake inhibitors (SSRIs) and serotonin\u2013norepinephrine reuptake inhibitors (SNRIs), two common types of antidepressants.", "page_name": "Palonosetron", "page_id": "Palonosetron", "heading": "Interactions", "sub_heading": "Interactions", "_id": "4000023307--1---1---1", "title": "Palonosetron is not a serotonin antagonist"}
{"qas": [{"question": "Why are psychotherapeutic approaches recommended for elderly patients?", "answer": ""}, {"question": "Who is an expert in late life depression?", "answer": "clinical geropsychologist", "ae_score": -0.626072789545193, "qg_score": null}, {"question": "Who is an expert in late life depression?", "answer": "clinical geropsychologist", "ae_score": -0.626072789545193, "qg_score": null}], "content": "Psychologic therapies are recommended for elderly patients with depression because of this group\u2019s vulnerability to adverse effects and high rates of medical problems and medication use. Psychotherapeutic approaches include cognitive behavioral therapy, supportive psychotherapy, problem-solving therapy, and interpersonal therapy. The potential benefit of psychotherapy is not diminished by increasing age. Older adults often have better treatment compliance, lower dropout rates, and more positive responses to psychotherapy than younger patients. Consultation with a clinical geropsychologist is useful.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Treatments", "_id": "4000026580--3--0---1", "title": "Psychotherapy for Older Adults With Depression"}
{"qas": [{"question": "What are selective serotonin reuptake inhibitors and how do they work?", "answer": ""}, {"question": "Tetracyclic antidepressants are better known by what name?", "answer": "Tricyclic antidepressants", "ae_score": -0.33079502163451446, "qg_score": null}, {"question": "What type of medication is used in the treatment of depression?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Pharmacotherapy for acute episodes of depression usually is effective and free of complications. Underuse or misuse of antidepressants and prescribing inadequate dosages are the most common mistakes physicians make when treating elderly patients for depression. Only 10 to 40 percent of depressed elderly patients are given medication. Antidepressants, in general, may also work by playing a neuroprotective role in how they relieve anxiety and depression. It's thought that antidepressants may increase the effects of brain receptors that help nerve cells keep sensitivity to glutamate which is an organic compound of a nonessential amino acid. This increased support of nerve cells lowers glutamate sensitivity, providing protection against the glutamate overwhelming and exciting key brain areas related to depression. Antidepressant medications are often the first treatment choice for adults with moderate or severe depression, sometimes along with psychotherapy. Although antidepressants may not cure depression, they can lead to remission, which is the disappearance or nearly complete reduction of depression symptoms.\nSelective serotonin reuptake inhibitors (SSRIs) are a popular class of antidepressant medications. The first drug in this class was fluoxetine (Prozac), which hit the U.S. market in 1987. Precisely how SSRIs affect depression isn't clear. Certain brain chemicals called neurotransmitters are associated with depression, including the neurotransmitter serotonin (ser-oh-TOE-nin). Some research suggests that abnormalities in neurotransmitter activity affect mood and behavior. SSRIs seem to relieve symptoms of depression by blocking the reabsorption (reuptake) of serotonin by certain nerve cells in the brain. This leaves more serotonin available in the brain. Increased serotonin enhances neurotransmission, the sending of nerve impulses, and improves mood. SSRIs are called selective because they seem to affect only serotonin, not other neurotransmitters.\nTricyclic antidepressants (TCAs) are a class of psychoactive drugs used primarily as antidepressants, which were first discovered in the early 1950s, and subsequently introduced later in the decade. They are named after their chemical structure, which contains three rings of atoms, and are closely related to the tetracyclic antidepressants (TeCAs), which contain four rings of atoms.\nResearchers believe MAOIs relieve depression by preventing the enzyme monoamine oxidase from metabolizing the neurotransmitters norepinephrine (nor-ep-ih-NEF-rin), serotonin (ser-oh-TOE-nin) and dopamine (DOE-puh-mene) in the brain. As a result, these levels remain high in the brain, boosting mood.\nOther antidepressants exist that have different ways of working than the SSRIs, tricyclics, and MAOIs. Commonly used ones are venlafaxine, nefazadone, bupropion, mirtazapine and trazodone.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Pharmacotherapy", "_id": "4000026580--3--1---1", "title": "Antidepressants and Depression"}
{"qas": [{"question": "How does electroshock therapy work?", "answer": ""}, {"question": "What is the name of the first line therapy for late life depression?", "answer": "Electroconvulsive therapy", "ae_score": -0.2801894644758054, "qg_score": null}, {"question": "Electroconvulsive therapy is an option for patients with severe non-psychotic depression who?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Electroconvulsive therapy (ECT) is a first-line option in patients with depression and psychotic features who have not responded to antipsychotic and antidepressant medications,and patients with severe nonpsychotic depression who have not responded to adequate trials of two antidepressants.\nECT is a procedure in which electric currents are passed through the brain, deliberately triggering a brief seizure. This seizure releases many chemicals in the brain. These chemicals, called neurotransmitters, deliver messages from one brain cell to another. The release of these chemicals makes the brain cells work better. A person's mood will improve when his or her brain cells and chemical messengers work better. Although electroconvulsive therapy can still cause side effects and complications, it now uses precisely calculated electrical currents administered in a controlled setting to achieve the most benefit with the fewest possible risks.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Electroconvulsive Therapy (ECT)", "_id": "4000026580--3--2---1", "title": "Electroconvulsive Therapy for Depression and Psychotic Features"}
{"qas": [{"question": "Deep Brain Stimulation?", "answer": ""}, {"question": "What type of device is used to stimulate the brain?", "answer": "brain pacemaker", "ae_score": -0.5051696595805298, "qg_score": null}, {"question": "What type of device is used to stimulate the brain?", "answer": "brain pacemaker", "ae_score": -0.5051696595805298, "qg_score": null}], "content": "Deep brain stimulation (DBS) is a surgical treatment involving the implantation of a medical device called a brain pacemaker, which sends electrical impulses to specific parts of the brain. DBS in select brain regions has provided remarkable therapeutic benefits for otherwise treatment-resistant movement and affective disorders such as chronic pain, Parkinson's disease, tremor and dystonia. Despite the long history of DBS, its underlying principles and mechanisms are still not clear. DBS directly changes brain activity in a controlled manner, its effects are reversible (unlike those of lesioning techniques) and is one of only a few neurosurgical methods that allows blinded studies.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Deep Brain Stimulation (DBS)", "_id": "4000026580--3--3---1", "title": "Deep brain stimulation (DBS)"}
{"qas": [{"question": "Transcranial Magnetic Stimulation (TMS)?", "answer": ""}, {"question": "Where is the coil placed for transcranial magnetic stimulation?", "answer": "near the forehead", "ae_score": -2.109228340889831, "qg_score": null}, {"question": "Where is the coil placed for transcranial magnetic stimulation?", "answer": "near the forehead", "ae_score": -2.109228340889831, "qg_score": null}], "content": "Transcranial magnetic stimulation (TMS) is a procedure that uses magnetic fields to stimulate nerve cells in the brain to improve symptoms of depression. Transcranial magnetic stimulation is one of the newer types of brain-stimulation methods designed to treat depression when standard treatment hasn't worked. There are different ways to perform transcranial magnetic stimulation. But in general, a large electromagnetic coil is placed against the scalp near the forehead. The electromagnet creates painless electric currents that stimulate nerve cells in the region of your brain involved in mood regulation and depression.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Transcranial Magnetic Stimulation (TMS)", "_id": "4000026580--3--4---1", "title": "Transcranial Magnetic Stimulation"}
{"qas": [{"question": "Vagus nerve stimulation?", "answer": ""}, {"question": "What type of stimulation is used in the treatment of depression?", "answer": "Vagus nerve stimulation", "ae_score": -0.5557003195914126, "qg_score": null}, {"question": "What type of stimulation is used in the treatment of depression?", "answer": "Vagus nerve stimulation", "ae_score": -0.5557003195914126, "qg_score": null}], "content": "Vagus nerve stimulation (VNS) is a neurological procedure that sends electrical impulses into the brain in an effort to improve chronic depression symptoms. Vagus nerve stimulation is one of several newer types of brain stimulation methods designed to treat depression when standard treatment hasn't worked. Vagus nerve stimulation is sometimes called vagal nerve stimulation. With vagus nerve stimulation, a device called a pulse generator is surgically implanted in the chest. A wire threaded under the skin connects the pulse generator to the left vagus nerve in the neck. The pulse generator sends out electrical signals along the vagus nerve to the brain. These signals affect mood centers in the brain, possibly improving depression symptoms. Vagus nerve stimulation is recommended only for certain cases of severe or chronic depression.", "page_name": "Late life depression", "page_id": "Late%20life%20depression", "heading": "Treatments", "sub_heading": "Vagus Nerve Stimulation (VNS)", "_id": "4000026580--3--5---1", "title": "The Benefits of Vagus Nerve Stimulation for Depression"}
{"qas": [{"question": "How did the rise of oxygen change the appearance of life on Earth?", "answer": ""}, {"question": "What event occurred 2.4 to 2.1 billion years ago?", "answer": "Great Oxygenation Event", "ae_score": -0.6264139457155303, "qg_score": null}, {"question": "What event occurred 2.4 to 2.1 billion years ago?", "answer": "Great Oxygenation Event", "ae_score": -0.6264139457155303, "qg_score": null}], "content": "A core concept in geobiology is that life changes over time through evolution. The theory of evolution postulates that unique populations of organisms or species arose from genetic modifications in the ancestral population which were passed down by drift and natural selection.\nAlong with standard biological evolution, life and planet co-evolve. Since the best adaptations are those that suit the ecological niche that the organism lives in, the physical and chemical characteristics of the environment drive the evolution of life by natural selection, but the opposite can also be true: with every advent of evolution, the environment changes.\nA classic example of co-evolution is the evolution of oxygen-producing photosynthetic cyanobacteria which oxygenated Earth's Archean atmosphere. The ancestors of cyanobacteria began using water as an electron source to harness the energy of the sun and expelling oxygen before or during the early Paleoproterozoic. During this time, around 2.4 to 2.1 billion years ago, geologic data suggests that atmospheric oxygen began to rise in what is termed the Great Oxygenation Event (GOE). It is unclear for how long cyanobacteria had been doing oxygenic photosynthesis before the GOE. Some evidence suggests there were geochemical \"buffers\" or sinks suppressing the rise of oxygen such as volcanism though cyanobacteria may have been around producing it before the GOE. Other evidence indicates that the rise of oxygenic photosynthesis was coincident with the GOE.\nThe presence of oxygen on Earth from its first production by cyanobacteria to the GOE and through today has drastically impacted the course of evolution of life and planet. It may have triggered the formation of oxidized minerals and the disappearance of oxidizable minerals like pyrite from ancient stream beds. The presence of banded-iron formations (BIFs) have been interpreted as a clue for the rise of oxygen since small amounts of oxygen could have reacted with reduced ferrous iron (Fe(II)) in the oceans, resulting in the deposition of sediments containing Fe(III) oxide in places like Western Australia. However, any oxidizing environment, including that provided by microbes such as the iron-oxidizing photoautotroph ''Rhodopseudomonas palustris'', can trigger iron oxide formation and thus BIF deposition. Other mechanisms include oxidation by UV light. Indeed, BIFs occur across large swaths of Earth\u2019s history and may not correlate with only one event.\nOther changes correlated with the rise of oxygen include the appearance of rust-red ancient paleosols, different isotope fractionation of elements such as sulfur, and global glaciations and Snowball Earth events, perhaps caused by the oxidation of methane by oxygen, not to mention an overhaul of the types of organisms and metabolisms on Earth. Whereas organisms prior to the rise of oxygen were likely poisoned by oxygen gas as many anaerobes are today, those that evolved ways to harness the electron-accepting and energy-giving power of oxygen were poised to thrive and colonize the aerobic environment.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "Important concepts", "_id": "4000028338--2--0---1", "title": "The Evolution of Life and Planet"}
{"qas": [{"question": "Why has Earth remained the same since its planetary formation 4.5 billion years ago?", "answer": ""}, {"question": "When was the last time earth was the same?", "answer": "4.5 billion years ago", "ae_score": -0.394278244009832, "qg_score": null}, {"question": "How long has the earth been in a magnetic field?", "answer": "geomagnetic reversals", "ae_score": null, "qg_score": null}], "content": "Earth has not remained the same since its planetary formation 4.5 billion years ago. Continents have formed, broken up, and collided, offering new opportunities for and barriers to the dispersal of life. The redox state of the atmosphere and the oceans has changed, as indicated by isotope data. Fluctuating quantities of inorganic compounds such as carbon dioxide, nitrogen, methane, and oxygen have been driven by life evolving new biological metabolisms to make these chemicals and have driven the evolution of new metabolisms to use those chemicals. Earth acquired a magnetic field about 3.4 Ga that has undergone a series of geomagnetic reversals on the order of millions of years. The surface temperature is in constant fluctuation, falling in glaciations and Snowball Earth events due to ice-albedo feedback, rising and melting due to volcanic outgassing, and stabilizing due to silicate weathering feedback.\nAnd the Earth is not the only one that changed - the luminosity of the sun has increased over time. Because rocks record a history of relatively constant temperatures since Earth\u2019s beginnings, there must have been more greenhouse gasses to keep the temperatures up in the Archean when the sun was younger and fainter. All these major differences in the environment of the Earth placed very different constraints on the evolution of life throughout our planet\u2019s history. Moreover, more subtle changes in the habitat of life are always occurring, shaping the organisms and traces that we observe today and in the rock record.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "The Earth has changed", "_id": "4000028338--2--1---1", "title": "The Evolution of Life on Earth"}
{"qas": [{"question": "What is the purpose of the genetic code?", "answer": ""}, {"question": "What is the basic unit of inheritance and function?", "answer": "Genes", "ae_score": -0.3663486986751504, "qg_score": null}, {"question": "What is the basic unit of inheritance and function?", "answer": "Genes", "ae_score": -0.3663486986751504, "qg_score": null}], "content": "The genetic code is key to observing the history of evolution and understanding the capabilities of organisms. Genes are the basic unit of inheritance and function and, as such, they are the basic unit of evolution and the means behind metabolism.\nPhylogeny takes genetic sequences from living organisms and compares them to each other to reveal evolutionary relationships, much like a family tree reveals how individuals are connected to their distant cousins. It allows us to decipher modern relationships and infer how evolution happened in the past.\nPhylogeny can give some sense of history when combined with a little bit more information. Each difference in the DNA indicates divergence between one species and another. This divergence, whether via drift or natural selection, is representative of some lapse of time. Comparing DNA sequences alone gives a record of the history of evolution with an arbitrary measure of phylogenetic distance \u201cdating\u201d that last common ancestor. However, if information about the rate of genetic mutation is available or geologic markers are present to calibrate evolutionary divergence (i.e. fossils), we have a timeline of evolution. From there, with an idea about other contemporaneous changes in life and environment, we can begin to speculate why certain evolutionary paths might have been selected for.\nMolecular biology allows scientists to understand a gene\u2019s function using microbial culturing and mutagenesis. Searching for similar genes in other organisms and in metagenomic and metatranscriptomic data allows us to understand what processes could be relevant and important in a given ecosystem, providing insight into the biogeochemical cycles in that environment.\nFor example, an intriguing problem in geobiology is the role of organisms in the global cycling of methane. Genetics has revealed that the methane monooxygenase gene (''pmo'') is used for oxidizing methane and is present in all aerobic methane-oxidizers, or methanotrophs. The presence of DNA sequences of the ''pmo'' gene in the environment can be used as a proxy for methanotrophy. A more generalizable tool is the 16S ribosomal RNA gene, which is found in bacteria and archaea. This gene evolves very slowly over time and is not usually horizontally transferred, and so it is often used to distinguish different taxonomic units of organisms in the environment. In this way, genes are clues to organismal metabolism and identity. Genetics enables us to ask 'who is there?' and 'what are they doing?' This approach is called metagenomics.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "Genes encode geobiological function and history", "_id": "4000028338--2--2---1", "title": "Molecular Biology and Phylogeny"}
{"qas": [{"question": "How do different organisms metabolize the same chemical reactions?", "answer": ""}, {"question": "What does life use to generate energy and perform biosynthesis?", "answer": "chemical reactions", "ae_score": -0.9977481476219571, "qg_score": null}, {"question": "What does life use to generate energy and perform biosynthesis?", "answer": "chemical reactions", "ae_score": -0.9977481476219571, "qg_score": null}], "content": "Life harnesses chemical reactions to generate energy, perform biosynthesis, and eliminate waste. Different organisms use very different metabolic approaches to meet these basic needs. While animals such as ourselves are limited to aerobic respiration, other organisms can \"breathe\" sulfate (SO42-), nitrate (NO3-), ferric iron (Fe(III)), and uranium (U(VI)), or live off energy from fermentation. Some organisms, like plants, are autotrophs, meaning that they can fix carbon dioxide for biosynthesis. Plants are photoautotrophs, in that they use the energy of light to fix carbon. Microorganisms employ oxygenic and anoxygenic photoautotrophy, as well as chemoautotrophy. Microbial communities can coordinate in syntrophic metabolisms to shift reaction kinetics in their favor. Many organisms can perform multiple metabolisms to achieve the same end goal; these are called mixotrophs.\nBiotic metabolism is directly tied to the global cycling of elements and compounds on Earth. The geochemical environment fuels life, which then produces different molecules that go into the external environment. (This is directly relevant to biogeochemistry.) In addition, biochemical reactions are catalyzed by enzymes which sometimes prefer one isotope over others. For example, oxygenic photosynthesis is catalyzed by RuBisCO, which prefers carbon-12 over carbon-13, resulting in carbon isotope fractionation in the rock record.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "Metabolic diversity influences the environment", "_id": "4000028338--2--3---1", "title": "Biogeochemistry and Biogeochemistry"}
{"qas": [{"question": "What is the purpose of the sedimentary record?", "answer": ""}, {"question": "Stromatolites and banded-iron formations are examples of what type of?", "answer": "geobiology", "ae_score": -0.6383890891829695, "qg_score": null}, {"question": "Stromatolites and banded-iron formations are examples of what type of?", "answer": "geobiology", "ae_score": -0.6383890891829695, "qg_score": null}], "content": "Sedimentary rocks preserve remnants of the history of life on Earth in the form of fossils, biomarkers, isotopes, and other traces. The rock record is far from perfect, and the preservation of biosignatures is a rare occurrence. Understanding what factors determine the extent of preservation and the meaning behind what is preserved are important components to detangling the ancient history of the co-evolution of life and Earth. The sedimentary record allows scientists to observe changes in life and Earth in composition over time and sometimes even date major transitions, like extinction events.\nSome classic examples of geobiology in the sedimentary record include stromatolites and banded-iron formations. The role of life in the origin of both of these is a heavily debated topic.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "Sedimentary rocks tell a story", "_id": "4000028338--2--4---1", "title": "The Sedimentary Record"}
{"qas": [{"question": "How did the first life form?", "answer": ""}, {"question": "Where did the first life on earth come from?", "answer": "abiotic chemical reactions", "ae_score": -0.11733476621187144, "qg_score": null}, {"question": "Where did the first life on earth come from?", "answer": "abiotic chemical reactions", "ae_score": -0.11733476621187144, "qg_score": null}], "content": "The first life arose from abiotic chemical reactions. When this happened, how it happened, and even what planet it happened on are uncertain. However, life follows the rules of and arose from lifeless chemistry and physics. It is constrained by principles such as thermodynamics. This is an important concept in the field because it is represents the epitome of the interconnectedness, if not sameness, of life and Earth.\nWhile often delegated to the field of astrobiology, attempts to understand how and when life arose are relevant to geobiology as well. The first major strides towards understanding the \u201chow\u201d came with the Miller-Urey experiment, when amino acids formed out of a simulated \u201cprimordial soup\u201d. Another theory is that life originated in a system much like the hydrothermal vents at mid-oceanic spreading centers. In the Fischer-Tropsch synthesis, a variety of hydrocarbons form under vent-like conditions. Other ideas include the \u201cRNA World\u201d hypothesis, which postulates that the first biologic molecule was RNA and the idea that life originated elsewhere in the solar system and was brought to Earth, perhaps via a meteorite.", "page_name": "Geobiology", "page_id": "Geobiology", "heading": "Important concepts", "sub_heading": "Life is fundamentally chemistry", "_id": "4000028338--2--5---1", "title": "The Origins of Life in Geobiology"}
{"qas": [{"question": "How does the FDIC determine how much money a bank has?", "answer": ""}, {"question": "Who classifies banks according to their risk-based capital ratio?", "answer": "Federal Deposit Insurance Corporation", "ae_score": -0.2682783406129366, "qg_score": null}, {"question": "In the subprime mortgage crisis banks failed to adequately protect their capital against what type of?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "In the banking industry, undercapitalization refers to having insufficient capital to cover foreseeable risks.\nThe Federal Deposit Insurance Corporation (FDIC) classifies banks according to their risk-based capital ratio:\nWhen a bank becomes undercapitalized the FDIC issues a warning to the bank. When the number drops below 6% the FDIC can change management and force the bank to take other corrective action. When the bank becomes critically undercapitalized the FDIC declares the bank insolvent and can take over management of the bank.\nThe subprime mortgage crisis has shown that banks and other mortgage issuers in the USA were undercapitalized, failing to ensure that they had sufficient capital or insurance to cover the risk of mortgage defaults in the event of the bursting of a housing price bubble.  Since the affected institutions were important sources of capital to other industries, this triggered a global financial crisis during 2007-2008.", "page_name": "Undercapitalization", "page_id": "Undercapitalization", "heading": "Banking industry", "sub_heading": "Banking industry", "_id": "4000029917--3---1---1", "title": "Undercapitalization in the Banking Sector"}
{"qas": [{"question": "How did Khabra get elected as Prime Minister of Pakistan?", "answer": ""}, {"question": "Who did piara khabra succeed as mp for ealing southall?", "answer": "Sydney Bidwell", "ae_score": -0.2555211800176025, "qg_score": null}, {"question": "Who did piara khabra succeed as mp for ealing southall?", "answer": "Sydney Bidwell", "ae_score": -0.2555211800176025, "qg_score": null}], "content": "He entered Parliament at the 1992 election, the fifth Asian MP and inherited a large majority in the safe Labour seat of Ealing Southall, following Labour's de-selection of the long-serving sitting MP Sydney Bidwell. He claimed to have the largest caseload of immigration and asylum cases of any MP. He maintained good attendance and voting records, but very rarely spoke in Parliament. He said he was proud to speak on the report into the murder of Stephen Lawrence, and on the Race Relations Amendment Act 2000.\nKhabra was a strong supporter of people with autism and Asperger syndrome. He sponsored one of the most successful early day motions on autism in the 2002 Autism Awareness Year; it was supported by 153 parliamentarians of all parties. Khabra backed the work of the Autism Awareness Campaign UK.\nHow Khabra voted on key issues from 2001 to 2007:", "page_name": "Piara Khabra", "page_id": "Piara%20Khabra", "heading": "Parliamentary career", "sub_heading": "Parliamentary career", "_id": "4000041793--1---1---1", "title": "How Khabra voted in Parliament from 2001 to 2007"}
{"qas": [{"question": "Why do people with autoinflammatory disorders have such a high fever?", "answer": ""}, {"question": "The cells that engulf and ingest pathogens are called?", "answer": "Phagocytes", "ae_score": -0.185067222704381, "qg_score": null}, {"question": "The cells that engulf and ingest pathogens are called?", "answer": "Phagocytes", "ae_score": -0.185067222704381, "qg_score": null}], "content": "The International Union of Immunological Societies recognizes nine classes of primary immunodeficiencies, totaling over 120 conditions. A 2014 update of the classification guide added a 9th category and added 30 new gene defects from the prior 2009 version.  \nIn these disorders both T lymphocytes and often B lymphocytes, regulators of adaptive immunity, are dysfunctional or decreased in number. The main members are various types of severe combined immunodeficiency (SCID).\nIn primary antibody deficiencies, one or more isotypes of immunoglobulin are decreased or don't function properly. These proteins, generated by plasma cells, normally bind to pathogens, targeting them for destruction.<ref name=Notrangelo2009/>\nA number of syndromes escape formal classification but are otherwise recognisable by particular clinical or immunological features.<ref name=Notrangelo2009/>\nIn certain conditions, the regulation rather than the intrinsic activity of parts of the immune system is the predominant problem.<ref name=Notrangelo2009/>\nPhagocytes are the cells that engulf and ingest pathogens (phagocytosis), and destroy them with chemicals. Monocytes/macrophages as well as granulocytes are capable of this process. In certain conditions, either the number of phagocytes is reduced or their functional capacity is impaired.<ref name=Notrangelo2009/>\nSeveral rare conditions are due to defects in the innate immune system, which is a basic line of defence that is independent of the more advanced lymphocyte-related systems. Many of these conditions are associated with skin problems.<ref name=Notrangelo2009/>\nRather than predisposing for infections, most of the autoinflammatory disorders lead to excessive inflammation. Many manifest themselves as periodic fever syndromes. They may involve various organs directly, as well as predisposing for long-term damage (e.g. by leading to amyloid deposition).<ref name=Notrangelo2009/>\nThe complement system is part of the innate as well as the adaptive immune system; it is a group of circulating proteins that can bind pathogens and form a membrane attack complex. Complement deficiencies are the result of a lack of any of these proteins. They may predispose to infections but also to autoimmune conditions.<ref name=Notrangelo2009/>\nThese are a few specialized autoimmune disorders resulting from environmental rather than genetic causes, which mimic the genotypic disorders.", "page_name": "Primary immunodeficiency", "page_id": "Primary%20immunodeficiency", "heading": "Conditions", "sub_heading": "Conditions", "_id": "4000046065--2---1---1", "title": "Primary immunodeficiency | Conditions"}
{"qas": [{"question": "Why is it that when you listen to music in a concert hall, you can hear your own voice but not your own?", "answer": ""}, {"question": "What limits the dynamic range of a digital audio system?", "answer": "quantization error", "ae_score": -0.25479369164585414, "qg_score": null}, {"question": "Where does the range of sound in the ear come from?", "answer": "overstimulation of hair cells", "ae_score": null, "qg_score": null}], "content": "Audio engineers often use ''dynamic range'' to describe the ratio of the amplitude of the loudest possible undistorted sine wave to the root mean square (rms) noise amplitude, say of a microphone or loudspeaker.\nThe dynamic range of human hearing is roughly 140 dB, varying with frequency, from the threshold of hearing (around \u22129 dB SPL at 3 kHz) to the threshold of pain (from 120\u2013140 dB SPL).  This wide dynamic range cannot be perceived all at once, however; the tensor tympani, stapedius muscle, and outer hair cells all act as mechanical dynamic range compressors to adjust the sensitivity of the ear to different ambient levels.\nThe dynamic range of music as normally perceived in a concert hall doesn't exceed 80 dB, and human speech is normally perceived over a range of about 40 dB.\nThe dynamic range differs from the ratio of the maximum to minimum amplitude a given device can record, as a properly dithered recording device can record signals well below the noise RMS amplitude (noise floor).\nFor example, if the ceiling of a device is 5 V (rms) and the noise floor is 10 \u00b5V (rms) then the dynamic range is 500000:1, or 114 dB:\nIn digital audio theory the dynamic range is limited by quantization error. The maximum achievable dynamic range for a digital audio system with ''Q''-bit uniform quantization is calculated as the ratio of the largest sine-wave rms to rms noise is:\nThe maximum achievable signal-to-noise ratio (SNR) for a digital audio system with ''Q''-bit uniform quantization is\nThe 16-bit compact disc has a theoretical undithered dynamic range of about 96 dB, however, the ''perceived'' dynamic range of 16-bit audio can be 120 dB or more with noise-shaped dither, taking advantage of the frequency response of the human ear.\nDigital audio with undithered 20-bit digitization is theoretically capable of 120 dB dynamic range. 24-bit digital audio calculates to 144 dB dynamic range.<ref name=HuberRunstein513/> Most Digital audio workstations process audio with 32-bit floating-point representation which affords even higher dynamic range and so loss of dynamic range is no longer a concern in terms of digital audio processing. Low dynamic range audio mixes typically result from improper gain staging, imperfections in the analog-to-digital and digital-to-analog conversions, recording technique including ambient noise and intentional application of dynamic range compression.\nDynamic range in analog audio is the difference between low-level thermal noise in the electronic circuitry and high-level signal saturation resulting in increased distortion and, if pushed higher, clipping. Multiple noise processes determine the noise floor of a system. Noise can be picked up from microphone self-noise, preamp noise, wiring and interconnection noise, media noise, etc.\nEarly 78 rpm phonograph discs had a dynamic range of up to 40 dB, soon reduced to 30 dB and worse due to wear from repeated play. Vinyl microgroove phonograph records typically yield 55-65 dB, though the first play of the higher-fidelity outer rings can achieve a dynamic range of 70 dB.\nGerman magnetic tape in 1941 was reported to have had a dynamic range of 60 dB, though modern day restoration experts of such tapes note 45-50 dB as the observed dynamic range. Ampex tape recorders in the 1950s achieved 60 dB in practical usage, though tape formulations such as Scotch 111 boasted 68 dB dynamic range. In the 1960s, improvements in tape formulation processes resulted in 7 dB greater range,<ref name=Eargle158/> and Ray Dolby developed the Dolby A-Type noise reduction system that increased low- and mid-frequency dynamic range on magnetic tape by 10 dB, and high-frequency by 15 dB, using companding (compression and expansion) of four frequency bands. The peak of professional analog magnetic recording tape technology reached 90 dB dynamic range in the midband frequencies at 3% distortion, or about 80 dB in practical broadband applications.<ref name=Eargle158/> The Dolby SR noise reduction system gave a 20 dB further increased range resulting in 110 dB in the midband frequencies at 3% distortion. Compact Cassette tape performance ranges from 50 to 56 dB depending on tape formulation, with Metal Type IV tapes giving the greatest dynamic range, and systems such as XDR, dbx and Dolby noise reduction system increasing it further. Specialized bias and record head improvements by Nakamichi and Tandberg combined with Dolby C noise reduction yielded 72 dB dynamic range for the cassette.\nThe rugged elements of moving-coil microphones can have a dynamic range of up to 140 dB (at increased distortion), while condenser microphones are limited by the overloading of their associated electronic circuitry. Practical considerations of acceptable distortion levels in microphones combined with typical practices in a recording studio result in a useful operating range of 125 dB.\nIn 1981, researchers at Ampex determined that a dynamic range of 118 dB on a dithered digital audio stream was necessary for subjective noise-free playback of music in quiet listening environments.\nSince the early 1990s, it has been recommended by several authorities, including the Audio Engineering Society, that measurements of dynamic range be made with an audio signal present, which is then filtered out to get the noise floor. This avoids questionable measurements based on the use of blank media, or muting circuits.", "page_name": "Dynamic range", "page_id": "Dynamic%20range", "heading": "Audio", "sub_heading": "Audio", "_id": "4000049013--1---1---1", "title": "Dynamic Range of Digital Audio Systems"}
{"qas": [{"question": "Why do some people have diarrhea and others don't?", "answer": ""}, {"question": "What is the most common cause of viral diarrhea in adults?", "answer": "Norovirus", "ae_score": -0.15976177336583033, "qg_score": null}, {"question": "What is the most common cause of diarrhea?", "answer": "bile acid malabsorption", "ae_score": null, "qg_score": null}], "content": "Acute diarrhea is most commonly due to viral gastroenteritis with rotavirus, which accounts for 40% of cases in children under five.<ref name=WHO2010a/> (p. 17) In travelers however bacterial infections predominate. Various toxins such as mushroom poisoning and drugs can also cause acute diarrhea.\nChronic diarrhea can be the part of the presentations of a number of chronic medical conditions affecting the intestine. Common causes include ulcerative colitis, Crohn's disease, microscopic colitis, celiac disease, irritable bowel syndrome and bile acid malabsorption.\nThere are many causes of infectious diarrhea, which include viruses, bacteria and parasites. Infectious diarrhea is frequently referred to as gastroenteritis. Norovirus is the most common cause of viral diarrhea in adults, but rotavirus is the most common cause in children under five years old. Adenovirus types 40 and 41, and astroviruses cause a significant number of infections.\n''Campylobacter'' spp. are a common cause of bacterial diarrhea, but infections by ''Salmonella'' spp., ''Shigella'' spp. and some strains of ''Escherichia coli'' are also a frequent cause.\nIn the elderly, particularly those who have been treated with antibiotics for unrelated infections, a toxin produced by ''Clostridium difficile'' often causes severe diarrhea.\nParasites, particularly protozoa (e.g., ''Cryptosporidium'' spp., ''Giardia'' spp., ''Entamoeba histolytica'', ''Blastocystis'' spp., ''Cyclospora cayetanensis''), are frequently the cause of diarrhea that involves chronic infection. The broad-spectrum antiparasitic agent nitazoxanide has shown efficacy against many diarrhea-causing parasites.\nOther infectious agents, such as parasites or bacterial toxins, may exacerbate symptoms. In sanitary living conditions where there is ample food and a supply of clean water, an otherwise healthy person usually recovers from viral infections in a few days. However, for ill or malnourished individuals, diarrhea can lead to severe dehydration and can become life-threatening.\nMalabsorption is the inability to absorb food fully, mostly from disorders in the small bowel, but also due to maldigestion from diseases of the pancreas.\nCauses include:\nThe two overlapping types here are of unknown origin:\nAnother possible cause of diarrhea is irritable bowel syndrome (IBS), which usually presents with abdominal discomfort relieved by defecation and unusual stool (diarrhea or constipation) for at least 3 days a week over the previous 3 months. Symptoms of diarrhea-predominant IBS can be managed through a combination of dietary changes, soluble fiber supplements, and/or medications such as loperamide or codeine. About 30% of patients with diarrhea-predominant IBS have bile acid malabsorption diagnosed with an abnormal SeHCAT test.\nDiarrhea can be caused by other diseases and conditions, namely: ", "page_name": "Diarrhea", "page_id": "Diarrhea", "heading": "Differential diagnosis", "sub_heading": "Differential diagnosis", "_id": "4000049331--2---1---1", "title": "Causes of Diarrhea in the United States"}
{"qas": [{"question": "How do allergies work?", "answer": ""}, {"question": "A sudden and severe allergic reaction to an allergen is called?", "answer": "anaphylaxis", "ae_score": -0.3323157199698663, "qg_score": null}, {"question": "A sudden and severe allergic reaction to an allergen is called?", "answer": "anaphylaxis", "ae_score": -0.3323157199698663, "qg_score": null}], "content": "Allergy results from an inappropriate and excessive immune response to common antigens.  Substances that trigger an allergic response are called allergens.  Allergies involve mainly IgE, antibodies, and histamine. Mast cells release the histamine.  Sometimes an allergen may cause a sudden and severe, possibly fatal reaction in a sensitive individual; this is called anaphylaxis.", "page_name": "Thymus", "page_id": "Thymus", "heading": "Clinical significance", "sub_heading": "Clinical significance", "_id": "4000049375--4--0---1", "title": "Allergy Symptoms and Treatments"}
{"qas": [{"question": "Why is the thymus the organ of the immune system?", "answer": ""}, {"question": "A genetic disorder caused by the deletion of a small section of chromosome 22 is known as?", "answer": "DiGeorge syndrome", "ae_score": -0.6190803160196944, "qg_score": null}, {"question": "Where is the gene for ada located on the chromosome?", "answer": "chromosome", "ae_score": null, "qg_score": null}], "content": "As the thymus is the organ of T-cell development, any congenital defect in thymic genesis or a defect in thymocyte development can lead to a profound T cell deficiency in primary immunodeficiency disease.  Defects that affect both the T cell and B cell lymphocyte lineages result in Severe Combined Immunodeficiency Syndrome (SCIDs).  Acquired T cell deficiencies can also affect thymocyte development in the thymus.\nDiGeorge syndrome is a genetic disorder caused by the deletion of a small section of chromosome 22.  This results in a midline congenital defect including thymic aplasia, or congenital deficiency of a thymus.  Patients may present with a profound immunodeficiency disease, due to the lack of T cells.  No other immune cell lineages are affected by the congenital absence of the thymus.  DiGeorge syndrome is the most common congenital cause of thymic aplasia in humans.  In mice, the nude mouse strain are congenitally thymic deficient.  These mice are an important model of primary T cell deficiency.\nSevere combined immunodeficiency syndromes (SCID) are group of rare congenital genetic diseases that result in combined T lymphocyte and B lymphocyte deficiencies.  These syndromes are caused by defective hematopoietic progenitor cells which are the precursors of both B- and T-cells.  This results in a severe reduction in developing thymocytes in the thymus and consequently thymic atrophy.  A number of genetic defects can cause SCID, including IL-7 receptor deficiency, common gamma chain deficiency, and recombination activating gene deficiency.  The gene that codes for the enzyme called ADA (adenine deaminase), is located on chromosomes 20.\nThe HIV virus causes an acquired T-cell immunodeficiency syndrome (AIDS) by specifically killing CD4 T-cells.  Whereas the major effect of the virus is on mature peripheral T-cells, HIV can also infect developing thymocytes in the thymus, most of which express CD4.", "page_name": "Thymus", "page_id": "Thymus", "heading": "Clinical significance", "sub_heading": "Immunodeficiency", "_id": "4000049375--4--1---1", "title": "Severe Combined Immunodeficiency Syndrome"}
{"qas": [{"question": "What is a thymus and how does it work?", "answer": ""}, {"question": "What treatment is used to treat myasthenia gravis?", "answer": "Thymectomy", "ae_score": -0.4370112265553271, "qg_score": null}, {"question": "What treatment is used to treat myasthenia gravis?", "answer": "Thymectomy", "ae_score": -0.4370112265553271, "qg_score": null}], "content": "Autoimmune diseases are caused by a hyperactive immune system that instead of attacking foreign pathogens reacts against the host organism (self) causing disease.  One of the primary functions of the thymus is to prevent autoimmunity through the process of central tolerance, immunologic tolerance to self antigens.\nAutoimmune polyendocrinopathy-candidiasis-ectodermal dystrophy (APECED) is an extremely rare genetic autoimmune syndrome.  However, this disease highlights the importance of the thymus in prevention of autoimmunity.  This disease is caused by mutations in the Autoimmune Regulator (AIRE) gene.  AIRE allows for the ectopic expression of tissue-specific proteins in the thymus medulla, such as proteins that would normally only be expressed in the eye or pancreas.  This expression in the thymus, allows for the deletion of autoreactive thymocytes by exposing them to self-antigens during their development, a mechanism of central tolerance.  Patients with APECED develop an autoimmune disease that affects multiple endocrine tissues.\nMyasthenia gravis is an autoimmune disease caused by antibodies that block acetylcholine receptors.  Myasthenia gravis is often associated with thymic hypertrophy.  Thymectomy may be necessary to treat the disease.", "page_name": "Thymus", "page_id": "Thymus", "heading": "Clinical significance", "sub_heading": "Autoimmune disease", "_id": "4000049375--4--2---1", "title": "Thymus | Clinical significance | Autoimmune disease"}
{"qas": [{"question": "What is the difference between a cyst and a thymoma?", "answer": ""}, {"question": "Where do cancerous tumours originate in the body?", "answer": "thymus", "ae_score": -0.09768430679478456, "qg_score": null}, {"question": "Where do cancerous tumours originate in the body?", "answer": "thymus", "ae_score": -0.09768430679478456, "qg_score": null}], "content": "Two primary forms of tumours originate in the thymus.\nTumours originating from the thymic epithelial cells are called thymomas, and are found in about 10-15% of patients with myasthenia gravis.<ref name=sagel/>  Symptoms are sometimes confused with bronchitis or a strong cough because the tumour presses on the recurrent laryngeal nerve.  All thymomas are potentially cancerous, but they can vary a great deal.  Some grow very slowly.  Others grow rapidly and can spread to surrounding tissues.  Treatment of thymomas often requires surgery to remove the entire thymus.\nTumours originating from the thymocytes are called thymic lymphomas. Lymphomas or leukemias of thymocyte origin are classified as Precursor T acute lymphoblastic leukemia/lymphoma (T-ALL).\nPeople with an enlarged thymus, particularly children, were treated with intense radiation in the years before 1950.  There is an elevated incidence of thyroid cancer and leukemia in treated individuals.\nCervical thymus is a rare malformation. Thymic tissue containing cysts is rarely described in the literature, ectopic glandular tissue included in the wall of cystic formation can trigger a series of problems similar to those of thymus.\nThymic cysts are uncommon lesions, about 150 cases being found. While thymic cyst and ectopic cervical thymus are identified most frequently in childhood, the mean age at which thymoma is diagnosed is 45 years. However, studies have shown the existence necrotic thymic tissue masses in the neck (asymptomatic intravital) more frequently, the incidence reaching nearly 30%. These observations may mean absence of clinical observation.", "page_name": "Thymus", "page_id": "Thymus", "heading": "Clinical significance", "sub_heading": "Cancer", "_id": "4000049375--4--3---1", "title": "Thymomas and Cervical Thymus"}
{"qas": [{"question": "What is the difference between a thymectomy and a biopsy?", "answer": ""}, {"question": "Removal of the thymus from the heart is called?", "answer": "Thymectomy", "ae_score": -0.43533867315438474, "qg_score": null}, {"question": "Removal of the thymus from the heart is called?", "answer": "Thymectomy", "ae_score": -0.43533867315438474, "qg_score": null}], "content": "Thymectomy is the surgical removal of the thymus.  The usual reason for a thymectomy is to gain access to the heart for surgery to correct congenital heart defects in the neonatal period.  In neonates, but not older children or adults, the relative size of the thymus obstructs surgical access to the heart.  Removal of the thymus in infancy results in immunodeficiency by some measures, although T cells develop compensating function and it remains unknown whether disease incidence in later life is significantly greater. This is because sufficient T cells are generated during fetal life prior to birth.  These T cells are long-lived and can proliferate by homeostatic proliferation throughout the lifetime of the patient.  However, there is evidence of premature immune aging in patients thymectomized during early childhood.\nOther indications for thymectomy include the removal of thymomas and the treatment of myasthenia gravis.  Thymectomy is not indicated for the treatment of primary thymic lymphomas.  However, a thymic biopsy may be necessary to make the pathologic diagnosis.", "page_name": "Thymus", "page_id": "Thymus", "heading": "Clinical significance", "sub_heading": "Thymectomy", "_id": "4000049375--4--4---1", "title": "Thymectomy \u2014 The surgical removal of the thymus"}
{"qas": [{"question": "Why is it recommended and dangerous for XLA patients to receive live attenuated vaccines?", "answer": ""}, {"question": "What is the medical term for x-linked agammaglobulinemia?", "answer": "Serology", "ae_score": -0.31312071326884083, "qg_score": null}, {"question": "What is the medical term for x-linked agammaglobulinemia?", "answer": "severe combined immunodeficiency", "ae_score": null, "qg_score": null}], "content": "Serology (detection on antibodies to a specific pathogen or antigen) is often used to diagnose viral diseases. Because XLA patients lack antibodies, these tests always give a negative result regardless of their real condition. This applies to standard HIV tests. Special blood tests (such as the western blot based test) are required for proper viral diagnosis in XLA patients.\nIt is not recommended and dangerous for XLA patients to receive live attenuated vaccines such as live polio, or the measles, mumps, rubella (MMR vaccine).<ref name= IDF/> Special emphasis is given to avoiding the oral live attenuated SABIN-type polio vaccine that has been reported to cause polio to XLA patients. Furthermore, it is not known if active vaccines in general have any beneficial effect on XLA patients as they lack normal ability to maintain immune memory.\nXLA patients are specifically susceptible to viruses of the Enterovirus family, and mostly to: polio virus, coxsackie virus (hand, foot, and mouth disease) and  Echoviruses. These may cause severe central nervous system conditions as chronic encephalitis, meningitis and death. An experimental anti-viral agent, pleconaril, is active against picornaviruses. XLA patients, however, are apparently immune to the Epstein-Barr virus (EBV), as they lack mature B cells (and so HLA co-receptors) needed for the viral infection. Patients with XLA are also more likely to have a history of septic arthritis.\nIt is not known if XLA patients are able to generate an allergic reaction, as they lack functional IgE antibodies.There is no special hazard for XLA patients in dealing with pets or outdoor activities.<ref name= IDF/>Unlike in other primary immunodeficiencies XLA patients are at no greater risk for developing autoimmune illnesses.\nAgammaglobulinemia (XLA) is similar to the primary immunodeficiency disorder Hypogammaglobulinemia (CVID), and their clinical conditions and treatment are almost identical. However, while XLA is a congenital disorder, with known genetic causes, CVID may occur in adulthood and its causes are not yet understood.XLA was also historically mistaken as Severe Combined Immunodeficiency (SCID), a much more severe immune deficiency (\"Bubble boys\").A strain of laboratory mouse, XID, is used to study XLA. These mice have a mutated version of the mouse Btk gene, and exhibit a similar, yet milder, immune deficiency as in XLA.", "page_name": "X-linked agammaglobulinemia", "page_id": "X-linked%20agammaglobulinemia", "heading": "Treatment", "sub_heading": "Treatment", "_id": "4000050501--3--0---1", "title": "XLA & Vaccines"}
{"qas": [{"question": "How do we know the carbon composition of plants and animals?", "answer": ""}, {"question": "Where does the c isotope of chemicals come from?", "answer": "biospheric carbon", "ae_score": -0.4075163228090482, "qg_score": null}, {"question": "Where does the carbon in inorganic carbonates come from?", "answer": "isotopic fractionation", "ae_score": null, "qg_score": null}], "content": "For example, different sources and sinks of methane have different affinity for the C and C isotopes, which allows distinguishing between different sources by the C/C ratio in methane in the air. In geochemistry, paleoclimatology and paleoceanography this ratio is called \u03b4C. The ratio is calculated with respect to Pee Dee Belemnite (PDB) standard:\nSimilarly, carbon in inorganic carbonates shows little isotopic fractionation, while carbon in materials originated by photosynthesis is depleted of the heavier isotopes. In addition, there are two types of plants with different biochemical pathways; the C3 carbon fixation, where the isotope separation effect is more pronounced, C4 carbon fixation, where the heavier C is less depleted, and Crassulacean Acid Metabolism (CAM) plants, where the effect is similar but less pronounced than with C plants. Isotopic fractionation in plants is caused by physical (slower diffusion of C in plant tissues due to increased atomic weight) and biochemical (preference of C by two enzymes: RuBisCO and phosphoenolpyruvate carboxylase) factors. The different isotope ratios for the two kinds of plants propagate through the food chain, thus it is possible to determine if the principal diet of a human or an animal consists primarily of C plants (rice, wheat, soybeans, potatoes) or C plants (corn, or corn-fed beef) by isotope analysis of their flesh and bone collagen (however, to obtain more accurate determinations, carbon isotopic fractionation must be also taken into account, since several studies have reported significant C discrimination during biodegradation of simple and complex substrates).Within C3 plants processes regulating changes in \u03b4C are well understood, particularly at the leaf level, but also during wood formation. Many recent studies combine leaf level isotopic fractionation with annual patterns of wood formation (i.e. tree ring \u03b4C) to quantify the impacts of climatic variations and atmospheric composition on physiological processes of individual trees and forest stands. The next phase of understanding, in terrestrial ecosystems at least, seems to be the combination of multiple isotopic proxies to decipher interactions between plants, soils and the atmosphere, and predict how changes in land use will affect climate change.Similarly, marine fish contain more C than freshwater fish, with values approximating the C and C plants respectively.\nThe ratio of carbon-13 and carbon-12 isotopes in these types of plants is as follows:\nLimestones formed by precipitation in seas from the atmospheric carbon dioxide contain normal proportion of C. Conversely, calcite found in salt domes originates from carbon dioxide formed by oxidation of petroleum, which due to its plant origin is C-depleted.\nThe C isotope is important in distinguishing biosynthetized materials from man-made ones. Biogenic chemicals are derived from biospheric carbon, which contains C. Carbon in artificially made chemicals is usually derived from fossil fuels like coal or petroleum, where the C originally present has decayed below detectable limits. The amount of C currently present in a sample therefore indicates the proportion of carbon of biogenic origin.", "page_name": "Isotopic signature", "page_id": "Isotopic%20signature", "heading": "Stable isotopes", "sub_heading": "Stable isotopes", "_id": "4000051506--0--0---1", "title": "Carbon isotopes in plants"}
{"qas": [{"question": "What determines the amount of nitrogen in the food web?", "answer": ""}, {"question": "What is the percentage increase in the nitrogen isotope in the tissues of vegans?", "answer": "3-4 parts per thousand", "ae_score": -1.2424792663832247, "qg_score": null}, {"question": "What is the percentage increase in the nitrogen isotope in the tissues of vegans?", "answer": "3-4 parts per thousand", "ae_score": -1.2424792663832247, "qg_score": null}], "content": "Nitrogen-15, or N, is often used in agricultural and medical research, for example in the Meselson\u2013Stahl experiment to establish the nature of DNA replication. An extension of this research resulted in development of DNA-based stable-isotope probing, which allows examination of links between metabolic function and taxonomic identity of microorganisms in the environment, without the need for culture isolation. Proteins can be isotopically labelled by cultivating them in a medium containing N as the only source of nitrogen, e.g., in quantitative proteomics such as SILAC.\nNitrogen-15 is extensively used to trace mineral nitrogen compounds (particularly fertilizers) in the environment. When combined with the use of other isotopic labels, N is also a very important tracer for describing the fate of nitrogenous organic pollutants. Nitrogen-15 tracing is an important method used in biogeochemistry.\nThe ratio of stable nitrogen isotopes, N/N or \u03b4N, tends to increase with trophic level, such that herbivores have higher nitrogen isotope values than plants, and carnivores have higher nitrogen isotope values than herbivores. Depending on the tissue being examined, there tends to be an increase of 3-4 parts per thousand with each increase in trophic level. The tissues and hair of vegans therefore contain significantly lower \u03b4N than the bodies of people who eat mostly meat. Similarly, a terrestrial diet produces a different signature than a marine-based diet. Isotopic analysis of hair is an important source of information for archaeologists, providing clues about the ancient diets and differing cultural attitudes to food sources.\nA number of other environmental and physiological factors can influence the nitrogen isotopic composition at the base of the food web (i.e. in plants) or at the level of individual animals. For example, in arid regions, the nitrogen cycle tends to be more 'open' and prone to the loss of N, increasing \u03b4N in soils and plants. This leads to relatively high \u03b4N values in plants and animals in hot and arid ecosystems relative to cooler and moister ecosystems.\n\u03b4N also provides a diagnostic tool in planetary science as the ratio exhibited in atmospheres and surface materials \"is closely tied to the conditions under which materials form\".", "page_name": "Isotopic signature", "page_id": "Isotopic%20signature", "heading": "Stable isotopes", "sub_heading": "Nitrogen isotopes", "_id": "4000051506--0--1---1", "title": "Nitrogen-15 tracing in biogeochemistry."}
{"qas": [{"question": "How do we know how much oxygen is in water?", "answer": ""}, {"question": "How many isoforms of oxygen are there?", "answer": "three", "ae_score": -0.5869338412698024, "qg_score": null}, {"question": "Where does the oxygen in water come from?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "Oxygen comes in three variants, but the O is so rare that it is very difficult to detect (~0.04% abundant). The ratio of O/O in water depends on the amount of evaporation the water experienced (as O is heavier and therefore less likely to vaporize). As the vapor tension depends on the concentration of dissolved salts, the O/O ratio shows correlation on the salinity and temperature of water. As oxygen gets built into the shells of calcium carbonate secreting organisms, such sediments prove a chronological record of temperature and salinity of the water in the area.\nOxygen isotope ratio in atmosphere varies predictably with time of year and geographic location; e.g. there is a 2% difference between O-rich precipitation in Montana and O-depleted precipitation in Florida Keys. This variability can be used for approximate determination of geographic location of origin of a material; e.g. it is possible to determine where a shipment of uranium oxide was produced. The rate of exchange of surface isotopes with the environment has to be taken in account.", "page_name": "Isotopic signature", "page_id": "Isotopic%20signature", "heading": "Stable isotopes", "sub_heading": "Oxygen isotopes", "_id": "4000051506--0--2---1", "title": "Oxygen isotope ratios in the atmosphere"}
{"qas": [{"question": "How do archaeologists determine the date of ancient civilizations?", "answer": ""}, {"question": "What does ams stand for in absolute dating?", "answer": "accelerator mass spectrometry", "ae_score": -0.16091496221363288, "qg_score": null}, {"question": "Which type of radiocarbon dating is used to determine absolute dates?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "One of the most widely used and well-known absolute dating techniques is carbon-14 (or radiocarbon) dating, which is used to date organic remains.  This is a radiometric technique since it is based on radioactive decay.  Cosmic radiation entering the earth\u2019s atmosphere produces carbon-14, and plants take in carbon-14 as they fix carbon dioxide.  Carbon-14 moves up the food chain as animals eat plants and as predators eat other animals.  With death, the uptake of carbon-14 stops. \nIt takes 5,730 years for half the carbon-14 to change to nitrogen; this is the half-life of carbon-14. After another 5,730 years only one-quarter of the original carbon-14 will remain.  After yet another 5,730 years only one-eighth will be left.  \nBy measuring the carbon-14 in organic material, scientists can determine the  date of death of the organic matter in an artifact or ecofact.\nThe relatively short half-life of carbon-14, 5,730 years, makes the reliable only  up to about 75,000 years. The technique often cannot pinpoint the date of an archeological site better than historic records, but is highly effective for precise dates when calibrated with other dating techniques such as tree-ring dating.\nAn additional problem with carbon-14 dates from archeological sites is known as the \"old wood\" problem.  It is possible, particularly in dry, desert climates, for organic materials such as from dead trees to remain in their natural state for hundreds of years before people use them as firewood or building materials, after which they become part of the archaeological record. Thus dating that particular tree does not necessarily indicate when the fire burned or the structure was built. \nFor this reason, many archaeologists prefer to use samples from short-lived plants for radiocarbon dating.  The development of accelerator mass spectrometry (AMS) dating, which allows a date to be obtained from a very small sample, has been very useful in this regard.", "page_name": "Absolute dating", "page_id": "Absolute%20dating", "heading": "Radiometric techniques", "sub_heading": "Radiometric techniques", "_id": "4000051523--0--0---1", "title": "Carbon-14 Dating \u2014 Archeological Sites"}
{"qas": [{"question": "How do we know how old dinosaurs were?", "answer": ""}, {"question": "What is the half life of potassium-40?", "answer": "1.3 billion years", "ae_score": -0.24713929479355987, "qg_score": null}, {"question": "What is the half life of potassium-40?", "answer": "1.3 billion years", "ae_score": -0.24713929479355987, "qg_score": null}], "content": "Other radiometric dating techniques are available for earlier periods.  One of the most widely used is potassium-argon dating (K-Ar dating).  Potassium-40 is a radioactive isotope of potassium that decays into argon-40.  The half-life of potassium-40 is 1.3 billion years, far longer than that of carbon-14, allowing much older samples to be dated. Potassium is common in rocks and minerals, allowing many samples of geochronological or archeological interest to be dated. \nArgon, a noble gas, is not commonly incorporated into such samples except when produced ''in situ'' through radioactive decay. The date measured reveals the last time that the object was heated past the closure temperature at which the trapped argon can escape the lattice. K-Ar dating was used to calibrate the geomagnetic polarity time scale.", "page_name": "Absolute dating", "page_id": "Absolute%20dating", "heading": "Radiometric techniques", "sub_heading": "Potassium-argon dating", "_id": "4000051523--0--1---1", "title": "Geomagnetic Polarity Time Scale"}
{"qas": [{"question": "How did Moody\u2019s become the go-to rating for government bonds?", "answer": ""}, {"question": "Who was the inventor of modern bond credit ratings?", "answer": "John Moody", "ae_score": -0.4253948745992124, "qg_score": null}, {"question": "Moody's is a credit rating agency for?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "Moody's traces its history back to two publishing companies established by John Moody, the inventor of modern bond credit ratings. In 1900, Moody published his first market assessment, called ''Moody's Manual of Industrial and Miscellaneous Securities'', and established John Moody & Company. The publication provided detailed statistics relating to stocks and bonds of financial institutions, government agencies, manufacturing, mining, utilities, and food companies. It experienced early success, selling out its first print run in its first two months. By 1903, ''Moody's Manual'' was a nationally recognized publication. Moody was forced to sell his business, due to a shortage of capital, when the 1907 financial crisis fueled several changes in the markets.\nMoody returned in 1909 with a new publication focused solely on railroad bonds, ''Analysis of Railroad Investments'', and a new company, Moody's Analyses Publishing Company. While Moody acknowledged that the concept of bond ratings \"was not entirely original\" with him\u2014he credited early bond rating efforts in Vienna and Berlin as inspiration\u2014he was the first to publish them widely, in an accessible format. Moody was also the first to charge subscription fees to investors.  In 1913 he expanded the manual's focus to include industrial firms and utilities; the new ''Moody's Manual'' offered ratings of public securities, indicated by a letter-rating system borrowed from mercantile credit-reporting firms. The following year, Moody incorporated the company as Moody's Investors Service. Other rating companies followed over the next few years, including the antecedents of the \"Big Three\" credit rating agencies: Poor's in 1916, Standard Statistics Company in 1922, and the Fitch Publishing Company in 1924.\nMoody\u2019s expanded its focus to include ratings for U.S. state and local government bonds in 1919 and, by 1924, Moody's rated nearly the entire U.S. bond market.", "page_name": "Moody's Investors Service", "page_id": "Moody's%20Investors%20Service", "heading": "History of Moody's", "sub_heading": "History of Moody's", "_id": "4000053916--2--0---1", "title": "Moody\u2019s \u2014 A History of Bond Ratings"}
{"qas": [{"question": "How did the rating system in the U.S. come to be?", "answer": ""}, {"question": "When did moody's start doing credit reports?", "answer": "1962", "ae_score": -0.29718924101720173, "qg_score": null}, {"question": "What type of bonds are issued by moody's?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "The relationship between the U.S. bond market and rating agencies developed further in the 1930s. As the market grew beyond that of traditional investment banking institutions, new investors again called for increased transparency, leading to the passage of new, mandatory disclosure laws for issuers, and the creation of the Securities and Exchange Commission (SEC). In 1936 a new set of laws were introduced, prohibiting banks from investing in \"speculative investment securities\" (\"junk bonds\", in modern terminology) as determined by \"recognized rating manuals\". Banks were permitted only to hold \"investment grade\" bonds, following the judgment of Moody's, along with Standard, Poor's and Fitch. In the decades that followed, state insurance regulators approved similar requirements.\nIn 1962, Moody's Investors Service was bought by Dun & Bradstreet, a firm engaged in the related field of credit reporting, although they continued to operate largely as independent companies.", "page_name": "Moody's Investors Service", "page_id": "Moody's%20Investors%20Service", "heading": "History of Moody's", "sub_heading": "1930s to mid-century", "_id": "4000053916--2--1---1", "title": "The Bond Market and Rating Agencies"}
{"qas": [{"question": "How did Moody's and S & P get their ratings?", "answer": ""}, {"question": "What percentage of moody's revenue comes from issuing fees?", "answer": "90%", "ae_score": -0.2730439081352005, "qg_score": null}, {"question": "What type of mortgage crisis was responsible for the collapse of enron?", "answer": "subprime", "ae_score": null, "qg_score": null}], "content": "In the late 1960s and 1970s, commercial paper and bank deposits began to be rated. As well, the major agencies began charging the issuers of bonds as well as investors \u2014 Moody's began doing this in 1970 \u2014 thanks in part to a growing free rider problem related to the increasing availability of inexpensive photocopy machines, and the increased complexity of the financial markets. Rating agencies also grew in size as the number of issuers grew, both in the United States and abroad, making the credit rating business significantly more profitable. In 2005 Moody's estimated that 90% of credit rating agency revenues came from issuer fees.\nThe end of the Bretton Woods system in 1971 led to the liberalization of financial regulations, and the global expansion of capital markets in the 1970s and 1980s. In 1975, the SEC changed its minimum capital requirements for broker-dealers, using bond ratings as a measurement. Moody's and nine other agencies (later five, due to consolidation) were identified by the SEC as \"nationally recognized statistical ratings organizations\" (NRSROs) for broker-dealers to use in meeting these requirements.\nThe 1980s and beyond saw the global capital market expand; Moody's opened its first overseas offices in Japan in 1985, followed by offices in the United Kingdom in 1986, France in 1988, Germany in 1991, Hong Kong in 1994, India in 1998 and China in 2001. The number of bonds rated by Moody's and the Big Three agencies grew substantially as well. As of 1997, Moody's was rating about $5 trillion in securities from 20,000 U.S. and 1,200 non-U.S. issuers. The 1990s and 2000s were also a time of increased scrutiny, as Moody's was sued by unhappy issuers and investigation by the U.S. Department of Justice, as well as criticism following the collapse of Enron, the U.S. subprime mortgage crisis and subsequent late-2000s financial crisis.\nFollowing several years of rumors and pressure from institutional shareholders, in December 1999 Moody's parent Dun & Bradstreet announced it would spin off Moody's Investors Service into a separate publicly traded company. Although Moody's had fewer than 1,500 employees in its division, it represented about 51% of Dun & Bradstreet profits in the year before the announcement. The spin-off was completed on September 30, 2000, and, in the half decade that followed, the value of Moody's shares improved by more than 300%.", "page_name": "Moody's Investors Service", "page_id": "Moody's%20Investors%20Service", "heading": "History of Moody's", "sub_heading": "1970s to 2000", "_id": "4000053916--2--2---1", "title": "Moody's and the Great Recession"}
{"qas": [{"question": "Moody's downgrade of subprime mortgage backed securities?", "answer": ""}, {"question": "What percentage of the 2006 aaa mortgage backed security tranches were downgraded by m?", "answer": "83%", "ae_score": -0.2374144795468491, "qg_score": null}, {"question": "What type of correlation does moody's use to estimate the correlation of non?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "Structured finance went from 28% of Moody's revenue in 1998 to almost 50% in 2007, and \"accounted for pretty much all of Moody's growth\" during that time.  According to the Financial Crisis Inquiry Report, during the years 2005, 2006, and 2007, rating of structured finance products such as mortgage-backed securities made up close to half of Moody\u2019s rating revenues. From 2000 to 2007, revenues from rating structured financial instruments increased more than fourfold. However, there was some question about the models Moody's used to give structured products high ratings. In June 2005, shortly before the subprime mortgage crisis, Moody\u2019s updated its approach for estimating default correlation of non-prime/nontraditional mortgages involved in structured financial products like mortgage-backed securities and Collateralized debt obligations. Its new model was based on trends from the previous 20 years, during which time housing prices had been rising, mortgage delinquencies very low, and nontraditional mortgage products a very small niche of the market.\nOn July 10, 2007, in \"an unprecedented move\", Moody's downgraded 399 subprime mortgage-backed securities that had been issued the year before. Three months later, it downgraded another 2506 tranches  ($33.4 billion).  By the end of the crisis,  Moody's downgraded 83% of all the 2006 Aaa mortgage backed security tranches and all of the Baa tranches.\nIn June 2013, Moody's Investor Service has warned that Thailand's credit rating may be damaged due to an increasingly costly rice-pledging scheme which lost 200 billion baht ($6.5 billion) in 2011\u20132012.", "page_name": "Moody's Investors Service", "page_id": "Moody's%20Investors%20Service", "heading": "History of Moody's", "sub_heading": "Structured finance boom and after", "_id": "4000053916--2--3---1", "title": "Moody\u2019s Structured Finance Models"}
{"qas": [{"question": "What is the use of lithium in glazes?", "answer": ""}, {"question": "What are glazes containing lithium oxides used for?", "answer": "ovenware", "ae_score": -0.5200173470139912, "qg_score": null}, {"question": "What is the single largest use for glazes?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Lithium oxide is widely used as a flux for processing silica, reducing the melting point and viscosity of the material and leading to glazes with improved physical properties including low coefficients of thermal expansion. Worldwide, this is the single largest use for lithium compounds. Glazes containing lithium oxides are used for ovenware. Lithium carbonate (LiCO) is generally used in this application  because it converts to the oxide upon heating.", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Uses", "_id": "4000054763--4--0---1", "title": "Lithium Oxide Glazes"}
{"qas": [{"question": "What is the difference between Lithium-ion batteries and regular batteries?", "answer": ""}, {"question": "How many volts does a lead acid battery produce?", "answer": "2.1", "ae_score": null, "qg_score": null}, {"question": "What property of a lithium-ion battery is it known for?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Late in the 20th century, lithium became an important component of battery electrolytes and electrodes, because of its high electrode potential. Because of its low atomic mass, it has a high charge- and power-to-weight ratio. A typical lithium-ion battery can generate approximately 3 volts per cell, compared with 2.1 volts for lead-acid or 1.5 volts for zinc-carbon cells. Lithium-ion batteries, which are rechargeable and have a high energy density, should not be confused with lithium batteries, which are disposable (primary) batteries with lithium or its compounds as the anode. Other rechargeable batteries that use lithium include the lithium-ion polymer battery, lithium iron phosphate battery, and the nanowire battery.", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Electrical and electronics", "_id": "4000054763--4--1---1", "title": "Lithium-ion Batteries \u2014 Lithium-ion Batteries"}
{"qas": [{"question": "How does lithium hydroxide work?", "answer": ""}, {"question": "What is the third most common use of lithium?", "answer": "greases", "ae_score": -0.5304062590890273, "qg_score": null}, {"question": "What is the third most common use of lithium?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "The third most common use of lithium is in greases. Lithium hydroxide is a strong base and, when heated with a fat, produces a soap made of lithium stearate. Lithium soap has the ability to thicken oils, and it is used to manufacture all-purpose, high-temperature lubricating greases.<ref name=CRC/>", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Lubricating greases", "_id": "4000054763--4--2---1", "title": "Lithium is the third most common use of lithium in greases"}
{"qas": [{"question": "Why is lithium used as a flux for welding and soldering?", "answer": ""}, {"question": "What percentage of production does lithium fluoride account for?", "answer": "3%", "ae_score": -0.45610968952311864, "qg_score": null}, {"question": "What is the name of the compound that is used as an additive to continuous casting mould?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Lithium (e.g. as lithium carbonate) is used as an additive to continuous casting mould flux slags where it increases fluidity, a use which accounts for 5% of global lithium use (2011). Lithium compounds are also used as additives (fluxes) to foundry sand for iron casting to reduce veining.\nLithium (as  lithium fluoride) is used as an additive to aluminium smelters (Hall\u2013H\u00e9roult process), reducing melting temperature and increasing electrical resistance, a use which accounts for 3% of production (2011).\nWhen used as a flux for welding or soldering, metallic lithium promotes the fusing of metals during the process and eliminates the forming of oxides by absorbing impurities. Alloys of the metal with aluminium, cadmium, copper and manganese are used to make high-performance aircraft parts (see also Lithium-aluminium alloys).", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Metallurgy", "_id": "4000054763--4--3---1", "title": "Lithium-aluminium alloys \u2014 Lithium and aluminium alloy"}
{"qas": [{"question": "What is the difference between lithium chloride and lithium bromide?", "answer": ""}, {"question": "What is sprayed over a block of sulfur hexafluoride gas?", "answer": "lithium", "ae_score": -0.39551238239478353, "qg_score": null}, {"question": "What is an example of a metal that can be used in an oxygen lamp?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "Lithium compounds are used as pyrotechnic colorants and oxidizers in red fireworks and flares.<ref name=CRC/>\nLithium chloride and lithium bromide are hygroscopic and are used as desiccants for gas streams.<ref name=CRC/>  Lithium hydroxide and lithium peroxide are the salts most used in confined areas, such as aboard spacecraft and submarines, for carbon dioxide removal and air purification. Lithium hydroxide absorbs carbon dioxide from the air by forming lithium carbonate, and is preferred over other alkaline hydroxides for its low weight.\nLithium peroxide (LiO) in presence of moisture not only reacts with carbon dioxide to form lithium carbonate, but also releases oxygen. The reaction is as follows:\nSome of the aforementioned compounds, as well as lithium perchlorate, are used in oxygen candles that supply submarines with oxygen. These can also include small amounts of boron, magnesium, aluminum, silicon, titanium, manganese, and iron.\nLithium fluoride, artificially grown as crystal, is clear and transparent and often used in specialist optics for IR, UV and VUV (vacuum UV) applications. It has one of the lowest refractive indexes and the farthest transmission range in the deep UV of most common materials. Finely divided lithium fluoride powder has been used for thermoluminescent radiation dosimetry (TLD): when a sample of such is exposed to radiation, it accumulates crystal defects which, when heated, resolve via a release of bluish light whose intensity is proportional to the absorbed dose, thus allowing this to be quantified. Lithium fluoride is sometimes used in focal lenses of telescopes.<ref name=CRC/>\nThe high non-linearity of lithium niobate also makes it useful in non-linear optics applications. It is used extensively in telecommunication products such as mobile phones and optical modulators, for such components as resonant crystals. Lithium applications are used in more than 60% of mobile phones.\nOrganolithium compounds are widely used in the production of polymer and fine-chemicals. In the polymer industry, which is the dominant consumer of these reagents, alkyl lithium compounds are catalysts/initiators. in anionic polymerization of unfunctionalized olefins. For the production of fine chemicals, organolithium compounds function as strong bases and as reagents for the formation of carbon-carbon bonds. Organolithium compounds are prepared from lithium metal and alkyl halides.\nMany other lithium compounds are used as reagents to prepare organic compounds. Some popular compounds include lithium aluminium hydride (LiAlH), lithium triethylborohydride, n-Butyllithium and tert-butyllithium are commonly used as extremely strong bases called superbase.\nMetallic lithium and its complex hydrides, such as Li[AlH], are used as high-energy additives to rocket propellants.<ref name=emsley/> Lithium aluminum hydride can also be used by itself as a solid fuel.\nThe Mark 50 torpedo stored chemical energy propulsion system (SCEPS) uses a small tank of sulfur hexafluoride gas, which is sprayed over a block of solid lithium. The reaction generates heat, creating steam to propel the torpedo in a closed Rankine cycle.\nLithium hydride containing lithium-6 is used in thermonuclear weapons, where it encases the core of the bomb.", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Other chemical and industrial uses", "_id": "4000054763--4--5---1", "title": "Lithium Compounds & Chemicals."}
{"qas": [{"question": "Why is helium used as a fuel for nuclear fusion?", "answer": ""}, {"question": "What was the name of the fuel used in the hydrogen bomb?", "answer": "Lithium deuteride", "ae_score": -0.29838342284299385, "qg_score": null}, {"question": "What is the name of the element that is used to heat water under high pressure?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Lithium-6 is valued as a source material for tritium production and as a neutron absorber in nuclear fusion. Natural lithium contains about 7.5% lithium-6 from which large amounts of lithium-6 have been produced by isotope separation for use in nuclear weapons. Lithium-7 gained interest for use in nuclear reactor coolants.\nLithium deuteride was the fusion fuel of choice in early versions of the hydrogen bomb. When bombarded by neutrons, both Li and Li produce tritium \u2014 this reaction, which was not fully understood when hydrogen bombs were first tested, was responsible for the runaway yield of the Castle Bravo nuclear test. Tritium fuses with deuterium in a fusion reaction that is relatively easy to achieve. Although details remain secret, lithium-6 deuteride apparently still plays a role in modern nuclear weapons as a fusion material.\nLithium fluoride, when highly enriched in the lithium-7 isotope, forms the basic constituent of the fluoride salt mixture LiF-BeF used in liquid fluoride nuclear reactors. Lithium fluoride is exceptionally chemically stable and LiF-BeF mixtures have low melting points. In addition, Li, Be, and F are among the few nuclides with low enough thermal neutron capture cross-sections not to poison the fission reactions inside a nuclear fission reactor.\nIn conceptualized (hypothetical) nuclear fusion power plants, lithium will be used to produce tritium in magnetically confined reactors using deuterium and tritium as the fuel. Naturally occurring tritium is extremely rare, and must be synthetically produced by surrounding the reacting plasma with a 'blanket' containing lithium where neutrons from the deuterium-tritium reaction in the plasma will fission the lithium to produce more tritium:\nLithium is also used as a source for alpha particles, or helium nuclei. When Li is bombarded by accelerated protons Be is formed, which undergoes fission to form two alpha particles. This feat, called \"splitting the atom\" at the time, was the first fully man-made nuclear reaction. It was produced by Cockroft and Walton in 1932.\nIn 2013, the US Government Accountability Office said a shortage of lithium-7 critical to the operation of 65 out of 100 American nuclear reactors \u201cplaces their ability to continue to provide electricity at some risk\u201d. The problem stems from the decline of US nuclear infrastructure. The equipment needed to separate lithium-6 from lithium-7 is mostly a cold war leftover. The US shut down most of this machinery in 1963, when it had a huge surplus of separated lithium, mostly consumed during the twentieth century. The report said it would take five years and $10 million to $12 million to reestablish the ability to separate lithium-6 from lithium-7.<ref name=nyt1013/>\nReactors that use lithium-7 heat water under high pressure and transfer heat through heat exchangers that are prone to corrosion. The reactors use lithium to counteract the corrosive effects of boric acid, which is added to the water to absorb excess neutrons.", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Nuclear", "_id": "4000054763--4--6---1", "title": "Lithium-6 \u2014 a source material for tritium production and as a"}
{"qas": [{"question": "What are lithium salts and how do they work?", "answer": ""}, {"question": "Which metal has been researched as a treatment for cluster headaches?", "answer": "Lithium", "ae_score": -0.22513161788722735, "qg_score": null}, {"question": "What is the active part of lithium salts?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Lithium is useful in the treatment of bipolar disorder. Lithium salts may also be helpful for related diagnoses, such as schizoaffective disorder and cyclic major depression. The active part of these salts is the lithium ion Li. They may increase the risk of developing Ebstein's cardiac anomaly in infants born to women who take lithium during the first trimester of pregnancy.\nLithium has also been researched as a possible treatment for cluster headaches.", "page_name": "Lithium", "page_id": "Lithium", "heading": "Uses", "sub_heading": "Medicine", "_id": "4000054763--4--7---1", "title": "Lithium salts may be useful in the treatment of bipolar disorder"}
{"qas": [{"question": "How does the aggregate demand curve work?", "answer": ""}, {"question": "What is the standard textbook model for explaining macroeconomics?", "answer": "The AD-AS model", "ae_score": -0.8445727421880905, "qg_score": null}, {"question": "What is the standard textbook model for explaining macroeconomics?", "answer": "The AD-AS model", "ae_score": -0.8445727421880905, "qg_score": null}], "content": "The AD-AS model has become the standard textbook model for explaining the macroeconomy. This model shows the price level and level of real output given the equilibrium in aggregate demand and aggregate supply. The aggregate demand curve's downward slope means that more output is demanded at lower price levels. The downward slope is the result of three effects: the Pigou or real balance effect, which states that as real prices fall, real wealth increases, resulting in higher consumer demand of goods; the Keynes or interest rate effect, which states that as prices fall, the demand for money decreases, causing interest rates to decline and borrowing for investment and consumption to increase; and the net export effect, which states that as prices rise, domestic goods become comparatively more expensive to foreign consumers, leading to a decline in exports.\nIn the conventional Keynesian use of the AS-AD model, the aggregate supply curve is horizontal at low levels of output and becomes inelastic near the point of potential output, which corresponds with full employment. Since the economy cannot produce beyond the potential output, any AD expansion will lead to higher price levels instead of higher output.\nThe AD\u2013AS diagram can model a variety of macroeconomic phenomena, including inflation. Changes in the non-price level factors or determinants cause changes in aggregate demand and shifts of the entire aggregate demand (AD) curve. When demand for goods exceeds supply there is an inflationary gap where demand-pull inflation occurs and the AD curve shifts upward to a higher price level. When the economy faces higher costs, cost-push inflation occurs and the AS curve shifts upward to higher price levels. The AS\u2013AD diagram is also widely used as a pedagogical tool to model the effects of various macroeconomic policies.", "page_name": "Macroeconomics", "page_id": "Macroeconomics", "heading": "Macroeconomic models", "sub_heading": "Macroeconomic models", "_id": "4000054796--1--0---1", "title": "The AS\u2013AD Diagram"}
{"qas": [{"question": "What is the difference between the IS/LM model and the traditional economic model?", "answer": ""}, {"question": "What direction is the is curve in relation to the lm curve?", "answer": "downward sloping", "ae_score": -0.7790361662363335, "qg_score": null}, {"question": "What direction is the is curve in relation to the lm curve?", "answer": "downward sloping", "ae_score": -0.7790361662363335, "qg_score": null}], "content": "The IS\u2013LM model represents all the combinations of interest rates and output that ensure the equilibrium in the goods and money markets. The goods market is represented by the equilibrium in investment and saving (IS), and the money market is represented by the equilibrium between the money supply and liquidity preference. The IS curve consists of the points where investment, given the interest rate, is equal to savings, given output.\nThe IS curve is downward sloping because output and interest rate have an inverse relationship in the goods market: as output increases, more money is saved, which means interest rates must be lower to spur enough investment to match savings. The LM curve is upward sloping because interest rate and output have a positive relationship in the money market: as output increases, the demand for money increases, resulting in a rise in interest rate.\nThe IS/LM model is often used to demonstrate the effects of monetary and fiscal policy. Textbooks frequently use the IS/LM model, but it does not feature the complexities of most modern macroeconomic models. Nevertheless, these models still feature similar relationships to those in IS/LM.", "page_name": "Macroeconomics", "page_id": "Macroeconomics", "heading": "Macroeconomic models", "sub_heading": "IS\u2013LM", "_id": "4000054796--1--1---1", "title": "The IS\u2013LM Model and the LM Model"}
{"qas": [{"question": "How does the neoclassical growth model work?", "answer": ""}, {"question": "What emerged in the 1980s and 1990s to challenge neoclassical growth theory?", "answer": "endogenous growth theory", "ae_score": -0.34908756391092965, "qg_score": null}, {"question": "The solow model assumes that labor and capital are used at constant rates without the fluctuations?", "answer": "economic cycles", "ae_score": null, "qg_score": null}], "content": "The neoclassical growth model of Robert Solow has become a common textbook model for explaining economic growth in the long-run. The model begins with a production function where national output is the product of two inputs: capital and labor. The Solow model assumes that labor and capital are used at constant rates without the fluctuations in unemployment and capital utilization commonly seen in business cycles.\nAn increase in output, or economic growth, can only occur because of an increase in the capital stock, a larger population, or technological advancements that lead to higher productivity (total factor productivity). An increase in the savings rate leads to a temporary increase as the economy creates more capital, which adds to output. However, eventually the depreciation rate will limit the expansion of capital: savings will be used up replacing depreciated capital, and no savings will remain to pay for an additional expansion in capital. Solow's model suggests that economic growth in terms of output per capita depends solely on technological advances that enhance productivity.\nIn the 1980s and 1990s endogenous growth theory arose to challenge neoclassical growth theory. This group of models explains economic growth through other factors, such as increasing returns to scale for capital and learning-by-doing, that are endogenously determined instead of the exogenous technological improvement used to explain growth in Solow's model.", "page_name": "Macroeconomics", "page_id": "Macroeconomics", "heading": "Macroeconomic models", "sub_heading": "Growth models", "_id": "4000054796--1--2---1", "title": "The Neoclassical Growth Model and the Endogenous Growth Theory"}
{"qas": [{"question": "Why is the median household income in the United States so low?", "answer": ""}, {"question": "When did the great recession end in the us?", "answer": "June 2009", "ae_score": -0.15022333108705202, "qg_score": null}, {"question": "What type of financial instrument was used to finance the great recession?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "The Great Recession met the IMF criteria for being a global recession, requiring a ''decline in annual real world GDP percapita \n'', only in the single calendar year 2009. Despite the fact that quarterly data are being used as recession definition criteria by all G20 members, representing 85% of the world GDP, the International Monetary Fund (IMF) has decided\u2014in the absence of a complete data set\u2014not to declare/measure global recessions according to quarterly GDP data. The ''seasonally adjusted PPPweighted real GDP'' for the G20zone, however, is a good indicator for the world GDP, and it was measured to have suffered a direct quarter on quarter decline during the three quarters from Q32008 until Q12009, which more accurately mark when the recession took place at the global level.\nAccording  to the U.S. National Bureau of Economic Research (the official arbiter of U.S. recessions) the recession began in December 2007 and ended in June 2009, and thus extended over eighteen months.\nThe years leading up to the crisis were characterized by an exorbitant rise in asset prices and associated boom in economic demand. Further, the U.S. shadow banking system (i.e., non-depository financial institutions such as investment banks) had grown to rival the depository system yet was not subject to the same regulatory oversight, making it vulnerable to a bank run.\nUS mortgage-backed securities, which had risks that were hard to assess, were marketed around the world, as they offered higher yields than U.S. government bonds. Many of these securities were backed by subprime mortgages, which collapsed in value when the U.S. housing bubble burst during 2006 and homeowners began to default on their mortgage payments in large numbers starting in 2007.\nThe emergence of sub-prime loan losses in 2007 began the crisis and exposed other risky loans and over-inflated asset prices. With loan losses mounting and the fall of Lehman Brothers on 15 September 2008, a major panic broke out on the inter-bank loan market. There was the equivalent of a bank run on the shadow banking system,  resulting in many large and well established investment and commercial banks in the United States and Europe suffering huge losses and even facing bankruptcy, resulting in massive public financial assistance (government bailouts).\nThe global recession that followed resulted in a sharp drop in international trade, rising unemployment and slumping commodity prices. Several economists predicted that recovery might not appear until 2011 and that the recession would be the worst since the Great Depression of the 1930s. Economist Paul Krugman once commented on this as seemingly the beginning of \"a second Great Depression.\"\nGovernments and central banks responded with fiscal and monetary policies to stimulate national economies and reduce financial system risks. The recession has renewed interest in Keynesian economic ideas on how to combat recessionary conditions.  Economists advise that the stimulus should be withdrawn as soon as the economies recover enough to \"chart a path to sustainable growth\".\nThe distribution of household incomes in the United States has become more unequal during the post-2008 economic recovery, a first for the US but in line with the trend over the last ten economic recoveries since 1949. Income inequality in the United States has grown from 2005 to 2012 in more than 2 out of 3 metropolitan areas.  Median household wealth fell 35% in the US, from $106,591 to $68,839 between 2005 and 2011.", "page_name": "Great Recession", "page_id": "Great%20Recession", "heading": "Overview", "sub_heading": "Overview", "_id": "4000055538--1---1---1", "title": "The Great Recession"}
{"qas": [{"question": "Why are some people more prone to getting sick from birth than others?", "answer": ""}, {"question": "What type of transplants are used to treat immunodeficiency?", "answer": "stem cell transplantation", "ae_score": -0.36861545658186273, "qg_score": null}, {"question": "What is the primary component of immunodeficiency?", "answer": "severe combined immunodeficiency", "ae_score": null, "qg_score": null}], "content": "In reality, immunodeficiency often affects multiple components, with notable examples including severe combined immunodeficiency (which is primary) and acquired immune deficiency syndrome (which is secondary).\nDistinction between primary versus secondary immunodeficiencies are based on, respectively, whether the cause originates in the immune system itself or is, in turn, due to insufficiency of a supporting component of it or an external decreasing factor of it.\nA number of rare diseases feature a heightened susceptibility to infections from childhood onward.  Primary Immunodeficiency is also known as congenital immunodeficiencies.  Many of these disorders are hereditary and are autosomal recessive or X-linked. There are over 80 recognised primary immunodeficiency syndromes; they are generally grouped by the part of the immune system that is malfunctioning, such as lymphocytes or granulocytes.\nThe treatment of primary immunodeficiencies depends on the nature of the defect, and may involve antibody infusions, long-term antibiotics and (in some cases) stem cell transplantation.\nSecondary immunodeficiencies, also known as acquired immunodeficiencies, can result from various immunosuppressive agents, for example, malnutrition, aging, particular medications (e.g., chemotherapy, disease-modifying antirheumatic drugs, immunosuppressive drugs after organ transplants, glucocorticoids) and environmental toxins like mercury and other heavy metals, pesticides and petrochemicals like styrene, dichlorobenzene, xylene, and ethylphenol. For medications, the term ''immunosuppression'' generally refers to both beneficial and potential adverse effects of decreasing the function of the immune system, while the term ''immunodeficiency'' generally refers solely to the adverse effect of increased risk for infection.\nMany specific diseases directly or indirectly cause immunosuppression. This includes many types of cancer, particularly those of the bone marrow and blood cells (leukemia, lymphoma, multiple myeloma), and certain chronic infections. Immunodeficiency is also the hallmark of acquired immunodeficiency syndrome (AIDS), caused by the human immunodeficiency virus (HIV). HIV directly infects a small number of T helper cells, and also impairs other immune system responses indirectly.\nVarious hormonal and metabolic disorders can also result in immune deficiency including anemia, hypothyroidism, diabetes and hypoglycemia.\nSmoking, alcoholism and drug abuse also depress immune response.", "page_name": "Immunodeficiency", "page_id": "Immunodeficiency", "heading": "Types", "sub_heading": "Types", "_id": "5000000530--0---1---1", "title": "Immunodeficiency Syndromes \u2014 Primary and Secondary"}
{"qas": [{"question": "How do we know the age of rock?", "answer": ""}, {"question": "Which technique compares isotopic ratios from the same portion of a sample to avoid the problem?", "answer": "Ar\u2013Ar dating", "ae_score": -0.6348621734178842, "qg_score": null}, {"question": "Which two methods are used to determine the isotopic ratios of a sample?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "According to  the following assumptions must be true for computed dates to be accepted as representing the true age of the rock:\nBoth flame photometry and mass spectrometry are destructive tests, so particular care is needed to ensure that the aliquots used are truly representative of the sample. Ar\u2013Ar dating is a similar technique which compares isotopic ratios from the same portion of the sample to avoid this problem.", "page_name": "K\u2013Ar dating", "page_id": "K%E2%80%93Ar%20dating", "heading": "Assumptions", "sub_heading": "Assumptions", "_id": "5000001203--3---1---1", "title": "Ar\u2013Ar dating is based on the following assumptions"}
{"qas": [{"question": "Why do rechargeable batteries have such short life spans?", "answer": ""}, {"question": "Who is the manufacturer of nickel zinc battery?", "answer": "PowerGenix", "ae_score": -0.22139638155740168, "qg_score": null}, {"question": "Where does zinc come from in a nickel zinc battery?", "answer": "electrolyte", "ae_score": null, "qg_score": null}], "content": "Compared with cadmium hydroxide, the tendency of zinc hydroxide to dissolve into solution and not fully migrate back to the cathode during recharging has, in the past, presented challenges for the commercial viability of the NiZn battery. The zinc's reluctance to fully return to the solid electrode adversely manifests itself as shape change and dendrites (or \"whiskers\"), which may reduce the cell discharging performance or, eventually, short out the cell, resulting in a low cycle life.\nRecent advances have enabled manufacturers to greatly reduce this problem. These advances include improvements in electrode separator materials, inclusion of zinc material stabilizers, and electrolyte improvements (i.e. by using phosphates). One manufacturer, (PowerGenix), which has developed 1.6V batteries, has claimed battery cycle life comparable to NiCd batteries.\nBattery cycle life is most commonly specified at a discharge depth of 80 percent of rated capacity and assuming a one-hour discharge current rate. If the discharge current rate is reduced, or if the depth of discharge is reduced, then the number of charge-discharge cycles for a battery increases. When comparing NiZn to other battery technologies, cycle life specifications may vary with other battery technologies, depending on the discharge rate and depth of discharge that were used.", "page_name": "Nickel\u2013zinc battery", "page_id": "Nickel%E2%80%93zinc%20battery", "heading": "Battery life", "sub_heading": "Battery life", "_id": "5000002552--2---1---1", "title": "NiZn Battery Cycle Life Specifications"}
{"qas": [{"question": "Why is it that when I'm in the shower I feel like I need to pee, but when I go to bed I don't?", "answer": ""}, {"question": "What is the function of random permutation?", "answer": "bivariate generating function", "ae_score": -0.1605027625655191, "qg_score": null}, {"question": "What is the function of random permutation?", "answer": "bivariate generating function", "ae_score": -0.1605027625655191, "qg_score": null}], "content": "We construct the bivariate generating function \n using \n, where \n is one for all cycles (every cycle contributes one to the total number of cycles).\nNote that \nThough there is no closed form for \nand generates the unsigned Stirling numbers of the first kind.\nWe have\nHence the expected number of cycles is the harmonic number \n, or about \n.", "page_name": "Random permutation statistics", "page_id": "Random%20permutation%20statistics", "heading": "Expected number of cycles of any length of a random permutation", "sub_heading": "Expected number of cycles of any length of a random permutation", "_id": "5000003887--12---1---1", "title": "Bivariate Generating Function using Stirling Numbers"}
{"qas": [{"question": "How did countries like China, India, and South Korea become so rich?", "answer": ""}, {"question": "The history of capital free flows and controls can be traced to?", "answer": "financial globalization", "ae_score": -0.6330476479138393, "qg_score": null}, {"question": "The history of capital free flows and controls can be traced to?", "answer": "financial globalization", "ae_score": -0.6330476479138393, "qg_score": null}], "content": "The history of capital free flows and controls unfolds with the history of financial globalization. At the onset, capital moved freely across borders during the Gold Standard period before the World War I. After the World War II, owing to the suspicion that a country\u2019s macroeconomic instability could be due to the volatile capital flows, capital flows were deliberately managed under a variety of administrative controls as part of the governance in the international monetary Bretton Woods system.\nStarting from early 1970s, increasingly relaxed capital controls along with the adoptions of floating exchange rate regime worldwide, though in the midst of concerns, announced the collapse of the Bretton Woods. Roughly from 1990s to 2009 known as the Washington Consensus period, it was widely accepted that the economic prosperity in the emerging market economies was attributed to the liberalization of their capital accounts and the increasing capital inflow. Then the policy prescriptions for these countries were that capital controls should be loosened and eventually abandoned.\nThe pro-capital flow arguments were not reviewed and critiqued until the Great Recession in the late 2000s. Emerging markets experienced strong capital inflows in the boom stage of a business cycle whereas they witnessed huge flow reverse and financial collapse in the bust period. This boom and bust cycles in international capital flows imposed significant welfare costs. Then the theoretical underpinnings of the Great Recession crisis mechanism give a role for the prudential capital controls as an intervention to adjust the market imperfections in order to mitigate the systemic boom-bust cycle effects brought by the international capital flows", "page_name": "Prudential capital controls", "page_id": "Prudential%20capital%20controls", "heading": "History", "sub_heading": "History", "_id": "5000006978--1---1---1", "title": "Capital Freeflows and Controls"}
{"qas": [{"question": "Why is Helen Meara considered one of the most influential women in psychology?", "answer": ""}, {"question": "When did naomi meara write a language analysis of empathy responding to client anger?", "answer": "1982", "ae_score": -0.4588807506152611, "qg_score": null}, {"question": "What type of perspective did naomi meara advocate for in her paper just and?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Meara was a highly productive scholar, with a wide range of interests. She is listed in the top 5% of contributors to the Personnel and Guidance Journal/Journal of Counseling & Development from 1978 to 1993, as well as one of the most productive members of the Counseling Psychology Division of APA between 1974 and 1991. While a full bibliography of Meara's published works is beyond the scope of this article, the following is intended to outline her most important contributions.\nSome of Meara's earliest research interests were in human learning, and one of her first publications, ''A Time to Learn: A Guide to Academic and Personal Effectiveness'', written with Phillip Bandt and Lyle Schmidt, provided college students with skills and practice to enhance their learning.\nMeara carried her interest in learning into the counseling and psychotherapy setting. Returning to Ohio State as a visiting senior research associate in the Department of Computer and Information Science, she worked with Harold Pepinsky and others to develop and use an early computer system, CALAS (Computer-assisted Language Analysis System), for analyzing natural language in counseling. This work resulted in a series of papers regarding the language of counselors and their clients, showing, for example, how the linguistic styles of three psychotherapists (Carl Rogers, Fritz Perls, and Albert Ellis) differed significantly from each other.\nMeara\u2019s interest and research in the language of counseling extended beyond that project, however. In 1982, she published with Wycoff, Davis and Hector \u201cA Language Analysis of Empathic Responding to Client Anger\u201d, which made clear significant differences between low- and high- empathy counselors\u2019 linguistic behavior, pointing out that low-empathy counselors asked \u201csignificantly more questions\u201d. The value of this kind of detailed examination of the therapeutic process was noted in the Annual Review of Psychology as \"moving beyond global questions of outcome and focusing on specific ingredients of the change process. As we understand those specifics better, enhancement of outcome will fall into place.\"\nMeara also produced a number of studies around the topic of anger and verbal aggression. In 1991 for example, Meara, Rosemary Phelps, Kathleen L. Davis and Michael J. Patton conducted a study  comparing African American and white women\u2019s perceptions of verbal aggression. They found that white women viewed episodes of verbal aggression as more aggressive than their African American counterparts, pointing to significant differences in socialization around verbal behaviors. Interestingly, no other main effects were found, regardless of the race of the participants.\nDuring her time at Wisconsin, Meara published research, with Robert M. Jackson and Manmohan Arora, on the relationship between rural fathers\u2019 adequacy as models for identification and their adolescent sons\u2019 career goals and achievement. She and Jackson later published five- and ten-year follow-up research showing that \u201cthe occupational and educational achievements and aspirations\u201d of sons whose fathers had been judged as providing adequate modeling were \u201csignificantly higher\u201d than for those judged less than adequate.\nMeara\u2019s signal contribution to her field, however, came in the area of ethics. Through a series of seminal papers, she introduced the concept of virtue ethics to the counseling psychology field, explained how it was to be distinguished from principle ethics, and provided useful approach for ethical decision making in counseling, providing way of addressing. Virtue ethics emphasizes the importance of personal characteristics or virtues for ethical therapists. Although it has been criticized (e.g. by Donald N. Bersoff) as irrelevant, redundant and potentially idiosyncratic, virtue ethics addresses deficiencies in consequentialism and deontological ethics decision-making processes.\nIn her paper \u201cJust and Virtuous Leaders and Organizations\u201d (2001), she argued for the importance of a virtue ethics perspective in any conversation about moral aspects of organizational justice. She pointed out the need to focus on the character of those who distribute justice, and how the goals of an organization influence its salient virtues. She also warned about the need to understand organizational justice from the perspectives of those who are non-Western and least powerful.\nMeara also contributed substantially to the advancement of women in counseling psychology. She joined the Division 17 Women\u2019s Committee (1974\u201384), reviewing that committee's accomplishments with L.W. Harmon in 1989. She published a number of pieces examining the needs of women and career, including \"Contemporary developments in women\u2019s career counseling: Themes of the past, puzzles for the future\", \"Occupational possible selves: Fears and aspirations of college women\", \"The working lives of women from lower socioeconomic backgrounds: Assessing prospects, enabling success\" and \"Motivational attributes of occupational possible selves for low-income rural women\".", "page_name": "Naomi Meara", "page_id": "Naomi%20Meara", "heading": "Research", "sub_heading": "Research", "_id": "5000007323--2---1---1", "title": "The Role of Virtue Ethics in Counseling Psychology"}
{"qas": [{"question": "Why can't we use gas chromatography to determine the composition of pesticides?", "answer": ""}, {"question": "What facilitated the development of multicomponent analytical methods for 150 pesticide transformation products?", "answer": "High-resolution mass spectrometry", "ae_score": -0.6506971638091456, "qg_score": null}, {"question": "What is the name of the method used to determine the breakdown of pesticides?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "Available strategies to identify in situ pesticide transformation include measuring remnant or transformation product concentrations and estimation of a given environment's theoretical transformation potential. Measurements are only usable on the micro- or mesocosm scale.<ref name=s1308/>\nGas chromatography\u2013mass spectrometry (GC-MS) or liquid chromatography\u2013tandem mass spectrometry (LC-MS/MS) does not  distinguish transformation from other processes such as dilution or sorption unless combined with stringent mass balance modeling. Carbon 14-labeled pesticides do enable mass balances, but investigations with radioactively tagged substrates cannot be conducted in the field.<ref name=s1308/>\nTransformation product detection may calibrate degradation. Target analysis is straightforward when products and standards are understood, while suspect/nontarget analysis can be attempted otherwise. High-resolution mass spectrometry facilitated the development of multicomponent analytical methods for 150 pesticide transformation products and for  screening for suspected transformation products. In combination with transformation product structure models, screening allows a more comprehensive assessment of transformation products, independent of field degradation studies.<ref name=s1308/>\nIsotopic analysis may complement product measurements because it can measure degradation in the absence of metabolites and has the potential to cover sufficiently long time scales to assess transformation in groundwater. Isotope ratios (e.g.,/, /) can reveal history in the absence of any label. Because kinetic isotope effects typically favor transformation of light isotopes (e.g., ), heavy isotopes (13C) become enriched in residues. An increased / isotope ratio in a parent compound thus provides direct evidence of degradation. Repeated pesticide analyses, in groundwater over time, or direct measurements in combination with groundwater dating that show increasing / isotope ratios in a parent pesticide, provides direct evidence of degradation, even if the pesticide was released long before. Multiple transformation pathways were revealed for atrazine by measuring isotope effects of multiple elements. In such a case, transformation mechanisms are identifiable from plots of / versus / parent compound data, reflecting different underlying carbon- and nitrogen-isotope effects. The approach requires a relatively high amount of substance for gas chromatography\u2013isotope ratio mass spectrometry (GC-IRMS) or LC-IRMS analysis (100 ng to 1 \u03bcg), which, for instance, requires extraction of 10 liters of groundwater at pesticide concentrations of 100 ng/liter. For the special case of chiral pesticides, enantiomer analysis may substitute for isotopes in such analyses as a result of stereoselective reactions. Combining isotope and chirality measurement can increase prediction strength.<ref name=s1308/>\nGeochemical analysis including pH, redox potential and dissolved ions is routinely applied to assess the potential for biotic and abiotic transformations, complicated by any lack of specificity in the targets. Selective probe compounds must be used to detect individual reactive species when a mixture of reactive species is present. Combining probe compounds and scavengers or quenchers increases accuracy. E.g., N,N-dimethylaniline, used as a probe for the carbonate radical reacts very quickly with DOM-excited triplet states and its oxidation is hampered by DOM.<ref name=s1308/>\n13C-labeled parent pesticides were used in nontarget analysis of degraders by stable isotope probing (SIP) to demonstrate biotransformation potential in soil and sediment samples. A complementary, potentially more quantitative technique is to directly enumerate the biodegradative gene(s) via quantitative polymerase chain reaction (QPCR), gene sequencing or functional gene microarrays. A prerequisite for genetic approaches, however, is that the involved genes can be clearly linked to a given transformation reaction. For instance, the ''atzD'' gene encoding cyanuric acid hydrolase correlates with atrazine biodegradation in agricultural soil surface layers, consistent with ''AtzD'''s cleavage of the s-triazine ring during bacterial atrazine metabolism. ''AtzD'' was unambiguously identifiable and hence quantifiable, as unusually, it belongs to a protein family that largely consists of biodegradative enzymes. Most proteins studied to date are members of very large protein superfamilies, with as many as 600,000 individual members, with diverse functions. Another factor confounding gene-based approaches is that biodegradative function can arise independently in evolution, such that multiple unrelated genes catalyze the same reaction. E.g., organophosphate esterases that differ markedly in their fold and mechanism can act on the same organophosphate pesticide.<ref name=s1308/>", "page_name": "Pesticide degradation", "page_id": "Pesticide%20degradation", "heading": "Prediction", "sub_heading": "Prediction", "_id": "5000009049--3---1---1", "title": "Biodegradation of Atrazine"}
{"qas": [{"question": "Why are the membranes of the human body so much stronger than the membranes on the rest of the body?", "answer": ""}, {"question": "What type of fuel cell is graphene used in?", "answer": "fuel crossover", "ae_score": -0.24001151543845525, "qg_score": null}, {"question": "What type of material is used to make graphene?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "Graphene oxide membranes allow water vapor to pass through, but are impermeable to other liquids and gases. This phenomenon has been used for further distilling of vodka to higher alcohol concentrations, in a room-temperature laboratory, without the application of heat or vacuum as used in traditional distillation methods. Further development and commercialization of such membranes could revolutionize the economics of biofuel production and the alcoholic beverage industry.\nGraphene solar cells use graphene's unique combination of high electrical conductivity and optical transparency. This material absorbs only 2.6% of green light and 2.3% of red light. Graphene can be assembled into a film electrode with low roughness. These films must be made thicker than one atomic layer to obtain useful sheet resistances. This added resistance can be offset by incorporating conductive filler materials, such as a silica matrix. Reduced conductivity can be offset by attaching large aromatic molecules such as pyrene-1-sulfonic acid sodium salt (PyS) and the disodium salt of 3,4,9,10-perylenetetracarboxylic diimide bisbenzenesulfonic acid (PDI).  These molecules, under high temperatures, facilitate better \u03c0-conjugation of the graphene basal plane.\nUsing graphene as a photoactive material requires its bandgap to be 1.4\u20131.9 eV. In 2010, single cell efficiencies of nanostructured graphene-based PVs of over 12% were achieved.  According to P. Mukhopadhyay and R. K. Gupta organic photovoltaics could be \"devices in which semiconducting graphene is used as the photoactive material and metallic graphene is used as the conductive electrodes\".\nIn 2008, chemical vapor deposition produced graphene sheets by depositing a graphene film made from methane gas on a nickel plate. A protective layer of thermoplastic is laid over the graphene layer and the nickel underneath is then dissolved in an acid bath. The final step is to attach the plastic-coated graphene to a flexible polymer sheet, which can then be incorporated into a PV cell. Graphene/polymer sheets range in size up to 150 square centimeters and can be used to create dense arrays.\nSilicon generates only one current-driving electron for each photon it absorbs, while graphene can produce multiple electrons. Solar cells made with graphene could offer 60% conversion efficiency.\nIn 2010, researchers first reported creating a graphene-silicon heterojunction solar cell, where graphene served as a transparent electrode and introduced a built-in electric field near the interface between the graphene and n-type silicon to help collect charge carriers. In 2012 researchers reported efficiency of 8.6% for a prototype consisting of a silicon wafer coated with trifluoromethanesulfonyl-amide (TFSA) doped graphene. Doping increased efficiency to 9.6% in 2013. In 2015 researchers reported efficiency of 15.6% by choosing the optimal oxide thickness on the silicon. This combination of carbon materials with traditional silicon semiconductors to fabricate solar cells has been a promising field of carbon science.\nIn 2013, another team reported 15.6% percent by combining titanium oxide and graphene as a charge collector and perovskite as a sunlight absorber. The device is manufacturable at temperatures under 150 C using solution-based deposition. This lowers production costs and offers the potential using flexible plastics.\nIn 2015, researchers developed a prototype cell that used semitransparent perovskite with graphene electrodes. The design allowed light to be absorbed from both sides. It offered efficiency of around 12 percent with estimated production costs of less than $0.06/watt. The graphene was coated with PEDOT:PSS conductive polymer (poly(3,4-ethylenedioxythiophene) polystyrene sulfonate). Multilayering graphene via CVD created transparent electrodes reducing sheet resistance. Performance was further improved by increasing contact between the top electrodes and the hole transport layer.\nAppropriately perforated graphene (and hexagonal boron nitride hBN) can allow protons to pass through it, offering the potential for using graphene monolayers as a barrier that blocks hydrogen atoms but not protons/ionized hydrogen (hydrogen atoms with their electrons stripped off). They could even be used to extract hydrogen gas out of the atmosphere that could power electric generators with ambient air.\nThe membranes are more effective at elevated temperatures and when covered with catalytic nanoparticles such as platinum.\nGraphene could solve a major problem for fuel cells: fuel crossover that reduces efficiency and durability.\nIn methanol fuel cells, graphene used as a barrier layer in the membrane area, has reduced fuel cross over with negligible proton resistance, improving the performance.\nAt room temperature, proton conductivity with monolayer hBN, outperforms graphene, with resistivity to proton flow of about 10 \u03a9 cm and a low activation energy of about 0.3 electronvolts. At higher temperatures, graphene outperforms with resistivity estimated to fall below 10 \u03a9 cm above 250 degrees Celsius.\nIn another project, protons easily pass through slightly imperfect graphene membranes on fused silica in water. The membrane was exposed to cycles of high and low pH. Protons transferred reversibly from the aqueous phase through the graphene to the other side where they undergo acid\u2013base chemistry with silica hydroxyl groups. Computer simulations indicated energy barriers of 0.61\u20130.75\u2009eV for hydroxyl-terminated atomic defects that participate in a Grotthuss-type relay, while pyrylium-like ether terminations did not. Recently, Paul and co-workers at IISER Bhopal demonstrated solid state proton conduction for oxygen functionalized few-layer graphene(8.7x10 S/cm) with a low activation barrier (0.25 eV).\nAdding .6% graphene to a mixture of lanthanum and partly reduced strontium titanium oxide produces a strong Seebeck at temperatures ranging from room temperature to 750 \u00b0C (compared to 500-750 without graphene). The material converts 5% of the heat into electricity (compared to 1% for strontium titanium oxide.)\nIn 2015 a graphene coating on steam condensers quadrupled condensation efficiency, increasing overall plant efficiency by 2-3 percent.", "page_name": "Potential applications of graphene", "page_id": "Potential%20applications%20of%20graphene", "heading": "Energy", "sub_heading": "Energy", "_id": "5000009419--3--0---1", "title": "Graphene Solar Cells"}
{"qas": [{"question": "How is it possible for a battery to last over a week on one charge?", "answer": ""}, {"question": "When was graphene first used in lithium ion batteries?", "answer": "2012", "ae_score": -0.16348046944420555, "qg_score": null}, {"question": "What property of a stacked graphene supercapacitor is greatly increased by the use of?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Due to graphene's high surface area to mass ratio, one potential application is in the conductive plates of supercapacitors.\nIn February 2013 researchers announced a novel technique to produce graphene supercapacitors based on the DVD burner reduction approach.\nIn 2014 a supercapacitor was announced that was claimed to achieve energy density comparable to current lithium-ion batteries.\nIn 2015 the technique was adapted to produce stacked, 3-D supercapacitors. Laser-induced graphene was produced on both sides of a polymer sheet. The sections were then stacked, separated by solid electrolytes, making multiple microsupercapacitors. The stacked configuration substantially increased the energy density of the result. In testing, the researchers charged and discharged the devices for thousands of cycles with almost no loss of capacitance. The resulting devices were mechanically flexible, surviving 8,000 bending cycles. This makes them potentially suitable for rolling in a cylindrical configuration.  Solid-state polymeric electrolyte-based devices exhibit areal capacitance of >9 mF/cm2 at a current density of 0.02 mA/cm2, over twice that of conventional aqueous electrolytes.\nAlso in 2015 another project announced a microsupercapacitor that is small enough to fit in wearable or implantable devices. Just one-fifth the thickness of a sheet of paper, it is capable of holding more than twice as much charge as a comparable thin-film lithium battery. The design employed laser-scribed graphene, or LSG with manganese dioxide. They can be fabricated without extreme temperatures or expensive \u201cdry rooms\u201d. Their capacity is six times that of commercially available supercapacitors. The device reached volumetric capacitance of over 1,100 F/cm3. This corresponds to a specific capacitance of the constituent MnO2 of 1,145 F/g, close to the theoretical maximum of 1,380 F/g. Energy density varies between 22 and 42 Wh/l depending on device configuration.\nIn May 2015 a boric acid-infused, laser-induced graphene supercapacitor tripled its areal energy density and increased its volumetric energy density 5-10 fold. The new devices proved stable over 12,000 charge-discharge cycles, retaining 90 percent of their capacitance. In stress tests, they survived 8,000 bending cycles.\nSilicon-graphene anode lithium ion batteries were demonstrated in 2012.\nStable Lithium ion cycling was demonstrated in bi- and few layer graphene films grown on nickel substrates, while single layer graphene films have been demonstrated as a protective layer against corrosion in battery components such as the battery case. This creates possibilities for flexible electrodes for microscale Li-ion batteries, where the anode acts as the active material and the current collector.\nResearchers built a lithium-ion battery made of graphene and silicon, which was claimed to last over a week on one charge and took only 15 minutes to charge.\nIn 2015 argon-ion based plasma processing was used to bombard graphene samples with argon ions. That knocked out some carbon atoms and increased the capacitance of the materials three-fold. These \u201carmchair\u201d and \u201czigzag\u201d defects are named based on the configurations of the carbon atoms that surround the holes.", "page_name": "Potential applications of graphene", "page_id": "Potential%20applications%20of%20graphene", "heading": "Energy", "sub_heading": "Storage", "_id": "5000009419--3--1---1", "title": "Graphene Supercapacitors \u2014 The Future of Lithium Ion Batterie"}
{"qas": [{"question": "How do we know that the Earth's magnetic poles are reversed?", "answer": ""}, {"question": "The study of the magnetic field of the earth is known as?", "answer": "paleomagnetism", "ae_score": -0.2593802317881521, "qg_score": null}, {"question": "Where does the magnetic field of the earth come from?", "answer": "geomagnetic reversals", "ae_score": null, "qg_score": null}], "content": "Earth's magnetic field serves to deflect most of the solar wind, whose charged particles would otherwise strip away the ozone layer that protects the Earth from harmful ultraviolet radiation. One stripping mechanism is for gas to be caught in bubbles of magnetic field, which are ripped off by solar winds. Calculations of the loss of carbon dioxide from the atmosphere of Mars, resulting from scavenging of ions by the solar wind, indicate that the dissipation of the magnetic field of Mars caused a near total loss of its atmosphere.\nThe study of past magnetic field of the Earth is known as paleomagnetism. The polarity of the Earth's magnetic field is recorded in igneous rocks, and reversals of the field are thus detectable as \"stripes\" centered on mid-ocean ridges where the sea floor is spreading, while the stability of the geomagnetic poles between reversals has allowed paleomagnetists to track the past motion of continents. Reversals also provide the basis for magnetostratigraphy, a way of dating rocks and sediments. The field also magnetizes the crust, and magnetic anomalies can be used to search for deposits of metal ores.\nHumans have used compasses for direction finding since the 11th century A.D. and for navigation since the 12th century. Although the magnetic declination does shift with time, this wandering is slow enough that a simple compass remains useful for navigation. Using magnetoception various other organisms, ranging from some types of bacteria to pigeons, use the Earth's magnetic field for orientation and navigation.", "page_name": "Earth's magnetic field", "page_id": "Earth's%20magnetic%20field", "heading": "Importance", "sub_heading": "Importance", "_id": "5000015028--0---1---1", "title": "The Magnetic Field of the Earth"}
{"qas": [{"question": "What would happen if the Earth's magnetic poles were reversed?", "answer": ""}, {"question": "Where does the magnetic field of the earth come from?", "answer": "solar flares", "ae_score": -0.417906297230418, "qg_score": null}, {"question": "Where does the magnetic field of the earth come from?", "answer": "solar flares", "ae_score": -0.417906297230418, "qg_score": null}], "content": "The geomagnetic field changes on time scales from milliseconds to millions of years. Shorter time scales mostly arise from currents in the ionosphere (ionospheric dynamo region) and magnetosphere, and some changes can be traced to geomagnetic storms or daily variations in currents. Changes over time scales of a year or more mostly reflect changes in the Earth's interior, particularly the iron-rich core.\nFrequently, the Earth's magnetosphere is hit by solar flares causing geomagnetic storms, provoking displays of aurorae. The short-term instability of the magnetic field is measured with the K-index.\nData from THEMIS show that the magnetic field, which interacts with the solar wind, is reduced when the magnetic orientation is aligned between Sun and Earth - opposite to the previous hypothesis. During forthcoming  solar storms, this could result in blackouts and disruptions in artificial satellites.", "page_name": "Earth's magnetic field", "page_id": "Earth's%20magnetic%20field", "heading": "Time dependence", "sub_heading": "Time dependence", "_id": "5000015028--3--0---1", "title": "Geomagnetic Storms and the Earth's Magnetic Field"}
{"qas": [{"question": "How do we know that the Earth's magnetic poles have changed over millions of years?", "answer": ""}, {"question": "What is it called when the earth's magnetic field changes?", "answer": "secular variation", "ae_score": -0.5001745096915621, "qg_score": null}, {"question": "What is the main cause of changes in the earth's magnetic field?", "answer": "geomagnetic reversals", "ae_score": null, "qg_score": null}], "content": "Changes in Earth's magnetic field on a time scale of a year or more are referred to as ''secular variation''. Over hundreds of years, magnetic declination is observed to vary over tens of degrees. A movie on the right shows how global declinations have changed over the last few centuries.\nThe direction and intensity of the dipole change over time. Over the last two centuries the dipole strength has been decreasing at a rate of about 6.3% per century. At this rate of decrease, the field would be negligible in about 1600 years. However, this strength is about average for the last 7 thousand years, and the current rate of change is not unusual.\nA prominent feature in the non-dipolar part of the secular variation is a ''westward drift'' at a rate of about 0.2 degrees per year. This drift is not the same everywhere and has varied over time. The globally averaged drift has been westward since about 1400 AD but eastward between about 1000 AD and 1400 AD.\nChanges that predate magnetic observatories are recorded in archaeological and geological materials. Such changes are referred to as ''paleomagnetic secular variation'' or ''paleosecular variation (PSV)''. The records typically include long periods of small change with occasional large changes reflecting geomagnetic excursions and reversals.", "page_name": "Earth's magnetic field", "page_id": "Earth's%20magnetic%20field", "heading": "Time dependence", "sub_heading": "Secular variation", "_id": "5000015028--3--1---1", "title": "The Evolution of Earth's Magnetic Field"}
{"qas": [{"question": "How do we know the age of the ocean?", "answer": ""}, {"question": "The geophysical correlation technique that can be used to date both sedimentary and volcanic sequences?", "answer": "magnetostratigraphy", "ae_score": -0.3350741059762626, "qg_score": null}, {"question": "What is it called when the earth's magnetic field changes?", "answer": "polarity excursion", "ae_score": null, "qg_score": null}], "content": "Although generally Earth's field is approximately dipolar, with an axis that is nearly aligned with the rotational axis, occasionally the North and South geomagnetic poles trade places. Evidence for these ''geomagnetic reversals'' can be found in basalts, sediment cores taken from the ocean floors, and seafloor magnetic anomalies. Reversals occur nearly randomly in time, with intervals between reversals ranging from less than 0.1 million years to as much as 50 million years. The most recent geomagnetic reversal, called the Brunhes\u2013Matuyama reversal, occurred about 780,000 years ago. A related phenomenon, a geomagnetic excursion, amounts to an incomplete reversal, with no change in polarity. The Laschamp event is an example of an excursion, it having occurred during the last ice age (41,000 years ago).\nThe past magnetic field is recorded mostly by strongly magnetic minerals, particularly iron oxides such as magnetite, that can carry a permanent magnetic moment. This remanent magnetization, or ''remanence'', can be acquired in more than one way. In lava flows, the direction of the field is \"frozen\" in small minerals as they cool, giving rise to a thermoremanent magnetization. In sediments, the orientation of magnetic particles acquires a slight bias towards the magnetic field as they are deposited on an ocean floor or lake bottom. This is called ''detrital remanent magnetization''.\nThermoremanent magnetization is the main source of the magnetic anomalies around ocean ridges. As the seafloor spreads, magma wells up from the mantle, cools to form new basaltic crust on both sides of the ridge, and is carried away from it by seafloor spreading. As it cools, it records the direction of the Earth's field. When the Earth's field reverses, new basalt records the reversed direction. The result is a series of stripes that are symmetric about the ridge. A ship towing a magnetometer on the surface of the ocean can detect these stripes and infer the age of the ocean floor below. This provides information on the rate at which seafloor has spread in the past.\nRadiometric dating of lava flows has been used to establish a ''geomagnetic polarity time scale'', part of which is shown in the image. This forms the basis of magnetostratigraphy, a geophysical correlation technique that can be used to date both sedimentary and volcanic sequences as well as the seafloor magnetic anomalies.\nStudies of lava flows on Steens Mountain, Oregon, indicate that the magnetic field could have shifted at a rate of up to 6 degrees per day at some time in Earth's history, which significantly challenges the popular understanding of how the Earth's magnetic field works. This finding was later attributed to unusual rock magnetic properties of the lava flow under study, not rapid field change, by one of the original authors of the 1995 study.\nTemporary dipole tilt variations that take the dipole axis across the equator and then back to the original polarity are known as ''excursions''.", "page_name": "Earth's magnetic field", "page_id": "Earth's%20magnetic%20field", "heading": "Time dependence", "sub_heading": "Magnetic field reversals", "_id": "5000015028--3--2---1", "title": "Geomagnetic Excursions and the Earth's Magnetic Field"}
{"qas": [{"question": "Why is the Earth's magnetic north pole moving so slowly?", "answer": ""}, {"question": "What causes the strength of the earth's magnetic field?", "answer": "heteroscedastic fluctuation", "ae_score": -0.2374170240695523, "qg_score": null}, {"question": "What causes the strength of the earth's magnetic field?", "answer": "heteroscedastic fluctuation", "ae_score": -0.2374170240695523, "qg_score": null}], "content": "At present, the overall geomagnetic field is becoming weaker; the present strong deterioration corresponds to a 10\u201315% decline over the last 150 years and has accelerated in the past several years; geomagnetic intensity has declined almost continuously from a maximum 35% above the modern value achieved approximately 2,000 years ago. The rate of decrease and the current strength are within the normal range of variation, as shown by the record of past magnetic fields recorded in rocks.\nThe nature of Earth's magnetic field is one of heteroscedastic fluctuation. An instantaneous measurement of it, or several measurements of it across the span of decades or centuries, are not sufficient to extrapolate an overall trend in the field strength. It has gone up and down in the past for no apparent reason. Also, noting the local intensity of the dipole field (or its fluctuation) is insufficient to characterize Earth's magnetic field as a whole, as it is not strictly a dipole field. The dipole component of Earth's field can diminish even while the total magnetic field remains the same or increases.\nThe Earth's magnetic north pole is drifting from northern Canada towards Siberia with a presently accelerating rate\u201410 km per year at the beginning of the 20th century, up to 40 km per year in 2003, and since then has only accelerated.", "page_name": "Earth's magnetic field", "page_id": "Earth's%20magnetic%20field", "heading": "Time dependence", "sub_heading": "Future", "_id": "5000015028--3--4---1", "title": "Geomagnetic Field of Earth"}
{"qas": [{"question": "What is natural transformation?", "answer": ""}, {"question": "How many genes are needed to undergo horizontal gene transfer in bacillus subtilis?", "answer": "about 40", "ae_score": null, "qg_score": null}, {"question": "Where does the energy for horizontal gene transfer come from?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "Natural transformation is a bacterial adaptation for DNA transfer (HGT) that depends on the expression of numerous bacterial genes whose products are responsible for this process.  In general, transformation is a complex, energy-requiring developmental process. In order for a bacterium to bind, take up and recombine exogenous DNA into its chromosome, it must become competent, that is, enter a special physiological state. Competence development in Bacillus subtilis requires expression of about 40 genes.  The DNA integrated into the host chromosome is usually (but with infrequent exceptions) derived from another bacterium of the same species, and is thus homologous to the resident chromosome. The capacity for natural transformation occurs in at least 67 prokaryotic species. Competence for transformation is typically induced by high cell density and/or nutritional limitation, conditions associated with the stationary phase of bacterial growth.  Competence appears to be an adaptation for DNA repair.  Transformation in bacteria can be viewed as a primitive sexual process, since it involves interaction of homologous DNA from two individuals to form recombinant DNA that is passed on to succeeding generations.", "page_name": "Horizontal gene transfer", "page_id": "Horizontal%20gene%20transfer", "heading": "Prokaryotes", "sub_heading": "Prokaryotes", "_id": "5000015978--4--0---1", "title": "Bacillus subtilis Natural Transformation"}
{"qas": [{"question": "What is the difference between conjugation and recombination?", "answer": ""}, {"question": "Horizontal gene transfer in mycobacterium smegmatis is a type of?", "answer": "HGT", "ae_score": null, "qg_score": null}, {"question": "Where does horizontal gene transfer take place in bacteria?", "answer": "genomes", "ae_score": null, "qg_score": null}], "content": "Conjugation in ''Mycobacterium smegmatis'', like conjugation in ''E. coli'', requires stable and extended contact between a donor and a recipient strain, is DNase resistant, and the transferred DNA is incorporated into the recipient chromosome by homologous recombination. However, unlike ''E. coli'' high frequency of recombination conjugation (Hfr), mycobacterial conjugation is a type of HGT that is chromosome rather than plasmid based.   Furthermore, in contrast to ''E. coli'' (Hfr) conjugation, in M. smegmatis all regions of the chromosome are transferred with comparable efficiencies.  Substantial blending of the parental genomes was found as a result of conjugation, and this blending was regarded as reminiscent of that seen in the meiotic products of sexual reproduction.", "page_name": "Horizontal gene transfer", "page_id": "Horizontal%20gene%20transfer", "heading": "Prokaryotes", "sub_heading": "Eubacterial conjugation", "_id": "5000015978--4--1---1", "title": "''Mycobacterium smegmatis'' Conjugation"}
{"qas": [{"question": "How do thermophilic organisms survive the heat of the sun?", "answer": ""}, {"question": "How many genes are encoded by the ups operon?", "answer": "five", "ae_score": -0.42550419856258287, "qg_score": null}, {"question": "How many genes are encoded by the ups operon?", "answer": "five", "ae_score": -0.42550419856258287, "qg_score": null}], "content": "The archaeon ''Sulfolobus solfataricus'', when UV irradiated, strongly induces the formation of type IV pili which then facilitates cellular aggregation.  Exposure to chemical agents that cause DNA damage also induces cellular aggregation.  Other physical stressors, such as temperature shift or pH, do not induce aggregation, suggesting that DNA damage is a specific inducer of cellular aggregation.\nUV-induced cellular aggregation mediates intercellular chromosomal HGT marker exchange with high frequency, and UV-induced cultures display recombination rates that exceed those of uninduced cultures by as much as three orders of magnitude.  ''S. solfataricus'' cells aggregate preferentially with other cells of their own species.  Frols et al. and Ajon et al. suggested that UV-inducible DNA transfer is likely an important mechanism for providing increased repair of damaged DNA via homologous recombination. This process can be regarded as a simple form of sexual interaction.\nAnother thermophilic species, ''Sulfolobus acidocaldarius'', is able to undergo HGT.  ''S. acidocaldarius'' can exchange and recombine chromosomal markers at temperatures up to 84C.  UV exposure induces pili formation and cellular aggregation.  Cells with the ability to aggregate have greater survival than mutants lacking pili that are unable to aggregate.  The frequency of recombination is increased by DNA damage induced by UV-irradiation and by DNA damaging chemicals.\nThe ''ups'' operon, containing five genes, is highly induced by UV irradiation.  The proteins encoded by the ''ups'' operon are employed in UV-induced pili assembly and cellular aggregation leading to intercellular DNA exchange and homologous recombination.  Since this system increases the fitness of ''S. acidocaldarius'' cells after UV exposure, Wolferen et al. considered that transfer of DNA likely takes place in order to repair UV-induced DNA damages by homologous recombination.", "page_name": "Horizontal gene transfer", "page_id": "Horizontal%20gene%20transfer", "heading": "Prokaryotes", "sub_heading": "Archaeal DNA transfer", "_id": "5000015978--4--2---1", "title": "''Sulfolobus solfataricus'' \u2014 UV"}
{"qas": [{"question": "What are Spikes and how do they work?", "answer": ""}, {"question": "When does the viral process take place in lithium air battery?", "answer": "room temperature", "ae_score": -0.9614185611941394, "qg_score": null}, {"question": "What does a genetically modified m13 bacteriophage virus offer in lithium-ion?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "A  nanowire array cathode augmented by a genetically modified M13 bacteriophage virus offers two to three times the energy density of 2015 lithium-ion batteries. The virus increased the size of the nanowire array, which is about 80 nm across. The resulting wires had a spiked surface. Spikes create more surface area to host reaction sites. The viral process creates a cross-linked 3D structure, rather than isolated wires, stabilizing the electrode. The viral process is water-based and takes place at room temperature.", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Design", "sub_heading": "Design", "_id": "5000026109--2--0---1", "title": "A nanowire array cathode augmented with a genetically modified M13 "}
{"qas": [{"question": "Why is hydrogen peroxide the final discharge product of non-aqueous Li-O batteries?", "answer": ""}, {"question": "What is the best electrocatalyst for o evolution?", "answer": "Pt/C", "ae_score": -0.34079113711830755, "qg_score": null}, {"question": "What property of a lithium-air battery is limited by the reactions on the oxygen electrodes?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "The non-aqueous Li-air batteries were demonstrated first (Abraham and Jiang 1996). They usually use the same mixed ethylene carbonate+ propylene carbonate solvents with LiPF or Li bis-sulfonimide salts like the conventional lithium-ion batteries, however, with a gelled rather than liquid electrolyte. (Imanishi, Matsui, et al. 2014) The voltage difference upon constant current charge and discharge is usually between 1.3 and 1.8 V (with an OCP of ca. 4.2 V) even at such ridiculously low currents as 0.01-0.5 mA/cm\u00b2 and 50-500 mA/g of C on the positive electrode (see Fig. 2 as an example), (Balaish, Kraytsberg et al. 2014, McCloskey, Burke, et al. 2015, Liu, Xu, et al. 2016). However, the carbonate solvents do evaporate and get oxidized due to a high overvoltage upon charge, (Lu and Amine 2013) and other solvents, such as end-capped glymes, DMSO, dimethylacetamide, and ionic liquids, have been considered. (Balaish, Kraytsberg et al. 2014, Imanishi, Matsui et al. 2014)  Carbon cathode also gets oxidized above +3.5 V v Li during charge forming LiCO, which leads to an irreversible capacity loss (Imanishi, Matsui et al. 2014).\nMost effort involved aprotic materials, which consist of a lithium metal anode, a liquid organic electrolyte and a porous carbon cathode. The electrolyte can be made of any organic liquid able to solvate lithium salts such as , , , and ), but typically consisted of carbonates, ethers and esters. The carbon cathode is usually made of a high-surface-area carbon material with a nanostructured metal oxide catalyst (commonly  or ). A major advantage is the spontaneous formation of a barrier between anode and electrolyte (analogous to the barrier formed between electrolyte and carbon-lithium anodes in conventional Li-ion batteries) that protects the lithium metal from further reaction with the electrolyte. Although rechargeable, the  produced at the cathode is generally insoluble in the organic electrolyte, leading to buildup along the cathode/electrolyte interface. This makes cathodes in aprotic batteries prone to clogging and volume expansion that progressively reduces conductivity and degrades battery performance.  Another issue is that organic electrolytes are flammable and can ignite if the cell is damaged.\nIn 2012, researchers announced that a dimethyl sulfoxide electrolyte and gold nanoparticle cathode achieved 100 charge cycles with 5% capacity loss.<ref name=service/>\nAlthough most studies agree that  is the final discharge product of non-aqueous Li-O batteries, there is a considerable body of evidence that its formation does not proceed as a direct 2-electron electroreduction to peroxide O (which is the common pathway for O reduction in water on carbon) but rather via a one\u2013electron reduction to superoxide O, followed by its disproportionation:\n2=  \t\t\t\t\t(1).\nSuperoxide (O) has been traditionally considered as a dangerous intermediate in aprotic oxygen batteries due to its high nucleophilicity, basicity and redox potential (Balaish, Kraytsberg et al. 2014, McCloskey, Burke et al. 2015).  However, recent reports from Argonne (Zhai, Lau et al. 2015, Lu, Lee et al. 2016) suggest that superoxide (LiO) is not just an intermediate during the discharge to peroxide () and but that that LiO can actually be used as the final discharge product, potentially with an improved cycle life albeit with a lower specific energy (a little heavier battery weight). Indeed, it was shown that under certain conditions, the superoxide can be stable on the scale of 20-70 h at room temperature (Zhai, Lau et al. 2015). Although an irreversible capacity loss upon disproportionation of LiO in the charged battery was not addressed in that work.\nPt/C seems to be the best electrocatalyst for O evolution and Au/C for O reduction when  is the product (Lu, Xu et al. 2010). Nevertheless, \u201cthe performance of rechargeable lithium-air batteries with non-aqueous electrolytes is limited by the reactions on the oxygen electrode, especially by O evolution\u2026 Conventional porous carbon air electrodes are unable to provide mAh/g and mAh/cm capacities and discharge rates at the magnitudes required for really high energy density batteries for EV applications.\u201d (Lu, Xu, et al. 2010)   The capacity (in mAh/cm) and the cycle life of the non-aqueous Li-O batteries is limited by the deposition of insoluble and poorly electronically conducting LiOx phases upon discharge (Balaish, Kraytsberg et al. 2014). ( is predicted to have a better Li+ conductivity than the LiO and  phases) (Shi, Xu et al. 2015). This makes the practical specific energy of Li-O batteries significantly smaller than the reagent-level calculation predicts. It seems that these parameters have reached their limits by now, and further improvement can be expected only from alternative methods.", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Design", "sub_heading": "Electrolyte", "_id": "5000026109--2--1--0", "title": "Li-O Batteries \u2014 A Proteomic Approach"}
{"qas": [{"question": "What is aqueous Li-air battery?", "answer": ""}, {"question": "What does the aqueous electrolyte combine in a lithium-air battery?", "answer": "lithium salts dissolved in water", "ae_score": -1.40841221691845, "qg_score": null}, {"question": "What type of metal is in a lithium air battery?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "An aqueous Li-air battery consists of a lithium metal anode, an aqueous electrolyte and a porous carbon cathode. The aqueous electrolyte combines lithium salts dissolved in water. It avoids the issue of cathode clogging because the reaction products are water-soluble. The aqueous design has a higher practical discharge potential than its aprotic counterpart. However, lithium metal reacts violently with water and thus the aqueous design requires a solid electrolyte interface between the lithium and electrolyte. Commonly, a lithium-conducting ceramic or glass is used, but conductivities are generally low (on the order of 10 S/cm at ambient temperatures).", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Design", "sub_heading": "Aqueous", "_id": "5000026109--2--1--1", "title": "Aqueous Li-air Battery"}
{"qas": [{"question": "What is the difference between solid and ceramic electrolytes?", "answer": ""}, {"question": "What type of ceramic is used to join the electrolytes in a hybrid battery?", "answer": "lithium-conducting ceramic", "ae_score": -0.5830699269016776, "qg_score": null}, {"question": "What is on the aqueous side of a lithium air battery?", "answer": "anode", "ae_score": null, "qg_score": null}], "content": "The aqueous\u2013aprotic or mixed Li-air battery design attempts to unite advantages of the aprotic and aqueous battery designs. The common feature of hybrid designs is a two-part (one part aqueous and one part aprotic) electrolyte connected by a lithium-conducting membrane. The anode abuts the aprotic side while the cathode is in contact with the aqueous side. A lithium-conducting ceramic is typically employed as the membrane joining the two electrolytes.\nThe use of a solid electrolyte (see Fig. 3) is one such alternative approaches that allows for a combination of a lithium metal anode with an aqueous cathode (Visco 2004). Ceramic solid electrolytes (CSEs) of the NASICON type (e.g., LiAM(PO) with A \u2208 [Al, Sc, Y] and M \u2208 [Ti, Ge]) is one family of Li+ conducting materials that has been studied. Albeit compatible with water at alkaline pH and having a large electrochemical window (see Figs. 3,4), their low Li+ ion conductivity near room temperature (< 0.005 S/cm, >85 \u03a9 cm) (Imanishi, Matsui et al. 2014) makes them unsuitable for automotive and stationary energy storage applications which demand a low cost of power (i.e., operating current densities over 100 mA/cm). Further, both Ti and Ge are reduced by metallic Li, and an intermediate layer between the ceramic electrode and the negative electrode is required.  In contrast, solid polymer electrolytes (SPEs) can provide a higher conductivity but at the expense of a faster crossover of water and of other small molecules which are reactive toward metallic Li. Among the more exotic membranes considered for Li-O batteries is single-crystal silicon (Lu and Amine 2013).\nIn 2015 researchers announced a design that a used highly porous form of graphene for the anode, an electrolyte of lithium bis(trifluoromethyl) sulfonylimide/dimethoxyethane with added water and lithium iodide for use as a \"mediator\". The electrolyte produces lithium hydroxide (LiOH) at the cathode instead of lithium peroxide (). The result offered energy efficiency of 93 percent (voltage gap of .2) and cycled more than 2,000 times with little impact on output. However, the design required pure oxygen to function, rather than ambient air.", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Design", "sub_heading": "Mixed aqueous\u2013aprotic", "_id": "5000026109--2--1--2", "title": "Aqueous\u2013Aprotic Li-Air Battery Design"}
{"qas": [{"question": "What is the difference between solid state and non-solid state batteries?", "answer": ""}, {"question": "What is the main drawback of a solid state battery?", "answer": "low conductivity", "ae_score": -1.55851246450499, "qg_score": null}, {"question": "What type of anode is used in a solid state battery?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "A solid-state battery design is attractive for its safety, eliminating the chance of ignition from rupture. Current solid-state Li-air batteries use a lithium anode, a ceramic, glass, or glass-ceramic electrolyte, and a porous carbon cathode. The anode and cathode are typically separated from the electrolyte by polymer-ceramic composites that enhance charge transfer at the anode, and electrochemically couple the cathode to the electrolyte. The polymer-ceramic composites reduce overall impedance. The main drawback of the solid-state battery design is the low conductivity of most glass-ceramic electrolytes. The ionic conductivity of current lithium fast ion conductors is still lower than liquid electrolyte alternatives.", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Design", "sub_heading": "Solid state", "_id": "5000026109--2--1--3", "title": "Solid-state Li-air Batteries"}
{"qas": [{"question": "Why does the cathode of a car have a lower capacity than the battery?", "answer": ""}, {"question": "How are pore and pore distribution determined?", "answer": "poorly understood", "ae_score": -0.19930357284480815, "qg_score": null}, {"question": "What is the most common anode material used in lithium air battery?", "answer": "silicon", "ae_score": null, "qg_score": null}], "content": "As of 2013, many challenges confronted designers of Li-air batteries.\nMost of the current limits in Li-air battery development are at the cathode, which is also the source of its potential advantages. Incomplete discharge due to blockage of the porous carbon cathode with discharge product such as lithium peroxide (in aprotic designs) is the most serious.\nThe effect of pore size and pore size distribution remains poorly understood.\nCatalysts have shown promise in creating preferential nucleation of  over , which is irreversible with respect to lithium.\nAtmospheric oxygen must be present at the cathode, but contaminants such as water vapor can damage it.\nThe main challenge in anode development is preventing the anode from reacting with the electrolyte. Alternatives include new electrolyte materials or redesigning the interface between electrolyte and anode. Other challenges pertain to the particular choice of anode material, such as silicon or lithium. A great concern for silicon anodes is the large volume expansion (320%) it experiences as it alloys with lithium. For lithium anodes, dendritic lithium deposits can form, decreasing energy capacity or triggering a short circuit.\nIn current cell designs, the charge overpotential is much higher than the discharge overpotential. Significant charge overpotential indicates the presence of secondary reactions. Thus, electric efficiency is only around 65%.\nCatalysts such as manganese dioxide (), Co, Pt, and Au can potentially reduce the overpotentials, but the effect is poorly understood. Several catalysts improve cathode performance, notably . The mechanism of improvement is unknown, but may alter the structure of the oxide deposits.\nSignificant drops in cell capacity with increasing discharge rates are another issue. The decrease in cell capacity is attributed to kinetic charge transfer limits. Since the anodic reaction occurs very quickly, the charge transfer limits are thought to occur at the cathode.\nLong term battery operation requires chemical stability of all cell components. Current cell designs show poor resistance to oxidation by reaction products and intermediates. Many aqueous electrolytes are volatile and can evaporate over time. Stability is hampered in general by parasitic chemical reactions taking place for instance those involving reactive oxygen.,", "page_name": "Lithium\u2013air battery", "page_id": "Lithium%E2%80%93air%20battery", "heading": "Challenges", "sub_heading": "Challenges", "_id": "5000026109--3---1---1", "title": "Li-air Battery Design"}
{"qas": [{"question": "Why do some medicines have to be taken daily and others can be taken indefinitely?", "answer": ""}, {"question": "What is the relative risk of response to treatment with propranolol?", "answer": "1.94", "ae_score": -0.15288541606356493, "qg_score": null}, {"question": "Fluoxetine is an example of which type of antidepressant?", "answer": "selective serotonin reuptake inhibitors", "ae_score": null, "qg_score": null}], "content": "A 2006 review article by S. Modi and D. Lowder offers some general guidelines on when a physician should consider prescribing drugs for migraine prevention:\nPreventive medication has to be taken on a daily basis, usually for a few weeks, before the effectiveness can be determined. Supervision by a neurologist is advisable. A large number of medications with varying modes of action can be used. Selection of a suitable medication for any particular patient is a matter of trial and error, since the effectiveness of individual medications varies widely from one patient to the next. Often preventive medications do not have to be taken indefinitely. Sometimes as little as six months of preventive therapy is enough to \"break the headache cycle\" and then they can be discontinued.\nThe most effective prescription medications include several drug classes.\nA meta-analysis found that propranolol had an \"overall relative risk of response to treatment (here called the 'responder ratio')\" was 1.94.\nAnticonvulsants such as valproic acid and topiramate. A meta-analysis by the Cochrane Collaboration of ten randomized controlled trials or crossover studies, which together included 1341 patients, found anticonvulsants had an \"2.4 times more likely to experience a 50% or greater reduction in frequency with anticonvulsants than with placebo\" and a number needed to treat of 3.8. However, concerns have been raised about the marketing of gabapentin.\nTricyclic antidepressants (TCAs) such as amitriptyline and the newer selective serotonin reuptake inhibitors (SSRIs) such as fluoxetine are sometimes prescribed. Tricyclic antidepressants have been found to be more effective than SSRIs. A meta-analysis by the Cochrane Collaboration found selective serotonin reuptake inhibitors are no more effective than placebo. Another meta-analysis found benefit from SSRIs among patients with migraine or tension headache; however, the effect of SSRIs on only migraines was not separately reported.", "page_name": "Prevention of migraines", "page_id": "Prevention%20of%20migraines", "heading": "Medications", "sub_heading": "Medications", "_id": "5000026513--1---1---1", "title": "Preventive Medicines for Migraines"}
{"qas": [{"question": "What is the significance of the Curiosity rover landing on Mars?", "answer": ""}, {"question": "When did the rover get launched on mars?", "answer": "November 26, 2011", "ae_score": -0.2803939337002717, "qg_score": null}, {"question": "When did the rover get launched on mars?", "answer": "November 26, 2011", "ae_score": -0.2803939337002717, "qg_score": null}], "content": "John Grotzinger is involved in several planetary missions. He was Project Scientist for the Mars Science Laboratory (MSL) Curiosity rover mission, a Participating Scientist for the Mars Exploration Rover (MER) mission, and a Participating Scientist for the High Resolution Science Experiment (HiRISE) camera, onboard the Mars Reconnaissance Orbiter (MRO).\nGrotzinger has made significant contributions to understanding the early environmental history of Mars, as preserved within its record of sedimentary rocks.  A long-standing goal of Mars environmental studies has been to understand the role of water throughout its geologic history. The presence of water is an indicator of potential habitability as well as of formerly different climatic conditions. Prior to in situ investigations by the Mars Exploration Rovers, most studies of water-related processes had been based on orbiter analysis of geomorphic and spectroscopic attributes. However, we can now directly examine the record of past surface processes, including the role of water, through sedimentologic studies of the stratigraphic record of Mars. Many processes that operate at a planetary surface have the potential to create a record of sedimentary rocks. Sedimentary rocks can provide clues that allow past environmental conditions to be reconstructed. Therefore, the detection of sediment transport by water and wind in ancient sedimentary layers is important, because it provides insight into past climatic regimes and potential habitability.\nThe Mars Science Laboratory Curiosity rover was launched on Saturday, November 26, 2011 on-board an Atlas V-541 rocket from Cape Canaveral, Florida. The rover landed in Gale Crater on August 5, 2012. Curiosity\u2019s mission is to determine the planet\u2019s habitability and has been doing this using a suite of sophisticated instruments including cameras, spectrometers, environmental sensors, sample collection tools, and laboratory-quality geochemical instruments.\nCuriosity landed at the foot of Mt. Sharp \u2013 Gale Crater\u2019s central mound \u2013 near the end of an ancient alluvial fan that formed by sediments transported by streams from the crater rim. In the first year of its mission, Curiosity discovered fine-grained sedimentary rocks of basaltic composition that represent an ancient lake and preserve evidence of an environment that would have been suited to support a Martian biosphere founded on chemolithoautotrophy.  This aqueous environment was characterized by neutral pH, low salinity, and variable redox states of both iron and sulfur species.  C, H, N, O, S, and P were measured directly as key biogenic elements. The environment likely had a minimum duration of hundreds to tens of thousands of years, and could have existed for millions of years.  These results highlight the biological viability of fluvial-lacustrine environments in the post-Noachian history of Mars.", "page_name": "John P. Grotzinger", "page_id": "John%20P.%20Grotzinger", "heading": "Academic history", "sub_heading": "Academic history", "_id": "5000027319--0--0---1", "title": "Mars Science Laboratory \u2014 Curiosity"}
{"qas": [{"question": "How do we know the age of the Earth?", "answer": ""}, {"question": "What is the name of the award given out by the national academy of sciences to recognize?", "answer": "Charles Doolittle Walcott Medal", "ae_score": -0.29657403357539824, "qg_score": null}, {"question": "Which isotope of carbon is the largest known in earth history?", "answer": "carbonate", "ae_score": null, "qg_score": null}], "content": "Grotzinger has made major contributions to the fields of Geobiology and Paleontology.  Beginning in 1993, Grotzinger and his colleagues began a research program aimed at understanding the chronology of major biological and environmental events leading up to, and perhaps driving early Cambrian radiation of metazoans.  The so-called Cambrian explosion of biodiversity was shown to have been much more rapid than previously understood.  It also may have followed an extinction event of earlier organisms that pioneered and experimented with calcification. More recent research over the past decade has been based on understanding carbon and sulfur isotope ratios in carbonate sediments of Ediacaran age. This work proposed that vertical circulation of ocean water led to oxygenation of the deep ocean shortly before the end of the Proterozoic time, which may also have contributed to the rise in biodiversity in early Cambrian time.\nThe Shuram carbon isotopic excusion  - the largest known in Earth history - has been the subject of intensive research at Caltech.  Measurement of the carbon isotope ratios in ancient carbonate rocks provides the principal basis by which the fluxes of reduced and oxidized carbon are determined over the course of Earth\u2019s history. Globally distributed carbonate rocks of middle Ediacaran age (ca. 600-560 million years ago) record the largest carbon isotope excursion in Earth history, suggesting dramatic reorganization of Earth\u2019s carbon cycle. The Shuram Excursion closely precedes impressive evolutionary events including the rise of large metazoans and the origin of biomineralization in animals.\nCombining his expertise in sedimentology and geobiology, Grotzinger\u2019s research on stromatolites shows that they are vital tools in understanding the interactions between ancient microorganisms and their environment.  Stromatolites are attached, lithified sedimentary growth structures, accretionary away from a point or limited surface of initiation.  Though the accretion process is commonly regarded to result from the sediment trapping or precipitation-inducing activities of microbial mats, only rarely is evidence of this process preserved in Precambrian stromatolites.  Grotzinger\u2019s research has applied a process-based approach, oriented toward deconvolving the replacement textures of ancient stromatolites. The effects of diagenetic recrystallization first must be accounted for, followed by analysis of lamination textures and deduction of possible accretion mechanisms.  Accretion hypotheses can be tested using numerical simulations based on modern stromatolite growth processes.  Application of this approach has shown that stromatolites were originally formed largely through in situ precipitation of laminae during Archean and older Proterozoic times, but that younger Proterozoic stromatolites grew largely through the accretion of carbonate sediments, most likely through the physical process of microbial trapping and binding.  This trend most likely reflects long-term evolution of the earth\u2019s environment rather than microbial communities.\nIn 2007, Grotzinger received the Charles Doolittle Walcott Medal from the National Academy of Sciences", "page_name": "John P. Grotzinger", "page_id": "John%20P.%20Grotzinger", "heading": "Academic history", "sub_heading": "Co-evolution of Earth's early environment and biosphere", "_id": "5000027319--0--1---1", "title": "The Evolution of Stromatolites in the Deep Ocean"}
{"qas": [{"question": "Why are there so many different types of toilet paper?", "answer": ""}, {"question": "Serotonin reuptake inhibitors ( ssri ) are commonly used as?", "answer": "antidepressants", "ae_score": -0.8880108571060455, "qg_score": null}, {"question": "Serotonin reuptake inhibitors ( ssri ) are commonly used as?", "answer": "antidepressants", "ae_score": null, "qg_score": null}], "content": "Drugs in this class include:\n'''Most common:'''\n'''Other:'''\nSSRIs form a subclass of serotonin uptake inhibitors, which includes other non-selective inhibitors as well. The serotonergic serotonin-norepinephrine reuptake inhibitors and serotonin-norepinephrine-dopamine reuptake inhibitors are also commonly used as antidepressants.", "page_name": "Selective serotonin reuptake inhibitor", "page_id": "Selective%20serotonin%20reuptake%20inhibitor", "heading": "List of agents", "sub_heading": "List of agents", "_id": "5000027479--3---1---1", "title": "Serotonin Reuptake Inhibitors (SSRIs)"}
{"qas": [{"question": "Why do marshallers have to wear earplugs?", "answer": ""}, {"question": "What can cause hearing loss in marshallers?", "answer": "Excessive noise", "ae_score": -0.4118756172260663, "qg_score": null}, {"question": "What can cause hearing loss in marshallers?", "answer": "acoustic trauma", "ae_score": null, "qg_score": null}], "content": " Excessive noise can cause hearing loss in marshallers, either imperceptibly over years or after a one time acoustic trauma. In the United States noise limits at work are set by the Occupational Safety and Health Administration (OSHA).", "page_name": "Aircraft marshalling", "page_id": "Aircraft%20marshalling", "heading": "Noise exposure", "sub_heading": "Noise exposure", "_id": "5000028346--2---1---1", "title": "Noise Limits at Work"}
{"qas": [{"question": "Why is it that the city of Dallas is one of the most respected cities in the US?", "answer": ""}, {"question": "Who is the mayor of dallas dallas?", "answer": "Mike Rawlings", "ae_score": -0.19962780884154727, "qg_score": null}, {"question": "Who is the mayor of dallas dallas?", "answer": "Mike Rawlings", "ae_score": -0.19962780884154727, "qg_score": null}], "content": "Skinner was chosen by then Mayor Tom Leppert  in 2008 to become chairman of the City of Dallas Ethics Advisory Commission. Mayor Leppert worked closely with Chairman Skinner to bring strong ethical reform to the city of Dallas. Some of the items passed by the advisory commission included the requirement that lobbyists register with the city of Dallas, a limit to the amount of campaign contributions that came from developers, the disclosure of gifts to council members over $50, and two city council members were now required to \u201csecond\u201d major zoning cases certifying they had reviewed the details of the case before the matter could be voted on.\nMayor Leppert resigned as Dallas Mayor in 2011 in order to run for the Republican nomination of the U.S. Senate. Skinner continued to work with Mayor Pro Tem Dwayne Caraway  and the city council to prevent a weakening of the campaign contribution guidelines implemented under Mayor Leppert.  The chairman worked closely with the Mayor and council members to reverse a vote by the council that weakened campaign contribution laws.\nIn the fall of 2011, newly elected Mayor Mike Rawlings  asked Skinner to remain as chairman of the City of Dallas Ethics Commission  and work with Dallas City Councilman Jerry Allen  for a stronger culture of ethics within the city government \nSkinner has been supported in his work to strengthen ethics in city government by the Dallas Morning News editorial board.\nAs a result of Skinner and Councilman Jerry Allen's leadership, an Ethics and Diversity Office was created to address ethics issues for city employees. In May 2014, an ethics officer was hired by the City of Dallas to work closely with the City Manager on ethical education and reform. Since that time, the Ethics Office has completed training for over 12,000 city employees using a two-hour training designed by nationally recognized Ethics Consultant Firm, Navigant.\nSkinner began anew in 2013 working with Dallas Mayor Mike Rawlings to push for tighter ethical reform that included putting guidelines over the Mayor and City Councils office accounts, proper protocol on town hall meetings, guidelines on political activities for employees, and allowing the EAC (Ethics Advisory Commission) to begin working on the City of Dallas Election (Chapter 15A) guidelines for office holders and candidates.\nAs a result of Skinner\u2019s work with Councilman Jerry Allen, and the City of Dallas Ethics Office, the City of Dallas was nominated for the Greater Dallas Business Ethics Award.\nIn 2015, Mayor Mike Rawlings tapped Skinner to push through stronger ethical reforms for the City of Dallas. Rawlings highlighted his stance on stronger ethics as the keynote speaker of the Greater Dallas Business Ethics Award ceremony.", "page_name": "Randy H. Skinner", "page_id": "Randy%20H.%20Skinner", "heading": "Leadership on Ethical Reform for the City of Dallas", "sub_heading": "Leadership on Ethical Reform for the City of Dallas", "_id": "5000034130--11---1---1", "title": "The City of Dallas\u2019s Stronger Ethics"}
{"qas": [{"question": "What is the purpose of the Ethics Center at SMU?", "answer": ""}, {"question": "What is the focus of the maguire center for ethics?", "answer": "applied ethics", "ae_score": -1.7764250480002475, "qg_score": null}, {"question": "What is the focus of the maguire center for ethics?", "answer": "applied ethics", "ae_score": -1.7764250480002475, "qg_score": null}], "content": "The center seeks to recognize, honor, and model ethical behavior; provide moral reflection on the contemporary issues; and celebrate ethics that reflect SMU's fundamental goals throughout the campus and in the Greater Dallas Community. It focuses on interdisciplinary approaches to ethics and moral problems; applied ethics prioritized above theoretical ethics; academic excellence and quality; and reasoned and researched positions that illuminate prevailing ethical issues. ", "page_name": "Maguire Center for Ethics", "page_id": "Maguire%20Center%20for%20Ethics", "heading": "Mission statement", "sub_heading": "Mission statement", "_id": "5000034774--0---1---1", "title": "Ethics at SMU"}
{"qas": [{"question": "The Dodd-Frank Wall Street Reform and Consumer Protection Act?", "answer": ""}, {"question": "When did the us subprime mortgage crisis start?", "answer": "2008", "ae_score": -0.5005897830503092, "qg_score": null}, {"question": "What type of securities were lost as a result of the mortgage choice act of 2013?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "The U.S. subprime mortgage crisis was a nationwide banking emergency that triggered the recession of 2008, through subprime mortgage delinquencies and foreclosures, resulting in the devaluation of the attendant securities.\nThese mortgage-backed securities (MBS) and collateralized debt obligations (CDO) initially offered attractive rates of return due to the higher interest rates on the mortgages; however, the lower credit quality ultimately caused massive defaults. While elements of the crisis first became more visible during 2007, several major financial institutions collapsed in September 2008, with significant disruption in the flow of credit to businesses and consumers and the onset of a severe global recession.\nThere were many causes of the crisis, with commentators assigning different levels of blame to financial institutions, regulators, credit agencies, government housing policies, and consumers, among others. A proximate cause was the rise in subprime lending. The percentage of lower-quality subprime mortgages originated during a given year rose from the historical 8% or lower range to approximately 20% from 2004 to 2006, with much higher ratios in some parts of the U.S. A high percentage of these subprime mortgages, over 80% in 2006 for example, were adjustable-rate mortgages. These two changes were part of a broader trend of lowered lending standards and higher-risk mortgage products. Further, U.S. households had become increasingly indebted, with the ratio of debt to disposable personal income rising from 77% in 1990 to 127% at the end of 2007, much of this increase mortgage-related.\nWhen U.S. home prices declined steeply after peaking in mid-2006, it became more difficult for borrowers to refinance their loans. As adjustable-rate mortgages began to reset at higher interest rates (causing higher monthly payments), mortgage delinquencies soared. Securities backed with mortgages, including subprime mortgages, widely held by financial firms globally, lost most of their value. Global investors also drastically reduced purchases of mortgage-backed debt and other securities as part of a decline in the capacity and willingness of the private financial system to support lending. Concerns about the soundness of U.S. credit and financial markets led to tightening credit around the world and slowing economic growth in the U.S. and Europe.\nThe Dodd\u2013Frank Wall Street Reform and Consumer Protection Act was passed in 2010 was a legislative response to the financial crisis of 2007\u201308 (which the subprime mortgage crisis was a major part of) and the subsequent Great Recession. Dodd-Frank created the Consumer Financial Protection Bureau (CFPB), an independent agency of the United States government responsible for consumer protection in the financial sector. Its jurisdiction includes banks, credit unions, securities firms, payday lenders, mortgage-servicing operations, foreclosure relief services, debt collectors and other financial companies operating in the United States.", "page_name": "Mortgage Choice Act of 2013", "page_id": "Mortgage%20Choice%20Act%20of%202013", "heading": "Background", "sub_heading": "Background", "_id": "5000036149--0---1---1", "title": "The U.S. Subprime Mortgage Crisis"}
{"qas": [{"question": "What is the difference between ADD and ADHD?", "answer": ""}, {"question": "What syndrome does naois\u00e9 o'reilly work with?", "answer": "Asperger syndrome", "ae_score": -1.331551349761039, "qg_score": null}, {"question": "What type of attention deficit disorder does naois\u00e9 o'Reilly have?", "answer": "hyperactivity", "ae_score": null, "qg_score": null}], "content": "Attention deficit hyperactivity disorder is an area she has been described as an expert in and supporting people with Asperger syndrome, dyslexia, developmental coordination disorder, dyscalculia, dysgraphia, hearing impairments, expression disorders and depression.", "page_name": "Naois\u00e9 O'Reilly", "page_id": "Naois%C3%A9%20O'Reilly", "heading": "Learning difficulties", "sub_heading": "Learning difficulties", "_id": "5000037725--2---1---1", "title": "Naois\u00e9 O'Reilly | Learning difficulties"}
{"qas": [{"question": "Why is it that when a person has a stapedotomy, they don't get headaches or tinnitus?", "answer": ""}, {"question": "What is the medical term for a surgical procedure?", "answer": "stapedectomy", "ae_score": -0.016508442737921406, "qg_score": null}, {"question": "What are the effects of a stapedectomy?", "answer": "sensorineural hearing loss", "ae_score": null, "qg_score": null}], "content": "Complications of stapedectomy:\nWhen a stapedectomy is done in a middle ear with a congenitally fixed footplate, the results may be excellent but the risk of hearing damage is greater than when the stapes bone is removed and replaced (for otosclerosis). This is primarily due to the risk of additional anomalies being present in the congenitally abnormal ear. If high pressure within the fluid compartment that lies just below the stapes footplate exists, then a perilymphatic gusher may occur when the stapes is removed. Even without immediate complications during surgery, there is always concern of a perilymph fistula forming postoperatively.\nIn 1995, Glasscock et al. published a 25-year single-centre review of over 900 patients who underwent stapedectomy and stapedotomy and found complications rates as follows:  reparative granuloma 1.3%, tympanic membrane perforation 1.0%, total sensorineural hearing loss 0.6%, partial sensorineural hearing loss 0.3%, and vertigo 0.3%.  In this series, there was no incidence of facial nerve paralysis or tinnitus.", "page_name": "Stapedectomy", "page_id": "Stapedectomy", "heading": "Complications", "sub_heading": "Complications", "_id": "5000042317--2---1---1", "title": "Complications of Stapedectomy"}
{"qas": [{"question": "How do supercapacitors work?", "answer": ""}, {"question": "What is the voltage of a 40-f supercapacitor?", "answer": "3.5 V", "ae_score": -0.7189020461706062, "qg_score": null}, {"question": "What property of a 40-f supercapacitor can be improved by adding carbon?", "answer": "energy density", "ae_score": null, "qg_score": null}], "content": "MIT Research Laboratory of Electronics uses nanotubes to improve supercapacitors. The activated charcoal used in conventional ultracapacitors has many small hollow spaces of various size, which create together a large surface to store electric charge. But as charge is quantized into elementary charges, i.e. electrons, and each such elementary charge needs a minimum space, a significant fraction of the electrode surface is not available for storage because the hollow spaces are not compatible with the charge's requirements. With a nanotube electrode the spaces may be tailored to size\u2014few too large or too small\u2014and consequently the capacity should be increased considerably.\nA 40-F supercapacitor with a maximum voltage of 3.5 V that employed forest-grown SWNTs that are binder- and additive-free achieved an energy density of 15.6 Wh kg and a power density of 37 kW kg. CNTs can be bound to the charge plates of capacitors to dramatically increase the surface area and therefore energy density.", "page_name": "Potential applications of carbon nanotubes", "page_id": "Potential%20applications%20of%20carbon%20nanotubes", "heading": "Energy storage", "sub_heading": "Energy storage", "_id": "5000046930--6--0---1", "title": "Nanotubes for Supercapacitors"}
{"qas": [{"question": "Why are lead-acid batteries so much better than regular batteries?", "answer": ""}, {"question": "Who makes the swcnt used in lead acid batteries?", "answer": "OCSiAl", "ae_score": -0.4509606907678889, "qg_score": null}, {"question": "Graphite is most widely used as anode material for what type of battery?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Carbon nanotubes' (CNTs) exciting electronic properties have shown promise in the field of batteries, where typically they are being experimented as a new electrode material, particularly the anode for lithium ion batteries. This is due to the fact that the anode requires a relatively high reversible capacity at a potential close to metallic lithium, and a moderate irreversible capacity, observed thus far only by graphite-based composites, such as CNTs. They have shown to greatly improve capacity and cyclability of lithium-ion batteries, as well as the capability to be very effective buffering components, alleviating the degradation of the batteries that is typically due to repeated charging and discharging. Further, electronic transport in the anode can be greatly improved using highly metallic CNTs.\nMore specifically, CNTs have shown reversible capacities from 300 to 600 mAhg, with some treatments to them showing these numbers rise to up to 1000 mAhg. Meanwhile, graphite, which is most widely used as an anode material for these lithium batteries, has shown capacities of only 320 mAhg. By creating composites out of the CNTs, scientists see much potential in taking advantage of these exceptional capacities, as well as their excellent mechanical strength, conductivities, and low densities.\nMWNTs are used in lithium ion batteries. In these batteries, small amounts of MWNT powder are blended with active materials and a polymer binder, such as 1 wt % CNT loading in  cathodes and graphite anodes. CNTs provide increased electrical connectivity and mechanical integrity, which enhances rate capability and cycle life.\nA paper battery is a battery engineered to use a paper-thin sheet of cellulose (which is the major constituent of regular paper, among other things) infused with aligned carbon nanotubes. The potential for these devices is great, as they may be manufactured via a roll-to-roll process, which would make it very low-cost, and they would be lightweight, flexible, and thin. In order to productively use paper electronics (or any thin electronic devices), the power source must be equally thin, thus indicating the need for paper batteries. Recently, it has been shown that surfaces coated with CNTs can be used to replace heavy metals in batteries. More recently, functional paper batteries have been demonstrated, where a lithium-ion battery is integrated on a single sheet of paper through a lamination process as a composite with Li4Ti5O12 (LTO) or LiCoO2 (LCO). The paper substrate would function well as the separator for the battery, where the CNT films function as the current collectors for both the anode ''and'' the cathode. These rechargeable energy devices show potential in RFID tags, functional packaging, or new disposable electronic applications.\nImprovements have also been shown in lead-acid batteries, based on research performed by Bar-Ilan University using high quality SWCNT manufactured by OCSiAl. The study demonstrated an increase in the lifetime of lead acid batteries by 4.5 times and a capacity increase of 30% on average and up to 200% at high discharge rates.", "page_name": "Potential applications of carbon nanotubes", "page_id": "Potential%20applications%20of%20carbon%20nanotubes", "heading": "Energy storage", "sub_heading": "Batteries", "_id": "5000046930--6--1---1", "title": "Carbon Nanotubes: The Future of Battery Technology"}
{"qas": [{"question": "What is a single wall tire and how does it work?", "answer": ""}, {"question": "When was the first carbon nanotube demonstrated?", "answer": "2007", "ae_score": -0.20405028226036095, "qg_score": null}, {"question": "Carbon nanotube springs can store elastic potential energy at ten times the density of what?", "answer": "lithium", "ae_score": null, "qg_score": null}], "content": "Carbon nanotubes have been implemented in nanoelectromechanical systems, including mechanical memory elements (NRAM being developed by Nantero Inc.) and nanoscale electric motors (see Nanomotor or Nanotube nanomotor).\nCarboxyl-modified single-walled carbon nanotubes (so called zig-zag, armchair type) can act as sensors of atoms and ions of alkali metals Na, Li, K. In May 2005, Nanomix Inc. placed on the market a hydrogen sensor that integrated carbon nanotubes on a silicon platform. Since then, Nanomix has been patenting many such sensor applications, such as in the field of carbon dioxide, nitrous oxide, glucose, DNA detection, etc. End of 2014, Tulane University researchers have tested Nanomix's fast and fully automated point of care diagnostic system in Sierra Leone to help for rapid testing for Ebola. Nanomix announced that a product could be launched within three to six months.\nEikos Inc of Franklin, Massachusetts and Unidym Inc. of Silicon Valley, California are developing transparent, electrically conductive films of carbon nanotubes to replace indium tin oxide (ITO). Carbon nanotube films are substantially more mechanically robust than ITO films, making them ideal for high-reliability touchscreens and flexible displays. Printable water-based inks of carbon nanotubes are desired to enable the production of these films to replace ITO. Nanotube films show promise for use in displays for computers, cell phones, PDAs, and ATMs.\nA nanoradio, a radio receiver consisting of a single nanotube, was demonstrated in 2007.\nA flywheel made of carbon nanotubes could be spun at extremely high velocity on a floating magnetic axis in a vacuum, and potentially store energy at a density approaching that of conventional fossil fuels. Since energy can be added to and removed from flywheels very efficiently in the form of electricity, this might offer a way of storing electricity, making the electrical grid more efficient and variable power suppliers (like wind turbines) more useful in meeting energy needs. The practicality of this depends heavily upon the cost of making massive, unbroken nanotube structures, and their failure rate under stress.\nCarbon nanotube springs have the potential to indefinitely store elastic potential energy at ten times the density of lithium-ion batteries with flexible charge and discharge rates and extremely high cycling durability.\nUltra-short SWNTs (US-tubes) have been used as nanoscaled capsules for delivering MRI contrast agents in vivo.\nCarbon nanotubes provide a certain potential for metal-free catalysis of inorganic and organic reactions. For instance, oxygen groups attached to the surface of carbon nanotubes have the potential to catalyze oxidative dehydrogenations or selective oxidations. Nitrogen-doped carbon nanotubes may replace platinum catalysts used to reduce oxygen in fuel cells. A forest of vertically aligned nanotubes can reduce oxygen in alkaline solution more effectively than platinum, which has been used in such applications since the 1960s. Here, the nanotubes have the added benefit of not being subject to carbon monoxide poisoning.\nWake Forest University engineers are using multiwalled carbon nanotubes to enhance the brightness of field-induced polymer electroluminescent technology, potentially offering a step forward in the search for safe, pleasing, high-efficiency lighting. In this technology, moldable polymer matrix emits light when exposed to an electric current. It could eventually yield high-efficiency lights without the mercury vapor of compact fluorescent lamps or the bluish tint of some fluorescents and LEDs, which has been linked with circadian rhythm disruption.\n''Candida albicans'' has been used in combination with carbon nanotubes (CNT) to produce stable electrically conductive bio-nano-composite tissue materials that have been used as temperature sensing elements\nThe SWNT production company OCSiAl developed a series of masterbatches for industrial use of single-wall CNTs in multiple types of rubber blends and tires, with initial trials showing increases in hardness, viscosity, tensile strain resistance and resistance to abrasion while reducing elongation and compression In tires the three primary characteristics of durability, fuel efficiency and traction were improved using SWNTs. The development of rubber masterbatches built on earlier work by the Japanese National Institute of Advanced Industrial Science & Technology showing rubber to be a viable candidate for improvement with SWNTs.\nIntroducing MWNTs to polymers can improve  flame retardancy and retard thermal degradation of polymer. The results confirmed that combination of MWNTs and ammonium polyphosphates show a synergistic effect for improving flame retardancy.", "page_name": "Potential applications of carbon nanotubes", "page_id": "Potential%20applications%20of%20carbon%20nanotubes", "heading": "Other applications", "sub_heading": "Other applications", "_id": "5000046930--10---1---1", "title": "Carbon Nanotubes \u2014 The Future of Nanoelectromechanical Technology"}
{"qas": [{"question": "What is the difference between a \"normal\" and \"bad\" person?", "answer": ""}, {"question": "How many conjugacy classes are there in the symmetry group?", "answer": "two", "ae_score": null, "qg_score": null}, {"question": "How many conjugacy classes are there in the symmetry group?", "answer": "two", "ae_score": null, "qg_score": null}], "content": "As in the symmetric group, the conjugacy classes in A consist of elements with the same cycle shape. However, if the cycle shape consists only of cycles of odd length with no two cycles the same length, where cycles of length one are included in the cycle type, then there are exactly two conjugacy classes for this cycle shape .\nExamples:", "page_name": "Alternating group", "page_id": "Alternating%20group", "heading": "Conjugacy classes", "sub_heading": "Conjugacy classes", "_id": "5000049635--1---1---1", "title": "Conjugacy Classes in A"}
{"qas": [{"question": "Why are there so many cases of microscopic colitis?", "answer": ""}, {"question": "What percentage of patients with collagenous colitis have bile acid diarrhea?", "answer": "41%", "ae_score": -0.4909687983074341, "qg_score": null}, {"question": "What type of drugs are used to treat microscopic colitis?", "answer": "selective serotonin reuptake inhibitors", "ae_score": null, "qg_score": null}], "content": "A higher incidence of autoimmune diseases, for example arthritis, Sj\u00f6gren's syndrome, thyroid disorders, and coeliac disease, has been reported in patients with microscopic colitis. Associations with various drugs have been found, especially proton pump inhibitors, H blockers, selective serotonin reuptake inhibitors (SSRIs), and non-steroidal anti-inflammatory drugs (NSAIDs). Bile acid diarrhea is found in 41% of patients with collagenous colitis and 29% with lymphocytic colitis. Additionally, smoking has been identified as a significant risk factor of microscopic colitis.", "page_name": "Microscopic colitis", "page_id": "Microscopic%20colitis", "heading": "Associated conditions", "sub_heading": "Associated conditions", "_id": "5000052293--2---1---1", "title": "Microscopic Colitis Risk Factors"}
{"qas": [{"question": "What is the difference between a rechargeable and a non rechargeable battery?", "answer": ""}, {"question": "What is the reactant in a zinc air battery?", "answer": "Zinc granules", "ae_score": -0.5003143515792007, "qg_score": null}, {"question": "What type of cathode is used in zinc air battery?", "answer": "cathode", "ae_score": null, "qg_score": null}], "content": "Large zinc\u2013air batteries, with capacities up to 2,000 ampere\u2013hours per cell, are used to power navigation instruments and marker lights, oceanographic experiments and railway signals.\nPrimary cells are made in button format to about 1 Ah. Prismatic shapes for portable devices are manufactured with capacities between 5 and 30 Ah. Hybrid cell cathodes include manganese dioxide to allow high peak currents.\nButton cells are highly effective, but it is difficult to extend the same construction to larger sizes due to air diffusion performance, heat dissipation, and leakage problems. Prismatic and cylindrical cell designs address these problems. Stacking prismatic cells requires air channels in the battery and may require a fan to force air through the stack.\nRechargeable zinc\u2013air cells require zinc precipitation from the water-based electrolyte to be closely controlled. Challenges include dendrite formation, non-uniform zinc dissolution and limited solubility in electrolytes. Electrically reversing the reaction at a bi-functional air cathode, to liberate oxygen from discharge reaction products, is difficult; membranes tested to date have low overall efficiency. Charging voltage is much higher than discharge voltage, producing cycle energy efficiency as low as 50%. Providing charge and discharge functions by separate uni-functional cathodes, increases cell size, weight and complexity. A satisfactory electrically recharged system potentially offers low material cost and high specific energy.  As of 2014, only one company has commercial units for sale, as described in a Dept. of Energy produced video at the ARPA-e Energy Innovation Summit in 2013.  Fluidic Energy has apparently covered hundreds of thousands of outages in Asia at distributed critical load sites.  And at least one firm claims to be in field tests for grid-scale backup applications.\nRechargeable systems may mechanically replace the anode and electrolyte, essentially operating as a refurbishable primary cell, or may use zinc powder or other methods to replenish the reactants. Mechanically recharged systems were investigated for military electronics uses in the 1960s because of the high energy density and easy recharging. However, primary lithium batteries offered higher discharge rates and easier handling.\nMechanical recharging systems have been researched for decades for use in electric vehicles. Some approaches use a large zinc\u2013air battery to maintain charge on a high discharge\u2013rate battery used for peak loads during acceleration. Zinc granules serve as the reactant. Vehicles recharge via exchanging used electrolyte and depleted zinc for fresh reactants at a service station.\nThe term zinc\u2013air fuel cell usually refers to a zinc\u2013air battery in which zinc metal is added and zinc oxide is removed continuously. Zinc electrolyte paste or pellets are pushed into a chamber, and waste zinc oxide is pumped into a waste tank or bladder inside the fuel tank. Fresh zinc paste or pellets are taken from the fuel tank. The zinc oxide waste is pumped out at a refueling station for recycling. Alternatively, this term may refer to an electrochemical system in which zinc is a co-reactant assisting the reformation of hydrocarbons at the anode of a fuel cell.", "page_name": "Zinc\u2013air battery", "page_id": "Zinc%E2%80%93air%20battery", "heading": "Cell types", "sub_heading": "Cell types", "_id": "5000054665--5---1---1", "title": "Rechargeable Batteries and Fuel Cells."}
{"qas": [{"question": "What is the difference between rationalism and agency theory?", "answer": ""}, {"question": "What ideology promoted finance as a component of economics?", "answer": "neoliberalism", "ae_score": -0.7431782281998355, "qg_score": null}, {"question": "What ideology promoted finance as a component of economics?", "answer": "neoliberalism", "ae_score": -0.7431782281998355, "qg_score": null}], "content": "Fundamentally finance is a social science discipline. The discipline borders behavioral economics, sociology, economics, accounting and management. It concerns technical issues such as the mix of debt and equity, dividend policy, the evaluation of alternative investment projects, options, futures, swaps, and other derivatives, portfolio diversification and many others. It is often mistaken by the people to be a discipline free from ethical burdens. The 2008 financial crisis caused critics to challenge the ethics of the executives in charge of U.S. and European financial institutions and financial regulatory bodies. Finance ethics is overlooked for another reason\u2014issues in finance are often addressed as matters of law rather than ethics.\nAristotle said, \"the end and purpose of the polis is the good life\". Adam Smith characterized the good life in terms of material goods and intellectual and moral excellences of character. Smith in his ''The Wealth of Nations'' commented, \"All for ourselves, and nothing for other people, seems, in every age of the world, to have been the vile maxim of the masters of mankind.\" However, a section of economists influenced by the ideology of neoliberalism, interpreted the objective of economics to be maximization of economic growth through accelerated consumption and production of goods and services. Neoliberal ideology promoted finance from its position as a component of economics to its core. Proponents of the ideology hold that unrestricted financial flows, if redeemed from the shackles of \"financial repressions\", best help impoverished nations to grow. The theory holds that open financial systems accelerate economic growth by encouraging foreign capital in\ufb02ows, thereby enabling higher levels of savings, investment, employment, productivity and \"welfare\", along with containing corruption. Neoliberals recommended that governments open their financial systems to the global market with minimal regulation over capital flows. The recommendations however, met with criticisms from various schools of ethical philosophy. Some pragmatic ethicists, found these claims to unfalsifiable and a priori, although neither of these makes the recommendations false or unethical per se. Raising economic growth to the highest value necessarily means that welfare is subordinate, although advocates dispute this saying that economic growth provides more welfare than known alternatives. Since history shows that neither regulated nor unregulated firms always behave ethically, neither regime offers an ethical panacea.\nNeoliberal recommendations to developing countries to unconditionally open up their economies to transnational finance corporations was fiercely contested by some ethicists. The claim that deregulation and the opening up of economies would reduce corruption was also contested.\nDobson observes, \"a rational agent is simply one who pursues personal material advantage ad infinitum. In essence, to be rational in finance is to be individualistic, materialistic, and competitive. Business is a game played by individuals, as with all games the object is to win, and winning is measured in terms solely of material wealth. Within the discipline this rationality concept is never questioned, and has indeed become the theory-of-the-firm's sine qua non\". Financial ethics is in this view a mathematical function of shareholder wealth. Such simplifying assumptions were once necessary for the construction of mathematically robust models. However signalling theory and agency theory extended the paradigm to greater realism.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Functional business areas", "_id": "5000054892--3--0---1", "title": "The Ethics of Finance"}
{"qas": [{"question": "What is the difference between finance and accounting?", "answer": ""}, {"question": "Which us oil company was found guilty of accounting fraud?", "answer": "Enron", "ae_score": null, "qg_score": null}, {"question": "What type of fraud is considered to be a violation of business ethics?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "Fairness in trading practices, trading conditions, financial contracting, sales practices, consultancy services, tax payments, internal audit, external audit and executive compensation also fall under the umbrella of finance and accounting. Particular corporate ethical/legal abuses include: creative accounting, earnings management, misleading financial analysis, insider trading, securities fraud, bribery/kickbacks and facilitation payments. Outside of corporations, bucket shops and forex scams are criminal manipulations of financial markets. Cases include accounting scandals, Enron, WorldCom and Satyam.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Other issues", "_id": "5000054892--3--1---1", "title": "Corporate Ethics & Legal Abuse"}
{"qas": [{"question": "How is it legal for an employer to pass over an employee for a promotion?", "answer": ""}, {"question": "What must an employer consider when designing their workplace?", "answer": "workplace safety", "ae_score": -0.2061002381793113, "qg_score": null}, {"question": "What must an employer consider when designing their workplace?", "answer": "workplace safety", "ae_score": -0.2061002381793113, "qg_score": null}], "content": "Human resource management occupies the sphere of activity of recruitment selection, orientation, performance appraisal, training and development, industrial relations and health and safety issues. Business Ethicists differ in their orientation towards labour ethics. Some assess human resource policies according to whether they support an egalitarian workplace and the dignity of labor.\nIssues including employment itself, privacy, compensation in accord with comparable worth, collective bargaining (and/or its opposite)  can be seen either as inalienable rights or as negotiable.Discrimination by age (preferring the young or the old), gender/sexual harassment, race, religion, disability, weight and attractiveness. A common approach to remedying discrimination is affirmative action.\nOnce hired, employees have the right to occasional cost of living increases, as well as raises based on merit.  Promotions, however, are not a right, and there are often fewer openings than qualified applicants.  It may seem unfair if an employee who has been with a company longer is passed over for a promotion, but it is not unethical.  It is only unethical if the employer did not give the employee proper consideration or used improper criteria for the promotion.\nPotential employees have ethical obligations to employers, involving intellectual property protection and whistle-blowing.\nEmployers must consider workplace safety, which may involve modifying the workplace, or providing appropriate training or hazard disclosure.\nLarger economic issues such as immigration, trade policy, globalization and trade unionism affect workplaces and have an ethical dimension, but are often beyond the purview of individual companies.<ref name=pin/>\nUnions for example, may push employers to establish due process for workers, but may also cost jobs by demanding unsustainable compensation and work rules.\nUnionized workplaces may confront union busting and strike breaking and face the ethical implications of work rules that advantage some workers over others.\nAmong the many people management strategies that companies employ are a \"soft\" approach that regards employees as a source of creative energy and participants in workplace decision making, a \"hard\" version explicitly focused on control and Theory Z that emphasizes philosophy, culture and consensus. None ensure ethical behavior. Some studies claim that sustainable success requires a humanely treated and satisfied workforce.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Human resource management", "_id": "5000054892--3--2---1", "title": "Ethics of Human Resources Management"}
{"qas": [{"question": "How did marketing ethics come of age?", "answer": ""}, {"question": "What is an example of a business decision that can influence a person's perceptions of?", "answer": "marketing", "ae_score": -0.4841454782489057, "qg_score": null}, {"question": "Deontology, consequentialism, pragmatism and relativism are examples of what?", "answer": "virtue ethics", "ae_score": null, "qg_score": null}], "content": "Marketing ethics came of age only as late as 1990s. Marketing ethics was approached from ethical perspectives of virtue or virtue ethics, deontology, consequentialism, pragmatism and relativism.\nEthics in marketing deals with the principles, values and/or ideals by which marketers (and marketing institutions) ought to act. Marketing ethics is also contested terrain, beyond the previously described issue of potential conflicts between profitability and other concerns.Ethical marketing issues include marketing redundant or dangerous products/services transparency about environmental risks, transparency about product ingredients such as genetically modified organisms possible health risks, financial risks, security risks, etc., respect for consumer privacy and autonomy, advertising truthfulness and fairness in pricing & distribution.\nAccording to Borgerson, and Schroeder (2008), marketing can influence individuals' perceptions of and interactions with other people, implying an ethical responsibility to avoid distorting those perceptions and interactions.\nMarketing ethics involves pricing practices, including illegal actions such as price fixing and legal actions including price discrimination and price skimming. Certain promotional activities have drawn fire, including  greenwashing, bait and switch, shilling, viral marketing, spam (electronic), pyramid schemes and multi-level marketing. Advertising has raised objections about attack ads, subliminal messages, sex in advertising and marketing in schools.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Sales and marketing", "_id": "5000054892--3--3---1", "title": "Marketing Ethics \u2014 A Review"}
{"qas": [{"question": "What is business ethics?", "answer": ""}, {"question": "What has been attacked for violating the rights of both humans and animals?", "answer": "Product testing protocols", "ae_score": -1.085324064528508, "qg_score": null}, {"question": "What has been attacked for violating the rights of both humans and animals?", "answer": "Product testing protocols", "ae_score": -1.085324064528508, "qg_score": null}], "content": "This area of business ethics usually deals with the duties of a company to ensure that products and production processes do not needlessly cause harm. Since few goods and services can be produced and consumed with zero risk, determining the ethical course can be problematic. In some case consumers demand products that harm them, such as tobacco products. Production may have environmental impacts, including pollution, habitat destruction and urban sprawl. The downstream effects of technologies nuclear power, genetically modified food and mobile phones may not be well understood. While the precautionary principle may prohibit introducing new technology whose consequences are not fully understood, that principle would have prohibited most new technology introduced since the industrial revolution. Product testing protocols have been attacked for violating the rights of both humans and animals.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Production", "_id": "5000054892--3--4---1", "title": "Business Ethics \u2014 Business Ethics"}
{"qas": [{"question": "What is the difference between a property rights and a Custodian of a property?", "answer": ""}, {"question": "What is the latin word for property?", "answer": "proprius", "ae_score": -0.23743813698191296, "qg_score": null}, {"question": "What is the latin word for property?", "answer": "proprius", "ae_score": -0.23743813698191296, "qg_score": null}], "content": "The etymological root of property is  the Latin 'proprius' which refers to 'nature', 'quality', 'one's own', 'special characteristic', 'proper', 'intrinsic', 'inherent', 'regular', 'normal', 'genuine', 'thorough, complete, perfect' etc. The word property is value loaded and associated with the personal qualities of propriety and respectability, also implies questions relating to ownership. A 'proper' person owns and is true to herself or himself, and is thus genuine, perfect and pure.\nModern discourse on property emerged by the turn of 17th century within theological discussions of that time. For instance, John Locke justified property rights saying that God had made \"the earth, and all inferior creatures, [in] common to all men\".\nIn 1802 Utilitarian Jeremy Bentham stated, \"property and law are born together and die together\".\nOne argument for property ownership is that it enhances individual liberty by extending the line of non-interference by the state or others around the person. Seen from this perspective, property right is absolute and property has a special and distinctive character that precedes its legal protection. Blackstone conceptualized property as the \"sole and despotic dominion which one man claims and exercises over the external things of the world, in total exclusion of the right of any other individual in the universe\".\nDuring the seventeenth and eighteenth centuries, slavery spread to European colonies including America, where colonial legislatures defined the legal status of slaves as a form of property. During this time settlers began the centuries-long process of dispossessing the natives of America of millions of acres of land. Ironically, the natives lost about 200000 sqmi of land in the Louisiana Territory under the leadership of Thomas Jefferson, who championed property rights.\nCombined with theological justification, property was taken to be essentially natural ordained by God. Property, which later gained meaning as ownership and appeared natural to Locke, Jefferson and to many of the 18th and 19th century intellectuals as land, labour or idea and property right over slaves had the same theological and essentialized justification It was even held that the property in slaves was a sacred right. Wiecek noted, \"slavery was more clearly and explicitly established under the Constitution as it had been under the Articles\". Accordingly, US Supreme Court Chief Justice Roger B. Taney in his 1857 judgment stated, \"The right of property in a slave is distinctly and expressly affirmed in the Constitution\".\nNeoliberals hold that private property rights are a non-negotiable natural right. Davies counters with \"property is no different from other legal categories in that it is simply a consequence of the significance attached by law to the relationships between legal persons.\" Singer claims, \"Property is a form of power, and the distribution of power is a political problem of the highest order\". Rose finds, \"'Property' is only an effect, a construction, of relationships between people, meaning that its objective character is contestable. Persons and things, are 'constituted' or 'fabricated' by legal and other normative techniques.\". Singer observes, \"A private property regime is not, after all, a Hobbesian state of nature; it requires a working legal system that can define, allocate, and enforce property rights.\" Davis claims that common law theory generally favors the view that \"property is not essentially a 'right to a thing', but rather a separable bundle of rights subsisting between persons which may vary according to the context and the object which is at stake\".\nIn common parlance property rights involve a 'bundle of rights' including occupancy, use and enjoyment, and the right to sell, devise, give, or lease all or part of these rights. Custodians of property have obligations as well as rights.  Michelman writes, \"A property regime thus depends on a great deal of cooperation, trustworthiness, and self-restraint among the people who enjoy it.\"\nMenon claims that the autonomous individual, responsible for his/her own existence is a cultural construct moulded by Western culture rather than the truth about the human condition. Penner views property as an \"illusion\"\u2014a \"normative phantasm\" without substance.\nIn the neoliberal literature, property is part of the private side of a public/private dichotomy and acts a counterweight to state power. Davies counters that \"any space may be subject to plural meanings or appropriations which do not necessarily come into conflict\".\nPrivate property has never been a universal doctrine, although since the end of the Cold War is it has become nearly so. Some societies, e.g., Native American bands, held land, if not all property, in common. When groups came into conflict, the victor often appropriated the loser's property. The rights paradigm tended to stabilize the distribution of property holdings on the presumption that title had been lawfully acquired.\nProperty does not exist in isolation, and so property rights too. Bryan claimed that property rights describe relations among people and not just relations between people and things Singer holds that the idea that owners have no legal obligations to others wrongly supposes that property rights hardly ever conflict with other legally protected interests. Singer continues implying that legal realists \"did not take the character and structure of social relations as an important independent factor in choosing the rules that govern market life\". Ethics of property rights begins with recognizing the vacuous nature of the notion of property.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Property", "_id": "5000054892--3--5---1", "title": "The Ethics of Property Rights."}
{"qas": [{"question": "What is the difference between a knowledge economy and an economy of abundance?", "answer": ""}, {"question": "Who argued that government does not typically enforce monopolies for producers of other goods?", "answer": "Boldrin", "ae_score": null, "qg_score": null}, {"question": "Who argued that government does not typically enforce monopolies for producers of other goods?", "answer": "Boldrin", "ae_score": null, "qg_score": null}], "content": "Intellectual property (IP) encompasses expressions of ideas, thoughts, codes and information. \"Intellectual property rights\" (IPR) treat IP as a kind of real property, subject to analogous protections, rather than as a reproducible good or service. Boldrin and Levine argue that \"government does not ordinarily enforce monopolies for producers of other goods. This is because it is widely recognized that monopoly creates many social costs. Intellectual monopoly is no different in this respect. The question we address is whether it also creates social benefits commensurate with these social costs.\"\nInternational standards relating to Intellectual Property Rights are enforced through Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS). In the US, IP other than copyrights is regulated by the United States Patent and Trademark Office.\nThe US Constitution included the power to protect intellectual property, empowering the Federal government \"''to promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries''\". Boldrin and Levine see no value in such state-enforced monopolies stating, \"we ordinarily think of innovative monopoly as an oxymoron. Further they comment, 'intellectual property' \"is not like ordinary property at all, but constitutes a government grant of a costly and dangerous private monopoly over ideas. We show through theory and example that intellectual monopoly is not necessary for innovation and as a practical matter is damaging to growth, prosperity, and liberty\" .<ref name=steel/> Steelman defends patent monopolies, writing, \"Consider prescription drugs, for instance. Such drugs have benefited millions of people, improving or extending their lives. Patent protection enables drug companies to recoup their development costs because for a specific period of time they have the sole right to manufacture and distribute the products they have invented.\" The court cases by 39 pharmaceutical companies against South Africa's 1997 Medicines and Related Substances Control Amendment Act, which intended to provide affordable HIV medicines has been cited as a harmful effect of patents.\nOne attack on IPR is moral rather than utilitarian, claiming that inventions are mostly a collective, cumulative, path dependent, social creation and therefore, no one person or \ufb01rm should be able to monopolize them even for a limited period. The opposing argument is that the benefits of innovation arrive sooner when patents encourage innovators and their investors to increase their commitments. Roderick Long, a libertarian philosopher, observes, \"Ethically, property rights of any kind have to be justified as extensions of the right of individuals to control their own lives. Thus any alleged property rights that conflict with this moral basis\u2014like the \"right\" to own slaves\u2014are invalidated. In my judgment, intellectual property rights also fail to pass this test. To enforce copyright laws and the like is to prevent people from making peaceful use of the information they possess. If you have acquired the information legitimately (say, by buying a book), then on what grounds can you be prevented from using it, reproducing it, trading it? Is this not a violation of the freedom of speech and press? It may be objected that the person who originated the information deserves ownership rights over it. But information is not a concrete thing an individual can control; it is a universal, existing in other people's minds and other people's property, and over these the originator has no legitimate sovereignty. You cannot own information without owning other people\". Machlup concluded that patents do not have the intended effect of enhancing innovation. Self-declared anarchist Proudhon, in his 1847 seminal work noted, \"Monopoly is the natural opposite of competition,\" and continued, \"Competition is the vital force which animates the collective being: to destroy it, if such a supposition were possible, would be to kill society\"\nMindeli and Pipiya hold that the knowledge economy is an economy of abundance because it relies on the \"infinite potential\" of knowledge and ideas rather than on the limited resources of natural resources, labor and capital. Allison envisioned an egalitarian distribution of knowledge. Kinsella claims that IPR create artificial scarcity and reduce equality. Bouckaert wrote, \"Natural scarcity is that which follows from the relationship between man and nature. Scarcity is natural when it is possible to conceive of it before any human, institutional, contractual arrangement. Artificial scarcity, on the other hand, is the outcome of such arrangements. Artificial scarcity can hardly serve as a justification for the legal framework that causes that scarcity. Such an argument would be completely circular. On the contrary, artificial scarcity itself needs a justification\"  Corporations fund much IP creation and can acquire IP they do not create, to which Menon and others object. Andersen claims that IPR has increasingly become an instrument in eroding public domain.\nEthical and legal issues include: Patent infringement, copyright infringement, trademark infringement, patent and copyright misuse, submarine patents, biological patents, patent, copyright and trademark trolling, Employee raiding and monopolizing talent, Bioprospecting, biopiracy and industrial espionage, digital rights management.\nNotable IP copyright  cases include Napster, Eldred v. Ashcroft and Air Pirates.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Functional business areas", "sub_heading": "Intellectual property", "_id": "5000054892--3--6---1", "title": "Intellectual Property Rights: A Critical Approach"}
{"qas": [{"question": "Why do some people support corporate ethics policies that govern ethical conduct?", "answer": ""}, {"question": "Who is the author of the book business ethics?", "answer": "Richard DeGeorge", "ae_score": -0.4582554327009246, "qg_score": null}, {"question": "Who is the author of the book business ethics?", "answer": "Richard DeGeorge", "ae_score": -0.4582554327009246, "qg_score": null}], "content": "As part of more comprehensive compliance and ethics programs, many companies have formulated internal policies pertaining to the ethical conduct of employees. These policies can be simple exhortations in broad, highly generalized language (typically called a corporate ethics statement), or they can be more detailed policies, containing specific behavioural requirements (typically called corporate ethics codes). They are generally meant to identify the company's expectations of workers and to offer guidance on handling some of the more common ethical problems that might arise in the course of doing business. It is hoped that having such a policy will lead to greater ethical awareness, consistency in application, and the avoidance of ethical disasters.\nAn increasing number of companies also require employees to attend seminars regarding business conduct, which often include discussion of the company's policies, specific case studies, and legal requirements. Some companies even require their employees to sign agreements stating that they will abide by the company's rules of conduct.\nMany companies are assessing the environmental factors that can lead employees to engage in unethical conduct. A competitive business environment may call for unethical behaviour. Lying has become expected in fields such as trading. An example of this are the issues surrounding the unethical actions of the Salomon Brothers.\nNot everyone supports corporate policies that govern ethical conduct. Some claim that ethical problems are better dealt with by depending upon employees to use their own judgment.\nOthers believe that corporate ethics policies are primarily rooted in utilitarian concerns, and that they are mainly to limit the company's legal liability, or to curry public favour by giving the appearance of being a good corporate citizen. Ideally, the company will avoid a lawsuit because its employees will follow the rules. Should a lawsuit occur, the company can claim that the problem would not have arisen if the employee had only followed the code properly.\nSometimes there is disconnection between the company's code of ethics and the company's actual practices. Thus, whether or not such conduct is explicitly sanctioned by management, at worst, this makes the policy duplicitous, and, at best, it is merely a marketing tool.\nJones and Parker write, \"Most of what we read under the name business ethics is either sentimental common sense, or a set of excuses for being unpleasant.\" Many manuals are procedural form filling exercises unconcerned about the real ethical dilemmas. For instance, US Department of Commerce ethics program treats business ethics as a set of instructions and procedures to be followed by 'ethics officers'.,<ref name=program/> some others claim being ethical is just for the sake of being ethical. Business ethicists may trivialize the subject, offering standard answers that do not reflect the situation's complexity.<ref name=ag43/>\nAuthor of 'Business Ethics,' Richard DeGeorge writes in regard to the importance of maintaining a corporate code, \"Corporate codes have a certain usefulness and there are several advantages to developing them. First, the very exercise of doing so in itself is worthwhile, especially if it forces a large number of people in the firm to think through, in a fresh way, their mission and the important obligations they as a group and as individuals have to the firm, to each other, to their clients and customers, and to society as a whole. Second, once adopted a code can be used to generate continuing discussion and possible modification to the code. Third, it could help to inculcate in new employees at all levels the perspective of responsibility, the need to think in moral terms about their actions, and the importance of developing the virtues appropriate to their position.\"", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Implementation", "sub_heading": "Implementation", "_id": "5000054892--7--0---1", "title": "Corporate Ethics Codes \u2014 A Practical Guide"}
{"qas": [{"question": "Why are there no ethics officers at the top of the corporate hierarchy?", "answer": ""}, {"question": "When was the federal sentencing guidelines for organizations passed?", "answer": "1991", "ae_score": -0.3241972774879305, "qg_score": null}, {"question": "When was the federal sentencing guidelines for organizations passed?", "answer": "1991", "ae_score": -0.3241972774879305, "qg_score": null}], "content": "Following a series of fraud, corruption, and abuse scandals that affected the United States defense industry in the mid-1980s, the Defense Industry Initiative (DII) was created to promote ethical business practices and ethics management in multiple industries. Subsequent to these scandals, many organizations began appointing ethics officers (also referred to as \"compliance\" officers). In 1991, the Ethics & Compliance Officer Association (ECOA)\u2014originally the Ethics Officer Association (EOA)\u2014was founded at the Center for Business Ethics at Bentley University as a professional association for ethics and compliance officers.\nThe 1991 passing of the Federal Sentencing Guidelines for Organizations in 1991 was another factor in many companies appointing ethics/compliance officers. These guidelines, intended to assist judges with sentencing, set standards organizations must follow to obtain a reduction in sentence if they should be convicted of a federal offense.\nFollowing the high-profile corporate scandals of companies like Enron, WorldCom and Tyco between 2001 and 2004, and following the passage of the Sarbanes\u2013Oxley Act, many small and mid-sized companies also began to appoint ethics officers.\nOften reporting to the Chief Executive Officer, ethics officers focus on uncovering or preventing unethical and illegal actions. This is accomplished by assessing the ethical implications of the company's activities, making recommendations on ethical policies, and disseminating information to employees.\nThe effectiveness of ethics officers is not clear. The establishment of an ethics officer position is likely to be insufficient in driving ethical business practices without a corporate culture that values ethical behavior. These values and behaviors should be consistently and systemically supported by those at the top of the organization. Employees with strong community involvement, loyalty to employers, superiors or owners, smart work practices, trust among the team members do inculcate a corporate culture", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Implementation", "sub_heading": "Ethics officers", "_id": "5000054892--7--1---1", "title": "Ethics & Compliance Officers: The Role of Ethics Officers in Corporate Ethics"}
{"qas": [{"question": "What is the difference between environmentalism and social sustainability?", "answer": ""}, {"question": "What is one of the most important aspects of business ethics?", "answer": "social sustainability", "ae_score": -0.6481846279040544, "qg_score": null}, {"question": "What is one of the most important aspects of business ethics?", "answer": "social sustainability", "ae_score": -0.6481846279040544, "qg_score": null}], "content": "Many corporate and business strategies now include sustainability. In addition to the traditional environmental 'green' sustainability concerns, business ethics practices have expanded to include social sustainability. Social sustainability focuses on issues related to human capital in the business supply chain, such as worker's rights, working conditions, child labor, and human trafficking. Incorporation of these considerations is increasing, as consumers and procurement officials demand documentation of a business' compliance with national and international initiatives, guidelines, and standards. Many industries have organizations dedicated to verifying ethical delivery of products from start to finish, such as the Kimberly Process, which aims to stop the flow of conflict diamonds into international markets, or the Fair Wear Foundation, dedicated to sustainability and fairness in the garment industry.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Implementation", "sub_heading": "Sustainability Initiatives", "_id": "5000054892--7--2---1", "title": "Social Sustainability in the Business Supply Chain"}
{"qas": [{"question": "What is the difference between business ethics and political economy?", "answer": ""}, {"question": "Who argues that business ethics is an oxymoron?", "answer": "libertarian socialists", "ae_score": -0.41713994118684167, "qg_score": null}, {"question": "Who argues that business ethics is an oxymoron?", "answer": "libertarian socialists", "ae_score": -0.41713994118684167, "qg_score": null}], "content": "Business ethics is part of the philosophy of economics, the branch of philosophy that deals with the philosophical, political, and ethical underpinnings of business and economics. Business ethics operates on the premise, for example, that the ethical operation of a private business is possible\u2014those who dispute that premise, such as libertarian socialists, (who contend that \"business ethics\" is an oxymoron) do so by definition outside of the domain of business ethics proper.\nThe philosophy of economics also deals with questions such as what, if any, are the social responsibilities of a business; business management theory; theories of individualism vs. collectivism; free will among participants in the marketplace; the role of self interest; invisible hand theories; the requirements of social justice; and natural rights, especially property rights, in relation to the business enterprise.\nBusiness ethics is also related to political economy, which is economic analysis from political and historical perspectives. Political economy deals with the distributive consequences of economic actions.", "page_name": "Business ethics", "page_id": "Business%20ethics", "heading": "Related disciplines", "sub_heading": "Related disciplines", "_id": "5000054892--10---1---1", "title": "Business Ethics \u2014 The Philosophy of Economics"}
{"qas": [{"question": "Why is deuterium the most common element used in nuclear fusion?", "answer": ""}, {"question": "What is the most common nuclide used in nuclear fusion reactor designs?", "answer": "deuterium", "ae_score": -0.18079101234407718, "qg_score": null}, {"question": "What does deuterium slow in heavy water fission reactors?", "answer": "neutrons", "ae_score": null, "qg_score": null}], "content": "Deuterium is used in heavy water moderated fission reactors, usually as liquid DO, to slow neutrons without the high neutron absorption of ordinary hydrogen. This is a common commercial use for larger amounts of deuterium.\nIn research reactors, liquid D is used in cold sources to moderate neutrons to very low energies and wavelengths appropriate for scattering experiments.\nExperimentally, deuterium is the most common nuclide used in nuclear fusion reactor designs, especially in combination with tritium, because of the large reaction rate (or nuclear cross section) and high energy yield of the D\u2013T reaction. There is an even higher-yield D\u2013 fusion reaction, though the breakeven point of D\u2013 is higher than that of most other fusion reactions; together with the scarcity of , this makes it implausible as a practical power source until at least D\u2013T and D\u2013D fusion reactions have been performed on a commercial scale. However, commercial nuclear fusion is not yet an accomplished technology.", "page_name": "Deuterium", "page_id": "Deuterium", "heading": "Applications", "sub_heading": "Applications", "_id": "5000055017--2--0---1", "title": "Deuterium in Nuclear Fusion Reactors"}
{"qas": [{"question": "Why is deuterium used in nuclear magnetic resonance spectroscopy?", "answer": ""}, {"question": "Which chemical element is most commonly used in hydrogen nuclear magnetic resonance spectroscopy (pro?", "answer": "Deuterium", "ae_score": -0.8698252592055188, "qg_score": null}, {"question": "Which chemical element is most commonly used in hydrogen nuclear magnetic resonance spectroscopy (pro?", "answer": "Deuterium", "ae_score": -0.8698252592055188, "qg_score": null}], "content": "Deuterium is most commonly used in hydrogen nuclear magnetic resonance spectroscopy (proton NMR) in the following way. NMR ordinarily requires compounds of interest to be analyzed as dissolved in solution. Because of deuterium's nuclear spin properties which differ from the light hydrogen usually present in organic molecules, NMR spectra of hydrogen/protium are highly differentiable from that of deuterium, and in practice deuterium is not \"seen\" by an NMR instrument tuned for light-hydrogen. Deuterated solvents (including heavy water, but also compounds like deuterated chloroform, CDCl) are therefore routinely used in NMR spectroscopy, in order to allow only the light-hydrogen spectra of the compound of interest to be measured, without solvent-signal interference.\nNuclear magnetic resonance spectroscopy can also be used to obtain information about the deuteron's environment in isotopically labelled samples (Deuterium NMR).  For example, the flexibility in the tail, which is a long hydrocarbon chains, in deuterium-labelled lipid molecules can be quantified using solid state deuterium NMR.\nDeuterium NMR spectra are especially informative in the solid state because of its relatively small quadrupole moment in comparison with those of bigger quadrupolar nuclei such as chlorine-35, for example.", "page_name": "Deuterium", "page_id": "Deuterium", "heading": "Applications", "sub_heading": "NMR spectroscopy", "_id": "5000055017--2--1---1", "title": "Deuterium NMR Spectra"}
{"qas": [{"question": "What is deuterium and how does it work?", "answer": ""}, {"question": "The enrichment of heavy isotopes in rainwater is plotted along what line?", "answer": "global meteoric water line", "ae_score": -0.5133375309181972, "qg_score": null}, {"question": "How can deuterium be distinguished from hydrogen?", "answer": "mass spectrometry", "ae_score": null, "qg_score": null}], "content": "In chemistry, biochemistry and environmental sciences, deuterium is used as a non-radioactive, stable isotopic tracer, for example, in the doubly labeled water test. In chemical reactions and metabolic pathways, deuterium behaves somewhat similarly to ordinary hydrogen (with a few chemical differences, as noted). It can be distinguished from ordinary hydrogen most easily by its mass, using mass spectrometry or infrared spectrometry. Deuterium can be detected by femtosecond infrared spectroscopy, since the mass difference drastically affects the frequency of molecular vibrations; deuterium-carbon bond vibrations are found in spectral regions free of other signals.\nMeasurements of small variations in the natural abundances of deuterium, along with those of the stable heavy oxygen isotopes O and O, are of importance in hydrology, to trace the geographic origin of Earth's waters. The heavy isotopes of hydrogen and oxygen in rainwater (so-called meteoric water) are enriched as a function of the environmental temperature of the region in which the precipitation falls (and thus enrichment is related to mean latitude). The relative enrichment of the heavy isotopes in rainwater (as referenced to mean ocean water), when plotted against temperature falls predictably along a line called the global meteoric water line (GMWL). This plot allows samples of precipitation-originated water to be identified along with general information about the climate in which it originated. Evaporative and other processes in bodies of water, and also ground water processes, also differentially alter the ratios of heavy hydrogen and oxygen isotopes in fresh and salt waters, in characteristic and often regionally distinctive ways. The ratio of concentration of H to H is usually indicated with a delta as \u03b4H and the geographic patterns of these values are plotted in maps termed as isoscapes. Stable isotope are incorporated into plants and animals and an analysis of the ratios in a migrant bird or insect can help suggest a rough guide to their origins.", "page_name": "Deuterium", "page_id": "Deuterium", "heading": "Applications", "sub_heading": "Tracing", "_id": "5000055017--2--2---1", "title": "Deuterium: A Stable Isotope Tracer"}
{"qas": [{"question": "Why is hydrogen so important in chemistry?", "answer": ""}, {"question": "What is an important component in all materials of organic chemistry and life science?", "answer": "Hydrogen", "ae_score": -0.6053394366789945, "qg_score": null}, {"question": "What do hydrogen and deuterium interact strongly with?", "answer": "neutrons", "ae_score": null, "qg_score": null}], "content": "Neutron scattering techniques particularly profit from availability of deuterated samples: The H and D cross sections are very distinct and different in sign, which allows contrast variation in such experiments. Further, a nuisance problem of ordinary hydrogen is its large incoherent neutron cross section, which is nil for D. The substitution of deuterium atoms for hydrogen atoms thus reduces scattering noise.\nHydrogen is an important and major component in all materials of organic chemistry and life science, but it barely interacts with X-rays. As hydrogen (and deuterium) interact strongly with neutrons, neutron scattering techniques, together with a modern deuteration facility, fills a niche in many studies of macromolecules in biology and many other areas.", "page_name": "Deuterium", "page_id": "Deuterium", "heading": "Applications", "sub_heading": "Contrast properties", "_id": "5000055017--2--3---1", "title": "Neutron Scattering Techniques"}
{"qas": [{"question": "Why can't we make hydrogen bombs?", "answer": ""}, {"question": "What is another name for light hydrogen?", "answer": "protium", "ae_score": -0.5566328480134771, "qg_score": null}, {"question": "What is another name for light hydrogen?", "answer": "protium", "ae_score": -0.5566328480134771, "qg_score": null}], "content": "This is discussed below. It is notable that although most stars, including the Sun, generate energy over most of their lives by fusing hydrogen into heavier elements, such fusion of light hydrogen (protium) has never been successful in the conditions attainable on Earth. Thus, all artificial fusion, including the hydrogen fusion that occurs in so-called hydrogen bombs, requires heavy hydrogen (either tritium or deuterium, or both) in order for the process to work.", "page_name": "Deuterium", "page_id": "Deuterium", "heading": "Applications", "sub_heading": "Nuclear weapons", "_id": "5000055017--2--4---1", "title": "How to Make a Heavy Hydrogen Bomb"}
{"qas": [{"question": "How did the earth get so hot after the Ice Age?", "answer": ""}, {"question": "Where did the last ice age occur in the atmosphere?", "answer": "volcanoes", "ae_score": -0.3606150487318479, "qg_score": null}, {"question": "Where did the last ice age occur in the atmosphere?", "answer": "volcanoes", "ae_score": -0.3606150487318479, "qg_score": null}], "content": "There is evidence that greenhouse gas levels fell at the start of ice ages and rose during the retreat of the ice sheets, but it is difficult to establish cause and effect (see the notes above on the role of weathering). Greenhouse gas levels may also have been affected by other factors which have been proposed as causes of ice ages, such as the movement of continents and volcanism.\nThe Snowball Earth hypothesis maintains that the severe freezing in the late Proterozoic was ended by an increase in  levels in the atmosphere, mainly from volcanoes, and some supporters of Snowball Earth argue that it was caused in the first place by a reduction in atmospheric . The hypothesis also warns of future Snowball Earths.\nIn 2009, further evidence was provided that changes in solar insolation provide the initial trigger for the earth to warm after an Ice Age, with secondary factors like increases in greenhouse gases accounting for the magnitude of the change.\nThere is considerable evidence that over the very recent period of the last 100\u20131000 years, the sharp increases in human activity, especially the burning of fossil fuels, has caused the parallel sharp and accelerating increase in atmospheric greenhouse gases which trap the sun's heat. The consensus theory of the scientific community is that the resulting greenhouse effect is a principal cause of the increase in global warming which has occurred over the same period, and a chief contributor to the accelerated melting of the remaining glaciers and polar ice. A 2012 investigation finds that dinosaurs released methane through digestion in a similar amount to humanity's current methane release, which \"could have been a key factor\" to the very warm climate 150 million years ago.\nWilliam Ruddiman has proposed the early anthropocene hypothesis, according to which the anthropocene era, as some people call the most recent period in the earth's history when the activities of the human species first began to have a significant global impact on the earth's climate and ecosystems, did not begin in the 18th century with the advent of the Industrial Era, but dates back to 8,000 years ago, due to intense farming activities of our early agrarian ancestors. It was at that time that atmospheric greenhouse gas concentrations stopped following the periodic pattern of the Milankovitch cycles. In his overdue-glaciation hypothesis Ruddiman states that an incipient glacial would probably have begun several thousand years ago, but the arrival of that scheduled glacial was forestalled by the activities of early farmers.\nAt a meeting of the American Geophysical Union (December 17, 2008), scientists detailed evidence in support of the controversial idea that the introduction of large-scale rice agriculture in Asia, coupled with extensive deforestation in Europe began to alter world climate by pumping significant amounts of greenhouse gases into the atmosphere over the last 1,000 years. In turn, a warmer atmosphere heated the oceans making them much less efficient storehouses of carbon dioxide and reinforcing global warming, possibly forestalling the onset of a new glacial age.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Causes of ice ages", "_id": "5000055229--5--0---1", "title": "Climate Change and the Global Warming of the Past"}
{"qas": [{"question": "How do geologists know that the Earth will continue to experience glacial periods in the future?", "answer": ""}, {"question": "How many continents are there in the ice age?", "answer": "three", "ae_score": -0.19657284504379927, "qg_score": null}, {"question": "How many continents are there in the ice age?", "answer": "three", "ae_score": -0.19657284504379927, "qg_score": null}], "content": "The geological record appears to show that ice ages start when the continents are in positions which block or reduce the flow of warm water from the equator to the poles and thus allow ice sheets to form. The ice sheets increase Earth's reflectivity and thus reduce the absorption of solar radiation. With less radiation absorbed the atmosphere cools; the cooling allows the ice sheets to grow, which further increases reflectivity in a positive feedback loop. The ice age continues until the reduction in weathering causes an increase in the greenhouse effect.\nThere are three known configurations of the continents which block or reduce the flow of warm water from the equator to the poles:\nSince today's Earth has a continent over the South Pole and an almost land-locked ocean over the North Pole, geologists believe that Earth will continue to experience glacial periods in the geologically near future.\nSome scientists believe that the Himalayas are a major factor in the current ice age, because these mountains have increased Earth's total rainfall and therefore the rate at which carbon dioxide is washed out of the atmosphere, decreasing the greenhouse effect. The Himalayas' formation started about 70 million years ago when the Indo-Australian Plate collided with the Eurasian Plate, and the Himalayas are still rising by about 5 mm per year because the Indo-Australian plate is still moving at 67 mm/year. The history of the Himalayas broadly fits the long-term decrease in Earth's average temperature since the mid-Eocene, 40 million years ago.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Position of the continents", "_id": "5000055229--5--1---1", "title": "The Ice Age and the Himalayas"}
{"qas": [{"question": "How did the sea levels rise so much during the last ice age?", "answer": ""}, {"question": "During the last glacial period the sea level fluctuated by how much?", "answer": "20\u201330 m", "ae_score": -0.7043889949682978, "qg_score": null}, {"question": "During the last glacial period the sea level fluctuated by how much?", "answer": "20\u201330 m", "ae_score": -0.7043889949682978, "qg_score": null}], "content": "Another important contribution to ancient climate regimes is the variation of '''ocean currents''', which are modified by continent position, sea levels and salinity, as well as other factors. They have the ability to cool (e.g. aiding the creation of Antarctic ice) and the ability to warm (e.g. giving the British Isles a temperate as opposed to a boreal climate). The closing of the Isthmus of Panama about 3 million years ago may have ushered in the present period of strong glaciation over North America by ending the exchange of water between the tropical Atlantic and Pacific Oceans.\nAnalyses suggest that ocean current fluctuations can adequately account for recent glacial oscillations. During the last glacial period the sea-level has fluctuated 20\u201330 m as water was sequestered, primarily in the Northern Hemisphere ice sheets. When ice collected and the sea level dropped sufficiently, flow through the Bering Strait (the narrow strait between Siberia and Alaska is about 50 m deep today) was reduced, resulting in increased flow from the North Atlantic. This realigned the thermohaline circulation in the Atlantic, increasing heat transport into the Arctic, which melted the polar ice accumulation and reduced other continental ice sheets. The release of water raised sea levels again, restoring the ingress of colder water from the Pacific with an accompanying shift to northern hemisphere ice accumulation.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Fluctuations in ocean currents", "_id": "5000055229--5--2---1", "title": "Ice age | Causes of ice ages | Fluctuations in ocean currents"}
{"qas": [{"question": "How did the ice caps melt?", "answer": ""}, {"question": "Where did the last glacial Maximum occur?", "answer": "the Tibetan Plateau", "ae_score": null, "qg_score": null}, {"question": "Where did the last glacial Maximum occur?", "answer": "the Tibetan Plateau", "ae_score": null, "qg_score": null}], "content": "Matthias Kuhle's geological theory of Ice Age development was suggested by the existence of an ice sheet covering the Tibetan Plateau during the Ice Ages (Last Glacial Maximum?). According to Kuhle, the plate-tectonic uplift of Tibet past the snow-line has led to a surface of c. 2,400,000 square kilometres (930,000 sq mi) changing from bare land to ice with a 70% greater albedo. The reflection of energy into space resulted in a global cooling, triggering the Pleistocene Ice Age. Because this highland is at a subtropical latitude, with 4 to 5 times the insolation of high-latitude areas, what would be Earth's strongest heating surface has turned into a cooling surface.\nKuhle explains the interglacial periods by the 100,000-year cycle of radiation changes due to variations in Earth's orbit. This comparatively insignificant warming, when combined with the lowering of the Nordic inland ice areas and Tibet due to the weight of the superimposed ice-load, has led to the repeated complete thawing of the inland ice areas.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Uplift of the Tibetan plateau and surrounding mountain areas above the snowline", "_id": "5000055229--5--3---1", "title": "Kuhle's Geological Theory of the Ice Age"}
{"qas": [{"question": "Why does the Earth have a 100,000 year cycle?", "answer": ""}, {"question": "Who proposed a model that explains the 100,000-year ice age?", "answer": "William Ruddiman", "ae_score": -0.32535655790110807, "qg_score": null}, {"question": "What is the effect of eccentricity on precession?", "answer": "model recession", "ae_score": null, "qg_score": null}], "content": "The Milankovitch cycles are a set of cyclic variations in characteristics of the Earth's orbit around the Sun. Each cycle has a different length, so at some times their effects reinforce each other and at other times they (partially) cancel each other.\nThere is strong evidence that the Milankovitch cycles affect the occurrence of glacial and interglacial periods within an ice age. The present ice age is the most studied and best understood, particularly the last 400,000 years, since this is the period covered by ice cores that record atmospheric composition and proxies for temperature and ice volume. Within this period, the match of glacial/interglacial frequencies to the Milankovi\u0107 orbital forcing periods is so close that orbital forcing is generally accepted. The combined effects of the changing distance to the Sun, the precession of the Earth's axis, and the changing tilt of the Earth's axis redistribute the sunlight received by the Earth. Of particular importance are changes in the tilt of the Earth's axis, which affect the intensity of seasons. For example, the amount of solar influx in July at 65 degrees north latitude varies by as much as 22% (from 450 W/m\u00b2 to 550 W/m\u00b2). It is widely believed that ice sheets advance when summers become too cool to melt all of the accumulated snowfall from the previous winter. Some believe that the strength of the orbital forcing is too small to trigger glaciations, but feedback mechanisms like  may explain this mismatch.\nWhile Milankovitch forcing predicts that cyclic changes in the Earth's orbital elements can be expressed in the glaciation record, additional explanations are necessary to explain which cycles are observed to be most important in the timing of glacial\u2013interglacial periods. In particular, during the last 800,000 years, the dominant period of glacial\u2013interglacial oscillation has been 100,000 years, which corresponds to changes in Earth's orbital eccentricity and orbital inclination. Yet this is by far the weakest of the three frequencies predicted by Milankovitch. During the period 3.0\u20130.8 million years ago, the dominant pattern of glaciation corresponded to the 41,000-year period of changes in Earth's obliquity (tilt of the axis). The reasons for dominance of one frequency versus another are poorly understood and an active area of current research, but the answer probably relates to some form of resonance in the Earth's climate system.\nThe \"traditional\" Milankovitch explanation struggles to explain the dominance of the 100,000-year cycle over the last 8 cycles. Richard A. Muller, Gordon J. F. MacDonald, and others have pointed out that those calculations are for a two-dimensional orbit of Earth but the three-dimensional orbit also has a 100,000-year cycle of orbital inclination. They proposed that these variations in orbital inclination lead to variations in insolation, as the Earth moves in and out of known dust bands in the solar system. Although this is a different mechanism to the traditional view, the \"predicted\" periods over the last 400,000 years are nearly the same. The Muller and MacDonald theory, in turn, has been challenged by Jose Antonio Rial.\nAnother worker, William Ruddiman, has suggested a model that explains the 100,000-year cycle by the modulating effect of eccentricity (weak 100,000-year cycle) on precession (26,000-year cycle) combined with greenhouse gas feedbacks in the 41,000- and 26,000-year cycles. Yet another theory has been advanced by Peter Huybers who argued that the 41,000-year cycle has always been dominant, but that the Earth has entered a mode of climate behavior where only the second or third cycle triggers an ice age. This would imply that the 100,000-year periodicity is really an illusion created by averaging together cycles lasting 80,000 and 120,000 years. This theory is consistent with a simple empirical multi-state model proposed by Didier Paillard. Paillard suggests that the late Pleistocene glacial cyclescan be seen as jumps between three quasi-stable climate states. The jumps are induced by the orbital forcing, while in the early Pleistocene the 41,000-year glacial cycles resulted from jumps between only two climate states. A dynamicalmodel explaining this behavior was proposed by Peter Ditlevsen. This is in support of the suggestion that the late Pleistocene glacial cycles are not due to the weak 100,000-year eccentricity cycle, but a non-linear response to mainly the 41,000-year obliquity cycle.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Variations in Earth's orbit (Milankovitch cycles)", "_id": "5000055229--5--4---1", "title": "The Milankovitch Cycles"}
{"qas": [{"question": "How did volcanoes cause global warming?", "answer": ""}, {"question": "What caused the end of the ice age?", "answer": "Volcanic eruptions", "ae_score": -0.7852079396437579, "qg_score": null}, {"question": "What caused the end of the ice age?", "answer": "Volcanic eruptions", "ae_score": -0.7852079396437579, "qg_score": null}], "content": "Volcanic eruptions may have contributed to the inception and/or the end of ice age periods. At times during the paleoclimate, carbon dioxide levels were two or three times greater than today. Volcanoes and movements in continental plates contributed to high amounts of CO2 in the atmosphere. Carbon dioxide from volcanoes probably contributed to periods with highest overall temperatures. One suggested explanation of the Paleocene-Eocene Thermal Maximum is that undersea volcanoes released methane from clathrates and thus caused a large and rapid increase in the greenhouse effect.  There appears to be no geological evidence for such eruptions at the right time, but this does not prove they did not happen.", "page_name": "Ice age", "page_id": "Ice%20age", "heading": "Causes of ice ages", "sub_heading": "Volcanism", "_id": "5000055229--5--6---1", "title": "The Paleocene-Eocene Thermal Maximum"}
{"qas": [{"question": "Why do people with narcolepsy get so much sleep?", "answer": ""}, {"question": "What is the name of the antidepressant used to treat narcolepsy?", "answer": "Venlafaxine", "ae_score": -0.2172312543626486, "qg_score": null}, {"question": "What type of drugs are used to treat narcolepsy?", "answer": "selective serotonin reuptake inhibitors", "ae_score": null, "qg_score": null}], "content": "People with narcolepsy can be substantially helped, but not cured. Treatment is tailored to the individual, based on symptoms and therapeutic response. The time required to achieve optimal control of symptoms is highly variable, and may take several months or longer. Medication adjustments are frequently necessary, and complete control of symptoms is seldom possible. While oral medications are the mainstay of formal narcolepsy treatment, lifestyle changes are also important.\nThe main treatment of excessive daytime sleepiness in narcolepsy is central nervous system stimulants such as methylphenidate, amphetamine, dextroamphetamine, modafinil, and armodafinil. In late 2007 an alert for severe adverse skin reactions to modafinil was issued by the FDA.\nAnother drug that is used is atomoxetine, a non-stimulant and norepinephrine reuptake inhibitor (NRI), that has no addiction liability or recreational effects. In many cases, planned regular short naps can reduce the need for pharmacological treatment of the EDS, but only improve symptoms for a short duration.  A 120 minute nap provided benefit for 3 hours in patient alertness whereas a 15 minute nap provided no benefit. Daytime naps are not a replacement for nighttime sleep. Ongoing communication between the health care provider, patient, and the patient's family members is important for optimal management of narcolepsy.\nAnother FDA-approved treatment option for narcolepsy is sodium oxybate, also known as sodium gamma-hydroxybutyrate (GHB). It can be used for cataplexy associated with narcolepsy and excessive daytime sleepiness associated with narcolepsy.\nNarcolepsy has sometimes been treated with selective serotonin reuptake inhibitors and tricyclic antidepressants, such as clomipramine, imipramine, or protriptyline, as well as other drugs that suppress REM sleep. Venlafaxine, an antidepressant which blocks the reuptake of serotonin and norepinephrine, has shown usefulness in managing symptoms of cataplexy, however, it has notable side-effects including sleep disruption.", "page_name": "Narcolepsy", "page_id": "Narcolepsy", "heading": "Treatment", "sub_heading": "Treatment", "_id": "5000055775--3---1---1", "title": "Narcolepsy Treatment and Treatment"}
{"qas": [{"question": "What is the subprime mortgage crisis?", "answer": ""}, {"question": "How many subprime loans were there in the us in the mid 1990s?", "answer": "$30 billion", "ae_score": -0.3900922415633467, "qg_score": null}, {"question": "The subprime crisis in the late 1990s was associated with the securitization?", "answer": "mortgage", "ae_score": null, "qg_score": null}], "content": "Although most references to the Subprime Mortgage Crisis refer to events and conditions that led to the financial crisis and subsequent recession that began in 2008, a much smaller bubble and collapse occurred in the mid- to late-1990s, sometimes dubbed \"Subprime I\" or \"Subprime 1.0\". It ended in 1999 when the rate of subprime mortgage securitization dropped from 55.1% in 1998 to 37.4% in 1999. In the two years following the 1998 Russian financial crisis, \"eight of the top ten\" subprime lenders \"declared bankruptcy, ceased operations, or sold out to stronger firms.\"\nThe crisis is said to have had \"had all the earmarks of a classic bubble\" with enthusiasm over rising stock prices replacing caution over shoddy business practices and concern over whether the earnings of the companies were sustainable. Loans were made to borrowers who were unable to pay them back. The subprime mortgage companies began taking unexpected write-downs as mortgages were refinanced at lower interest rates. Much of the reported profits turned out to be illusory and companies such as Famco went under. Along with the bankruptcies came a wave of lawsuits and complaints from consumer advocates, who accused the subprime industry of engaging in predatory lending. The impact was slight compared to the later bubble.  \nSubprime I was smaller in size \u2014 in the mid-1990s $30 billion of mortgages constituted \"a big year\" for subprime lending, by 2005 there were $625 billion in subprime mortgage loans, $507 billion of which were in mortgage backed securities \u2014 and was essentially \"really high rates for borrowers with bad credit\". Mortgages were mostly fixed-rate, still required borrowers to prove they could pay by documenting income, etc. By 2006, 75% of subprime loans were some form of floating-rate, usually fixed for the first two years.\"", "page_name": "Subprime crisis background information", "page_id": "Subprime%20crisis%20background%20information", "heading": "Precursor, \"Subprime I\"", "sub_heading": "Precursor, \"Subprime I\"", "_id": "5000056146--2---1---1", "title": "The Subprime Mortgage Crisis \u2014 A History"}
{"qas": [{"question": "Why did Lehman Brothers and Bear Stearns make so much money during the financial crisis?", "answer": ""}, {"question": "When did the subprime crisis start in the us?", "answer": "2006", "ae_score": -0.5894694825953459, "qg_score": null}, {"question": "What happened to the majority of subprime loans in the us in 2006?", "answer": "default", "ae_score": null, "qg_score": null}], "content": "In 2006, Lehman Brothers and Bear Stearns, whose fixed-income franchises benefitted from having integrated mortgage origination businesses, were seen as runaway success stories. Many more investment banks had already built large mortgage desks, and invested heavily in subprime platforms. Mortgage origination and securitization generated lucrative fees during the time when the US market developed away from the traditional agency/CMO model.\nFannie Mae and Freddie Mac shrunk their balance sheets substantially as conforming mortgage origination volumes diminished, and private label securitization grew substantially from 2002. Large-scale defaults from subprime lending had yet to hit headlines in 2006; rating agencies began sounding early alarm bells in the summer of 2006 but it was anticipated delinquencies would go up with the biggest rollovers on the new loans (around 2008).", "page_name": "Subprime crisis background information", "page_id": "Subprime%20crisis%20background%20information", "heading": "Background to the crisis", "sub_heading": "Background to the crisis", "_id": "5000056146--3---1---1", "title": "Mortgage Origination and Securitization in the United States"}
{"qas": [{"question": "What was the \"credit freeze\" that caused the 2008 financial crisis?", "answer": ""}, {"question": "Who provided the background to the subprime crisis?", "answer": "Thomas Friedman", "ae_score": -0.05403362477365754, "qg_score": null}, {"question": "The subprime crisis of 2007 resulted in the loss of billions of dollars in what?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "The crisis has gone through stages.  First, during late 2007, over 100 mortgage lending companies went bankrupt as subprime mortgage-backed securities could no longer be sold to investors to acquire funds. Second, starting in Q4 2007 and in each quarter since then, financial institutions have recognized massive losses as they adjust the value of their mortgage backed securities to a fraction of their purchased prices. These losses as the housing market continued to deteriorate meant that the banks have a weaker capital base from which to lend. Third, during Q1 2008, investment bank Bear Stearns was hastily merged with bank JP Morgan with $30 billion in government guarantees, after it was unable to continue borrowing to finance its operations.\nFourth, during September 2008, the system approached meltdown. In early September Fannie Mae and Freddie Mac, representing $5 trillion in mortgage obligations, were nationalized by the U.S. government as mortgage losses increased. Next, investment bank Lehman Brothers filed for bankruptcy. In addition, two large U.S. banks (Washington Mutual and Wachovia) became insolvent and were sold to stronger banks. The world's largest insurer, AIG, was 80% nationalized by the U.S. government, due to concerns regarding its ability to honor its obligations via a form of financial insurance called credit default swaps.\nThese sequential and significant institutional failures, particularly the Lehman bankruptcy, involved further seizing of credit markets and more serious global impact. The interconnected nature of Lehman was such that its failure triggered system-wide (systemic) concerns regarding the ability of major institutions to honor their obligations to counterparties. The interest rates banks charged to each other (see the TED spread) increased to record levels and various methods of obtaining short-term funding became less available to non-financial corporations.\nIt was this \"credit freeze\" that some described as a near-complete seizing of the credit markets in September that drove the massive bailout procedures implemented by worldwide governments in Q4 2008. Prior to that point, each major U.S. institutional intervention had been ad-hoc; critics argued this damaged investor and consumer confidence in the U.S. government's ability to deal effectively and proactively with the crisis. Further, the judgment and credibility of senior U.S. financial leadership was called into question.\nSince the near-meltdown, the crisis has shifted into what some consider to be a deep recession and others consider to be a \"reset\" of economic activity at a lower level, now that enormous lending capacity has been removed from the system. Unsustainable U.S. borrowing and consumption were significant drivers of global economic growth in the years leading up to the crisis. Record rates of housing foreclosures are expected to continue in the U.S. during the 2009-2011, continuing to inflict losses on financial institutions. Dramatically reduced wealth due to both housing prices and stock market declines are unlikely to enable U.S. consumption to return to pre-crisis levels.\nThomas Friedman summarized how the crisis has moved through stages: \nAlan Greenspan has stated that until the record level of housing inventory currently on the market declines to more typical historical levels, there will be downward pressure on home prices. As long as the uncertainty remains regarding housing prices, mortgage-backed securities will continue to decline in value, placing the health of banks at risk.", "page_name": "Subprime crisis background information", "page_id": "Subprime%20crisis%20background%20information", "heading": "Stages of the crisis", "sub_heading": "Stages of the crisis", "_id": "5000056146--4---1---1", "title": "The Financial Crisis: A Brief History"}
{"qas": [{"question": "What is the first vicious cycle in the US housing market?", "answer": ""}, {"question": "How much did the housing market decline in 2008?", "answer": "over 20%", "ae_score": -0.2988100269685813, "qg_score": null}, {"question": "What type of securities were they selling at the time of the crisis?", "answer": "securities", "ae_score": null, "qg_score": null}], "content": "The first vicious cycle is within the housing market and relates to the feedback effects of payment delinquencies and foreclosures on home prices. By September 2008, average U.S. housing prices had declined by over 20% from their mid-2006 peak.\nThis major and unexpected decline in house prices means that many borrowers have zero or negative equity in their homes, meaning their homes were worth less than their mortgages. As of March 2008, an estimated 8.8 million borrowers \u2014 10.8% of all homeowners \u2014 had negative equity in their homes, a number that is believed to have risen to 12 million by November 2008. Borrowers in this situation have an incentive to \"walk away\" from their mortgages and abandon their homes, even though doing so will damage their credit rating for a number of years.\nThe reason is that unlike what is the case in most other countries, American residential mortgages are non-recourse loans; once the creditor has regained the property purchased with a mortgage in default, he has no further claim against the defaulting borrower's income or assets. As more borrowers stop paying their mortgage payments, foreclosures and the supply of homes for sale increase. This places downward pressure on housing prices, which further lowers homeowners' equity. The decline in mortgage payments also reduces the value of mortgage-backed securities, which erodes the net worth and financial health of banks. This vicious cycle is at the heart of the crisis.\nThe second vicious cycle is between the housing market and financial market. Foreclosures reduce the cash flowing into banks and the value of mortgage-backed securities (MBS) widely held by banks.  Banks incur losses and require additional funds (\u201crecapitalization\u201d).  If banks are not capitalized sufficiently to lend, economic activity slows and unemployment increases, which further increases foreclosures.\nAs of August 2008, financial firms around the globe have written down their holdings of subprime related securities by US$501 billion. Mortgage defaults and provisions for future defaults caused profits at the 8533 USA depository institutions insured by the FDIC to decline from $35.2 billion in 2006 Q4 billion to $646 million in the same quarter a year later, a decline of 98%. 2007 Q4 saw the worst bank and thrift quarterly performance since 1990. In all of 2007, insured depository institutions earned approximately $100 billion, down 31% from a record profit of $145 billion in 2006. Profits declined from $35.6 billion in 2007 Q1 to $19.3 billion in 2008 Q1, a decline of 46%.\nFederal Reserve data indicates banks have significantly tightened lending standards throughout the crisis.", "page_name": "Subprime crisis background information", "page_id": "Subprime%20crisis%20background%20information", "heading": "Vicious Cycles", "sub_heading": "Vicious Cycles", "_id": "5000056146--12---1---1", "title": "Three Viral Cycles of the Financial Crisis"}
